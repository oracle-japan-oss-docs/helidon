{
    "docs": [
        {
            "location": "/about/archetype",
            "text": " Helidon CLI provides a convenient way to bootstrap Helidon applications. It allows you to choose from a set of archetypes i.e. application with pre-defined feature sets and lets you customize it by providing a host of options. ",
            "title": "Introduction"
        },
        {
            "location": "/about/archetype",
            "text": " This option creates a Helidon project that includes multiple REST operations along with default observability setup and a set of dependencies to enable ease of development e.g. in case of Helidon MP, it uses helidon-microprofile bundle instead of minimal helidon-microprofile-core bundle. ",
            "title": "QuickStart"
        },
        {
            "location": "/about/archetype",
            "text": " This option builds on QuickStart to demonstrate how to integrate with database (in-memory H2, by default). In case of, Helidon SE that uses the DbClient API while for Helidon MP that uses JPA. ",
            "title": "Database"
        },
        {
            "location": "/about/archetype",
            "text": " This option builds on QuickStart to demonstrate integration with Oracle Cloud Infrastructure (OCI) services using the OCI SDK. Generated project showcases OpenApi-driven development approach where the practice of designing and building APIs is done first, then creating the rest of an application around them is implemented next. This is available for Helidon MP only. ",
            "title": "OCI"
        },
        {
            "location": "/about/archetype",
            "text": " This option enables user to create Helidon project of their choice, suitable to start from scratch i.e. bare minimum, if default values are chosen Or choose from many options available. ",
            "title": "Custom"
        },
        {
            "location": "/about/archetype",
            "text": " Helidon provides the following set of archetypes to bootstrap your application development journey. QuickStart This option creates a Helidon project that includes multiple REST operations along with default observability setup and a set of dependencies to enable ease of development e.g. in case of Helidon MP, it uses helidon-microprofile bundle instead of minimal helidon-microprofile-core bundle. Database This option builds on QuickStart to demonstrate how to integrate with database (in-memory H2, by default). In case of, Helidon SE that uses the DbClient API while for Helidon MP that uses JPA. OCI This option builds on QuickStart to demonstrate integration with Oracle Cloud Infrastructure (OCI) services using the OCI SDK. Generated project showcases OpenApi-driven development approach where the practice of designing and building APIs is done first, then creating the rest of an application around them is implemented next. This is available for Helidon MP only. Custom This option enables user to create Helidon project of their choice, suitable to start from scratch i.e. bare minimum, if default values are chosen Or choose from many options available. ",
            "title": "Archetypes"
        },
        {
            "location": "/about/archetype",
            "text": " You can scaffold a new Maven project based on these archetypes. See Helidon CLI and our Helidon SE QuickStart Guide or Helidon MP QuickStart Guide for more information. Once the archetype is selected, the other options have defaults and the project is generated in a directory named after the artifactId value. It mainly contains the following: Maven structure skeletal application code associated unit test code example Dockerfile files application configuration file(s) instructions to build and run application/test ",
            "title": "Generated Application Structure"
        },
        {
            "location": "/about/archetype",
            "text": " The easiest way to get started is to follow the instructions in the README file and familiarize with layout and features provided to build upon them. In addition, look at the pom.xml files. You can find a suitable Helidon parent pom file that will enable you to use the different dependencies managed and provided by Helidon. ",
            "title": "Using Generated Application"
        },
        {
            "location": "/about/benefits",
            "text": " Open Source with Support Two API Flavors for Two Programming Styles Feature Richness Enterprise Features Integrations ",
            "title": "preambule"
        },
        {
            "location": "/about/benefits",
            "text": " Helidon is open-source software, licensed with Apache License, Version 2.0. Its codebase is kept in GitHub. Its artifacts are published to Maven Central. This makes it easy for users to inspect, modify, and contribute to its source code. The Apache license makes it easy for organizations to adopt Helidon from a licensing perspective. Publishing artifacts to Maven Central makes it easy and natural for developers and operators to pull Helidon binaries into development environments and CI/CD pipelines. In short, Helidon is intentionally aligned with modern mainstream development practices to make it as easy as possible to adopt and use. And yet, enterprise-grade support is also available for Helidon. Oracle offers cost-competitive commercial support for Helidon, for customers serious about support SLAs for their production operations. So, customers can get the best of both worlds: seamless incorporation of Helidon into DevOps practices and third- party product approvals, and award-winning customer support for high-scale mission-critical production applications. ",
            "title": "Open Source with Support"
        },
        {
            "location": "/about/benefits",
            "text": " Helidon offers two API flavors: Helidon SE, and Helidon MP. Both are fun to program in, but each caters to a different style of programming ",
            "title": "Two API Flavors for Two Programming Styles"
        },
        {
            "location": "/about/benefits",
            "text": " Both API flavors, Helidon SE and Helidon MP, offer a rich and similar set of features, like configuration and metrics and security, as examples. In Helidon MP, the APIs for the features are specified by a standards body, whereas in Helidon SE they are not. In both cases, the set of features available is complete enough to cover every aspect of the needs of modern microservices applications. ",
            "title": "Feature Richness"
        },
        {
            "location": "/about/benefits",
            "text": " Helidon intentionally includes many features required by industrial-strength enterprise applications – even when they are now architected with microservices. Among these features are support for data access, messaging, and transactions, with integrations to existing Oracle products in each category. ",
            "title": "Enterprise Features"
        },
        {
            "location": "/about/benefits",
            "text": " Helidon integrates with many other technologies that are useful in the implementation of microservices applications, for example: Oracle Coherence and Coherence Community Edition, the leading in- memory data grid, which can serve as a distributed cache or system of record for stateful microservices The Oracle Cloud Infrastructure (OCI) SDK for Java, for using a wide variety of OCI services from within Helidon applications Oracle WebLogic Server (WLS), including Bi-directional REST service invocations Helidon-to-WLS SOAP web service invocations Helidon consumption and production of messages on WLS- hosted JMS destinations Single sign-on between Helidon and WLS -hosted services using Oracle Identity Cloud Service Distributed transaction coordination between Helidon and WLS hosted resources using Oracle MicroTx Free Messaging Connectors for JMS, Kafka, and Oracle AQ, to allow Helidon applications to consume and produce messages with those providers HashiCorp Vault for accessing securely stored tokens, passwords, API keys, PKI certificates, and other secrets Micrometer Metrics, for monitoring Helidon applications using Micrometer Neo4j, for using a graph database from within Helidon applications ",
            "title": "Integrations"
        },
        {
            "location": "/about/cli",
            "text": " The Helidon CLI lets you easily create a Helidon project by picking from a set of archetypes. It also supports a developer loop that performs continuous compilation and application restart, so you can easily iterate over source code changes. The CLI is distributed as a standalone executable (compiled using GraalVM) for ease of installation. It is currently available as a download for Linux, Mac and Windows. Simply download the binary, install it at a location accessible from your PATH and you’re ready to go. ",
            "title": "Introduction"
        },
        {
            "location": "/about/cli",
            "text": " Helidon requires Java and Maven. You might also need Docker and Kubernetes depending on how you plan to deploy your services. Prerequisite product versions for Helidon 4.0.2 Java&#160;SE&#160;21 ( Open&#160;JDK&#160;21 ) Helidon requires Java 21+. Maven 3.8+ Helidon requires Maven 3.8+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop . You should make sure java and mvn are in your path. <markup lang=\"bash\" >java -version mvn --version ",
            "title": "Prerequisites"
        },
        {
            "location": "/about/cli",
            "text": "<markup lang=\"bash\" title=\"MacOS\" >curl -L -O https://helidon.io/cli/latest/darwin/helidon chmod +x ./helidon sudo mv ./helidon /usr/local/bin/ If you get a warning that \"the developer cannot be verified\" when running the CLI this is due to the Helidon CLI not being signed and notarized yet. You can disable this check by running: xattr -d com.apple.quarantine helidon <markup lang=\"bash\" title=\"Linux\" >curl -L -O https://helidon.io/cli/latest/linux/helidon chmod +x ./helidon sudo mv ./helidon /usr/local/bin/ <markup lang=\"powershell\" title=\"Windows\" >PowerShell -Command Invoke-WebRequest -Uri \"https://helidon.io/cli/latest/windows/helidon.exe\" -OutFile \"C:\\Windows\\system32\\helidon.exe\" For Windows you will also need the Visual C++ Redistributable Runtime. See Helidon on Windows for more information. ",
            "title": "Installation"
        },
        {
            "location": "/about/cli",
            "text": "<markup lang=\"bash\" >helidon init Then answer the questions. ",
            "title": "Create a New Project"
        },
        {
            "location": "/about/cli",
            "text": "<markup lang=\"bash\" >cd myproject helidon dev As you make source code changes the project will automatically recompile and restart your application. ",
            "title": "Developer Loop"
        },
        {
            "location": "/about/cli",
            "text": " ",
            "title": "Demo"
        },
        {
            "location": "/about/doc_sitemap",
            "text": " New to Helidon? Start with the Helidon Documentation page. Here you will find some of the most common topics for getting started as well as easy first steps for building your first project or application. Once you&#8217;ve settled on your preferred programming framework, visit the Helidon flavor sections of this site for more information. Helidon SE Helidon MP ",
            "title": "New Users"
        },
        {
            "location": "/about/doc_sitemap",
            "text": " Welcome back! The documentation site has a couple of new features that we hope will make your experience here a bit easier. The new Helidon Documentation page offers quick links to some of our most popular topics, including our new training and certification programs. Check out the What&#8217;s New in Helidon 4 for a list of new features and functionality. ",
            "title": "Existing Helidon Users"
        },
        {
            "location": "/about/doc_sitemap",
            "text": " Welcome to the Helidon documentation site. Here you will find general concepts, quickstart guides, tutorials and reference material. Existing Helidon users can go directly to their preferred programming flavor in the navigation panel to the left. New Users New to Helidon? Start with the Helidon Documentation page. Here you will find some of the most common topics for getting started as well as easy first steps for building your first project or application. Once you&#8217;ve settled on your preferred programming framework, visit the Helidon flavor sections of this site for more information. Helidon SE Helidon MP Existing Helidon Users Welcome back! The documentation site has a couple of new features that we hope will make your experience here a bit easier. The new Helidon Documentation page offers quick links to some of our most popular topics, including our new training and certification programs. Check out the What&#8217;s New in Helidon 4 for a list of new features and functionality. ",
            "title": "Using This Site"
        },
        {
            "location": "/about/generating_project",
            "text": " Helidon Project Starter allows you to choose from a set of archetypes with pre-defined feature sets and lets you customize it by providing a host of options. ",
            "title": "preambule"
        },
        {
            "location": "/about/generating_project",
            "text": "",
            "title": "Helidon SE"
        },
        {
            "location": "/about/generating_project",
            "text": "",
            "title": "Helidon MP"
        },
        {
            "location": "/about/generating_project",
            "text": " Helidon SE Helidon MP ",
            "title": "Select a Flavor"
        },
        {
            "location": "/about/generating_project",
            "text": " This option creates a Helidon project that includes multiple REST operations along with default observability setup and a set of dependencies to enable ease of development e.g. in case of Helidon MP, it uses helidon-microprofile bundle instead of minimal helidon-microprofile-core bundle. ",
            "title": "QuickStart"
        },
        {
            "location": "/about/generating_project",
            "text": " This option builds on QuickStart to demonstrate how to integrate with database (in-memory H2, by default). In case of, Helidon SE that uses the DbClient API while for Helidon MP that uses JPA. ",
            "title": "Database"
        },
        {
            "location": "/about/generating_project",
            "text": " This option enables user to create Helidon project of their choice, suitable to start from scratch i.e. bare minimum, if default values are chosen Or choose from many options available. ",
            "title": "Custom"
        },
        {
            "location": "/about/generating_project",
            "text": " This option builds on QuickStart to demonstrate integration with Oracle Cloud Infrastructure (OCI) services using the OCI SDK. Generated project showcases OpenApi-driven development approach where the practice of designing and building APIs is done first, then creating the rest of an application around them is implemented next. This is available for Helidon MP only. ",
            "title": "OCI (MP Only)"
        },
        {
            "location": "/about/generating_project",
            "text": " Helidon provides the following set of archetypes to bootstrap your application development journey. QuickStart This option creates a Helidon project that includes multiple REST operations along with default observability setup and a set of dependencies to enable ease of development e.g. in case of Helidon MP, it uses helidon-microprofile bundle instead of minimal helidon-microprofile-core bundle. Database This option builds on QuickStart to demonstrate how to integrate with database (in-memory H2, by default). In case of, Helidon SE that uses the DbClient API while for Helidon MP that uses JPA. Custom This option enables user to create Helidon project of their choice, suitable to start from scratch i.e. bare minimum, if default values are chosen Or choose from many options available. OCI (MP Only) This option builds on QuickStart to demonstrate integration with Oracle Cloud Infrastructure (OCI) services using the OCI SDK. Generated project showcases OpenApi-driven development approach where the practice of designing and building APIs is done first, then creating the rest of an application around them is implemented next. This is available for Helidon MP only. ",
            "title": "Choose an Application Type"
        },
        {
            "location": "/about/generating_project",
            "text": "",
            "title": "Jackson JSON"
        },
        {
            "location": "/about/generating_project",
            "text": " Default. ",
            "title": "JSON-B"
        },
        {
            "location": "/about/generating_project",
            "text": "",
            "title": "JSON-P (SE Only)"
        },
        {
            "location": "/about/generating_project",
            "text": " Jackson JSON JSON-B Default. JSON-P (SE Only) ",
            "title": "Media Support Options"
        },
        {
            "location": "/about/generating_project",
            "text": " groupId artifactId Project Version Java package name ",
            "title": "Customize Project"
        },
        {
            "location": "/about/generating_project",
            "text": " Click Download and Project Starter generates the files in a directory named after the artifactId value. It mainly contains the following: Maven structure skeletal application code associated unit test code example Dockerfile files application configuration file(s) Readme file with instructions to build and run application/test ",
            "title": "Download the Project Files"
        },
        {
            "location": "/about/intro",
            "text": " Introduction of the new Helidon WebServer (Project N&iacute;ma): a virtual threads-based web server implementation based on JDK Project Loom virtual threads. Removed Helidon&#8217;s Reactive WebServer and WebClient that were based on Netty. Our new implementations are based on virtual threads that have a blocking style API (Project N&iacute;ma). Learn more: Helidon 4 WebServer. Converted other reactive API modules to blocking style APIs. The io.helidon.common.reactive APIs will stay as general purpose reactive utilities and operators. Learn more: Helidon SE Upgraded MicroProfile support to MicroProfile 6 and Jakarta 10 Core Profile running on the Helidon WebServer. Learn more: Helidon MP Java 21 is required to use Helidon 4. ",
            "title": "What&#8217;s New in This Release"
        },
        {
            "location": "/about/intro",
            "text": " Before Helidon 4, the Helidon WebServer was built on Netty and had a reactive API. In Helidon 4 we have replaced this with a new server implementation (Project N&iacute;ma) that is written from the ground up to take full advantage of Java 21&#8217;s virtual threads. With virtual threads, threads are no longer a scarce resource to be carefully pooled and managed. Instead they are an abundant resource that can be created as needed to handle nearly unlimited concurrent requests. Because each request runs in its own dedicated thread, it is free to perform blocking operations&#8201;&#8212;&#8201;like calling a database, or another service. And it can do so in a simple synchronous way with no fear of blocking a platform thread and starving other requests. You no longer need to resort to complicated asynchronous code to implement a low-overhead, highly concurrent service. ",
            "title": "Helidon 4 WebServer"
        },
        {
            "location": "/about/intro",
            "text": " Helidon SE is Helidon&#8217;s foundational set of APIs. The big change in Helidon 4 is that the use of virtual threads have enabled these APIs to change from asynchronous to blocking. This results in much simpler code that is easier to write, maintain, debug and understand. Existing Helidon 3 SE code will require modification to run on these new APIs, but the effort is well worth the improved performance and simplicity of the resulting code. To give a very simple example of the differences between Helidon 3 SE and Helidon 4 SE, let&#8217;s take a look at extracting a JSON body from an HTTP request and doing something with it: <markup lang=\"java\" title=\"Helidon 3\" >request.content().as(JsonObject.class) .thenAccept(jo -&gt; doSomething(jo, response)); <markup lang=\"java\" title=\"Helidon 4\" >doSomething(request.content().as(JsonObject.class), response); ",
            "title": "Helidon SE"
        },
        {
            "location": "/about/intro",
            "text": " Helidon MP is Helidon&#8217;s MicroProfile implementation and in Helidon 4 it supports MicroProfile 6 and the Jakarta EE 10 Core Profile. Your Helidon 3 MicroProfile application should migrate to Helidon 4 fairly easily (the most significant changes are in MicroProfile Metrics 5.0), and since Helidon&#8217;s MicroProfile server is based on the new Helidon WebServer (Project N&iacute;ma), you get all the benefits of running on virtual threads. ",
            "title": "Helidon MP"
        },
        {
            "location": "/about/introduction",
            "text": " What is Helidon? Helidon Flavors What flavor shall I use? Prerequisites Next Steps ",
            "title": "What is Helidon?"
        },
        {
            "location": "/about/introduction",
            "text": " Helidon is a collection of Java libraries for writing microservices. Helidon is open source under the Apache license. Sources are available on GitHub . Helidon is cloud-native ready. It provides fast start-up time and has low memory consumption and a small disk footprint. It also comes with a full observability stack out of the box including health checks, metrics, tracing and logging. Helidon fully supports GraalVM native image allowing you to build a native executable from your Java application. Helidon applications are stand-alone Java applications running in their own JVM and powered by the Helidon WebServer. ",
            "title": "What is Helidon?"
        },
        {
            "location": "/about/introduction",
            "text": " Use Helidon SE if Performance is your main goal. Your application is heavily using concurrency. You are not planning to use any CDI-based components. You want to use a minimum number of third-party dependencies. Use Helidon MP if You want to base your application on modern enterprise Java standards such as Jakarta EE and MicroProfile. You are familiar with Java EE, Jakarta EE or Spring Boot and would like to have a similar development experience. You are migrating existing Java EE/Jakarta EE application to microservices. You are planning to use CDI components or extensions. You are planning to use JPA for data access and Jersey (JAX-RS) for RESTful services. Note If you don&#8217;t know which Helidon flavor to use – use Helidon MP . ",
            "title": "What flavor shall I use?"
        },
        {
            "location": "/about/introduction",
            "text": " Helidon comes in two flavors: Helidon SE and Helidon MP . Think about these flavors as frameworks providing similar functionality but offering different developer experiences. Helidon SE Helidon MP Gives you full transparency and puts you in control. Built on top of the Helidon SE libraries and provides a platform that is familiar to enterprise Java developers. Microframework model with a very small footprint and limited functionality (~7 MB). MicroProfile implementation; slightly larger footprint than SE (~13 MB). Helidon SE is Helidon’s foundational set of APIs. As of Helidon 4, virtual threads have enabled these APIs to change from asynchronous to blocking. This results in much simpler code that is easier to write, maintain, debug and understand.. Declarative style with dependency injection. Transparent \"no magic\" development experience; pure java application development with no annotations and no dependency injections. Developer experience similar to that of Spring Boot, Jakarta EE and MicroProfile; layers on some Jakarta EE components (CDI, JAX-RS, JSON-P, JSON-B). Learn more about Helidon SE . Learn more about Helidon MP . To help illustrate the differences, below are two samples implementing a simple RESTful service. One uses Helidon SE, the other Helidon MP. <markup lang=\"java\" title=\"Helidon SE sample\" >Routing routing = Routing.builder() .get(\"/hello\", (req, res) -&gt; res.send(\"Hello World\")) .build(); WebServer.create(routing) .start(); <markup lang=\"java\" title=\"Helidon MP sample\" >@Path(\"hello\") public class HelloWorld { @GET public String hello() { return \"Hello World\"; } } Even though Helidon MP supports Jakarta EE APIs it does not require an application server. Helidon MP applications are stand-alone Java applications running in their own JVM powered by Helidon WebServer. What flavor shall I use? Use Helidon SE if Performance is your main goal. Your application is heavily using concurrency. You are not planning to use any CDI-based components. You want to use a minimum number of third-party dependencies. Use Helidon MP if You want to base your application on modern enterprise Java standards such as Jakarta EE and MicroProfile. You are familiar with Java EE, Jakarta EE or Spring Boot and would like to have a similar development experience. You are migrating existing Java EE/Jakarta EE application to microservices. You are planning to use CDI components or extensions. You are planning to use JPA for data access and Jersey (JAX-RS) for RESTful services. Note If you don&#8217;t know which Helidon flavor to use – use Helidon MP . ",
            "title": "Helidon Flavors"
        },
        {
            "location": "/about/introduction",
            "text": " Helidon requires Java and Maven. You might also need Docker and Kubernetes depending on how you plan to deploy your services. Prerequisite product versions for Helidon 4.0.2 Java&#160;SE&#160;21 ( Open&#160;JDK&#160;21 ) Helidon requires Java 21+. Maven 3.8+ Helidon requires Maven 3.8+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop . We also strongly suggest installing the Helidon CLI (command line interface) which helps in generating and building Helidon projects. ",
            "title": "Prerequisites"
        },
        {
            "location": "/about/introduction",
            "text": " To upgrade your current version of Helidon, follow the Upgrade Guides : To upgrade from Helidon 3.x to 4.x: Helidon SE 4x Upgrade Guide Helidon MP 4x Upgrade Guide To upgrade from Helidon 2.x to 3.x: Helidon SE 3x Upgrade Guide Helidon MP 3x Upgrade Guide To upgrade from Helidon 1.x to 2.x: Helidon SE 2x Upgrade Guide Helidon MP 2x Upgrade Guide ",
            "title": "Upgrade"
        },
        {
            "location": "/about/introduction",
            "text": " Choose a Helidon flavor to explore and start using it. Check out the following: Helidon SE Documentation Helidon MP Documentation ",
            "title": "Next Steps"
        },
        {
            "location": "/about/kubernetes",
            "text": " For development it&#8217;s often convenient to run Kubernetes on your desktop. Two popular ways to do this are with Kubernetes Minikube or Kubernetes support in Docker for Desktop . In this guide we&#8217;ll use Docker for Desktop. ",
            "title": "preambule"
        },
        {
            "location": "/about/kubernetes",
            "text": " Install Docker for Mac or Docker for Windows . Starting with version 18.06 Docker for Desktop includes Kubernetes support. ",
            "title": "Install"
        },
        {
            "location": "/about/kubernetes",
            "text": " Enable Kubernetes Support for Mac or Kubernetes Support for Windows . Once Kubernetes installation is complete, make sure you have your context set correctly to use docker-for-desktop. <markup lang=\"bash\" title=\"Make sure K8s context is set to docker-for-desktop\" >kubectl config get-contexts kubectl config use-context docker-for-desktop kubectl cluster-info kubectl version --short kubectl get nodes ",
            "title": "Enable Kubernetes Support"
        },
        {
            "location": "/about/managing-dependencies",
            "text": " Helidon provides a &#8220;Bill Of Materials&#8221; (BOM) to manage dependencies. This is a special Maven pom file that provides dependency management. Using the Helidon BOM allows you to use Helidon component dependencies with a single version: the Helidon version. ",
            "title": "preambule"
        },
        {
            "location": "/about/managing-dependencies",
            "text": " If you created your application using the Helidon CLI or archetypes then your project will have a Helidon Application POM as its parent POM. In this case you will get Helidon&#8217;s dependency management automatically. If your project doesn&#8217;t use a Helidon Application POM as its parent, then you will need to import the Helidon BOM POM. ",
            "title": "The Helidon Application POMs"
        },
        {
            "location": "/about/managing-dependencies",
            "text": " To import the Helidon BOM POM add the following snippet to your pom.xml file. <markup lang=\"xml\" title=\"Import the Helidon BOM\" >&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon&lt;/groupId&gt; &lt;artifactId&gt;helidon-bom&lt;/artifactId&gt; &lt;version&gt;4.0.2&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; ",
            "title": "The Helidon BOM POM"
        },
        {
            "location": "/about/managing-dependencies",
            "text": " Once you have imported the BOM, you can declare dependencies on Helidon components without specifying a version. <markup lang=\"xml\" title=\"Component dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.config&lt;/groupId&gt; &lt;artifactId&gt;helidon-config-yaml&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Using Helidon Component Dependencies"
        },
        {
            "location": "/about/managing-dependencies",
            "text": " Maven Build Guide for SE and MP Gradle Build Guide for SE and MP ",
            "title": "For More Information"
        },
        {
            "location": "/about/prerequisites",
            "text": " Everything you need to get started with Helidon is listed here. ",
            "title": "preambule"
        },
        {
            "location": "/about/prerequisites",
            "text": " Helidon requires Java and Maven. You might also need Docker and Kubernetes depending on how you plan to deploy your services. Prerequisite product versions for Helidon 4.0.2 Java&#160;SE&#160;21 ( Open&#160;JDK&#160;21 ) Helidon requires Java 21+. Maven 3.8+ Helidon requires Maven 3.8+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop . <markup lang=\"bash\" title=\"Verify Prerequisites\" >java -version mvn --version docker --version kubectl version --short ",
            "title": "Prerequisites"
        },
        {
            "location": "/about/prerequisites",
            "text": "<markup lang=\"bash\" title=\"Setting JAVA_HOME \" ># On Mac export JAVA_HOME=`/usr/libexec/java_home -v 21` # On Linux # Use the appropriate path to your JDK export JAVA_HOME=/usr/lib/jvm/jdk-21 ",
            "title": "Setting JAVA_HOME "
        },
        {
            "location": "/about/prerequisites",
            "text": " Now you are ready to try the Quickstart Examples: Helidon MP Quickstart Example Helidon SE Quickstart Example See About Helidon for more information on the differences between Helidon MP and SE. See Helidon on Windows for some tips on using Helidon on Windows. ",
            "title": "Try the Quickstart Examples"
        },
        {
            "location": "/about/windows",
            "text": " Most of the Helidon documentation is Linux/Mac/Unix centric. This document gives some tips for Windows users. ",
            "title": "Introduction"
        },
        {
            "location": "/about/windows",
            "text": " Windows 10 is required. For general pre-requisites like Java and Maven see Getting Started . If you want to use the Helidon CLI you&#8217;ll also need to install the Visual C++ Redistributable Runtime: x64 x86 We also recommend installing the following from the Microsoft Store: PowerShell Windows Terminal This document assumes you will be using PowerShell. ",
            "title": "Prerequisites"
        },
        {
            "location": "/about/windows",
            "text": "<markup lang=\"bash\" >mvn \"-U\" \"archetype:generate\" \"-DinteractiveMode=false\" ` \"-DarchetypeGroupId=io.helidon.archetypes\" ` \"-DarchetypeArtifactId=helidon-quickstart-se\" ` \"-DarchetypeVersion=4.0.2\" ` \"-DgroupId=io.helidon.examples\" ` \"-DartifactId=helidon-quickstart-se\" ` \"-Dpackage=io.helidon.examples.quickstart.se\" You can then follow the instructions in the Helidon SE Quickstart . If you do not have curl installed you can use Invoke-WebRequest : <markup lang=\"bash\" >Invoke-WebRequest -Uri \"http://localhost:8080/greet\" ",
            "title": "Helidon SE"
        },
        {
            "location": "/about/windows",
            "text": "<markup lang=\"bash\" >mvn \"-U\" \"archetype:generate\" \"-DinteractiveMode=false\" ` \"-DarchetypeGroupId=io.helidon.archetypes\" ` \"-DarchetypeArtifactId=helidon-quickstart-mp\" ` \"-DarchetypeVersion=4.0.2\" ` \"-DgroupId=io.helidon.examples\" ` \"-DartifactId=helidon-quickstart-mp\" ` \"-Dpackage=io.helidon.examples.quickstart.mp\" You can then follow the instructions in the Helidon MP Quickstart . If you do not have curl installed you can use Invoke-WebRequest : <markup lang=\"bash\" >Invoke-WebRequest -Uri \"http://localhost:8080/greet\" ",
            "title": "Helidon MP"
        },
        {
            "location": "/about/windows",
            "text": " Helidon SE <markup lang=\"bash\" >mvn \"-U\" \"archetype:generate\" \"-DinteractiveMode=false\" ` \"-DarchetypeGroupId=io.helidon.archetypes\" ` \"-DarchetypeArtifactId=helidon-quickstart-se\" ` \"-DarchetypeVersion=4.0.2\" ` \"-DgroupId=io.helidon.examples\" ` \"-DartifactId=helidon-quickstart-se\" ` \"-Dpackage=io.helidon.examples.quickstart.se\" You can then follow the instructions in the Helidon SE Quickstart . If you do not have curl installed you can use Invoke-WebRequest : <markup lang=\"bash\" >Invoke-WebRequest -Uri \"http://localhost:8080/greet\" Helidon MP <markup lang=\"bash\" >mvn \"-U\" \"archetype:generate\" \"-DinteractiveMode=false\" ` \"-DarchetypeGroupId=io.helidon.archetypes\" ` \"-DarchetypeArtifactId=helidon-quickstart-mp\" ` \"-DarchetypeVersion=4.0.2\" ` \"-DgroupId=io.helidon.examples\" ` \"-DartifactId=helidon-quickstart-mp\" ` \"-Dpackage=io.helidon.examples.quickstart.mp\" You can then follow the instructions in the Helidon MP Quickstart . If you do not have curl installed you can use Invoke-WebRequest : <markup lang=\"bash\" >Invoke-WebRequest -Uri \"http://localhost:8080/greet\" ",
            "title": "Maven Quickstart Archetypes"
        },
        {
            "location": "/community",
            "text": " Helidon is a Java open source project under the Apache License version 2.0 . We encourage community contributions whether it&#8217;s participating in discussions, creating issues, or submitting pull requests. ",
            "title": "Open Source"
        },
        {
            "location": "/community",
            "text": " Have a question? Ask them in in Slack at #helidon-user Or on Stack Overflow using the helidon tag Read the Helidon FAQ ",
            "title": "Get Answers"
        },
        {
            "location": "/community",
            "text": " Helidon source is hosted on GitHub . If you&#8217;d like to report a bug, enhancement request, or check if an issue is on our list, visit the Helidon GitHub issue tracker . ",
            "title": "Code and Issues"
        },
        {
            "location": "/community",
            "text": " Follow us on Twitter @helidon_project Read the Helidon blog . ",
            "title": "Stay Informed"
        },
        {
            "location": "/config/io_helidon_common_configurable_AllowList",
            "text": " Type: io.helidon.common.configurable.AllowList ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_common_configurable_AllowList",
            "text": " Optional configuration options key type default value description allow.all boolean false Allows all strings to match (subject to \"deny\" conditions). An allow.all setting of false does not deny all strings but rather represents the absence of a universal match, meaning that other allow and deny settings determine the matching outcomes. @return whether to allow all strings to match (subject to \"deny\" conditions) allow.exact string[&#93; &#160; Exact strings to allow. @return exact strings to allow allow.pattern Pattern[&#93; &#160; Patterns specifying strings to allow. @return patterns which allow matching allow.prefix string[&#93; &#160; Prefixes specifying strings to allow. @return prefixes which allow matching allow.suffix string[&#93; &#160; Suffixes specifying strings to allow. @return suffixes which allow matching deny.exact string[&#93; &#160; Exact strings to deny. @return exact strings to allow deny.pattern Pattern[&#93; &#160; Patterns specifying strings to deny. @return patterns which deny matching deny.prefix string[&#93; &#160; Prefixes specifying strings to deny. @return prefixes which deny matching deny.suffix string[&#93; &#160; Suffixes specifying strings to deny. @return suffixes which deny matching ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_common_configurable_LruCache",
            "text": " Type: io.helidon.common.configurable.LruCache ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_common_configurable_LruCache",
            "text": " Optional configuration options key type default value description capacity int 10000 Configure capacity of the cache. Defaults to LruCache#DEFAULT_CAPACITY . @return maximal number of records in the cache before the oldest one is removed ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_common_configurable_Resource",
            "text": " Type: io.helidon.common.configurable.Resource ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_common_configurable_Resource",
            "text": " Optional configuration options key type default value description content string &#160; Binary content of the resource (base64 encoded). @return binary content content-plain string &#160; Plain content of the resource (text). @return plain content description string &#160; Description of this resource when configured through plain text or binary. @return description path Path &#160; Resource is located on filesystem. @return path of the resource proxy-host string &#160; Host of the proxy when using URI. @return proxy host proxy-port int 80 Port of the proxy when using URI. @return proxy port resource-path string &#160; Resource is located on classpath. @return classpath location of the resource uri URI &#160; Resource is available on a java.net.URI. @return of the resource @see #proxy() @see #useProxy() use-proxy boolean true Whether to use proxy. If set to false , proxy will not be used even if configured. When set to true (default), proxy will be used if configured. @return whether to use proxy if configured ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_common_configurable_ScheduledThreadPoolConfig",
            "text": " Type: io.helidon.common.configurable.ScheduledThreadPoolSupplier ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_common_configurable_ScheduledThreadPoolConfig",
            "text": " Optional configuration options key type default value description core-pool-size int 16 Core pool size of the thread pool executor. Defaults to DEFAULT_CORE_POOL_SIZE . @return corePoolSize see java.util.concurrent.ThreadPoolExecutor#getCorePoolSize() is-daemon boolean true Is daemon of the thread pool executor. Defaults to DEFAULT_IS_DAEMON . @return whether the threads are daemon threads prestart boolean false Whether to prestart core threads in this thread pool executor. Defaults to DEFAULT_PRESTART . @return whether to prestart the threads thread-name-prefix string helidon- Name prefix for threads in this thread pool executor. Defaults to DEFAULT_THREAD_NAME_PREFIX . @return prefix of a thread name virtual-threads boolean &#160; When configured to true , an unbounded virtual executor service (project Loom) will be used. If enabled, all other configuration options of this executor service are ignored! @return whether to use virtual threads or not, defaults to `false` ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_common_configurable_ScheduledThreadPoolSupplier",
            "text": " Type: io.helidon.common.configurable.ScheduledThreadPoolSupplier ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_common_configurable_ScheduledThreadPoolSupplier",
            "text": " Optional configuration options key type default value description core-pool-size int 16 Core pool size of the thread pool executor. Defaults to DEFAULT_CORE_POOL_SIZE . @return corePoolSize see java.util.concurrent.ThreadPoolExecutor#getCorePoolSize() is-daemon boolean true Is daemon of the thread pool executor. Defaults to DEFAULT_IS_DAEMON . @return whether the threads are daemon threads prestart boolean false Whether to prestart core threads in this thread pool executor. Defaults to DEFAULT_PRESTART . @return whether to prestart the threads thread-name-prefix string helidon- Name prefix for threads in this thread pool executor. Defaults to DEFAULT_THREAD_NAME_PREFIX . @return prefix of a thread name virtual-threads boolean &#160; When configured to true , an unbounded virtual executor service (project Loom) will be used. If enabled, all other configuration options of this executor service are ignored! @return whether to use virtual threads or not, defaults to `false` ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_common_configurable_ThreadPoolConfig",
            "text": " Type: io.helidon.common.configurable.ThreadPoolSupplier ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_common_configurable_ThreadPoolConfig",
            "text": " Optional configuration options key type default value description core-pool-size int 10 Core pool size of the thread pool executor. Defaults to DEFAULT_CORE_POOL_SIZE . @return corePoolSize see java.util.concurrent.ThreadPoolExecutor#getCorePoolSize() growth-rate int 0 The percentage of task submissions that should result in adding threads, expressed as a value from 1 to 100. The rate applies only when all of the following are true: the pool size is below the maximum, and there are no idle threads, and the number of tasks in the queue exceeds the growthThreshold For example, a rate of 20 means that while these conditions are met one thread will be added for every 5 submitted tasks. Defaults to `DEFAULT_GROWTH_RATE` @return the growth rate growth-threshold int 1000 The queue size above which pool growth will be considered if the pool is not fixed size. Defaults to DEFAULT_GROWTH_THRESHOLD . @return the growth threshold is-daemon boolean true Is daemon of the thread pool executor. Defaults to DEFAULT_IS_DAEMON . @return whether the threads are daemon threads keep-alive Duration PT3M Keep alive of the thread pool executor. Defaults to DEFAULT_KEEP_ALIVE . @return keep alive see java.util.concurrent.ThreadPoolExecutor#getKeepAliveTime(java.util.concurrent.TimeUnit) max-pool-size int 50 Max pool size of the thread pool executor. Defaults to DEFAULT_MAX_POOL_SIZE . @return maxPoolSize see java.util.concurrent.ThreadPoolExecutor#getMaximumPoolSize() name string &#160; Name of this thread pool executor. @return the pool name queue-capacity int 10000 Queue capacity of the thread pool executor. Defaults to DEFAULT_QUEUE_CAPACITY . @return capacity of the queue backing the executor should-prestart boolean true Whether to prestart core threads in this thread pool executor. Defaults to DEFAULT_PRESTART . @return whether to prestart the threads thread-name-prefix string &#160; Name prefix for threads in this thread pool executor. Defaults to DEFAULT_THREAD_NAME_PREFIX . @return prefix of a thread name virtual-threads boolean &#160; When configured to true , an unbounded virtual executor service (project Loom) will be used. If enabled, all other configuration options of this executor service are ignored! @return whether to use virtual threads or not, defaults to `false` ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_common_configurable_ThreadPoolSupplier",
            "text": " Type: io.helidon.common.configurable.ThreadPoolSupplier ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_common_configurable_ThreadPoolSupplier",
            "text": " Optional configuration options key type default value description core-pool-size int 10 Core pool size of the thread pool executor. Defaults to DEFAULT_CORE_POOL_SIZE . @return corePoolSize see java.util.concurrent.ThreadPoolExecutor#getCorePoolSize() growth-rate int 0 The percentage of task submissions that should result in adding threads, expressed as a value from 1 to 100. The rate applies only when all of the following are true: the pool size is below the maximum, and there are no idle threads, and the number of tasks in the queue exceeds the growthThreshold For example, a rate of 20 means that while these conditions are met one thread will be added for every 5 submitted tasks. Defaults to `DEFAULT_GROWTH_RATE` @return the growth rate growth-threshold int 1000 The queue size above which pool growth will be considered if the pool is not fixed size. Defaults to DEFAULT_GROWTH_THRESHOLD . @return the growth threshold is-daemon boolean true Is daemon of the thread pool executor. Defaults to DEFAULT_IS_DAEMON . @return whether the threads are daemon threads keep-alive Duration PT3M Keep alive of the thread pool executor. Defaults to DEFAULT_KEEP_ALIVE . @return keep alive see java.util.concurrent.ThreadPoolExecutor#getKeepAliveTime(java.util.concurrent.TimeUnit) max-pool-size int 50 Max pool size of the thread pool executor. Defaults to DEFAULT_MAX_POOL_SIZE . @return maxPoolSize see java.util.concurrent.ThreadPoolExecutor#getMaximumPoolSize() name string &#160; Name of this thread pool executor. @return the pool name queue-capacity int 10000 Queue capacity of the thread pool executor. Defaults to DEFAULT_QUEUE_CAPACITY . @return capacity of the queue backing the executor should-prestart boolean true Whether to prestart core threads in this thread pool executor. Defaults to DEFAULT_PRESTART . @return whether to prestart the threads thread-name-prefix string &#160; Name prefix for threads in this thread pool executor. Defaults to DEFAULT_THREAD_NAME_PREFIX . @return prefix of a thread name virtual-threads boolean &#160; When configured to true , an unbounded virtual executor service (project Loom) will be used. If enabled, all other configuration options of this executor service are ignored! @return whether to use virtual threads or not, defaults to `false` ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_common_pki_Keys",
            "text": " Type: io.helidon.common.pki.Keys ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_common_pki_Keys",
            "text": " Optional configuration options key type default value description keystore KeystoreKeys &#160; Configure keys from a keystore. Once the config object is built, this option will ALWAYS be empty. All keys from the keystore will be populated to #privateKey(), #publicKey(), #publicCert() etc. @return keystore configuration pem PemKeys &#160; Configure keys from pem file(s). Once the config object is built, this option will ALWAYS be empty. All keys from the keystore will be populated to #privateKey(), #publicKey(), #publicCert() etc. @return pem based definition ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_common_pki_KeystoreKeys",
            "text": " Type: io.helidon.common.pki.KeystoreKeys ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_common_pki_KeystoreKeys",
            "text": " Required configuration options key type default value description resource Resource &#160; Keystore resource definition. @return keystore resource, from file path, classpath, URL etc. Optional configuration options key type default value description cert-chain.alias string &#160; Alias of an X.509 chain. @return alias of certificate chain in the keystore cert.alias string &#160; Alias of X.509 certificate of public key. Used to load both the certificate and public key. @return alias under which the certificate is stored in the keystore key.alias string &#160; Alias of the private key in the keystore. @return alias of the key in the keystore key.passphrase char[] &#160; Pass-phrase of the key in the keystore (used for private keys). This is (by default) the same as keystore passphrase - only configure if it differs from keystore passphrase. @return pass-phrase of the key passphrase char[] &#160; Pass-phrase of the keystore (supported with JKS and PKCS12 keystores). @return keystore password to use trust-store boolean false If you want to build a trust store, call this method to add all certificates present in the keystore to certificate list. @return whether this is a trust store type string PKCS12 Set type of keystore. Defaults to DEFAULT_KEYSTORE_TYPE , expected are other keystore types supported by java then can store keys under aliases. @return keystore type to load the key ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_common_pki_PemKeys",
            "text": " Type: io.helidon.common.pki.PemKeys ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_common_pki_PemKeys",
            "text": " Optional configuration options key type default value description cert-chain.resource Resource &#160; Load certificate chain from PEM resource. @return resource (e.g. classpath, file path, URL etc.) certificates.resource Resource &#160; Read one or more certificates in PEM format from a resource definition. Used eg: in a trust store. @return key resource (file, classpath, URL etc.) key.passphrase char[] &#160; Passphrase for private key. If the key is encrypted (and in PEM PKCS#8 format), this passphrase will be used to decrypt it. @return passphrase used to encrypt the private key key.resource Resource &#160; Read a private key from PEM format from a resource definition. @return key resource (file, classpath, URL etc.) public-key.resource Resource &#160; Read a public key from PEM format from a resource definition. @return public key resource (file, classpath, URL etc.) ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_common_socket_SocketOptions",
            "text": " Type: io.helidon.common.socket.SocketOptions ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_common_socket_SocketOptions",
            "text": " Optional configuration options key type default value description connect-timeout Duration PT10S Socket connect timeout. Default is 10 seconds. @return connect timeout duration read-timeout Duration PT30S Socket read timeout. Default is 30 seconds. @return read timeout duration socket-keep-alive boolean true Configure socket keep alive. Default is true . @return keep alive @see java.net.StandardSocketOptions#SO_KEEPALIVE socket-receive-buffer-size int 32768 Socket receive buffer size. @return buffer size, in bytes @see java.net.StandardSocketOptions#SO_RCVBUF socket-reuse-address boolean true Socket reuse address. Default is true . @return whether to reuse address @see java.net.StandardSocketOptions#SO_REUSEADDR socket-send-buffer-size int 32768 Socket send buffer size. @return buffer size, in bytes @see java.net.StandardSocketOptions#SO_SNDBUF tcp-no-delay boolean false This option may improve performance on some systems. Default is false . @return whether to use TCP_NODELAY, defaults to `false` @see java.net.StandardSocketOptions#TCP_NODELAY ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_common_tls_Tls",
            "text": " Type: io.helidon.common.tls.Tls ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_common_tls_Tls",
            "text": " Optional configuration options key type default value description cipher-suite string[&#93; &#160; Enabled cipher suites for TLS communication. @return cipher suits to enable, by default (or if list is empty), all available cipher suites are enabled client-auth TlsClientAuth (REQUIRED, OPTIONAL, NONE) NONE Configure requirement for mutual TLS. @return what type of mutual TLS to use, defaults to TlsClientAuth#NONE enabled boolean true Flag indicating whether Tls is enabled. @return enabled flag endpoint-identification-algorithm string HTTPS Identification algorithm for SSL endpoints. @return configure endpoint identification algorithm, or set to `NONE` to disable endpoint identification (equivalent to hostname verification). Defaults to `Tls#ENDPOINT_IDENTIFICATION_HTTPS` internal-keystore-provider string &#160; Provider of the key stores used internally to create a key and trust manager factories. @return keystore provider, if not defined, provider is not specified internal-keystore-type string &#160; Type of the key stores used internally to create a key and trust manager factories. @return keystore type, defaults to java.security.KeyStore#getDefaultType() key-manager-factory-algorithm string &#160; Algorithm of the key manager factory used when private key is defined. Defaults to javax.net.ssl.KeyManagerFactory#getDefaultAlgorithm(). @return algorithm to use manager io.helidon.common.tls.TlsManager (service provider interface) &#160; The Tls manager. If one is not explicitly defined in the config then a default manager will be created. @return the tls manager of the tls instance @see ConfiguredTlsManager private-key PrivateKey &#160; Private key to use. For server side TLS, this is required. For client side TLS, this is optional (used when mutual TLS is enabled). @return private key to use protocol string TLS Configure the protocol used to obtain an instance of javax.net.ssl.SSLContext. @return protocol to use, defaults to `DEFAULT_PROTOCOL` protocols string[&#93; &#160; Enabled protocols for TLS communication. Example of valid values for TLS protocol: TLSv1.3 , TLSv1.2 @return protocols to enable, by default (or if list is empty), all available protocols are enabled provider string &#160; Use explicit provider to obtain an instance of javax.net.ssl.SSLContext. @return provider to use, defaults to none (only #protocol() is used by default) secure-random-algorithm string &#160; Algorithm to use when creating a new secure random. @return algorithm to use, by default uses java.security.SecureRandom constructor secure-random-provider string &#160; Provider to use when creating a new secure random. When defined, #secureRandomAlgorithm() must be defined as well. @return provider to use, by default no provider is specified session-cache-size int 1024 SSL session cache size. @return session cache size, defaults to 1024 session-timeout Duration PT30M SSL session timeout. @return session timeout, defaults to 30 minutes trust X509Certificate[&#93; &#160; List of certificates that form the trust manager. @return certificates to be trusted trust-all boolean false Trust any certificate provided by the other side of communication. &lt;b&gt;This is a dangerous setting: &lt;/b&gt; if set to `true`, any certificate will be accepted, throwing away most of the security advantages of TLS. &lt;b&gt;NEVER&lt;/b&gt; do this in production. @return whether to trust all certificates, do not use in production trust-manager-factory-algorithm string &#160; Trust manager factory algorithm. @return algorithm to use ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_config_mp_MpConfigBuilder",
            "text": " Type: org.eclipse.microprofile.config.Config This is a standalone configuration type, prefix from configuration root: mp.config ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_config_mp_MpConfigBuilder",
            "text": " Optional configuration options key type default value description profile string &#160; Configure an explicit profile name. ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_cors_CrossOriginConfig",
            "text": " Type: io.helidon.cors.CrossOriginConfig ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_cors_CrossOriginConfig",
            "text": " Optional configuration options key type default value description allow-credentials boolean false Sets the allow credentials flag. allow-headers string[&#93; * Sets the allow headers. allow-methods string[&#93; * Sets the allow methods. allow-origins string[&#93; * Sets the allowOrigins. enabled boolean true Sets whether this config should be enabled or not. expose-headers string[&#93; &#160; Sets the expose headers. max-age-seconds long 3600 Sets the maximum age. path-pattern string {+} Updates the path prefix for this cross-origin config. ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_dbclient_jdbc_JdbcParametersConfig",
            "text": " Type: io.helidon.dbclient.jdbc.JdbcParametersConfig <markup lang=\"text\" title=\"Config key\" >parameters ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_dbclient_jdbc_JdbcParametersConfig",
            "text": " Optional configuration options key type default value description set-object-for-java-time boolean true Set all java.time Date/Time values directly using java.sql.PreparedStatement#setObject(int, Object). This option shall work fine for recent JDBC drivers. Default value is true . @return whether to use java.sql.PreparedStatement#setObject(int, Object) for `java.time` Date/Time values string-binding-size int 1024 String values with length above this limit will be bound using java.sql.PreparedStatement#setCharacterStream(int, java.io.Reader, int) if #useStringBinding() is set to true . Default value is 1024 . @return String values length limit for java.io.CharArrayReader binding timestamp-for-local-time boolean true Use java.sql.PreparedStatement#setTimestamp(int, java.sql.Timestamp) to set java.time.LocalTime values when true or use java.sql.PreparedStatement#setTime(int, java.sql.Time) when false . Default value is true . This option is vendor specific. Most of the databases are fine with java.sql.Timestamp, but for example SQL Server requires java.sql.Time. This option does not apply when #setObjectForJavaTime() is set to true . @return whether to use java.sql.Timestamp instead of java.sql.Time for java.time.LocalTime values use-byte-array-binding boolean true Use java.sql.PreparedStatement#setBinaryStream(int, java.io.InputStream, int) binding for byte[] values. Default value is true . @return whether to use java.io.ByteArrayInputStream binding use-n-string boolean false Use SQL NCHAR , NVARCHAR or LONGNVARCHAR value conversion for String values. Default value is false . @return whether NString conversion is used use-string-binding boolean true Use java.sql.PreparedStatement#setCharacterStream(int, java.io.Reader, int) binding for String values with length above #stringBindingSize() limit. Default value is true . @return whether to use java.io.CharArrayReader binding ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_faulttolerance_Async",
            "text": " Type: io.helidon.faulttolerance.Async ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_faulttolerance_Async",
            "text": " Optional configuration options key type default value description executor-name string &#160; Name of an executor service. This is only honored when service registry is used. @return name fo the java.util.concurrent.ExecutorService to lookup @see #executor() ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_faulttolerance_Bulkhead",
            "text": " Type: io.helidon.faulttolerance.Bulkhead This is a standalone configuration type, prefix from configuration root: fault-tolerance.bulkheads ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_faulttolerance_Bulkhead",
            "text": " Optional configuration options key type default value description limit int 10 Maximal number of parallel requests going through this bulkhead. When the limit is reached, additional requests are enqueued. @return maximal number of parallel calls, defaults is `DEFAULT_LIMIT` queue-length int 10 Maximal number of enqueued requests waiting for processing. When the limit is reached, additional attempts to invoke a request will receive a BulkheadException. @return length of the queue ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_faulttolerance_CircuitBreaker",
            "text": " Type: io.helidon.faulttolerance.CircuitBreaker This is a standalone configuration type, prefix from configuration root: fault-tolerance.circuit-breakers ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_faulttolerance_CircuitBreaker",
            "text": " Optional configuration options key type default value description delay Duration PT5S How long to wait before transitioning from open to half-open state. @return delay error-ratio int 60 How many failures out of 100 will trigger the circuit to open. This is adapted to the #volume() used to handle the window of requests. If errorRatio is 40, and volume is 10, 4 failed requests will open the circuit. Default is DEFAULT_ERROR_RATIO . @return percent of failure that trigger the circuit to open @see #volume() success-threshold int 1 How many successful calls will close a half-open circuit. Nevertheless, the first failed call will open the circuit again. Default is DEFAULT_SUCCESS_THRESHOLD . @return number of calls volume int 10 Rolling window size used to calculate ratio of failed requests. Default is DEFAULT_VOLUME . @return how big a window is used to calculate error errorRatio @see #errorRatio() ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_faulttolerance_Retry",
            "text": " Type: io.helidon.faulttolerance.Retry This is a standalone configuration type, prefix from configuration root: fault-tolerance.retries ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_faulttolerance_Retry",
            "text": " Optional configuration options key type default value description calls int 3 Number of calls (first try + retries). @return number of desired calls, must be 1 (means no retries) or higher. delay Duration PT0.2S Base delay between try and retry. Defaults to 200 ms . @return delay between retries (combines with retry policy) delay-factor double -1 Delay retry policy factor. If unspecified (value of -1 ), Jitter retry policy would be used, unless jitter is also unspecified. Default when Retry.DelayingRetryPolicy is used is `2`. @return delay factor for delaying retry policy jitter Duration PT-1S Jitter for Retry.JitterRetryPolicy. If unspecified (value of -1 ), delaying retry policy is used. If both this value, and #delayFactor() are specified, delaying retry policy would be used. @return jitter overall-timeout Duration PT1S Overall timeout of all retries combined. @return overall timeout ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_faulttolerance_Timeout",
            "text": " Type: io.helidon.faulttolerance.Timeout This is a standalone configuration type, prefix from configuration root: fault-tolerance.timeouts ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_faulttolerance_Timeout",
            "text": " Optional configuration options key type default value description current-thread boolean false Flag to indicate that code must be executed in current thread instead of in an executor&#8217;s thread. This flag is false by default. @return whether to execute on current thread (`true`), or in an executor service (`false`}) timeout Duration PT10S Duration to wait before timing out. Defaults to 10 seconds . @return timeout ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_http_RequestedUriDiscoveryContext",
            "text": " Type: io.helidon.http.RequestedUriDiscoveryContext ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_http_RequestedUriDiscoveryContext",
            "text": " Optional configuration options key type default value description discovery-types RequestedUriDiscoveryType[&#93; (FORWARDED, X_FORWARDED, HOST) &#160; Sets the discovery types for requested URI discovery for requests arriving on the socket. enabled boolean true if &#x27;discoveryTypes&#x27; or &#x27;trusted-proxies&#x27; is set; false otherwise Sets whether requested URI discovery is enabled for requestes arriving on the socket. trusted-proxies AllowList &#160; Sets the trusted proxies for requested URI discovery for requests arriving on the socket. ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_http_encoding_ContentEncodingContext",
            "text": " Type: io.helidon.http.encoding.ContentEncodingContext ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_http_encoding_ContentEncodingContext",
            "text": " Optional configuration options key type default value description content-encodings io.helidon.http.encoding.ContentEncoding[&#93; (service provider interface) &#160; List of content encodings that should be used. Encodings configured here have priority over encodings discovered through service loader. @return list of content encodings to be used (such as `gzip,deflate`) ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_http_media_MediaContext",
            "text": " Type: io.helidon.http.media.MediaContext ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_http_media_MediaContext",
            "text": " Optional configuration options key type default value description fallback MediaContext &#160; Existing context to be used as a fallback for this context. @return media context to use if supports configured on this request cannot provide a good result media-supports io.helidon.http.media.MediaSupport[&#93; (service provider interface) &#160; Media supports to use. This instance has priority over provider(s) discovered by service loader. The providers are used in order of calling this method, where the first support added is the first one to be queried for readers and writers. @return media supports register-defaults boolean true Should we register defaults of Helidon, such as String media support. @return whether to register default media supports ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_integrations_micrometer_MicrometerFeature",
            "text": " Type: io.helidon.integrations.micrometer.MicrometerFeature <markup lang=\"text\" title=\"Config key\" >micrometer ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_integrations_micrometer_MicrometerFeature",
            "text": " Optional configuration options key type default value description cross-origin-config CrossOriginConfig &#160; Set the CORS config from the specified CrossOriginConfig object. web-context string &#160; Set the root context for the REST API of the service. ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_integrations_neo4j_Neo4j",
            "text": " Type: io.helidon.integrations.neo4j.Neo4j ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_integrations_neo4j_Neo4j",
            "text": " Optional configuration options key type default value description authentication-enabled boolean true Enable authentication. certificate Path &#160; Set certificate path. connection-acquisition-timeout Duration PT1MS Set connection acquisition timeout. encrypted boolean &#160; Enable encrypted field. hostname-verification-enabled boolean &#160; Enable hostname verification. idle-time-before-connection-test Duration PT-1MS Set idle time. log-leaked-sessions boolean &#160; Enable log leaked sessions. max-connection-lifetime Duration PT5H Set max life time. max-connection-pool-size int 100 Set pool size. metrics-enabled boolean &#160; Enable metrics. password string &#160; Create password. trust-strategy TrustStrategy (TRUST_ALL_CERTIFICATES, TRUST_CUSTOM_CA_SIGNED_CERTIFICATES, TRUST_SYSTEM_CA_SIGNED_CERTIFICATES) &#160; Set trust strategy. uri string &#160; Create uri. username string &#160; Create username. ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_integrations_oci_metrics_OciMetricsSupport",
            "text": " Type: io.helidon.integrations.oci.metrics.OciMetricsSupport ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_integrations_oci_metrics_OciMetricsSupport",
            "text": " Optional configuration options key type default value description batch-delay long 1 Sets the delay interval if metrics are posted in batches (defaults to DEFAULT_BATCH_DELAY ). batch-size int 50 Sets the maximum no. of metrics to send in a batch (defaults to DEFAULT_BATCH_SIZE ). compartment-id string &#160; Sets the compartment ID. delay long 60 Sets the delay interval between metric posting (defaults to DEFAULT_SCHEDULER_DELAY ). description-enabled boolean true Sets whether the description should be enabled or not. Defaults to `true`. enabled boolean true Sets whether metrics transmission to OCI is enabled. Defaults to `true`. initial-delay long 1 Sets the initial delay before metrics are sent to OCI (defaults to DEFAULT_SCHEDULER_INITIAL_DELAY ). namespace string &#160; Sets the namespace. resource-group string &#160; Sets the resource group. scheduling-time-unit TimeUnit (NANOSECONDS, MICROSECONDS, MILLISECONDS, SECONDS, MINUTES, HOURS, DAYS) TimeUnit.SECONDS Sets the time unit applied to the initial delay and delay values (defaults to TimeUnit.SECONDS ). scopes String[] All scopes Sets which metrics scopes (e.g., base, vendor, application) should be sent to OCI. If this method is never invoked, defaults to all scopes. ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_integrations_oci_sdk_runtime_OciConfig",
            "text": " Type: io.helidon.integrations.oci.sdk.runtime.OciConfig This is a standalone configuration type, prefix from configuration root: oci ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_integrations_oci_sdk_runtime_OciConfig",
            "text": " Optional configuration options key type default value description auth-strategies string[&#93; (auto, config, config-file, instance-principals, resource-principal) &#160; The list of authentication strategies that will be attempted by com.oracle.bmc.auth.AbstractAuthenticationDetailsProvider when one is called for. This is only used if #authStrategy() is not present. auto - if present in the list, or if no value for this property exists. config - the com.oracle.bmc.auth.SimpleAuthenticationDetailsProvider will be used, customized with other configuration properties described here. config-file - the com.oracle.bmc.auth.ConfigFileAuthenticationDetailsProvider will be used, customized with other configuration properties described here. instance-principals - the com.oracle.bmc.auth.InstancePrincipalsAuthenticationDetailsProvider will be used. resource-principal - the com.oracle.bmc.auth.ResourcePrincipalAuthenticationDetailsProvider will be used. If there are more than one strategy descriptors defined, the first one that is deemed to be available/suitable will be used and all others will be ignored. @return the list of authentication strategies that will be applied, defaulting to `auto` @see io.helidon.integrations.oci.sdk.runtime.OciAuthenticationDetailsProvider.AuthStrategy auth-strategy string (auto, config, config-file, instance-principals, resource-principal) &#160; The singular authentication strategy to apply. This will be preferred over #authStrategies() if both are present. @return the singular authentication strategy to be applied auth.fingerprint string &#160; The OCI authentication fingerprint. This configuration property has an effect only when `config` is, explicitly or implicitly, present in the value for the #authStrategies(). This is also known as #simpleConfigIsPresent(). When it is present, this property must be provided in order to set the &lt;a href=\"https://docs.oracle.com/en-us/iaas/Content/API/Concepts/apisigningkey.htm\"&gt;API signing key's fingerprint&lt;/a&gt;. See {@linkplain com.oracle.bmc.auth.SimpleAuthenticationDetailsProvider#getFingerprint()} for more details. @return the OCI authentication fingerprint auth.keyFile string oci_api_key.pem The OCI authentication key file. This configuration property has an effect only when `config` is, explicitly or implicitly, present in the value for the #authStrategies(). This is also known as #simpleConfigIsPresent(). When it is present, this property must be provided in order to set the {@linkplain com.oracle.bmc.auth.SimpleAuthenticationDetailsProvider#getPrivateKey()}. This file must exist in the `user.home` directory. Alternatively, this property can be set using either #authPrivateKey() or using #authPrivateKeyPath(). @return the OCI authentication key file auth.passphrase char[] &#160; The OCI authentication passphrase. This configuration property has an effect only when `config` is, explicitly or implicitly, present in the value for the #authStrategies(). This is also known as #simpleConfigIsPresent(). When it is present, this property must be provided in order to set the {@linkplain com.oracle.bmc.auth.SimpleAuthenticationDetailsProvider#getPassphraseCharacters()}. @return the OCI authentication passphrase auth.private-key char[] &#160; The OCI authentication private key. This configuration property has an effect only when `config` is, explicitly or implicitly, present in the value for the #authStrategies(). This is also known as #simpleConfigIsPresent(). When it is present, this property must be provided in order to set the {@linkplain com.oracle.bmc.auth.SimpleAuthenticationDetailsProvider#getPrivateKey()}. Alternatively, this property can be set using either #authKeyFile() residing in the `user.home` directory, or using #authPrivateKeyPath(). @return the OCI authentication private key auth.private-key-path string &#160; The OCI authentication key file path. This configuration property has an effect only when `config` is, explicitly or implicitly, present in the value for the #authStrategies(). This is also known as #simpleConfigIsPresent(). When it is present, this property must be provided in order to set the {@linkplain com.oracle.bmc.auth.SimpleAuthenticationDetailsProvider#getPrivateKey()}. This file path is an alternative for using #authKeyFile() where the file must exist in the `user.home` directory. Alternatively, this property can be set using #authPrivateKey(). @return the OCI authentication key file path auth.region string &#160; The OCI region. This configuration property has an effect only when `config` is, explicitly or implicitly, present in the value for the #authStrategies(). This is also known as #simpleConfigIsPresent(). When it is present, either this property or com.oracle.bmc.auth.RegionProvider must be provide a value in order to set the {@linkplain com.oracle.bmc.auth.ConfigFileAuthenticationDetailsProvider#getRegion()}. @return the OCI region auth.tenant-id string &#160; The OCI tenant id. This configuration property has an effect only when `config` is, explicitly or implicitly, present in the value for the #authStrategies(). This is also known as #simpleConfigIsPresent(). When it is present, this property must be provided in order to set the {@linkplain com.oracle.bmc.auth.ConfigFileAuthenticationDetailsProvider#getTenantId()}. @return the OCI tenant id auth.user-id string &#160; The OCI user id. This configuration property has an effect only when `config` is, explicitly or implicitly, present in the value for the #authStrategies(). When it is present, this property must be provided in order to set the {@linkplain com.oracle.bmc.auth.ConfigFileAuthenticationDetailsProvider#getUserId()}. @return the OCI user id config.path string &#160; The OCI configuration profile path. This configuration property has an effect only when `config-file` is, explicitly or implicitly, present in the value for the #authStrategies(). This is also known as #fileConfigIsPresent(). When it is present, this property must also be present and then the {@linkplain com.oracle.bmc.ConfigFileReader#parse(String)} method will be passed this value. It is expected to be passed with a valid OCI configuration file path. @return the OCI configuration profile path config.profile string DEFAULT The OCI configuration/auth profile name. This configuration property has an effect only when `config-file` is, explicitly or implicitly, present in the value for the #authStrategies(). This is also known as #fileConfigIsPresent(). When it is present, this property may also be optionally provided in order to override the default `DEFAULT_PROFILE_NAME`. @return the optional OCI configuration/auth profile name imds.hostname string 169.254.169.254 The OCI IMDS hostname. This configuration property is used to identify the metadata service url. @return the OCI IMDS hostname imds.timeout.milliseconds Duration PT0.1S The OCI IMDS connection timeout. This is used to auto-detect availability. This configuration property is used when attempting to connect to the metadata service. @return the OCI IMDS connection timeout @see OciAvailability ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_integrations_openapi_ui_OpenApiUi",
            "text": " Type: io.helidon.integrations.openapi.ui.OpenApiUi ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_integrations_openapi_ui_OpenApiUi",
            "text": " Optional configuration options key type default value description enabled boolean true Sets whether the service should be enabled. @return `true` if enabled, `false` otherwise options Map&lt;string, string&gt; &#160; Merges implementation-specific UI options. @return options for the UI to merge web-context string &#160; Full web context (not just the suffix). @return full web context path ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_metrics_api_ComponentMetricsSettings",
            "text": " Type: io.helidon.metrics.api.ComponentMetricsSettings <markup lang=\"text\" title=\"Config key\" >metrics ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_metrics_api_ComponentMetricsSettings",
            "text": " Optional configuration options key type default value description enabled boolean &#160; Sets whether metrics should be enabled for the component. ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_metrics_api_KeyPerformanceIndicatorMetricsConfig",
            "text": " Type: io.helidon.metrics.api.KeyPerformanceIndicatorMetricsConfig ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_metrics_api_KeyPerformanceIndicatorMetricsConfig",
            "text": " Optional configuration options key type default value description extended boolean false Whether KPI extended metrics are enabled. @return true if KPI extended metrics are enabled; false otherwise long-running-requests.threshold Duration PT10S Threshold in ms that characterizes whether a request is long running. @return threshold in ms indicating a long-running request ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_metrics_api_MetricsConfig",
            "text": " Type: io.helidon.metrics.api.MetricsConfig This is a standalone configuration type, prefix from configuration root: metrics ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_metrics_api_MetricsConfig",
            "text": " Optional configuration options key type default value description app-name string &#160; Value for the application tag to be added to each meter ID. @return application tag value app-tag-name string &#160; Name for the application tag to be added to each meter ID. @return application tag name enabled boolean true Whether metrics functionality is enabled. @return if metrics are configured to be enabled key-performance-indicators KeyPerformanceIndicatorMetricsConfig &#160; Key performance indicator metrics settings. @return key performance indicator metrics settings permit-all boolean &#160; Whether to allow anybody to access the endpoint. @return whether to permit access to metrics endpoint to anybody, defaults to `true` @see #roles() rest-request-enabled boolean &#160; Whether automatic REST request metrics should be measured. @return true/false roles string[&#93; &#160; Hints for role names the user is expected to be in. @return list of hints scoping ScopingConfig &#160; Settings related to scoping management. @return scoping settings tags Tag[&#93; &#160; Global tags. @return name/value pairs for global tags ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_metrics_api_ScopeConfig",
            "text": " Type: io.helidon.metrics.api.ScopeConfig ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_metrics_api_ScopeConfig",
            "text": " Optional configuration options key type default value description enabled boolean true Whether the scope is enabled. @return if the scope is enabled filter.exclude Pattern &#160; Regular expression for meter names to exclude. @return exclude expression filter.include Pattern &#160; Regular expression for meter names to include. @return include expression name string &#160; Name of the scope to which the configuration applies. @return scope name ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_metrics_api_ScopingConfig",
            "text": " Type: io.helidon.metrics.api.ScopingConfig ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_metrics_api_ScopingConfig",
            "text": " Optional configuration options key type default value description default string application Default scope value to associate with meters that are registered without an explicit setting; no setting means meters are assigned scope io.helidon.metrics.api.Meter.Scope#DEFAULT . @return default scope value scopes Map&lt;string, ScopeConfig&gt; &#160; Settings for individual scopes. @return scope settings tag-name string scope Tag name for storing meter scope values in the underlying implementation meter registry. @return tag name for storing scope values ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_metrics_api_Tag",
            "text": " Type: io.helidon.metrics.api.Tag ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_metrics_api_Tag",
            "text": "",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_microprofile_jwt",
            "text": " MicroProfile configuration options: key type default value description mp.jwt.verify.publickey string &#160; The property allows the Public Verification Key text itself to be supplied as a string. mp.jwt.verify.publickey.location string &#160; The property allows for an external or internal location of Public Verification Key to be specified. The value may be a relative path or a URL. mp.jwt.verify.publickey.algorithm string &#160; The configuration property allows for specifying which Public Key Signature Algorithm is supported by the MP JWT endpoint. This property can be set to either RS256 or ES256 . Default value is RS256 . Support for the other asymmetric signature algorithms such as RS512 , ES512 and others is optional. mp.jwt.verify.issuer string &#160; Configuration key for expected issuer of incoming tokens. mp.jwt.verify.audiences string &#160; Configuration key for expected audiences of incoming tokens. mp.jwt.verify.token.age int &#160; Max number of seconds since token issue time. If this number of second accedes configured value, validation will fail. mp.jwt.verify.clock.skew int &#160; Number of seconds for the clock skew during the token age verification and expiry. mp.jwt.token.cookie string &#160; Cookie property name which is expected to contain a JWT token. mp.jwt.token.header string &#160; Header name which is expected to contain a JWT token. mp.jwt.decrypt.key.location string &#160; The property allows for an external or internal location of Private Decryption Key to be specified. The value may be a relative path or a URL. mp.jwt.decrypt.key.algorithm string &#160; The configuration property allows for specifying which key management algorithm is supported by the MP JWT endpoint. Supported algorithms are either RSA-OAEP or RSA-OAEP-256 . If no algorithm is set, both algorithms must be accepted. Helidon configuration options: key type default value description optional boolean false If set to true , failure to authenticate will return ABSTAIN result instead of FAILURE . This is an important distinction when more than one provider is used authenticate boolean true Whether to attempt authentication propagate boolean true Whether to attempt identity propagation/JWT creation principal-type string USER Whether we authenticate a user or a service (other option is SERVICE) atn-token string &#160; A group for configuring authentication of the request atn-token.verify-signature boolean true Whether to verify signature in incoming JWT. If disabled, ANY JWT will be accepted atn-token.jwt-audience string &#160; Expected audience of the JWT. If not defined, any audience is accepted (and we may accept JWT not inteded for us) atn-token.jwk.resource Resource &#160; Configuration of the JWK to obtain key(s) to validate signatures of inbound token. The JWK should contain public keys. atn-token.handler string Authorization header with `bearer ` prefix A handler configuration for inbound token - e.g. how to extract it atn-token.handler.header string &#160; Name of a header the token is expected in atn-token.handler.prefix string &#160; Prefix before the token value (optional) atn-token.handler.regexp string &#160; Regular expression to obtain the token, first matching group is used (optional) sign-token string &#160; A group for configuring outbound security sign-token.jwk.resource Resource &#160; Configuration of the JWK to use when generating tokens (follows the same rules as atn-token.jwk above). The JWK must contain private keys when using asymmetric ciphers. sign-token.jwt-issuer string &#160; When we issue a new token, this is the issuer to be placed into it (validated by target service) sign-token.outbound string &#160; A group for configuring outbound rules (based on transport, host and.or path) sign-token.outbound.*.name string &#160; A short descriptive name for configured target service(s) sign-token.outbound.*.transports string any An array of transports this outbound matches (e.g. https) sign-token.outbound.*.hosts string any An array of hosts this outbound matches, may use * as a wild-card (e.g. *.oracle.com) sign-token.outbound.*.paths string any An array of paths on the host this outbound matches, may use * as a wild-card (e.g. /some/path/*) sign-token.outbound.*.outbound-token string Authorization header with `bearer ` prefix Configuration of outbound token handler (same as atn-token.handler) sign-token.outbound.*.outbound-token.format string &#160; Java text format for generating the value of outbound token header (e.g. \"bearer %1$s\") sign-token.outbound.*.jwk-kid string &#160; If this key is defined, we are generating a new token, otherwise we propagate existing. Defines the key id of a key definition in the JWK file to use for signing the outbound token sign-token.outbound.*.jwt-kid string &#160; A key to use in the generated JWT - this is for the other service to locate the verification key in their JWK sign-token.outbound.*.jwt-audience string &#160; Audience this key is generated for (e.g. http://www.example.org/api/myService ) - validated by the other service sign-token.outbound.*.jwt-not-before-seconds string 5 Makes this key valid this amount of seconds into the past. Allows a certain time-skew for the generated token to be valid before current time (e.g. when we expect a certain misalignment of clocks) sign-token.outbound.*.jwt-validity-seconds string 1 day Token validity in seconds ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_microprofile_openapi_MpOpenApiManagerConfig",
            "text": " Type: io.helidon.microprofile.openapi.MpOpenApiManagerConfig ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_microprofile_openapi_MpOpenApiManagerConfig",
            "text": " Optional configuration options key type default value description mp.openapi.extensions.helidon.use-jaxrs-semantics boolean &#160; If true and the jakarta.ws.rs.core.Application class returns a non-empty set, endpoints defined by other resources are not included in the OpenAPI document. @return `true` if enabled, `false` otherwise ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_microprofile_server_Server",
            "text": " Configuration of Helidon Microprofile Server Type: io.helidon.microprofile.server.Server This is a standalone configuration type, prefix from configuration root: server ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_microprofile_server_Server",
            "text": " Optional configuration options key type default value description host string &#160; Configure listen host. port int &#160; Configure listen port. ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_openapi_OpenApiFeature",
            "text": " Type: io.helidon.openapi.OpenApiFeature This is a standalone configuration type, prefix from configuration root: openapi ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_openapi_OpenApiFeature",
            "text": " Optional configuration options key type default value description cors CrossOriginConfig &#160; CORS config. @return CORS config enabled boolean true Sets whether the feature should be enabled. @return `true` if enabled, `false` otherwise manager io.helidon.openapi.OpenApiManager (service provider interface) &#160; OpenAPI manager. @return the OpenAPI manager permit-all boolean &#160; Whether to allow anybody to access the endpoint. @return whether to permit access to metrics endpoint to anybody, defaults to `true` @see #roles() roles string[&#93; &#160; Hints for role names the user is expected to be in. @return list of hints services io.helidon.openapi.OpenApiService[&#93; (service provider interface) &#160; OpenAPI services. @return the OpenAPI services static-file string &#160; Path of the static OpenAPI document file. Default types are json , yaml , and yml . @return location of the static OpenAPI document file web-context string /openapi Web context path for the OpenAPI endpoint. @return webContext to use ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_scheduling_Cron",
            "text": " Type: io.helidon.scheduling.Cron ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_scheduling_Cron",
            "text": " Required configuration options key type default value description expression string &#160; Cron expression for specifying period of execution. &lt;b&gt;Examples:&lt;/b&gt; 0/2 * * * * ? * - Every 2 seconds 0 45 9 ? * * - Every day at 9:45 0 15 8 ? * MON-FRI - Every workday at 8:15 @return cron expression Optional configuration options key type default value description concurrent boolean true Allow concurrent execution if previous task didn&#8217;t finish before next execution. Default value is true . @return true for allow concurrent execution. ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_scheduling_FixedRate",
            "text": " Type: io.helidon.scheduling.FixedRate ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_scheduling_FixedRate",
            "text": " Required configuration options key type default value description delay long &#160; Fixed rate delay between each invocation. Time unit is by default java.util.concurrent.TimeUnit#SECONDS, can be specified with io.helidon.scheduling.Scheduling.FixedRateBuilder#timeUnit(java.util.concurrent.TimeUnit). @return delay between each invocation Optional configuration options key type default value description delay-type DelayType (SINCE_PREVIOUS_START, SINCE_PREVIOUS_END) @io.helidon.scheduling.FixedRate.DelayType@.SINCE_PREVIOUS_START Configure whether the delay between the invocations should be calculated from the time when previous task started or ended. Delay type is by default FixedRate.DelayType#SINCE_PREVIOUS_START. @return delay type initial-delay long 0 Initial delay of the first invocation. Time unit is by default java.util.concurrent.TimeUnit#SECONDS, can be specified with io.helidon.scheduling.Scheduling.FixedRateBuilder#timeUnit(java.util.concurrent.TimeUnit) timeUnit(). @return initial delay value time-unit TimeUnit (NANOSECONDS, MICROSECONDS, MILLISECONDS, SECONDS, MINUTES, HOURS, DAYS) TimeUnit.SECONDS java.util.concurrent.TimeUnit TimeUnit used for interpretation of values provided with io.helidon.scheduling.Scheduling.FixedRateBuilder#delay(long) and io.helidon.scheduling.Scheduling.FixedRateBuilder#initialDelay(long). @return time unit for interpreting values in io.helidon.scheduling.Scheduling.FixedRateBuilder#delay(long) and io.helidon.scheduling.Scheduling.FixedRateBuilder#initialDelay(long) ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_scheduling_TaskConfig",
            "text": " Type: io.helidon.scheduling.TaskConfig ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_scheduling_TaskConfig",
            "text": "",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_security_Security",
            "text": " Configuration of security providers, integration and other security options Type: io.helidon.security.Security This is a standalone configuration type, prefix from configuration root: security ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_security_Security",
            "text": " Required configuration options key type default value description providers io.helidon.security.spi.SecurityProvider[&#93; (service provider interface) Such as: idcs-role-mapper (IdcsRoleMapperProvider) http-basic-auth (HttpBasicAuthProvider) idcs-role-mapper (IdcsMtRoleMapperProvider) google-login (GoogleTokenProvider) oidc (OidcProvider) http-digest-auth (HttpDigestAuthProvider) jwt (JwtProvider) header-atn (HeaderAtnProvider) abac (AbacProvider) &#160; Add a provider, works as #addProvider(io.helidon.security.spi.SecurityProvider, String), where the name is set to Class#getSimpleName() . Optional configuration options key type default value description default-authentication-provider string (service provider interface) &#160; ID of the default authentication provider default-authorization-provider string &#160; ID of the default authorization provider enabled boolean true Security can be disabled using configuration, or explicitly. By default, security instance is enabled. Disabled security instance will not perform any checks and allow all requests. environment.server-time SecurityTime &#160; Server time to use when evaluating security policies that depend on time. provider-policy.class-name Class &#160; Provider selection policy class name, only used when type is set to CLASS provider-policy.type ProviderSelectionPolicyType (FIRST, COMPOSITE, CLASS) FIRST Type of the policy. secrets Map&lt;string, string&gt; (documented for specific cases) &#160; Configured secrets secrets.*.config io.helidon.security.SecretsProviderConfig (service provider interface) &#160; Configuration specific to the secret provider secrets.*.name string &#160; Name of the secret, used for lookup secrets.*.provider string &#160; Name of the secret provider tracing.enabled boolean true Whether or not tracing should be enabled. If set to false, security tracer will be a no-op tracer. ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_security_SecurityTime",
            "text": " Type: io.helidon.security.SecurityTime ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_security_SecurityTime",
            "text": " Optional configuration options key type default value description day-of-month long &#160; Set an explicit value for one of the time fields (such as ChronoField#YEAR). hour-of-day long &#160; Set an explicit value for one of the time fields (such as ChronoField#YEAR). millisecond long &#160; Set an explicit value for one of the time fields (such as ChronoField#YEAR). minute long &#160; Set an explicit value for one of the time fields (such as ChronoField#YEAR). month long &#160; Set an explicit value for one of the time fields (such as ChronoField#YEAR). second long &#160; Set an explicit value for one of the time fields (such as ChronoField#YEAR). shift-by-seconds long 0 Configure a time-shift in seconds, to move the current time to past or future. time-zone ZoneId &#160; Override current time zone. The time will represent the SAME instant, in an explicit timezone. If we are in a UTC time zone and you set the timezone to \"Europe/Prague\", the time will be shifted by the offset of Prague (e.g. if it is noon right now in UTC, you would get 14:00). year long &#160; Set an explicit value for one of the time fields (such as ChronoField#YEAR). ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_security_providers_abac_AbacProvider",
            "text": " Attribute Based Access Control provider Type: io.helidon.security.providers.abac.AbacProvider <markup lang=\"text\" title=\"Config key\" >abac This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthorizationProvider ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_security_providers_abac_AbacProvider",
            "text": " Optional configuration options key type default value description fail-if-none-validated boolean true Whether to fail if NONE of the attributes is validated. fail-on-unvalidated boolean true Whether to fail if any attribute is left unvalidated. ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_security_providers_common_EvictableCache",
            "text": " Type: io.helidon.security.providers.common.EvictableCache ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_security_providers_common_EvictableCache",
            "text": " Optional configuration options key type default value description cache-enabled boolean true If the cacheEnabled is set to false, no caching will be done. Otherwise (default behavior) evictable caching will be used. cache-evict-delay-millis long 60000 Delay from the creation of the cache to first eviction cache-evict-period-millis long 300000 How often to evict records cache-overall-timeout-millis long 3600000 Configure record timeout since its creation. cache-timeout-millis long 3600000 Configure record timeout since last access. evictor-class Class &#160; Configure evictor to check if a record is still valid. This should be a fast way to check, as it is happening in a ConcurrentHashMap#forEachKey(long, Consumer). This is also called during all get and remove operations to only return valid records. max-size long 100000 Configure maximal cache size. parallelism-threshold long 10000 Configure parallelism threshold. ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_security_providers_common_OutboundConfig",
            "text": " Outbound configuration for outbound security Type: io.helidon.security.providers.common.OutboundConfig ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_security_providers_common_OutboundConfig",
            "text": " Optional configuration options key type default value description outbound OutboundTarget[&#93; &#160; Add a new target configuration. ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_security_providers_common_OutboundTarget",
            "text": " Type: io.helidon.security.providers.common.OutboundTarget ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_security_providers_common_OutboundTarget",
            "text": " Required configuration options key type default value description name string &#160; Configure the name of this outbound target. Optional configuration options key type default value description hosts string[&#93; &#160; Add supported host for this target. May be called more than once to add more hosts. Valid examples: localhost www.google.com 127.0.0.1 *.oracle.com 192.169. . .google. methods string[&#93; &#160; Add supported method for this target. May be called more than once to add more methods. The method is tested as is ignoring case against the used method. paths string[&#93; &#160; Add supported paths for this target. May be called more than once to add more paths. The path is tested as is against called path, and also tested as a regular expression. transport string[&#93; &#160; Add supported transports for this target. May be called more than once to add more transports. Valid examples: http https There is no wildcard support ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_security_providers_google_login_GoogleTokenProvider",
            "text": " Google Authentication provider Type: io.helidon.security.providers.google.login.GoogleTokenProvider <markup lang=\"text\" title=\"Config key\" >google-login This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthenticationProvider ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_security_providers_google_login_GoogleTokenProvider",
            "text": " Optional configuration options key type default value description client-id string &#160; Google application client id, to validate that the token was generated by Google for us. optional boolean false If set to true, this provider will return io.helidon.security.SecurityResponse.SecurityStatus#ABSTAIN instead of failing in case of invalid request. outbound OutboundConfig &#160; Outbound configuration - a set of outbound targets that will have the token propagated. proxy-host string &#160; Set proxy host when talking to Google. proxy-port int 80 Set proxy port when talking to Google. realm string helidon Set the authentication realm to build challenge, defaults to \"helidon\". token TokenHandler &#x60;Authorization&#x60; header with &#x60;bearer&#x60; prefix Token provider to extract Google access token from request, defaults to \"Authorization\" header with a \"bearer \" prefix. ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_security_providers_header_HeaderAtnProvider",
            "text": " Security provider that extracts a username (or service name) from a header. Type: io.helidon.security.providers.header.HeaderAtnProvider <markup lang=\"text\" title=\"Config key\" >header-atn This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthenticationProvider ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_security_providers_header_HeaderAtnProvider",
            "text": " Optional configuration options key type default value description atn-token TokenHandler &#160; Token handler to extract username from request. authenticate boolean true Whether to authenticate requests. optional boolean false Whether authentication is required. By default, request will fail if the username cannot be extracted. If set to false, request will process and this provider will abstain. outbound OutboundTarget[&#93; &#160; Configure outbound target for identity propagation. outbound-token TokenHandler &#160; Token handler to create outbound headers to propagate identity. If not defined, #atnTokenHandler will be used. principal-type SubjectType (USER, SERVICE) USER Principal type this provider extracts (and also propagates). propagate boolean false Whether to propagate identity. ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_security_providers_httpauth_ConfigUserStore_ConfigUser",
            "text": " Type: io.helidon.security.providers.httpauth.ConfigUserStore.ConfigUser ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_security_providers_httpauth_ConfigUserStore_ConfigUser",
            "text": " Optional configuration options key type default value description login string &#160; User&#8217;s login password string &#160; User&#8217;s password roles string[&#93; &#160; List of roles the user is in ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_security_providers_httpauth_HttpBasicAuthProvider",
            "text": " HTTP Basic Authentication provider Type: io.helidon.security.providers.httpauth.HttpBasicAuthProvider <markup lang=\"text\" title=\"Config key\" >http-basic-auth This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthenticationProvider ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_security_providers_httpauth_HttpBasicAuthProvider",
            "text": " Optional configuration options key type default value description optional boolean false Whether authentication is required. By default, request will fail if the authentication cannot be verified. If set to false, request will process and this provider will abstain. outbound OutboundTarget[&#93; &#160; Add a new outbound target to configure identity propagation or explicit username/password. principal-type SubjectType (USER, SERVICE) USER Principal type this provider extracts (and also propagates). realm string helidon Set the realm to use when challenging users. users ConfigUser[&#93; &#160; Set user store to validate users. Removes any other stores added through #addUserStore(SecureUserStore). ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_security_providers_httpauth_HttpDigestAuthProvider",
            "text": " Http digest authentication security provider Type: io.helidon.security.providers.httpauth.HttpDigestAuthProvider <markup lang=\"text\" title=\"Config key\" >http-digest-auth This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthenticationProvider ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_security_providers_httpauth_HttpDigestAuthProvider",
            "text": " Optional configuration options key type default value description algorithm Algorithm (MD5) MD5 Digest algorithm to use. nonce-timeout-millis long 86400000 How long will the nonce value be valid. When timed-out, browser will re-request username/password. optional boolean false Whether authentication is required. By default, request will fail if the authentication cannot be verified. If set to false, request will process and this provider will abstain. principal-type SubjectType (USER, SERVICE) USER Principal type this provider extracts (and also propagates). qop Qop (NONE, AUTH) NONE Only AUTH supported. If left empty, uses the legacy approach (older RFC version). AUTH-INT is not supported. realm string Helidon Set the realm to use when challenging users. server-secret string &#160; The nonce is encrypted using this secret - to make sure the nonce we get back was generated by us and to make sure we can safely time-out nonce values. This secret must be the same for all service instances (or all services that want to share the same authentication). Defaults to a random password - e.g. if deployed to multiple servers, the authentication WILL NOT WORK. You MUST provide your own password to work in a distributed environment with non-sticky load balancing. users ConfigUser[&#93; &#160; Set user store to obtain passwords and roles based on logins. ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_security_providers_httpsign_HttpSignProvider",
            "text": " HTTP header signature provider. Type: io.helidon.security.providers.httpsign.HttpSignProvider <markup lang=\"text\" title=\"Config key\" >http-signatures This type provides the following service implementations: io.helidon.security.spi.AuthenticationProvider ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_security_providers_httpsign_HttpSignProvider",
            "text": " Optional configuration options key type default value description backward-compatible-eol boolean false Enable support for Helidon versions before 3.0.0 (exclusive). Until version 3.0.0 (exclusive) there was a trailing end of line added to the signed data. To be able to communicate cross versions, we must configure this when talking to older versions of Helidon. Default value is `false`. In Helidon 2.x, this switch exists as well and the default is `true`, to allow communication between versions as needed. headers HttpSignHeader[&#93; (SIGNATURE, AUTHORIZATION, CUSTOM) &#160; Add a header that is validated on inbound requests. Provider may support more than one header to validate. inbound.keys InboundClientDefinition[&#93; &#160; Add inbound configuration. This is used to validate signature and authenticate the party. The same can be done through configuration: &lt;pre&gt; { name = \"http-signatures\" class = \"HttpSignProvider\" http-signatures { inbound { # This configures the InboundClientDefinition keys: [ { key-id = \"service1\" hmac.secret = \"${CLEAR=password}\" }] } } } &lt;/pre&gt; optional boolean true Set whether the signature is optional. If set to true (default), this provider will SecurityResponse.SecurityStatus#ABSTAIN from this request if signature is not present. If set to false, this provider will SecurityResponse.SecurityStatus#FAILURE fail if signature is not present. outbound OutboundConfig &#160; Add outbound targets to this builder. The targets are used to chose what to do for outbound communication. The targets should have OutboundTargetDefinition attached through OutboundTarget.Builder#customObject(Class, Object) to tell us how to sign the request. The same can be done through configuration: &lt;pre&gt; { name = \"http-signatures\" class = \"HttpSignProvider\" http-signatures { targets: [ { name = \"service2\" hosts = [\"localhost\"] paths = [\"/service2/.*\"] # This configures the OutboundTargetDefinition signature { key-id = \"service1\" hmac.secret = \"${CLEAR=password}\" } }] } } &lt;/pre&gt; realm string helidon Realm to use for challenging inbound requests that do not have \"Authorization\" header in case header is HttpSignHeader#AUTHORIZATION and singatures are not optional. sign-headers HeadersConfig[&#93; &#160; Override the default inbound required headers (e.g. headers that MUST be signed and headers that MUST be signed IF present). Defaults: get, head, delete methods: date, (request-target), host are mandatory; authorization if present (unless we are creating/validating the HttpSignHeader#AUTHORIZATION ourselves put, post: same as above, with addition of: content-length, content-type and digest if present for other methods: date, (request-target) Note that this provider DOES NOT validate the \"Digest\" HTTP header, only the signature. ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_security_providers_httpsign_InboundClientDefinition",
            "text": " Type: io.helidon.security.providers.httpsign.InboundClientDefinition ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_security_providers_httpsign_InboundClientDefinition",
            "text": " Optional configuration options key type default value description algorithm string &#160; Algorithm of signature used by this client. Currently supported: rsa-sha256 - asymmetric based on public/private keys hmac-sha256 - symmetric based on a shared secret hmac.secret string &#160; Helper method to configure a password-like secret (instead of byte based #hmacSecret(byte[]). The password is transformed to bytes with StandardCharsets#UTF_8 charset. key-id string &#160; The key id of this client to map to this signature validation configuration. principal-name string &#160; The principal name of the client, defaults to keyId if not configured. principal-type SubjectType (USER, SERVICE) SERVICE The type of principal we have authenticated (either user or service, defaults to service). public-key Keys &#160; For algorithms based on public/private key (such as rsa-sha256), this provides access to the public key of the client. ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_security_providers_httpsign_SignedHeadersConfig_HeadersConfig",
            "text": " Type: io.helidon.security.providers.httpsign.SignedHeadersConfig.HeadersConfig ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_security_providers_httpsign_SignedHeadersConfig_HeadersConfig",
            "text": " Optional configuration options key type default value description always string[&#93; &#160; Headers that must be signed (and signature validation or creation should fail if not signed or present) if-present string[&#93; &#160; Headers that must be signed if present in request. method string &#160; HTTP method this header configuration is bound to. If not present, it is considered default header configuration. ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_security_providers_idcs_mapper_IdcsMtRoleMapperProvider",
            "text": " Multitenant IDCS role mapping provider Type: io.helidon.security.providers.idcs.mapper.IdcsMtRoleMapperProvider <markup lang=\"text\" title=\"Config key\" >idcs-role-mapper This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.SubjectMappingProvider ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_security_providers_idcs_mapper_IdcsMtRoleMapperProvider",
            "text": " Optional configuration options key type default value description cache-config EvictableCache &#160; Use explicit io.helidon.security.providers.common.EvictableCache for role caching. default-idcs-subject-type string user Configure subject type to use when requesting roles from IDCS. Can be either #IDCS_SUBJECT_TYPE_USER or #IDCS_SUBJECT_TYPE_CLIENT. Defaults to #IDCS_SUBJECT_TYPE_USER. idcs-app-name-handler TokenHandler &#160; Configure token handler for IDCS Application name. By default the header IdcsMtRoleMapperProvider#IDCS_APP_HEADER is used. idcs-tenant-handler TokenHandler &#160; Configure token handler for IDCS Tenant ID. By default the header IdcsMtRoleMapperProvider#IDCS_TENANT_HEADER is used. oidc-config OidcConfig &#160; Use explicit io.helidon.security.providers.oidc.common.OidcConfig instance, e.g. when using it also for OIDC provider. subject-types SubjectType[&#93; (USER, SERVICE) USER Add a supported subject type. If none added, io.helidon.security.SubjectType#USER is used. If any added, only the ones added will be used (e.g. if you want to use both io.helidon.security.SubjectType#USER and io.helidon.security.SubjectType#SERVICE, both need to be added. ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_security_providers_idcs_mapper_IdcsRoleMapperProvider",
            "text": " IDCS role mapping provider Type: io.helidon.security.providers.idcs.mapper.IdcsRoleMapperProvider <markup lang=\"text\" title=\"Config key\" >idcs-role-mapper This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.SubjectMappingProvider ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_security_providers_idcs_mapper_IdcsRoleMapperProvider",
            "text": " Optional configuration options key type default value description cache-config EvictableCache &#160; Use explicit io.helidon.security.providers.common.EvictableCache for role caching. default-idcs-subject-type string user Configure subject type to use when requesting roles from IDCS. Can be either #IDCS_SUBJECT_TYPE_USER or #IDCS_SUBJECT_TYPE_CLIENT. Defaults to #IDCS_SUBJECT_TYPE_USER. oidc-config OidcConfig &#160; Use explicit io.helidon.security.providers.oidc.common.OidcConfig instance, e.g. when using it also for OIDC provider. subject-types SubjectType[&#93; (USER, SERVICE) USER Add a supported subject type. If none added, io.helidon.security.SubjectType#USER is used. If any added, only the ones added will be used (e.g. if you want to use both io.helidon.security.SubjectType#USER and io.helidon.security.SubjectType#SERVICE, both need to be added. ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_security_providers_idcs_mapper_IdcsRoleMapperProviderBase_Builder",
            "text": " Type: io.helidon.security.providers.idcs.mapper.IdcsRoleMapperProviderBase.Builder ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_security_providers_idcs_mapper_IdcsRoleMapperProviderBase_Builder",
            "text": " Optional configuration options key type default value description default-idcs-subject-type string user Configure subject type to use when requesting roles from IDCS. Can be either #IDCS_SUBJECT_TYPE_USER or #IDCS_SUBJECT_TYPE_CLIENT. Defaults to #IDCS_SUBJECT_TYPE_USER. oidc-config OidcConfig &#160; Use explicit io.helidon.security.providers.oidc.common.OidcConfig instance, e.g. when using it also for OIDC provider. subject-types SubjectType[&#93; (USER, SERVICE) USER Add a supported subject type. If none added, io.helidon.security.SubjectType#USER is used. If any added, only the ones added will be used (e.g. if you want to use both io.helidon.security.SubjectType#USER and io.helidon.security.SubjectType#SERVICE, both need to be added. ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_security_providers_jwt_JwtProvider",
            "text": " JWT authentication provider Type: io.helidon.security.providers.jwt.JwtProvider <markup lang=\"text\" title=\"Config key\" >jwt This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthenticationProvider ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_security_providers_jwt_JwtProvider",
            "text": " Optional configuration options key type default value description allow-impersonation boolean false Whether to allow impersonation by explicitly overriding username from outbound requests using io.helidon.security.EndpointConfig#PROPERTY_OUTBOUND_ID property. By default this is not allowed and identity can only be propagated. allow-unsigned boolean false Configure support for unsigned JWT. If this is set to true any JWT that has algorithm set to none and no kid defined will be accepted. Note that this has serious security impact - if JWT can be sent from a third party, this allows the third party to send ANY JWT and it would be accpted as valid. atn-token.handler TokenHandler &#160; Token handler to extract username from request. atn-token.jwk.resource Resource &#160; JWK resource used to verify JWTs created by other parties. atn-token.jwt-audience string &#160; Audience expected in inbound JWTs. atn-token.verify-signature boolean true Configure whether to verify signatures. Signatures verification is enabled by default. You can configure the provider not to verify signatures. &lt;b&gt;Make sure your service is properly secured on network level and only accessible from a secure endpoint that provides the JWTs when signature verification is disabled. If signature verification is disabled, this service will accept &lt;i&gt;ANY&lt;/i&gt; JWT&lt;/b&gt; authenticate boolean true Whether to authenticate requests. optional boolean false Whether authentication is required. By default, request will fail if the username cannot be extracted. If set to false, request will process and this provider will abstain. principal-type SubjectType (USER, SERVICE) USER Principal type this provider extracts (and also propagates). propagate boolean true Whether to propagate identity. sign-token OutboundConfig &#160; Configuration of outbound rules. sign-token.jwk.resource Resource &#160; JWK resource used to sign JWTs created by us. sign-token.jwt-issuer string &#160; Issuer used to create new JWTs. use-jwt-groups boolean true Claim groups from JWT will be used to automatically add groups to current subject (may be used with jakarta.annotation.security.RolesAllowed annotation). ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_security_providers_oidc_OidcProvider",
            "text": " Open ID Connect security provider Type: io.helidon.security.providers.oidc.OidcProvider <markup lang=\"text\" title=\"Config key\" >oidc This type provides the following service implementations: io.helidon.security.spi.AuthenticationProvider io.helidon.security.spi.SecurityProvider ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_security_providers_oidc_OidcProvider",
            "text": " Optional configuration options key type default value description audience string &#160; Audience of issued tokens. authorization-endpoint-uri URI &#160; URI of an authorization endpoint used to redirect users to for logging-in. If not defined, it is obtained from #oidcMetadata(Resource), if that is not defined an attempt is made to use #identityUri(URI)/oauth2/v1/authorize. base-scopes string openid Configure base scopes. By default, this is DEFAULT_BASE_SCOPES . If scope has a qualifier, it must be used here. check-audience boolean false Configure audience claim check. client-id string &#160; Client ID as generated by OIDC server. client-secret string &#160; Client secret as generated by OIDC server. Used to authenticate this application with the server when requesting JWT based on a code. client-timeout-millis Duration 30000 Timeout of calls using web client. cookie-domain string &#160; Domain the cookie is valid for. Not used by default. cookie-http-only boolean true When using cookie, if set to true, the HttpOnly attribute will be configured. Defaults to OidcCookieHandler.Builder#DEFAULT_HTTP_ONLY . cookie-max-age-seconds long &#160; When using cookie, used to set MaxAge attribute of the cookie, defining how long the cookie is valid. Not used by default. cookie-name string JSESSIONID Name of the cookie to use. Defaults to DEFAULT_COOKIE_NAME . cookie-name-tenant string HELIDON_TENANT The name of the cookie to use for the tenant name. Defaults to DEFAULT_TENANT_COOKIE_NAME . cookie-path string / Path the cookie is valid for. Defaults to \"/\". cookie-same-site SameSite (LAX, STRICT, NONE) LAX When using cookie, used to set the SameSite cookie value. Can be \"Strict\" or \"Lax\". cookie-secure boolean false When using cookie, if set to true, the Secure attribute will be configured. Defaults to false. cookie-use boolean true Whether to use cookie to store JWT between requests. Defaults to DEFAULT_COOKIE_USE . cors CrossOriginConfig &#160; Assign cross-origin resource sharing settings. force-https-redirects boolean false Force HTTPS for redirects to identity provider. Defaults to false . frontend-uri string &#160; Full URI of this application that is visible from user browser. Used to redirect request back from identity server after successful login. header-token TokenHandler &#160; A TokenHandler to process header containing a JWT. Default is \"Authorization\" header with a prefix \"bearer \". header-use boolean true Whether to expect JWT in a header field. identity-uri URI &#160; URI of the identity server, base used to retrieve OIDC metadata. introspect-endpoint-uri URI &#160; Endpoint to use to validate JWT. Either use this or set #signJwk(JwkKeys) or #signJwk(Resource). issuer string &#160; Issuer of issued tokens. max-redirects int 5 Configure maximal number of redirects when redirecting to an OIDC provider within a single authentication attempt. Defaults to `DEFAULT_MAX_REDIRECTS` oidc-metadata-well-known boolean true If set to true, metadata will be loaded from default (well known) location, unless it is explicitly defined using oidc-metadata-resource. If set to false, it would not be loaded even if oidc-metadata-resource is not defined. In such a case all URIs must be explicitly defined (e.g. token-endpoint-uri). oidc-metadata.resource Resource &#160; Resource configuration for OIDC Metadata containing endpoints to various identity services, as well as information about the identity server. optional boolean false Whether authentication is required. By default, request will fail if the authentication cannot be verified. If set to true, request will process and this provider will abstain. optional-audience boolean false Allow audience claim to be optional. outbound OutboundTarget[&#93; &#160; Add a new target configuration. propagate boolean false Whether to propagate identity. proxy-host string &#160; Proxy host to use. When defined, triggers usage of proxy for HTTP requests. Setting to empty String has the same meaning as setting to null - disables proxy. proxy-port int 80 Proxy port. Defaults to DEFAULT_PROXY_PORT proxy-protocol string http Proxy protocol to use when proxy is used. Defaults to DEFAULT_PROXY_PROTOCOL . query-param-name string accessToken Name of a query parameter that contains the JWT token when parameter is used. query-param-tenant-name string h_tenant Name of a query parameter that contains the tenant name when the parameter is used. Defaults to #DEFAULT_TENANT_PARAM_NAME. query-param-use boolean false Whether to use a query parameter to send JWT token from application to this server. redirect boolean false By default, the client should redirect to the identity server for the user to log in. This behavior can be overridden by setting redirect to false. When token is not present in the request, the client will not redirect and just return appropriate error response code. redirect-attempt-param string h_ra Configure the parameter used to store the number of attempts in redirect. Defaults to `DEFAULT_ATTEMPT_PARAM` redirect-uri string /oidc/redirect URI to register web server component on, used by the OIDC server to redirect authorization requests to after a user logs in or approves scopes. Note that usually the redirect URI configured here must be the same one as configured on OIDC server. Defaults to `DEFAULT_REDIRECT_URI` relative-uris boolean false Can be set to true to force the use of relative URIs in all requests, regardless of the presence or absence of proxies or no-proxy lists. By default, requests that use the Proxy will have absolute URIs. Set this flag to true if the host is unable to accept absolute URIs. Defaults to DEFAULT_RELATIVE_URIS . scope-audience string &#160; Audience of the scope required by this application. This is prefixed to the scope name when requesting scopes from the identity server. Defaults to empty string. server-type string @default Configure one of the supported types of identity servers. If the type does not have an explicit mapping, a warning is logged and the default implementation is used. sign-jwk.resource Resource &#160; A resource pointing to JWK with public keys of signing certificates used to validate JWT. tenants TenantConfig &#160; Configurations of the tenants token-endpoint-auth ClientAuthentication (CLIENT_SECRET_BASIC, CLIENT_SECRET_POST, CLIENT_SECRET_JWT, PRIVATE_KEY_JWT, NONE) CLIENT_SECRET_BASIC Type of authentication to use when invoking the token endpoint. Current supported options: io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#CLIENT_SECRET_BASIC io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#CLIENT_SECRET_POST io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#NONE token-endpoint-uri URI &#160; URI of a token endpoint used to obtain a JWT based on the authentication code. If not defined, it is obtained from #oidcMetadata(Resource), if that is not defined an attempt is made to use #identityUri(URI)/oauth2/v1/token. use-jwt-groups boolean true Claim groups from JWT will be used to automatically add groups to current subject (may be used with jakarta.annotation.security.RolesAllowed annotation). validate-jwt-with-jwk boolean true Use JWK (a set of keys to validate signatures of JWT) to validate tokens. Use this method when you want to use default values for JWK or introspection endpoint URI. ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_security_providers_oidc_common_BaseBuilder",
            "text": " Type: io.helidon.security.providers.oidc.common.BaseBuilder ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_security_providers_oidc_common_BaseBuilder",
            "text": " Optional configuration options key type default value description audience string &#160; Audience of issued tokens. authorization-endpoint-uri URI &#160; URI of an authorization endpoint used to redirect users to for logging-in. If not defined, it is obtained from #oidcMetadata(Resource), if that is not defined an attempt is made to use #identityUri(URI)/oauth2/v1/authorize. base-scopes string openid Configure base scopes. By default, this is DEFAULT_BASE_SCOPES . If scope has a qualifier, it must be used here. check-audience boolean false Configure audience claim check. client-id string &#160; Client ID as generated by OIDC server. client-secret string &#160; Client secret as generated by OIDC server. Used to authenticate this application with the server when requesting JWT based on a code. client-timeout-millis Duration 30000 Timeout of calls using web client. identity-uri URI &#160; URI of the identity server, base used to retrieve OIDC metadata. introspect-endpoint-uri URI &#160; Endpoint to use to validate JWT. Either use this or set #signJwk(JwkKeys) or #signJwk(Resource). issuer string &#160; Issuer of issued tokens. oidc-metadata-well-known boolean true If set to true, metadata will be loaded from default (well known) location, unless it is explicitly defined using oidc-metadata-resource. If set to false, it would not be loaded even if oidc-metadata-resource is not defined. In such a case all URIs must be explicitly defined (e.g. token-endpoint-uri). oidc-metadata.resource Resource &#160; Resource configuration for OIDC Metadata containing endpoints to various identity services, as well as information about the identity server. optional-audience boolean false Allow audience claim to be optional. scope-audience string &#160; Audience of the scope required by this application. This is prefixed to the scope name when requesting scopes from the identity server. Defaults to empty string. server-type string @default Configure one of the supported types of identity servers. If the type does not have an explicit mapping, a warning is logged and the default implementation is used. sign-jwk.resource Resource &#160; A resource pointing to JWK with public keys of signing certificates used to validate JWT. token-endpoint-auth ClientAuthentication (CLIENT_SECRET_BASIC, CLIENT_SECRET_POST, CLIENT_SECRET_JWT, PRIVATE_KEY_JWT, NONE) CLIENT_SECRET_BASIC Type of authentication to use when invoking the token endpoint. Current supported options: io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#CLIENT_SECRET_BASIC io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#CLIENT_SECRET_POST io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#NONE token-endpoint-uri URI &#160; URI of a token endpoint used to obtain a JWT based on the authentication code. If not defined, it is obtained from #oidcMetadata(Resource), if that is not defined an attempt is made to use #identityUri(URI)/oauth2/v1/token. validate-jwt-with-jwk boolean true Use JWK (a set of keys to validate signatures of JWT) to validate tokens. Use this method when you want to use default values for JWK or introspection endpoint URI. ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_security_providers_oidc_common_OidcConfig",
            "text": " Open ID Connect configuration Type: io.helidon.security.providers.oidc.common.OidcConfig ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_security_providers_oidc_common_OidcConfig",
            "text": " Optional configuration options key type default value description audience string &#160; Audience of issued tokens. authorization-endpoint-uri URI &#160; URI of an authorization endpoint used to redirect users to for logging-in. If not defined, it is obtained from #oidcMetadata(Resource), if that is not defined an attempt is made to use #identityUri(URI)/oauth2/v1/authorize. base-scopes string openid Configure base scopes. By default, this is DEFAULT_BASE_SCOPES . If scope has a qualifier, it must be used here. check-audience boolean false Configure audience claim check. client-id string &#160; Client ID as generated by OIDC server. client-secret string &#160; Client secret as generated by OIDC server. Used to authenticate this application with the server when requesting JWT based on a code. client-timeout-millis Duration 30000 Timeout of calls using web client. cookie-domain string &#160; Domain the cookie is valid for. Not used by default. cookie-http-only boolean true When using cookie, if set to true, the HttpOnly attribute will be configured. Defaults to OidcCookieHandler.Builder#DEFAULT_HTTP_ONLY . cookie-max-age-seconds long &#160; When using cookie, used to set MaxAge attribute of the cookie, defining how long the cookie is valid. Not used by default. cookie-name string JSESSIONID Name of the cookie to use. Defaults to DEFAULT_COOKIE_NAME . cookie-name-tenant string HELIDON_TENANT The name of the cookie to use for the tenant name. Defaults to DEFAULT_TENANT_COOKIE_NAME . cookie-path string / Path the cookie is valid for. Defaults to \"/\". cookie-same-site SameSite (LAX, STRICT, NONE) LAX When using cookie, used to set the SameSite cookie value. Can be \"Strict\" or \"Lax\". cookie-secure boolean false When using cookie, if set to true, the Secure attribute will be configured. Defaults to false. cookie-use boolean true Whether to use cookie to store JWT between requests. Defaults to DEFAULT_COOKIE_USE . cors CrossOriginConfig &#160; Assign cross-origin resource sharing settings. force-https-redirects boolean false Force HTTPS for redirects to identity provider. Defaults to false . frontend-uri string &#160; Full URI of this application that is visible from user browser. Used to redirect request back from identity server after successful login. header-token TokenHandler &#160; A TokenHandler to process header containing a JWT. Default is \"Authorization\" header with a prefix \"bearer \". header-use boolean true Whether to expect JWT in a header field. identity-uri URI &#160; URI of the identity server, base used to retrieve OIDC metadata. introspect-endpoint-uri URI &#160; Endpoint to use to validate JWT. Either use this or set #signJwk(JwkKeys) or #signJwk(Resource). issuer string &#160; Issuer of issued tokens. max-redirects int 5 Configure maximal number of redirects when redirecting to an OIDC provider within a single authentication attempt. Defaults to `DEFAULT_MAX_REDIRECTS` oidc-metadata-well-known boolean true If set to true, metadata will be loaded from default (well known) location, unless it is explicitly defined using oidc-metadata-resource. If set to false, it would not be loaded even if oidc-metadata-resource is not defined. In such a case all URIs must be explicitly defined (e.g. token-endpoint-uri). oidc-metadata.resource Resource &#160; Resource configuration for OIDC Metadata containing endpoints to various identity services, as well as information about the identity server. optional-audience boolean false Allow audience claim to be optional. proxy-host string &#160; Proxy host to use. When defined, triggers usage of proxy for HTTP requests. Setting to empty String has the same meaning as setting to null - disables proxy. proxy-port int 80 Proxy port. Defaults to DEFAULT_PROXY_PORT proxy-protocol string http Proxy protocol to use when proxy is used. Defaults to DEFAULT_PROXY_PROTOCOL . query-param-name string accessToken Name of a query parameter that contains the JWT token when parameter is used. query-param-tenant-name string h_tenant Name of a query parameter that contains the tenant name when the parameter is used. Defaults to #DEFAULT_TENANT_PARAM_NAME. query-param-use boolean false Whether to use a query parameter to send JWT token from application to this server. redirect boolean false By default, the client should redirect to the identity server for the user to log in. This behavior can be overridden by setting redirect to false. When token is not present in the request, the client will not redirect and just return appropriate error response code. redirect-attempt-param string h_ra Configure the parameter used to store the number of attempts in redirect. Defaults to `DEFAULT_ATTEMPT_PARAM` redirect-uri string /oidc/redirect URI to register web server component on, used by the OIDC server to redirect authorization requests to after a user logs in or approves scopes. Note that usually the redirect URI configured here must be the same one as configured on OIDC server. Defaults to `DEFAULT_REDIRECT_URI` relative-uris boolean false Can be set to true to force the use of relative URIs in all requests, regardless of the presence or absence of proxies or no-proxy lists. By default, requests that use the Proxy will have absolute URIs. Set this flag to true if the host is unable to accept absolute URIs. Defaults to DEFAULT_RELATIVE_URIS . scope-audience string &#160; Audience of the scope required by this application. This is prefixed to the scope name when requesting scopes from the identity server. Defaults to empty string. server-type string @default Configure one of the supported types of identity servers. If the type does not have an explicit mapping, a warning is logged and the default implementation is used. sign-jwk.resource Resource &#160; A resource pointing to JWK with public keys of signing certificates used to validate JWT. tenants TenantConfig &#160; Configurations of the tenants token-endpoint-auth ClientAuthentication (CLIENT_SECRET_BASIC, CLIENT_SECRET_POST, CLIENT_SECRET_JWT, PRIVATE_KEY_JWT, NONE) CLIENT_SECRET_BASIC Type of authentication to use when invoking the token endpoint. Current supported options: io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#CLIENT_SECRET_BASIC io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#CLIENT_SECRET_POST io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#NONE token-endpoint-uri URI &#160; URI of a token endpoint used to obtain a JWT based on the authentication code. If not defined, it is obtained from #oidcMetadata(Resource), if that is not defined an attempt is made to use #identityUri(URI)/oauth2/v1/token. validate-jwt-with-jwk boolean true Use JWK (a set of keys to validate signatures of JWT) to validate tokens. Use this method when you want to use default values for JWK or introspection endpoint URI. ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_security_providers_oidc_common_TenantConfig",
            "text": " Open ID Connect tenant configuration Type: io.helidon.security.providers.oidc.common.TenantConfig ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_security_providers_oidc_common_TenantConfig",
            "text": " Required configuration options key type default value description name string &#160; Name of the tenant. Optional configuration options key type default value description audience string &#160; Audience of issued tokens. authorization-endpoint-uri URI &#160; URI of an authorization endpoint used to redirect users to for logging-in. If not defined, it is obtained from #oidcMetadata(Resource), if that is not defined an attempt is made to use #identityUri(URI)/oauth2/v1/authorize. base-scopes string openid Configure base scopes. By default, this is DEFAULT_BASE_SCOPES . If scope has a qualifier, it must be used here. check-audience boolean false Configure audience claim check. client-id string &#160; Client ID as generated by OIDC server. client-secret string &#160; Client secret as generated by OIDC server. Used to authenticate this application with the server when requesting JWT based on a code. client-timeout-millis Duration 30000 Timeout of calls using web client. identity-uri URI &#160; URI of the identity server, base used to retrieve OIDC metadata. introspect-endpoint-uri URI &#160; Endpoint to use to validate JWT. Either use this or set #signJwk(JwkKeys) or #signJwk(Resource). issuer string &#160; Issuer of issued tokens. oidc-metadata-well-known boolean true If set to true, metadata will be loaded from default (well known) location, unless it is explicitly defined using oidc-metadata-resource. If set to false, it would not be loaded even if oidc-metadata-resource is not defined. In such a case all URIs must be explicitly defined (e.g. token-endpoint-uri). oidc-metadata.resource Resource &#160; Resource configuration for OIDC Metadata containing endpoints to various identity services, as well as information about the identity server. optional-audience boolean false Allow audience claim to be optional. scope-audience string &#160; Audience of the scope required by this application. This is prefixed to the scope name when requesting scopes from the identity server. Defaults to empty string. server-type string @default Configure one of the supported types of identity servers. If the type does not have an explicit mapping, a warning is logged and the default implementation is used. sign-jwk.resource Resource &#160; A resource pointing to JWK with public keys of signing certificates used to validate JWT. token-endpoint-auth ClientAuthentication (CLIENT_SECRET_BASIC, CLIENT_SECRET_POST, CLIENT_SECRET_JWT, PRIVATE_KEY_JWT, NONE) CLIENT_SECRET_BASIC Type of authentication to use when invoking the token endpoint. Current supported options: io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#CLIENT_SECRET_BASIC io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#CLIENT_SECRET_POST io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#NONE token-endpoint-uri URI &#160; URI of a token endpoint used to obtain a JWT based on the authentication code. If not defined, it is obtained from #oidcMetadata(Resource), if that is not defined an attempt is made to use #identityUri(URI)/oauth2/v1/token. validate-jwt-with-jwk boolean true Use JWK (a set of keys to validate signatures of JWT) to validate tokens. Use this method when you want to use default values for JWK or introspection endpoint URI. ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_security_util_TokenHandler",
            "text": " Type: io.helidon.security.util.TokenHandler ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_security_util_TokenHandler",
            "text": " Optional configuration options key type default value description format string &#160; Token format for creating outbound tokens. header string &#160; Set the name of header to look into to extract the token. prefix string &#160; Set the prefix of header value to extract the token. regexp string &#160; Set the token pattern (Regular expression) to extract the token. ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_tracing_Tracer",
            "text": " Jaeger tracer configuration. Type: io.helidon.tracing.Tracer This is a standalone configuration type, prefix from configuration root: tracing ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_tracing_Tracer",
            "text": " Optional configuration options key type default value description client-cert-pem Resource &#160; Certificate of client in PEM format. exporter-timeout Duration PT10S Timeout of exporter requests. max-export-batch-size int 512 Maximum Export Batch Size of exporter requests. max-queue-size int 2048 Maximum Queue Size of exporter requests. private-key-pem Resource &#160; Private key in PEM format. propagation PropagationFormat[&#93; (B3, B3_SINGLE, JAEGER, W3C) JAEGER Add propagation format to use. sampler-param Number 1 The sampler parameter (number). sampler-type SamplerType (CONSTANT, RATIO) CONSTANT Sampler type. See &lt;a href=\"https://www.jaegertracing.io/docs/latest/sampling/#client-sampling-configuration\"&gt;Sampler types&lt;/a&gt;. schedule-delay Duration PT5S Schedule Delay of exporter requests. span-processor-type SpanProcessorType (SIMPLE, BATCH) batch Span Processor type used. trusted-cert-pem Resource &#160; Trusted certificates in PEM format. ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_tracing_TracerBuilder",
            "text": " Tracer configuration. Type: io.helidon.tracing.TracerBuilder ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_tracing_TracerBuilder",
            "text": "",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_tracing_providers_jaeger_JaegerTracerBuilder",
            "text": " Jaeger tracer configuration. Type: io.helidon.tracing.Tracer This is a standalone configuration type, prefix from configuration root: tracing ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_tracing_providers_jaeger_JaegerTracerBuilder",
            "text": " Optional configuration options key type default value description client-cert-pem Resource &#160; Certificate of client in PEM format. exporter-timeout Duration PT10S Timeout of exporter requests. max-export-batch-size int 512 Maximum Export Batch Size of exporter requests. max-queue-size int 2048 Maximum Queue Size of exporter requests. private-key-pem Resource &#160; Private key in PEM format. propagation PropagationFormat[&#93; (B3, B3_SINGLE, JAEGER, W3C) JAEGER Add propagation format to use. sampler-param Number 1 The sampler parameter (number). sampler-type SamplerType (CONSTANT, RATIO) CONSTANT Sampler type. See &lt;a href=\"https://www.jaegertracing.io/docs/latest/sampling/#client-sampling-configuration\"&gt;Sampler types&lt;/a&gt;. schedule-delay Duration PT5S Schedule Delay of exporter requests. span-processor-type SpanProcessorType (SIMPLE, BATCH) batch Span Processor type used. trusted-cert-pem Resource &#160; Trusted certificates in PEM format. ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_tracing_providers_opentracing_OpenTracingTracerBuilder",
            "text": " OpenTracing tracer configuration. Type: io.helidon.tracing.providers.opentracing.OpenTracingTracerBuilder ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_tracing_providers_opentracing_OpenTracingTracerBuilder",
            "text": "",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_tracing_providers_zipkin_ZipkinTracerBuilder",
            "text": " Zipkin tracer configuration Type: io.opentracing.Tracer This is a standalone configuration type, prefix from configuration root: tracing ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_tracing_providers_zipkin_ZipkinTracerBuilder",
            "text": " Optional configuration options key type default value description api-version Version (V1, V2) V2 Version of Zipkin API to use. Defaults to Version#V2. ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_webclient_api_HttpClientConfig",
            "text": " Type: io.helidon.webclient.api.HttpClientConfig ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_webclient_api_HttpClientConfig",
            "text": " Optional configuration options key type default value description base-uri string &#160; Base uri used by the client in all requests. @return base uri of the client requests connect-timeout Duration &#160; Connect timeout. @return connect timeout @see io.helidon.common.socket.SocketOptions#connectTimeout() connection-cache-size int 256 Maximal size of the connection cache. For most HTTP protocols, we may cache connections to various endpoints for keep alive (or stream reuse in case of HTTP/2). This option limits the size. Setting this number lower than the \"usual\" number of target services will cause connections to be closed and reopened frequently. content-encoding ContentEncodingContext &#160; Configure the listener specific io.helidon.http.encoding.ContentEncodingContext. This method discards all previously registered ContentEncodingContext. If no content encoding context is registered, default encoding context is used. @return content encoding context cookie-manager WebClientCookieManager &#160; WebClient cookie manager. @return cookie manager to use default-headers Map&lt;string, string&gt; &#160; Default headers to be used in every request from configuration. @return default headers follow-redirects boolean true Whether to follow redirects. @return whether to follow redirects keep-alive boolean true Determines if connection keep alive is enabled (NOT socket keep alive, but HTTP connection keep alive, to re-use the same connection for multiple requests). @return keep alive for this connection @see io.helidon.common.socket.SocketOptions#socketKeepAlive() max-in-memory-entity int 131072 If the entity is expected to be smaller that this number of bytes, it would be buffered in memory to optimize performance. If bigger, streaming will be used. Note that for some entity types we cannot use streaming, as they are already fully in memory (String, byte[]), for such cases, this option is ignored. Default is 128Kb. @return maximal number of bytes to buffer in memory for supported writers max-redirects int 10 Max number of followed redirects. This is ignored if #followRedirects() option is false . @return max number of followed redirects media-context MediaContext create() Configure the listener specific io.helidon.http.media.MediaContext. This method discards all previously registered MediaContext. If no media context is registered, default media context is used. @return media context media-type-parser-mode ParserMode (STRICT, RELAXED) STRICT Configure media type parsing mode for HTTP Content-Type header. @return media type parsing mode properties Map&lt;string, string&gt; &#160; Properties configured for this client. These properties are propagated through client request, to be used by services (and possibly for other purposes). @return map of client properties proxy Proxy &#160; Proxy configuration to be used for requests. @return proxy to use, defaults to Proxy#noProxy() read-continue-timeout Duration PT1S Socket 100-Continue read timeout. Default is 1 second. This read timeout is used when 100-Continue is sent by the client, before it sends an entity. @return read 100-Continue timeout duration read-timeout Duration &#160; Read timeout. @return read timeout @see io.helidon.common.socket.SocketOptions#readTimeout() relative-uris boolean false Can be set to true to force the use of relative URIs in all requests, regardless of the presence or absence of proxies or no-proxy lists. @return relative URIs flag send-expect-continue boolean true Whether Expect-100-Continue header is sent to verify server availability before sending an entity. Defaults to `true`. @return whether Expect:100-Continue header should be sent on streamed transfers services io.helidon.webclient.spi.WebClientService[&#93; (service provider interface) &#160; WebClient services. @return services to use with this web client share-connection-cache boolean true Whether to share connection cache between all the WebClient instances in JVM. @return true if connection cache is shared socket-options SocketOptions &#160; Socket options for connections opened by this client. If there is a value explicitly configured on this type and on the socket options, the one configured on this type&#8217;s builder will win: #readTimeout() #connectTimeout() @return socket options tls Tls &#160; TLS configuration for any TLS request from this client. TLS can also be configured per request. TLS is used when the protocol is set to https . @return TLS configuration to use ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_webclient_api_HttpConfigBase",
            "text": " Type: io.helidon.webclient.api.HttpConfigBase ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_webclient_api_HttpConfigBase",
            "text": " Optional configuration options key type default value description connect-timeout Duration &#160; Connect timeout. @return connect timeout @see io.helidon.common.socket.SocketOptions#connectTimeout() follow-redirects boolean true Whether to follow redirects. @return whether to follow redirects keep-alive boolean true Determines if connection keep alive is enabled (NOT socket keep alive, but HTTP connection keep alive, to re-use the same connection for multiple requests). @return keep alive for this connection @see io.helidon.common.socket.SocketOptions#socketKeepAlive() max-redirects int 10 Max number of followed redirects. This is ignored if #followRedirects() option is false . @return max number of followed redirects properties Map&lt;string, string&gt; &#160; Properties configured for this client. These properties are propagated through client request, to be used by services (and possibly for other purposes). @return map of client properties proxy Proxy &#160; Proxy configuration to be used for requests. @return proxy to use, defaults to Proxy#noProxy() read-timeout Duration &#160; Read timeout. @return read timeout @see io.helidon.common.socket.SocketOptions#readTimeout() tls Tls &#160; TLS configuration for any TLS request from this client. TLS can also be configured per request. TLS is used when the protocol is set to https . @return TLS configuration to use ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_webclient_api_Proxy",
            "text": " Type: io.helidon.webclient.api.Proxy ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_webclient_api_Proxy",
            "text": " Optional configuration options key type default value description host string &#160; Sets a new host value. no-proxy string[&#93; &#160; Configure a host pattern that is not going through a proxy. Options are: IP Address, such as 192.168.1.1 IP V6 Address, such as [2001:db8:85a3:8d3:1319:8a2e:370:7348] Hostname, such as localhost Domain name, such as helidon.io Domain name and all sub-domains, such as .helidon.io (leading dot) Combination of all options from above with a port, such as .helidon.io:80 password string &#160; Sets a new password for the proxy. port int &#160; Sets a port value. type ProxyType (NONE, SYSTEM, HTTP) HTTP Sets a new proxy type. username string &#160; Sets a new username for the proxy. ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_webclient_api_WebClient",
            "text": " Type: io.helidon.webclient.api.WebClient This is a standalone configuration type, prefix from configuration root: clients ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_webclient_api_WebClient",
            "text": " Optional configuration options key type default value description base-uri string &#160; Base uri used by the client in all requests. @return base uri of the client requests connect-timeout Duration &#160; Connect timeout. @return connect timeout @see io.helidon.common.socket.SocketOptions#connectTimeout() connection-cache-size int 256 Maximal size of the connection cache. For most HTTP protocols, we may cache connections to various endpoints for keep alive (or stream reuse in case of HTTP/2). This option limits the size. Setting this number lower than the \"usual\" number of target services will cause connections to be closed and reopened frequently. content-encoding ContentEncodingContext &#160; Configure the listener specific io.helidon.http.encoding.ContentEncodingContext. This method discards all previously registered ContentEncodingContext. If no content encoding context is registered, default encoding context is used. @return content encoding context cookie-manager WebClientCookieManager &#160; WebClient cookie manager. @return cookie manager to use default-headers Map&lt;string, string&gt; &#160; Default headers to be used in every request from configuration. @return default headers follow-redirects boolean true Whether to follow redirects. @return whether to follow redirects keep-alive boolean true Determines if connection keep alive is enabled (NOT socket keep alive, but HTTP connection keep alive, to re-use the same connection for multiple requests). @return keep alive for this connection @see io.helidon.common.socket.SocketOptions#socketKeepAlive() max-in-memory-entity int 131072 If the entity is expected to be smaller that this number of bytes, it would be buffered in memory to optimize performance. If bigger, streaming will be used. Note that for some entity types we cannot use streaming, as they are already fully in memory (String, byte[]), for such cases, this option is ignored. Default is 128Kb. @return maximal number of bytes to buffer in memory for supported writers max-redirects int 10 Max number of followed redirects. This is ignored if #followRedirects() option is false . @return max number of followed redirects media-context MediaContext create() Configure the listener specific io.helidon.http.media.MediaContext. This method discards all previously registered MediaContext. If no media context is registered, default media context is used. @return media context media-type-parser-mode ParserMode (STRICT, RELAXED) STRICT Configure media type parsing mode for HTTP Content-Type header. @return media type parsing mode properties Map&lt;string, string&gt; &#160; Properties configured for this client. These properties are propagated through client request, to be used by services (and possibly for other purposes). @return map of client properties protocol-configs io.helidon.webclient.spi.ProtocolConfig[&#93; (service provider interface) &#160; Configuration of client protocols. @return client protocol configurations proxy Proxy &#160; Proxy configuration to be used for requests. @return proxy to use, defaults to Proxy#noProxy() read-continue-timeout Duration PT1S Socket 100-Continue read timeout. Default is 1 second. This read timeout is used when 100-Continue is sent by the client, before it sends an entity. @return read 100-Continue timeout duration read-timeout Duration &#160; Read timeout. @return read timeout @see io.helidon.common.socket.SocketOptions#readTimeout() relative-uris boolean false Can be set to true to force the use of relative URIs in all requests, regardless of the presence or absence of proxies or no-proxy lists. @return relative URIs flag send-expect-continue boolean true Whether Expect-100-Continue header is sent to verify server availability before sending an entity. Defaults to `true`. @return whether Expect:100-Continue header should be sent on streamed transfers services io.helidon.webclient.spi.WebClientService[&#93; (service provider interface) &#160; WebClient services. @return services to use with this web client share-connection-cache boolean true Whether to share connection cache between all the WebClient instances in JVM. @return true if connection cache is shared socket-options SocketOptions &#160; Socket options for connections opened by this client. If there is a value explicitly configured on this type and on the socket options, the one configured on this type&#8217;s builder will win: #readTimeout() #connectTimeout() @return socket options tls Tls &#160; TLS configuration for any TLS request from this client. TLS can also be configured per request. TLS is used when the protocol is set to https . @return TLS configuration to use ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_webclient_api_WebClientCookieManager",
            "text": " Type: io.helidon.webclient.api.WebClientCookieManager ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_webclient_api_WebClientCookieManager",
            "text": " Optional configuration options key type default value description automatic-store-enabled boolean false Whether automatic cookie store is enabled or not. @return status of cookie store cookie-policy CookiePolicy java.net.CookiePolicy.ACCEPT_ORIGINAL_SERVER Current cookie policy for this client. @return the cookie policy default-cookies Map&lt;string, string&gt; &#160; Map of default cookies to include in all requests if cookies enabled. @return map of default cookies ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_webclient_http1_Http1ClientProtocolConfig",
            "text": " Type: io.helidon.webclient.http1.Http1ClientProtocolConfig ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_webclient_http1_Http1ClientProtocolConfig",
            "text": " Optional configuration options key type default value description default-keep-alive boolean true Whether to use keep alive by default. @return `true` for keeping connections alive and re-using them for multiple requests (default), `false` to create a new connection for each request max-header-size int 16384 Configure the maximum allowed header size of the response. @return maximum header size max-status-line-length int 256 Configure the maximum allowed length of the status line from the response. @return maximum status line length name string http_1_1 validate-request-headers boolean false Sets whether the request header format is validated or not. Defaults to `false` as user has control on the header creation. @return whether request header validation should be enabled validate-response-headers boolean true Sets whether the response header format is validated or not. Defaults to `true`. @return whether response header validation should be enabled ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_webclient_http2_Http2ClientProtocolConfig",
            "text": " Type: io.helidon.webclient.http2.Http2ClientProtocolConfig ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_webclient_http2_Http2ClientProtocolConfig",
            "text": " Optional configuration options key type default value description flow-control-block-timeout Duration PT0.1S Timeout for blocking between windows size check iterations. @return timeout initial-window-size int 65535 Configure INITIAL_WINDOW_SIZE setting for new HTTP/2 connections. Sends to the server the size of the largest frame payload client is willing to receive. Defaults to io.helidon.http.http2.WindowSize#DEFAULT_WIN_SIZE . @return units of octets max-frame-size int 16384 Configure initial MAX_FRAME_SIZE setting for new HTTP/2 connections. Maximum size of data frames in bytes the client is prepared to accept from the server. Default value is 2^14(16_384). @return data frame size in bytes between 2^14(16_384) and 2^24-1(16_777_215) max-header-list-size long -1 Configure initial MAX_HEADER_LIST_SIZE setting for new HTTP/2 connections. Sends to the server the maximum header field section size client is prepared to accept. Defaults to -1 , which means \"unconfigured\". @return units of octets name string h2 ping boolean false Check healthiness of cached connections with HTTP/2.0 ping frame. Defaults to false . @return use ping if true ping-timeout Duration PT0.5S Timeout for ping probe used for checking healthiness of cached connections. Defaults to PT0.5S , which means 500 milliseconds. @return timeout prior-knowledge boolean false Prior knowledge of HTTP/2 capabilities of the server. If server we are connecting to does not support HTTP/2 and prior knowledge is set to false , only features supported by HTTP/1 will be available and attempts to use HTTP/2 specific will throw an UnsupportedOperationException. &lt;h4&gt;Plain text connection&lt;/h4&gt; If prior knowledge is set to true , we will not attempt an upgrade of connection and use prior knowledge. If prior knowledge is set to false , we will initiate an HTTP/1 connection and upgrade it to HTTP/2, if supported by the server. plaintext connection ( h2c ). &lt;h4&gt;TLS protected connection&lt;/h4&gt; If prior knowledge is set to true , we will negotiate protocol using HTTP/2 only, failing if not supported. if prior knowledge is set to false , we will negotiate protocol using both HTTP/2 and HTTP/1, using the protocol supported by server. @return whether to use prior knowledge of HTTP/2 ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_webclient_websocket_WsClient",
            "text": " Type: io.helidon.webclient.websocket.WsClient ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_webclient_websocket_WsClient",
            "text": " Optional configuration options key type default value description protocol-config WsClientProtocolConfig create() WebSocket specific configuration. @return protocol specific configuration ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_webclient_websocket_WsClientProtocolConfig",
            "text": " Type: io.helidon.webclient.websocket.WsClientProtocolConfig ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_webclient_websocket_WsClientProtocolConfig",
            "text": " Optional configuration options key type default value description name string websocket sub-protocols string[&#93; &#160; ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_webserver_ConnectionConfig",
            "text": " Type: io.helidon.webserver.ConnectionConfig ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_webserver_ConnectionConfig",
            "text": " Optional configuration options key type default value description connect-timeout Duration PT10S Connect timeout. Default is DEFAULT_CONNECT_TIMEOUT_DURATION . @return connect timeout keep-alive boolean true Configure socket keep alive. Default is true . @return keep alive @see java.net.StandardSocketOptions#SO_KEEPALIVE read-timeout Duration PT30S Read timeout. Default is DEFAULT_READ_TIMEOUT_DURATION @return read timeout receive-buffer-size int 32768 Socket receive buffer size. Default is DEFAULT_SO_BUFFER_SIZE . @return buffer size, in bytes @see java.net.StandardSocketOptions#SO_RCVBUF reuse-address boolean true Socket reuse address. Default is true . @return whether to reuse address @see java.net.StandardSocketOptions#SO_REUSEADDR send-buffer-size int 32768 Socket send buffer size. Default is DEFAULT_SO_BUFFER_SIZE . @return buffer size, in bytes @see java.net.StandardSocketOptions#SO_SNDBUF tcp-no-delay boolean false Disable Nagle&#8217;s algorithm by setting TCP_NODELAY to true. This can result in better performance on Mac or newer linux kernels for some payload types. Default is false . @return whether to use TCP_NODELAY, defaults to `false` @see java.net.StandardSocketOptions#TCP_NODELAY ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_webserver_ListenerConfig",
            "text": " Type: io.helidon.webserver.ListenerConfig ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_webserver_ListenerConfig",
            "text": " Optional configuration options key type default value description backlog int 1024 Accept backlog. @return backlog connection-config ConnectionConfig &#160; Configuration of a connection (established from client against our server). @return connection configuration connection-options SocketOptions &#160; Options for connections accepted by this listener. This is not used to setup server connection. @return socket options content-encoding ContentEncodingContext &#160; Configure the listener specific io.helidon.http.encoding.ContentEncodingContext. This method discards all previously registered ContentEncodingContext. If no content encoding context is registered, content encoding context of the webserver would be used. @return content encoding context host string 0.0.0.0 Host of the default socket. Defaults to all host addresses ( 0.0.0.0 ). @return host address to listen on (for the default socket) idle-connection-period Duration PT2M How often should we check for #idleConnectionTimeout(). Defaults to PT2M (2 minutes). @return period of checking for idle connections idle-connection-timeout Duration PT5M How long should we wait before closing a connection that has no traffic on it. Defaults to PT5M (5 minutes). Note that the timestamp is refreshed max. once per second, so this setting would be useless if configured for shorter periods of time (also not a very good support for connection keep alive, if the connections are killed so soon anyway). @return timeout of idle connections max-concurrent-requests int -1 Limits the number of requests that can be executed at the same time (the number of active virtual threads of requests). Defaults to -1 , meaning \"unlimited\" - what the system allows. Also make sure that this number is higher than the expected time it takes to handle a single request in your application, as otherwise you may stop in-progress requests. @return number of requests that can be processed on this listener, regardless of protocol max-in-memory-entity int 131072 If the entity is expected to be smaller that this number of bytes, it would be buffered in memory to optimize performance when writing it. If bigger, streaming will be used. Note that for some entity types we cannot use streaming, as they are already fully in memory (String, byte[]), for such cases, this option is ignored. Default is 128Kb. @return maximal number of bytes to buffer in memory for supported writers max-payload-size long -1 Maximal number of bytes an entity may have. If io.helidon.http.HeaderNames#CONTENT_LENGTH is used, this is checked immediately, if io.helidon.http.HeaderValues#TRANSFER_ENCODING_CHUNKED is used, we will fail when the number of bytes read would exceed the max payload size. Defaults to unlimited ( -1 ). @return maximal number of bytes of entity max-tcp-connections int -1 Limits the number of connections that can be opened at a single point in time. Defaults to -1 , meaning \"unlimited\" - what the system allows. @return number of TCP connections that can be opened to this listener, regardless of protocol media-context MediaContext &#160; Configure the listener specific io.helidon.http.media.MediaContext. This method discards all previously registered MediaContext. If no media context is registered, media context of the webserver would be used. @return media context name string @default Name of this socket. Defaults to @default . Must be defined if more than one socket is needed. @return name of the socket port int 0 Port of the default socket. If configured to 0 (the default), server starts on a random port. @return port to listen on (for the default socket) protocols io.helidon.webserver.spi.ProtocolConfig[&#93; (service provider interface) &#160; Configuration of protocols. This may be either protocol selectors, or protocol upgraders from HTTP/1.1. As the order is not important (providers are ordered by weight by default), we can use a configuration as an object, such as: &lt;pre&gt; protocols: providers: http_1_1: max-prologue-length: 8192 http_2: max-frame-size: 4096 websocket: &#8230;&#8203;. &lt;/pre&gt; @return all defined protocol configurations, loaded from service loader by default receive-buffer-size int &#160; Listener receive buffer size. @return buffer size in bytes shutdown-grace-period Duration PT0.5S Grace period in ISO 8601 duration format to allow running tasks to complete before listener&#8217;s shutdown. Default is 500 milliseconds. Configuration file values example: PT0.5S , PT2S . @return grace period tls Tls &#160; Listener TLS configuration. @return tls of this configuration write-buffer-size int 512 Initial buffer size in bytes of java.io.BufferedOutputStream created internally to write data to a socket connection. Default is 512 . @return initial buffer size used for writing write-queue-length int 0 Number of buffers queued for write operations. @return maximal number of queued writes, defaults to 0 ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_webserver_WebServer",
            "text": " Type: io.helidon.webserver.WebServer This is a standalone configuration type, prefix from configuration root: server ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_webserver_WebServer",
            "text": " Optional configuration options key type default value description backlog int 1024 Accept backlog. @return backlog connection-config ConnectionConfig &#160; Configuration of a connection (established from client against our server). @return connection configuration connection-options SocketOptions &#160; Options for connections accepted by this listener. This is not used to setup server connection. @return socket options content-encoding ContentEncodingContext &#160; Configure the listener specific io.helidon.http.encoding.ContentEncodingContext. This method discards all previously registered ContentEncodingContext. If no content encoding context is registered, content encoding context of the webserver would be used. @return content encoding context features io.helidon.webserver.spi.ServerFeature[&#93; (service provider interface) Such as: observe (ObserveFeature) context (ContextFeature) cors (CorsFeature) security (SecurityFeature) access-log (AccessLogFeature) &#160; Server features allow customization of the server, listeners, or routings. @return server features host string 0.0.0.0 Host of the default socket. Defaults to all host addresses ( 0.0.0.0 ). @return host address to listen on (for the default socket) idle-connection-period Duration PT2M How often should we check for #idleConnectionTimeout(). Defaults to PT2M (2 minutes). @return period of checking for idle connections idle-connection-timeout Duration PT5M How long should we wait before closing a connection that has no traffic on it. Defaults to PT5M (5 minutes). Note that the timestamp is refreshed max. once per second, so this setting would be useless if configured for shorter periods of time (also not a very good support for connection keep alive, if the connections are killed so soon anyway). @return timeout of idle connections max-concurrent-requests int -1 Limits the number of requests that can be executed at the same time (the number of active virtual threads of requests). Defaults to -1 , meaning \"unlimited\" - what the system allows. Also make sure that this number is higher than the expected time it takes to handle a single request in your application, as otherwise you may stop in-progress requests. @return number of requests that can be processed on this listener, regardless of protocol max-in-memory-entity int 131072 If the entity is expected to be smaller that this number of bytes, it would be buffered in memory to optimize performance when writing it. If bigger, streaming will be used. Note that for some entity types we cannot use streaming, as they are already fully in memory (String, byte[]), for such cases, this option is ignored. Default is 128Kb. @return maximal number of bytes to buffer in memory for supported writers max-payload-size long -1 Maximal number of bytes an entity may have. If io.helidon.http.HeaderNames#CONTENT_LENGTH is used, this is checked immediately, if io.helidon.http.HeaderValues#TRANSFER_ENCODING_CHUNKED is used, we will fail when the number of bytes read would exceed the max payload size. Defaults to unlimited ( -1 ). @return maximal number of bytes of entity max-tcp-connections int -1 Limits the number of connections that can be opened at a single point in time. Defaults to -1 , meaning \"unlimited\" - what the system allows. @return number of TCP connections that can be opened to this listener, regardless of protocol media-context MediaContext &#160; Configure the listener specific io.helidon.http.media.MediaContext. This method discards all previously registered MediaContext. If no media context is registered, media context of the webserver would be used. @return media context name string @default Name of this socket. Defaults to @default . Must be defined if more than one socket is needed. @return name of the socket port int 0 Port of the default socket. If configured to 0 (the default), server starts on a random port. @return port to listen on (for the default socket) protocols io.helidon.webserver.spi.ProtocolConfig[&#93; (service provider interface) &#160; Configuration of protocols. This may be either protocol selectors, or protocol upgraders from HTTP/1.1. As the order is not important (providers are ordered by weight by default), we can use a configuration as an object, such as: &lt;pre&gt; protocols: providers: http_1_1: max-prologue-length: 8192 http_2: max-frame-size: 4096 websocket: &#8230;&#8203;. &lt;/pre&gt; @return all defined protocol configurations, loaded from service loader by default receive-buffer-size int &#160; Listener receive buffer size. @return buffer size in bytes shutdown-grace-period Duration PT0.5S Grace period in ISO 8601 duration format to allow running tasks to complete before listener&#8217;s shutdown. Default is 500 milliseconds. Configuration file values example: PT0.5S , PT2S . @return grace period shutdown-hook boolean true When true the webserver registers a shutdown hook with the JVM Runtime. Defaults to true. Set this to false such that a shutdown hook is not registered. @return whether to register a shutdown hook sockets Map&lt;string, ListenerConfig&gt; &#160; Socket configurations. Note that socket named WebServer#DEFAULT_SOCKET_NAME cannot be used, configure the values on the server directly. @return map of listener configurations, except for the default one tls Tls &#160; Listener TLS configuration. @return tls of this configuration write-buffer-size int 512 Initial buffer size in bytes of java.io.BufferedOutputStream created internally to write data to a socket connection. Default is 512 . @return initial buffer size used for writing write-queue-length int 0 Number of buffers queued for write operations. @return maximal number of queued writes, defaults to 0 ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_webserver_accesslog_AccessLogConfig",
            "text": " Type: io.helidon.webserver.accesslog.AccessLogFeature <markup lang=\"text\" title=\"Config key\" >access-log This type provides the following service implementations: io.helidon.webserver.spi.ServerFeatureProvider ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_webserver_accesslog_AccessLogConfig",
            "text": " Optional configuration options key type default value description enabled boolean true Whether this feature will be enabled. @return whether enabled format string &#160; The format for log entries (similar to the Apache LogFormat ). &lt;table class=\"config\"&gt; &lt;caption&gt;Log format elements&lt;/caption&gt; &lt;tr&gt; &lt;td&gt;%h&lt;/td&gt; &lt;td&gt;IP address of the remote host&lt;/td&gt; &lt;td&gt;HostLogEntry&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;%l&lt;/td&gt; &lt;td&gt;The client identity. This is always undefined in Helidon.&lt;/td&gt; &lt;td&gt;UserIdLogEntry&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;%u&lt;/td&gt; &lt;td&gt;User ID as asserted by Helidon Security.&lt;/td&gt; &lt;td&gt;UserLogEntry&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;%t&lt;/td&gt; &lt;td&gt;The timestamp&lt;/td&gt; &lt;td&gt;TimestampLogEntry&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;%r&lt;/td&gt; &lt;td&gt;The request line ( \"GET /favicon.ico HTTP/1.0\" )&lt;/td&gt; &lt;td&gt;RequestLineLogEntry&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;%s&lt;/td&gt; &lt;td&gt;The status code returned to the client&lt;/td&gt; &lt;td&gt;StatusLogEntry&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;%b&lt;/td&gt; &lt;td&gt;The entity size in bytes&lt;/td&gt; &lt;td&gt;SizeLogEntry&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;%D&lt;/td&gt; &lt;td&gt;The time taken in microseconds (start of request until last byte written)&lt;/td&gt; &lt;td&gt;TimeTakenLogEntry&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;%T&lt;/td&gt; &lt;td&gt;The time taken in seconds (start of request until last byte written), integer&lt;/td&gt; &lt;td&gt;TimeTakenLogEntry&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;%{header-name}i&lt;/td&gt; &lt;td&gt;Value of header header-name &lt;/td&gt; &lt;td&gt;HeaderLogEntry&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; @return format string, such as `%h %l %u %t %r %b %{Referer`i} logger-name string io.helidon.webserver.AccessLog Name of the logger used to obtain access log logger from System#getLogger(String). Defaults to AccessLogFeature#DEFAULT_LOGGER_NAME . @return name of the logger to use sockets string[&#93; &#160; List of sockets to register this feature on. If empty, it would get registered on all sockets. The logger used will have the expected logger with a suffix of the socket name. @return socket names to register on, defaults to empty (all available sockets) weight double 1000.0 Weight of the access log feature. We need to log access for anything happening on the server, so weight is high: io.helidon.webserver.accesslog.AccessLogFeature#WEIGHT . @return weight of the feature ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_webserver_accesslog_AccessLogFeature",
            "text": " Type: io.helidon.webserver.accesslog.AccessLogFeature <markup lang=\"text\" title=\"Config key\" >access-log This type provides the following service implementations: io.helidon.webserver.spi.ServerFeatureProvider ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_webserver_accesslog_AccessLogFeature",
            "text": " Optional configuration options key type default value description enabled boolean true Whether this feature will be enabled. @return whether enabled format string &#160; The format for log entries (similar to the Apache LogFormat ). &lt;table class=\"config\"&gt; &lt;caption&gt;Log format elements&lt;/caption&gt; &lt;tr&gt; &lt;td&gt;%h&lt;/td&gt; &lt;td&gt;IP address of the remote host&lt;/td&gt; &lt;td&gt;HostLogEntry&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;%l&lt;/td&gt; &lt;td&gt;The client identity. This is always undefined in Helidon.&lt;/td&gt; &lt;td&gt;UserIdLogEntry&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;%u&lt;/td&gt; &lt;td&gt;User ID as asserted by Helidon Security.&lt;/td&gt; &lt;td&gt;UserLogEntry&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;%t&lt;/td&gt; &lt;td&gt;The timestamp&lt;/td&gt; &lt;td&gt;TimestampLogEntry&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;%r&lt;/td&gt; &lt;td&gt;The request line ( \"GET /favicon.ico HTTP/1.0\" )&lt;/td&gt; &lt;td&gt;RequestLineLogEntry&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;%s&lt;/td&gt; &lt;td&gt;The status code returned to the client&lt;/td&gt; &lt;td&gt;StatusLogEntry&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;%b&lt;/td&gt; &lt;td&gt;The entity size in bytes&lt;/td&gt; &lt;td&gt;SizeLogEntry&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;%D&lt;/td&gt; &lt;td&gt;The time taken in microseconds (start of request until last byte written)&lt;/td&gt; &lt;td&gt;TimeTakenLogEntry&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;%T&lt;/td&gt; &lt;td&gt;The time taken in seconds (start of request until last byte written), integer&lt;/td&gt; &lt;td&gt;TimeTakenLogEntry&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;%{header-name}i&lt;/td&gt; &lt;td&gt;Value of header header-name &lt;/td&gt; &lt;td&gt;HeaderLogEntry&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; @return format string, such as `%h %l %u %t %r %b %{Referer`i} logger-name string io.helidon.webserver.AccessLog Name of the logger used to obtain access log logger from System#getLogger(String). Defaults to AccessLogFeature#DEFAULT_LOGGER_NAME . @return name of the logger to use sockets string[&#93; &#160; List of sockets to register this feature on. If empty, it would get registered on all sockets. The logger used will have the expected logger with a suffix of the socket name. @return socket names to register on, defaults to empty (all available sockets) weight double 1000.0 Weight of the access log feature. We need to log access for anything happening on the server, so weight is high: io.helidon.webserver.accesslog.AccessLogFeature#WEIGHT . @return weight of the feature ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_webserver_context_ContextFeature",
            "text": " Type: io.helidon.webserver.context.ContextFeature <markup lang=\"text\" title=\"Config key\" >context This type provides the following service implementations: io.helidon.webserver.spi.ServerFeatureProvider ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_webserver_context_ContextFeature",
            "text": " Optional configuration options key type default value description sockets string[&#93; &#160; List of sockets to register this feature on. If empty, it would get registered on all sockets. @return socket names to register on, defaults to empty (all available sockets) weight double 1100.0 Weight of the context feature. As it is used by other features, the default is quite high: io.helidon.webserver.context.ContextFeature#WEIGHT . @return weight of the feature ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_webserver_cors_CorsConfig",
            "text": " Type: io.helidon.webserver.cors.CorsFeature <markup lang=\"text\" title=\"Config key\" >cors This type provides the following service implementations: io.helidon.webserver.spi.ServerFeatureProvider ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_webserver_cors_CorsConfig",
            "text": " Optional configuration options key type default value description enabled boolean true This feature can be disabled. @return whether the feature is enabled sockets string[&#93; &#160; List of sockets to register this feature on. If empty, it would get registered on all sockets. @return socket names to register on, defaults to empty (all available sockets) weight double 950.0 Weight of the CORS feature. As it is used by other features, the default is quite high: CorsFeature#WEIGHT . @return weight of the feature ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_webserver_cors_CorsFeature",
            "text": " Type: io.helidon.webserver.cors.CorsFeature <markup lang=\"text\" title=\"Config key\" >cors This type provides the following service implementations: io.helidon.webserver.spi.ServerFeatureProvider ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_webserver_cors_CorsFeature",
            "text": " Optional configuration options key type default value description enabled boolean true This feature can be disabled. @return whether the feature is enabled sockets string[&#93; &#160; List of sockets to register this feature on. If empty, it would get registered on all sockets. @return socket names to register on, defaults to empty (all available sockets) weight double 950.0 Weight of the CORS feature. As it is used by other features, the default is quite high: CorsFeature#WEIGHT . @return weight of the feature ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_webserver_grpc_GrpcConfig",
            "text": " Type: io.helidon.webserver.grpc.GrpcConfig This type provides the following service implementations: io.helidon.webserver.spi.ProtocolConfig ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_webserver_grpc_GrpcConfig",
            "text": "",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_webserver_http1_Http1Config",
            "text": " Type: io.helidon.webserver.http1.Http1Config This type provides the following service implementations: io.helidon.webserver.spi.ProtocolConfig ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_webserver_http1_Http1Config",
            "text": " Optional configuration options key type default value description continue-immediately boolean false When true WebServer answers to expect continue with 100 continue immediately, not waiting for user to actually request the data. @return if `true` answer with 100 continue immediately after expect continue max-headers-size int 16384 Maximal size of received headers in bytes. @return maximal header size max-prologue-length int 2048 Maximal size of received HTTP prologue (GET /path HTTP/1.1). @return maximal size in bytes recv-log boolean true Logging of received packets. Uses trace and debug levels on logger of Http1LoggingConnectionListener with suffix of .recv` . @return `true` if logging should be enabled for received packets, `false` if no logging should be done requested-uri-discovery RequestedUriDiscoveryContext &#160; Requested URI discovery settings. @return settings for computing the requested URI send-log boolean true Logging of sent packets. Uses trace and debug levels on logger of Http1LoggingConnectionListener with suffix of .send` . @return `true` if logging should be enabled for sent packets, `false` if no logging should be done validate-path boolean true If set to false, any path is accepted (even containing illegal characters). @return whether to validate path validate-request-headers boolean true Whether to validate headers. If set to false, any value is accepted, otherwise validates headers + known headers are validated by format (content length is always validated as it is part of protocol processing (other headers may be validated if features use them)). Defaults to `true`. @return whether to validate headers validate-response-headers boolean false Whether to validate headers. If set to false, any value is accepted, otherwise validates headers + known headers are validated by format (content length is always validated as it is part of protocol processing (other headers may be validated if features use them)). Defaults to `false` as user has control on the header creation. @return whether to validate headers ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_webserver_http2_Http2Config",
            "text": " Type: io.helidon.webserver.http2.Http2Config This type provides the following service implementations: io.helidon.webserver.spi.ProtocolConfig ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_webserver_http2_Http2Config",
            "text": " Optional configuration options key type default value description flow-control-timeout Duration PT0.1S Outbound flow control blocking timeout configured as java.time.Duration or text in ISO-8601 format. Blocking timeout defines an interval to wait for the outbound window size changes(incoming window updates) before the next blocking iteration. Default value is PT0.1S . &lt;table&gt; &lt;caption&gt;&lt;b&gt;ISO_8601 format examples:&lt;/b&gt;&lt;/caption&gt; &lt;tr&gt;&lt;th&gt;PT0.1S&lt;/th&gt;&lt;th&gt;100 milliseconds&lt;/th&gt;&lt;/tr&gt; &lt;tr&gt;&lt;th&gt;PT0.5S&lt;/th&gt;&lt;th&gt;500 milliseconds&lt;/th&gt;&lt;/tr&gt; &lt;tr&gt;&lt;th&gt;PT2S&lt;/th&gt;&lt;th&gt;2 seconds&lt;/th&gt;&lt;/tr&gt; &lt;/table&gt; @return duration @see &lt;a href=\"https://en.wikipedia.org/wiki/ISO_8601#Durations\"&gt;ISO_8601 Durations&lt;/a&gt; initial-window-size int 1048576 This setting indicates the sender&#8217;s maximum window size in bytes for stream-level flow control. Default and maximum value is 2&lt;sup&gt;31&lt;/sup&gt;-1 = 2147483647 bytes. This setting affects the window size of HTTP/2 connection. Any value greater than 2147483647 causes an error. Any value smaller than initial window size causes an error. See RFC 9113 section 6.9.1 for details. @return maximum window size in bytes max-concurrent-streams long 8192 Maximum number of concurrent streams that the server will allow. Defaults to 8192 . This limit is directional: it applies to the number of streams that the sender permits the receiver to create. It is recommended that this value be no smaller than 100 to not unnecessarily limit parallelism See RFC 9113 section 6.5.2 for details. @return maximal number of concurrent streams max-frame-size int 16384 The size of the largest frame payload that the sender is willing to receive in bytes. Default value is 16384 and maximum value is 2&lt;sup&gt;24&lt;/sup&gt;-1 = 16777215 bytes. See RFC 9113 section 6.5.2 for details. @return maximal frame size max-header-list-size long 8192 The maximum field section size that the sender is prepared to accept in bytes. See RFC 9113 section 6.5.2 for details. Default is 8192. @return maximal header list size in bytes requested-uri-discovery RequestedUriDiscoveryContext &#160; Requested URI discovery settings. @return settings for computing the requested URI send-error-details boolean false Whether to send error message over HTTP to client. Defaults to false , as exception message may contain internal information that could be used as an attack vector. Use with care and in cases where both server and clients are under your full control (such as for testing). @return whether to send error messages over the network validate-path boolean true If set to false, any path is accepted (even containing illegal characters). @return whether to validate path ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_webserver_observe_ObserveFeature",
            "text": " Type: io.helidon.webserver.observe.ObserveFeature <markup lang=\"text\" title=\"Config key\" >observe This type provides the following service implementations: io.helidon.webserver.spi.ServerFeatureProvider ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_webserver_observe_ObserveFeature",
            "text": " Optional configuration options key type default value description cors CrossOriginConfig @io.helidon.cors.CrossOriginConfig@.create() Cors support inherited by each observe provider, unless explicitly configured. @return cors support to use enabled boolean true Whether the observe support is enabled. @return `false` to disable observe feature endpoint string /observe Root endpoint to use for observe providers. By default, all observe endpoint are under this root endpoint. Example: &lt;br&gt; If root endpoint is `/observe` (the default), and default health endpoint is `health` (relative), health endpoint would be `/observe/health`. @return endpoint to use observers io.helidon.webserver.observe.spi.Observer[&#93; (service provider interface) Such as: ConfigObserver InfoObserver LogObserver TracingObserver metrics (MetricsObserver) health (HealthObserver) &#160; Observers to use with this observe features. Each observer type is registered only once, unless it uses a custom name (default name is the same as the type). @return list of observers to use in this feature sockets string[&#93; &#160; Sockets the observability endpoint should be exposed on. If not defined, defaults to the default socket ( io.helidon.webserver.WebServer#DEFAULT_SOCKET_NAME . Each observer may have its own configuration of sockets that are relevant to it, this only controls the endpoints! @return list of sockets to register observe endpoint on weight double 80.0 Change the weight of this feature. This may change the order of registration of this feature. By default, observability weight is ObserveFeature#WEIGHT so it is registered after routing. @return weight to use ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_webserver_observe_ObserverConfigBase",
            "text": " Type: io.helidon.webserver.observe.ObserverConfigBase ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_webserver_observe_ObserverConfigBase",
            "text": " Optional configuration options key type default value description enabled boolean true Whether this observer is enabled. @return `false` to disable observer ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_webserver_observe_config_ConfigObserver",
            "text": " Type: io.helidon.webserver.observe.config.ConfigObserver This type provides the following service implementations: io.helidon.webserver.observe.spi.ObserveProvider ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_webserver_observe_config_ConfigObserver",
            "text": " Optional configuration options key type default value description endpoint string config permit-all boolean &#160; Permit all access, even when not authorized. @return whether to permit access for anybody secrets string[&#93; .*password, .*passphrase, .*secret Secret patterns (regular expressions) to exclude from output. Any pattern that matches a key will cause the output to be obfuscated and not contain the value. Patterns always added: .*password .*passphrase .*secret @return set of regular expression patterns for keys, where values should be excluded from output ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_webserver_observe_health_HealthObserver",
            "text": " Type: io.helidon.webserver.observe.health.HealthObserver This is a standalone configuration type, prefix from configuration root: health This type provides the following service implementations: io.helidon.webserver.observe.spi.ObserveProvider ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_webserver_observe_health_HealthObserver",
            "text": " Optional configuration options key type default value description details boolean false Whether details should be printed. By default, health only returns a io.helidon.http.Status#NO_CONTENT_204 for success, io.helidon.http.Status#SERVICE_UNAVAILABLE_503 for health down, and io.helidon.http.Status#INTERNAL_SERVER_ERROR_500 in case of error with no entity. When details are enabled, health returns io.helidon.http.Status#OK_200 for success, same codes otherwise and a JSON entity with detailed information about each health check executed. @return set to `true` to enable details endpoint string health use-system-services boolean true Whether to use services discovered by java.util.ServiceLoader. By default, all io.helidon.health.spi.HealthCheckProvider based health checks are added. @return set to `false` to disable discovery ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_webserver_observe_info_InfoObserver",
            "text": " Type: io.helidon.webserver.observe.info.InfoObserver This type provides the following service implementations: io.helidon.webserver.observe.spi.ObserveProvider ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_webserver_observe_info_InfoObserver",
            "text": " Optional configuration options key type default value description endpoint string info values Map&lt;string, string&gt; &#160; Values to be exposed using this observability endpoint. @return value map ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_webserver_observe_log_LogObserver",
            "text": " Type: io.helidon.webserver.observe.log.LogObserver This type provides the following service implementations: io.helidon.webserver.observe.spi.ObserveProvider ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_webserver_observe_log_LogObserver",
            "text": " Optional configuration options key type default value description endpoint string log permit-all boolean &#160; Permit all access, even when not authorized. @return whether to permit access for anybody stream LogStreamConfig @io.helidon.webserver.observe.log.LogStreamConfig@.create() Configuration of log stream. @return log stream configuration ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_webserver_observe_log_LogStreamConfig",
            "text": " Type: io.helidon.webserver.observe.log.LogStreamConfig ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_webserver_observe_log_LogStreamConfig",
            "text": " Optional configuration options key type default value description content-type HttpMediaType @io.helidon.http.HttpMediaTypes@.PLAINTEXT_UTF_8 enabled boolean true Whether stream is enabled. @return whether to allow streaming of log statements idle-message-timeout Duration PT5S How long to wait before we send the idle message, to make sure we keep the stream alive. @return if no messages appear within this duration, and idle message will be sent @see #idleString() idle-string string `% ` String sent when there are no log messages within the #idleMessageTimeout(). @return string to write over the network when no log messages are received queue-size int 100 Length of the in-memory queue that buffers log messages from loggers before sending them over the network. If the messages are produced faster than we can send them to client, excess messages are DISCARDED, and will not be sent. @return size of the in-memory queue for log messages ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_webserver_observe_metrics_MetricsObserver",
            "text": " Type: io.helidon.webserver.observe.metrics.MetricsObserver This is a standalone configuration type, prefix from configuration root: metrics This type provides the following service implementations: io.helidon.webserver.observe.spi.ObserveProvider ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_webserver_observe_metrics_MetricsObserver",
            "text": " Optional configuration options key type default value description app-name string &#160; Value for the application tag to be added to each meter ID. @return application tag value app-tag-name string &#160; Name for the application tag to be added to each meter ID. @return application tag name enabled boolean true Whether metrics functionality is enabled. @return if metrics are configured to be enabled endpoint string metrics key-performance-indicators KeyPerformanceIndicatorMetricsConfig &#160; Key performance indicator metrics settings. @return key performance indicator metrics settings permit-all boolean &#160; Whether to allow anybody to access the endpoint. @return whether to permit access to metrics endpoint to anybody, defaults to `true` @see #roles() rest-request-enabled boolean &#160; Whether automatic REST request metrics should be measured. @return true/false roles string[&#93; &#160; Hints for role names the user is expected to be in. @return list of hints scoping ScopingConfig &#160; Settings related to scoping management. @return scoping settings tags Tag[&#93; &#160; Global tags. @return name/value pairs for global tags ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_webserver_observe_tracing_TracingObserver",
            "text": " Type: io.helidon.webserver.observe.tracing.TracingObserver This type provides the following service implementations: io.helidon.webserver.observe.spi.ObserveProvider ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_webserver_observe_tracing_TracingObserver",
            "text": " Optional configuration options key type default value description env-config TracingConfig TracingConfig.ENABLED Use the provided configuration as a default for any request. @return default web server tracing configuration path-configs PathTracingConfig[&#93; new @java.util.ArrayList@(@java.util.List@.of(PathTracingConfig.builder() .path(&quot;/metrics/ &quot;) .tracingConfig(TracingConfig.DISABLED) .build(), PathTracingConfig.builder() .path(&quot;/health/ &quot;) .tracingConfig(TracingConfig.DISABLED) .build(), PathTracingConfig.builder() .path(&quot;/openapi/*&quot;) .tracingConfig(TracingConfig.DISABLED) .build())) Path specific configuration of tracing. @return configuration of tracing for specific paths weight double 900.0 Weight of the feature registered with WebServer. Changing weight may cause tracing to be executed at a different time (such as after security, or even after all routes). Please understand feature weights before changing this order. @return weight of tracing feature ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_webserver_security_PathsConfig",
            "text": " Type: io.helidon.webserver.security.PathsConfig ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_webserver_security_PathsConfig",
            "text": " Optional configuration options key type default value description audit boolean &#160; Whether to audit this request - defaults to false, if enabled, request is audited with event type \"request\". @return whether to audit audit-event-type string &#160; Override for event-type, defaults to SecurityHandler#DEFAULT_AUDIT_EVENT_TYPE . @return audit event type to use audit-message-format string &#160; Override for audit message format, defaults to SecurityHandler#DEFAULT_AUDIT_MESSAGE_FORMAT . @return audit message format to use authenticate boolean &#160; If called, request will go through authentication process - defaults to false (even if authorize is true). @return whether to authenticate or not authentication-optional boolean &#160; If called, authentication failure will not abort request and will continue as anonymous (defaults to false). @return whether authn is optional authenticator string &#160; Use a named authenticator (as supported by security - if not defined, default authenticator is used). Will enable authentication. @return name of authenticator as configured in io.helidon.security.Security authorize boolean &#160; Enable authorization for this route. @return whether to authorize authorizer string &#160; Use a named authorizer (as supported by security - if not defined, default authorizer is used, if none defined, all is permitted). Will enable authorization. @return name of authorizer as configured in io.helidon.security.Security methods Method[&#93; &#160; path string &#160; roles-allowed string[&#93; &#160; An array of allowed roles for this path - must have a security provider supporting roles (either authentication or authorization provider). This method enables authentication and authorization (you can disable them again by calling SecurityHandler#skipAuthorization() and #authenticationOptional() if needed). @return if subject is any of these roles, allow access sockets string[&#93; @default sockets string[&#93; &#160; List of sockets this configuration should be applied to. If empty, the configuration is applied to all configured sockets. @return list of sockets ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_webserver_security_SecurityFeature",
            "text": " Type: io.helidon.webserver.security.SecurityFeature <markup lang=\"text\" title=\"Config key\" >security This type provides the following service implementations: io.helidon.webserver.spi.ServerFeatureProvider ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_webserver_security_SecurityFeature",
            "text": " Optional configuration options key type default value description defaults SecurityHandler SecurityHandler.create() The default security handler. @return security handler defaults paths PathsConfig[&#93; &#160; Configuration for webserver paths. @return path configuration security Security &#160; Security associated with this feature. If not specified here, the feature uses security registered with io.helidon.common.context.Contexts#globalContext(), if not found, it creates a new instance from root of configuration (using security key). This configuration allows usage of a different security instance for a specific security feature setup. @return security instance to be used to handle security in this feature configuration weight double 800.0 Weight of the security feature. Value is: io.helidon.webserver.security.SecurityFeature#WEIGHT . @return weight of the feature ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_webserver_security_SecurityHandler",
            "text": " Type: io.helidon.webserver.security.SecurityHandler ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_webserver_security_SecurityHandler",
            "text": " Optional configuration options key type default value description audit boolean &#160; Whether to audit this request - defaults to false, if enabled, request is audited with event type \"request\". @return whether to audit audit-event-type string &#160; Override for event-type, defaults to SecurityHandler#DEFAULT_AUDIT_EVENT_TYPE . @return audit event type to use audit-message-format string &#160; Override for audit message format, defaults to SecurityHandler#DEFAULT_AUDIT_MESSAGE_FORMAT . @return audit message format to use authenticate boolean &#160; If called, request will go through authentication process - defaults to false (even if authorize is true). @return whether to authenticate or not authentication-optional boolean &#160; If called, authentication failure will not abort request and will continue as anonymous (defaults to false). @return whether authn is optional authenticator string &#160; Use a named authenticator (as supported by security - if not defined, default authenticator is used). Will enable authentication. @return name of authenticator as configured in io.helidon.security.Security authorize boolean &#160; Enable authorization for this route. @return whether to authorize authorizer string &#160; Use a named authorizer (as supported by security - if not defined, default authorizer is used, if none defined, all is permitted). Will enable authorization. @return name of authorizer as configured in io.helidon.security.Security roles-allowed string[&#93; &#160; An array of allowed roles for this path - must have a security provider supporting roles (either authentication or authorization provider). This method enables authentication and authorization (you can disable them again by calling SecurityHandler#skipAuthorization() and #authenticationOptional() if needed). @return if subject is any of these roles, allow access sockets string[&#93; &#160; List of sockets this configuration should be applied to. If empty, the configuration is applied to all configured sockets. @return list of sockets ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_webserver_servicecommon_HelidonFeatureSupport_Builder",
            "text": " Type: io.helidon.webserver.servicecommon.HelidonFeatureSupport.Builder ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_webserver_servicecommon_HelidonFeatureSupport_Builder",
            "text": " Optional configuration options key type default value description cross-origin-config CrossOriginConfig &#160; Set the CORS config from the specified CrossOriginConfig object. web-context string &#160; Set the root context for the REST API of the service. ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_webserver_servicecommon_RestServiceSettings",
            "text": " Type: io.helidon.webserver.servicecommon.RestServiceSettings ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_webserver_servicecommon_RestServiceSettings",
            "text": " Optional configuration options key type default value description cors Map&lt;string, CrossOriginConfig&gt; &#160; Sets the cross-origin config builder for use in establishing CORS support for the service endpoints. enabled boolean true Is this service enabled or not. routing string &#160; Sets the routing name to use for setting up the service&#8217;s endpoint. web-context string &#160; Sets the web context to use for the service&#8217;s endpoint. ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_helidon_webserver_websocket_WsConfig",
            "text": " Type: io.helidon.webserver.websocket.WsConfig This type provides the following service implementations: io.helidon.webserver.spi.ProtocolConfig ",
            "title": "preambule"
        },
        {
            "location": "/config/io_helidon_webserver_websocket_WsConfig",
            "text": " Optional configuration options key type default value description name string websocket Name of this configuration. @return configuration name origins string[&#93; &#160; WebSocket origins. @return origins ",
            "title": "Configuration options"
        },
        {
            "location": "/config/io_opentracing_Tracer",
            "text": " Zipkin tracer configuration Type: io.opentracing.Tracer This is a standalone configuration type, prefix from configuration root: tracing ",
            "title": "preambule"
        },
        {
            "location": "/config/io_opentracing_Tracer",
            "text": " Optional configuration options key type default value description api-version Version (V1, V2) V2 Version of Zipkin API to use. Defaults to Version#V2. ",
            "title": "Configuration options"
        },
        {
            "location": "/config/org_eclipse_microprofile_config_Config",
            "text": " Type: org.eclipse.microprofile.config.Config This is a standalone configuration type, prefix from configuration root: mp.config ",
            "title": "preambule"
        },
        {
            "location": "/config/org_eclipse_microprofile_config_Config",
            "text": " Optional configuration options key type default value description profile string &#160; Configure an explicit profile name. ",
            "title": "Configuration options"
        },
        {
            "location": "/guides/jib",
            "text": " This guide describes how to build container images for Helidon applications using Jib and Maven. ",
            "title": "preambule"
        },
        {
            "location": "/guides/jib",
            "text": " About 10 minutes Helidon Prerequisites ",
            "title": "What You Need"
        },
        {
            "location": "/guides/jib",
            "text": " Jib is a java tool chain for building Docker images for Java applications. It is integrated with Maven and Gradle and uses a distro-less base image to produce small images. Jib does not require the docker command or the Docker daemon, there is no need to solve the Docker-in-Docker problem in order to build Docker images as part of your continuous integration. The docker command is only required for local usage when registering images in your local Docker registry. The example below shows how to build an image and register it in the local registry using the jib-maven-plugin . Add the following plugin declaration to your pom.xml: <markup lang=\"xml\" >&lt;plugin&gt; &lt;groupId&gt;com.google.cloud.tools&lt;/groupId&gt; &lt;artifactId&gt;jib-maven-plugin&lt;/artifactId&gt; &lt;version&gt;0.10.1&lt;/version&gt; &lt;configuration&gt; &lt;to&gt; &lt;image&gt;jib-${project.artifactId}&lt;/image&gt; &lt;tags&gt; &lt;tag&gt;${project.version}&lt;/tag&gt; &lt;tag&gt;latest&lt;/tag&gt; &lt;/tags&gt; &lt;/to&gt; &lt;container&gt; &lt;!-- good defaults intended for containers --&gt; &lt;jvmFlags&gt; &lt;jmxFlag&gt;-server&lt;/jmxFlag&gt; &lt;jmxFlag&gt;-Djava.awt.headless=true&lt;/jmxFlag&gt; &lt;jmxFlag&gt;-XX:+UnlockExperimentalVMOptions&lt;/jmxFlag&gt; &lt;jmxFlag&gt;-XX:+UseCGroupMemoryLimitForHeap&lt;/jmxFlag&gt; &lt;jmxFlag&gt;-XX:InitialRAMFraction=2&lt;/jmxFlag&gt; &lt;jmxFlag&gt;-XX:MinRAMFraction=2&lt;/jmxFlag&gt; &lt;jmxFlag&gt;-XX:MaxRAMFraction=2&lt;/jmxFlag&gt; &lt;jmxFlag&gt;-XX:+UseG1GC&lt;/jmxFlag&gt; &lt;/jvmFlags&gt; &lt;mainClass&gt;${mainClass}&lt;/mainClass&gt; &lt;ports&gt; &lt;port&gt;8080&lt;/port&gt; &lt;/ports&gt; &lt;/container&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;dockerBuild&lt;/goal&gt; &lt;/goals&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; By default, Jib uses distroless/java as the base image. You can override the default with configuration see the documentation <markup lang=\"bash\" title=\"Package the updated application\" >mvn package <markup lang=\"bash\" title=\"Run the image\" >docker run --rm -p 8080:8080 jib-helidon-quickstart-se <markup lang=\"bash\" title=\"Ping the application\" >curl -X GET http://localhost:8080/greet <markup lang=\"bash\" title=\"Take a look at the image size\" >docker images jib-quickstart-se:latest <markup lang=\"bash\" >REPOSITORY TAG IMAGE ID CREATED SIZE jib-quickstart-se latest 384aebda5594 48 years ago 124MB Ignore the fact that it says the image was created 48 years ago. Refer to the Jib FAQ for explanations. the Jib image is smaller because of the use of a distroless base image. ",
            "title": "Creating a Docker Image Using Jib"
        },
        {
            "location": "/guides/oke",
            "text": " Push a Docker image of your Helidon application to Oracle Cloud Infrastructure Registry (OCIR), and deploy the image from the registry to Oracle Cloud Infrastructure Container Engine for Kubernetes (OKE). ",
            "title": "preambule"
        },
        {
            "location": "/guides/oke",
            "text": " About 10 minutes Helidon prerequisites An OKE cluster. See the OKE documentation . A Helidon project created from the quickstart Maven archetype. See quickstart Maven archetype . ",
            "title": "What You Need"
        },
        {
            "location": "/guides/oke",
            "text": " Your account must be in the Administrators group or another group that has the REPOSITORY_CREATE permission. Sign in to the Oracle Cloud Infrastructure (OCI) web console and generate an authentication token. See Getting an Auth Token . Remember to copy the generated token. You won&#8217;t be able to access it again. <markup lang=\"bash\" title=\"Log in to the OCIR Docker registry:\" >docker login \\ -u &lt;username&gt; \\ -p &lt;password&gt; \\ &lt;region-code&gt;.ocir.io The user name in the format &lt;tenancy_name&gt;/&lt;username&gt; . The password is the generated token. &lt;region-code&gt; is the code for the OCI region that you&#8217;re using. For example, the region code for Phoenix is phx . See Regions and Availability Domains . <markup lang=\"bash\" title=\"Tag the image that you want to push to the registry:\" >docker tag \\ helidon-quickstart-se:latest \\ &lt;region-code&gt;.ocir.io/&lt;tenancy-name&gt;/&lt;repo-name&gt;/&lt;image-name&gt;:&lt;tag&gt; the local image to tag &lt;repo-name&gt; is optional. It is the name of a repository to which you want to push the image (for example, project01 ). <markup lang=\"bash\" title=\"Push the image to the Registry:\" >docker push \\ &lt;region-code&gt;.ocir.io/&lt;tenancy-name&gt;/&lt;repo-name&gt;/&lt;image-name&gt;:&lt;tag&gt; You can pull your image with the image path used above, for example: phx.ocir.io/helidon/example/helidon-quickstart-se:latest ",
            "title": "Push Your Image to OCIR"
        },
        {
            "location": "/guides/oke",
            "text": " First, change to the helidon-quickstart-se directory. Then edit app.yaml and add the following under spec in the deployment section: <markup lang=\"yaml\" >spec: imagePullSecrets: - name: ocirsecret containers: - name: helidon-quickstart-se image: phx.ocir.io/helidon/example/helidon-quickstart-se:latest imagePullPolicy: Always ports: - containerPort: 8080 The config secret name The image path <markup lang=\"bash\" title=\"Deploy the application:\" >kubectl create -f app.yaml -n helidon <markup lang=\"bash\" title=\"Get the NodePort number for your new pod:\" >kubectl get svc -n helidon <markup lang=\"bash\" title=\"Get the IP address for your cluster nodes:\" >kubectl get nodes You can now access the application at http://&lt;NodeIpAddress&gt;:&lt;NodePort&gt;/greet . ",
            "title": "Deploy the Image to Kubernetes"
        },
        {
            "location": "/guides/oke",
            "text": " Create a namespace (for example, helidon ) for the project: <markup lang=\"bash\" >kubectl create namespace helidon The repository that you created is private. To allow Kubernetes to authenticate with the container registry and pull the private image, you must create and use an image-pull secret. <markup lang=\"bash\" title=\"Create an image-pull secret:\" >kubectl create secret docker-registry \\ ocirsecret \\ --docker-server=&lt;region-code&gt;.ocir.io \\ --docker-username='&lt;tenancy-name&gt;/&lt;oci-username&gt;' \\ --docker-password='&lt;oci-auth-token&gt;' \\ --docker-email='&lt;email-address&gt;' \\ --namespace helidon The name of the config secret The docker registry (see docker tag step above) The user name (see docker login step above) The password (see docker login step above) The namespace created in the previous step Deploy the Image to Kubernetes First, change to the helidon-quickstart-se directory. Then edit app.yaml and add the following under spec in the deployment section: <markup lang=\"yaml\" >spec: imagePullSecrets: - name: ocirsecret containers: - name: helidon-quickstart-se image: phx.ocir.io/helidon/example/helidon-quickstart-se:latest imagePullPolicy: Always ports: - containerPort: 8080 The config secret name The image path <markup lang=\"bash\" title=\"Deploy the application:\" >kubectl create -f app.yaml -n helidon <markup lang=\"bash\" title=\"Get the NodePort number for your new pod:\" >kubectl get svc -n helidon <markup lang=\"bash\" title=\"Get the IP address for your cluster nodes:\" >kubectl get nodes You can now access the application at http://&lt;NodeIpAddress&gt;:&lt;NodePort&gt;/greet . ",
            "title": "Setup your K8s Cluster"
        },
        {
            "location": "/mp/beanvalidation",
            "text": " Overview Maven Coordinates API Configuration Examples Additional Information Reference ",
            "title": "Contents"
        },
        {
            "location": "/mp/beanvalidation",
            "text": " Helidon supports Bean Validation via its integration with JAX-RS/Jersey. The Jakarta Bean Validation specification defines an API to validate Java beans. Bean Validation is supported in REST resource classes as well as in regular application beans. If bean validation is required outside JAX-RS/Jersey use cases, it is also available in Helidon. It follows the standard Jakarta Bean Validation specification which defines an API to validate Java beans. ",
            "title": "Overview"
        },
        {
            "location": "/mp/beanvalidation",
            "text": " To enable Bean Validation add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;org.glassfish.jersey.ext&lt;/groupId&gt; &lt;artifactId&gt;jersey-bean-validation&lt;/artifactId&gt; &lt;/dependency&gt; For general validation, please add to your pom.xml : <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.bean-validation&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-bean-validation&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/beanvalidation",
            "text": " The specification defines a small set of built-in constraints. Their usage is encouraged both in regular constraint declarations and as composing constraints. Using this set of constraints will enhance portability of your constraints across constraint-consuming frameworks relying on the metadata API (such as client side validation frameworks or database schema generation frameworks). Built-in annotations are annotated with an empty @Constraint annotation to avoid any dependency between the specification API and a specific implementation. Each Jakarta Bean Validation provider must recognize built-in constraint annotations as valid constraint definitions and provide compliant constraint implementations for each. The built-in constraint validation implementation is having a lower priority than an XML mapping definition. In other words ConstraintValidator implementations for built-in constraints can be overridden by using the XML mapping (see Overriding constraint definitions in XML). All built-in constraints are in the jakarta.validation.constraints package. Here is the list of constraints and their declaration. <div class=\"table__overflow elevation-1 flex sm10 \"> Annotation Description @Null The annotated element must be null . Accepts any type. @NotNull The annotated element must not be null . Accepts any type. @AssertTrue The annotated element must be true. Supported types are boolean and Boolean . Null elements are considered valid. @AssertFalse The annotated element must be false. Supported types are boolean and Boolean . Null elements are considered valid. @Min The annotated element must be a number whose value must be higher or equal to the specified minimum. Supported types are: BigDecimal BigInteger byte , short , int , long , and their respective wrappers Note that double and float are not supported due to rounding errors (some providers might provide some approximative support). Null elements are considered valid. @Max The annotated element must be a number whose value must be higher or equal to the specified minimum. Supported types are: BigDecimal BigInteger byte , short , int , long , and their respective wrappers Note that double and float are not supported due to rounding errors (some providers might provide some approximative support). Null elements are considered valid. @DecimalMin The annotated element must be a number whose value must be lower or equal to the specified maximum. Supported types are: BigDecimal BigInteger byte , short , int , long , and their respective wrappers Note that double and float are not supported due to rounding errors (some providers might provide some approximative support). Null elements are considered valid. @DecimalMax The annotated element must be a number whose value must be lower or equal to the specified maximum. Supported types are: BigDecimal BigInteger byte , short , int , long , and their respective wrappers Note that double and float are not supported due to rounding errors (some providers might provide some approximative support). Null elements are considered valid. @Negative The annotated element must be a strictly negative number (i.e. 0 is considered as an invalid value). Supported types are: BigDecimal BigInteger byte , short , int , long , and their respective wrappers Null elements are considered valid. @NegativeOrZero The annotated element must be a negative number or 0. Supported types are: BigDecimal BigInteger byte , short , int , long , float , or double and their respective wrappers Null elements are considered valid. @Positive The annotated element must be a strictly positive number (i.e. 0 is considered as an invalid value). Supported types are: BigDecimal BigInteger byte , short , int , long , float , or double and their respective wrappers Null elements are considered valid. @PositiveOrZero The annotated element must be a positive number or 0. Supported types are: BigDecimal BigInteger byte , short , int , long , float , or double and their respective wrappers Null elements are considered valid. @Size The annotated element size must be between the specified boundaries (included). Supported types are: * CharSequence - length of character sequence is evaluated * Collection - collection size is evaluated * Map - map size is evaluated * Array (array length is evaluated) Null elements are considered valid. @Digits The annotated element must be a number within accepted range. Supported types are: BigDecimal BigInteger CharSequence byte , short , int , long , and their respective wrapper types Null elements are considered valid. @Past The annotated element must be an instant, date or time in the past or in the present. Now is defined by the ClockProvider attached to the Validator or ValidatorFactory . The default clockProvider defines the current time according to the virtual machine, applying the current default time zone if needed. Supported types are: java.util.Date java.util.Calendar java.time.Instant java.time.LocalDate java.time.LocalDateTime java.time.LocalTime java.time.MonthDay java.time.OffsetDateTime java.time.OffsetTime java.time.Year java.time.YearMonth java.time.ZonedDateTime java.time.chrono.HijrahDate java.time.chrono.JapaneseDate java.time.chrono.MinguoDate java.time.chrono.ThaiBuddhistDate Null elements are considered valid. @PastOrPresent The annotated element must be an instant, date or time in the past or in the present. Now is defined by the ClockProvider attached to the Validator or ValidatorFactory . The default clockProvider defines the current time according to the virtual machine, applying the current default time zone if needed. Supported types are: java.util.Date java.util.Calendar java.time.Instant java.time.LocalDate java.time.LocalDateTime java.time.LocalTime java.time.MonthDay java.time.OffsetDateTime java.time.OffsetTime java.time.Year java.time.YearMonth java.time.ZonedDateTime java.time.chrono.HijrahDate java.time.chrono.JapaneseDate java.time.chrono.MinguoDate java.time.chrono.ThaiBuddhistDate Null elements are considered valid. @PastOrPresent The annotated element must be an instant, date or time in the future. Now is defined by the ClockProvider attached to the Validator or ValidatorFactory . The default clockProvider defines the current time according to the virtual machine, applying the current default time zone if needed. Supported types are: java.util.Date java.util.Calendar java.time.Instant java.time.LocalDate java.time.LocalDateTime java.time.LocalTime java.time.MonthDay java.time.OffsetDateTime java.time.OffsetTime java.time.Year java.time.YearMonth java.time.ZonedDateTime java.time.chrono.HijrahDate java.time.chrono.JapaneseDate java.time.chrono.MinguoDate java.time.chrono.ThaiBuddhistDate Null elements are considered valid. @FutureOrPresent The annotated element must be an instant, date or time in the present or in the future. Now is defined by the ClockProvider attached to the Validator or ValidatorFactory . The default clockProvider defines the current time according to the virtual machine, applying the current default time zone if needed. Supported types are: java.util.Date java.util.Calendar java.time.Instant java.time.LocalDate java.time.LocalDateTime java.time.LocalTime java.time.MonthDay java.time.OffsetDateTime java.time.OffsetTime java.time.Year java.time.YearMonth java.time.ZonedDateTime java.time.chrono.HijrahDate java.time.chrono.JapaneseDate java.time.chrono.MinguoDate java.time.chrono.ThaiBuddhistDate Null elements are considered valid. @FutureOrPresent The annotated CharSequence must match the specified regular expression. The regular expression follows the Java regular expression conventions see java.util.regex.Pattern . Accepts CharSequence . Null elements are considered valid. @NotEmpty The annotated element must not be null nor empty. Supported types are: * CharSequence - length of character sequence is evaluated * Collection - collection size is evaluated * Map - map size is evaluated * Array (array length is evaluated) @NotBlank The annotated element must not be null and must contain at least one non-whitespace character. Accepts CharSequence . @Email The string has to be a well-formed email address. Exact semantics of what makes up a valid email address are left to Jakarta Bean Validation providers. Accepts CharSequence . Null elements are considered valid. ",
            "title": "API"
        },
        {
            "location": "/mp/beanvalidation",
            "text": " Bean Validation can be configured using META-INF/validation.xml . For more information about configuring the validator factory in validation.xml, see Hibernate Validator Documentation . ",
            "title": "Configuration"
        },
        {
            "location": "/mp/beanvalidation",
            "text": " The following example shows a simple resource method annotated with @POST whose parameter must be not null and valid . Validating a parameter in this case implies making sure that any constraint annotations in the Greeting class are satisfied. The resource method shall never be called if the validation fails, with a 400 (Bad Request) status code returned instead. <markup lang=\"java\" >@Path(\"helloworld\") public class HelloWorld { @POST @Consumes(MediaType.APPLICATION_JSON) public void post(@NotNull @Valid Greeting greeting) { // ... } } The following example shows a simple application with one field declared as not null using @NotNull annotation: <markup lang=\"java\" >public class GreetingHolder { @NotNull private String greeting; //... } If the bean contains a method parameter annotated with @Valid, and GreetingHolder with null_greeting is passed, then a _ValidationException will be thrown: <markup lang=\"java\" >@ApplicationScoped public class GreetingProvider { private GreetingHolder greetingHolder; //.. void setGreeting(@Valid GreetingHolder greetingHolder) { this.greetingHolder = greetingHolder; } } beans.xml is required to identify beans and for bean validation to work properly. Examples are available in our official GitHub repository . ",
            "title": "Examples"
        },
        {
            "location": "/mp/beanvalidation",
            "text": " Helidon uses Hibernate Bean Validator for general bean validation. ",
            "title": "Additional Information"
        },
        {
            "location": "/mp/beanvalidation",
            "text": " Bean Validation Specification ",
            "title": "Reference"
        },
        {
            "location": "/mp/config/advanced-configuration",
            "text": " Creating MicroProfile Config Sources for Manual Setup of Config Creating Custom Config Sources Creating MicroProfile Config Sources from meta-config Extending Meta-Config to Create a Custom Config Source Type Creating MicroProfile Config Source from Helidon SE Config Source Creating MicroProfile Config Source from Helidon SE Config Instance ",
            "title": "Contents"
        },
        {
            "location": "/mp/config/advanced-configuration",
            "text": " You can create Microprofile Config Source from a map. <markup lang=\"java\" title=\"Create MicroProfile Config Source based on Environment Variables and Custom Map\" >ConfigProviderResolver resolver = ConfigProviderResolver.instance(); org.eclipse.microprofile.config.Config config = resolver.getBuilder() .withSources(MpConfigSources.environmentVariables()) .withSources(MpConfigSources.create(Map.of(\"key\",\"value\"))) .build(); resolver.registerConfig(config, null); Creates MicroProfile Config Source builder. Adds environment variables. Adds a custom map. Builds the MicroProfile Config Source. Registers the config, so it can be used by other components ",
            "title": "Create Custom Map MicroProfile Config Source"
        },
        {
            "location": "/mp/config/advanced-configuration",
            "text": " You can create YAML Microprofile Config Source from a path or a URL. When you create a MicroProfile instance from the builder, the YamlMpConfigSource allows you to create a custom Config Source and register it with the builder. <markup lang=\"java\" title=\"Create YamlMPConfigSource from a path\" >ConfigProviderResolver.instance().newBuilder() .withSources(YamlMpConfigSource.create(path)) .build(); ",
            "title": "Create YAML MicroProfile Config Source"
        },
        {
            "location": "/mp/config/advanced-configuration",
            "text": " You can use the following methods to create MicroProfile Config Sources to manually set up the Config from org.eclipse.microprofile.config.spi.ConfigProviderResolver#getBuilder() on io.helidon.config.mp.MpConfigSources class: Method Description systemProperties() System properties config source. environmentVariables() Environment variables config source. create(java.nio.file.Path) Loads a properties file from file system. To load the properties file from file system with custom name, use create(String, java.nio.file.Path) . create(java.util.Map) Creates an in-memory source from map. To create an in-memory source from map with custom name, use create(String, java.util.Map) . create(java.util.Properties) Creates an in-memory source from properties. To create an in-memory source from properties with custom name, use create(String, java.util.Properties) . Create Custom Map MicroProfile Config Source You can create Microprofile Config Source from a map. <markup lang=\"java\" title=\"Create MicroProfile Config Source based on Environment Variables and Custom Map\" >ConfigProviderResolver resolver = ConfigProviderResolver.instance(); org.eclipse.microprofile.config.Config config = resolver.getBuilder() .withSources(MpConfigSources.environmentVariables()) .withSources(MpConfigSources.create(Map.of(\"key\",\"value\"))) .build(); resolver.registerConfig(config, null); Creates MicroProfile Config Source builder. Adds environment variables. Adds a custom map. Builds the MicroProfile Config Source. Registers the config, so it can be used by other components Create YAML MicroProfile Config Source You can create YAML Microprofile Config Source from a path or a URL. When you create a MicroProfile instance from the builder, the YamlMpConfigSource allows you to create a custom Config Source and register it with the builder. <markup lang=\"java\" title=\"Create YamlMPConfigSource from a path\" >ConfigProviderResolver.instance().newBuilder() .withSources(YamlMpConfigSource.create(path)) .build(); ",
            "title": "Creating MicroProfile Config Sources for Manual Setup of Config"
        },
        {
            "location": "/mp/config/advanced-configuration",
            "text": "<markup lang=\"java\" >public class CustomConfigSource implements ConfigSource { private static final String NAME = \"MyConfigSource\"; private static final int ORDINAL = 200; // Default for MP is 100 private static final Map&lt;String, String&gt; PROPERTIES = mapOf(\"app.greeting\", \"Hi\"); @Override public String getName() { return NAME; } @Override public Map&lt;String, String&gt; getProperties() { return PROPERTIES; } @Override public String getValue(String key) { return PROPERTIES.get(key); } @Override public int getOrdinal() { return ORDINAL; } } Returns the name of the Config Source to use for logging or analysis of configured values. Returns the properties in this Config Source as a map. Returns the value of the requested key, or null if the key is not available Returns the ordinal of this Config Source. ",
            "title": "Example of a Custom Config Source"
        },
        {
            "location": "/mp/config/advanced-configuration",
            "text": " Custom Config Sources are loaded using the Java Service Loader pattern, by implementing either org.eclipse.microprofile.config.spi.ConfigSource , or org.eclipse.microprofile.config.spi.ConfigSourceProvider SPI and registering it as a service (Using META-INF/services/${class-name} file when using classpath, or using the provides statement in module-info.java when using module path). The interface org.eclipse.microprofile.config.spi.ConfigSource requires implementation of the following methods: String getName() Map&lt;String, String&gt; getProperties() String getValue(String key) getOrdinal() Example of a Custom Config Source <markup lang=\"java\" >public class CustomConfigSource implements ConfigSource { private static final String NAME = \"MyConfigSource\"; private static final int ORDINAL = 200; // Default for MP is 100 private static final Map&lt;String, String&gt; PROPERTIES = mapOf(\"app.greeting\", \"Hi\"); @Override public String getName() { return NAME; } @Override public Map&lt;String, String&gt; getProperties() { return PROPERTIES; } @Override public String getValue(String key) { return PROPERTIES.get(key); } @Override public int getOrdinal() { return ORDINAL; } } Returns the name of the Config Source to use for logging or analysis of configured values. Returns the properties in this Config Source as a map. Returns the value of the requested key, or null if the key is not available Returns the ordinal of this Config Source. ",
            "title": "Creating Custom Config Sources"
        },
        {
            "location": "/mp/config/advanced-configuration",
            "text": " Instead of directly specifying the configuration sources in your code, you can use meta-configuration in a file that declares the configuration sources, and their attributes as mentioned in Microprofile Config . When used, the Microprofile Config uses configuration sources and flags configured in the meta configuration file. If a file named mp-meta-config.yaml , or mp-meta-config.properties is in the current directory or on the classpath, and there is no explicit setup of configuration in the code, the configuration will be loaded from the meta-config file. The location of the file can be overridden using system property io.helidon.config.mp.meta-config , or environment variable HELIDON_MP_META_CONFIG <markup lang=\"yaml\" title=\"Example of a YAML meta configuration file:\" >add-discovered-sources: true add-discovered-converters: false add-default-sources: false sources: - type: \"environment-variables\" - type: \"system-properties\" - type: \"properties\" path: \"/conf/prod.properties\" ordinal: 50 optional: true - type: \"yaml\" classpath: \"META-INF/database.yaml\" - type: \"hocon\" classpath: \"custom-application.conf\" - type: \"json\" path: \"path: conf/custom-application.json\" If configured to true , config sources discovered through service loader will be added If configured to true , converters discovered through service loader will be added If configured to true , default config sources (system properties, environment variables, and `META-INF/microprofile-config.properties) will be added Loads the environment variables config source. Loads the system properties config source. Loads a properties file Location of the file: /conf/prod.properties on the file system Custom ordinal, if not defined, the value defined in the file, or default value is used. The source precedence order is the order of appearance in the file. The file is optional (if not optional and no file is found, the bootstrap fails) Loads a YAML file Location of the file: META-INF/database.yaml on the classpath Loads a HOCON file Location of the file: custom-application.conf on the classpath Loads a JSON file Location of the file: conf/custom-application.json relative to the directory of where the app was executed on the file system. Important Note: To enable support for HOCON and JSON types, add the following dependency to your project’s pom.xml. <markup lang=\"xml\" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.config&lt;/groupId&gt; &lt;artifactId&gt;helidon-config-hocon-mp&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Creating MicroProfile Config Sources from meta-config"
        },
        {
            "location": "/mp/config/advanced-configuration",
            "text": "<markup lang=\"java\" >public class CustomMpMetaConfigProvider implements MpMetaConfigProvider { @Override public Set&lt;String&gt; supportedTypes() { return Set.of(\"custom\"); } @Override public List&lt;? extends ConfigSource&gt; create(String type, Config metaConfig, String profile) { ConfigValue&lt;Path&gt; pathConfig = metaConfig.get(\"path\").as(Path.class); if (pathConfig.isPresent()) { Path path = pathConfig.get(); List&lt;ConfigSource&gt; sources = sourceFromPath(path, profile); if (sources != null &amp;&amp; !sources.isEmpty()) { return result; } location = \"path \" + path.toAbsolutePath(); } else { ConfigValue&lt;String&gt; classpathConfig = metaConfig.get(\"classpath\").as(String.class); if (classpathConfig.isPresent()) { String classpath = classpathConfig.get(); List&lt;ConfigSource&gt; sources = sourceFromClasspath(classpath, profile); if (sources != null &amp;&amp; !sources.isEmpty()) { return sources; } location = \"classpath \" + classpath; } else { ConfigValue&lt;URL&gt; urlConfig = metaConfig.get(\"url\").as(URL.class); if (urlConfig.isPresent()) { URL url = urlConfig.get(); List&lt;ConfigSource&gt; sources = sourceFromUrlMeta(url, profile); if (sources != null &amp;&amp; !sources.isEmpty()) { return sources; } location = \"url \" + url; } else { throw new ConfigException(\"No config source location for \" + config.key()); } } } } if (metaConfig.get(\"optional\").asBoolean().orElse(false);) { return List.of(); } throw new ConfigException(\"Meta configuration could not find non-optional config source on \" + location); } Returns the names of the types that will be supported in this meta-config. Processes config source from file system if path is provided. Method to parse config source from a specified path Processes config source from classpath location if classpath is provided. Method to parse config source from a specified classpath Processes config source from URL location if location is provided. Method to parse config source from a specified url Returns an empty result if set to optional and config source is not found. Throws a ConfigException if not set to optional and config source is not found. ",
            "title": "Example of a Meta-Config Custom Type"
        },
        {
            "location": "/mp/config/advanced-configuration",
            "text": " Helidon meta-config by default supports the following types: environment-variables, system-properties, properties, yaml, hocon and json. Users can also extend meta-config to create a custom config source type by loading it using the Java Service Loader pattern. This is achieved by implementing io.helidon.config.mp.spi.MpMetaConfigProvider SPI and registering it as a service (Using META-INF/services/${class-name} file when using classpath, or using the provides statement in module-info.java when using module path). The interface io.helidon.config.mp.spi.MpMetaConfigProvider requires implementation of the following methods: Set&lt;String&gt; supportedTypes() List&lt;? extends ConfigSource&gt; create(String type, Config metaConfig, String profile); Example of a Meta-Config Custom Type <markup lang=\"java\" >public class CustomMpMetaConfigProvider implements MpMetaConfigProvider { @Override public Set&lt;String&gt; supportedTypes() { return Set.of(\"custom\"); } @Override public List&lt;? extends ConfigSource&gt; create(String type, Config metaConfig, String profile) { ConfigValue&lt;Path&gt; pathConfig = metaConfig.get(\"path\").as(Path.class); if (pathConfig.isPresent()) { Path path = pathConfig.get(); List&lt;ConfigSource&gt; sources = sourceFromPath(path, profile); if (sources != null &amp;&amp; !sources.isEmpty()) { return result; } location = \"path \" + path.toAbsolutePath(); } else { ConfigValue&lt;String&gt; classpathConfig = metaConfig.get(\"classpath\").as(String.class); if (classpathConfig.isPresent()) { String classpath = classpathConfig.get(); List&lt;ConfigSource&gt; sources = sourceFromClasspath(classpath, profile); if (sources != null &amp;&amp; !sources.isEmpty()) { return sources; } location = \"classpath \" + classpath; } else { ConfigValue&lt;URL&gt; urlConfig = metaConfig.get(\"url\").as(URL.class); if (urlConfig.isPresent()) { URL url = urlConfig.get(); List&lt;ConfigSource&gt; sources = sourceFromUrlMeta(url, profile); if (sources != null &amp;&amp; !sources.isEmpty()) { return sources; } location = \"url \" + url; } else { throw new ConfigException(\"No config source location for \" + config.key()); } } } } if (metaConfig.get(\"optional\").asBoolean().orElse(false);) { return List.of(); } throw new ConfigException(\"Meta configuration could not find non-optional config source on \" + location); } Returns the names of the types that will be supported in this meta-config. Processes config source from file system if path is provided. Method to parse config source from a specified path Processes config source from classpath location if classpath is provided. Method to parse config source from a specified classpath Processes config source from URL location if location is provided. Method to parse config source from a specified url Returns an empty result if set to optional and config source is not found. Throws a ConfigException if not set to optional and config source is not found. ",
            "title": "Extending Meta-Config to Create a Custom Config Source Type"
        },
        {
            "location": "/mp/config/advanced-configuration",
            "text": " To use the Helidon SE features in Helidon MP, create MicroProfile Config Source from Helidon SE Config Source. The Config Source is immutable regardless of configured polling strategy or change watchers. Config config = ConfigProviderResolver.instance() .getBuilder() .withSources(MpConfigSources.create(helidonConfigSource) .build(); Creates a MicroProfile config instance using Helidon Config Source. ",
            "title": "Creating MicroProfile Config Source from Helidon SE Config Source"
        },
        {
            "location": "/mp/config/advanced-configuration",
            "text": " To use advanced Helidon SE features in Helidon MP, create MicroProfile Config Source from Helidon SE Config. The Config Source is mutable if the config uses either polling strategy and change watchers, or polling strategy or change watchers. The latest config version is queried each time org.eclipse.microprofile.config.spi.ConfigSource#getValue(String) is called. io.helidon.config.Config helidonConfig = io.helidon.config.Config.builder() .addSource(ConfigSources.create(Map.of(\"key\", \"value\"))) .build(); ConfigProviderResolver.instance(); Config config = ConfigProviderResolver.instance() .getBuilder() .withSources(MpConfigSources.create(helidonConfig)) .build(); Creates a config source from Helidon Config. Creates a MicroProfile config instance using Helidon Config. ",
            "title": "Creating MicroProfile Config Source from Helidon SE Config Instance"
        },
        {
            "location": "/mp/config/introduction",
            "text": " Overview Maven Coordinates Usage Configuration Reference ",
            "title": "Contents"
        },
        {
            "location": "/mp/config/introduction",
            "text": " Helidon MicroProfile Config is an implementation of Eclipse MicroProfile Config . You can configure your applications using MicroProfile&#8217;s config configuration sources and APIs. You can also extend the configuration using MicroProfile SPI to add custom ConfigSource and Converter . ",
            "title": "Overview"
        },
        {
            "location": "/mp/config/introduction",
            "text": " To enable MicroProfile Config either add a dependency on the helidon-microprofile bundle or add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.config&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-config&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/config/introduction",
            "text": " A Config Source provides configuration values from different sources such as property files and user classes that are registered by the application. By default, the following configuration sources are used to retrieve the configuration: Source Description System properties A mutable source that uses System.getProperties() to obtain configuration values. Environment variables An immutable source that uses System.env() to obtain configuration values and resolves aliases as defined by the MicroProfile Config specification. META-INF/microprofile-config.properties The properties config source as defined by MicroProfile Config specification. MicroProfile Config uses ConfigSource SPI to load configuration data, either from default configuration sources or from custom ConfigSource located by Java Service Loader. ",
            "title": "MicroProfile Config Sources"
        },
        {
            "location": "/mp/config/introduction",
            "text": " You can use MicroProfile Config API to get configuration properties by using a Config instance programmatically or injecting configuration values with @ConfigProperty . <markup lang=\"java\" title=\"Using Config \" >org.eclipse.microprofile.config.Config config = ConfigProvider.getConfig(); config.getOptionalValue(\"app.greeting\", String.class).orElse(\"Hello\"); <markup lang=\"java\" title=\"Injecting configured properties into a constructor\" >@Inject public GreetingProvider(@ConfigProperty(name = \"app.greeting\", defaultValue = \"Hello\") String message) { this.message = message } MicroProfile Config provides typed access to configuration values, using built-in converters, and Converter implementations located by Java Service Loader. ",
            "title": "Using MicroProfile Config API"
        },
        {
            "location": "/mp/config/introduction",
            "text": " In order to properly configure your application using configuration sources, you need to understand the precedence rules used to merge your configuration data. The default MicroProfile Config Sources ordering is: System properties (ordinal=400) Environment variables (ordinal=300) /META-INF/microprofile-config.properties (ordinal=100) Each Config Source has an ordinal that determines the priority of the Config Source. A Config Source with higher ordinal has higher priority as compared to the Config Source with lower ordinal. The values taken from the high-priority Config Source overrides the values from low-priority Config Source. This helps to customize the configuration of Config Sources using external Config Source if an external Config Source has higher ordinal values than the built-in Config Sources of the application. The example below shows how the MicroProfile configuration file microprofile-config.properties can be used to modify the server listen port property. <markup lang=\"properties\" >// Application properties. This is the default greeting app.greeting=Hello // Microprofile server properties server.port=8080 server.host=0.0.0.0 ",
            "title": "Ordering of Default Config Sources"
        },
        {
            "location": "/mp/config/introduction",
            "text": " MicroProfile Config supports a concept of configuration profiles. You can define a profile using the configuration property mp.config.profile (when using default configuration, this can be defined as a system property, environment variable or as a property in microprofile-config.properties ). When a profile is defined, additional config source is loaded ( microprofile-config-profile.properties ) and properties from profile have precedence over default properties. Profile properties can be defined using %profile prefix, such as %dev.server.port . ",
            "title": "MicroProfile Config Profiles"
        },
        {
            "location": "/mp/config/introduction",
            "text": " MicroProfile Config Sources A Config Source provides configuration values from different sources such as property files and user classes that are registered by the application. By default, the following configuration sources are used to retrieve the configuration: Source Description System properties A mutable source that uses System.getProperties() to obtain configuration values. Environment variables An immutable source that uses System.env() to obtain configuration values and resolves aliases as defined by the MicroProfile Config specification. META-INF/microprofile-config.properties The properties config source as defined by MicroProfile Config specification. MicroProfile Config uses ConfigSource SPI to load configuration data, either from default configuration sources or from custom ConfigSource located by Java Service Loader. Using MicroProfile Config API You can use MicroProfile Config API to get configuration properties by using a Config instance programmatically or injecting configuration values with @ConfigProperty . <markup lang=\"java\" title=\"Using Config \" >org.eclipse.microprofile.config.Config config = ConfigProvider.getConfig(); config.getOptionalValue(\"app.greeting\", String.class).orElse(\"Hello\"); <markup lang=\"java\" title=\"Injecting configured properties into a constructor\" >@Inject public GreetingProvider(@ConfigProperty(name = \"app.greeting\", defaultValue = \"Hello\") String message) { this.message = message } MicroProfile Config provides typed access to configuration values, using built-in converters, and Converter implementations located by Java Service Loader. Ordering of Default Config Sources In order to properly configure your application using configuration sources, you need to understand the precedence rules used to merge your configuration data. The default MicroProfile Config Sources ordering is: System properties (ordinal=400) Environment variables (ordinal=300) /META-INF/microprofile-config.properties (ordinal=100) Each Config Source has an ordinal that determines the priority of the Config Source. A Config Source with higher ordinal has higher priority as compared to the Config Source with lower ordinal. The values taken from the high-priority Config Source overrides the values from low-priority Config Source. This helps to customize the configuration of Config Sources using external Config Source if an external Config Source has higher ordinal values than the built-in Config Sources of the application. The example below shows how the MicroProfile configuration file microprofile-config.properties can be used to modify the server listen port property. <markup lang=\"properties\" >// Application properties. This is the default greeting app.greeting=Hello // Microprofile server properties server.port=8080 server.host=0.0.0.0 MicroProfile Config Profiles MicroProfile Config supports a concept of configuration profiles. You can define a profile using the configuration property mp.config.profile (when using default configuration, this can be defined as a system property, environment variable or as a property in microprofile-config.properties ). When a profile is defined, additional config source is loaded ( microprofile-config-profile.properties ) and properties from profile have precedence over default properties. Profile properties can be defined using %profile prefix, such as %dev.server.port . ",
            "title": "MicroProfile Config Features"
        },
        {
            "location": "/mp/config/introduction",
            "text": " Helidon MicroProfile Config offers the following features on top of the specification: ",
            "title": "Helidon MicroProfile Config Features"
        },
        {
            "location": "/mp/config/introduction",
            "text": " You can use ${reference} to reference another configuration key in a key value. This allows to configure a single key to be reused in multiple other keys. <markup lang=\"yaml\" title=\"Example\" >uri: \"http://localhost:8080\" service-1: \"${uri}/service1\" service-2: \"${uri}/service2\" ",
            "title": "References"
        },
        {
            "location": "/mp/config/introduction",
            "text": " Polling (or change watching) for file based config sources (not classpath based). To enable polling for a config source created using meta configuration (see below), or using MpConfigSources.create(Path) , or YamlMpConfigSource.create(Path) , use the following properties: Property Description helidon.config.polling.enabled To enable polling file for changes, uses timestamp to identify a change. helidon.config.polling.duration Polling period duration, defaults to 10 seconds ('PT10S`) See javadoc helidon.config.watcher.enabled To enable watching file for changes using the Java WatchService . See link:https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/nio/file/WatchService.html ",
            "title": "Change support"
        },
        {
            "location": "/mp/config/introduction",
            "text": " You can encrypt secrets using a master password and store them in a configuration file. The config encryption filter in MicroProfile Config is enabled by default. For more information, see Configuration Secrets . <markup lang=\"properties\" title=\"Example of encrypted secrets\" ># Password encrypted using a master password client_secret=${GCM=mYRkg+4Q4hua1kvpCCI2hg==} # Password encrypted using public key (there are length limits when using RSA) client_secret=${RSA=mYRkg+4Q4hua1kvpCCI2hg==} # Password in clear text, can be used in development # The system needs to be configured to accept clear text client_secret=${CLEAR=known_password} ",
            "title": "Encryption"
        },
        {
            "location": "/mp/config/introduction",
            "text": " You can configure the Config using Helidon MP Config meta configuration feature. The meta-config allows configuration of config sources and other configuration options, including addition of discovered sources and converters. See Microprofile Config Sources for detailed information. For backward compatibility, we will support usage of Helidon SE meta-configuration until version 3.0.0. Using this approach causes behavior that is not compatible with MicroProfile Config specification. ",
            "title": "Meta Configuration"
        },
        {
            "location": "/mp/config/introduction",
            "text": " Helidon configuration sources can use different formats for the configuration data. You can specify the format on a per source bases, mixing and matching formats as required. The following configuration sources can be used to retrieve the configuration: Source Description File Creates the source from a properties file on the file system with MpConfigSources.create(Path) . URL Creates the source from properties from a URL with MpConfigSources.create(URL) . Map&lt;String, String&gt; Creates the source from a Map with MpConfigSources.create(Map) . Properties Creates the source directly from Properties with MpConfigSources.create(Properties) . File on classpath Creates the source from a properties file on classpath with MpConfigSources.classpath(String) . YAML Creates the source from YAML using YamlMpConfigSource.create(Path) or YamlMpConfigSource.create(URL) . See manual setup of config section for more information. References You can use ${reference} to reference another configuration key in a key value. This allows to configure a single key to be reused in multiple other keys. <markup lang=\"yaml\" title=\"Example\" >uri: \"http://localhost:8080\" service-1: \"${uri}/service1\" service-2: \"${uri}/service2\" Change support Polling (or change watching) for file based config sources (not classpath based). To enable polling for a config source created using meta configuration (see below), or using MpConfigSources.create(Path) , or YamlMpConfigSource.create(Path) , use the following properties: Property Description helidon.config.polling.enabled To enable polling file for changes, uses timestamp to identify a change. helidon.config.polling.duration Polling period duration, defaults to 10 seconds ('PT10S`) See javadoc helidon.config.watcher.enabled To enable watching file for changes using the Java WatchService . See link:https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/nio/file/WatchService.html Encryption You can encrypt secrets using a master password and store them in a configuration file. The config encryption filter in MicroProfile Config is enabled by default. For more information, see Configuration Secrets . <markup lang=\"properties\" title=\"Example of encrypted secrets\" ># Password encrypted using a master password client_secret=${GCM=mYRkg+4Q4hua1kvpCCI2hg==} # Password encrypted using public key (there are length limits when using RSA) client_secret=${RSA=mYRkg+4Q4hua1kvpCCI2hg==} # Password in clear text, can be used in development # The system needs to be configured to accept clear text client_secret=${CLEAR=known_password} Meta Configuration You can configure the Config using Helidon MP Config meta configuration feature. The meta-config allows configuration of config sources and other configuration options, including addition of discovered sources and converters. See Microprofile Config Sources for detailed information. For backward compatibility, we will support usage of Helidon SE meta-configuration until version 3.0.0. Using this approach causes behavior that is not compatible with MicroProfile Config specification. ",
            "title": "Helidon MicroProfile Config Sources"
        },
        {
            "location": "/mp/config/introduction",
            "text": " MicroProfile Config Features MicroProfile Config Sources A Config Source provides configuration values from different sources such as property files and user classes that are registered by the application. By default, the following configuration sources are used to retrieve the configuration: Source Description System properties A mutable source that uses System.getProperties() to obtain configuration values. Environment variables An immutable source that uses System.env() to obtain configuration values and resolves aliases as defined by the MicroProfile Config specification. META-INF/microprofile-config.properties The properties config source as defined by MicroProfile Config specification. MicroProfile Config uses ConfigSource SPI to load configuration data, either from default configuration sources or from custom ConfigSource located by Java Service Loader. Using MicroProfile Config API You can use MicroProfile Config API to get configuration properties by using a Config instance programmatically or injecting configuration values with @ConfigProperty . <markup lang=\"java\" title=\"Using Config \" >org.eclipse.microprofile.config.Config config = ConfigProvider.getConfig(); config.getOptionalValue(\"app.greeting\", String.class).orElse(\"Hello\"); <markup lang=\"java\" title=\"Injecting configured properties into a constructor\" >@Inject public GreetingProvider(@ConfigProperty(name = \"app.greeting\", defaultValue = \"Hello\") String message) { this.message = message } MicroProfile Config provides typed access to configuration values, using built-in converters, and Converter implementations located by Java Service Loader. Ordering of Default Config Sources In order to properly configure your application using configuration sources, you need to understand the precedence rules used to merge your configuration data. The default MicroProfile Config Sources ordering is: System properties (ordinal=400) Environment variables (ordinal=300) /META-INF/microprofile-config.properties (ordinal=100) Each Config Source has an ordinal that determines the priority of the Config Source. A Config Source with higher ordinal has higher priority as compared to the Config Source with lower ordinal. The values taken from the high-priority Config Source overrides the values from low-priority Config Source. This helps to customize the configuration of Config Sources using external Config Source if an external Config Source has higher ordinal values than the built-in Config Sources of the application. The example below shows how the MicroProfile configuration file microprofile-config.properties can be used to modify the server listen port property. <markup lang=\"properties\" >// Application properties. This is the default greeting app.greeting=Hello // Microprofile server properties server.port=8080 server.host=0.0.0.0 MicroProfile Config Profiles MicroProfile Config supports a concept of configuration profiles. You can define a profile using the configuration property mp.config.profile (when using default configuration, this can be defined as a system property, environment variable or as a property in microprofile-config.properties ). When a profile is defined, additional config source is loaded ( microprofile-config-profile.properties ) and properties from profile have precedence over default properties. Profile properties can be defined using %profile prefix, such as %dev.server.port . Helidon MicroProfile Config Features Helidon MicroProfile Config offers the following features on top of the specification: Helidon MicroProfile Config Sources Helidon configuration sources can use different formats for the configuration data. You can specify the format on a per source bases, mixing and matching formats as required. The following configuration sources can be used to retrieve the configuration: Source Description File Creates the source from a properties file on the file system with MpConfigSources.create(Path) . URL Creates the source from properties from a URL with MpConfigSources.create(URL) . Map&lt;String, String&gt; Creates the source from a Map with MpConfigSources.create(Map) . Properties Creates the source directly from Properties with MpConfigSources.create(Properties) . File on classpath Creates the source from a properties file on classpath with MpConfigSources.classpath(String) . YAML Creates the source from YAML using YamlMpConfigSource.create(Path) or YamlMpConfigSource.create(URL) . See manual setup of config section for more information. References You can use ${reference} to reference another configuration key in a key value. This allows to configure a single key to be reused in multiple other keys. <markup lang=\"yaml\" title=\"Example\" >uri: \"http://localhost:8080\" service-1: \"${uri}/service1\" service-2: \"${uri}/service2\" Change support Polling (or change watching) for file based config sources (not classpath based). To enable polling for a config source created using meta configuration (see below), or using MpConfigSources.create(Path) , or YamlMpConfigSource.create(Path) , use the following properties: Property Description helidon.config.polling.enabled To enable polling file for changes, uses timestamp to identify a change. helidon.config.polling.duration Polling period duration, defaults to 10 seconds ('PT10S`) See javadoc helidon.config.watcher.enabled To enable watching file for changes using the Java WatchService . See link:https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/nio/file/WatchService.html Encryption You can encrypt secrets using a master password and store them in a configuration file. The config encryption filter in MicroProfile Config is enabled by default. For more information, see Configuration Secrets . <markup lang=\"properties\" title=\"Example of encrypted secrets\" ># Password encrypted using a master password client_secret=${GCM=mYRkg+4Q4hua1kvpCCI2hg==} # Password encrypted using public key (there are length limits when using RSA) client_secret=${RSA=mYRkg+4Q4hua1kvpCCI2hg==} # Password in clear text, can be used in development # The system needs to be configured to accept clear text client_secret=${CLEAR=known_password} Meta Configuration You can configure the Config using Helidon MP Config meta configuration feature. The meta-config allows configuration of config sources and other configuration options, including addition of discovered sources and converters. See Microprofile Config Sources for detailed information. For backward compatibility, we will support usage of Helidon SE meta-configuration until version 3.0.0. Using this approach causes behavior that is not compatible with MicroProfile Config specification. ",
            "title": "Usage"
        },
        {
            "location": "/mp/config/introduction",
            "text": " Optional configuration options key type default value description profile string &#160; Configure an explicit profile name. Current properties may be set in application.yaml or in microprofile-config.properties with mp.config prefix. See Config Profiles for more information. ",
            "title": "Configuration options"
        },
        {
            "location": "/mp/config/introduction",
            "text": " Config sources can be configured using the following properties. The class responsible for configuration is: Type: org.eclipse.microprofile.config.Config This is a standalone configuration type, prefix from configuration root: mp.config Configuration options Optional configuration options key type default value description profile string &#160; Configure an explicit profile name. Current properties may be set in application.yaml or in microprofile-config.properties with mp.config prefix. See Config Profiles for more information. ",
            "title": "Configuration"
        },
        {
            "location": "/mp/config/introduction",
            "text": " MP Config Guide Step-by-step guide about using MicroProfile Config in your Helidon MP application. ",
            "title": "Additional Information"
        },
        {
            "location": "/mp/config/introduction",
            "text": " MicroProfile Config Specifications MicroProfile Config Javadocs ",
            "title": "Reference"
        },
        {
            "location": "/mp/cors/cors",
            "text": " Overview Maven Coordinates Usage API Configuration Examples Additional Information ",
            "title": "Contents"
        },
        {
            "location": "/mp/cors/cors",
            "text": " Before you revise your application to add CORS support, you need to decide what type of cross-origin sharing you want to allow for each resource your application exposes. For example, suppose for a given resource you want to allow unrestricted sharing for GET, HEAD, and POST requests (what CORS refers to as \"simple\" requests), but permit other types of requests only from the two origins foo.com and there.com . Your application would implement two types of CORS sharing: more relaxed for the simple requests and stricter for others. Once you know the type of sharing you want to allow for each of your resources&#8201;&#8212;&#8201;including any from built-in services&#8201;&#8212;&#8201;you can change your application accordingly. ",
            "title": "Before You Begin"
        },
        {
            "location": "/mp/cors/cors",
            "text": " The cross-origin resource sharing (CORS) protocol helps developers control if and how REST resources served by their applications can be shared across origins. Helidon MP includes an implementation of CORS that you can use to add CORS behavior to the services you develop. You can define your application&#8217;s CORS behavior programmatically using the Helidon CORS API alone, or together with configuration. Helidon also provides three built-in services that add their own endpoints to your application&#8201;&#8212;&#8201;health, metrics, and OpenAPI&#8201;&#8212;&#8201;that have integrated CORS support. By adding very little code to your application, you control how all the resources in your application&#8201;&#8212;&#8201;the ones you write and the ones provided by the Helidon built-in services&#8201;&#8212;&#8201;can be shared across origins. Before You Begin Before you revise your application to add CORS support, you need to decide what type of cross-origin sharing you want to allow for each resource your application exposes. For example, suppose for a given resource you want to allow unrestricted sharing for GET, HEAD, and POST requests (what CORS refers to as \"simple\" requests), but permit other types of requests only from the two origins foo.com and there.com . Your application would implement two types of CORS sharing: more relaxed for the simple requests and stricter for others. Once you know the type of sharing you want to allow for each of your resources&#8201;&#8212;&#8201;including any from built-in services&#8201;&#8212;&#8201;you can change your application accordingly. ",
            "title": "Overview"
        },
        {
            "location": "/mp/cors/cors",
            "text": " To enable CORS add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-cors&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/cors/cors",
            "text": " Once you have planned how each of your resources should support CORS, you specify the CORS behavior in one of two ways: add @CrossOrigin annotations to the Java code for the resources, or add configuration. You can do both. CORS configuration for a resource overrides any CORS settings declared using @CrossOrigin in the Java class for the resource. ",
            "title": "Usage"
        },
        {
            "location": "/mp/cors/cors",
            "text": " Adding CORS behavior to your Helidon MP application involves just a few simple steps. For each resource class in your application: Identify the resources and subresources&#8212;&#8203;in other words, the paths&#8212;&#8203;declared in the resource class which you want to support CORS. For each of those resources and subresources which should support CORS: Find or create a Java method annotated with @OPTIONS and with the correct @Path . To that @OPTIONS Java method add a Helidon @CrossOrigin annotation that describes the cross-origin sharing you want for that resource. Using @CrossOrigin Correctly Use the @CrossOrigin annotation only on methods which also have the @OPTIONS annotation. Remember that the @CrossOrigin settings apply to a given path and therefore to all Java resource methods which share that path. Helidon MP aborts the server start-up if you use the @CrossOrigin annotation on a resource method other than an @OPTIONS method. For an informal look at the reasons for applying the @CrossOrigin annotation to the @OPTIONS method, instead of another method, see Why @OPTIONS ? . The configuration table below describes the attributes of the @CrossOrigin annotation. ",
            "title": "The @CrossOrigin Annotation"
        },
        {
            "location": "/mp/cors/cors",
            "text": " The @CrossOrigin Annotation Adding CORS behavior to your Helidon MP application involves just a few simple steps. For each resource class in your application: Identify the resources and subresources&#8212;&#8203;in other words, the paths&#8212;&#8203;declared in the resource class which you want to support CORS. For each of those resources and subresources which should support CORS: Find or create a Java method annotated with @OPTIONS and with the correct @Path . To that @OPTIONS Java method add a Helidon @CrossOrigin annotation that describes the cross-origin sharing you want for that resource. Using @CrossOrigin Correctly Use the @CrossOrigin annotation only on methods which also have the @OPTIONS annotation. Remember that the @CrossOrigin settings apply to a given path and therefore to all Java resource methods which share that path. Helidon MP aborts the server start-up if you use the @CrossOrigin annotation on a resource method other than an @OPTIONS method. For an informal look at the reasons for applying the @CrossOrigin annotation to the @OPTIONS method, instead of another method, see Why @OPTIONS ? . The configuration table below describes the attributes of the @CrossOrigin annotation. ",
            "title": "API"
        },
        {
            "location": "/mp/cors/cors",
            "text": " You can define CORS behavior&#8212;&#8203;and you or your users can override behavior declared in your code&#8212;&#8203;using configuration. For each resource you want to configure, add a section to META-INF/microprofile-config.properties file: <markup lang=\"properties\" title=\"General form of CORS configuration\" >cors.enabled= # cors.paths. i .path-pattern= cors.paths. i .allow-headers= cors.paths. i .max-age-seconds= cors.paths. i .allow-credentials= cors.paths. i .allow-origins= cors.paths. i .expose-headers= cors.paths. i .allow-methods= cors.paths. i .enabled= You can disable CORS processing for all resources by setting cors.enabled to false . Defaults to true . Add a block for each resource you want to configure. The index i is an integer (0, 1, 2, etc.). Specify the settings as needed to define the CORS behavior you want for that resource. The enabled setting lets you control whether the system uses that set of CORS configuration. Defaults to true . The system uses the index i , not the position in the config file, to identify the settings for a particular resource. Path patterns can be any expression accepted by the PathMatcher class. Helidon scans the cross-origin entries in index order (0, 1, 2, etc.) until it finds an entry that matches an incoming request&#8217;s path and HTTP method, so be sure to assign index values to the entries so Helidon will check them in the order you want. In particular, use lower index values for entries with more specific path patterns. The table below describes the attributes on the @CrossOrigin annotation and the configuration keys that map to the headers defined in the CORS protocol. annotation attribute config key type default description CORS header name allowCredentials allow-credentials boolean false Sets the allow credentials flag. Access-Control-Allow-Credentials allowHeaders allow-headers string[] * Sets the allowed headers. Access-Control-Allow-Headers allowMethods allow-methods string[] * Sets the allowed methods. Access-Control-Allow-Methods allowOrigins allow-origins string[] * Sets the allowed origins. Access-Control-Allow-Origins exposeHeaders expose-headers string[] &#160; Sets the expose headers. Access-Control-Expose-Headers maxAgeSeconds max-age-seconds long 3600 Sets the maximum age. Access-Control-Max-Age enabled enabled boolean true Sets whether this config should be enabled or not. n/a If the cross-origin configuration is disabled ( enabled = false), then the Helidon CORS implementation ignores the cross-origin configuration entry. ",
            "title": "Configuration"
        },
        {
            "location": "/mp/cors/cors",
            "text": "<markup lang=\"java\" title=\"Using annotations to declare CORS behavior\" >@Path(\"/greet\") public class GreetResource { @GET public JsonObject getDefaultMessage() {...} @Path(\"/greeting\") @PUT public Response updateGreeting(JsonObject jsonObject) {...} @OPTIONS @CrossOrigin() public void optionsForRetrievingUnnamedGreeting() {} @OPTIONS @Path(\"/greeting\") @CrossOrigin({\"http://foo.com\", \"http://there.com\"}, allowMethods = {HttpMethod.PUT}) public void optionsForUpdatingGreeting() {} } Existing GreetResource resource class with path /greet . Existing @GET method for resource /greet . Existing @PUT method for resource /greet/greeting . New @OPTIONS method for /greet . (Just like the @GET method getDefaultMessage , this @OPTIONS method does not have a @Path annotation; both \"inherit\" the class-level @Path setting /greet .) The @CrossOrigin annotation declares default cross-origin sharing which permits sharing via all HTTP methods to all origins. New @OPTIONS method for /greet/greeting . The @CrossOrigin annotation specifies sharing only via the PUT HTTP method and only to the two listed origins. ",
            "title": "Adding Annotations"
        },
        {
            "location": "/mp/cors/cors",
            "text": " You could use the following configuration in place of using annotations to set up the same CORS behavior. <markup lang=\"properties\" title=\"Using configuration to set up the same CORS behavior\" >cors.paths.0.path-pattern=/greet cors.paths.1.path-pattern=/greet/greeting cors.paths.1.allow-origins=http://foo.com,http://there.com cors.paths.1.allow-methods=PUT Enables default CORS settings for the /greet resource. Sets up sharing for the /greet/greeting resource only via PUT requests and only from the specified origins. Or, alternatively, the following configuration example augments the settings from the @CrossOrigin annotations in the code. <markup lang=\"properties\" title=\"Using configuration to augment or override declared CORS behavior\" >cors.paths.0.path-pattern=/greet cors.paths.0.allow-methods=GET cors.paths.0.allow-origins=http://here.com,http://foo.com,http://there.com cors.paths.1.path-patterh=/greet/greeting cors.paths.1.allow-methods=PUT cors.paths.1.allow-origins=http://foo.com Changes the declared settings to restrict cross-origin use of /greet to only GET and only from foo.com and there.com . Changes the settings for /greet/greeting from what they were declared; with this configuration, only the origin foo.com is permitted. (The declared setting also allowed there.com ). ",
            "title": "Adding Configuration"
        },
        {
            "location": "/mp/cors/cors",
            "text": " The Helidon MP Quickstart application allows users to: obtain greetings by sending GET requests to the /greet resource, and change the greeting message by sending a PUT request to the /greet/greeting resource. The Helidon MP CORS Example shows the basic quickstart example enhanced for CORS. The discussion below describes the changes in the application which: permit unrestricted sharing of the resource /greet , and restrict sharing of the resource /greet/greeting so that only the origins http://foo.com and http://there.com can change the greeting. Adding Annotations <markup lang=\"java\" title=\"Using annotations to declare CORS behavior\" >@Path(\"/greet\") public class GreetResource { @GET public JsonObject getDefaultMessage() {...} @Path(\"/greeting\") @PUT public Response updateGreeting(JsonObject jsonObject) {...} @OPTIONS @CrossOrigin() public void optionsForRetrievingUnnamedGreeting() {} @OPTIONS @Path(\"/greeting\") @CrossOrigin({\"http://foo.com\", \"http://there.com\"}, allowMethods = {HttpMethod.PUT}) public void optionsForUpdatingGreeting() {} } Existing GreetResource resource class with path /greet . Existing @GET method for resource /greet . Existing @PUT method for resource /greet/greeting . New @OPTIONS method for /greet . (Just like the @GET method getDefaultMessage , this @OPTIONS method does not have a @Path annotation; both \"inherit\" the class-level @Path setting /greet .) The @CrossOrigin annotation declares default cross-origin sharing which permits sharing via all HTTP methods to all origins. New @OPTIONS method for /greet/greeting . The @CrossOrigin annotation specifies sharing only via the PUT HTTP method and only to the two listed origins. Adding Configuration You could use the following configuration in place of using annotations to set up the same CORS behavior. <markup lang=\"properties\" title=\"Using configuration to set up the same CORS behavior\" >cors.paths.0.path-pattern=/greet cors.paths.1.path-pattern=/greet/greeting cors.paths.1.allow-origins=http://foo.com,http://there.com cors.paths.1.allow-methods=PUT Enables default CORS settings for the /greet resource. Sets up sharing for the /greet/greeting resource only via PUT requests and only from the specified origins. Or, alternatively, the following configuration example augments the settings from the @CrossOrigin annotations in the code. <markup lang=\"properties\" title=\"Using configuration to augment or override declared CORS behavior\" >cors.paths.0.path-pattern=/greet cors.paths.0.allow-methods=GET cors.paths.0.allow-origins=http://here.com,http://foo.com,http://there.com cors.paths.1.path-patterh=/greet/greeting cors.paths.1.allow-methods=PUT cors.paths.1.allow-origins=http://foo.com Changes the declared settings to restrict cross-origin use of /greet to only GET and only from foo.com and there.com . Changes the settings for /greet/greeting from what they were declared; with this configuration, only the origin foo.com is permitted. (The declared setting also allowed there.com ). ",
            "title": "Examples"
        },
        {
            "location": "/mp/cors/cors",
            "text": " The decisions the Helidon CORS feature makes depend on accurate information about each incoming request, particularly the host to which the request is sent. Conveyed as headers in the request, this information can be changed or overwritten by intermediate nodes&#8212;&#8203;such as load balancers&#8212;&#8203;between the origin of the request and your service. Well-behaved intermediate nodes preserve this important data in other headers, such as Forwarded . You can configure how the Helidon server handles these headers as described in the documentation for requested URI discovery . The CORS support in Helidon uses the requested URI feature to discover the correct information about each request, according to your configuration, so it can make accurate decisions about whether to permit cross-origin accesses. ",
            "title": "CORS and the Requested URI Feature"
        },
        {
            "location": "/mp/cors/cors",
            "text": " To use built-in services with CORS support and customize the CORS behavior: Add the built-in service or services to your application. The health, metrics, and OpenAPI services automatically include default CORS support. Add a dependency on the Helidon MP CORS artifact to your Maven pom.xml file. If you want the built-in services to support CORS, then you need to add the CORS dependency even if your own endpoints do not use CORS. Use configuration to customize the CORS behavior as needed. The documentation for the individual built-in services describes how to add each service to your application, including adding a Maven dependency. In your application&#8217;s configuration file, the configuration for each service appears under its own key. Helidon Service Documentation Configuration Key health health metrics metrics OpenAPI openapi The Helidon MP QuickStart example uses these services, so you can use that as a template for your own application, or use the example project itself to experiment with customizing the CORS behavior in the built-in services. ",
            "title": "Built-in Services with CORS"
        },
        {
            "location": "/mp/cors/cors",
            "text": " You can use configuration to control whether and how each of the built-in services works with CORS. In the configuration for the health, metrics, and OpenAPI services, you can add a section for CORS. You have full control over the CORS configuration for a built-in Helidon service. Use a CORS config section as described in the configuration table . The following example restricts sharing of the /health resource, provided by the health built-in service, to only the origin http://there.com , and the /metrics resource, provided by the metrics built-in service, to only the origin http://foo.com . <markup lang=\"properties\" title=\"Configuration which restricts sharing of the health and metrics resources\" >health.cors.allow-origins=http://there.com metrics.cors.allow-origins=http://foo.com ",
            "title": "Configuring CORS for Built-in Services"
        },
        {
            "location": "/mp/cors/cors",
            "text": " Build and run the QuickStart application as usual. <markup lang=\"bash\" >mvn package java -jar target/helidon-quickstart-mp.jar ... 2020.05.12 05:44:08 INFO io.helidon.microprofile.server.ServerCdiExtension Thread[main,5,main]: Server started on http://localhost:8080 (and all other host addresses) in 5280 milliseconds (since JVM startup). ... ",
            "title": "Build and Run the Application"
        },
        {
            "location": "/mp/cors/cors",
            "text": " The metrics service rejects attempts to access metrics on behalf of a disallowed origin. <markup lang=\"bash\" >curl -i -H \"Origin: http://other.com\" http://localhost:8080/metrics <markup lang=\"listing\" >HTTP/1.1 403 Forbidden Date: Mon, 11 May 2020 11:08:09 -0500 transfer-encoding: chunked connection: keep-alive But accesses from foo.com succeed. <markup lang=\"bash\" >curl -i -H \"Origin: http://foo.com\" http://localhost:8080/metrics <markup lang=\"listing\" >HTTP/1.1 200 OK Access-Control-Allow-Origin: http://foo.com Content-Type: text/plain Date: Mon, 11 May 2020 11:08:16 -0500 Vary: Origin connection: keep-alive content-length: 6065 # TYPE base_classloader_loadedClasses_count gauge # HELP base_classloader_loadedClasses_count Displays the number of classes that are currently loaded in the Java virtual machine. base_classloader_loadedClasses_count 3568 ",
            "title": "Retrieve Metrics"
        },
        {
            "location": "/mp/cors/cors",
            "text": " The health service rejects requests from origins not specifically approved. <markup lang=\"bash\" >curl -i -H \"Origin: http://foo.com\" http://localhost:8080/health <markup lang=\"listing\" >HTTP/1.1 403 Forbidden Date: Mon, 11 May 2020 12:06:55 -0500 transfer-encoding: chunked connection: keep-alive And responds successfully only to cross-origin requests from http://there.com . <markup lang=\"bash\" >curl -i -H \"Origin: http://there.com\" http://localhost:8080/health <markup lang=\"listing\" >HTTP/1.1 200 OK Access-Control-Allow-Origin: http://there.com Content-Type: application/json Date: Mon, 11 May 2020 12:07:32 -0500 Vary: Origin connection: keep-alive content-length: 461 {\"outcome\":\"UP\",...} ",
            "title": "Retrieve Health"
        },
        {
            "location": "/mp/cors/cors",
            "text": " If you have edited the Helidon MP QuickStart application as described in the previous topics and saved your changes, you can build and run the application. Once you do so you can execute curl commands to demonstrate the behavior changes in the metric and health services with the addition of the CORS functionality. Note the addition of the Origin header value in the curl commands, and the Access-Control-Allow-Origin in the successful responses. Build and Run the Application Build and run the QuickStart application as usual. <markup lang=\"bash\" >mvn package java -jar target/helidon-quickstart-mp.jar ... 2020.05.12 05:44:08 INFO io.helidon.microprofile.server.ServerCdiExtension Thread[main,5,main]: Server started on http://localhost:8080 (and all other host addresses) in 5280 milliseconds (since JVM startup). ... Retrieve Metrics The metrics service rejects attempts to access metrics on behalf of a disallowed origin. <markup lang=\"bash\" >curl -i -H \"Origin: http://other.com\" http://localhost:8080/metrics <markup lang=\"listing\" >HTTP/1.1 403 Forbidden Date: Mon, 11 May 2020 11:08:09 -0500 transfer-encoding: chunked connection: keep-alive But accesses from foo.com succeed. <markup lang=\"bash\" >curl -i -H \"Origin: http://foo.com\" http://localhost:8080/metrics <markup lang=\"listing\" >HTTP/1.1 200 OK Access-Control-Allow-Origin: http://foo.com Content-Type: text/plain Date: Mon, 11 May 2020 11:08:16 -0500 Vary: Origin connection: keep-alive content-length: 6065 # TYPE base_classloader_loadedClasses_count gauge # HELP base_classloader_loadedClasses_count Displays the number of classes that are currently loaded in the Java virtual machine. base_classloader_loadedClasses_count 3568 Retrieve Health The health service rejects requests from origins not specifically approved. <markup lang=\"bash\" >curl -i -H \"Origin: http://foo.com\" http://localhost:8080/health <markup lang=\"listing\" >HTTP/1.1 403 Forbidden Date: Mon, 11 May 2020 12:06:55 -0500 transfer-encoding: chunked connection: keep-alive And responds successfully only to cross-origin requests from http://there.com . <markup lang=\"bash\" >curl -i -H \"Origin: http://there.com\" http://localhost:8080/health <markup lang=\"listing\" >HTTP/1.1 200 OK Access-Control-Allow-Origin: http://there.com Content-Type: application/json Date: Mon, 11 May 2020 12:07:32 -0500 Vary: Origin connection: keep-alive content-length: 461 {\"outcome\":\"UP\",...} ",
            "title": "Accessing the Shared Resources"
        },
        {
            "location": "/mp/cors/cors",
            "text": " Several built-in Helidon services&#8212;&#8203; health , metrics , and OpenAPI --have integrated CORS support. You can include these services in your application and control how those resources can be shared across origins. For example, several websites related to OpenAPI run a web application in your browser. You provide the URL for your application to the browser application. The browser application uses the URL to retrieve the OpenAPI document that describes the application&#8217;s endpoints directly from your application. The browser application then displays a user interface that you use to \"drive\" your application. That is, you provide input, have the web application send requests to your application endpoints, and then view the responses. This scenario is exactly the situation CORS addresses: an application in the browser from one origin&#8201;&#8212;&#8201;the user interface downloaded from the website&#8201;&#8212;&#8201;requests a resource from another origin&#8201;&#8212;&#8201;the /openapi endpoint which Helidon&#8217;s OpenAPI built-in service automatically adds to your application. Integrating CORS support into these built-in services allows such third-party web sites and their browser applications&#8201;&#8212;&#8201;or more generally, apps from any other origin&#8201;&#8212;&#8201;to work with your Helidon application. Because all three of these built-in Helidon services serve only GET endpoints, by default the integrated CORS support in all three services permits any origin to share their resources using GET , HEAD , and OPTIONS HTTP requests. You can customize the CORS set-up for these built-in services independently from each other using configuration. You can use this override feature to control the CORS behavior of the built-in services even if you do not add CORS behavior to your own endpoints. Built-in Services with CORS To use built-in services with CORS support and customize the CORS behavior: Add the built-in service or services to your application. The health, metrics, and OpenAPI services automatically include default CORS support. Add a dependency on the Helidon MP CORS artifact to your Maven pom.xml file. If you want the built-in services to support CORS, then you need to add the CORS dependency even if your own endpoints do not use CORS. Use configuration to customize the CORS behavior as needed. The documentation for the individual built-in services describes how to add each service to your application, including adding a Maven dependency. In your application&#8217;s configuration file, the configuration for each service appears under its own key. Helidon Service Documentation Configuration Key health health metrics metrics OpenAPI openapi The Helidon MP QuickStart example uses these services, so you can use that as a template for your own application, or use the example project itself to experiment with customizing the CORS behavior in the built-in services. Configuring CORS for Built-in Services You can use configuration to control whether and how each of the built-in services works with CORS. In the configuration for the health, metrics, and OpenAPI services, you can add a section for CORS. You have full control over the CORS configuration for a built-in Helidon service. Use a CORS config section as described in the configuration table . The following example restricts sharing of the /health resource, provided by the health built-in service, to only the origin http://there.com , and the /metrics resource, provided by the metrics built-in service, to only the origin http://foo.com . <markup lang=\"properties\" title=\"Configuration which restricts sharing of the health and metrics resources\" >health.cors.allow-origins=http://there.com metrics.cors.allow-origins=http://foo.com Accessing the Shared Resources If you have edited the Helidon MP QuickStart application as described in the previous topics and saved your changes, you can build and run the application. Once you do so you can execute curl commands to demonstrate the behavior changes in the metric and health services with the addition of the CORS functionality. Note the addition of the Origin header value in the curl commands, and the Access-Control-Allow-Origin in the successful responses. Build and Run the Application Build and run the QuickStart application as usual. <markup lang=\"bash\" >mvn package java -jar target/helidon-quickstart-mp.jar ... 2020.05.12 05:44:08 INFO io.helidon.microprofile.server.ServerCdiExtension Thread[main,5,main]: Server started on http://localhost:8080 (and all other host addresses) in 5280 milliseconds (since JVM startup). ... Retrieve Metrics The metrics service rejects attempts to access metrics on behalf of a disallowed origin. <markup lang=\"bash\" >curl -i -H \"Origin: http://other.com\" http://localhost:8080/metrics <markup lang=\"listing\" >HTTP/1.1 403 Forbidden Date: Mon, 11 May 2020 11:08:09 -0500 transfer-encoding: chunked connection: keep-alive But accesses from foo.com succeed. <markup lang=\"bash\" >curl -i -H \"Origin: http://foo.com\" http://localhost:8080/metrics <markup lang=\"listing\" >HTTP/1.1 200 OK Access-Control-Allow-Origin: http://foo.com Content-Type: text/plain Date: Mon, 11 May 2020 11:08:16 -0500 Vary: Origin connection: keep-alive content-length: 6065 # TYPE base_classloader_loadedClasses_count gauge # HELP base_classloader_loadedClasses_count Displays the number of classes that are currently loaded in the Java virtual machine. base_classloader_loadedClasses_count 3568 Retrieve Health The health service rejects requests from origins not specifically approved. <markup lang=\"bash\" >curl -i -H \"Origin: http://foo.com\" http://localhost:8080/health <markup lang=\"listing\" >HTTP/1.1 403 Forbidden Date: Mon, 11 May 2020 12:06:55 -0500 transfer-encoding: chunked connection: keep-alive And responds successfully only to cross-origin requests from http://there.com . <markup lang=\"bash\" >curl -i -H \"Origin: http://there.com\" http://localhost:8080/health <markup lang=\"listing\" >HTTP/1.1 200 OK Access-Control-Allow-Origin: http://there.com Content-Type: application/json Date: Mon, 11 May 2020 12:07:32 -0500 Vary: Origin connection: keep-alive content-length: 461 {\"outcome\":\"UP\",...} ",
            "title": "Using CORS Support in Built-in Helidon Services"
        },
        {
            "location": "/mp/cors/cors",
            "text": " CORS and the Requested URI Feature The decisions the Helidon CORS feature makes depend on accurate information about each incoming request, particularly the host to which the request is sent. Conveyed as headers in the request, this information can be changed or overwritten by intermediate nodes&#8212;&#8203;such as load balancers&#8212;&#8203;between the origin of the request and your service. Well-behaved intermediate nodes preserve this important data in other headers, such as Forwarded . You can configure how the Helidon server handles these headers as described in the documentation for requested URI discovery . The CORS support in Helidon uses the requested URI feature to discover the correct information about each request, according to your configuration, so it can make accurate decisions about whether to permit cross-origin accesses. Using CORS Support in Built-in Helidon Services Several built-in Helidon services&#8212;&#8203; health , metrics , and OpenAPI --have integrated CORS support. You can include these services in your application and control how those resources can be shared across origins. For example, several websites related to OpenAPI run a web application in your browser. You provide the URL for your application to the browser application. The browser application uses the URL to retrieve the OpenAPI document that describes the application&#8217;s endpoints directly from your application. The browser application then displays a user interface that you use to \"drive\" your application. That is, you provide input, have the web application send requests to your application endpoints, and then view the responses. This scenario is exactly the situation CORS addresses: an application in the browser from one origin&#8201;&#8212;&#8201;the user interface downloaded from the website&#8201;&#8212;&#8201;requests a resource from another origin&#8201;&#8212;&#8201;the /openapi endpoint which Helidon&#8217;s OpenAPI built-in service automatically adds to your application. Integrating CORS support into these built-in services allows such third-party web sites and their browser applications&#8201;&#8212;&#8201;or more generally, apps from any other origin&#8201;&#8212;&#8201;to work with your Helidon application. Because all three of these built-in Helidon services serve only GET endpoints, by default the integrated CORS support in all three services permits any origin to share their resources using GET , HEAD , and OPTIONS HTTP requests. You can customize the CORS set-up for these built-in services independently from each other using configuration. You can use this override feature to control the CORS behavior of the built-in services even if you do not add CORS behavior to your own endpoints. Built-in Services with CORS To use built-in services with CORS support and customize the CORS behavior: Add the built-in service or services to your application. The health, metrics, and OpenAPI services automatically include default CORS support. Add a dependency on the Helidon MP CORS artifact to your Maven pom.xml file. If you want the built-in services to support CORS, then you need to add the CORS dependency even if your own endpoints do not use CORS. Use configuration to customize the CORS behavior as needed. The documentation for the individual built-in services describes how to add each service to your application, including adding a Maven dependency. In your application&#8217;s configuration file, the configuration for each service appears under its own key. Helidon Service Documentation Configuration Key health health metrics metrics OpenAPI openapi The Helidon MP QuickStart example uses these services, so you can use that as a template for your own application, or use the example project itself to experiment with customizing the CORS behavior in the built-in services. Configuring CORS for Built-in Services You can use configuration to control whether and how each of the built-in services works with CORS. In the configuration for the health, metrics, and OpenAPI services, you can add a section for CORS. You have full control over the CORS configuration for a built-in Helidon service. Use a CORS config section as described in the configuration table . The following example restricts sharing of the /health resource, provided by the health built-in service, to only the origin http://there.com , and the /metrics resource, provided by the metrics built-in service, to only the origin http://foo.com . <markup lang=\"properties\" title=\"Configuration which restricts sharing of the health and metrics resources\" >health.cors.allow-origins=http://there.com metrics.cors.allow-origins=http://foo.com Accessing the Shared Resources If you have edited the Helidon MP QuickStart application as described in the previous topics and saved your changes, you can build and run the application. Once you do so you can execute curl commands to demonstrate the behavior changes in the metric and health services with the addition of the CORS functionality. Note the addition of the Origin header value in the curl commands, and the Access-Control-Allow-Origin in the successful responses. Build and Run the Application Build and run the QuickStart application as usual. <markup lang=\"bash\" >mvn package java -jar target/helidon-quickstart-mp.jar ... 2020.05.12 05:44:08 INFO io.helidon.microprofile.server.ServerCdiExtension Thread[main,5,main]: Server started on http://localhost:8080 (and all other host addresses) in 5280 milliseconds (since JVM startup). ... Retrieve Metrics The metrics service rejects attempts to access metrics on behalf of a disallowed origin. <markup lang=\"bash\" >curl -i -H \"Origin: http://other.com\" http://localhost:8080/metrics <markup lang=\"listing\" >HTTP/1.1 403 Forbidden Date: Mon, 11 May 2020 11:08:09 -0500 transfer-encoding: chunked connection: keep-alive But accesses from foo.com succeed. <markup lang=\"bash\" >curl -i -H \"Origin: http://foo.com\" http://localhost:8080/metrics <markup lang=\"listing\" >HTTP/1.1 200 OK Access-Control-Allow-Origin: http://foo.com Content-Type: text/plain Date: Mon, 11 May 2020 11:08:16 -0500 Vary: Origin connection: keep-alive content-length: 6065 # TYPE base_classloader_loadedClasses_count gauge # HELP base_classloader_loadedClasses_count Displays the number of classes that are currently loaded in the Java virtual machine. base_classloader_loadedClasses_count 3568 Retrieve Health The health service rejects requests from origins not specifically approved. <markup lang=\"bash\" >curl -i -H \"Origin: http://foo.com\" http://localhost:8080/health <markup lang=\"listing\" >HTTP/1.1 403 Forbidden Date: Mon, 11 May 2020 12:06:55 -0500 transfer-encoding: chunked connection: keep-alive And responds successfully only to cross-origin requests from http://there.com . <markup lang=\"bash\" >curl -i -H \"Origin: http://there.com\" http://localhost:8080/health <markup lang=\"listing\" >HTTP/1.1 200 OK Access-Control-Allow-Origin: http://there.com Content-Type: application/json Date: Mon, 11 May 2020 12:07:32 -0500 Vary: Origin connection: keep-alive content-length: 461 {\"outcome\":\"UP\",...} ",
            "title": "Additional Information"
        },
        {
            "location": "/mp/cors/why-options",
            "text": " There are some good reasons why it is @OPTIONS methods that you decorate with the Helidon MP @CrossOrigin annotation. Take an informal look at the rationale for this choice. ",
            "title": "preambule"
        },
        {
            "location": "/mp/cors/why-options",
            "text": " At the heart of cross-origin resource sharing is the resource itself. CORS lets you control how a given resource should be shared among various origins. All the attributes of CORS&#8201;&#8212;&#8201;whether authentication should be used, what headers can be passed through on CORS-controlled requests, and so on&#8201;&#8212;&#8201;pertain to a given resource. In Helidon MP, the parameters defined on the @CrossOrigin annotation map directly to those CORS sharing attributes. It would be natural, then, to use @CrossOrigin to annotate the single Java element in the application that represents a resource. ",
            "title": "The Resource"
        },
        {
            "location": "/mp/cors/why-options",
            "text": " Unfortunately, there is no single Java element that is sure to correspond one-to-one with a JAX-RS resource, for two reasons. JAX-RS allows a resource class to define one or more subresources, denoted by the @Path annotation on methods. So a resource class does not necessarily represent only a single resource. A JAX-RS resource class can contain multiple endpoints for the same resource. A common example is two methods, annotated with @GET and @PUT respectively, that have the same path. Although no single endpoint method by itself fully represents the resource, at least each endpoint method maps to exactly one resource. So we could annotate any one of those endpoint methods with @CrossOrigin and unambiguously link the CORS behavior that the annotation defines to the resource. But which endpoint method, and why? ",
            "title": "Methods, Resources, and Subresources in JAX-RS Resource Classes"
        },
        {
            "location": "/mp/cors/why-options",
            "text": " The OPTIONS HTTP method plays an important role in CORS. While the CORS protocol applies to all HTTP methods, it relies on OPTIONS &#8201;&#8212;&#8201;with suitable headers&#8201;&#8212;&#8201;to represent CORS pre-flight requests. From that point of view, the OPTIONS HTTP method has a more prominent place in CORS than the other methods. In a JAX-RS resource class, the @OPTIONS annotation denotes which endpoint method should receive incoming OPTIONS HTTP requests for a resource. Therefore, we could view a Java method annotated with @OPTIONS as somewhat distinguished in the same way that we think of the OPTIONS HTTP method as distinguished within the CORS protocol. Furthermore, there is this technical detail: Helidon MP uses a JAX-RS filter internally to gather information about each @CrossOrigin annotation. Some JAX-RS implementations do not provide the filter with what it needs to find and introspect the @CrossOrigin annotation unless the application itself implements the @OPTIONS endpoint for the resource. ",
            "title": " OPTIONS in CORS, @OPTIONS in JAX-RS, and Technical Reality"
        },
        {
            "location": "/mp/cors/why-options",
            "text": " If you want a resource to participate in CORS, Helidon MP needs you to implement the @OPTIONS endpoint method for the resource, even if the method does nothing. Given that you have to write that method, and given that any endpoint method uniquely identifies its resource, the @OPTIONS method is a reasonable place to ask you to annotate with @CrossOrigin . ",
            "title": "The Bottom Line"
        },
        {
            "location": "/mp/fault-tolerance",
            "text": " Overview Maven Coordinates API Configuration Examples Additional Information Reference ",
            "title": "Contents"
        },
        {
            "location": "/mp/fault-tolerance",
            "text": " Fault Tolerance is part of the MicroProfile set of specifications. This API defines mostly annotations that improve application robustness by providing support to conveniently handle error conditions (faults) that may occur in real-world applications. Examples include service restarts, network delays, temporal infrastructure instabilities, etc. ",
            "title": "Overview"
        },
        {
            "location": "/mp/fault-tolerance",
            "text": " To enable MicroProfile Fault Tolerance either add a dependency on the helidon-microprofile bundle or add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-fault-tolerance&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/fault-tolerance",
            "text": " The MicroProfile Fault Tolerance specification defines a set of annotations to decorate classes and methods in your application for the purpose of improving its robustness. Many of these annotations can be applied at the class or method level: if applied at the class level, they will impact all methods in the class; if applied both at the class and method level, the latter will take precedence over the former. The following table provides a brief description of each of these annotations, including its parameters and default values. <div class=\"table__overflow elevation-1 flex sm10 \"> Annotation Description @Retry( maxRetries=3, delay=0, delayUnit=ChronoUnit.MILLIS, maxDuration=180000, durationUnit=ChronoUnit.MILLIS, jitter=200, jitterDelayUnit=ChronoUnit.MILLIS, retryOn={Exception.class}, abortOn={} ) Retries the execution of a method if a failure is encountered. Annotation attributes can be used to control the number of retries, delay between retries and which exceptions to retry or abort on. @Timeout( value=1000, unit=ChronoUnit.MILLIS ) Defines an upper bound on a method&#8217;s execution time. Default value is 1 second. @CircuitBreaker( failOn={Throwable.class}, skipOn={}, delay=5000, delayUnit=ChronoUnit.MILLIS, requestVolumeThreshold=20, failureRation=.50, successThreshold=1 ) Defines a policy to avoid repeated execution of logic that is likely to fail. A circuit breaker can be closed , open or half-open . In closed state a circuit breaker will execute logic normally. In open state a circuit breaker will prevent execution of logic that has been seen to fail. Finally, in half-open state a circuit breaker will allow trial executions in an attempt to switch its internal state to closed . The other annotation parameters are used to control how these state transitions are triggered. @Bulkhead( value=10, waitingTaskQueue=10 ) Defines a policy to limit the number of concurrent executions allowed over some application logic. A queue is used to park tasks awaiting execution after the limit has been reached. A queue is only active when invocations are @Asynchronous . @Fallback( value=DEFAULT.class, fallbackMethod=\"\", applyOn={Throwable.class}, skipOn={} ) Establishes a handler to be executed upon encountering an invocation failure. A handler is either a class that implements FallbackHandler&lt;T&gt; or just a simple method in the same class. Additional properties are used to control the conditions under which these handlers are called. @Asynchronous Executes an invocation asynchronously without blocking the calling thread. Annotated method must return Future or CompletionStage . Typically used to avoid blocking the calling thread on I/O or on a long-running computation. ",
            "title": "API"
        },
        {
            "location": "/mp/fault-tolerance",
            "text": " Helidon&#8217;s implementation uses two types of thread pools: normal and scheduled. The default core size of these executors is 20; however, that can be configured using an application.yaml file as follows: <markup lang=\"yaml\" >executor: core-pool-size: 32 scheduled-executor: core-pool-size: 32 There is currently no support to configure these executor properties via a microprofile-config.properties file. For a complete set of properties available to configure these executors, see ServerThreadPoolSupplier and ScheduledThreadPoolSupplier . ",
            "title": "Configuration"
        },
        {
            "location": "/mp/fault-tolerance",
            "text": " The method retryWithFallback shall be called at most 3 times, first call plus 2 retries, with a delay of 400 milliseconds between calls. If none of the calls is successful, the onFailure method shall be called as a fallback mechanism. <markup lang=\"java\" >@Retry(maxRetries = 2, delay = 400L) @Fallback(fallbackMethod = \"onFailure\") String retryWithFallback() { //... } The method timedCircuitBreaker defines a rolling window of size 10 and a policy to open the circuit breaker after 4 or more failures occur in that window, and to transition back to half-open state after 3 consecutive and successful runs. Additionally, it sets an overall timeout for the invocation of 1.5 seconds. <markup lang=\"java\" >@Timeout(1500) @CircuitBreaker(requestVolumeThreshold = 10, failureRatio = .4 successThreshold = 3) void timedCircuitBreaker() throws InterruptedException { //... } The method executeWithQueueAndFallback defines a bulkhead that will limit the number of concurrent calls to a maximum of 2; any additional tasks shall be queued up to a maximum of 10. Finally, if an error occurs the onFailure method shall be called as a fallback mechanism. The @Asynchronous annotation is needed to enable queueing of bulkhead tasks. <markup lang=\"java\" >@Asynchronous @Fallback(fallbackMethod = \"onFailure\") @Bulkhead(value = 2, waitingTaskQueue = 10) CompletableFuture&lt;String&gt; executeWithQueueAndFallback() { //... } ",
            "title": "Examples"
        },
        {
            "location": "/mp/fault-tolerance",
            "text": " For additional information about this API, see the MicroProfile Fault Tolerance Javadocs . ",
            "title": "Additional Information"
        },
        {
            "location": "/mp/fault-tolerance",
            "text": " MicroProfile Fault Tolerance ",
            "title": "Reference"
        },
        {
            "location": "/mp/graphql",
            "text": " Overview Maven Coordinates API Configuration Examples Additional Information Reference ",
            "title": "Contents"
        },
        {
            "location": "/mp/graphql",
            "text": " Helidon MP implements the MicroProfile GraphQL specification . This specifcation describes how applications can be built to expose an endpoint for GraphQL. GraphQL is an open-source data query and manipulation language for APIs, and a runtime for fulfilling data queries. It provides an alternative to, though not necessarily a replacement for, REST. ",
            "title": "Overview"
        },
        {
            "location": "/mp/graphql",
            "text": " To enable MicroProfile GraphQL add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.graphql&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-graphql-server&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/graphql",
            "text": " As part of building your application, you must create a Jandex index using the jandex-maven-plugin for all API and POJO classes. <markup lang=\"xml\" title=\"Generate Jandex index\" >&lt;plugin&gt; &lt;groupId&gt;io.smallrye&lt;/groupId&gt; &lt;artifactId&gt;jandex-maven-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;make-index&lt;/id&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; As per the instructions here ensure you have added a src/main/resources/META-INF/beans.xml file, so the CDI implementation can pick up your classes. ",
            "title": "Building your application"
        },
        {
            "location": "/mp/graphql",
            "text": " After starting your application you should see a log message indicating that GraphQL is in the list of features. You can access the GraphQL endpoint at http://host:port/graphql , and the corresponding schema at http://host:port/graphql/schema.graphql . See for additional information on how to change the location of these resources. If you wish to use the GraphQL UI then please see the GraphQL MP Example . ",
            "title": "Accessing the GraphQL endpoints"
        },
        {
            "location": "/mp/graphql",
            "text": " The MicroProfile GraphQL specification defines a number of key annotations to be used when writing a GraphQL endpoint: @GraphQLApi - identifies a CDI Bean as a GraphQL endpoint @Query - identifies a method as returning one or more entities @Mutation - identifies a method which creates, deletes or updates entities For example, the following defines a GraphQL endpoint with a number of queries and mutations that work against a fictional CustomerService service and Customer class. <markup lang=\"java\" title=\"Simple ContactGraphQLApi\" >@ApplicationScoped @GraphQLApi public class ContactGraphQLApi { @Inject private CustomerService customerService; @Query public Collection&lt;Customer&gt; findAllCustomers() { return customerService.getAllCustomers(); } @Query public Customer findCustomer(@Name(\"customerId\") int id) { return customerService.getCustomer(id); } @Query public Collection&lt;Customer&gt; findCustomersByName(@Name(\"name\") String name) { return customerService.getAllCustomers(name); } @Mutation public Contact createCustomer(@Name(\"customerId\") int id, @Name(\"name\") String name, @Name(\"balance\") float balance) { return customerService.createCustomer(id, name, balance); } } public class customer { private int id; @NonNull private String name; private float balance; // getters and setters omitted for brevity } a query with no-arguments that will return all Customer s a query that takes an argument to return a specific Customer a query that optionally takes a name and returns a collection of Customer s a mutation that creates a Customer and returns the newly created Customer The example above would generate a GraphQL schema as shown below: <markup lang=\"graphql\" title=\"Sample GraphQL schema\" >type Query { findAllCustomers: [Customer] findCustomer(customerId: Int!): Customer findCustomersByName(name: String): [Customers] } type Mutation { createCustomer(customerId: Int!, name: String!, balance: Float!): Customer } type Customer { id: Int! name: String! balance: Float } After application startup, a GraphQL schema will be generated from your annotated API classes and POJO&#8217;s and you will be able to access these via the URLs described below. Building your application As part of building your application, you must create a Jandex index using the jandex-maven-plugin for all API and POJO classes. <markup lang=\"xml\" title=\"Generate Jandex index\" >&lt;plugin&gt; &lt;groupId&gt;io.smallrye&lt;/groupId&gt; &lt;artifactId&gt;jandex-maven-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;make-index&lt;/id&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; As per the instructions here ensure you have added a src/main/resources/META-INF/beans.xml file, so the CDI implementation can pick up your classes. Accessing the GraphQL endpoints After starting your application you should see a log message indicating that GraphQL is in the list of features. You can access the GraphQL endpoint at http://host:port/graphql , and the corresponding schema at http://host:port/graphql/schema.graphql . See for additional information on how to change the location of these resources. If you wish to use the GraphQL UI then please see the GraphQL MP Example . ",
            "title": "API"
        },
        {
            "location": "/mp/graphql",
            "text": " The specification defines the following configuration options: key default value description mp.graphql.defaultErrorMessage Server Error Error message to send to caller in case of error mp.graphql.exceptionsBlackList &#160; Array of checked exception classes that should return default error message mp.graphql.exceptionsWhiteList &#160; Array of unchecked exception classes that should return message to caller (instead of default error message) The following configuration keys can be used to set up integration with WebServer: key default value description graphql.web-context /graphql Context that serves the GraphQL endpoint. graphql.schema-uri /schema.graphql URI that serves the schema (under web context) graphql.cors &#160; CORS configuration for this service graphql.executor-service &#160; Configuration of ServerThreadPoolSupplier used to set up executor service The following configuration keys can be used to set up GraphQL invocation: key default value description graphql.default-error-message Server Error Error message to send to caller in case of error graphql.exception-white-list &#160; Array of checked exception classes that should return default error message graphql.exception-black-list &#160; Array of unchecked exception classes that should return message to caller (instead of default error message) ",
            "title": "Configuration"
        },
        {
            "location": "/mp/graphql",
            "text": " For a complete example, see GraphQL MP Example . ",
            "title": "Examples"
        },
        {
            "location": "/mp/graphql",
            "text": " GraphQL . ",
            "title": "Additional Information"
        },
        {
            "location": "/mp/graphql",
            "text": " MicroProfile GraphQL Javadocs . ",
            "title": "Reference"
        },
        {
            "location": "/mp/grpc/client",
            "text": " Overview ",
            "title": "Contents"
        },
        {
            "location": "/mp/grpc/client",
            "text": " gRPC is temporarily removed in Helidon, please follow issue https://github.com/helidon-io/helidon/issues/5418 If you require gRPC in Helidon MP, kindly stay with Helidon MP 3.x, until the issue is resolved. ",
            "title": "Overview"
        },
        {
            "location": "/mp/grpc/server",
            "text": " Overview ",
            "title": "Contents"
        },
        {
            "location": "/mp/grpc/server",
            "text": " gRPC is temporarily removed in Helidon, please follow issue https://github.com/helidon-io/helidon/issues/5418 If you require gRPC in Helidon MP, kindly stay with Helidon MP 3.x, until the issue is resolved. ",
            "title": "Overview"
        },
        {
            "location": "/mp/guides/config",
            "text": " This guide describes how to create a sample MicroProfile (MP) project that can be used to run some basic examples using both default and custom configuration with Helidon MP. ",
            "title": "preambule"
        },
        {
            "location": "/mp/guides/config",
            "text": " For this 20 minute tutorial, you will need the following: <div class=\"table__overflow elevation-1 flex sm7 \"> A Helidon MP Application You can use your own application or use the Helidon MP Quickstart to create a sample application. Java&#160;SE&#160;21 ( Open&#160;JDK&#160;21 ) Helidon requires Java 21+. Maven 3.8+ Helidon requires Maven 3.8+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop . <markup lang=\"bash\" title=\"Verify Prerequisites\" >java -version mvn --version docker --version kubectl version --short <markup lang=\"bash\" title=\"Setting JAVA_HOME\" ># On Mac export JAVA_HOME=`/usr/libexec/java_home -v 21` # On Linux # Use the appropriate path to your JDK export JAVA_HOME=/usr/lib/jvm/jdk-21 ",
            "title": "What You Need"
        },
        {
            "location": "/mp/guides/config",
            "text": " Use the Helidon MP Maven archetype to create a simple project that can be used for the examples in this guide. <markup lang=\"bash\" title=\"Run the Maven archetype:\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-mp \\ -DarchetypeVersion=4.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-mp \\ -Dpackage=io.helidon.examples.quickstart.mp <markup lang=\"bash\" title=\"The project will be built and run from the helidon-quickstart-mp directory:\" >cd helidon-quickstart-mp ",
            "title": "Create a Sample Helidon MP Project"
        },
        {
            "location": "/mp/guides/config",
            "text": " Helidon has an internal configuration, so you are not required to provide any configuration data for your application, though in practice you most likely would. By default, that configuration can be overridden from three sources: system properties, environment variables, and the contents of META-INF/microprofile-config.properties . For example, if you specify a custom server port in META-INF/microprofile-config.properties then your server will listen on that port. A main class is also required to start up the server and run the application. By default, the Quickstart sample project uses the built-in Helidon main class. In this guide you want to use your own main class, so you have more control over the server initialization. First define your own Main : <markup lang=\"java\" title=\"src/main/java/io/helidon/examples/quickstart/mp/Main.java\" >package io.helidon.examples.quickstart.mp; import io.helidon.microprofile.server.Server; import java.io.IOException; public final class Main { private Main() { } public static void main(final String[] args) { Server server = startServer(); System.out.println(\"http://localhost:\" + server.port() + \"/greet\"); } static Server startServer() { return Server.create().start(); } } In this class, a main method is defined which starts the Helidon MP server and prints out a message with the listen address. Notice that this class has an empty no-args constructor to make sure this class cannot be instantiated. The MicroProfile server is started with the default configuration. Next change the project&#8217;s pom.xml to use your main class: <markup lang=\"xml\" title=\"pom.xml\" > &lt;properties&gt; &lt;mainClass&gt;io.helidon.examples.quickstart.mp.Main&lt;/mainClass&gt; &lt;/properties&gt; This property will be used to set the Main-Class attribute in the application jar&#8217;s MANIFEST. In your application code, Helidon uses the default configuration when you create a Server object without a custom Config object. See the following code from the project you created. <markup lang=\"Java\" title=\"View Main.startServer :\" > static Server startServer() { return Server.create().start(); } There is no Config object being used during server creation, so the default configuration is used. ",
            "title": "Default Configuration"
        },
        {
            "location": "/mp/guides/config",
            "text": " An environment variable has a higher precedence than the configuration properties file. <markup lang=\"bash\" title=\"Set the environment variable and restart the application:\" >export APP_GREETING=HelloFromEnvironment java -jar target/helidon-quickstart-mp.jar <markup lang=\"bash\" title=\"Invoke the endpoint below and check the response:\" >curl http://localhost:8080/greet <markup lang=\"json\" >{ \"message\": \"HelloFromEnvironment World!\" } The environment variable took precedence over the value in META-INF/microprofile-config.properties . ",
            "title": "Environment Variable Override"
        },
        {
            "location": "/mp/guides/config",
            "text": " A system property has a higher precedence than environment variables. <markup lang=\"bash\" title=\"Restart the application with a system property. The app.greeting environment variable is still set:\" >java -Dapp.greeting=\"HelloFromSystemProperty\" -jar target/helidon-quickstart-mp.jar <markup lang=\"bash\" title=\"Invoke the endpoint below and check the response:\" >curl http://localhost:8080/greet <markup lang=\"json\" >{ \"message\": \"HelloFromSystemProperty World!\" } The system property took precedence over both the environment variable and META-INF/microprofile-config.properties . ",
            "title": "System Property Override"
        },
        {
            "location": "/mp/guides/config",
            "text": " Change a configuration parameter in the default configuration resource file, META-INF/microprofile-config.properties . There are no environment variable or system property overrides defined. <markup lang=\"bash\" title=\"Change app.greeting in the META-INF/microprofile-config.properties from Hello to HelloFromMPConfig :\" >app.greeting=HelloFromMPConfig <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-mp.jar <markup lang=\"bash\" title=\"Run the curl command in a new terminal window and check the response:\" >curl http://localhost:8080/greet <markup lang=\"json\" >{ \"message\": \"HelloFromMPConfig World!\" } The new app.greeting value in META-INF/microprofile-config.properties is used. Environment Variable Override An environment variable has a higher precedence than the configuration properties file. <markup lang=\"bash\" title=\"Set the environment variable and restart the application:\" >export APP_GREETING=HelloFromEnvironment java -jar target/helidon-quickstart-mp.jar <markup lang=\"bash\" title=\"Invoke the endpoint below and check the response:\" >curl http://localhost:8080/greet <markup lang=\"json\" >{ \"message\": \"HelloFromEnvironment World!\" } The environment variable took precedence over the value in META-INF/microprofile-config.properties . System Property Override A system property has a higher precedence than environment variables. <markup lang=\"bash\" title=\"Restart the application with a system property. The app.greeting environment variable is still set:\" >java -Dapp.greeting=\"HelloFromSystemProperty\" -jar target/helidon-quickstart-mp.jar <markup lang=\"bash\" title=\"Invoke the endpoint below and check the response:\" >curl http://localhost:8080/greet <markup lang=\"json\" >{ \"message\": \"HelloFromSystemProperty World!\" } The system property took precedence over both the environment variable and META-INF/microprofile-config.properties . ",
            "title": "Default Configuration Resource"
        },
        {
            "location": "/mp/guides/config",
            "text": " In order to properly configure your application using configuration sources, you need to understand the precedence rules that Helidon uses to merge your configuration data. By default, Helidon will use the following sources in precedence order: Java system properties Environment variables Properties specified in META-INF/microprofile-config.properties Each of these sources specify configuration properties in Java Property format (key/value), like color=red . If any of the Helidon required properties are not specified in one of these source, like server.port , then Helidon will use a default value. Because environment variable names are restricted to alphanumeric characters and underscores, Helidon adds aliases to the environment configuration source, allowing entries with dotted and/or hyphenated keys to be overridden. For example, this mapping allows an environment variable named \"APP_GREETING\" to override an entry key named \"app.greeting\". In the same way, an environment variable named \"APP_dash_GREETING\" will map to \"app-greeting\". See Microprofile Config Specifications for more information. The following examples will demonstrate the default precedence order. Default Configuration Resource Change a configuration parameter in the default configuration resource file, META-INF/microprofile-config.properties . There are no environment variable or system property overrides defined. <markup lang=\"bash\" title=\"Change app.greeting in the META-INF/microprofile-config.properties from Hello to HelloFromMPConfig :\" >app.greeting=HelloFromMPConfig <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-mp.jar <markup lang=\"bash\" title=\"Run the curl command in a new terminal window and check the response:\" >curl http://localhost:8080/greet <markup lang=\"json\" >{ \"message\": \"HelloFromMPConfig World!\" } The new app.greeting value in META-INF/microprofile-config.properties is used. Environment Variable Override An environment variable has a higher precedence than the configuration properties file. <markup lang=\"bash\" title=\"Set the environment variable and restart the application:\" >export APP_GREETING=HelloFromEnvironment java -jar target/helidon-quickstart-mp.jar <markup lang=\"bash\" title=\"Invoke the endpoint below and check the response:\" >curl http://localhost:8080/greet <markup lang=\"json\" >{ \"message\": \"HelloFromEnvironment World!\" } The environment variable took precedence over the value in META-INF/microprofile-config.properties . System Property Override A system property has a higher precedence than environment variables. <markup lang=\"bash\" title=\"Restart the application with a system property. The app.greeting environment variable is still set:\" >java -Dapp.greeting=\"HelloFromSystemProperty\" -jar target/helidon-quickstart-mp.jar <markup lang=\"bash\" title=\"Invoke the endpoint below and check the response:\" >curl http://localhost:8080/greet <markup lang=\"json\" >{ \"message\": \"HelloFromSystemProperty World!\" } The system property took precedence over both the environment variable and META-INF/microprofile-config.properties . ",
            "title": "Source Precedence for Default Configuration"
        },
        {
            "location": "/mp/guides/config",
            "text": " Helidon provides a very flexible and comprehensive configuration system, offering you many application configuration choices. You can include configuration data from a variety of sources using different formats, like JSON and YAML. Furthermore, you can customize the precedence of sources and make them optional or mandatory. This guide introduces Helidon MP configuration and demonstrates the fundamental concepts using several examples. Refer to Helidon Config for the full configuration concepts documentation. Create a Sample Helidon MP Project Use the Helidon MP Maven archetype to create a simple project that can be used for the examples in this guide. <markup lang=\"bash\" title=\"Run the Maven archetype:\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-mp \\ -DarchetypeVersion=4.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-mp \\ -Dpackage=io.helidon.examples.quickstart.mp <markup lang=\"bash\" title=\"The project will be built and run from the helidon-quickstart-mp directory:\" >cd helidon-quickstart-mp Default Configuration Helidon has an internal configuration, so you are not required to provide any configuration data for your application, though in practice you most likely would. By default, that configuration can be overridden from three sources: system properties, environment variables, and the contents of META-INF/microprofile-config.properties . For example, if you specify a custom server port in META-INF/microprofile-config.properties then your server will listen on that port. A main class is also required to start up the server and run the application. By default, the Quickstart sample project uses the built-in Helidon main class. In this guide you want to use your own main class, so you have more control over the server initialization. First define your own Main : <markup lang=\"java\" title=\"src/main/java/io/helidon/examples/quickstart/mp/Main.java\" >package io.helidon.examples.quickstart.mp; import io.helidon.microprofile.server.Server; import java.io.IOException; public final class Main { private Main() { } public static void main(final String[] args) { Server server = startServer(); System.out.println(\"http://localhost:\" + server.port() + \"/greet\"); } static Server startServer() { return Server.create().start(); } } In this class, a main method is defined which starts the Helidon MP server and prints out a message with the listen address. Notice that this class has an empty no-args constructor to make sure this class cannot be instantiated. The MicroProfile server is started with the default configuration. Next change the project&#8217;s pom.xml to use your main class: <markup lang=\"xml\" title=\"pom.xml\" > &lt;properties&gt; &lt;mainClass&gt;io.helidon.examples.quickstart.mp.Main&lt;/mainClass&gt; &lt;/properties&gt; This property will be used to set the Main-Class attribute in the application jar&#8217;s MANIFEST. In your application code, Helidon uses the default configuration when you create a Server object without a custom Config object. See the following code from the project you created. <markup lang=\"Java\" title=\"View Main.startServer :\" > static Server startServer() { return Server.create().start(); } There is no Config object being used during server creation, so the default configuration is used. Source Precedence for Default Configuration In order to properly configure your application using configuration sources, you need to understand the precedence rules that Helidon uses to merge your configuration data. By default, Helidon will use the following sources in precedence order: Java system properties Environment variables Properties specified in META-INF/microprofile-config.properties Each of these sources specify configuration properties in Java Property format (key/value), like color=red . If any of the Helidon required properties are not specified in one of these source, like server.port , then Helidon will use a default value. Because environment variable names are restricted to alphanumeric characters and underscores, Helidon adds aliases to the environment configuration source, allowing entries with dotted and/or hyphenated keys to be overridden. For example, this mapping allows an environment variable named \"APP_GREETING\" to override an entry key named \"app.greeting\". In the same way, an environment variable named \"APP_dash_GREETING\" will map to \"app-greeting\". See Microprofile Config Specifications for more information. The following examples will demonstrate the default precedence order. Default Configuration Resource Change a configuration parameter in the default configuration resource file, META-INF/microprofile-config.properties . There are no environment variable or system property overrides defined. <markup lang=\"bash\" title=\"Change app.greeting in the META-INF/microprofile-config.properties from Hello to HelloFromMPConfig :\" >app.greeting=HelloFromMPConfig <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-mp.jar <markup lang=\"bash\" title=\"Run the curl command in a new terminal window and check the response:\" >curl http://localhost:8080/greet <markup lang=\"json\" >{ \"message\": \"HelloFromMPConfig World!\" } The new app.greeting value in META-INF/microprofile-config.properties is used. Environment Variable Override An environment variable has a higher precedence than the configuration properties file. <markup lang=\"bash\" title=\"Set the environment variable and restart the application:\" >export APP_GREETING=HelloFromEnvironment java -jar target/helidon-quickstart-mp.jar <markup lang=\"bash\" title=\"Invoke the endpoint below and check the response:\" >curl http://localhost:8080/greet <markup lang=\"json\" >{ \"message\": \"HelloFromEnvironment World!\" } The environment variable took precedence over the value in META-INF/microprofile-config.properties . System Property Override A system property has a higher precedence than environment variables. <markup lang=\"bash\" title=\"Restart the application with a system property. The app.greeting environment variable is still set:\" >java -Dapp.greeting=\"HelloFromSystemProperty\" -jar target/helidon-quickstart-mp.jar <markup lang=\"bash\" title=\"Invoke the endpoint below and check the response:\" >curl http://localhost:8080/greet <markup lang=\"json\" >{ \"message\": \"HelloFromSystemProperty World!\" } The system property took precedence over both the environment variable and META-INF/microprofile-config.properties . ",
            "title": "Getting Started with Configuration"
        },
        {
            "location": "/mp/guides/config",
            "text": " You can inject configuration at the field level as shown below. Use the volatile keyword since you cannot use AtomicReference with field level injection. <markup lang=\"yaml\" title=\"Update the meta-config.yaml with the following contents:\" >sources: - type: \"classpath\" properties: resource: \"META-INF/microprofile-config.properties\" This example only uses the default classpath source. <markup lang=\"java\" title=\"Update the following code from GreetingProvider.java :\" >@ApplicationScoped public class GreetingProvider { @Inject @ConfigProperty(name = \"app.greeting\") private volatile String message; String getMessage() { return message; } void setMessage(String message) { this.message = message; } } Inject the value of app.greeting into the GreetingProvider object. Define a class member variable to hold the greeting. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet <markup lang=\"json\" >{ \"message\": \"HelloFromMPConfig World!\" } ",
            "title": "Injecting at Field Level"
        },
        {
            "location": "/mp/guides/config",
            "text": " You can inject the Config object into the class and access it directly as shown below. <markup lang=\"java\" title=\"Update the GreetingProvider.java file; 1) Add new imports and 2) Replace the GreetingProvider class:\" > import io.helidon.config.Config; import jakarta.enterprise.context.Initialized; import jakarta.enterprise.event.Observes; @ApplicationScoped public class GreetingProvider { private final AtomicReference&lt;String&gt; message = new AtomicReference&lt;&gt;(); @Inject public GreetingProvider(Config config) { String message = config.get(\"app.greeting\").asString().get(); this.message.set(message); } String getMessage() { return message.get(); } void setMessage(String message) { this.message.set(message); } } Add three new imports. Inject the Config object into the GreetingProvider object. Get the app.greeting value from the Config object and set the member variable. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet <markup lang=\"json\" >{ \"message\": \"HelloFromMPConfig World!\" } ",
            "title": "Injecting the Config Object"
        },
        {
            "location": "/mp/guides/config",
            "text": " Helidon offers a variety of methods to access in-memory configuration. These can be categorized as key access or tree navigation . You have been using key access for all the examples to this point. For example app.greeting is accessing the greeting child node of the app parent node. This simple example below demonstrates how to access a child node as a detached configuration subtree. <markup lang=\"yaml\" title=\"Create a file config-file.yaml in the helidon-quickstart-mp directory and add the following contents:\" >app: greeting: sender: Joe message: Hello-from-config-file.yaml <markup lang=\"yaml\" title=\"Update the meta-config.yaml with the following contents:\" >sources: - type: \"classpath\" properties: resource: \"META-INF/microprofile-config.properties\" - type: \"file\" properties: path: \"./config-file.yaml\" <markup lang=\"java\" title=\"Replace GreetingProvider class with the following code:\" >@ApplicationScoped public class GreetingProvider { private final AtomicReference&lt;String&gt; message = new AtomicReference&lt;&gt;(); private final AtomicReference&lt;String&gt; sender = new AtomicReference&lt;&gt;(); @Inject Config config; public void onStartUp(@Observes @Initialized(ApplicationScoped.class) Object init) { Config appNode = config.get(\"app.greeting\"); message.set(appNode.get(\"message\").asString().get()); sender.set(appNode.get(\"sender\").asString().get()); } String getMessage() { return sender.get() + \" says \" + message.get(); } void setMessage(String message) { this.message.set(message); } } Get the configuration subtree where the app.greeting node is the root. Get the value from the message Config node. Get the value from the sender Config node. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet <markup lang=\"json\" >{ \"message\": \"Joe says Hello-from-config-file.yaml World!\" } ",
            "title": "Navigating the Config Tree"
        },
        {
            "location": "/mp/guides/config",
            "text": " The examples in this section will demonstrate how to access that config data at runtime. Your application uses the Config object to access the in-memory tree, retrieving config data. The generated project already accesses configuration data in the GreetingProvider class as follows: <markup lang=\"java\" title=\"View the following code from GreetingProvider.java :\" >@ApplicationScoped public class GreetingProvider { private final AtomicReference&lt;String&gt; message = new AtomicReference&lt;&gt;(); @Inject public GreetingProvider(@ConfigProperty(name = \"app.greeting\") String message) { this.message.set(message); } String getMessage() { return message.get(); } void setMessage(String message) { this.message.set(message); } } This class is application scoped so a single instance of GreetingProvider will be shared across the entire application. Define a thread-safe reference that will refer to the message member variable. The value of the configuration property app.greeting is injected into the GreetingProvider . constructor as a String parameter named message . Injecting at Field Level You can inject configuration at the field level as shown below. Use the volatile keyword since you cannot use AtomicReference with field level injection. <markup lang=\"yaml\" title=\"Update the meta-config.yaml with the following contents:\" >sources: - type: \"classpath\" properties: resource: \"META-INF/microprofile-config.properties\" This example only uses the default classpath source. <markup lang=\"java\" title=\"Update the following code from GreetingProvider.java :\" >@ApplicationScoped public class GreetingProvider { @Inject @ConfigProperty(name = \"app.greeting\") private volatile String message; String getMessage() { return message; } void setMessage(String message) { this.message = message; } } Inject the value of app.greeting into the GreetingProvider object. Define a class member variable to hold the greeting. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet <markup lang=\"json\" >{ \"message\": \"HelloFromMPConfig World!\" } Injecting the Config Object You can inject the Config object into the class and access it directly as shown below. <markup lang=\"java\" title=\"Update the GreetingProvider.java file; 1) Add new imports and 2) Replace the GreetingProvider class:\" > import io.helidon.config.Config; import jakarta.enterprise.context.Initialized; import jakarta.enterprise.event.Observes; @ApplicationScoped public class GreetingProvider { private final AtomicReference&lt;String&gt; message = new AtomicReference&lt;&gt;(); @Inject public GreetingProvider(Config config) { String message = config.get(\"app.greeting\").asString().get(); this.message.set(message); } String getMessage() { return message.get(); } void setMessage(String message) { this.message.set(message); } } Add three new imports. Inject the Config object into the GreetingProvider object. Get the app.greeting value from the Config object and set the member variable. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet <markup lang=\"json\" >{ \"message\": \"HelloFromMPConfig World!\" } Navigating the Config Tree Helidon offers a variety of methods to access in-memory configuration. These can be categorized as key access or tree navigation . You have been using key access for all the examples to this point. For example app.greeting is accessing the greeting child node of the app parent node. This simple example below demonstrates how to access a child node as a detached configuration subtree. <markup lang=\"yaml\" title=\"Create a file config-file.yaml in the helidon-quickstart-mp directory and add the following contents:\" >app: greeting: sender: Joe message: Hello-from-config-file.yaml <markup lang=\"yaml\" title=\"Update the meta-config.yaml with the following contents:\" >sources: - type: \"classpath\" properties: resource: \"META-INF/microprofile-config.properties\" - type: \"file\" properties: path: \"./config-file.yaml\" <markup lang=\"java\" title=\"Replace GreetingProvider class with the following code:\" >@ApplicationScoped public class GreetingProvider { private final AtomicReference&lt;String&gt; message = new AtomicReference&lt;&gt;(); private final AtomicReference&lt;String&gt; sender = new AtomicReference&lt;&gt;(); @Inject Config config; public void onStartUp(@Observes @Initialized(ApplicationScoped.class) Object init) { Config appNode = config.get(\"app.greeting\"); message.set(appNode.get(\"message\").asString().get()); sender.set(appNode.get(\"sender\").asString().get()); } String getMessage() { return sender.get() + \" says \" + message.get(); } void setMessage(String message) { this.message.set(message); } } Get the configuration subtree where the app.greeting node is the root. Get the value from the message Config node. Get the value from the sender Config node. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet <markup lang=\"json\" >{ \"message\": \"Joe says Hello-from-config-file.yaml World!\" } ",
            "title": "Accessing Config within an Application"
        },
        {
            "location": "/mp/guides/config",
            "text": " The following example uses a Kubernetes ConfigMap to pass the configuration data to your Helidon application deployed to Kubernetes. When the pod is created, Kubernetes will automatically create a local file within the container that has the contents of the configuration file used for the ConfigMap. This example will create the file at /etc/config/config-file.properties . <markup lang=\"java\" title=\"Update the Main class and replace the buildConfig method:\" >private static Config buildConfig() { return Config.builder() .sources( file(\"/etc/config/config-file.properties\").optional(), classpath(\"META-INF/microprofile-config.properties\")) .build(); } The app.greeting value will be fetched from /etc/config/config-file.properties within the container. The server port is specified in META-INF/microprofile-config.properties within the helidon-quickstart-mp.jar . <markup lang=\"java\" title=\"Update the following code from GreetingProvider.java :\" >@ApplicationScoped public class GreetingProvider { @Inject @ConfigProperty(name = \"app.greeting\") private volatile String message; String getMessage() { return message; } void setMessage(String message) { this.message = message; } } <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet <markup lang=\"json\" >{ \"message\": \"HelloFromConfigFile World!\" } <markup lang=\"bash\" title=\"Stop the application and build the docker image:\" >docker build -t helidon-config-mp . <markup lang=\"bash\" title=\"Generate a ConfigMap from config-file.properties :\" >kubectl create configmap helidon-configmap --from-file config-file.properties <markup lang=\"bash\" title=\"View the contents of the ConfigMap:\" >kubectl get configmap helidon-configmap -o yaml <markup lang=\"yaml\" >apiVersion: v1 data: config-file.properties: | app.greeting=HelloFromConfigFile kind: ConfigMap The file config-file.properties will be created within the Kubernetes container. The config-file.properties file will have this single property defined. <markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named k8s-config.yaml , with the following contents:\" >kind: Service apiVersion: v1 metadata: name: helidon-config labels: app: helidon-config spec: type: NodePort selector: app: helidon-config ports: - port: 8080 targetPort: 8080 name: http --- kind: Deployment apiVersion: apps/v1 metadata: name: helidon-config spec: replicas: 1 selector: matchLabels: app: helidon-config template: metadata: labels: app: helidon-config version: v1 spec: containers: - name: helidon-config image: helidon-config-mp imagePullPolicy: IfNotPresent ports: - containerPort: 8080 volumeMounts: - name: config-volume mountPath: /etc/config volumes: - name: config-volume configMap: # Provide the name of the ConfigMap containing the files you want # to add to the container name: helidon-configmap A service of type NodePort that serves the default routes on port 8080 . A deployment with one replica of a pod. Mount the ConfigMap as a volume at /etc/config . This is where Kubernetes will create config-file.properties . Specify the ConfigMap which contains the configuration data. <markup lang=\"bash\" title=\"Create and deploy the application into Kubernetes:\" >kubectl apply -f ./k8s-config.yaml <markup lang=\"bash\" title=\"Get the service information:\" >kubectl get service/helidon-config <markup lang=\"bash\" >NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE helidon-config NodePort 10.99.159.2 &lt;none&gt; 8080:31143/TCP 8s A service of type NodePort that serves the default routes on port 31143 . <markup lang=\"bash\" title=\"Verify the configuration endpoint using port 31143 , your port will likely be different:\" >curl http://localhost:31143/greet <markup lang=\"json\" >{ \"message\": \"HelloFromConfigFile World!\" } The greeting value from /etc/config/config-file.properties within the container was used. You can now delete the Kubernetes resources that were just created during this example. <markup lang=\"bash\" title=\"Delete the Kubernetes resources:\" >kubectl delete -f ./k8s-config.yaml kubectl delete configmap helidon-configmap ",
            "title": "Integration with Kubernetes"
        },
        {
            "location": "/mp/guides/config",
            "text": " This guide has demonstrated how to use basic Helidon configuration features. For more information about using the advanced Helidon configuration features, including mutability support and extensions, see Helidon Configuration . ",
            "title": "Summary"
        },
        {
            "location": "/mp/guides/config",
            "text": " Refer to the following references for additional information: MicroProfile Config specification MicroProfile Config Javadoc Helidon Javadoc ",
            "title": "References"
        },
        {
            "location": "/mp/guides/graalnative",
            "text": " This guide describes how to build a GraalVM native image for a Helidon MP application. ",
            "title": "preambule"
        },
        {
            "location": "/mp/guides/graalnative",
            "text": " Native images are ahead-of-time compiled Java code that result in a self contained native executable. When used appropriately native images have dramatically faster startup and lower runtime memory overhead compared to a Java VM. In this guide you will learn how to build a native image locally on your machine, as well as using Docker. ",
            "title": "Introduction"
        },
        {
            "location": "/mp/guides/graalnative",
            "text": " For this 10 minute tutorial, you will need the following: <div class=\"table__overflow elevation-1 flex sm7 \"> A Helidon MP Application You can use your own application or use the Helidon MP Quickstart to create a sample application. Java&#160;SE&#160;21 ( Open&#160;JDK&#160;21 ) Helidon requires Java 21+. Maven 3.8+ Helidon requires Maven 3.8+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop . GraalVM for JDK 21 <markup lang=\"bash\" title=\"Verify Prerequisites\" >java -version mvn --version docker --version kubectl version --short <markup lang=\"bash\" title=\"Setting JAVA_HOME\" ># On Mac export JAVA_HOME=`/usr/libexec/java_home -v 21` # On Linux # Use the appropriate path to your JDK export JAVA_HOME=/usr/lib/jvm/jdk-21 ",
            "title": "What You Need"
        },
        {
            "location": "/mp/guides/graalnative",
            "text": " After downloading and installing GraalVM, set the GRAALVM_HOME environment variable to point at your GraalVM installation, or use the GraalVM installation as your Java home. <markup lang=\"bash\" ># Your path might be different export GRAALVM_HOME=/usr/local/graalvm-jdk-21+35.1/Contents/Home/ Then verify: <markup lang=\"bash\" >$GRAALVM_HOME/bin/java -version $GRAALVM_HOME/bin/native-image --version ",
            "title": "Install GraalVM and the Native Image Command"
        },
        {
            "location": "/mp/guides/graalnative",
            "text": " Generate the project using the Helidon MP Quickstart Maven archetype. <markup lang=\"bash\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-mp \\ -DarchetypeVersion=4.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-mp \\ -Dpackage=io.helidon.examples.quickstart.mp The archetype generates a Maven project in your current directory (for example, helidon-quickstart-mp ). Change into this directory and build. <markup lang=\"bash\" >cd helidon-quickstart-mp mvn package At this point you can run the application using the JVM: <markup lang=\"bash\" >java -jar target/helidon-quickstart-mp.jar In another shell test an endpoint: <markup lang=\"bash\" >curl -X GET http://localhost:8080/greet The application should respond with {\"message\":\"Hello World!\"} Now stop the running application (by pressing Ctrl+C). For more information about the Quickstart application and other endpoints it supports see the Helidon MP Quickstart Guide . ",
            "title": "Generate the Project"
        },
        {
            "location": "/mp/guides/graalnative",
            "text": " Make sure you have GraalVM locally installed: <markup lang=\"bash\" >$GRAALVM_HOME/bin/native-image --version Build the native image using the native image profile: <markup lang=\"bash\" >mvn package -Pnative-image Tip This uses the org.graalvm.buildtools:native-maven-plugin to perform the native compilation using your installed copy of GraalVM. It might take a while to complete. Once it completes start the application using the native executable (no JVM!): <markup lang=\"bash\" >./target/helidon-quickstart-mp Yep, it starts fast. You can exercise the application&#8217;s endpoints as before. ",
            "title": "Local build"
        },
        {
            "location": "/mp/guides/graalnative",
            "text": " Build the \"native\" Docker image <markup lang=\"bash\" >docker build -t helidon-quickstart-mp-native -f Dockerfile.native . Tip This does a full build inside the Docker container. The first time you run it, it will take a while because it is downloading all of the Maven dependencies and caching them in a Docker layer. Subsequent builds will be much faster as long as you don&#8217;t change the pom.xml file. If the pom is modified then the dependencies will be re-downloaded. Start the application: <markup lang=\"bash\" >docker run --rm -p 8080:8080 helidon-quickstart-mp-native:latest Again, it starts fast. You can exercise the application&#8217;s endpoints as before. ",
            "title": "Multi-stage Docker build"
        },
        {
            "location": "/mp/guides/graalnative",
            "text": " You can build a native executable in 2 different ways: With a local installation of GraalVM Using Docker Local build Make sure you have GraalVM locally installed: <markup lang=\"bash\" >$GRAALVM_HOME/bin/native-image --version Build the native image using the native image profile: <markup lang=\"bash\" >mvn package -Pnative-image Tip This uses the org.graalvm.buildtools:native-maven-plugin to perform the native compilation using your installed copy of GraalVM. It might take a while to complete. Once it completes start the application using the native executable (no JVM!): <markup lang=\"bash\" >./target/helidon-quickstart-mp Yep, it starts fast. You can exercise the application&#8217;s endpoints as before. Multi-stage Docker build Build the \"native\" Docker image <markup lang=\"bash\" >docker build -t helidon-quickstart-mp-native -f Dockerfile.native . Tip This does a full build inside the Docker container. The first time you run it, it will take a while because it is downloading all of the Maven dependencies and caching them in a Docker layer. Subsequent builds will be much faster as long as you don&#8217;t change the pom.xml file. If the pom is modified then the dependencies will be re-downloaded. Start the application: <markup lang=\"bash\" >docker run --rm -p 8080:8080 helidon-quickstart-mp-native:latest Again, it starts fast. You can exercise the application&#8217;s endpoints as before. ",
            "title": "Building a Native Image"
        },
        {
            "location": "/mp/guides/graalnative",
            "text": " Native images are ideal for applications with high horizontal scalability requirements where the ability to rapidly scale out to numerous instances is important. That said, native images do have some limitations , and for long running applications where startup and footprint are less of a priority, the Java SE HotSpot VM might be more appropriate. For information about creating custom Java runtime images see Custom Runtime Images with jlink . When building Helidon using native-image, we check features on classpath, and warn if there is a problem or restriction of support ",
            "title": "When should I use Native Images?"
        },
        {
            "location": "/mp/guides/gradle-build",
            "text": " This guide describes Helidon&#8217;s support for Gradle projects. ",
            "title": "preambule"
        },
        {
            "location": "/mp/guides/gradle-build",
            "text": " While most of Helidon&#8217;s examples use Maven, you can also use Helidon with a Gradle project. Gradle 8.4+ is required to build Helidon 4 projects. ",
            "title": "Introduction"
        },
        {
            "location": "/mp/guides/gradle-build",
            "text": " The Helidon Quickstart Example contains a build.gradle file that you can use as an example for building your Helidon application using Gradle. ",
            "title": "Gradle Example"
        },
        {
            "location": "/mp/guides/gradle-build",
            "text": " Gradle supports using a Maven POM to perform dependency management. You can use the Helidon Dependencies POM for this purpose. Once you import the Helidon dependency management POM you can specify dependencies without providing a version. <markup lang=\"xml\" title=\"Using the Helidon Dependencies POM\" >dependencies { // import Helidon dependency management implementation enforcedPlatform(\"io.helidon:helidon-dependencies:${project.helidonversion}\") implementation 'io.helidon.microprofile.bundles:helidon-microprofile' implementation 'org.glassfish.jersey.media:jersey-media-json-binding' runtimeOnly 'io.smallrye:jandex' runtimeOnly 'jakarta.activation:jakarta.activation-api' testCompileOnly 'org.junit.jupiter:junit-jupiter-api:' } ",
            "title": "Dependency Management"
        },
        {
            "location": "/mp/guides/health",
            "text": " This guide describes how to create a sample MicroProfile (MP) project that can be used to run some basic examples using both built-in and custom health checks with Helidon MP. ",
            "title": "preambule"
        },
        {
            "location": "/mp/guides/health",
            "text": " Generate the project sources using the Helidon MP Maven archetype. The result is a simple project that can be used for the examples in this guide. <markup lang=\"bash\" title=\"Run the Maven archetype:\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-mp \\ -DarchetypeVersion=4.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-mp \\ -Dpackage=io.helidon.examples.quickstart.mp ",
            "title": "Create a Sample MP Project"
        },
        {
            "location": "/mp/guides/health",
            "text": " Helidon has a set of built-in health checks: deadlock detection available disk space available heap memory The following example will demonstrate how to use the built-in health checks. These examples are all executed from the root directory of your project (helidon-quickstart-mp). <markup lang=\"xml\" title=\"Include dependency for the built-in health checks\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.health&lt;/groupId&gt; &lt;artifactId&gt;helidon-health-checks&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"bash\" title=\"Build the application then run it:\" >mvn package java -jar target/helidon-quickstart-mp.jar <markup lang=\"bash\" title=\"Verify the health endpoint in a new terminal window:\" >curl http://localhost:8080/health <markup lang=\"json\" title=\"JSON response:\" >{ \"status\": \"UP\", \"checks\": [ { \"name\": \"deadlock\", \"status\": \"UP\" }, { \"name\": \"diskSpace\", \"status\": \"UP\", \"data\": { \"free\": \"325.54 GB\", \"freeBytes\": 349543358464, \"percentFree\": \"69.91%\", \"total\": \"465.63 GB\", \"totalBytes\": 499963174912 } }, { \"name\": \"heapMemory\", \"status\": \"UP\", \"data\": { \"free\": \"230.87 MB\", \"freeBytes\": 242085696, \"max\": \"3.56 GB\", \"maxBytes\": 3817865216, \"percentFree\": \"98.90%\", \"total\": \"271.00 MB\", \"totalBytes\": 284164096 } } ] } ",
            "title": "Using the Built-In Health Checks"
        },
        {
            "location": "/mp/guides/health",
            "text": " You can create application-specific custom health checks and integrate them with Helidon using CDI. The following example shows how to add a custom liveness health check. <markup lang=\"java\" title=\"Create a new GreetLivenessCheck class with the following content:\" >package io.helidon.examples.quickstart.mp; import jakarta.enterprise.context.ApplicationScoped; import org.eclipse.microprofile.health.HealthCheck; import org.eclipse.microprofile.health.HealthCheckResponse; import org.eclipse.microprofile.health.Liveness; @Liveness @ApplicationScoped public class GreetLivenessCheck implements HealthCheck { private GreetingProvider provider; @Override public HealthCheckResponse call() { return HealthCheckResponse.named(\"LivenessCheck\") .up() .withData(\"time\", System.currentTimeMillis()) .build(); } } Annotation indicating this is a liveness health check. Annotation indicating there is a single liveness HealthCheck object during the lifetime of the application. Build the HealthCheckResponse with status UP and the current time. <markup lang=\"bash\" title=\"Build and run the application, then verify the custom liveness health endpoint:\" >curl http://localhost:8080/health/live <markup lang=\"json\" title=\"JSON response:\" >{ \"status\": \"UP\", \"checks\": [ { \"name\": \"LivenessCheck\", \"status\": \"UP\", \"data\": { \"time\": 1566338255331 } } ] } ",
            "title": "Custom Liveness Health Checks"
        },
        {
            "location": "/mp/guides/health",
            "text": " You can add a readiness check to indicate that the application is ready to be used. In this example, the server will wait five seconds before it becomes ready. <markup lang=\"java\" title=\"Create a new GreetReadinessCheck class with the following content:\" >package io.helidon.examples.quickstart.mp; import java.time.Duration; import java.util.concurrent.atomic.AtomicLong; import jakarta.enterprise.context.ApplicationScoped; import jakarta.enterprise.context.Initialized; import jakarta.enterprise.event.Observes; import org.eclipse.microprofile.health.HealthCheck; import org.eclipse.microprofile.health.HealthCheckResponse; import org.eclipse.microprofile.health.Readiness; @Readiness @ApplicationScoped public class GreetReadinessCheck implements HealthCheck { private final AtomicLong readyTime = new AtomicLong(0); @Override public HealthCheckResponse call() { return HealthCheckResponse.named(\"ReadinessCheck\") .status(isReady()) .withData(\"time\", readyTime.get()) .build(); } public void onStartUp( @Observes @Initialized(ApplicationScoped.class) Object init) { readyTime.set(System.currentTimeMillis()); } /** * Become ready after 5 seconds * * @return true if application ready */ private boolean isReady() { return Duration.ofMillis(System.currentTimeMillis() - readyTime.get()).getSeconds() &gt;= 5; } } Include additional imports. Annotation indicating that this is a readiness health check. Build the HealthCheckResponse with status UP after five seconds, else DOWN . Record the time at startup. <markup lang=\"bash\" title=\"Build and run the application. Issue the curl command with -v within five seconds and you will see that the application is not ready:\" >curl -v http://localhost:8080/health/ready <markup lang=\"listing\" title=\"HTTP response status\" >&lt; HTTP/1.1 503 Service Unavailable The HTTP status is 503 since the application is not ready. <markup lang=\"json\" title=\"Response body\" >{ \"status\": \"DOWN\", \"checks\": [ { \"name\": \"ReadinessCheck\", \"status\": \"DOWN\", \"data\": { \"time\": 1566399775700 } } ] } <markup lang=\"bash\" title=\"After five seconds you will see the application is ready:\" >curl -v http://localhost:8080/health/ready <markup lang=\"listing\" title=\"HTTP response status\" >&lt; HTTP/1.1 200 OK The HTTP status is 200 indicating that the application is ready. <markup lang=\"json\" title=\"Response body\" >{ \"status\": \"UP\", \"checks\": [ { \"name\": \"ReadinessCheck\", \"status\": \"UP\", \"data\": { \"time\": 1566399775700 } } ] } ",
            "title": "Custom Readiness Health Checks"
        },
        {
            "location": "/mp/guides/health",
            "text": " You can add a startup check to indicate whether or not the application has initialized to the point that the other health checks make sense. In this example, the server will wait eight seconds before it declares itself started. <markup lang=\"java\" title=\"Create a new GreetStartedCheck class with the following content:\" >package io.helidon.examples.quickstart.mp; import java.time.Duration; import java.util.concurrent.atomic.AtomicLong; import jakarta.enterprise.context.ApplicationScoped; import jakarta.enterprise.context.Initialized; import jakarta.enterprise.event.Observes; import org.eclipse.microprofile.health.HealthCheck; import org.eclipse.microprofile.health.HealthCheckResponse; import org.eclipse.microprofile.health.Startup; @Startup @ApplicationScoped public class GreetStartedCheck implements HealthCheck { private final AtomicLong readyTime = new AtomicLong(0); @Override public HealthCheckResponse call() { return HealthCheckResponse.named(\"StartedCheck\") .status(isStarted()) .withData(\"time\", readyTime.get()) .build(); } public void onStartUp( @Observes @Initialized(ApplicationScoped.class) Object init) { readyTime.set(System.currentTimeMillis()); } /** * Become ready after 5 seconds * * @return true if application ready */ private boolean isStarted() { return Duration.ofMillis(System.currentTimeMillis() - readyTime.get()).getSeconds() &gt;= 8; } } Include additional imports. Annotation indicating that this is a startup health check. Build the HealthCheckResponse with status UP after eight seconds, else DOWN . Record the time at startup of Helidon; the application will declare itself as started eight seconds later. <markup lang=\"bash\" title=\"Build and run the application. Issue the curl command with -v within five seconds and you will see that the application has not yet started:\" >curl -v http://localhost:8080/health/started <markup lang=\"listing\" title=\"HTTP response status\" >&lt; HTTP/1.1 503 Service Unavailable The HTTP status is 503 since the application has not started. <markup lang=\"json\" title=\"Response body\" >{ \"status\": \"DOWN\", \"checks\": [ { \"name\": \"StartedCheck\", \"status\": \"DOWN\", \"data\": { \"time\": 1566399775700 } } ] } <markup lang=\"bash\" title=\"After eight seconds you will see the application has started:\" >curl -v http://localhost:8080/health/started <markup lang=\"listing\" title=\"HTTP response status\" >&lt; HTTP/1.1 200 OK The HTTP status is 200 indicating that the application is started. <markup lang=\"json\" title=\"Response body\" >{ \"status\": \"UP\", \"checks\": [ { \"name\": \"StartedCheck\", \"status\": \"UP\", \"data\": { \"time\": 1566399775700 } } ] } When using the health check URLs, you can get the following health check data: liveness only - http://localhost:8080/health/live readiness only - http://localhost:8080/health/ready startup checks only - http://localhost:8080/health/started all health check data - http://localhost:8080/health <markup lang=\"bash\" title=\"Get all the health check data, including custom data:\" >curl http://localhost:8080/health <markup lang=\"json\" title=\"JSON response:\" >{ \"status\": \"UP\", \"checks\": [ { \"name\": \"LivenessCheck\", \"status\": \"UP\", \"data\": { \"time\": 1566403431536 } }, { \"name\": \"ReadinessCheck\", \"status\": \"UP\", \"data\": { \"time\": 1566403280639 } }, { \"name\": \"StartedCheck\", \"status\": \"UP\", \"data\": { \"time\": 1566403280639 } }, { \"name\": \"deadlock\", \"state\": \"UP\", \"status\": \"UP\" }, { \"name\": \"diskSpace\", \"state\": \"UP\", \"status\": \"UP\", \"data\": { \"free\": \"325.50 GB\", \"freeBytes\": 349500698624, \"percentFree\": \"69.91%\", \"total\": \"465.63 GB\", \"totalBytes\": 499963174912 } }, { \"name\": \"heapMemory\", \"state\": \"UP\", \"status\": \"UP\", \"data\": { \"free\": \"231.01 MB\", \"freeBytes\": 242235928, \"max\": \"3.56 GB\", \"maxBytes\": 3817865216, \"percentFree\": \"98.79%\", \"total\": \"275.00 MB\", \"totalBytes\": 288358400 } } ] } ",
            "title": "Custom Startup Health Checks"
        },
        {
            "location": "/mp/guides/health",
            "text": " You can specify a custom port and root context for the root health endpoint path. However, you cannot use different ports, such as http://localhost:8080/myhealth and http://localhost:8081/myhealth/live . Likewise, you cannot use different paths, such as http://localhost:8080/health and http://localhost:8080/probe/live . The example below will change the root path. <markup lang=\"yaml\" title=\"Create a file named application.yaml in the resources directory with the following contents:\" >health: endpoint: \"/myhealth\" The endpoint settings specifies the root path for the health endpoint. <markup lang=\"bash\" title=\"Build and run the application, then verify that the health endpoint is using the new /myhealth root:\" >curl http://localhost:8080/myhealth curl http://localhost:8080/myhealth/live curl http://localhost:8080/myhealth/ready curl http://localhost:8080/myhealth/started The following example will change the root path and the health port. <markup lang=\"yaml\" title=\"Update application.yaml to use a different port and root path for the health endpoint:\" >server: port: 8080 sockets: - name: \"admin\" port: 8081 features: observe: sockets: \"admin\" health: endpoint: \"/myhealth\" The default port for the application. The name of the new socket, it can be any name, this example uses admin . The port for the admin socket. The health endpoint, as part of Helidon&#8217;s observability support, uses the socket admin . <markup lang=\"bash\" title=\"Build and run the application, then verify the health endpoint using port 8081 and /myhealth :\" >curl http://localhost:8081/myhealth curl http://localhost:8081/myhealth/live curl http://localhost:8081/myhealth/ready curl http://localhost:8081/myhealth/started ",
            "title": "Custom Health Root Path and Port"
        },
        {
            "location": "/mp/guides/health",
            "text": " The following example shows how to integrate the Helidon health check API with an application that implements health endpoints for the Kubernetes liveness, readiness, and startup probes. Delete the contents of application.yaml so that the default health endpoint path and port are used. <markup lang=\"bash\" title=\"Rebuild and start the application, then verify the health endpoint:\" >curl http://localhost:8080/health <markup lang=\"bash\" title=\"Stop the application and build the docker image:\" >docker build -t helidon-quickstart-mp . <markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named health.yaml , with the following content:\" >kind: Service apiVersion: v1 metadata: name: helidon-health labels: app: helidon-health spec: type: NodePort selector: app: helidon-health ports: - port: 8080 targetPort: 8080 name: http --- kind: Deployment apiVersion: apps/v1 metadata: name: helidon-health spec: replicas: 1 selector: matchLabels: app: helidon-health template: metadata: labels: app: helidon-health version: v1 spec: containers: - name: helidon-health image: helidon-quickstart-mp imagePullPolicy: IfNotPresent ports: - containerPort: 8080 livenessProbe: httpGet: path: /health/live port: 8080 initialDelaySeconds: 5 periodSeconds: 10 timeoutSeconds: 3 failureThreshold: 3 readinessProbe: httpGet: path: /health/ready port: 8080 initialDelaySeconds: 5 periodSeconds: 2 timeoutSeconds: 3 startupProbe: httpGet: path: /health/started port: 8080 initialDelaySeconds: 8 periodSeconds: 10 timeoutSeconds: 3 failureThreshold: 3 --- A service of type NodePort that serves the default routes on port 8080 . A deployment with one replica of a pod. The HTTP endpoint for the liveness probe. The liveness probe configuration. The HTTP endpoint for the readiness probe. The readiness probe configuration. The HTTP endpoint for the startup probe. The startup probe configuration. <markup lang=\"bash\" title=\"Create and deploy the application into Kubernetes:\" >kubectl apply -f ./health.yaml <markup lang=\"bash\" title=\"Get the service information:\" >kubectl get service/helidon-health <markup lang=\"bash\" >NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE helidon-health NodePort 10.107.226.62 &lt;none&gt; 8080:30116/TCP 4s A service of type NodePort that serves the default routes on port 30116 . <markup lang=\"bash\" title=\"Verify the health endpoints using port '30116', your port may be different. The JSON response will be the same as your previous test:\" >curl http://localhost:30116/health <markup lang=\"bash\" title=\"Delete the application, cleaning up Kubernetes resources:\" >kubectl delete -f ./health.yaml ",
            "title": "Using Liveness, Readiness, and Startup Health Checks with Kubernetes"
        },
        {
            "location": "/mp/guides/health",
            "text": " This guide demonstrated how to use health checks in a Helidon MP application as follows: Access the default health checks Create and use custom readiness, liveness, and startup checks Customize the health check root path and port Integrate Helidon health check API with Kubernetes Refer to the following references for additional information: MicroProfile health check specification MicroProfile health check Javadoc Helidon Javadoc ",
            "title": "Summary"
        },
        {
            "location": "/mp/guides/health",
            "text": " For this 15 minute tutorial, you will need the following: <div class=\"table__overflow elevation-1 flex sm7 \"> A Helidon MP Application You can use your own application or use the Helidon MP Quickstart to create a sample application. Java&#160;SE&#160;21 ( Open&#160;JDK&#160;21 ) Helidon requires Java 21+. Maven 3.8+ Helidon requires Maven 3.8+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop . <markup lang=\"bash\" title=\"Verify Prerequisites\" >java -version mvn --version docker --version kubectl version --short <markup lang=\"bash\" title=\"Setting JAVA_HOME\" ># On Mac export JAVA_HOME=`/usr/libexec/java_home -v 21` # On Linux # Use the appropriate path to your JDK export JAVA_HOME=/usr/lib/jvm/jdk-21 Create a Sample MP Project Generate the project sources using the Helidon MP Maven archetype. The result is a simple project that can be used for the examples in this guide. <markup lang=\"bash\" title=\"Run the Maven archetype:\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-mp \\ -DarchetypeVersion=4.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-mp \\ -Dpackage=io.helidon.examples.quickstart.mp Using the Built-In Health Checks Helidon has a set of built-in health checks: deadlock detection available disk space available heap memory The following example will demonstrate how to use the built-in health checks. These examples are all executed from the root directory of your project (helidon-quickstart-mp). <markup lang=\"xml\" title=\"Include dependency for the built-in health checks\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.health&lt;/groupId&gt; &lt;artifactId&gt;helidon-health-checks&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"bash\" title=\"Build the application then run it:\" >mvn package java -jar target/helidon-quickstart-mp.jar <markup lang=\"bash\" title=\"Verify the health endpoint in a new terminal window:\" >curl http://localhost:8080/health <markup lang=\"json\" title=\"JSON response:\" >{ \"status\": \"UP\", \"checks\": [ { \"name\": \"deadlock\", \"status\": \"UP\" }, { \"name\": \"diskSpace\", \"status\": \"UP\", \"data\": { \"free\": \"325.54 GB\", \"freeBytes\": 349543358464, \"percentFree\": \"69.91%\", \"total\": \"465.63 GB\", \"totalBytes\": 499963174912 } }, { \"name\": \"heapMemory\", \"status\": \"UP\", \"data\": { \"free\": \"230.87 MB\", \"freeBytes\": 242085696, \"max\": \"3.56 GB\", \"maxBytes\": 3817865216, \"percentFree\": \"98.90%\", \"total\": \"271.00 MB\", \"totalBytes\": 284164096 } } ] } Custom Liveness Health Checks You can create application-specific custom health checks and integrate them with Helidon using CDI. The following example shows how to add a custom liveness health check. <markup lang=\"java\" title=\"Create a new GreetLivenessCheck class with the following content:\" >package io.helidon.examples.quickstart.mp; import jakarta.enterprise.context.ApplicationScoped; import org.eclipse.microprofile.health.HealthCheck; import org.eclipse.microprofile.health.HealthCheckResponse; import org.eclipse.microprofile.health.Liveness; @Liveness @ApplicationScoped public class GreetLivenessCheck implements HealthCheck { private GreetingProvider provider; @Override public HealthCheckResponse call() { return HealthCheckResponse.named(\"LivenessCheck\") .up() .withData(\"time\", System.currentTimeMillis()) .build(); } } Annotation indicating this is a liveness health check. Annotation indicating there is a single liveness HealthCheck object during the lifetime of the application. Build the HealthCheckResponse with status UP and the current time. <markup lang=\"bash\" title=\"Build and run the application, then verify the custom liveness health endpoint:\" >curl http://localhost:8080/health/live <markup lang=\"json\" title=\"JSON response:\" >{ \"status\": \"UP\", \"checks\": [ { \"name\": \"LivenessCheck\", \"status\": \"UP\", \"data\": { \"time\": 1566338255331 } } ] } Custom Readiness Health Checks You can add a readiness check to indicate that the application is ready to be used. In this example, the server will wait five seconds before it becomes ready. <markup lang=\"java\" title=\"Create a new GreetReadinessCheck class with the following content:\" >package io.helidon.examples.quickstart.mp; import java.time.Duration; import java.util.concurrent.atomic.AtomicLong; import jakarta.enterprise.context.ApplicationScoped; import jakarta.enterprise.context.Initialized; import jakarta.enterprise.event.Observes; import org.eclipse.microprofile.health.HealthCheck; import org.eclipse.microprofile.health.HealthCheckResponse; import org.eclipse.microprofile.health.Readiness; @Readiness @ApplicationScoped public class GreetReadinessCheck implements HealthCheck { private final AtomicLong readyTime = new AtomicLong(0); @Override public HealthCheckResponse call() { return HealthCheckResponse.named(\"ReadinessCheck\") .status(isReady()) .withData(\"time\", readyTime.get()) .build(); } public void onStartUp( @Observes @Initialized(ApplicationScoped.class) Object init) { readyTime.set(System.currentTimeMillis()); } /** * Become ready after 5 seconds * * @return true if application ready */ private boolean isReady() { return Duration.ofMillis(System.currentTimeMillis() - readyTime.get()).getSeconds() &gt;= 5; } } Include additional imports. Annotation indicating that this is a readiness health check. Build the HealthCheckResponse with status UP after five seconds, else DOWN . Record the time at startup. <markup lang=\"bash\" title=\"Build and run the application. Issue the curl command with -v within five seconds and you will see that the application is not ready:\" >curl -v http://localhost:8080/health/ready <markup lang=\"listing\" title=\"HTTP response status\" >&lt; HTTP/1.1 503 Service Unavailable The HTTP status is 503 since the application is not ready. <markup lang=\"json\" title=\"Response body\" >{ \"status\": \"DOWN\", \"checks\": [ { \"name\": \"ReadinessCheck\", \"status\": \"DOWN\", \"data\": { \"time\": 1566399775700 } } ] } <markup lang=\"bash\" title=\"After five seconds you will see the application is ready:\" >curl -v http://localhost:8080/health/ready <markup lang=\"listing\" title=\"HTTP response status\" >&lt; HTTP/1.1 200 OK The HTTP status is 200 indicating that the application is ready. <markup lang=\"json\" title=\"Response body\" >{ \"status\": \"UP\", \"checks\": [ { \"name\": \"ReadinessCheck\", \"status\": \"UP\", \"data\": { \"time\": 1566399775700 } } ] } Custom Startup Health Checks You can add a startup check to indicate whether or not the application has initialized to the point that the other health checks make sense. In this example, the server will wait eight seconds before it declares itself started. <markup lang=\"java\" title=\"Create a new GreetStartedCheck class with the following content:\" >package io.helidon.examples.quickstart.mp; import java.time.Duration; import java.util.concurrent.atomic.AtomicLong; import jakarta.enterprise.context.ApplicationScoped; import jakarta.enterprise.context.Initialized; import jakarta.enterprise.event.Observes; import org.eclipse.microprofile.health.HealthCheck; import org.eclipse.microprofile.health.HealthCheckResponse; import org.eclipse.microprofile.health.Startup; @Startup @ApplicationScoped public class GreetStartedCheck implements HealthCheck { private final AtomicLong readyTime = new AtomicLong(0); @Override public HealthCheckResponse call() { return HealthCheckResponse.named(\"StartedCheck\") .status(isStarted()) .withData(\"time\", readyTime.get()) .build(); } public void onStartUp( @Observes @Initialized(ApplicationScoped.class) Object init) { readyTime.set(System.currentTimeMillis()); } /** * Become ready after 5 seconds * * @return true if application ready */ private boolean isStarted() { return Duration.ofMillis(System.currentTimeMillis() - readyTime.get()).getSeconds() &gt;= 8; } } Include additional imports. Annotation indicating that this is a startup health check. Build the HealthCheckResponse with status UP after eight seconds, else DOWN . Record the time at startup of Helidon; the application will declare itself as started eight seconds later. <markup lang=\"bash\" title=\"Build and run the application. Issue the curl command with -v within five seconds and you will see that the application has not yet started:\" >curl -v http://localhost:8080/health/started <markup lang=\"listing\" title=\"HTTP response status\" >&lt; HTTP/1.1 503 Service Unavailable The HTTP status is 503 since the application has not started. <markup lang=\"json\" title=\"Response body\" >{ \"status\": \"DOWN\", \"checks\": [ { \"name\": \"StartedCheck\", \"status\": \"DOWN\", \"data\": { \"time\": 1566399775700 } } ] } <markup lang=\"bash\" title=\"After eight seconds you will see the application has started:\" >curl -v http://localhost:8080/health/started <markup lang=\"listing\" title=\"HTTP response status\" >&lt; HTTP/1.1 200 OK The HTTP status is 200 indicating that the application is started. <markup lang=\"json\" title=\"Response body\" >{ \"status\": \"UP\", \"checks\": [ { \"name\": \"StartedCheck\", \"status\": \"UP\", \"data\": { \"time\": 1566399775700 } } ] } When using the health check URLs, you can get the following health check data: liveness only - http://localhost:8080/health/live readiness only - http://localhost:8080/health/ready startup checks only - http://localhost:8080/health/started all health check data - http://localhost:8080/health <markup lang=\"bash\" title=\"Get all the health check data, including custom data:\" >curl http://localhost:8080/health <markup lang=\"json\" title=\"JSON response:\" >{ \"status\": \"UP\", \"checks\": [ { \"name\": \"LivenessCheck\", \"status\": \"UP\", \"data\": { \"time\": 1566403431536 } }, { \"name\": \"ReadinessCheck\", \"status\": \"UP\", \"data\": { \"time\": 1566403280639 } }, { \"name\": \"StartedCheck\", \"status\": \"UP\", \"data\": { \"time\": 1566403280639 } }, { \"name\": \"deadlock\", \"state\": \"UP\", \"status\": \"UP\" }, { \"name\": \"diskSpace\", \"state\": \"UP\", \"status\": \"UP\", \"data\": { \"free\": \"325.50 GB\", \"freeBytes\": 349500698624, \"percentFree\": \"69.91%\", \"total\": \"465.63 GB\", \"totalBytes\": 499963174912 } }, { \"name\": \"heapMemory\", \"state\": \"UP\", \"status\": \"UP\", \"data\": { \"free\": \"231.01 MB\", \"freeBytes\": 242235928, \"max\": \"3.56 GB\", \"maxBytes\": 3817865216, \"percentFree\": \"98.79%\", \"total\": \"275.00 MB\", \"totalBytes\": 288358400 } } ] } Custom Health Root Path and Port You can specify a custom port and root context for the root health endpoint path. However, you cannot use different ports, such as http://localhost:8080/myhealth and http://localhost:8081/myhealth/live . Likewise, you cannot use different paths, such as http://localhost:8080/health and http://localhost:8080/probe/live . The example below will change the root path. <markup lang=\"yaml\" title=\"Create a file named application.yaml in the resources directory with the following contents:\" >health: endpoint: \"/myhealth\" The endpoint settings specifies the root path for the health endpoint. <markup lang=\"bash\" title=\"Build and run the application, then verify that the health endpoint is using the new /myhealth root:\" >curl http://localhost:8080/myhealth curl http://localhost:8080/myhealth/live curl http://localhost:8080/myhealth/ready curl http://localhost:8080/myhealth/started The following example will change the root path and the health port. <markup lang=\"yaml\" title=\"Update application.yaml to use a different port and root path for the health endpoint:\" >server: port: 8080 sockets: - name: \"admin\" port: 8081 features: observe: sockets: \"admin\" health: endpoint: \"/myhealth\" The default port for the application. The name of the new socket, it can be any name, this example uses admin . The port for the admin socket. The health endpoint, as part of Helidon&#8217;s observability support, uses the socket admin . <markup lang=\"bash\" title=\"Build and run the application, then verify the health endpoint using port 8081 and /myhealth :\" >curl http://localhost:8081/myhealth curl http://localhost:8081/myhealth/live curl http://localhost:8081/myhealth/ready curl http://localhost:8081/myhealth/started Using Liveness, Readiness, and Startup Health Checks with Kubernetes The following example shows how to integrate the Helidon health check API with an application that implements health endpoints for the Kubernetes liveness, readiness, and startup probes. Delete the contents of application.yaml so that the default health endpoint path and port are used. <markup lang=\"bash\" title=\"Rebuild and start the application, then verify the health endpoint:\" >curl http://localhost:8080/health <markup lang=\"bash\" title=\"Stop the application and build the docker image:\" >docker build -t helidon-quickstart-mp . <markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named health.yaml , with the following content:\" >kind: Service apiVersion: v1 metadata: name: helidon-health labels: app: helidon-health spec: type: NodePort selector: app: helidon-health ports: - port: 8080 targetPort: 8080 name: http --- kind: Deployment apiVersion: apps/v1 metadata: name: helidon-health spec: replicas: 1 selector: matchLabels: app: helidon-health template: metadata: labels: app: helidon-health version: v1 spec: containers: - name: helidon-health image: helidon-quickstart-mp imagePullPolicy: IfNotPresent ports: - containerPort: 8080 livenessProbe: httpGet: path: /health/live port: 8080 initialDelaySeconds: 5 periodSeconds: 10 timeoutSeconds: 3 failureThreshold: 3 readinessProbe: httpGet: path: /health/ready port: 8080 initialDelaySeconds: 5 periodSeconds: 2 timeoutSeconds: 3 startupProbe: httpGet: path: /health/started port: 8080 initialDelaySeconds: 8 periodSeconds: 10 timeoutSeconds: 3 failureThreshold: 3 --- A service of type NodePort that serves the default routes on port 8080 . A deployment with one replica of a pod. The HTTP endpoint for the liveness probe. The liveness probe configuration. The HTTP endpoint for the readiness probe. The readiness probe configuration. The HTTP endpoint for the startup probe. The startup probe configuration. <markup lang=\"bash\" title=\"Create and deploy the application into Kubernetes:\" >kubectl apply -f ./health.yaml <markup lang=\"bash\" title=\"Get the service information:\" >kubectl get service/helidon-health <markup lang=\"bash\" >NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE helidon-health NodePort 10.107.226.62 &lt;none&gt; 8080:30116/TCP 4s A service of type NodePort that serves the default routes on port 30116 . <markup lang=\"bash\" title=\"Verify the health endpoints using port '30116', your port may be different. The JSON response will be the same as your previous test:\" >curl http://localhost:30116/health <markup lang=\"bash\" title=\"Delete the application, cleaning up Kubernetes resources:\" >kubectl delete -f ./health.yaml Summary This guide demonstrated how to use health checks in a Helidon MP application as follows: Access the default health checks Create and use custom readiness, liveness, and startup checks Customize the health check root path and port Integrate Helidon health check API with Kubernetes Refer to the following references for additional information: MicroProfile health check specification MicroProfile health check Javadoc Helidon Javadoc ",
            "title": "What You Need"
        },
        {
            "location": "/mp/guides/jbatch",
            "text": " This guide describes how Helidon and Jakarta Batch (JBatch) can be used together to execute batch jobs in environments that do not fully support EE environments. ",
            "title": "preambule"
        },
        {
            "location": "/mp/guides/jbatch",
            "text": " For this 20 minute tutorial, you will need the following: <div class=\"table__overflow elevation-1 flex sm7 \"> A Helidon MP Application You can use your own application or use the Helidon MP Quickstart to create a sample application. Java&#160;SE&#160;21 ( Open&#160;JDK&#160;21 ) Helidon requires Java 21+. Maven 3.8+ Helidon requires Maven 3.8+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop . <markup lang=\"bash\" title=\"Verify Prerequisites\" >java -version mvn --version docker --version kubectl version --short <markup lang=\"bash\" title=\"Setting JAVA_HOME\" ># On Mac export JAVA_HOME=`/usr/libexec/java_home -v 21` # On Linux # Use the appropriate path to your JDK export JAVA_HOME=/usr/lib/jvm/jdk-21 This guide assumes you are familiar with the Jakarta Batch project specification from the Eclipse Foundation project site. ",
            "title": "What You Need"
        },
        {
            "location": "/mp/guides/jbatch",
            "text": " For this example, add the IBM JBatch implementation and the derby embedded DB (since JPA and JPA are not available by default) dependencies to the testing module: <markup lang=\"xml\" title=\"Maven dependencies\" >&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.imb.jbatch&lt;/groupId&gt; &lt;artifactId&gt;com.ibm.jbatch.container&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.derby&lt;/groupId&gt; &lt;artifactId&gt;derby&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; ",
            "title": "Dependencies"
        },
        {
            "location": "/mp/guides/jbatch",
            "text": "<markup lang=\"java\" title=\"MyOutputRecord\" >public class MyOutputRecord { private int id; public MyOutputRecord(int id) { this.id = id; } public int getId() { return id; } public void setId(int id) { this.id = id; } @Override public String toString() { return \"MyOutputRecord: \" + id; } } ",
            "title": "2. Create a unit of output information"
        },
        {
            "location": "/mp/guides/jbatch",
            "text": " MyItemReader should look like this: <markup lang=\"java\" title=\"MyItemReader\" >public class MyItemReader extends AbstractItemReader { private final StringTokenizer tokens; public MyItemReader() { tokens = new StringTokenizer(\"1,2,3,4,5,6,7,8,9,10\", \",\"); } /** * Perform read Item. * @return Stage result. */ @Override public MyInputRecord readItem() { if (tokens.hasMoreTokens()) { return new MyInputRecord(Integer.valueOf(tokens.nextToken())); } return null; } } ",
            "title": "3. Create MyItemReader to extend AbstractItemReader "
        },
        {
            "location": "/mp/guides/jbatch",
            "text": " The MyItemProcessor will perform some simple operations: <markup lang=\"java\" title=\"MyItemProcessor\" >public class MyItemProcessor implements ItemProcessor { @Override public MyOutputRecord processItem(Object t) { System.out.println(\"processItem: \" + t); return (((MyInputRecord) t).getId() % 2 == 0) ? null : new MyOutputRecord(((MyInputRecord) t).getId() * 2); } } ",
            "title": "4. Create MyItemProcessor to implement ItemProcessor "
        },
        {
            "location": "/mp/guides/jbatch",
            "text": " MyItemWriter prints the result: <markup lang=\"java\" title=\"MyItemWriter\" >public class MyItemWriter extends AbstractItemWriter { @Override public void writeItems(List list) { System.out.println(\"writeItems: \" + list); } } ",
            "title": "5. Create MyItemWriter to extend AbstractItemWriter "
        },
        {
            "location": "/mp/guides/jbatch",
            "text": " MyBatchlet simply completes the process: <markup lang=\"java\" title=\"MyBatchlet\" >public class MyBatchlet extends AbstractBatchlet { @Override public String process() { System.out.println(\"Running inside a batchlet\"); return \"COMPLETED\"; } } ",
            "title": "6. Create MyBatchlet to extend AbstractBatchlet "
        },
        {
            "location": "/mp/guides/jbatch",
            "text": "<markup lang=\"java\" title=\"MyInputRecord\" >public class MyInputRecord { private int id; public MyInputRecord(int id) { this.id = id; } public int getId() { return id; } public void setId(int id) { this.id = id; } @Override public String toString() { return \"MyInputRecord: \" + id; } } 2. Create a unit of output information <markup lang=\"java\" title=\"MyOutputRecord\" >public class MyOutputRecord { private int id; public MyOutputRecord(int id) { this.id = id; } public int getId() { return id; } public void setId(int id) { this.id = id; } @Override public String toString() { return \"MyOutputRecord: \" + id; } } 3. Create MyItemReader to extend AbstractItemReader MyItemReader should look like this: <markup lang=\"java\" title=\"MyItemReader\" >public class MyItemReader extends AbstractItemReader { private final StringTokenizer tokens; public MyItemReader() { tokens = new StringTokenizer(\"1,2,3,4,5,6,7,8,9,10\", \",\"); } /** * Perform read Item. * @return Stage result. */ @Override public MyInputRecord readItem() { if (tokens.hasMoreTokens()) { return new MyInputRecord(Integer.valueOf(tokens.nextToken())); } return null; } } 4. Create MyItemProcessor to implement ItemProcessor The MyItemProcessor will perform some simple operations: <markup lang=\"java\" title=\"MyItemProcessor\" >public class MyItemProcessor implements ItemProcessor { @Override public MyOutputRecord processItem(Object t) { System.out.println(\"processItem: \" + t); return (((MyInputRecord) t).getId() % 2 == 0) ? null : new MyOutputRecord(((MyInputRecord) t).getId() * 2); } } 5. Create MyItemWriter to extend AbstractItemWriter MyItemWriter prints the result: <markup lang=\"java\" title=\"MyItemWriter\" >public class MyItemWriter extends AbstractItemWriter { @Override public void writeItems(List list) { System.out.println(\"writeItems: \" + list); } } 6. Create MyBatchlet to extend AbstractBatchlet MyBatchlet simply completes the process: <markup lang=\"java\" title=\"MyBatchlet\" >public class MyBatchlet extends AbstractBatchlet { @Override public String process() { System.out.println(\"Running inside a batchlet\"); return \"COMPLETED\"; } } ",
            "title": "1. Create a unit of input information"
        },
        {
            "location": "/mp/guides/jbatch",
            "text": " In this demonstration you will first create sample input and output records and then the following jobs: MyItemReader MyItemProcessor MyItemWriter Finally you will create MyBatchlet to demonstrate all possible usages of JBatch. 1. Create a unit of input information <markup lang=\"java\" title=\"MyInputRecord\" >public class MyInputRecord { private int id; public MyInputRecord(int id) { this.id = id; } public int getId() { return id; } public void setId(int id) { this.id = id; } @Override public String toString() { return \"MyInputRecord: \" + id; } } 2. Create a unit of output information <markup lang=\"java\" title=\"MyOutputRecord\" >public class MyOutputRecord { private int id; public MyOutputRecord(int id) { this.id = id; } public int getId() { return id; } public void setId(int id) { this.id = id; } @Override public String toString() { return \"MyOutputRecord: \" + id; } } 3. Create MyItemReader to extend AbstractItemReader MyItemReader should look like this: <markup lang=\"java\" title=\"MyItemReader\" >public class MyItemReader extends AbstractItemReader { private final StringTokenizer tokens; public MyItemReader() { tokens = new StringTokenizer(\"1,2,3,4,5,6,7,8,9,10\", \",\"); } /** * Perform read Item. * @return Stage result. */ @Override public MyInputRecord readItem() { if (tokens.hasMoreTokens()) { return new MyInputRecord(Integer.valueOf(tokens.nextToken())); } return null; } } 4. Create MyItemProcessor to implement ItemProcessor The MyItemProcessor will perform some simple operations: <markup lang=\"java\" title=\"MyItemProcessor\" >public class MyItemProcessor implements ItemProcessor { @Override public MyOutputRecord processItem(Object t) { System.out.println(\"processItem: \" + t); return (((MyInputRecord) t).getId() % 2 == 0) ? null : new MyOutputRecord(((MyInputRecord) t).getId() * 2); } } 5. Create MyItemWriter to extend AbstractItemWriter MyItemWriter prints the result: <markup lang=\"java\" title=\"MyItemWriter\" >public class MyItemWriter extends AbstractItemWriter { @Override public void writeItems(List list) { System.out.println(\"writeItems: \" + list); } } 6. Create MyBatchlet to extend AbstractBatchlet MyBatchlet simply completes the process: <markup lang=\"java\" title=\"MyBatchlet\" >public class MyBatchlet extends AbstractBatchlet { @Override public String process() { System.out.println(\"Running inside a batchlet\"); return \"COMPLETED\"; } } ",
            "title": "Add Sample Jobs"
        },
        {
            "location": "/mp/guides/jbatch",
            "text": " Add this code to your job descriptor.xml file: <markup lang=\"xml\" title=\"Updated descriptor file\" >&lt;job id=\"myJob\" xmlns=\"https://jakarta.ee/xml/ns/jakartaee\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"https://jakarta.ee/xml/ns/jakartaee https://jakarta.ee/xml/ns/jakartaee/jobXML_2_0.xsd\" version=\"2.0\"&gt; &lt;step id=\"step1\" next=\"step2\"&gt; &lt;chunk item-count=\"3\"&gt; &lt;reader ref=\"io.helidon.examples.jbatch.jobs.MyItemReader\"/&gt; &lt;processor ref=\"io.helidon.examples.jbatch.jobs.MyItemProcessor\"/&gt; &lt;writer ref=\"io.helidon.examples.jbatch.jobs.MyItemWriter\"/&gt; &lt;/chunk&gt; &lt;/step&gt; &lt;step id=\"step2\"&gt; &lt;batchlet ref=\"io.helidon.examples.jbatch.jobs.MyBatchlet\"/&gt; &lt;/step&gt; &lt;/job&gt; The first step of the job includes MyItemReader , MyItemProcessor and MyItemWriter . The second step of the job includes MyBatchlet . You must specify the fully qualified names in the ref properties, like “jobs.io.helidon.examples.jbatch.MyItemReader”, otherwise it will not work. ",
            "title": "Update the Descriptor File"
        },
        {
            "location": "/mp/guides/jbatch",
            "text": " Create a small endpoint to activate the job: <markup lang=\"java\" title=\"new endpoint\" >@Path(\"/batch\") @ApplicationScoped public class BatchResource { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); private JobOperator jobOperator; @GET @Produces(MediaType.APPLICATION_JSON) public JsonObject executeBatch() { BatchSPIManager batchSPIManager = BatchSPIManager.getInstance(); batchSPIManager.registerPlatformMode(BatchSPIManager.PlatformMode.SE); batchSPIManager.registerExecutorServiceProvider(new HelidonExecutorServiceProvider()); jobOperator = getJobOperator(); Long executionId = jobOperator.start(\"myJob\", new Properties()); return JSON.createObjectBuilder() .add(\"Started a job with Execution ID: \", executionId) .build(); } @GET @Path(\"/status/{execution-id}\") public JsonObject status(@PathParam(\"execution-id\") Long executionId){ JobExecution jobExecution = jobOperator.getJobExecution(executionId); List&lt;StepExecution&gt; stepExecutions = jobOperator.getStepExecutions(executionId); List&lt;String&gt; executedSteps = new ArrayList&lt;&gt;(); for (StepExecution stepExecution : stepExecutions) { executedSteps.add(stepExecution.getStepName()); } return JSON.createObjectBuilder() .add(\"Steps executed\", Arrays.toString(executedSteps.toArray())) .add(\"Status\", jobExecution.getBatchStatus().toString()) .build(); } } Helidon specifies to JBatch that it should run in Standalone (SE) mode. It will also register the HelidonExecutorServiceProvider which is actually relatively small. For our example we need something really small, like a FixedTheadPool with 2 threads. This provider is used to tell our JBatch engine exactly which ExecutorService to use. <markup lang=\"java\" title=\"HelidonExecutorServiceProvider\" >public class HelidonExecutorServiceProvider implements ExecutorServiceProvider { @Override public ExecutorService getExecutorService() { return ThreadPoolSupplier.builder().corePoolSize(2).build().get(); } } ",
            "title": "Create an Endpoint"
        },
        {
            "location": "/mp/guides/jbatch",
            "text": "<markup lang=\"bash\" >mvn package java -jar target/helidon-jbatch-example.jar ",
            "title": "Run the Code"
        },
        {
            "location": "/mp/guides/jbatch",
            "text": "<markup lang=\"bash\" >curl -X GET http://localhost:8080/batch/status/1 In this example the job ID is 1, but make sure that you enter your specific job ID in the string. The results should look something like this: <markup lang=\"bash\" >{\"Steps executed\":\"[step1, step2]\",\"Status\":\"COMPLETED\"} ",
            "title": "Check the Status"
        },
        {
            "location": "/mp/guides/jbatch",
            "text": "<markup lang=\"bash\" >curl -X GET http://localhost:8080/batch You should receive the following log: <markup lang=\"bash\" >processItem: MyInputRecord: 1 processItem: MyInputRecord: 2 processItem: MyInputRecord: 3 writeItems: [MyOutputRecord: 2, MyOutputRecord: 6] processItem: MyInputRecord: 4 processItem: MyInputRecord: 5 processItem: MyInputRecord: 6 writeItems: [MyOutputRecord: 10] processItem: MyInputRecord: 7 processItem: MyInputRecord: 8 processItem: MyInputRecord: 9 writeItems: [MyOutputRecord: 14, MyOutputRecord: 18] processItem: MyInputRecord: 10 Running inside a batchlet and the following result: <markup lang=\"bash\" >{\"Started a job with Execution ID: \":1} This indicates that the batch job was called and executed successfully. Check the Status <markup lang=\"bash\" >curl -X GET http://localhost:8080/batch/status/1 In this example the job ID is 1, but make sure that you enter your specific job ID in the string. The results should look something like this: <markup lang=\"bash\" >{\"Steps executed\":\"[step1, step2]\",\"Status\":\"COMPLETED\"} ",
            "title": "Call the Endpoint"
        },
        {
            "location": "/mp/guides/jbatch",
            "text": " This guide demonstrated how to use Helidon with JBatch even though Helidon is not a full EE container. ",
            "title": "Summary"
        },
        {
            "location": "/mp/guides/jlink-image",
            "text": " This guide describes how to build a custom runtime image for your Helidon application using Helidon&#8217;s support for the JDK&#8217;s jlink tool. ",
            "title": "preambule"
        },
        {
            "location": "/mp/guides/jlink-image",
            "text": " JDK 9 introduced the jlink command that supports assembling a set of modules and their dependencies into a custom runtime image. The helidon-maven-plugin has support for easily creating a custom runtime image for your Helidon application resulting in a smaller, better performing runtime. In this guide you will learn how to build a custom runtime image locally on your machine, as well as how to build it in a Docker image. ",
            "title": "Introduction"
        },
        {
            "location": "/mp/guides/jlink-image",
            "text": " For this 10 minute tutorial, you will need the following: <div class=\"table__overflow elevation-1 flex sm7 \"> A Helidon MP Application You can use your own application or use the Helidon MP Quickstart to create a sample application. Java&#160;SE&#160;21 ( Open&#160;JDK&#160;21 ) Helidon requires Java 21+. Maven 3.8+ Helidon requires Maven 3.8+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop . <markup lang=\"bash\" title=\"Verify Prerequisites\" >java -version mvn --version docker --version kubectl version --short <markup lang=\"bash\" title=\"Setting JAVA_HOME\" ># On Mac export JAVA_HOME=`/usr/libexec/java_home -v 21` # On Linux # Use the appropriate path to your JDK export JAVA_HOME=/usr/lib/jvm/jdk-21 ",
            "title": "What You Need"
        },
        {
            "location": "/mp/guides/jlink-image",
            "text": " As noted in the prerequisites above, JDK 21 or newer is required. <markup lang=\"bash\" >$JAVA_HOME/bin/java --version Creating a custom runtime image requires that the JDK modules are present as *.jmod files, and some distributions do not provide them by default. Check the jmods directory to ensure they are present: <markup lang=\"bash\" >ls $JAVA_HOME/jmods OpenJDK on Linux RPM based distributions provide *.jmod files in separate java-*-openjdk-jmods packages. Debian based distributions provide *.jmod files only in the openjdk-*-jdk-headless packages. ",
            "title": "Verify JDK"
        },
        {
            "location": "/mp/guides/jlink-image",
            "text": " Generate the project using the Helidon MP Quickstart Maven archetype. <markup lang=\"bash\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-mp \\ -DarchetypeVersion=4.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-mp \\ -Dpackage=io.helidon.examples.quickstart.mp The archetype generates a Maven project in your current directory (for example, helidon-quickstart-mp ). Change into this directory and build. <markup lang=\"bash\" >cd helidon-quickstart-mp mvn package At this point you can run the application using the JVM: <markup lang=\"bash\" >java -jar target/helidon-quickstart-mp.jar In another shell test an endpoint: <markup lang=\"bash\" >curl -X GET http://localhost:8080/greet The application should respond with {\"message\":\"Hello World!\"} Now stop the running application (by pressing Ctrl+C). For more information about the Quickstart application and other endpoints it supports see the Helidon MP quickstart Guide . ",
            "title": "Generate the Project"
        },
        {
            "location": "/mp/guides/jlink-image",
            "text": " Build the custom runtime image using the jlink image profile: <markup lang=\"bash\" >mvn package -Pjlink-image Tip This uses the helidon-maven-plugin to perform the custom image generation. After the build completes it will report some statistics about the build including the reduction in image size. The target/helidon-quickstart-mp-jri directory is a self contained custom image of your application. It contains your application, its runtime dependencies and the JDK modules it depends on. You can start your application using the provide start script: <markup lang=\"bash\" >./target/helidon-quickstart-mp-jri/bin/start ",
            "title": "Local Build"
        },
        {
            "location": "/mp/guides/jlink-image",
            "text": " Also included in the custom image is a Class Data Sharing (CDS) archive that improves your application&#8217;s startup performance and in-memory footprint. You can learn more about Class Data Sharing in the JDK documentation . The CDS archive increases your image size to get these performance optimizations. It can be of significant size (tens of MB). The size of the CDS archive is reported at the end of the build output. If you&#8217;d rather have a smaller image size (with a slightly increased startup time) you can skip the creation of the CDS archive by executing your build like this: <markup lang=\"bash\" >mvn package -Pjlink-image -Djlink.image.addClassDataSharingArchive=false For more information on available configuration options see the helidon-maven-plugin documentation . ",
            "title": "Class Data Sharing (CDS) Archive"
        },
        {
            "location": "/mp/guides/jlink-image",
            "text": " To build a Docker image with a custom Java runtime image use the jlink Dockerfile included with the quickstart. <markup lang=\"bash\" >docker build -t helidon-quickstart-mp-jri -f Dockerfile.jlink . Tip This does a full build inside the Docker container. The first time you run it, it will take a while because it is downloading all of the Maven dependencies and caching them in a Docker layer. Subsequent builds will be much faster as long as you don&#8217;t change the pom.xml file. If the pom is modified then the dependencies will be re-downloaded. Start the application: <markup lang=\"bash\" >docker run --rm -p 8080:8080 helidon-quickstart-mp-jri:latest You can exercise the application&#8217;s endpoints as before. ",
            "title": "Multi-Stage Docker Build"
        },
        {
            "location": "/mp/guides/jlink-image",
            "text": " You can build a custom runtime image in 2 different ways: Locally, on your desktop Using Docker Local Build Build the custom runtime image using the jlink image profile: <markup lang=\"bash\" >mvn package -Pjlink-image Tip This uses the helidon-maven-plugin to perform the custom image generation. After the build completes it will report some statistics about the build including the reduction in image size. The target/helidon-quickstart-mp-jri directory is a self contained custom image of your application. It contains your application, its runtime dependencies and the JDK modules it depends on. You can start your application using the provide start script: <markup lang=\"bash\" >./target/helidon-quickstart-mp-jri/bin/start Class Data Sharing (CDS) Archive Also included in the custom image is a Class Data Sharing (CDS) archive that improves your application&#8217;s startup performance and in-memory footprint. You can learn more about Class Data Sharing in the JDK documentation . The CDS archive increases your image size to get these performance optimizations. It can be of significant size (tens of MB). The size of the CDS archive is reported at the end of the build output. If you&#8217;d rather have a smaller image size (with a slightly increased startup time) you can skip the creation of the CDS archive by executing your build like this: <markup lang=\"bash\" >mvn package -Pjlink-image -Djlink.image.addClassDataSharingArchive=false For more information on available configuration options see the helidon-maven-plugin documentation . Multi-Stage Docker Build To build a Docker image with a custom Java runtime image use the jlink Dockerfile included with the quickstart. <markup lang=\"bash\" >docker build -t helidon-quickstart-mp-jri -f Dockerfile.jlink . Tip This does a full build inside the Docker container. The first time you run it, it will take a while because it is downloading all of the Maven dependencies and caching them in a Docker layer. Subsequent builds will be much faster as long as you don&#8217;t change the pom.xml file. If the pom is modified then the dependencies will be re-downloaded. Start the application: <markup lang=\"bash\" >docker run --rm -p 8080:8080 helidon-quickstart-mp-jri:latest You can exercise the application&#8217;s endpoints as before. ",
            "title": "Building a Custom Runtime Image"
        },
        {
            "location": "/mp/guides/jlink-image",
            "text": " Custom runtime images are ideal for use when you want all of the runtime performance of the JDK JVM in a reasonably compact form. For cases where absolute minimal startup time and image size are required, then consider using GraalVM Native Images . ",
            "title": "Using Custom Runtime Images"
        },
        {
            "location": "/mp/guides/maven-build",
            "text": " This guide describes Helidon&#8217;s support for Maven projects. ",
            "title": "preambule"
        },
        {
            "location": "/mp/guides/maven-build",
            "text": " Helidon supports Maven by providing the following: The Helidon Application parent POM Dependency management via the Helidon BOM and Dependencies POMs The helidon-maven-plugin ",
            "title": "Introduction"
        },
        {
            "location": "/mp/guides/maven-build",
            "text": " Helidon examples and projects generated using the Helidon Quickstart use a Helidon application POM as their parent. This parent POM provides the following: Helidon dependency management. Maven plugin configurations to help in the building and packaging of your Helidon application. If you want to use your own parent POM, then take a look at the standalone quickstart example . This example has a stand-alone POM that you can pattern your own application POM after. For more details on Helidon application POMs see the Helidon&#8217;s Application POMS ",
            "title": "The Helidon Application POM"
        },
        {
            "location": "/mp/guides/maven-build",
            "text": " In Maven you use Dependency Management to manage the versions of the dependencies used by your project so that you do not need to specify versions when declaring project dependencies. Helidon provides two POMs that are used together for dependency management: The Helidon Bill of Materials (BOM) POM ( io.helidon:helidon-bom ): manages the version of Helidon artifacts (to align with the Helidon version). The Helidon Dependencies POM ( io.helidon:helidon-dependencies ): manages the versions of third party dependencies to ensure consistency across Helidon and your Helidon application. Inherits the Helidon BOM POM. When you use a Helidon Application POM as your project&#8217;s parent pom, you inherit Helidon&#8217;s dependency management. If you have your own parent, then you can import Helidon dependency management like this: <markup lang=\"xml\" title=\"Import Helidon Dependency Management\" >&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon&lt;/groupId&gt; &lt;artifactId&gt;helidon-dependencies&lt;/artifactId&gt; &lt;version&gt;4.0.2&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; You then declare dependencies on Helidon (and other) components without specifying a version. <markup lang=\"xml\" title=\"Component dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.config&lt;/groupId&gt; &lt;artifactId&gt;helidon-config-yaml&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Dependency Management"
        },
        {
            "location": "/mp/guides/maven-build",
            "text": " You can override many of the plugin attributes by passing a system property to the mvn command: <markup lang=\"bash\" >mvn -Djlink.image.addClassDataSharingArchive=false package ",
            "title": "Pass Property on Command Line"
        },
        {
            "location": "/mp/guides/maven-build",
            "text": " Or you can set the properties in your project&#8217;s pom.xml: <markup lang=\"xml\" >&lt;properties&gt; &lt;jlink.image.addClassDataSharingArchive&gt;false&lt;/jlink.image.addClassDataSharingArchive&gt; &lt;native.image.reportExceptionStackTraces&gt;true&lt;/native.image.reportExceptionStackTraces&gt; &lt;/properties&gt; ",
            "title": "Set Property in pom.xml"
        },
        {
            "location": "/mp/guides/maven-build",
            "text": " For full control you can override the plugin&#8217;s configuration using pluginManagement : <markup lang=\"xml\" title=\"Turn off generation of the CDS Archive when generating a custom Java runtime image\" > &lt;build&gt; &lt;pluginManagement&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;io.helidon.build-tools&lt;/groupId&gt; &lt;artifactId&gt;helidon-maven-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;jlink-image&lt;/id&gt; &lt;configuration&gt; &lt;addClassDataSharingArchive&gt;false&lt;/addClassDataSharingArchive&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;/build&gt; ",
            "title": "Override Plugin Configuration using pluginManagement "
        },
        {
            "location": "/mp/guides/maven-build",
            "text": " Helidon provides a Maven plugin that, among other things, provides the following goals: jlink-image: Build a custom runtime Java image . native-image: Build a GraalVM native image . Note: this capability is now provided via the Maven plugin for GraalVM Native Image For full documentation of the plugin please see the Helidon Maven Plugin README . If you use the Helidon application parent POM you will have this plugin configured for you. If you need to customize the helidon-maven-plugin you can do so in a few ways: Passing system properties to Maven on the command line. Setting system properties in your project&#8217;s pom.xml Overriding the plugin configuration by using pluginManagment Pass Property on Command Line You can override many of the plugin attributes by passing a system property to the mvn command: <markup lang=\"bash\" >mvn -Djlink.image.addClassDataSharingArchive=false package Set Property in pom.xml Or you can set the properties in your project&#8217;s pom.xml: <markup lang=\"xml\" >&lt;properties&gt; &lt;jlink.image.addClassDataSharingArchive&gt;false&lt;/jlink.image.addClassDataSharingArchive&gt; &lt;native.image.reportExceptionStackTraces&gt;true&lt;/native.image.reportExceptionStackTraces&gt; &lt;/properties&gt; Override Plugin Configuration using pluginManagement For full control you can override the plugin&#8217;s configuration using pluginManagement : <markup lang=\"xml\" title=\"Turn off generation of the CDS Archive when generating a custom Java runtime image\" > &lt;build&gt; &lt;pluginManagement&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;io.helidon.build-tools&lt;/groupId&gt; &lt;artifactId&gt;helidon-maven-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;jlink-image&lt;/id&gt; &lt;configuration&gt; &lt;addClassDataSharingArchive&gt;false&lt;/addClassDataSharingArchive&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;/build&gt; ",
            "title": "The helidon-maven-plugin "
        },
        {
            "location": "/mp/guides/metrics",
            "text": " This guide describes how to create a sample Helidon MicroProfile (MP) project that can be used to run some basic examples using both built-in and custom metrics with Helidon. ",
            "title": "preambule"
        },
        {
            "location": "/mp/guides/metrics",
            "text": " Use the Helidon MP Maven archetype to create a simple project that can be used for the examples in this guide. <markup lang=\"bash\" title=\"Run the Maven archetype\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-mp \\ -DarchetypeVersion=4.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-mp \\ -Dpackage=io.helidon.examples.quickstart.mp ",
            "title": "Create a Sample Helidon MP Project"
        },
        {
            "location": "/mp/guides/metrics",
            "text": " Helidon provides three built-in scopes of metrics: base, vendor, and application. Here are the metric endpoints: /metrics?scope=base - Base metrics as specified by the MicroProfile Metrics specification /metrics?scope=vendor - Helidon-specific metrics /metrics?scope=application - Application-specific metrics data. Applications can add their own custom scopes as well simply by specifying a custom scope name when registering a metric. The /metrics endpoint returns data for all scopes. The built-in metrics fall into these categories: JVM behavior (in the base scope), and basic key performance indicators for request handling (in the vendor scope). A later section describes the key performance indicator metrics in detail. The following example demonstrates how to use the other built-in metrics. All examples are executed from the root directory of your project (helidon-quickstart-mp). <markup lang=\"bash\" title=\"Build the application and then run it:\" >mvn package java -jar target/helidon-quickstart-mp.jar Metrics output can be returned in either text format (the default), or JSON. The text format uses OpenMetrics (Prometheus) Text Format, see https://prometheus.io/docs/instrumenting/exposition_formats/#text-format-details . <markup lang=\"bash\" title=\"Verify the metrics endpoint in a new terminal window:\" >curl http://localhost:8080/metrics <markup lang=\"text\" title=\"Text response: (partial)\" ># HELP classloader_loadedClasses_total Displays the total number of classes that have been loaded since the Java virtual machine has started execution. # TYPE classloader_loadedClasses_total counter classloader_loadedClasses_total{mp_scope=\"base\",} 8146.0 # HELP requests_count_total Each request (regardless of HTTP method) will increase this counter # TYPE requests_count_total counter requests_count_total{mp_scope=\"vendor\",} 1.0 # HELP jvm_uptime_seconds Displays the start time of the Java virtual machine in seconds. This attribute displays the approximate time when the Java virtual machine started. # TYPE jvm_uptime_seconds gauge jvm_uptime_seconds{mp_scope=\"base\",} 7.3770 You can get the same data in JSON format. <markup lang=\"bash\" title=\"Verify the metrics endpoint with an HTTP accept header:\" >curl -H \"Accept: application/json\" http://localhost:8080/metrics <markup lang=\"json\" title=\"JSON response (partial):\" >{ \"application\": { \"personalizedGets\": 0, \"allGets\": { \"count\": 0, \"elapsedTime\": 0, \"max\": 0, \"mean\": 0 } }, \"vendor\": { \"requests.count\": 2 }, \"base\": { \"gc.total;name=G1 Concurrent GC\": 2, \"cpu.systemLoadAverage\": 10.3388671875, \"classloader.loadedClasses.count\": 8224, \"thread.count\": 19, \"classloader.unloadedClasses.total\": 0, \"jvm.uptime\": 36.8224 } } You can get a single metric by specifying the scope and name as query parameters in the URL. <markup lang=\"bash\" title=\"Get the Helidon requests.count metric:\" >curl -H \"Accept: application/json\" 'http://localhost:8080/metrics?scope=vendor&amp;name=requests.count' <markup lang=\"json\" title=\"JSON response:\" >{ \"requests.count\": 6 } The base metrics illustrated above provide some insight into the behavior of the JVM in which the server runs. The vendor metric shown above gives an idea of the request traffic the server is handling. See the later section for more information on the basic and extended key performance indicator metrics. ",
            "title": "Using the Built-In Metrics"
        },
        {
            "location": "/mp/guides/metrics",
            "text": " You can disable the metrics subsystem entirely using configuration: <markup lang=\"properties\" title=\"Configuration properties file disabling metrics\" >metrics.enabled=false With metrics processing disabled, Helidon never updates any metrics and the /metrics endpoints respond with 404 . ",
            "title": "Disabling Metrics Subsystem Entirely"
        },
        {
            "location": "/mp/guides/metrics",
            "text": " Any time you include the Helidon metrics module in your application, Helidon tracks a basic performance indicator metric: a Counter of all requests received ( requests.count ). Helidon MP also includes additional, extended KPI metrics which are disabled by default: current number of requests in-flight - a Gauge ( requests.inFlight ) of requests currently being processed long-running requests - a Counter ( requests.longRunning ) measuring the total number of requests which take at least a given amount of time to complete; configurable, defaults to 10000 milliseconds (10 seconds) load - a Counter ( requests.load ) measuring the number of requests worked on (as opposed to received) deferred - a Gauge ( requests.deferred ) measuring delayed request processing (work on a request was delayed after Helidon received the request) You can enable and control these metrics using configuration: <markup lang=\"properties\" title=\"Configuration properties file controlling extended KPI metrics\" >metrics.key-performance-indicators.extended = true metrics.key-performance-indicators.long-running.threshold-ms = 2000 ",
            "title": "Collecting Basic and Extended Key Performance Indicator (KPI) Metrics"
        },
        {
            "location": "/mp/guides/metrics",
            "text": " Helidon MP implements the optional family of metrics, all with the name REST.request , as described in the MicroProfile Metrics specification . Each instance is a Timer with tags class and method identifying exactly which REST endpoint Java method that instance measures. By default, Helidon MP does not enable this feature. Enable it by editing your application configuration to set metrics.rest-request.enabled to true . Note that the applications you generate using the full Helidon archetype do enable this feature in the generated config file. You can see the results in the sample output shown in earlier example runs. ",
            "title": "Controlling REST.request Metrics"
        },
        {
            "location": "/mp/guides/metrics",
            "text": " By adding a metrics section to your application configuration you can control how the Helidon metrics subsystem behaves in any of several ways. Disable metrics subsystem entirely . Control REST.request metrics. Select whether to collect extended key performance indicator metrics . Disabling Metrics Subsystem Entirely You can disable the metrics subsystem entirely using configuration: <markup lang=\"properties\" title=\"Configuration properties file disabling metrics\" >metrics.enabled=false With metrics processing disabled, Helidon never updates any metrics and the /metrics endpoints respond with 404 . Collecting Basic and Extended Key Performance Indicator (KPI) Metrics Any time you include the Helidon metrics module in your application, Helidon tracks a basic performance indicator metric: a Counter of all requests received ( requests.count ). Helidon MP also includes additional, extended KPI metrics which are disabled by default: current number of requests in-flight - a Gauge ( requests.inFlight ) of requests currently being processed long-running requests - a Counter ( requests.longRunning ) measuring the total number of requests which take at least a given amount of time to complete; configurable, defaults to 10000 milliseconds (10 seconds) load - a Counter ( requests.load ) measuring the number of requests worked on (as opposed to received) deferred - a Gauge ( requests.deferred ) measuring delayed request processing (work on a request was delayed after Helidon received the request) You can enable and control these metrics using configuration: <markup lang=\"properties\" title=\"Configuration properties file controlling extended KPI metrics\" >metrics.key-performance-indicators.extended = true metrics.key-performance-indicators.long-running.threshold-ms = 2000 Controlling REST.request Metrics Helidon MP implements the optional family of metrics, all with the name REST.request , as described in the MicroProfile Metrics specification . Each instance is a Timer with tags class and method identifying exactly which REST endpoint Java method that instance measures. By default, Helidon MP does not enable this feature. Enable it by editing your application configuration to set metrics.rest-request.enabled to true . Note that the applications you generate using the full Helidon archetype do enable this feature in the generated config file. You can see the results in the sample output shown in earlier example runs. ",
            "title": "Controlling Metrics Behavior"
        },
        {
            "location": "/mp/guides/metrics",
            "text": " Each metric has associated metadata that includes: name: The name of the metric. units: The unit of the metric such as time (seconds, milliseconds), size (bytes, megabytes), etc. a description of the metric. You can get the metadata for any scope, such as /metrics?scope=base , as shown below: <markup lang=\"bash\" title=\"Get the metrics metadata using HTTP OPTIONS method:\" > curl -X OPTIONS -H \"Accept: application/json\" 'http://localhost:8080/metrics?scope=base' <markup lang=\"json\" title=\"JSON response (truncated):\" >{ \"classloader.loadedClasses.count\": { \"type\": \"gauge\", \"description\": \"Displays the number of classes that are currently loaded in the Java virtual machine.\" }, \"jvm.uptime\": { \"type\": \"gauge\", \"unit\": \"seconds\", \"description\": \"Displays the start time of the Java virtual machine in milliseconds. This attribute displays the approximate time when the Java virtual machine started.\" }, \"memory.usedHeap\": { \"type\": \"gauge\", \"unit\": \"bytes\", \"description\": \"Displays the amount of used heap memory in bytes.\" } } ",
            "title": "Metrics Metadata"
        },
        {
            "location": "/mp/guides/metrics",
            "text": " There are two metrics that you can use by annotating a method: @Counted - Register a Counter metric @Timed - Register a Timer metric The following example will demonstrate how to use the @Counted annotation to track the number of times the /cards endpoint is called. <markup lang=\"java\" title=\"Create a new class GreetingCards with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import jakarta.enterprise.context.RequestScoped; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.annotation.Counted; @Path(\"/cards\") @RequestScoped public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"any-card\") public JsonObject anyCard() throws InterruptedException { return createResponse(\"Here are some random cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } } This class is annotated with Path which sets the path for this resource as /cards . The @RequestScoped annotation defines that this bean is request scoped. The request scope is active only for the duration of one web service invocation and it is destroyed at the end of that invocation. The annotation @Counted will register a Counter metric for this method, creating it if needed. The counter is incremented each time the anyCards method is called. The name attribute is optional. <markup lang=\"bash\" title=\"Build and run the application, then invoke the application endpoints below:\" >curl http://localhost:8080/cards curl http://localhost:8080/cards curl -H \"Accept: application/json\" 'http://localhost:8080/metrics?scope=application' <markup lang=\"json\" title=\"JSON response (partial):\" >{ \"io.helidon.examples.quickstart.mp.GreetingCards.any-card\":2 } The any-card count is two, since you invoked the endpoint twice. Notice the counter is fully qualified. You can remove the package prefix by using the absolute=true field in the @Counted annotation. You must use absolute=false for class-level annotations. ",
            "title": "Method Level Metrics"
        },
        {
            "location": "/mp/guides/metrics",
            "text": " The @Timed annotation can also be used with a method. For the following example. you can just annotate the same method with @Timed . These metrics collect significant information about the measured methods, but at a cost of some overhead and more complicated output. Note that when using multiple annotations on a method, you must give the metrics different names as shown below. <markup lang=\"java\" title=\"Replace the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import jakarta.enterprise.context.RequestScoped; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.MetricUnits; import org.eclipse.microprofile.metrics.annotation.Counted; import org.eclipse.microprofile.metrics.annotation.Timed; @Path(\"/cards\") @RequestScoped public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"cardCount\", absolute = true) @Timed(name = \"cardTimer\", absolute = true, unit = MetricUnits.MILLISECONDS) public JsonObject anyCard() { return createResponse(\"Here are some random cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } } Specify a custom name for the Counter metric and set absolute=true to remove the path prefix from the name. Add the @Timed annotation to get a Timer metric. <markup lang=\"bash\" title=\"Build and run the application, then invoke the application endpoints below:\" >curl http://localhost:8080/cards curl http://localhost:8080/cards curl -H \"Accept: application/json\" 'http://localhost:8080/metrics?scope=application' <markup lang=\"json\" title=\"JSON response (partial):\" >{ \"cardTimer\": { \"count\": 2, \"max\": 0.002921992, \"mean\": 0.0014682555, \"elapsedTime\": 0.002936511, \"p0.5\": 1.4336e-05, \"p0.75\": 0.003014144, \"p0.95\": 0.003014144, \"p0.98\": 0.003014144, \"p0.99\": 0.003014144, \"p0.999\": 0.003014144 } \"cardCount\": 2 } ",
            "title": "Additional Method Level Metrics"
        },
        {
            "location": "/mp/guides/metrics",
            "text": " You can share a metric across multiple endpoints simply by specifying the same metric annotation as demonstrated below. <markup lang=\"java\" title=\"Replace the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import jakarta.enterprise.context.RequestScoped; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.annotation.Counted; @Path(\"/cards\") @RequestScoped public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"anyCard\", absolute = true) public JsonObject anyCard() throws InterruptedException { return createResponse(\"Here are some cards ...\"); } @GET @Path(\"/birthday\") @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"specialEventCard\", absolute = true) public JsonObject birthdayCard() throws InterruptedException { return createResponse(\"Here are some birthday cards ...\"); } @GET @Path(\"/wedding\") @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"specialEventCard\", absolute = true) public JsonObject weddingCard() throws InterruptedException { return createResponse(\"Here are some wedding cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } } The /birthday endpoint uses a Counter metric, named specialEventCard . The /wedding endpoint uses the same Counter metric, named specialEventCard . <markup lang=\"bash\" title=\"Build and run the application, then invoke the following endpoints:\" >curl http://localhost:8080/cards/wedding curl http://localhost:8080/cards/birthday curl http://localhost:8080/cards curl -H \"Accept: application/json\" 'http://localhost:8080/metrics?scope=application' <markup lang=\"json\" title=\"JSON response (partial)`:\" >{ \"anyCard\": 1, \"specialEventCard\": 2 } Notice that specialEventCard count is two, since you accessed /cards/wedding and /cards/birthday . ",
            "title": "Reusing Metrics"
        },
        {
            "location": "/mp/guides/metrics",
            "text": " You can collect metrics at the class-level to aggregate data from all methods in that class using the same metric. The following example introduces a metric to count all card queries. In the following example, the method-level metrics are not needed to aggregate the counts, but they are left in the example to demonstrate the combined output of all three metrics. <markup lang=\"java\" title=\"Replace the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import jakarta.enterprise.context.RequestScoped; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.annotation.Counted; @Path(\"/cards\") @RequestScoped @Counted(name = \"totalCards\") public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) @Counted(absolute = true) public JsonObject anyCard() throws InterruptedException { return createResponse(\"Here are some random cards ...\"); } @Path(\"/birthday\") @GET @Produces(MediaType.APPLICATION_JSON) @Counted(absolute = true) public JsonObject birthdayCard() throws InterruptedException { return createResponse(\"Here are some birthday cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } } This class is annotated with @Counted , which aggregates count data from all the method that have a Count annotation. Use absolute=true to remove path prefix for method-level annotations. Add a method with a Counter metric to get birthday cards. <markup lang=\"bash\" title=\"Build and run the application, then invoke the following endpoints:\" >curl http://localhost:8080/cards curl http://localhost:8080/cards/birthday curl -H \"Accept: application/json\" 'http://localhost:8080/metrics?scope=application' <markup lang=\"json\" title=\"JSON response (partial):\" >{ \"anyCard\": 1, \"birthdayCard\": 1, \"io.helidon.examples.quickstart.mp.totalCards.GreetingCards\": 2 } The totalCards count is a total of all the method-level Counter metrics. Class level metric names are always fully qualified. ",
            "title": "Class Level Metrics"
        },
        {
            "location": "/mp/guides/metrics",
            "text": " Field level metrics can be injected into managed objects, but they need to be updated by the application code. This annotation can be used on fields of type Timer , Counter , and Histogram . The following example shows how to use a field-level Counter metric to track cache hits. <markup lang=\"java\" title=\"Replace the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import java.util.Random; import jakarta.enterprise.context.RequestScoped; import jakarta.inject.Inject; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.Counter; import org.eclipse.microprofile.metrics.annotation.Counted; import org.eclipse.microprofile.metrics.annotation.Metric; @Path(\"/cards\") @RequestScoped @Counted(name = \"totalCards\") public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @Inject @Metric(name = \"cacheHits\", absolute = true) private Counter cacheHits; @GET @Produces(MediaType.APPLICATION_JSON) @Counted(absolute = true) public JsonObject anyCard() throws InterruptedException { updateStats(); return createResponse(\"Here are some random cards ...\"); } @Path(\"/birthday\") @GET @Produces(MediaType.APPLICATION_JSON) @Counted(absolute = true) public JsonObject birthdayCard() throws InterruptedException { updateStats(); return createResponse(\"Here are some birthday cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } private void updateStats() { if (new Random().nextInt(3) == 1) { cacheHits.inc(); } } } A Counter metric field, cacheHits , is automatically injected by Helidon. Call updateStats() to update the cache hits. Call updateStats() to update the cache hits. Randomly increment the cacheHits counter. <markup lang=\"bash\" title=\"Build and run the application, then invoke the following endpoints:\" >curl http://localhost:8080/cards curl http://localhost:8080/cards curl http://localhost:8080/cards/birthday curl http://localhost:8080/cards/birthday curl http://localhost:8080/cards/birthday curl -H \"Accept: application/json\" 'http://localhost:8080/metrics?scope=application' <markup lang=\"json\" title=\"JSON response (partial):\" >{ \"anyCard\": 2, \"birthdayCard\": 3, \"cacheHits\": 2, \"io.helidon.examples.quickstart.mp.totalCards.GreetingCards\": 5 } The cache was hit two times out of five queries. ",
            "title": "Field Level Metrics"
        },
        {
            "location": "/mp/guides/metrics",
            "text": " The Gauge metric measures a value that is maintained by code outside the metrics subsystem. As with other metrics, the application explicitly registers a gauge. When the /metrics endpoint is invoked, Helidon retrieves the value of each registered Gauge . The following example demonstrates how to use a Gauge to track application up-time. <markup lang=\"java\" title=\"Create a new GreetingCardsAppMetrics class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.time.Duration; import java.util.concurrent.atomic.AtomicLong; import jakarta.enterprise.context.ApplicationScoped; import jakarta.enterprise.context.Initialized; import jakarta.enterprise.event.Observes; import org.eclipse.microprofile.metrics.annotation.Gauge; @ApplicationScoped public class GreetingCardsAppMetrics { private AtomicLong startTime = new AtomicLong(0); public void onStartUp(@Observes @Initialized(ApplicationScoped.class) Object init) { startTime = new AtomicLong(System.currentTimeMillis()); } @Gauge(unit = \"TimeSeconds\") public long appUpTimeSeconds() { return Duration.ofMillis(System.currentTimeMillis() - startTime.get()).getSeconds(); } } This managed object must be application scoped to properly register and use the Gauge metric. Declare an AtomicLong field to hold the start time of the application. Initialize the application start time. Return the application appUpTimeSeconds metric, which will be included in the application metrics. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code to simplify the metrics output:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import jakarta.enterprise.context.RequestScoped; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.annotation.Counted; @Path(\"/cards\") @RequestScoped public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"cardCount\", absolute = true) public JsonObject anyCard() throws InterruptedException { return createResponse(\"Here are some random cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } } <markup lang=\"bash\" title=\"Build and run the application, then invoke the application metrics endpoint:\" >curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response from /metrics/application :\" >{ \"cardCount\": 0, \"io.helidon.examples.quickstart.mp.GreetingCardsAppMetrics.appUpTimeSeconds\": 6 } The application has been running for 6 seconds. ",
            "title": "Gauge Metric"
        },
        {
            "location": "/mp/guides/metrics",
            "text": " You can create application-specific metrics and integrate them with Helidon using CDI. To add a new metric, simply annotate the JAX-RS resource with one of the metric annotations. Metrics can be injected at the class, method, and field-levels. This document shows examples of all three. Helidon will automatically create and register annotated application metrics and store them in the application MetricRegistry , which also contains the metric metadata. The metrics will exist for the lifetime of the application. Each metric annotation has mandatory and optional fields. The name field, for example, is optional. Method Level Metrics There are two metrics that you can use by annotating a method: @Counted - Register a Counter metric @Timed - Register a Timer metric The following example will demonstrate how to use the @Counted annotation to track the number of times the /cards endpoint is called. <markup lang=\"java\" title=\"Create a new class GreetingCards with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import jakarta.enterprise.context.RequestScoped; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.annotation.Counted; @Path(\"/cards\") @RequestScoped public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"any-card\") public JsonObject anyCard() throws InterruptedException { return createResponse(\"Here are some random cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } } This class is annotated with Path which sets the path for this resource as /cards . The @RequestScoped annotation defines that this bean is request scoped. The request scope is active only for the duration of one web service invocation and it is destroyed at the end of that invocation. The annotation @Counted will register a Counter metric for this method, creating it if needed. The counter is incremented each time the anyCards method is called. The name attribute is optional. <markup lang=\"bash\" title=\"Build and run the application, then invoke the application endpoints below:\" >curl http://localhost:8080/cards curl http://localhost:8080/cards curl -H \"Accept: application/json\" 'http://localhost:8080/metrics?scope=application' <markup lang=\"json\" title=\"JSON response (partial):\" >{ \"io.helidon.examples.quickstart.mp.GreetingCards.any-card\":2 } The any-card count is two, since you invoked the endpoint twice. Notice the counter is fully qualified. You can remove the package prefix by using the absolute=true field in the @Counted annotation. You must use absolute=false for class-level annotations. Additional Method Level Metrics The @Timed annotation can also be used with a method. For the following example. you can just annotate the same method with @Timed . These metrics collect significant information about the measured methods, but at a cost of some overhead and more complicated output. Note that when using multiple annotations on a method, you must give the metrics different names as shown below. <markup lang=\"java\" title=\"Replace the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import jakarta.enterprise.context.RequestScoped; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.MetricUnits; import org.eclipse.microprofile.metrics.annotation.Counted; import org.eclipse.microprofile.metrics.annotation.Timed; @Path(\"/cards\") @RequestScoped public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"cardCount\", absolute = true) @Timed(name = \"cardTimer\", absolute = true, unit = MetricUnits.MILLISECONDS) public JsonObject anyCard() { return createResponse(\"Here are some random cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } } Specify a custom name for the Counter metric and set absolute=true to remove the path prefix from the name. Add the @Timed annotation to get a Timer metric. <markup lang=\"bash\" title=\"Build and run the application, then invoke the application endpoints below:\" >curl http://localhost:8080/cards curl http://localhost:8080/cards curl -H \"Accept: application/json\" 'http://localhost:8080/metrics?scope=application' <markup lang=\"json\" title=\"JSON response (partial):\" >{ \"cardTimer\": { \"count\": 2, \"max\": 0.002921992, \"mean\": 0.0014682555, \"elapsedTime\": 0.002936511, \"p0.5\": 1.4336e-05, \"p0.75\": 0.003014144, \"p0.95\": 0.003014144, \"p0.98\": 0.003014144, \"p0.99\": 0.003014144, \"p0.999\": 0.003014144 } \"cardCount\": 2 } Reusing Metrics You can share a metric across multiple endpoints simply by specifying the same metric annotation as demonstrated below. <markup lang=\"java\" title=\"Replace the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import jakarta.enterprise.context.RequestScoped; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.annotation.Counted; @Path(\"/cards\") @RequestScoped public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"anyCard\", absolute = true) public JsonObject anyCard() throws InterruptedException { return createResponse(\"Here are some cards ...\"); } @GET @Path(\"/birthday\") @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"specialEventCard\", absolute = true) public JsonObject birthdayCard() throws InterruptedException { return createResponse(\"Here are some birthday cards ...\"); } @GET @Path(\"/wedding\") @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"specialEventCard\", absolute = true) public JsonObject weddingCard() throws InterruptedException { return createResponse(\"Here are some wedding cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } } The /birthday endpoint uses a Counter metric, named specialEventCard . The /wedding endpoint uses the same Counter metric, named specialEventCard . <markup lang=\"bash\" title=\"Build and run the application, then invoke the following endpoints:\" >curl http://localhost:8080/cards/wedding curl http://localhost:8080/cards/birthday curl http://localhost:8080/cards curl -H \"Accept: application/json\" 'http://localhost:8080/metrics?scope=application' <markup lang=\"json\" title=\"JSON response (partial)`:\" >{ \"anyCard\": 1, \"specialEventCard\": 2 } Notice that specialEventCard count is two, since you accessed /cards/wedding and /cards/birthday . Class Level Metrics You can collect metrics at the class-level to aggregate data from all methods in that class using the same metric. The following example introduces a metric to count all card queries. In the following example, the method-level metrics are not needed to aggregate the counts, but they are left in the example to demonstrate the combined output of all three metrics. <markup lang=\"java\" title=\"Replace the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import jakarta.enterprise.context.RequestScoped; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.annotation.Counted; @Path(\"/cards\") @RequestScoped @Counted(name = \"totalCards\") public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) @Counted(absolute = true) public JsonObject anyCard() throws InterruptedException { return createResponse(\"Here are some random cards ...\"); } @Path(\"/birthday\") @GET @Produces(MediaType.APPLICATION_JSON) @Counted(absolute = true) public JsonObject birthdayCard() throws InterruptedException { return createResponse(\"Here are some birthday cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } } This class is annotated with @Counted , which aggregates count data from all the method that have a Count annotation. Use absolute=true to remove path prefix for method-level annotations. Add a method with a Counter metric to get birthday cards. <markup lang=\"bash\" title=\"Build and run the application, then invoke the following endpoints:\" >curl http://localhost:8080/cards curl http://localhost:8080/cards/birthday curl -H \"Accept: application/json\" 'http://localhost:8080/metrics?scope=application' <markup lang=\"json\" title=\"JSON response (partial):\" >{ \"anyCard\": 1, \"birthdayCard\": 1, \"io.helidon.examples.quickstart.mp.totalCards.GreetingCards\": 2 } The totalCards count is a total of all the method-level Counter metrics. Class level metric names are always fully qualified. Field Level Metrics Field level metrics can be injected into managed objects, but they need to be updated by the application code. This annotation can be used on fields of type Timer , Counter , and Histogram . The following example shows how to use a field-level Counter metric to track cache hits. <markup lang=\"java\" title=\"Replace the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import java.util.Random; import jakarta.enterprise.context.RequestScoped; import jakarta.inject.Inject; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.Counter; import org.eclipse.microprofile.metrics.annotation.Counted; import org.eclipse.microprofile.metrics.annotation.Metric; @Path(\"/cards\") @RequestScoped @Counted(name = \"totalCards\") public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @Inject @Metric(name = \"cacheHits\", absolute = true) private Counter cacheHits; @GET @Produces(MediaType.APPLICATION_JSON) @Counted(absolute = true) public JsonObject anyCard() throws InterruptedException { updateStats(); return createResponse(\"Here are some random cards ...\"); } @Path(\"/birthday\") @GET @Produces(MediaType.APPLICATION_JSON) @Counted(absolute = true) public JsonObject birthdayCard() throws InterruptedException { updateStats(); return createResponse(\"Here are some birthday cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } private void updateStats() { if (new Random().nextInt(3) == 1) { cacheHits.inc(); } } } A Counter metric field, cacheHits , is automatically injected by Helidon. Call updateStats() to update the cache hits. Call updateStats() to update the cache hits. Randomly increment the cacheHits counter. <markup lang=\"bash\" title=\"Build and run the application, then invoke the following endpoints:\" >curl http://localhost:8080/cards curl http://localhost:8080/cards curl http://localhost:8080/cards/birthday curl http://localhost:8080/cards/birthday curl http://localhost:8080/cards/birthday curl -H \"Accept: application/json\" 'http://localhost:8080/metrics?scope=application' <markup lang=\"json\" title=\"JSON response (partial):\" >{ \"anyCard\": 2, \"birthdayCard\": 3, \"cacheHits\": 2, \"io.helidon.examples.quickstart.mp.totalCards.GreetingCards\": 5 } The cache was hit two times out of five queries. Gauge Metric The Gauge metric measures a value that is maintained by code outside the metrics subsystem. As with other metrics, the application explicitly registers a gauge. When the /metrics endpoint is invoked, Helidon retrieves the value of each registered Gauge . The following example demonstrates how to use a Gauge to track application up-time. <markup lang=\"java\" title=\"Create a new GreetingCardsAppMetrics class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.time.Duration; import java.util.concurrent.atomic.AtomicLong; import jakarta.enterprise.context.ApplicationScoped; import jakarta.enterprise.context.Initialized; import jakarta.enterprise.event.Observes; import org.eclipse.microprofile.metrics.annotation.Gauge; @ApplicationScoped public class GreetingCardsAppMetrics { private AtomicLong startTime = new AtomicLong(0); public void onStartUp(@Observes @Initialized(ApplicationScoped.class) Object init) { startTime = new AtomicLong(System.currentTimeMillis()); } @Gauge(unit = \"TimeSeconds\") public long appUpTimeSeconds() { return Duration.ofMillis(System.currentTimeMillis() - startTime.get()).getSeconds(); } } This managed object must be application scoped to properly register and use the Gauge metric. Declare an AtomicLong field to hold the start time of the application. Initialize the application start time. Return the application appUpTimeSeconds metric, which will be included in the application metrics. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code to simplify the metrics output:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import jakarta.enterprise.context.RequestScoped; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.annotation.Counted; @Path(\"/cards\") @RequestScoped public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"cardCount\", absolute = true) public JsonObject anyCard() throws InterruptedException { return createResponse(\"Here are some random cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } } <markup lang=\"bash\" title=\"Build and run the application, then invoke the application metrics endpoint:\" >curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response from /metrics/application :\" >{ \"cardCount\": 0, \"io.helidon.examples.quickstart.mp.GreetingCardsAppMetrics.appUpTimeSeconds\": 6 } The application has been running for 6 seconds. ",
            "title": "Application-Specific Metrics Data"
        },
        {
            "location": "/mp/guides/metrics",
            "text": " The following example shows how to integrate the Helidon MP application with Kubernetes. <markup lang=\"bash\" title=\"Stop the application and build the docker image:\" >docker build -t helidon-metrics-mp . <markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named metrics.yaml , with the following content:\" >kind: Service apiVersion: v1 metadata: name: helidon-metrics labels: app: helidon-metrics annotations: prometheus.io/scrape: true spec: type: NodePort selector: app: helidon-metrics ports: - port: 8080 targetPort: 8080 name: http --- kind: Deployment apiVersion: apps/v1 metadata: name: helidon-metrics spec: replicas: 1 selector: matchLabels: app: helidon-metrics template: metadata: labels: app: helidon-metrics version: v1 spec: containers: - name: helidon-metrics image: helidon-metrics-mp imagePullPolicy: IfNotPresent ports: - containerPort: 8080 A service of type NodePort that serves the default routes on port 8080 . An annotation that will allow Prometheus to discover and scrape the application pod. A deployment with one replica of a pod. <markup lang=\"bash\" title=\"Create and deploy the application into Kubernetes:\" >kubectl apply -f ./metrics.yaml <markup lang=\"bash\" title=\"Get the service information:\" >kubectl get service/helidon-metrics <markup lang=\"bash\" >NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE helidon-metrics NodePort 10.99.159.2 &lt;none&gt; 8080:31143/TCP 8s A service of type NodePort that serves the default routes on port 31143 . <markup lang=\"bash\" title=\"Verify the metrics endpoint using port 30116 , your port will likely be different:\" >curl http://localhost:31143/metrics Leave the application running in Kubernetes since it will be used for Prometheus integration. ",
            "title": "Kubernetes Integration"
        },
        {
            "location": "/mp/guides/metrics",
            "text": " The metrics service that you just deployed into Kubernetes is already annotated with prometheus.io/scrape: . This will allow Prometheus to discover the service and scrape the metrics. This example shows how to install Prometheus into Kubernetes, then verify that it discovered the Helidon metrics in your application. <markup lang=\"bash\" title=\"Install Prometheus and wait until the pod is ready:\" >helm install stable/prometheus --name metrics export POD_NAME=$(kubectl get pods --namespace default -l \"app=prometheus,component=server\" -o jsonpath=\"{.items[0].metadata.name}\") kubectl get pod $POD_NAME You will see output similar to the following. Repeat the kubectl get pod command until you see 2/2 and Running . This may take up to one minute. <markup lang=\"bash\" >metrics-prometheus-server-5fc5dc86cb-79lk4 2/2 Running 0 46s <markup lang=\"bash\" title=\"Create a port-forward so you can access the server URL:\" >kubectl --namespace default port-forward $POD_NAME 7090:9090 Now open your browser and navigate to http://localhost:7090/targets . Search for helidon on the page and you will see your Helidon application as one of the Prometheus targets. ",
            "title": "Prometheus Integration"
        },
        {
            "location": "/mp/guides/metrics",
            "text": " You can now delete the Kubernetes resources that were just created during this example. <markup lang=\"bash\" title=\"Delete the Prometheus Kubernetes resources:\" >helm delete --purge metrics <markup lang=\"bash\" title=\"Delete the application Kubernetes resources:\" >kubectl delete -f ./metrics.yaml ",
            "title": "Final Cleanup"
        },
        {
            "location": "/mp/guides/metrics",
            "text": " Kubernetes Integration The following example shows how to integrate the Helidon MP application with Kubernetes. <markup lang=\"bash\" title=\"Stop the application and build the docker image:\" >docker build -t helidon-metrics-mp . <markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named metrics.yaml , with the following content:\" >kind: Service apiVersion: v1 metadata: name: helidon-metrics labels: app: helidon-metrics annotations: prometheus.io/scrape: true spec: type: NodePort selector: app: helidon-metrics ports: - port: 8080 targetPort: 8080 name: http --- kind: Deployment apiVersion: apps/v1 metadata: name: helidon-metrics spec: replicas: 1 selector: matchLabels: app: helidon-metrics template: metadata: labels: app: helidon-metrics version: v1 spec: containers: - name: helidon-metrics image: helidon-metrics-mp imagePullPolicy: IfNotPresent ports: - containerPort: 8080 A service of type NodePort that serves the default routes on port 8080 . An annotation that will allow Prometheus to discover and scrape the application pod. A deployment with one replica of a pod. <markup lang=\"bash\" title=\"Create and deploy the application into Kubernetes:\" >kubectl apply -f ./metrics.yaml <markup lang=\"bash\" title=\"Get the service information:\" >kubectl get service/helidon-metrics <markup lang=\"bash\" >NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE helidon-metrics NodePort 10.99.159.2 &lt;none&gt; 8080:31143/TCP 8s A service of type NodePort that serves the default routes on port 31143 . <markup lang=\"bash\" title=\"Verify the metrics endpoint using port 30116 , your port will likely be different:\" >curl http://localhost:31143/metrics Leave the application running in Kubernetes since it will be used for Prometheus integration. Prometheus Integration The metrics service that you just deployed into Kubernetes is already annotated with prometheus.io/scrape: . This will allow Prometheus to discover the service and scrape the metrics. This example shows how to install Prometheus into Kubernetes, then verify that it discovered the Helidon metrics in your application. <markup lang=\"bash\" title=\"Install Prometheus and wait until the pod is ready:\" >helm install stable/prometheus --name metrics export POD_NAME=$(kubectl get pods --namespace default -l \"app=prometheus,component=server\" -o jsonpath=\"{.items[0].metadata.name}\") kubectl get pod $POD_NAME You will see output similar to the following. Repeat the kubectl get pod command until you see 2/2 and Running . This may take up to one minute. <markup lang=\"bash\" >metrics-prometheus-server-5fc5dc86cb-79lk4 2/2 Running 0 46s <markup lang=\"bash\" title=\"Create a port-forward so you can access the server URL:\" >kubectl --namespace default port-forward $POD_NAME 7090:9090 Now open your browser and navigate to http://localhost:7090/targets . Search for helidon on the page and you will see your Helidon application as one of the Prometheus targets. Final Cleanup You can now delete the Kubernetes resources that were just created during this example. <markup lang=\"bash\" title=\"Delete the Prometheus Kubernetes resources:\" >helm delete --purge metrics <markup lang=\"bash\" title=\"Delete the application Kubernetes resources:\" >kubectl delete -f ./metrics.yaml ",
            "title": "Integration with Kubernetes and Prometheus"
        },
        {
            "location": "/mp/guides/metrics",
            "text": " This guide demonstrated how to use metrics in a Helidon MP application using various combinations of metrics and scopes. Access metrics for all three scopes: base, vendor, and application Configure application metrics at the class, method, and field-level Integrate Helidon metrics with Kubernetes and Prometheus Refer to the following references for additional information: MicroProfile Metrics specification MicroProfile Metrics Javadoc Helidon Javadoc at /apidocs/index.html?overview-summary.html ",
            "title": "Summary"
        },
        {
            "location": "/mp/guides/metrics",
            "text": " For this 30 minute tutorial, you will need the following: <div class=\"table__overflow elevation-1 flex sm7 \"> A Helidon MP Application You can use your own application or use the Helidon MP Quickstart to create a sample application. Java&#160;SE&#160;21 ( Open&#160;JDK&#160;21 ) Helidon requires Java 21+. Maven 3.8+ Helidon requires Maven 3.8+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop . Helm To manage Kubernetes applications. <markup lang=\"bash\" title=\"Verify Prerequisites\" >java -version mvn --version docker --version kubectl version --short <markup lang=\"bash\" title=\"Setting JAVA_HOME\" ># On Mac export JAVA_HOME=`/usr/libexec/java_home -v 21` # On Linux # Use the appropriate path to your JDK export JAVA_HOME=/usr/lib/jvm/jdk-21 Create a Sample Helidon MP Project Use the Helidon MP Maven archetype to create a simple project that can be used for the examples in this guide. <markup lang=\"bash\" title=\"Run the Maven archetype\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-mp \\ -DarchetypeVersion=4.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-mp \\ -Dpackage=io.helidon.examples.quickstart.mp Using the Built-In Metrics Helidon provides three built-in scopes of metrics: base, vendor, and application. Here are the metric endpoints: /metrics?scope=base - Base metrics as specified by the MicroProfile Metrics specification /metrics?scope=vendor - Helidon-specific metrics /metrics?scope=application - Application-specific metrics data. Applications can add their own custom scopes as well simply by specifying a custom scope name when registering a metric. The /metrics endpoint returns data for all scopes. The built-in metrics fall into these categories: JVM behavior (in the base scope), and basic key performance indicators for request handling (in the vendor scope). A later section describes the key performance indicator metrics in detail. The following example demonstrates how to use the other built-in metrics. All examples are executed from the root directory of your project (helidon-quickstart-mp). <markup lang=\"bash\" title=\"Build the application and then run it:\" >mvn package java -jar target/helidon-quickstart-mp.jar Metrics output can be returned in either text format (the default), or JSON. The text format uses OpenMetrics (Prometheus) Text Format, see https://prometheus.io/docs/instrumenting/exposition_formats/#text-format-details . <markup lang=\"bash\" title=\"Verify the metrics endpoint in a new terminal window:\" >curl http://localhost:8080/metrics <markup lang=\"text\" title=\"Text response: (partial)\" ># HELP classloader_loadedClasses_total Displays the total number of classes that have been loaded since the Java virtual machine has started execution. # TYPE classloader_loadedClasses_total counter classloader_loadedClasses_total{mp_scope=\"base\",} 8146.0 # HELP requests_count_total Each request (regardless of HTTP method) will increase this counter # TYPE requests_count_total counter requests_count_total{mp_scope=\"vendor\",} 1.0 # HELP jvm_uptime_seconds Displays the start time of the Java virtual machine in seconds. This attribute displays the approximate time when the Java virtual machine started. # TYPE jvm_uptime_seconds gauge jvm_uptime_seconds{mp_scope=\"base\",} 7.3770 You can get the same data in JSON format. <markup lang=\"bash\" title=\"Verify the metrics endpoint with an HTTP accept header:\" >curl -H \"Accept: application/json\" http://localhost:8080/metrics <markup lang=\"json\" title=\"JSON response (partial):\" >{ \"application\": { \"personalizedGets\": 0, \"allGets\": { \"count\": 0, \"elapsedTime\": 0, \"max\": 0, \"mean\": 0 } }, \"vendor\": { \"requests.count\": 2 }, \"base\": { \"gc.total;name=G1 Concurrent GC\": 2, \"cpu.systemLoadAverage\": 10.3388671875, \"classloader.loadedClasses.count\": 8224, \"thread.count\": 19, \"classloader.unloadedClasses.total\": 0, \"jvm.uptime\": 36.8224 } } You can get a single metric by specifying the scope and name as query parameters in the URL. <markup lang=\"bash\" title=\"Get the Helidon requests.count metric:\" >curl -H \"Accept: application/json\" 'http://localhost:8080/metrics?scope=vendor&amp;name=requests.count' <markup lang=\"json\" title=\"JSON response:\" >{ \"requests.count\": 6 } The base metrics illustrated above provide some insight into the behavior of the JVM in which the server runs. The vendor metric shown above gives an idea of the request traffic the server is handling. See the later section for more information on the basic and extended key performance indicator metrics. Controlling Metrics Behavior By adding a metrics section to your application configuration you can control how the Helidon metrics subsystem behaves in any of several ways. Disable metrics subsystem entirely . Control REST.request metrics. Select whether to collect extended key performance indicator metrics . Disabling Metrics Subsystem Entirely You can disable the metrics subsystem entirely using configuration: <markup lang=\"properties\" title=\"Configuration properties file disabling metrics\" >metrics.enabled=false With metrics processing disabled, Helidon never updates any metrics and the /metrics endpoints respond with 404 . Collecting Basic and Extended Key Performance Indicator (KPI) Metrics Any time you include the Helidon metrics module in your application, Helidon tracks a basic performance indicator metric: a Counter of all requests received ( requests.count ). Helidon MP also includes additional, extended KPI metrics which are disabled by default: current number of requests in-flight - a Gauge ( requests.inFlight ) of requests currently being processed long-running requests - a Counter ( requests.longRunning ) measuring the total number of requests which take at least a given amount of time to complete; configurable, defaults to 10000 milliseconds (10 seconds) load - a Counter ( requests.load ) measuring the number of requests worked on (as opposed to received) deferred - a Gauge ( requests.deferred ) measuring delayed request processing (work on a request was delayed after Helidon received the request) You can enable and control these metrics using configuration: <markup lang=\"properties\" title=\"Configuration properties file controlling extended KPI metrics\" >metrics.key-performance-indicators.extended = true metrics.key-performance-indicators.long-running.threshold-ms = 2000 Controlling REST.request Metrics Helidon MP implements the optional family of metrics, all with the name REST.request , as described in the MicroProfile Metrics specification . Each instance is a Timer with tags class and method identifying exactly which REST endpoint Java method that instance measures. By default, Helidon MP does not enable this feature. Enable it by editing your application configuration to set metrics.rest-request.enabled to true . Note that the applications you generate using the full Helidon archetype do enable this feature in the generated config file. You can see the results in the sample output shown in earlier example runs. Metrics Metadata Each metric has associated metadata that includes: name: The name of the metric. units: The unit of the metric such as time (seconds, milliseconds), size (bytes, megabytes), etc. a description of the metric. You can get the metadata for any scope, such as /metrics?scope=base , as shown below: <markup lang=\"bash\" title=\"Get the metrics metadata using HTTP OPTIONS method:\" > curl -X OPTIONS -H \"Accept: application/json\" 'http://localhost:8080/metrics?scope=base' <markup lang=\"json\" title=\"JSON response (truncated):\" >{ \"classloader.loadedClasses.count\": { \"type\": \"gauge\", \"description\": \"Displays the number of classes that are currently loaded in the Java virtual machine.\" }, \"jvm.uptime\": { \"type\": \"gauge\", \"unit\": \"seconds\", \"description\": \"Displays the start time of the Java virtual machine in milliseconds. This attribute displays the approximate time when the Java virtual machine started.\" }, \"memory.usedHeap\": { \"type\": \"gauge\", \"unit\": \"bytes\", \"description\": \"Displays the amount of used heap memory in bytes.\" } } Application-Specific Metrics Data You can create application-specific metrics and integrate them with Helidon using CDI. To add a new metric, simply annotate the JAX-RS resource with one of the metric annotations. Metrics can be injected at the class, method, and field-levels. This document shows examples of all three. Helidon will automatically create and register annotated application metrics and store them in the application MetricRegistry , which also contains the metric metadata. The metrics will exist for the lifetime of the application. Each metric annotation has mandatory and optional fields. The name field, for example, is optional. Method Level Metrics There are two metrics that you can use by annotating a method: @Counted - Register a Counter metric @Timed - Register a Timer metric The following example will demonstrate how to use the @Counted annotation to track the number of times the /cards endpoint is called. <markup lang=\"java\" title=\"Create a new class GreetingCards with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import jakarta.enterprise.context.RequestScoped; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.annotation.Counted; @Path(\"/cards\") @RequestScoped public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"any-card\") public JsonObject anyCard() throws InterruptedException { return createResponse(\"Here are some random cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } } This class is annotated with Path which sets the path for this resource as /cards . The @RequestScoped annotation defines that this bean is request scoped. The request scope is active only for the duration of one web service invocation and it is destroyed at the end of that invocation. The annotation @Counted will register a Counter metric for this method, creating it if needed. The counter is incremented each time the anyCards method is called. The name attribute is optional. <markup lang=\"bash\" title=\"Build and run the application, then invoke the application endpoints below:\" >curl http://localhost:8080/cards curl http://localhost:8080/cards curl -H \"Accept: application/json\" 'http://localhost:8080/metrics?scope=application' <markup lang=\"json\" title=\"JSON response (partial):\" >{ \"io.helidon.examples.quickstart.mp.GreetingCards.any-card\":2 } The any-card count is two, since you invoked the endpoint twice. Notice the counter is fully qualified. You can remove the package prefix by using the absolute=true field in the @Counted annotation. You must use absolute=false for class-level annotations. Additional Method Level Metrics The @Timed annotation can also be used with a method. For the following example. you can just annotate the same method with @Timed . These metrics collect significant information about the measured methods, but at a cost of some overhead and more complicated output. Note that when using multiple annotations on a method, you must give the metrics different names as shown below. <markup lang=\"java\" title=\"Replace the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import jakarta.enterprise.context.RequestScoped; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.MetricUnits; import org.eclipse.microprofile.metrics.annotation.Counted; import org.eclipse.microprofile.metrics.annotation.Timed; @Path(\"/cards\") @RequestScoped public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"cardCount\", absolute = true) @Timed(name = \"cardTimer\", absolute = true, unit = MetricUnits.MILLISECONDS) public JsonObject anyCard() { return createResponse(\"Here are some random cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } } Specify a custom name for the Counter metric and set absolute=true to remove the path prefix from the name. Add the @Timed annotation to get a Timer metric. <markup lang=\"bash\" title=\"Build and run the application, then invoke the application endpoints below:\" >curl http://localhost:8080/cards curl http://localhost:8080/cards curl -H \"Accept: application/json\" 'http://localhost:8080/metrics?scope=application' <markup lang=\"json\" title=\"JSON response (partial):\" >{ \"cardTimer\": { \"count\": 2, \"max\": 0.002921992, \"mean\": 0.0014682555, \"elapsedTime\": 0.002936511, \"p0.5\": 1.4336e-05, \"p0.75\": 0.003014144, \"p0.95\": 0.003014144, \"p0.98\": 0.003014144, \"p0.99\": 0.003014144, \"p0.999\": 0.003014144 } \"cardCount\": 2 } Reusing Metrics You can share a metric across multiple endpoints simply by specifying the same metric annotation as demonstrated below. <markup lang=\"java\" title=\"Replace the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import jakarta.enterprise.context.RequestScoped; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.annotation.Counted; @Path(\"/cards\") @RequestScoped public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"anyCard\", absolute = true) public JsonObject anyCard() throws InterruptedException { return createResponse(\"Here are some cards ...\"); } @GET @Path(\"/birthday\") @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"specialEventCard\", absolute = true) public JsonObject birthdayCard() throws InterruptedException { return createResponse(\"Here are some birthday cards ...\"); } @GET @Path(\"/wedding\") @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"specialEventCard\", absolute = true) public JsonObject weddingCard() throws InterruptedException { return createResponse(\"Here are some wedding cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } } The /birthday endpoint uses a Counter metric, named specialEventCard . The /wedding endpoint uses the same Counter metric, named specialEventCard . <markup lang=\"bash\" title=\"Build and run the application, then invoke the following endpoints:\" >curl http://localhost:8080/cards/wedding curl http://localhost:8080/cards/birthday curl http://localhost:8080/cards curl -H \"Accept: application/json\" 'http://localhost:8080/metrics?scope=application' <markup lang=\"json\" title=\"JSON response (partial)`:\" >{ \"anyCard\": 1, \"specialEventCard\": 2 } Notice that specialEventCard count is two, since you accessed /cards/wedding and /cards/birthday . Class Level Metrics You can collect metrics at the class-level to aggregate data from all methods in that class using the same metric. The following example introduces a metric to count all card queries. In the following example, the method-level metrics are not needed to aggregate the counts, but they are left in the example to demonstrate the combined output of all three metrics. <markup lang=\"java\" title=\"Replace the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import jakarta.enterprise.context.RequestScoped; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.annotation.Counted; @Path(\"/cards\") @RequestScoped @Counted(name = \"totalCards\") public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) @Counted(absolute = true) public JsonObject anyCard() throws InterruptedException { return createResponse(\"Here are some random cards ...\"); } @Path(\"/birthday\") @GET @Produces(MediaType.APPLICATION_JSON) @Counted(absolute = true) public JsonObject birthdayCard() throws InterruptedException { return createResponse(\"Here are some birthday cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } } This class is annotated with @Counted , which aggregates count data from all the method that have a Count annotation. Use absolute=true to remove path prefix for method-level annotations. Add a method with a Counter metric to get birthday cards. <markup lang=\"bash\" title=\"Build and run the application, then invoke the following endpoints:\" >curl http://localhost:8080/cards curl http://localhost:8080/cards/birthday curl -H \"Accept: application/json\" 'http://localhost:8080/metrics?scope=application' <markup lang=\"json\" title=\"JSON response (partial):\" >{ \"anyCard\": 1, \"birthdayCard\": 1, \"io.helidon.examples.quickstart.mp.totalCards.GreetingCards\": 2 } The totalCards count is a total of all the method-level Counter metrics. Class level metric names are always fully qualified. Field Level Metrics Field level metrics can be injected into managed objects, but they need to be updated by the application code. This annotation can be used on fields of type Timer , Counter , and Histogram . The following example shows how to use a field-level Counter metric to track cache hits. <markup lang=\"java\" title=\"Replace the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import java.util.Random; import jakarta.enterprise.context.RequestScoped; import jakarta.inject.Inject; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.Counter; import org.eclipse.microprofile.metrics.annotation.Counted; import org.eclipse.microprofile.metrics.annotation.Metric; @Path(\"/cards\") @RequestScoped @Counted(name = \"totalCards\") public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @Inject @Metric(name = \"cacheHits\", absolute = true) private Counter cacheHits; @GET @Produces(MediaType.APPLICATION_JSON) @Counted(absolute = true) public JsonObject anyCard() throws InterruptedException { updateStats(); return createResponse(\"Here are some random cards ...\"); } @Path(\"/birthday\") @GET @Produces(MediaType.APPLICATION_JSON) @Counted(absolute = true) public JsonObject birthdayCard() throws InterruptedException { updateStats(); return createResponse(\"Here are some birthday cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } private void updateStats() { if (new Random().nextInt(3) == 1) { cacheHits.inc(); } } } A Counter metric field, cacheHits , is automatically injected by Helidon. Call updateStats() to update the cache hits. Call updateStats() to update the cache hits. Randomly increment the cacheHits counter. <markup lang=\"bash\" title=\"Build and run the application, then invoke the following endpoints:\" >curl http://localhost:8080/cards curl http://localhost:8080/cards curl http://localhost:8080/cards/birthday curl http://localhost:8080/cards/birthday curl http://localhost:8080/cards/birthday curl -H \"Accept: application/json\" 'http://localhost:8080/metrics?scope=application' <markup lang=\"json\" title=\"JSON response (partial):\" >{ \"anyCard\": 2, \"birthdayCard\": 3, \"cacheHits\": 2, \"io.helidon.examples.quickstart.mp.totalCards.GreetingCards\": 5 } The cache was hit two times out of five queries. Gauge Metric The Gauge metric measures a value that is maintained by code outside the metrics subsystem. As with other metrics, the application explicitly registers a gauge. When the /metrics endpoint is invoked, Helidon retrieves the value of each registered Gauge . The following example demonstrates how to use a Gauge to track application up-time. <markup lang=\"java\" title=\"Create a new GreetingCardsAppMetrics class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.time.Duration; import java.util.concurrent.atomic.AtomicLong; import jakarta.enterprise.context.ApplicationScoped; import jakarta.enterprise.context.Initialized; import jakarta.enterprise.event.Observes; import org.eclipse.microprofile.metrics.annotation.Gauge; @ApplicationScoped public class GreetingCardsAppMetrics { private AtomicLong startTime = new AtomicLong(0); public void onStartUp(@Observes @Initialized(ApplicationScoped.class) Object init) { startTime = new AtomicLong(System.currentTimeMillis()); } @Gauge(unit = \"TimeSeconds\") public long appUpTimeSeconds() { return Duration.ofMillis(System.currentTimeMillis() - startTime.get()).getSeconds(); } } This managed object must be application scoped to properly register and use the Gauge metric. Declare an AtomicLong field to hold the start time of the application. Initialize the application start time. Return the application appUpTimeSeconds metric, which will be included in the application metrics. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code to simplify the metrics output:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import jakarta.enterprise.context.RequestScoped; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.annotation.Counted; @Path(\"/cards\") @RequestScoped public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"cardCount\", absolute = true) public JsonObject anyCard() throws InterruptedException { return createResponse(\"Here are some random cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } } <markup lang=\"bash\" title=\"Build and run the application, then invoke the application metrics endpoint:\" >curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response from /metrics/application :\" >{ \"cardCount\": 0, \"io.helidon.examples.quickstart.mp.GreetingCardsAppMetrics.appUpTimeSeconds\": 6 } The application has been running for 6 seconds. Integration with Kubernetes and Prometheus Kubernetes Integration The following example shows how to integrate the Helidon MP application with Kubernetes. <markup lang=\"bash\" title=\"Stop the application and build the docker image:\" >docker build -t helidon-metrics-mp . <markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named metrics.yaml , with the following content:\" >kind: Service apiVersion: v1 metadata: name: helidon-metrics labels: app: helidon-metrics annotations: prometheus.io/scrape: true spec: type: NodePort selector: app: helidon-metrics ports: - port: 8080 targetPort: 8080 name: http --- kind: Deployment apiVersion: apps/v1 metadata: name: helidon-metrics spec: replicas: 1 selector: matchLabels: app: helidon-metrics template: metadata: labels: app: helidon-metrics version: v1 spec: containers: - name: helidon-metrics image: helidon-metrics-mp imagePullPolicy: IfNotPresent ports: - containerPort: 8080 A service of type NodePort that serves the default routes on port 8080 . An annotation that will allow Prometheus to discover and scrape the application pod. A deployment with one replica of a pod. <markup lang=\"bash\" title=\"Create and deploy the application into Kubernetes:\" >kubectl apply -f ./metrics.yaml <markup lang=\"bash\" title=\"Get the service information:\" >kubectl get service/helidon-metrics <markup lang=\"bash\" >NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE helidon-metrics NodePort 10.99.159.2 &lt;none&gt; 8080:31143/TCP 8s A service of type NodePort that serves the default routes on port 31143 . <markup lang=\"bash\" title=\"Verify the metrics endpoint using port 30116 , your port will likely be different:\" >curl http://localhost:31143/metrics Leave the application running in Kubernetes since it will be used for Prometheus integration. Prometheus Integration The metrics service that you just deployed into Kubernetes is already annotated with prometheus.io/scrape: . This will allow Prometheus to discover the service and scrape the metrics. This example shows how to install Prometheus into Kubernetes, then verify that it discovered the Helidon metrics in your application. <markup lang=\"bash\" title=\"Install Prometheus and wait until the pod is ready:\" >helm install stable/prometheus --name metrics export POD_NAME=$(kubectl get pods --namespace default -l \"app=prometheus,component=server\" -o jsonpath=\"{.items[0].metadata.name}\") kubectl get pod $POD_NAME You will see output similar to the following. Repeat the kubectl get pod command until you see 2/2 and Running . This may take up to one minute. <markup lang=\"bash\" >metrics-prometheus-server-5fc5dc86cb-79lk4 2/2 Running 0 46s <markup lang=\"bash\" title=\"Create a port-forward so you can access the server URL:\" >kubectl --namespace default port-forward $POD_NAME 7090:9090 Now open your browser and navigate to http://localhost:7090/targets . Search for helidon on the page and you will see your Helidon application as one of the Prometheus targets. Final Cleanup You can now delete the Kubernetes resources that were just created during this example. <markup lang=\"bash\" title=\"Delete the Prometheus Kubernetes resources:\" >helm delete --purge metrics <markup lang=\"bash\" title=\"Delete the application Kubernetes resources:\" >kubectl delete -f ./metrics.yaml Summary This guide demonstrated how to use metrics in a Helidon MP application using various combinations of metrics and scopes. Access metrics for all three scopes: base, vendor, and application Configure application metrics at the class, method, and field-level Integrate Helidon metrics with Kubernetes and Prometheus Refer to the following references for additional information: MicroProfile Metrics specification MicroProfile Metrics Javadoc Helidon Javadoc at /apidocs/index.html?overview-summary.html ",
            "title": "What You Need"
        },
        {
            "location": "/mp/guides/mp-tutorial",
            "text": " This tutorial describes how to build a Helidon MicroProfile (MP) application from scratch including JSON REST endpoints, metrics, health check, and configuration. ",
            "title": "preambule"
        },
        {
            "location": "/mp/guides/mp-tutorial",
            "text": " For this 30 minute tutorial, you will need the following: <div class=\"table__overflow elevation-1 flex sm7 \"> A Helidon MP Application You can use your own application or use the Helidon MP Quickstart to create a sample application. Java&#160;SE&#160;21 ( Open&#160;JDK&#160;21 ) Helidon requires Java 21+. Maven 3.8+ Helidon requires Maven 3.8+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop . curl (Optional) for testing <markup lang=\"bash\" title=\"Verify Prerequisites\" >java -version mvn --version docker --version kubectl version --short <markup lang=\"bash\" title=\"Setting JAVA_HOME\" ># On Mac export JAVA_HOME=`/usr/libexec/java_home -v 21` # On Linux # Use the appropriate path to your JDK export JAVA_HOME=/usr/lib/jvm/jdk-21 ",
            "title": "What You Need"
        },
        {
            "location": "/mp/guides/mp-tutorial",
            "text": " This tutorial demonstrates how to create the application from scratch, without using the Maven archetypes as a quickstart. Create a new empty directory for the project (for example, helidon-mp-tutorial ). Change into this directory. Create a new Maven POM file (called pom.xml ) and add the following content: <markup lang=\"xml\" title=\"Initial Maven POM file\" >&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;io.helidon.applications&lt;/groupId&gt; &lt;artifactId&gt;helidon-mp&lt;/artifactId&gt; &lt;version&gt;4.0.2&lt;/version&gt; &lt;relativePath/&gt; &lt;/parent&gt; &lt;groupId&gt;io.helidon.examples&lt;/groupId&gt; &lt;artifactId&gt;helidon-mp-tutorial&lt;/artifactId&gt; &lt;name&gt;${project.artifactId}&lt;/name&gt; &lt;properties&gt; &lt;mainClass&gt;io.helidon.examples.Main&lt;/mainClass&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.bundles&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-dependency-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;copy-libs&lt;/id&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;io.smallrye&lt;/groupId&gt; &lt;artifactId&gt;jandex-maven-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;make-index&lt;/id&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/project&gt; The POM file contains the basic project information and configurations needed to get started and does the following: Includes the Helidon MP application parent pom. This parent pom contains dependency and plugin management to keep your application&#8217;s pom simple and clean. Establishes the Maven coordinates for the new project. Sets the mainClass which will be used later when building a JAR file. The class will be created later in this tutorial. Adds a dependency for the MicroProfile bundle which allows the use of MicroProfile features in the application. The helidon-mp parent pom includes dependency management, so you don&#8217;t need to include a version number here. You will automatically use the version of Helidon that matches the version of the parent pom ({helidon.version} in this case). Adds plugins to be executed during the build. The maven-dependency-plugin is used to copy the runtime dependencies into your target directory. The jandex-maven-plugin builds an index of your class files for faster loading. The Helidon parent pom handles the details of configuring these plugins. But you can modify the configuration here. MicroProfile contains features like Metrics, Health Check, Streams Operators, Open Tracing, OpenAPI, REST client, and fault tolerance. You can find detailed information about MicroProfile on the Eclipse MicroProfile site. With this pom.xml , the application can be built successfully with Maven: <markup lang=\"bash\" >mvn clean package This will create a JAR file in the target directory. The warning message JAR will be empty - no content was marked for inclusion! can be ignored for now because there is no actual content in the application yet. ",
            "title": "Create the Maven Project"
        },
        {
            "location": "/mp/guides/mp-tutorial",
            "text": " The actual application logic can be created now. Create a directory for your source code, and then create directories for the package hierarchy: <markup lang=\"bash\" title=\"Create directories for source code\" >mkdir -p src/main/java/io/helidon/examples The application will be a simple REST service that will return a greeting to the caller. The first iteration of the application will contain a resource class and a Main class which will be used to start up the Helidon server and the application. Technically, your own main class is not needed unless you want to control the startup sequence. You can set the mainClass property to io.helidon.microprofile.cdi.Main and it will use Helidon&#8217;s default main class. The GreetResource is defined in the GreetResource.java class as shown below: <markup lang=\"java\" title=\"src/main/java/io/helidon/examples/GreetResource.java\" >package io.helidon.examples; import jakarta.enterprise.context.RequestScoped; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.core.MediaType; import java.util.Collections; @Path(\"/greet\") @RequestScoped public class GreetResource { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) public JsonObject getDefaultMessage() { return JSON.createObjectBuilder() .add(\"message\", \"Hello World\") .build(); } } This class is annotated with Path which sets the path for this resource as /greet . The RequestScoped annotation defines that this bean is request scoped. The request scope is active only for the duration of one web service invocation and it is destroyed at the end of that invocation. You can learn more about scopes and contexts, and how they are used from the Specification . A public JsonObject getDefaultMessage() method is defined which is annotated with GET , meaning it will accept the HTTP GET method. It is also annotated with Produces(MediaType.APPLICATION_JSON) which declares that this method will return JSON data. The method body creates a JSON object containing a single object named \"message\" with the content \"Hello World\". This method will be expanded and improved later in the tutorial. So far this is just a JAX-RS application, with no Helidon or MicroProfile specific code in it. There are many JAX-RS tutorials available if you want to learn more about this kind of application. A main class is also required to start up the server and run the application. If you don&#8217;t use Helidon&#8217;s built-in main class you can define your own: <markup lang=\"java\" title=\"src/main/java/io/helidon/examples/Main.java\" >package io.helidon.examples; import io.helidon.microprofile.server.Server; import java.io.IOException; public final class Main { private Main() { } public static void main(final String[] args) throws IOException { Server server = startServer(); System.out.println(\"http://localhost:\" + server.port() + \"/greet\"); } static Server startServer() { return Server.create().start(); } } In this class, a main method is defined which starts the Helidon MP server and prints out a message with the listen address. Notice that this class has an empty no-args constructor to make sure this class cannot be instantiated. The MicroProfile server is started with the default configuration. Helidon MP applications also require a beans.xml resource file to tell Helidon to use the annotations discussed above to discover Java beans in the application. Create a beans.xml in the src/main/resources/META-INF directory with the following content: <markup lang=\"xml\" title=\"src/main/resources/META-INF/beans.xml\" >&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;beans xmlns=\"http://xmlns.jcp.org/xml/ns/javaee\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/beans_2_0.xsd\" version=\"2.0\" bean-discovery-mode=\"annotated\"&gt; &lt;/beans&gt; The bean-discovery-mode tells Helidon to look for the annotations to discover Java beans in the application. ",
            "title": "Start Implementing the MicroProfile Application"
        },
        {
            "location": "/mp/guides/mp-tutorial",
            "text": " Helidon MP applications are packaged into a JAR file and the dependencies are copied into a libs directory. You can now build the application. <markup lang=\"bash\" title=\"Build the Application\" >mvn package This will build the application jar and save all runtime dependencies in the target/libs directory. This means you can easily start the application by running the application jar file: <markup lang=\"bash\" title=\"Run the application\" >java -jar target/helidon-mp-tutorial.jar At this stage, the application is a very simple \"Hello World\" greeting service. It supports a single GET request for generating a greeting message. The response is encoded using JSON. For example: <markup lang=\"bash\" title=\"Try the Application\" >curl -X GET http://localhost:7001/greet {\"message\":\"Hello World!\"} In the output you can see the JSON output from the getDefaultMessage() method that was discussed earlier. The server has used a default port 7001 . The application can be stopped cleanly by pressing Ctrl+C. ",
            "title": "Build the Application"
        },
        {
            "location": "/mp/guides/mp-tutorial",
            "text": " Helidon MP applications can use the META-INF/microprofile-config.properties file to specify configuration data. This file (resource) is read by default if it is present on the classpath. Create this file in src/main/resources/META-INF with the following content: <markup lang=\"bash\" title=\"Initial microprofile-config.properties\" ># Microprofile server properties server.port=8080 server.host=0.0.0.0 Rebuild the application and run it again. Notice that it now uses port 8080 as specified in the configuration file. You can learn more about options for configuring the Helidon Server on the Server Configuration page. In addition to predefined server properties, application-specific configuration information can be added to this file. Add the app.greeting property to the file as shown below. This property will be used to set the content of greeting message. <markup lang=\"bash\" title=\"Updated META-INF/microprofile-config.properties\" ># Microprofile server properties server.port=8080 server.host=0.0.0.0 # Application properties app.greeting=Hello Add a new \"provider\" class to read this property and make it available to the application. The class will be called GreetingProvider.java and have the following content: <markup lang=\"java\" title=\"src/main/java/io/helidon/examples/GreetingProvider.java\" >package io.helidon.examples; import org.eclipse.microprofile.config.inject.ConfigProperty; import jakarta.enterprise.context.ApplicationScoped; import jakarta.inject.Inject; import java.util.concurrent.atomic.AtomicReference; @ApplicationScoped public class GreetingProvider { private final AtomicReference&lt;String&gt; message = new AtomicReference&lt;&gt;(); @Inject public GreetingProvider(@ConfigProperty(name = \"app.greeting\") String message) { this.message.set(message); } String getMessage() { return message.get(); } void setMessage(String message) { this.message.set(message); } } This class also has the ApplicationScoped annotation, so it will persist for the life of the application. The class contains an AtomicReference to a String where the greeting will be stored. The AtomicReference provides lock-free thread-safe access to the underlying String . The public GreetingProvider(&#8230;&#8203;) constructor is annotated with Inject which tells Helidon to use Contexts and Dependency Injection to provide the needed values. In this case, the String message is annotated with ConfigProperty(name = \"app.greeting\") so Helidon will inject the property from the configuration file with the key app.greeting . This method demonstrates how to read configuration information into the application. A getter and setter are also included in this class. The GreetResource must be updated to use this value instead of the hard coded response. Make the following updates to that class: <markup lang=\"java\" title=\"Updated GreetResource class\" >package io.helidon.examples; import jakarta.enterprise.context.RequestScoped; import jakarta.inject.Inject; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.core.MediaType; import java.util.Collections; @Path(\"/greet\") @RequestScoped public class GreetResource { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); private final GreetingProvider greetingProvider; @Inject public GreetResource(GreetingProvider greetingConfig) { this.greetingProvider = greetingConfig; } @GET @Produces(MediaType.APPLICATION_JSON) public JsonObject getDefaultMessage() { return createResponse(\"World\"); } private JsonObject createResponse(String who) { String msg = String.format(\"%s %s!\", greetingProvider.getMessage(), who); return JSON.createObjectBuilder() .add(\"message\", msg) .build(); } } This updated class adds a GreetingProvider and uses constructor injection to get the value from the configuration file. The logic to create the response message is refactored into a createResponse method and the getDefaultMessage() method is updated to use this new method. In createResponse() the message is obtained from the GreetingProvider which in turn got it from the configuration files. Rebuild and run the application. Notice that it now uses the greeting from the configuration file. Change the configuration file and restart the application, notice that it uses the changed value. To learn more about Helidon MP configuration please see the Config section of the documentation. ",
            "title": "Configuration"
        },
        {
            "location": "/mp/guides/mp-tutorial",
            "text": " In this section, the application will be extended to add a PUT resource method which will allow users to update the greeting and a second GET resource method which will accept a parameter. Here are the two new methods to add to GreetResource.java : <markup lang=\"java\" title=\"New methods for GreetResource.java\" >import jakarta.ws.rs.Consumes; import jakarta.ws.rs.PUT; import jakarta.ws.rs.PathParam; import jakarta.ws.rs.core.Response; // some lines omitted @Path(\"/{name}\") @GET @Produces(MediaType.APPLICATION_JSON) public JsonObject getMessage(@PathParam(\"name\") String name) { return createResponse(name); } @Path(\"/greeting\") @PUT @Consumes(MediaType.APPLICATION_JSON) @Produces(MediaType.APPLICATION_JSON) public Response updateGreeting(JsonObject jsonObject) { if (!jsonObject.containsKey(\"greeting\")) { JsonObject entity = JSON.createObjectBuilder() .add(\"error\", \"No greeting provided\") .build(); return Response.status(Response.Status.BAD_REQUEST).entity(entity).build(); } String newGreeting = jsonObject.getString(\"greeting\"); greetingProvider.setMessage(newGreeting); return Response.status(Response.Status.NO_CONTENT).build(); } The first of these two methods implements a new HTTP GET service that returns JSON and it has a path parameter. The Path annotation defines the next part of the path to be a parameter named name . In the method arguments the PathParam(\"name\") annotation on String name has the effect of passing the parameter from the URL into this method as name . The second method implements a new HTTP PUT service which produces and consumes JSON, note the Consumes and PUT annotations. It also defines a path of \"/greeting\". Notice that the method argument is a JsonObject . Inside the method body there is code to check for the expected JSON, extract the value and update the message in the GreetingProvider . Rebuild and run the application. Test the new services using curl commands similar to those shown below: <markup lang=\"bash\" title=\"Testing the new services\" >curl -X GET http://localhost:8080/greet {\"message\":\"Hello World!\"} curl -X GET http://localhost:8080/greet/Joe {\"message\":\"Hello Joe!\"} curl -X PUT -H \"Content-Type: application/json\" -d '{\"greeting\" : \"Hola\"}' http://localhost:8080/greet/greeting curl -X GET http://localhost:8080/greet/Jose {\"message\":\"Hola Jose!\"} Helidon MP provides many other features which can be added to the application. ",
            "title": "Extending the Application"
        },
        {
            "location": "/mp/guides/mp-tutorial",
            "text": " The application logging can be customized. The default logging provider is java.util.logging , however it is possible to use other providers. In this tutorial the default provider is used. Create a logging.properties file in src/main/resources with the following content: <markup lang=\"properties\" title=\"Example logging.properties file\" ># Send messages to the console handlers=io.helidon.logging.jul.HelidonConsoleHandler # HelidonConsoleHandler uses a SimpleFormatter subclass that replaces \"!thread!\" with the current thread java.util.logging.SimpleFormatter.format=%1$tY.%1$tm.%1$td %1$tH:%1$tM:%1$tS %4$s %3$s !thread!: %5$s%6$s%n # Global logging level. Can be overridden by specific loggers .level=INFO The Helidon console logging handler is configured. This handler writes to System.out , does not filter by level and uses a custom SimpleFormatter that supports thread names. The format string is set using the standard options to include the timestamp, thread name and message. The global logging level is set to INFO . The Helidon MicroProfile server will detect the new logging.properties file and configure the LogManager for you. Rebuild and run the application and notice the new logging format takes effect. <markup lang=\"bash\" title=\"Log output\" >// before Aug 22, 2019 11:10:11 AM io.helidon.webserver.LoomWebServer lambda$start$8 INFO: Channel '@default' started: [id: 0xd0afba31, L:/0:0:0:0:0:0:0:0:8080] Aug 22, 2019 11:10:11 AM io.helidon.microprofile.server.ServerImpl lambda$start$10 INFO: Server started on http://localhost:8080 (and all other host addresses) in 182 milliseconds. http://localhost:8080/greet // after 2019.08.22 11:24:42 INFO io.helidon.webserver.LoomServer Thread[main,5,main]: Version: 1.2.0 2019.08.22 11:24:42 INFO io.helidon.webserver.LoomServer Thread[nioEventLoopGroup-2-1,10,main]: Channel '@default' started: [id: 0x8f652dfe, L:/0:0:0:0:0:0:0:0:8080] 2019.08.22 11:24:42 INFO io.helidon.microprofile.server.ServerImpl Thread[nioEventLoopGroup-2-1,10,main]: Server started on http://localhost:8080 (and all other host addresses) in 237 milliseconds. http://localhost:8080/greet ",
            "title": "Logging"
        },
        {
            "location": "/mp/guides/mp-tutorial",
            "text": " Helidon provides built-in support for metrics endpoints. <markup lang=\"bash\" title=\"Metrics in Prometheus Format\" >curl -s -X GET http://localhost:8080/metrics <markup lang=\"bash\" title=\"Metrics in JSON Format\" >curl -H 'Accept: application/json' -X GET http://localhost:8080/metrics It is possible to disable metrics by adding properties to the microprofile-config.properties file, for example: <markup lang=\"bash\" title=\"Disable a metric\" >metrics.base.classloader.currentLoadedClass.count.enabled=false Call the metrics endpoint before adding this change to confirm that the metric is included, then add the property to disable the metric, rebuild and restart the application and check again: <markup lang=\"bash\" title=\"Checking metrics before and after disabling the metric\" ># before curl -s http://localhost:8080/metrics | grep classloader_current # TYPE base:classloader_current_loaded_class_count counter # HELP base:classloader_current_loaded_class_count Displays the number of classes that are currently loaded in the Java virtual machine. base:classloader_current_loaded_class_count 7936 # after curl -s http://localhost:8080/metrics | grep classloader_current # (no output) Helidon also support custom metrics. To add a new metric, annotate the JAX-RS resource with one of the metric annotations as shown in the example below: You can find details of the available annotations in the MicroProfile Metrics Specification . <markup lang=\"java\" title=\"Updated GreetResource.java with custom metrics\" >import org.eclipse.microprofile.metrics.annotation.Timed; // some lines omitted @GET @Produces(MediaType.APPLICATION_JSON) @Timed public JsonObject getDefaultMessage() { return createResponse(\"World\"); } The Timed annotation is added to the getDefaultMessage() method. Rebuild and run the application. Make some calls to the endpoint ( http://localhost:8080/greet ) so there will be some data to report. Then obtain the application metrics as follows: <markup lang=\"bash\" title=\"Checking the application metrics\" >curl -H \"Accept: application/json\" http://localhost:8080/metrics/application { \"io.helidon.examples.GreetResource.getDefaultMessage\": { \"count\": 2, \"meanRate\": 0.036565171873527716, \"oneMinRate\": 0.015991117074135343, \"fiveMinRate\": 0.0033057092356765017, \"fifteenMinRate\": 0.0011080303990206543, \"min\": 78658, \"max\": 1614077, \"mean\": 811843.8728029992, \"stddev\": 766932.8494434259, \"p50\": 78658, \"p75\": 1614077, \"p95\": 1614077, \"p98\": 1614077, \"p99\": 1614077, \"p999\": 1614077 } } Learn more about using Helidon and MicroProfile metrics in the Metrics Guide . ",
            "title": "Metrics"
        },
        {
            "location": "/mp/guides/mp-tutorial",
            "text": " Helidon provides built-in support for health check endpoints. Obtain the built-in health check using the following URL: <markup lang=\"bash\" title=\"Health check\" >curl -s -X GET http://localhost:8080/health { \"outcome\": \"UP\", \"status\": \"UP\", \"checks\": [ { \"name\": \"deadlock\", \"state\": \"UP\", \"status\": \"UP\" }, { \"name\": \"diskSpace\", \"state\": \"UP\", \"status\": \"UP\", \"data\": { \"free\": \"381.23 GB\", \"freeBytes\": 409340088320, \"percentFree\": \"43.39%\", \"total\": \"878.70 GB\", \"totalBytes\": 943491723264 } }, { \"name\": \"heapMemory\", \"state\": \"UP\", \"status\": \"UP\", \"data\": { \"free\": \"324.90 MB\", \"freeBytes\": 340682920, \"max\": \"3.46 GB\", \"maxBytes\": 3715629056, \"percentFree\": \"97.65%\", \"total\": \"408.00 MB\", \"totalBytes\": 427819008 } } ] } Endpoints for readiness and liveness checks are also provided by default. Obtain the default results using these URLs, which return the same result as the previous example.: <markup lang=\"bash\" title=\"Default readiness and liveness endpoints\" ># readiness curl -i -X GET http://localhost:8080/health/ready # liveness curl -i -X GET http://localhost:8080/health/live Helidon allows the addition of custom health checks to applications. Create a new class GreetHealthcheck.java with the following content: <markup lang=\"java\" title=\"src/main/java/io/helidon/examples/GreetHealthcheck.java\" >package io.helidon.examples; import jakarta.enterprise.context.ApplicationScoped; import jakarta.inject.Inject; import org.eclipse.microprofile.health.HealthCheck; import org.eclipse.microprofile.health.HealthCheckResponse; import org.eclipse.microprofile.health.Liveness; @Liveness @ApplicationScoped public class GreetHealthcheck implements HealthCheck { private GreetingProvider provider; @Inject public GreetHealthcheck(GreetingProvider provider) { this.provider = provider; } @Override public HealthCheckResponse call() { String message = provider.getMessage(); return HealthCheckResponse.named(\"greeting\") .state(\"Hello\".equals(message)) .withData(\"greeting\", message) .build(); } } This class has the MicroProfile Liveness annotation which tells Helidon that this class provides a custom health check. You can learn more about the available annotations in the MicroProfile Health Protocol and Wireformat document. This class also has the ApplicationScoped annotation, as seen previously. The GreetingProvider is injected using Context and Dependency Injection. This example will use the greeting to determine whether the application is healthy, this is a contrived example for demonstration purposes. Health checks must implement the HealthCheck functional interface, which includes the method HealthCheckResponse call() . Helidon will invoke the call() method to verify the healthiness of the application. In this example, the application is deemed to be healthy if the GreetingProvider,getMessage() method returns the string \"Hello\" and unhealthy otherwise. Rebuild the application, make sure that the mp.conf has the greeting set to something other than \"Hello\" and then run the application and check the health: <markup lang=\"bash\" title=\"Custom health check reporting unhealthy state\" >curl -i -X GET http://localhost:8080/health/live HTTP/1.1 503 Service Unavailable Content-Type: application/json Date: Fri, 23 Aug 2019 10:07:23 -0400 transfer-encoding: chunked connection: keep-alive {\"outcome\":\"DOWN\",\"status\":\"DOWN\",\"checks\":[{\"name\":\"deadlock\",\"state\":\"UP\",\"status\":\"UP\"},{\"name\":\"diskSpace\",\"state\":\"UP\",\"status\":\"UP\",\"data\":{\"free\":\"381.08 GB\",\"freeBytes\":409182306304,\"percentFree\":\"43.37%\",\"total\":\"878.70 GB\",\"totalBytes\":943491723264}},{\"name\":\"greeting\",\"state\":\"DOWN\",\"status\":\"DOWN\",\"data\":{\"greeting\":\"Hey\"}},{\"name\":\"heapMemory\",\"state\":\"UP\",\"status\":\"UP\",\"data\":{\"free\":\"243.81 MB\",\"freeBytes\":255651048,\"max\":\"3.46 GB\",\"maxBytes\":3715629056,\"percentFree\":\"98.58%\",\"total\":\"294.00 MB\",\"totalBytes\":308281344}}]} The HTTP return code is now 503 Service Unavailable. The status is reported as \"DOWN\" and the custom check is included in the output. Now update the greeting to \"Hello\" using the following request, and then check health again: <markup lang=\"bash\" title=\"Update the greeting and check health again\" ># update greeting curl -i -X PUT -H \"Content-Type: application/json\" -d '{\"greeting\": \"Hello\"}' http://localhost:8080/greet/greeting HTTP/1.1 204 No Content Date: Thu, 22 Aug 2019 13:29:57 -0400 connection: keep-alive # check health curl -i -X GET http://localhost:8080/health/live HTTP/1.1 200 OK Content-Type: application/json Date: Fri, 23 Aug 2019 10:08:09 -0400 connection: keep-alive content-length: 536 {\"outcome\":\"UP\",\"status\":\"UP\",\"checks\":[{\"name\":\"deadlock\",\"state\":\"UP\",\"status\":\"UP\"},{\"name\":\"diskSpace\",\"state\":\"UP\",\"status\":\"UP\",\"data\":{\"free\":\"381.08 GB\",\"freeBytes\":409179811840,\"percentFree\":\"43.37%\",\"total\":\"878.70 GB\",\"totalBytes\":943491723264}},{\"name\":\"greeting\",\"state\":\"UP\",\"status\":\"UP\",\"data\":{\"greeting\":\"Hello\"}},{\"name\":\"heapMemory\",\"state\":\"UP\",\"status\":\"UP\",\"data\":{\"free\":\"237.25 MB\",\"freeBytes\":248769720,\"max\":\"3.46 GB\",\"maxBytes\":3715629056,\"percentFree\":\"98.40%\",\"total\":\"294.00 MB\",\"totalBytes\":308281344}}]} The PUT returns a HTTP 204. The health check now returns a HTTP 200. The status is now reported as \"UP\" and the details are provided in the checks. Learn more about health checks in the Health Check Guide . ",
            "title": "Health Check"
        },
        {
            "location": "/mp/guides/mp-tutorial",
            "text": " To run the application in Docker (or Kubernetes), a Dockerfile is needed to build a Docker image. To build the Docker image, you need to have Docker installed and running on your system. Add a new Dockerfile in the project root directory with the following content: <markup lang=\"bash\" title=\"Dockerfile content\" >FROM container-registry.oracle.com/java/openjdk:21 as build # Install maven WORKDIR /usr/share RUN set -x &amp;&amp; \\ curl -O https://archive.apache.org/dist/maven/maven-3/3.8.4/binaries/apache-maven-3.8.4-bin.tar.gz &amp;&amp; \\ tar -xvf apache-maven-*-bin.tar.gz &amp;&amp; \\ rm apache-maven-*-bin.tar.gz &amp;&amp; \\ mv apache-maven-* maven &amp;&amp; \\ ln -s /usr/share/maven/bin/mvn /bin/ WORKDIR /helidon ADD pom.xml . RUN mvn package -DskipTests ADD src src RUN mvn package -DskipTests RUN echo \"done!\" FROM container-registry.oracle.com/java/openjdk:21 WORKDIR /helidon COPY --from=build /helidon/target/helidon-mp-tutorial.jar ./ COPY --from=build /helidon/target/libs ./libs CMD [\"java\", \"-jar\", \"helidon-mp-tutorial.jar\"] EXPOSE 8080 This Dockerfile uses Docker&#8217;s multi-stage build feature. The FROM keyword creates the first stage. In this stage, the base container has the build tools needed to build the application. These are not required to run the application, so the second stage uses a smaller container. Add the pom.xml and running an \"empty\" maven build will download all of the dependencies and plugins in this layer. This will make future builds faster because they will use this cached layer rather than downloading everything again. Add the source code and do the real build. Copy the binary and libraries from the first stage. Set the initial command and expose port 8080. To create the Docker image, use the following command: <markup lang=\"bash\" title=\"Docker build\" >docker build -t helidon-mp-tutorial . Make sure the application is shutdown if it was still running locally so that port 8080 will not be in use, then start the application in Docker using the following command: <markup lang=\"bash\" title=\"Run Docker Image\" >docker run --rm -p 8080:8080 helidon-mp-tutorial:latest Try the application as before. <markup lang=\"bash\" title=\"Try the application\" >curl http://localhost:8080/greet/bob {\"message\":\"Howdee bob!\"} curl http://localhost:8080/health/ready {\"outcome\":\"UP\",\"status\":\"UP\",\"checks\":[]} ",
            "title": "Build a Docker Image"
        },
        {
            "location": "/mp/guides/mp-tutorial",
            "text": " If you don&#8217;t have access to a Kubernetes cluster, you can install one on your desktop . Then deploy the example: <markup lang=\"bash\" title=\"Verify connectivity to cluster\" >kubectl cluster-info kubectl get nodes To deploy the application to Kubernetes, a Kubernetes YAML file that defines the deployment and associated resources is needed. In this case all that is required is the deployment and a service. Create a file called app.yaml in the project&#8217;s root directory with the following content: <markup lang=\"yaml\" title=\"Kubernetes YAML file\" >--- kind: Service apiVersion: v1 metadata: name: helidon-mp-tutorial labels: app: helidon-mp-tutorial spec: type: NodePort selector: app: helidon-mp-tutorial ports: - port: 8080 targetPort: 8080 name: http --- kind: Deployment apiVersion: apps/v1 metadata: name: helidon-mp-tutorial spec: replicas: 1 selector: matchLabels: app: helidon-mp-tutorial template: metadata: labels: app: helidon-mp-tutorial version: v1 spec: containers: - name: helidon-mp-tutorial image: helidon-mp-tutorial imagePullPolicy: IfNotPresent ports: - containerPort: 8080 Define a Service to provide access to the application. Define a NodePort to expose the application outside the Kubernetes cluster. Define a Deployment of the application. Define how many replicas of the application to run. Define the Docker image to use - this must be the one that was built in the previous step. If the image was built on a different machine to the one where Kubernetes is running, or if Kubernetes is running on multiple machines (worker nodes) then the image must either be manually copied to each node or otherwise pushed to a Docker registry that is accessible to the worker nodes. This Kubernetes YAML file can be used to deploy the application to Kubernetes: <markup lang=\"bash\" title=\"Deploy the application to Kubernetes\" >kubectl create -f app.yaml kubectl get pods # Wait for quickstart pod to be RUNNING Remember, if Kubernetes is running on a different machine, or inside a VM (as in Docker for Desktop) then the Docker image must either be manually copied to the Kubernetes worker nodes or pushed to a Docker registry that is accessible to those worker nodes. Update the image entry in the example above to include the Docker registry name. If the registry is private a Docker registry secret will also be required. The step above created a service that is exposed using any available node port. Kubernetes allocates a free port. Lookup the service to find the port. <markup lang=\"bash\" title=\"Lookup the service\" >kubectl get service helidon-mp-tutorial Note the PORTs. The application can be exercised as before but use the second port number (the NodePort) instead of 8080. For example: <markup lang=\"bash\" title=\"Access the application\" >curl -X GET http://localhost:31431/greet If desired, the Kubernetes YAML file can also be used to remove the application from Kubernetes as follows: <markup lang=\"bash\" title=\"Remove the application from Kubernetes\" >kubectl delete -f app.yaml ",
            "title": "Deploy the application to Kubernetes"
        },
        {
            "location": "/mp/guides/mp-tutorial",
            "text": " This tutorial demonstrated how to build a new Helidon MP application, how to use Helidon and MicroProfile configuration, logging, metrics, and health checks. It also demonstrated how to package the application in a Docker image and run it in Kubernetes. There were several links to more detailed information included in the tutorial. These links are repeated below and can be explored to learn more details about Helidon application development. ",
            "title": "Summary"
        },
        {
            "location": "/mp/guides/mp-tutorial",
            "text": " Eclipse MicroProfile Contexts and Dependency Injection Specification Server Configuration Config MicroProfile Metrics Specification Metrics Guide MicroProfile Health Protocol and Wireformat Install Kubernetes on your desktop ",
            "title": "Related links"
        },
        {
            "location": "/mp/guides/overview",
            "text": " Quickstart MP Create your first Helidon MP application in under 5 minutes. ",
            "title": "Getting Started"
        },
        {
            "location": "/mp/guides/overview",
            "text": " MP Config Guide Learn how to configure a Helidon MP application. MP Health Check Guide Learn how to use Helidon MP built-in and custom health checks. MP Metrics Guide Learn how to use Helidon MP built-in and application metrics. MP Tracing Guide Learn how to trace a Helidon MP application. Helidon MP Tutorial Learn how to build a Helidon MicroProfile (MP) application from scratch. Helidon MP Upgrade guide Learn how to upgrade your Helidon MP application from 1.x to 2.x. OIDC Tutorial Learn how to set up OIDC security in your Helidon MP application. Helidon MP Tracing Learn how to use tracing in your Helidon MP application. Testing with JUnit 5 Learn how to use JUnit5 for testing your applications. Helidon MP and JBatch Learn how to use JBatch with Helidon MP. Performance tuning in Helidon MP Learn how to improve performance of your application. ",
            "title": "Helidon MP Guides"
        },
        {
            "location": "/mp/guides/overview",
            "text": " Maven Guide Using Helidon in your Maven project. Gradle Guide Using Helidon in your Gradle project. GraalVM Native Images Learn how to build a GraalVM native image for your Helidon application both on your desktop and as part of a Docker image. Custom Runtime Images using jlink Learn how to build a custom runtime Java image for your Helidon application both on your desktop and as part of a Docker image. Building Container Images with Jib Learn how to use Jib to create a container image without Docker. Deploying to OKE Learn how to deploy your application to Oracle Cloud Infrastructure Container Engine for Kubernetes (OKE). ",
            "title": "Build and Deploy"
        },
        {
            "location": "/mp/guides/performance-tuning",
            "text": " In this guide you fill find basic advice for performance tuning of your Helidon application. Most of this concerns tuning Helidon WebServer, but you should also consider configuring/tuning Java heap size as per any Java application. ",
            "title": "Introduction"
        },
        {
            "location": "/mp/guides/performance-tuning",
            "text": " Use helidon-microprofile-core dependency (and not the helidon-microprofile dependency) and add only what you use. For example: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.bundles&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-core&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-metrics&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.health&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-health&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Use io.helidon.microprofile.bundles:helidon-microprofile-core "
        },
        {
            "location": "/mp/guides/performance-tuning",
            "text": " Helidon WebServer is in large part self tuning. It uses default values that will satisfy most use cases, and with the adoption of Java virtual threads there is no longer a need to tune pools of platform threads. Still, there might be cases where you wish to change configuration options from their default values. For details on the following options please see: WebServer Configuration WebServer Connection Configuration WebServer Socket Configuration ",
            "title": "WebServer Tuning"
        },
        {
            "location": "/mp/guides/performance-tuning",
            "text": " The following application.yaml snippet shows some configuration options that can be used to tune your application. It is intended to show configuration options in context. Please make sure you understand these options before using them. See the documentation referenced above. <markup lang=\"yaml\" title=\"application.yaml snippet\" >server: # These are used to prevent unbounded resource consumption of the server idle-connection-period: PT2M # Check idle connections every 2 minutes idle-connection-timeout: PT5M # Close connections that have been idle for 5 minutes max-concurrent-requests: NNNN # Maximum number of concurrent requests. -1 is unlimited. max-tcp-connections: NNNN # Max number of concurrent tcp connections. -1 is unlimited. max-in-memory-entity: NNNNNN # Entities smaller than this are buffered in memory vs streamed (bytes) max-payload-size: NNNNNNN # Reject requests with payload sizes greater than this. -1 is unlimited (bytes) # Depends on the workload and kernel version backlog: NNNN receive-buffer-size: NNNNN write-buffer-size: NNNNN write-queue-length: NN # 0 means direct write connection-options: # 0 means indefinite (and less clutter on socket impl) read-timeout: PT0S connect-timeout: PT0S # Default (false: Nagle's algorithm enabled) is best for most cases. But for some OS and # workloads enabling TCP_NODELAY (disable Nagle's algorithm) can improve performance. tcp-no-delay: true|false # The default is TCP autotuning which is best for most cases. socket-send-buffer-size: NNNNN socket-receive-buffer-size: NNNNN # Protocol validation. # Careful with this! Can be dangerous if you turn these off. protocols: \"http_1_1\": validate-request-headers: true|false validate-response-headers: true|false validate-path: true|false recv-log: true|false send-log: true|false ",
            "title": "Summary of Tuning Options"
        },
        {
            "location": "/mp/guides/quickstart",
            "text": " This guide describes a basic example of an Helidon MP application using Docker and Kubernetes. ",
            "title": "preambule"
        },
        {
            "location": "/mp/guides/quickstart",
            "text": " For this 5 minute tutorial, you will need the following: <div class=\"table__overflow elevation-1 flex sm7 \"> A Helidon MP Application You can use your own application or use the Helidon MP Quickstart to create a sample application. Java&#160;SE&#160;21 ( Open&#160;JDK&#160;21 ) Helidon requires Java 21+. Maven 3.8+ Helidon requires Maven 3.8+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop . <markup lang=\"bash\" title=\"Verify Prerequisites\" >java -version mvn --version docker --version kubectl version --short <markup lang=\"bash\" title=\"Setting JAVA_HOME\" ># On Mac export JAVA_HOME=`/usr/libexec/java_home -v 21` # On Linux # Use the appropriate path to your JDK export JAVA_HOME=/usr/lib/jvm/jdk-21 ",
            "title": "What You Need"
        },
        {
            "location": "/mp/guides/quickstart",
            "text": " Generate the project sources using one (or both) of the Helidon Maven archetypes. The result is a simple project that shows the basics of configuring the WebServer and implementing basic routing rules. <markup lang=\"bash\" title=\"Run the Maven archetype\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-mp \\ -DarchetypeVersion=4.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-mp \\ -Dpackage=io.helidon.examples.quickstart.mp The archetype generates a Maven project in your current directory (for example, helidon-quickstart-mp ). Change into this directory. <markup lang=\"bash\" >cd helidon-quickstart-mp If you want to use the generated project as a starter for your own application, then you can replace groupId, artifactId and package with values appropriate for your application. <markup lang=\"bash\" title=\"Build the Application\" >mvn package The project builds an application jar for the example and saves all runtime dependencies in the target/libs directory. This means you can easily start the application by running the application jar file: <markup lang=\"bash\" title=\"Run the application\" >java -jar target/helidon-quickstart-mp.jar The example is a very simple \"Hello World\" greeting service. It supports GET requests for generating a greeting message, and a PUT request for changing the greeting itself. The response is encoded using JSON. For example: <markup lang=\"bash\" title=\"Try the Application\" >curl -X GET http://localhost:8080/greet {\"message\":\"Hello World!\"} curl -X GET http://localhost:8080/greet/Joe {\"message\":\"Hello Joe!\"} curl -X PUT -H \"Content-Type: application/json\" -d '{\"greeting\" : \"Hola\"}' http://localhost:8080/greet/greeting curl -X GET http://localhost:8080/greet/Jose {\"message\":\"Hola Jose!\"} ",
            "title": "Generate the Project"
        },
        {
            "location": "/mp/guides/quickstart",
            "text": " Helidon provides built-in support for health and metrics endpoints. <markup lang=\"bash\" title=\"Health\" >curl -s -X GET http://localhost:8080/health <markup lang=\"bash\" title=\"Metrics in Prometheus Format\" >curl -s -X GET http://localhost:8080/metrics <markup lang=\"bash\" title=\"Metrics in JSON Format\" >curl -H 'Accept: application/json' -X GET http://localhost:8080/metrics ",
            "title": "Health and Metrics"
        },
        {
            "location": "/mp/guides/quickstart",
            "text": " The project also contains a Dockerfile so that you can easily build and run a Docker image. To build the Docker image, you need to have Docker installed and running on your system. <markup lang=\"bash\" title=\"Docker build\" >docker build -t helidon-quickstart-mp . <markup lang=\"bash\" title=\"Run Docker Image\" >docker run --rm -p 8080:8080 helidon-quickstart-mp:latest Then you can try the application as you did before. ",
            "title": "Build a Docker Image"
        },
        {
            "location": "/mp/guides/quickstart",
            "text": " If you don&#8217;t have access to a Kubernetes cluster, you can install one on your desktop . Then deploy the example: <markup lang=\"bash\" title=\"Verify connectivity to cluster\" >kubectl cluster-info kubectl get nodes <markup lang=\"bash\" title=\"Deploy the application to Kubernetes\" >kubectl create -f app.yaml kubectl get pods # Wait for quickstart pod to be RUNNING The step above created a service that is exposed into any node port. Lookup the service to find the port. <markup lang=\"bash\" title=\"Lookup the service\" >kubectl get service helidon-quickstart-mp Note the PORTs. You can now exercise the application as you did before but use the second port number (the NodePort) instead of 8080. For example: <markup lang=\"bash\" >curl -X GET http://localhost:31431/greet After you&#8217;re done, cleanup. <markup lang=\"bash\" title=\"Remove the application from Kubernetes\" >kubectl delete -f app.yaml ",
            "title": "Deploy the Application to Kubernetes"
        },
        {
            "location": "/mp/guides/quickstart",
            "text": " Helidon also includes support for GraalVM Native Images and Java Custom Runtime Images. For more information see: GraalVM Native Images Custom Runtime Images using jlink ",
            "title": "Building Native and Custom Runtime Images"
        },
        {
            "location": "/mp/guides/quickstart",
            "text": " With the Helidon CLI you can create additional types of Helidon applications and use the \"dev loop\" to do fast, iterative development. Try it now . ",
            "title": "The Helidon CLI"
        },
        {
            "location": "/mp/guides/se-services",
            "text": " This guide shows how reuse Helidon SE Service in your Helidon MP application. ",
            "title": "preambule"
        },
        {
            "location": "/mp/guides/se-services",
            "text": " For this 10 minute tutorial, you will need the following: <div class=\"table__overflow elevation-1 flex sm7 \"> A Helidon MP Application You can use your own application or use the Helidon MP Quickstart to create a sample application. Java&#160;SE&#160;21 ( Open&#160;JDK&#160;21 ) Helidon requires Java 21+. Maven 3.8+ Helidon requires Maven 3.8+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop . <markup lang=\"bash\" title=\"Verify Prerequisites\" >java -version mvn --version docker --version kubectl version --short <markup lang=\"bash\" title=\"Setting JAVA_HOME\" ># On Mac export JAVA_HOME=`/usr/libexec/java_home -v 21` # On Linux # Use the appropriate path to your JDK export JAVA_HOME=/usr/lib/jvm/jdk-21 Helidon MP supports WebServer routing which brings possibility for reusing io.helidon.webserver.HttpService implementations in Helidon MP. Such feature can be quite useful for common solutions for filtering, auditing, logging or augmenting REST endpoints in hybrid Helidon SE/MP environment. Let&#8217;s define simple Helidon SE Service for adding special header to every REST response: <markup lang=\"java\" >public class CoolingService implements HttpService, Handler { public static final String COOL_HEADER_NAME = \"Cool-Header\"; public static final String COOLING_VALUE = \"This is way cooler response than \"; @Override public void routing(HttpRules rules) { rules.any(this); } @Override public void accept(ServerRequest req, ServerResponse res) { res.headers().add(COOL_HEADER_NAME, COOLING_VALUE); req.next(); } } Its easy to use it with Helidon SE: <markup lang=\"java\" >WebServer.builder(Routing.builder() // register service with routing path .register(\"/cool\", new CoolingService()) .build()) .config(config) .addMediaSupport(JsonpSupport.create()) .build() .start(); And not much harder to use it with Helidon MP: <markup lang=\"java\" >@ApplicationScoped public class MyBean { @Produces @ApplicationScoped @RoutingPath(\"/cool\") public Service coolService() { return new CoolingService(); } } You can leverage annotations: @RoutingPath - path of the WebServer service @RoutingName - select routing when serving requests on multiple ports ",
            "title": "What You Need"
        },
        {
            "location": "/mp/guides/security-oidc",
            "text": " This guide describes how to set up Keycloak and Helidon to secure an application with OIDC security provider. ",
            "title": "preambule"
        },
        {
            "location": "/mp/guides/security-oidc",
            "text": " For this 20 minute tutorial, you will need the following: <div class=\"table__overflow elevation-1 flex sm7 \"> A Helidon MP Application You can use your own application or use the Helidon MP Quickstart to create a sample application. Java&#160;SE&#160;21 ( Open&#160;JDK&#160;21 ) Helidon requires Java 21+. Maven 3.8+ Helidon requires Maven 3.8+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop . <markup lang=\"bash\" title=\"Verify Prerequisites\" >java -version mvn --version docker --version kubectl version --short <markup lang=\"bash\" title=\"Setting JAVA_HOME\" ># On Mac export JAVA_HOME=`/usr/libexec/java_home -v 21` # On Linux # Use the appropriate path to your JDK export JAVA_HOME=/usr/lib/jvm/jdk-21 ",
            "title": "What You Need"
        },
        {
            "location": "/mp/guides/security-oidc",
            "text": " This guide describes the steps required to protect your whole application or a specific area with Open ID Connect (OIDC) security. OIDC is a secure mechanism for an application to contact an identity service. Its built on top of OAuth 2.0 and provides full-fledged authentication and authorization protocols. ",
            "title": "Introduction"
        },
        {
            "location": "/mp/guides/security-oidc",
            "text": " To install Keycloak with Docker, open a terminal and make sure the port 8080 is free. <markup lang=\"bash\" title=\"Enter the following command\" >docker run -p 8080:8080 -e KEYCLOAK_USER=admin -e KEYCLOAK_PASSWORD=admin quay.io/keycloak/keycloak:11.0.2 This will start Keycloak on local port 8080. It will create the admin user with username admin and password admin Feel free to modify 11.0.2 by any keycloak version of your wish. If you are running docker behind a proxy server, make sure it is either configured into docker or disabled. Otherwise, you might face a connection timeout because docker cannot download the required data. To verify that Keycloak is running correctly, go to the admin console : http://localhost:8080/auth/admin Log in using the username and password mentioned above: admin . You should be logged in successfully, and it prompts the admin console. ",
            "title": "On Docker"
        },
        {
            "location": "/mp/guides/security-oidc",
            "text": " Download the last version of Keycloak from Keycloak website : https://www.keycloak.org/downloads In the table Server choose Standalone server distribution. ZIP or Tar format are available, click on either to download Keycloak. After extracting the archive file, you should have a directory named keycloak followed by the version. For example, if you chose version 11.0.2, the folder must be named keycloak-11.0.2. Open keycloak folder to make it your current directory. <markup lang=\"bash\" title=\"Run this command from command prompt to open the directory:\" >cd keycloak-11.0.2 ",
            "title": "On JDK"
        },
        {
            "location": "/mp/guides/security-oidc",
            "text": " On Docker To install Keycloak with Docker, open a terminal and make sure the port 8080 is free. <markup lang=\"bash\" title=\"Enter the following command\" >docker run -p 8080:8080 -e KEYCLOAK_USER=admin -e KEYCLOAK_PASSWORD=admin quay.io/keycloak/keycloak:11.0.2 This will start Keycloak on local port 8080. It will create the admin user with username admin and password admin Feel free to modify 11.0.2 by any keycloak version of your wish. If you are running docker behind a proxy server, make sure it is either configured into docker or disabled. Otherwise, you might face a connection timeout because docker cannot download the required data. To verify that Keycloak is running correctly, go to the admin console : http://localhost:8080/auth/admin Log in using the username and password mentioned above: admin . You should be logged in successfully, and it prompts the admin console. On JDK Download the last version of Keycloak from Keycloak website : https://www.keycloak.org/downloads In the table Server choose Standalone server distribution. ZIP or Tar format are available, click on either to download Keycloak. After extracting the archive file, you should have a directory named keycloak followed by the version. For example, if you chose version 11.0.2, the folder must be named keycloak-11.0.2. Open keycloak folder to make it your current directory. <markup lang=\"bash\" title=\"Run this command from command prompt to open the directory:\" >cd keycloak-11.0.2 ",
            "title": "Install Keycloak"
        },
        {
            "location": "/mp/guides/security-oidc",
            "text": " You need to create an admin user because it does not come by default when installing Keycloak. To do this, open http://localhost:8080/auth in your favorite browser. A window Welcome to Keycloak should be prompted. If not, check if any error appear in the terminal. Fill the form by adding Username and Password. Click on Create to create the admin user. Above Administration Console should be printed \"User created\" in a green rectangle. To check that the admin user was created correctly, click on Administration user which should redirect you to a Login form. Enter the Username and Password created earlier to log in. After successfully logged in, the admin console is prompted. ",
            "title": "Create an Admin User"
        },
        {
            "location": "/mp/guides/security-oidc",
            "text": " To start keycloak and have it ready for further steps, run the following command. <markup lang=\"bash\" title=\"On Linux run:\" >bin/standalone.sh <markup lang=\"bash\" title=\"On Windows run:\" >bin/standalone.bat Keycloak runs on localhost:8080 by default. Create an Admin User You need to create an admin user because it does not come by default when installing Keycloak. To do this, open http://localhost:8080/auth in your favorite browser. A window Welcome to Keycloak should be prompted. If not, check if any error appear in the terminal. Fill the form by adding Username and Password. Click on Create to create the admin user. Above Administration Console should be printed \"User created\" in a green rectangle. To check that the admin user was created correctly, click on Administration user which should redirect you to a Login form. Enter the Username and Password created earlier to log in. After successfully logged in, the admin console is prompted. ",
            "title": "Start Keycloak"
        },
        {
            "location": "/mp/guides/security-oidc",
            "text": " A realm is the place where groups of applications, and their environment, can be created. It gathers : One or several applications One or several users Sessions Events Clients and their scopes By default, there is a realm called Master . It is used to manage Keycloak. It is not recommended to associate your application with this realm as it could disturb Keycloak functioning. To create a new realm to manage your application: Open Keycloak admin console http://localhost:8080/auth/admin . Hover the mouse over the dropdown in the top-left corner where it says Master , and press Add realm . Fill the form by adding the realm name, myRealm for example. Click on Create to create the new realm. To verify that your realm is created, on the top-left corner where it said Master previously should be now your realm name or myRealm is you followed the example. To switch from a realm to another, hover the realm name, and the other realm created appear in the dropdown. Click on any realm name to change the current realm. Make sure all configuration or modification are saved before changing the current realm or be subject to lose your configuration. ",
            "title": "Create a Realm"
        },
        {
            "location": "/mp/guides/security-oidc",
            "text": " Initially there are no users in a new realm. An unlimited number of user can be created per realm. A realm contains resources such as client which can be accessed by users. To create a new user: Open the Keycloak admin console: http://localhost:8080/auth/admin Click on Users in the left menu Press Add user Fill the form (Username is the only mandatory field) with this value Username: myUser Click Save A new user is just created but it needs a password to be able to login. To initialize it, do this: Click on Credentials at the top of the page, under Myuser . Fill Password and Password confirmation with the user password of your choice. If the Temporary field is set to ON , the user has to update password on next login. Click ON to make it OFF and prevent it. Press Set Password . A pop-up window is popping off. Click on Set Password to confirm the new password. To verify that the new user is created correctly: Open the Keycloak account console: http://localhost:8080/auth/realms/myRealm/account . Login with myUser and password chosen earlier. You should now be logged-in to the account console where users can manage their accounts. ",
            "title": "Create a User"
        },
        {
            "location": "/mp/guides/security-oidc",
            "text": " To create your first client: Open the Keycloak admin console: http://localhost:8080/auth/admin . Make sure the current realm is myRealm and not Master . Navigate to the left menu, into configure section, click on Clients . This window displays a table with every client from the realm. Click on Create . Fill the following: Client ID : myClientID Client Protocol : openid-connect Press Save Modify Access type : confidential Update Valid Redirect URIs : http://localhost:7987/* Click on + to add the new URI. Click on Save . A new tab named Credentials is created. Click on it to access this new tab. Select Client Authenticator : Client ID and Secret Click on generate secret to generate client secret. Keycloak is now configured and ready. Keep keycloak running on your terminal and open a new tab to set up Helidon. ",
            "title": "Create a Client"
        },
        {
            "location": "/mp/guides/security-oidc",
            "text": " To set up Keycloak properly, go to the admin console: http://localhost:8080/auth/admin If you are using Docker, use Username admin and password admin as it is the default admin user. Otherwise, use the username and password you used to create the admin user. Create a Realm A realm is the place where groups of applications, and their environment, can be created. It gathers : One or several applications One or several users Sessions Events Clients and their scopes By default, there is a realm called Master . It is used to manage Keycloak. It is not recommended to associate your application with this realm as it could disturb Keycloak functioning. To create a new realm to manage your application: Open Keycloak admin console http://localhost:8080/auth/admin . Hover the mouse over the dropdown in the top-left corner where it says Master , and press Add realm . Fill the form by adding the realm name, myRealm for example. Click on Create to create the new realm. To verify that your realm is created, on the top-left corner where it said Master previously should be now your realm name or myRealm is you followed the example. To switch from a realm to another, hover the realm name, and the other realm created appear in the dropdown. Click on any realm name to change the current realm. Make sure all configuration or modification are saved before changing the current realm or be subject to lose your configuration. Create a User Initially there are no users in a new realm. An unlimited number of user can be created per realm. A realm contains resources such as client which can be accessed by users. To create a new user: Open the Keycloak admin console: http://localhost:8080/auth/admin Click on Users in the left menu Press Add user Fill the form (Username is the only mandatory field) with this value Username: myUser Click Save A new user is just created but it needs a password to be able to login. To initialize it, do this: Click on Credentials at the top of the page, under Myuser . Fill Password and Password confirmation with the user password of your choice. If the Temporary field is set to ON , the user has to update password on next login. Click ON to make it OFF and prevent it. Press Set Password . A pop-up window is popping off. Click on Set Password to confirm the new password. To verify that the new user is created correctly: Open the Keycloak account console: http://localhost:8080/auth/realms/myRealm/account . Login with myUser and password chosen earlier. You should now be logged-in to the account console where users can manage their accounts. Create a Client To create your first client: Open the Keycloak admin console: http://localhost:8080/auth/admin . Make sure the current realm is myRealm and not Master . Navigate to the left menu, into configure section, click on Clients . This window displays a table with every client from the realm. Click on Create . Fill the following: Client ID : myClientID Client Protocol : openid-connect Press Save Modify Access type : confidential Update Valid Redirect URIs : http://localhost:7987/* Click on + to add the new URI. Click on Save . A new tab named Credentials is created. Click on it to access this new tab. Select Client Authenticator : Client ID and Secret Click on generate secret to generate client secret. Keycloak is now configured and ready. Keep keycloak running on your terminal and open a new tab to set up Helidon. ",
            "title": "Set up Keycloak"
        },
        {
            "location": "/mp/guides/security-oidc",
            "text": " Update the pom.xml file and add the following Helidon dependency to the &lt;dependencies&gt; section. <markup lang=\"xml\" title=\"Add the following dependency to pom.xml :\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-oidc&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Update Project Dependencies"
        },
        {
            "location": "/mp/guides/security-oidc",
            "text": " The OIDC security provider configuration can be joined to helidon configuration file. This file is located here: src/main/resources/application.yaml . It can be easily used to configure the web server without modifying application code. <markup lang=\"yaml\" title=\"Create application.yaml file and add the following line\" >security: providers: - abac: # Adds ABAC Provider - it does not require any configuration - oidc: redirect-uri: \"/oidc/redirect\" audience: \"account\" client-id: \"myClientID\" header-use: true client-secret: \"Client secret generated into Keycloak client credential\" identity-uri: \"http://localhost:8080/auth/realms/myRealm\" frontend-uri: \"http://localhost:7987\" client-id must be the same as the one configure in keycloak. The client secret generate by Keycloak during Create a client section. identity-uri is used to redirect the user to keycloak. frontend-uri will direct you back to the application. The client secret is the one generate into Keycloak Client Credentials. It must be copy past into client-id variable from application.yaml. Make sure keycloak and the application are not running on the same port. The application port value can be changed into microprofile-config.properties. <markup lang=\"properties\" title=\"Change these properties to configure the server host and port\" >server.port=7987 server.host=localhost If the port 7987 is already used, check what port is free on your machine. <markup lang=\"properties\" title=\"Replace the old port into microprofile-config.properties\" >server.port=\"{Your-new-port}\" <markup lang=\"yaml\" title=\"Replace the old port into application.yaml\" >frontend-uri: \"http://localhost:{Your-new-port}\" ",
            "title": "Add OIDC Security Properties"
        },
        {
            "location": "/mp/guides/security-oidc",
            "text": " The GreetResource class is a JAX-RS resource available at the endpoint /greet . Use @Authenticated annotation to protect any method or endpoint. Modify the getDefaultMessage method with the @Authenticated to limit its access. <markup lang=\"java\" title=\"Import Authenticated annotation:\" >import io.helidon.security.annotations.Authenticated; <markup lang=\"java\" title=\"Add @Authenticated to secure getDefaultMessage \" >@Authenticated @GET @Produces(MediaType.APPLICATION_JSON) public JsonObject getDefaultMessage() { return createResponse(\"World\"); } It is also needed to add the following line to the module-info.java file: <markup lang=\"java\" title=\"Add security annotations module requirement\" >requires io.helidon.security.annotations; When a client will send an HTTP GET request at the endpoint http://localhost:7987/greet , he will be redirected to keycloak. Keycloak will check if the client has the required authorisation to access this endpoint. If the client can log in successfully, keycloak redirect it to the wished endpoint. If the client cannot log in, or the required access data are incomplete, Keycloak refuses the access. ",
            "title": "Secure Your Application"
        },
        {
            "location": "/mp/guides/security-oidc",
            "text": " Use the Helidon MP Maven archetype to create a simple project. It will be used as an example to show how to set up Helidon. Replace 4.0.2 by the latest helidon version. It will download the quickstart project into the current directory. <markup lang=\"bash\" title=\"Run the Maven archetype\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-mp \\ -DarchetypeVersion=4.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-mp \\ -Dpackage=io.helidon.examples.quickstart.mp <markup lang=\"bash\" title=\"The project will be built and run from the helidon-quickstart-mp directory:\" >cd helidon-quickstart-mp Update Project Dependencies Update the pom.xml file and add the following Helidon dependency to the &lt;dependencies&gt; section. <markup lang=\"xml\" title=\"Add the following dependency to pom.xml :\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-oidc&lt;/artifactId&gt; &lt;/dependency&gt; Add OIDC Security Properties The OIDC security provider configuration can be joined to helidon configuration file. This file is located here: src/main/resources/application.yaml . It can be easily used to configure the web server without modifying application code. <markup lang=\"yaml\" title=\"Create application.yaml file and add the following line\" >security: providers: - abac: # Adds ABAC Provider - it does not require any configuration - oidc: redirect-uri: \"/oidc/redirect\" audience: \"account\" client-id: \"myClientID\" header-use: true client-secret: \"Client secret generated into Keycloak client credential\" identity-uri: \"http://localhost:8080/auth/realms/myRealm\" frontend-uri: \"http://localhost:7987\" client-id must be the same as the one configure in keycloak. The client secret generate by Keycloak during Create a client section. identity-uri is used to redirect the user to keycloak. frontend-uri will direct you back to the application. The client secret is the one generate into Keycloak Client Credentials. It must be copy past into client-id variable from application.yaml. Make sure keycloak and the application are not running on the same port. The application port value can be changed into microprofile-config.properties. <markup lang=\"properties\" title=\"Change these properties to configure the server host and port\" >server.port=7987 server.host=localhost If the port 7987 is already used, check what port is free on your machine. <markup lang=\"properties\" title=\"Replace the old port into microprofile-config.properties\" >server.port=\"{Your-new-port}\" <markup lang=\"yaml\" title=\"Replace the old port into application.yaml\" >frontend-uri: \"http://localhost:{Your-new-port}\" Secure Your Application The GreetResource class is a JAX-RS resource available at the endpoint /greet . Use @Authenticated annotation to protect any method or endpoint. Modify the getDefaultMessage method with the @Authenticated to limit its access. <markup lang=\"java\" title=\"Import Authenticated annotation:\" >import io.helidon.security.annotations.Authenticated; <markup lang=\"java\" title=\"Add @Authenticated to secure getDefaultMessage \" >@Authenticated @GET @Produces(MediaType.APPLICATION_JSON) public JsonObject getDefaultMessage() { return createResponse(\"World\"); } It is also needed to add the following line to the module-info.java file: <markup lang=\"java\" title=\"Add security annotations module requirement\" >requires io.helidon.security.annotations; When a client will send an HTTP GET request at the endpoint http://localhost:7987/greet , he will be redirected to keycloak. Keycloak will check if the client has the required authorisation to access this endpoint. If the client can log in successfully, keycloak redirect it to the wished endpoint. If the client cannot log in, or the required access data are incomplete, Keycloak refuses the access. ",
            "title": "Set up Helidon"
        },
        {
            "location": "/mp/guides/security-oidc",
            "text": " At this stage of the application, tests cannot pass because of OIDC security. The only way to authenticate a user is through the front end of that server which can be accessed with the browser for example. In order to keep security and test the application locally, a new security provider must be provided. By adding specific configuration to the test, it is possible to override the application configuration. The following explains how to set a basic authentication instead of oidc security provider only for the tests. Which means, at the end of this guide, the application will be secured by oidc and the tests will use basic authentication. In the test folder helidon-quickstart-mp/src/test : <markup lang=\"bash\" title=\"Create a new directory and another one inside\" >mkdir resources cd resources touch application.yaml Open the application.yaml file you just created. <markup lang=\"yaml\" title=\"Copy these properties into the new application.yaml\" >app: greeting: \"Hello\" server: port: 7987 host: localhost security: providers: - abac: - http-basic-auth: users: - login: \"jack\" password: \"jackIsGreat\" By adding this new application.yaml, it will append the properties to the application.yaml located into java/resources . The oidc properties are not overridden, and the server cannot decide which security provider to choose. Excluding oidc dependency during the test leaves only basic authentication security available for the tests. <markup lang=\"xml\" title=\"Add this plugin to the build\" >&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;classpathDependencyExcludes&gt; &lt;classpathDependencyExclude&gt;io.helidon.microprofile:helidon-microprofile-oidc&lt;/classpathDependencyExclude&gt; &lt;/classpathDependencyExcludes&gt; &lt;/configuration&gt; &lt;/plugin&gt; In the MainTest.java file, tests need to be modified to pass the application security when accessing /greet path with a GET method. The server has now one security provider, basic authentication configured. Next step is to create the test to check that the application is correctly protected. Firstly, create new test method testHelloWorld <markup lang=\"java\" title=\"Add this method to the test class\" >@Test void testHellowWorld() { } Now we can add the first test: <markup lang=\"java\" title=\"Add this code into testHelloWorld method:\" >try (Response r = target .path(\"greet\") .request() .get()) { assertThat(r.getStatus(), is(401)); } This piece of code uses the JAX-RS client to access the application on /greet path with a GET method. The http basic authentication security provider protects this path, so the client should receive an HTTP 401 code for unauthorized. Only jack user has access to this part of the application. <markup lang=\"java\" title=\"Change the testHelloWorld method:\" >String encoding = Base64.getEncoder().encodeToString(\"jack:jackIsGreat\".getBytes()); Message jsonMessage = target .path(\"greet\") .request() .header(HttpHeaders.AUTHORIZATION, \"Basic \" + encoding) .get(Message.class); assertThat(jsonMessage.getMessage(), is(\"Hello World!\")); The username and password are encoded and placed inside the header in order to authenticate as jack to access the application. If the authentication is successful, the application send the Hello World back as a JsonObject . Now, the project can be build without skiping test. <markup lang=\"bash\" title=\"Build the project\" >mvn clean install ",
            "title": "Update Tests to the Secure Environment"
        },
        {
            "location": "/mp/guides/security-oidc",
            "text": " The Authorization Code flow is suitable for browser-based applications. It is composed of three main steps: The browser visits the application. The user is not logged in, so it redirects the browser to Keycloak which requires username and password for authentication. Keycloak authenticates the user and returns a temporary authorization code as a query parameter in the URL. The authorization code is used to get access and refresh token from Keycloak token endpoint. For the first step, paste the following URL into your browser: http://localhost:8080/auth/realms/myRealm/protocol/openid-connect/auth?client_id=myClientID&amp;response_type=code . The first part of the url http:/../auth is the Keycloak endpoint to request an authorization code. Two query parameters are provided, the client id and the response type. Press enter and Keycloak responds with different URL containing a query parameter code . You successfully received the authorization code. In order to achieve the third step, we can use Postman to exchange the authorization code for tokens. In Postman, select the Http POST method. Keycloak endpoint to get token is the following: http://localhost:8080/auth/realms/myRealm/protocol/openid-connect/token . In the body of the request, select x-www-form-urlencoded type. Add the following data: <markup lang=\"json\" title=\"Enter the key:value\" >[{\"key\":\"grant_type\",\"value\":\"authorization_code\"}, {\"key\":\"client_id\",\"value\":\"myClientID\"}, {\"key\":\"client_secret\",\"value\":\"client secret\"}, {\"key\":\"code\",\"value\":\"authorization code\"}] Do not forget to replace the client secret by its value (generated during Create a Client), and authorization code by the code value in the query parameter. Send the request by pressing Send . Keycloak returns an access token and a refresh token. ",
            "title": "Authorization Code Flow"
        },
        {
            "location": "/mp/guides/security-oidc",
            "text": " The Direct Access Grants flow is used by REST clients that want to request tokens on behalf of a user. To use Postman to make this request on behalf of myuser , select the GET method and enter this URL: http://localhost:7987/greet/ . Under Authorization tab, select authorization type`OAuth 2.0`. Under it, complete the sentence Add authorization data to with Request Headers , and complete the required fields. <markup lang=\"json\" title=\"Enter the following information:\" >[{\"key\":\"Header Prefix\",\"value\":\"bearer\"}, {\"key\":\"Grant type\",\"value\":\"Password Credentials\"}, {\"key\":\"Access Token URL\",\"value\":\"http://localhost:8080/auth/realms/myRealm/protocol/openid-connect/token\"}, {\"key\":\"Client ID\",\"value\":\"myClientID\"}, {\"key\":\"Client Secret\",\"value\":\"client secret\"}, {\"key\":\"Username\",\"value\":\"myuser\"}, {\"key\":\"Password\",\"value\":\"password\"}, {\"key\":\"Scope\",\"value\":\"openid\"}, {\"key\":\"Client Authentication\",\"value\":\"Send as Basic Auth Header\"}] Again, make sure to replace client secret by the actual client secret. Click on Get New Access Token . A popup window appears with Authentication complete, click on proceed to display access, refresh and identity token. Copy and paste the access token to Access Token field and press Send . Helidon greeting application sends back Hello World ! . ",
            "title": "Resource Owner Password Credentials Grant (Direct Access Grants)"
        },
        {
            "location": "/mp/guides/security-oidc",
            "text": " Keycloak supports many authentication and authorization flows, but only two of them will be shown. This section describes another way you can get an access token or refresh a token or identity token. The identity token contains information about the user. The access token contains access information that the application can use to determine what resources the user is allowed to access. Once expired, the refresh token allows the application to obtain a new access token. As these tokens contain sensitive information, they are valid for a very short period. It is possible to make them last longer in order to let you manipulate them with Postman. To do so: Open the Keycloak Console. Click on the Realm Setting in the left menu. Navigate to the Tokens tab. You can increase the access token lifespan. Authorization Code Flow The Authorization Code flow is suitable for browser-based applications. It is composed of three main steps: The browser visits the application. The user is not logged in, so it redirects the browser to Keycloak which requires username and password for authentication. Keycloak authenticates the user and returns a temporary authorization code as a query parameter in the URL. The authorization code is used to get access and refresh token from Keycloak token endpoint. For the first step, paste the following URL into your browser: http://localhost:8080/auth/realms/myRealm/protocol/openid-connect/auth?client_id=myClientID&amp;response_type=code . The first part of the url http:/../auth is the Keycloak endpoint to request an authorization code. Two query parameters are provided, the client id and the response type. Press enter and Keycloak responds with different URL containing a query parameter code . You successfully received the authorization code. In order to achieve the third step, we can use Postman to exchange the authorization code for tokens. In Postman, select the Http POST method. Keycloak endpoint to get token is the following: http://localhost:8080/auth/realms/myRealm/protocol/openid-connect/token . In the body of the request, select x-www-form-urlencoded type. Add the following data: <markup lang=\"json\" title=\"Enter the key:value\" >[{\"key\":\"grant_type\",\"value\":\"authorization_code\"}, {\"key\":\"client_id\",\"value\":\"myClientID\"}, {\"key\":\"client_secret\",\"value\":\"client secret\"}, {\"key\":\"code\",\"value\":\"authorization code\"}] Do not forget to replace the client secret by its value (generated during Create a Client), and authorization code by the code value in the query parameter. Send the request by pressing Send . Keycloak returns an access token and a refresh token. Resource Owner Password Credentials Grant (Direct Access Grants) The Direct Access Grants flow is used by REST clients that want to request tokens on behalf of a user. To use Postman to make this request on behalf of myuser , select the GET method and enter this URL: http://localhost:7987/greet/ . Under Authorization tab, select authorization type`OAuth 2.0`. Under it, complete the sentence Add authorization data to with Request Headers , and complete the required fields. <markup lang=\"json\" title=\"Enter the following information:\" >[{\"key\":\"Header Prefix\",\"value\":\"bearer\"}, {\"key\":\"Grant type\",\"value\":\"Password Credentials\"}, {\"key\":\"Access Token URL\",\"value\":\"http://localhost:8080/auth/realms/myRealm/protocol/openid-connect/token\"}, {\"key\":\"Client ID\",\"value\":\"myClientID\"}, {\"key\":\"Client Secret\",\"value\":\"client secret\"}, {\"key\":\"Username\",\"value\":\"myuser\"}, {\"key\":\"Password\",\"value\":\"password\"}, {\"key\":\"Scope\",\"value\":\"openid\"}, {\"key\":\"Client Authentication\",\"value\":\"Send as Basic Auth Header\"}] Again, make sure to replace client secret by the actual client secret. Click on Get New Access Token . A popup window appears with Authentication complete, click on proceed to display access, refresh and identity token. Copy and paste the access token to Access Token field and press Send . Helidon greeting application sends back Hello World ! . ",
            "title": "Test Keycloak process with Postman"
        },
        {
            "location": "/mp/guides/security-oidc",
            "text": " To give less access to a specific endpoint, it is possible to configure user role. So the application will grant access only the user with the required role. Navigate to the GreetResource and find the getDefaultMessage with @Authenticate annotation. <markup lang=\"java\" title=\"Import the RolesAllowed annotation\" >import jakarta.annotation.security.RolesAllowed; <markup lang=\"java\" title=\"Add the @RolesAllowed annotation under the @Authenticate annotation:\" >@RolesAllowed(\"admin\") The annotation parameter is the role with access to the method. In this case, only user with admin role can have access. Then, add a user and roles to the helidon-quickstart-mp/src/test/resources/application.yaml file. <markup lang=\"yaml\" title=\"Add jack roles and create a new user named john:\" >- http-basic-auth: users: - login: \"jack\" password: \"jackIsGreat\" roles: [ \"admin\", \"user\" ] - login: \"john\" password: \"johnPassword\" roles: [ \"user\" ] Now, only Jack has access to secure endpoint as he has an admin role. John, as a simple user, can not access it. Once it is done, go to the tests to check the application behavior. The test from previous section is still passing because jack has access. The user john has only the user role so when accessing protected endpoint, a 403 (Forbidden) http code is returned. <markup lang=\"java\" title=\"Check that john does not have access\" >encoding = Base64.getEncoder().encodeToString(\"john:johnPassword\".getBytes()); try (Response r = target .path(\"greet\") .request() .header(HttpHeaders.AUTHORIZATION, \"Basic \" + encoding) .get()) { assertThat(r.getStatus(), is(403)); } <markup lang=\"bash\" title=\"Build the project\" >mvn clean install The tests pass, and your application is secured with specific roles in addition to user IDs. ",
            "title": "Restrict Access to a Specific Role"
        },
        {
            "location": "/mp/guides/security-oidc",
            "text": " Helidon and Keycloak are now correctly configured and your application is safe. <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-mp.jar The tests must be skipped, otherwise it produces test failure. As the /greet endpoint for GET request is now protected, its access is limited, and the tests are not built to take oidc security in account. Open your favourite browser and try to access http://localhost:7987/greet/Michael . You should not be redirected and receive greeting from the application. Enter the following into URL : http://localhost:7987/greet . Keycloak redirect you to its login page. Enter the username and associated password: Username : myUser Password : password After successful log in, keycloak redirect you to the http://localhost:7987/greet endpoint and print Hello word. Press Ctrl+C to stop the application. From the actual settings, the user needs to log in only once, then Keycloak saves all the connection data. Update Tests to the Secure Environment At this stage of the application, tests cannot pass because of OIDC security. The only way to authenticate a user is through the front end of that server which can be accessed with the browser for example. In order to keep security and test the application locally, a new security provider must be provided. By adding specific configuration to the test, it is possible to override the application configuration. The following explains how to set a basic authentication instead of oidc security provider only for the tests. Which means, at the end of this guide, the application will be secured by oidc and the tests will use basic authentication. In the test folder helidon-quickstart-mp/src/test : <markup lang=\"bash\" title=\"Create a new directory and another one inside\" >mkdir resources cd resources touch application.yaml Open the application.yaml file you just created. <markup lang=\"yaml\" title=\"Copy these properties into the new application.yaml\" >app: greeting: \"Hello\" server: port: 7987 host: localhost security: providers: - abac: - http-basic-auth: users: - login: \"jack\" password: \"jackIsGreat\" By adding this new application.yaml, it will append the properties to the application.yaml located into java/resources . The oidc properties are not overridden, and the server cannot decide which security provider to choose. Excluding oidc dependency during the test leaves only basic authentication security available for the tests. <markup lang=\"xml\" title=\"Add this plugin to the build\" >&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;classpathDependencyExcludes&gt; &lt;classpathDependencyExclude&gt;io.helidon.microprofile:helidon-microprofile-oidc&lt;/classpathDependencyExclude&gt; &lt;/classpathDependencyExcludes&gt; &lt;/configuration&gt; &lt;/plugin&gt; In the MainTest.java file, tests need to be modified to pass the application security when accessing /greet path with a GET method. The server has now one security provider, basic authentication configured. Next step is to create the test to check that the application is correctly protected. Firstly, create new test method testHelloWorld <markup lang=\"java\" title=\"Add this method to the test class\" >@Test void testHellowWorld() { } Now we can add the first test: <markup lang=\"java\" title=\"Add this code into testHelloWorld method:\" >try (Response r = target .path(\"greet\") .request() .get()) { assertThat(r.getStatus(), is(401)); } This piece of code uses the JAX-RS client to access the application on /greet path with a GET method. The http basic authentication security provider protects this path, so the client should receive an HTTP 401 code for unauthorized. Only jack user has access to this part of the application. <markup lang=\"java\" title=\"Change the testHelloWorld method:\" >String encoding = Base64.getEncoder().encodeToString(\"jack:jackIsGreat\".getBytes()); Message jsonMessage = target .path(\"greet\") .request() .header(HttpHeaders.AUTHORIZATION, \"Basic \" + encoding) .get(Message.class); assertThat(jsonMessage.getMessage(), is(\"Hello World!\")); The username and password are encoded and placed inside the header in order to authenticate as jack to access the application. If the authentication is successful, the application send the Hello World back as a JsonObject . Now, the project can be build without skiping test. <markup lang=\"bash\" title=\"Build the project\" >mvn clean install Test Keycloak process with Postman Keycloak supports many authentication and authorization flows, but only two of them will be shown. This section describes another way you can get an access token or refresh a token or identity token. The identity token contains information about the user. The access token contains access information that the application can use to determine what resources the user is allowed to access. Once expired, the refresh token allows the application to obtain a new access token. As these tokens contain sensitive information, they are valid for a very short period. It is possible to make them last longer in order to let you manipulate them with Postman. To do so: Open the Keycloak Console. Click on the Realm Setting in the left menu. Navigate to the Tokens tab. You can increase the access token lifespan. Authorization Code Flow The Authorization Code flow is suitable for browser-based applications. It is composed of three main steps: The browser visits the application. The user is not logged in, so it redirects the browser to Keycloak which requires username and password for authentication. Keycloak authenticates the user and returns a temporary authorization code as a query parameter in the URL. The authorization code is used to get access and refresh token from Keycloak token endpoint. For the first step, paste the following URL into your browser: http://localhost:8080/auth/realms/myRealm/protocol/openid-connect/auth?client_id=myClientID&amp;response_type=code . The first part of the url http:/../auth is the Keycloak endpoint to request an authorization code. Two query parameters are provided, the client id and the response type. Press enter and Keycloak responds with different URL containing a query parameter code . You successfully received the authorization code. In order to achieve the third step, we can use Postman to exchange the authorization code for tokens. In Postman, select the Http POST method. Keycloak endpoint to get token is the following: http://localhost:8080/auth/realms/myRealm/protocol/openid-connect/token . In the body of the request, select x-www-form-urlencoded type. Add the following data: <markup lang=\"json\" title=\"Enter the key:value\" >[{\"key\":\"grant_type\",\"value\":\"authorization_code\"}, {\"key\":\"client_id\",\"value\":\"myClientID\"}, {\"key\":\"client_secret\",\"value\":\"client secret\"}, {\"key\":\"code\",\"value\":\"authorization code\"}] Do not forget to replace the client secret by its value (generated during Create a Client), and authorization code by the code value in the query parameter. Send the request by pressing Send . Keycloak returns an access token and a refresh token. Resource Owner Password Credentials Grant (Direct Access Grants) The Direct Access Grants flow is used by REST clients that want to request tokens on behalf of a user. To use Postman to make this request on behalf of myuser , select the GET method and enter this URL: http://localhost:7987/greet/ . Under Authorization tab, select authorization type`OAuth 2.0`. Under it, complete the sentence Add authorization data to with Request Headers , and complete the required fields. <markup lang=\"json\" title=\"Enter the following information:\" >[{\"key\":\"Header Prefix\",\"value\":\"bearer\"}, {\"key\":\"Grant type\",\"value\":\"Password Credentials\"}, {\"key\":\"Access Token URL\",\"value\":\"http://localhost:8080/auth/realms/myRealm/protocol/openid-connect/token\"}, {\"key\":\"Client ID\",\"value\":\"myClientID\"}, {\"key\":\"Client Secret\",\"value\":\"client secret\"}, {\"key\":\"Username\",\"value\":\"myuser\"}, {\"key\":\"Password\",\"value\":\"password\"}, {\"key\":\"Scope\",\"value\":\"openid\"}, {\"key\":\"Client Authentication\",\"value\":\"Send as Basic Auth Header\"}] Again, make sure to replace client secret by the actual client secret. Click on Get New Access Token . A popup window appears with Authentication complete, click on proceed to display access, refresh and identity token. Copy and paste the access token to Access Token field and press Send . Helidon greeting application sends back Hello World ! . Restrict Access to a Specific Role To give less access to a specific endpoint, it is possible to configure user role. So the application will grant access only the user with the required role. Navigate to the GreetResource and find the getDefaultMessage with @Authenticate annotation. <markup lang=\"java\" title=\"Import the RolesAllowed annotation\" >import jakarta.annotation.security.RolesAllowed; <markup lang=\"java\" title=\"Add the @RolesAllowed annotation under the @Authenticate annotation:\" >@RolesAllowed(\"admin\") The annotation parameter is the role with access to the method. In this case, only user with admin role can have access. Then, add a user and roles to the helidon-quickstart-mp/src/test/resources/application.yaml file. <markup lang=\"yaml\" title=\"Add jack roles and create a new user named john:\" >- http-basic-auth: users: - login: \"jack\" password: \"jackIsGreat\" roles: [ \"admin\", \"user\" ] - login: \"john\" password: \"johnPassword\" roles: [ \"user\" ] Now, only Jack has access to secure endpoint as he has an admin role. John, as a simple user, can not access it. Once it is done, go to the tests to check the application behavior. The test from previous section is still passing because jack has access. The user john has only the user role so when accessing protected endpoint, a 403 (Forbidden) http code is returned. <markup lang=\"java\" title=\"Check that john does not have access\" >encoding = Base64.getEncoder().encodeToString(\"john:johnPassword\".getBytes()); try (Response r = target .path(\"greet\") .request() .header(HttpHeaders.AUTHORIZATION, \"Basic \" + encoding) .get()) { assertThat(r.getStatus(), is(403)); } <markup lang=\"bash\" title=\"Build the project\" >mvn clean install The tests pass, and your application is secured with specific roles in addition to user IDs. ",
            "title": "Try it!"
        },
        {
            "location": "/mp/guides/testing-junit5",
            "text": " This guide describes how to write and execute tests for your MicroProfile applications in a JUnit 5 environment using optimized customizations. ",
            "title": "preambule"
        },
        {
            "location": "/mp/guides/testing-junit5",
            "text": " For this 20 minute tutorial, you will need the following: <div class=\"table__overflow elevation-1 flex sm7 \"> A Helidon MP Application You can use your own application or use the Helidon MP Quickstart to create a sample application. Java&#160;SE&#160;21 ( Open&#160;JDK&#160;21 ) Helidon requires Java 21+. Maven 3.8+ Helidon requires Maven 3.8+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop . <markup lang=\"bash\" title=\"Verify Prerequisites\" >java -version mvn --version docker --version kubectl version --short <markup lang=\"bash\" title=\"Setting JAVA_HOME\" ># On Mac export JAVA_HOME=`/usr/libexec/java_home -v 21` # On Linux # Use the appropriate path to your JDK export JAVA_HOME=/usr/lib/jvm/jdk-21 ",
            "title": "What You Need"
        },
        {
            "location": "/mp/guides/testing-junit5",
            "text": " To start using this feature, add the following dependencies to the testing module: <markup lang=\"xml\" title=\"Maven dependencies\" >&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.testing&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-testing-junit5&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.junit.jupiter&lt;/groupId&gt; &lt;artifactId&gt;junit-jupiter-engine&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; ",
            "title": "Dependencies"
        },
        {
            "location": "/mp/guides/testing-junit5",
            "text": " First you&#8217;ll need to create a test class with an empty test method, and annotate it with @HelidonTest : <markup lang=\"java\" title=\"Test Class\" >import io.helidon.microprofile.testing.junit5.HelidonTest; import org.junit.jupiter.api.Test; @HelidonTest class GreetTest { @Test void testDefaultGreeting() { } } The @HelidonTest annotation will cause the test extension to start a Helidon MicroProfile server so that you do not need to manage the server lifecycle in your test. The container is initialized once before the test class is instantiated, and shut down after the last test runs. You can see this in the test output: <markup lang=\"listing\" >`INFO io.helidon.microprofile.server.ServerCdiExtension: Server started on http://localhost:56293 (and all other host addresses) in 1893 milliseconds (since JVM startup)`. [source,java] The @HelidonTest annotation uses a random port regardless of the port configured in the application.yaml. ",
            "title": "Create a Test Class"
        },
        {
            "location": "/mp/guides/testing-junit5",
            "text": " The test is only useful if it invokes the server and verifies the result. To support testing, you can inject a WebTarget that is configured for the currently running server (it can also be a parameter to a test method). We can use the target to invoke our endpoint and validate the result. <markup lang=\"java\" title=\"Updated Class with webTarget\" >import static org.junit.jupiter.api.Assertions.assertEquals; @HelidonTest class GreetTest { @Inject WebTarget webTarget; @Test void testDefaultGreeting() { JsonObject jsonObject = webTarget.path(\"/greet\") .request() .get(JsonObject.class); String expected = \"Hello World!\"; String actual = jsonObject.getString(\"message\"); assertEquals(expected, actual, \"Message in JSON\"); } } The test is now complete and verifies the message. ",
            "title": "Inject a WebTarget"
        },
        {
            "location": "/mp/guides/testing-junit5",
            "text": " The testing extension supports a few additional annotations that allow for finer control of the test execution. Optional Extension Annotations Annotation Description @HelidonTest(resetPerTest = true) Resets the container for each method. This is useful when we want to modify configuration or beans between executions. In such a case, injection into fields is not possible, as we would need a different instance for each test. @AddConfig(key = \"app.greeting\", value = \"Unite\") Defines a new configuration (either on class level, or method level) by adding a single configuration key/value. @Configuration(configSources = \"test-config.properties\") Adds a whole config source from classpath. Here&#8217;s an example showing how these approaches are used to execute the same endpoint with different configuration: <markup lang=\"java\" >@HelidonTest(resetPerTest = true) class GreetTest { @Test void testDefaultGreeting(WebTarget webTarget) { validate(webTarget, \"/greet\", \"Hello World!\"); } @Test @AddConfig(key = \"app.greeting\", value = \"Unite\") void testConfiguredGreeting(WebTarget webTarget) { validate(webTarget, \"/greet\", \"Unite World!\"); } private void validate(WebTarget webTarget, String path, String expected) { JsonObject jsonObject = webTarget.path(path) .request() .get(JsonObject.class); String actual = jsonObject.getString(\"message\"); assertEquals(expected, actual, \"Message in JSON\"); } } ",
            "title": "Customize the Testing Extension"
        },
        {
            "location": "/mp/guides/testing-junit5",
            "text": " If you prefer to use only beans for testing, and want to add a different bean for each test, then you must use the @AddBean annotation. This cannot be achieved by CDI discovery because if we place META-INF/beans.xml on the classpath, then all of our beans would be added. <markup lang=\"java\" >@AddBean(TestBean.class) By default the bean is added to the container with scope set to ApplicationScoped . You can customize scope either by annotating the bean class with another scope or through the annotation: <markup lang=\"java\" >@AddBean(value = TestBean.class, scope = Dependent.class) This annotation can also be placed on a method when running in resetPerTest mode. ",
            "title": "Use Beans for Testing"
        },
        {
            "location": "/mp/guides/testing-junit5",
            "text": " When a custom bean is not enough, you may want to extend the CDI with a test-only Extension . Once again, if we use the standard way of doing this, we would need to create a META-INF/services record that would be picked up by every test class. For this purpose, we provide the following annotation which adds the extension to the container and allows you to modify its behavior as a usual CDI Portable Extension: <markup lang=\"java\" >@AddExtension(TestExtension.class) ",
            "title": "Add Test Extension"
        },
        {
            "location": "/mp/guides/testing-junit5",
            "text": " If you want to disable discovery and only add custom extensions and beans, then use the following annotation: <markup lang=\"java\" >@DisableDiscovery This annotation is typically used in conjunction with @AddBeans and/or @AddExtension . As you have seen in standard test output, by default Helidon starts with the dependencies defined in pom.xml. ",
            "title": "Disable Discovery"
        },
        {
            "location": "/mp/guides/testing-junit5",
            "text": " In this guide we will use the Helidon MP Quickstart project in our examples. This application provides an endpoint /greet , and we want to make sure this endpoint is available and returns expected value. Create a Test Class First you&#8217;ll need to create a test class with an empty test method, and annotate it with @HelidonTest : <markup lang=\"java\" title=\"Test Class\" >import io.helidon.microprofile.testing.junit5.HelidonTest; import org.junit.jupiter.api.Test; @HelidonTest class GreetTest { @Test void testDefaultGreeting() { } } The @HelidonTest annotation will cause the test extension to start a Helidon MicroProfile server so that you do not need to manage the server lifecycle in your test. The container is initialized once before the test class is instantiated, and shut down after the last test runs. You can see this in the test output: <markup lang=\"listing\" >`INFO io.helidon.microprofile.server.ServerCdiExtension: Server started on http://localhost:56293 (and all other host addresses) in 1893 milliseconds (since JVM startup)`. [source,java] The @HelidonTest annotation uses a random port regardless of the port configured in the application.yaml. Inject a WebTarget The test is only useful if it invokes the server and verifies the result. To support testing, you can inject a WebTarget that is configured for the currently running server (it can also be a parameter to a test method). We can use the target to invoke our endpoint and validate the result. <markup lang=\"java\" title=\"Updated Class with webTarget\" >import static org.junit.jupiter.api.Assertions.assertEquals; @HelidonTest class GreetTest { @Inject WebTarget webTarget; @Test void testDefaultGreeting() { JsonObject jsonObject = webTarget.path(\"/greet\") .request() .get(JsonObject.class); String expected = \"Hello World!\"; String actual = jsonObject.getString(\"message\"); assertEquals(expected, actual, \"Message in JSON\"); } } The test is now complete and verifies the message. Customize the Testing Extension The testing extension supports a few additional annotations that allow for finer control of the test execution. Optional Extension Annotations Annotation Description @HelidonTest(resetPerTest = true) Resets the container for each method. This is useful when we want to modify configuration or beans between executions. In such a case, injection into fields is not possible, as we would need a different instance for each test. @AddConfig(key = \"app.greeting\", value = \"Unite\") Defines a new configuration (either on class level, or method level) by adding a single configuration key/value. @Configuration(configSources = \"test-config.properties\") Adds a whole config source from classpath. Here&#8217;s an example showing how these approaches are used to execute the same endpoint with different configuration: <markup lang=\"java\" >@HelidonTest(resetPerTest = true) class GreetTest { @Test void testDefaultGreeting(WebTarget webTarget) { validate(webTarget, \"/greet\", \"Hello World!\"); } @Test @AddConfig(key = \"app.greeting\", value = \"Unite\") void testConfiguredGreeting(WebTarget webTarget) { validate(webTarget, \"/greet\", \"Unite World!\"); } private void validate(WebTarget webTarget, String path, String expected) { JsonObject jsonObject = webTarget.path(path) .request() .get(JsonObject.class); String actual = jsonObject.getString(\"message\"); assertEquals(expected, actual, \"Message in JSON\"); } } Use Beans for Testing If you prefer to use only beans for testing, and want to add a different bean for each test, then you must use the @AddBean annotation. This cannot be achieved by CDI discovery because if we place META-INF/beans.xml on the classpath, then all of our beans would be added. <markup lang=\"java\" >@AddBean(TestBean.class) By default the bean is added to the container with scope set to ApplicationScoped . You can customize scope either by annotating the bean class with another scope or through the annotation: <markup lang=\"java\" >@AddBean(value = TestBean.class, scope = Dependent.class) This annotation can also be placed on a method when running in resetPerTest mode. Add Test Extension When a custom bean is not enough, you may want to extend the CDI with a test-only Extension . Once again, if we use the standard way of doing this, we would need to create a META-INF/services record that would be picked up by every test class. For this purpose, we provide the following annotation which adds the extension to the container and allows you to modify its behavior as a usual CDI Portable Extension: <markup lang=\"java\" >@AddExtension(TestExtension.class) Disable Discovery If you want to disable discovery and only add custom extensions and beans, then use the following annotation: <markup lang=\"java\" >@DisableDiscovery This annotation is typically used in conjunction with @AddBeans and/or @AddExtension . As you have seen in standard test output, by default Helidon starts with the dependencies defined in pom.xml. ",
            "title": "Create a Sample Helidon MP Project"
        },
        {
            "location": "/mp/guides/testing-junit5",
            "text": " If you want just the basic test features enabled, then you only have to add a few required extensions and classes to your test. The following example uses only those extensions and classes required to run a bean that injects configuration value: <markup lang=\"java\" >import jakarta.inject.Inject; import io.helidon.microprofile.config.ConfigCdiExtension; import io.helidon.microprofile.testing.junit5.AddBean; import io.helidon.microprofile.testing.junit5.AddConfig; import io.helidon.microprofile.testing.junit5.AddExtension; import io.helidon.microprofile.testing.junit5.DisableDiscovery; import io.helidon.microprofile.testing.junit5.HelidonTest; import org.eclipse.microprofile.config.inject.ConfigProperty; import org.junit.jupiter.api.Test; import static org.junit.jupiter.api.Assertions.assertEquals; @HelidonTest @DisableDiscovery @AddExtension(ConfigCdiExtension.class) @AddBean(GreetTest.ConfiguredBean.class) @AddConfig(key = \"test.message\", value = \"Hello Guide!\") class GreetTest { @Inject ConfiguredBean bean; @Test void testBean() { assertEquals(\"Hello Guide!\", bean.message()); } public static class ConfiguredBean { @Inject @ConfigProperty(name = \"test.message\") private String message; String message() { return message; } } } ",
            "title": "Write a Basic Test"
        },
        {
            "location": "/mp/guides/testing-junit5",
            "text": " This guide demonstrated how to create tests for MicroProfile applications in a JUnit 5 environment. It described some useful customizations that can be added to your testing extension and allow you to configure test outcomes for your Helidon MP applications. Refer to the following references for additional information: JUnit 5 User Guide Testing with JUnit 5 ",
            "title": "Summary"
        },
        {
            "location": "/mp/guides/tracing",
            "text": " This guide describes how to create a sample MicroProfile (MP) project that can be used to run some basic examples using tracing with Helidon MP. ",
            "title": "preambule"
        },
        {
            "location": "/mp/guides/tracing",
            "text": " For this 30 minute tutorial, you will need the following: <div class=\"table__overflow elevation-1 flex sm7 \"> A Helidon MP Application You can use your own application or use the Helidon MP Quickstart to create a sample application. Java&#160;SE&#160;21 ( Open&#160;JDK&#160;21 ) Helidon requires Java 21+. Maven 3.8+ Helidon requires Maven 3.8+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop . <markup lang=\"bash\" title=\"Verify Prerequisites\" >java -version mvn --version docker --version kubectl version --short <markup lang=\"bash\" title=\"Setting JAVA_HOME\" ># On Mac export JAVA_HOME=`/usr/libexec/java_home -v 21` # On Linux # Use the appropriate path to your JDK export JAVA_HOME=/usr/lib/jvm/jdk-21 ",
            "title": "What You Need"
        },
        {
            "location": "/mp/guides/tracing",
            "text": " This section explains a few concepts that you need to understand before you get started with tracing. In the context of this document, a service is synonymous with an application. A span is the basic unit of work done within a single service, on a single host. Every span has a name, starting timestamp, and duration. For example, the work done by a REST endpoint is a span. A span is associated to a single service, but its descendants can belong to different services and hosts. A trace contains a collection of spans from one or more services, running on one or more hosts. For example, if you trace a service endpoint that calls another service, then the trace would contain spans from both services. Within a trace, spans are organized as a directed acyclic graph (DAG) and can belong to multiple services, running on multiple hosts. The OpenTracing Data Model describes the details at The OpenTracing Semantic Specification . Spans are automatically created by Helidon as needed during execution of the REST request. ",
            "title": "Tracing Concepts"
        },
        {
            "location": "/mp/guides/tracing",
            "text": " Distributed tracing is a critical feature of micro-service based applications, since it traces workflow both within a service and across multiple services. This provides insight to sequence and timing data for specific blocks of work, which helps you identify performance and operational issues. Helidon MP includes support for distributed tracing through the OpenTracing API . Tracing is integrated with WebServer and Security using either the Zipkin or Jaeger tracers. Tracing Concepts This section explains a few concepts that you need to understand before you get started with tracing. In the context of this document, a service is synonymous with an application. A span is the basic unit of work done within a single service, on a single host. Every span has a name, starting timestamp, and duration. For example, the work done by a REST endpoint is a span. A span is associated to a single service, but its descendants can belong to different services and hosts. A trace contains a collection of spans from one or more services, running on one or more hosts. For example, if you trace a service endpoint that calls another service, then the trace would contain spans from both services. Within a trace, spans are organized as a directed acyclic graph (DAG) and can belong to multiple services, running on multiple hosts. The OpenTracing Data Model describes the details at The OpenTracing Semantic Specification . Spans are automatically created by Helidon as needed during execution of the REST request. ",
            "title": "Introduction"
        },
        {
            "location": "/mp/guides/tracing",
            "text": " Use the Helidon MP Maven archetype to create a simple project that can be used for the examples in this guide. <markup lang=\"bash\" title=\"Run the Maven archetype:\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-mp \\ -DarchetypeVersion=4.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-mp \\ -Dpackage=io.helidon.examples.quickstart.mp <markup lang=\"bash\" title=\"The project will be built and run from the helidon-quickstart-mp directory:\" >cd helidon-quickstart-mp ",
            "title": "Create a Sample Helidon MP project"
        },
        {
            "location": "/mp/guides/tracing",
            "text": " First, you need to run the Jaeger tracer. Helidon will communicate with this tracer at runtime. <markup lang=\"bash\" title=\"Run Jaeger within a docker container, then check the Jaeger server working:\" >docker run -d --name jaeger \\ -e COLLECTOR_OTLP_ENABLED=true \\ -p 6831:6831/udp \\ -p 6832:6832/udp \\ -p 5778:5778 \\ -p 16686:16686 \\ -p 4317:4317 \\ -p 4318:4318 \\ -p 14250:14250 \\ -p 14268:14268 \\ -p 14269:14269 \\ -p 9411:9411 \\ jaegertracing/all-in-one:1.50 Run the Jaeger docker image. <markup lang=\"bash\" title=\"Check the Jaeger server by opening in browser:\" >http://localhost:16686/search ",
            "title": "Set up Jaeger"
        },
        {
            "location": "/mp/guides/tracing",
            "text": " Update the pom.xml file and add the following Jaeger dependency to the &lt;dependencies&gt; section ( not &lt;dependencyManagement&gt; ). This will enable Helidon to use Jaeger at the default host and port, localhost:14250 . <markup lang=\"xml\" title=\"Add the following dependency to pom.xml :\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-tracing&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-providers-jaeger&lt;/artifactId&gt; &lt;/dependency&gt; All spans sent by Helidon to Jaeger need to be associated with a service. Specify the service name below. <markup lang=\"bash\" title=\"Add the following line to META-INF/microprofile-config.properties :\" >tracing.service=helidon-mp-1 <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-mp.jar <markup lang=\"bash\" title=\"Run the curl command in a new terminal window and check the response:\" >curl http://localhost:8080/greet <markup lang=\"json\" >{ \"message\": \"Hello World!\" } ",
            "title": "Enable Tracing in the Helidon Application"
        },
        {
            "location": "/mp/guides/tracing",
            "text": " The tracing output data is verbose and can be difficult to interpret using the REST API, especially since it represents a structure of spans. Jaeger provides a web-based UI at http://localhost:16686/search , where you can see a visual representation of the same data and the relationship between spans within a trace. If you see a Lens UI button at the top center then click on it and it will take you to the specific UI used by this guide. Click on the UI Find traces button (the search icon) as shown in the image below. Jaeger UI The image below shows the trace summary, including start time and duration of each trace. There are several traces, each one generated in response to a curl http://localhost:8080/greet invocation. The oldest trace will have a much longer duration since there is one-time initialization that occurs. Tracing list view Click on a trace and you will see the trace detail page where the spans are listed. You can clearly see the root span and the relationship among all the spans in the trace, along with timing information. Trace detail page A parent span might not depend on the result of the child. This is called a FollowsFrom reference, see Open Tracing Semantic Spec . Note that the last span that writes the response after the root span ends falls into this category. You can examine span details by clicking on the span row. Refer to the image below, which shows the security span details, including timing information. You can see times for each space relative to the root span. These rows are annotated with Server Start and Server Finish , as shown in the third column. ",
            "title": "View Tracing Using Jaeger UI"
        },
        {
            "location": "/mp/guides/tracing",
            "text": " To trace at the method level, you just annotate a method with @Traced. <markup lang=\"java\" title=\"Update the GreetingProvider class; 1) Add a new import and 2) Add the @Traced annotation to the getMessage method:\" >import org.eclipse.microprofile.opentracing.Traced; class MyClass{ @Traced String getMessage() { return message.get(); } } Import the Traced annotation. Enable tracing for getMessage. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints and check the response:\" >curl http://localhost:8080/greet Click the back button on your browser, then click on the UI refresh button to see the new trace. Select the newest trace in the list to see the trace detail page like the one below. Notice the new span named io.helidon.examples.quickstart.mp.greetingprovider.getmessage . ",
            "title": "Tracing at the Method Level"
        },
        {
            "location": "/mp/guides/tracing",
            "text": " To trace at the class level, annotate the class with @Traced. This will enable tracing for all class methods, except for the constructor and private methods. <markup lang=\"java\" title=\"Update the GreetingProvider class; 1) Add @Traced to the GreetingProvider class and 2) Remove @Traced from the getMessage method:\" >@Traced @ApplicationScoped public class GreetingProvider { String getMessage() { return message.get(); } } This will enable tracing for all class methods, except for the constructor and methods that are private. Remove @Traced for the getMessage method. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints and check the response:\" >curl http://localhost:8080/greet You can refresh the UI view and drill down the trace to see the new spans. Methods invoked directly by your code are not enabled for tracing, even if you explicitly annotate them with @Traced. Tracing only works for methods invoked on CDI beans. See the example below. <markup lang=\"java\" title=\"Update the GreetingProvider class with the following code:\" >@ApplicationScoped public class GreetingProvider { private final AtomicReference&lt;String&gt; message = new AtomicReference&lt;&gt;(); @Inject public GreetingProvider(@ConfigProperty(name = \"app.greeting\") String message) { this.message.set(message); } @Traced String getMessage() { return getMessage2(); } @Traced String getMessage2() { return message.get(); } void setMessage(String message) { this.message.set(message); } } The getMessage method will be traced since it is externally invoked by GreetResource . The getMessage2 method will not be traced, even with the @Traced annotation, since it is called internally by getMessage . <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints:\" >curl http://localhost:8080/greet Then check the response in the Jaeger UI in the browser. ",
            "title": "Tracing at the Class Level"
        },
        {
            "location": "/mp/guides/tracing",
            "text": " So far in this tutorial, you have used tracing with JAX-RS without needing to annotate. You can enable tracing on other CDI beans, either at the class level or at the method level, as shown by the following examples. Tracing at the Method Level To trace at the method level, you just annotate a method with @Traced. <markup lang=\"java\" title=\"Update the GreetingProvider class; 1) Add a new import and 2) Add the @Traced annotation to the getMessage method:\" >import org.eclipse.microprofile.opentracing.Traced; class MyClass{ @Traced String getMessage() { return message.get(); } } Import the Traced annotation. Enable tracing for getMessage. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints and check the response:\" >curl http://localhost:8080/greet Click the back button on your browser, then click on the UI refresh button to see the new trace. Select the newest trace in the list to see the trace detail page like the one below. Notice the new span named io.helidon.examples.quickstart.mp.greetingprovider.getmessage . Tracing at the Class Level To trace at the class level, annotate the class with @Traced. This will enable tracing for all class methods, except for the constructor and private methods. <markup lang=\"java\" title=\"Update the GreetingProvider class; 1) Add @Traced to the GreetingProvider class and 2) Remove @Traced from the getMessage method:\" >@Traced @ApplicationScoped public class GreetingProvider { String getMessage() { return message.get(); } } This will enable tracing for all class methods, except for the constructor and methods that are private. Remove @Traced for the getMessage method. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints and check the response:\" >curl http://localhost:8080/greet You can refresh the UI view and drill down the trace to see the new spans. Methods invoked directly by your code are not enabled for tracing, even if you explicitly annotate them with @Traced. Tracing only works for methods invoked on CDI beans. See the example below. <markup lang=\"java\" title=\"Update the GreetingProvider class with the following code:\" >@ApplicationScoped public class GreetingProvider { private final AtomicReference&lt;String&gt; message = new AtomicReference&lt;&gt;(); @Inject public GreetingProvider(@ConfigProperty(name = \"app.greeting\") String message) { this.message.set(message); } @Traced String getMessage() { return getMessage2(); } @Traced String getMessage2() { return message.get(); } void setMessage(String message) { this.message.set(message); } } The getMessage method will be traced since it is externally invoked by GreetResource . The getMessage2 method will not be traced, even with the @Traced annotation, since it is called internally by getMessage . <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints:\" >curl http://localhost:8080/greet Then check the response in the Jaeger UI in the browser. ",
            "title": "Enable Tracing on CDI Beans"
        },
        {
            "location": "/mp/guides/tracing",
            "text": "<markup lang=\"bash\" title=\"Run the Maven archetype:\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-mp \\ -DarchetypeVersion=4.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-mp-2 \\ -Dpackage=io.helidon.examples.quickstart.mp <markup lang=\"bash\" title=\"The project will be built and run from the helidon-quickstart-mp directory:\" >cd helidon-quickstart-mp-2 <markup lang=\"xml\" title=\"Add the following dependency to pom.xml :\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-providers-jaeger&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"bash\" title=\"Replace META-INF/microprofile-config.properties with the following:\" >app.greeting=Hello From MP-2 tracing.service=helidon-mp-2 # Microprofile server properties server.port=8081 server.host=0.0.0.0 <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-mp-2.jar <markup lang=\"bash\" title=\"Run the curl command in a new terminal window and check the response ( notice the port is 8081 ) :\" >curl http://localhost:8081/greet <markup lang=\"json\" >{ \"message\": \"Hello From MP-2 World!\" } ",
            "title": "Create a second service"
        },
        {
            "location": "/mp/guides/tracing",
            "text": " Once you have validated that the second service is running correctly, you need to modify the original application to call it. <markup lang=\"java\" title=\"Replace the GreetResource class with the following code:\" >package io.helidon.examples.quickstart.se; import java.util.Collections; import jakarta.enterprise.context.RequestScoped; import jakarta.inject.Inject; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.client.WebTarget; import jakarta.ws.rs.core.MediaType; import org.glassfish.jersey.server.Uri; @Path(\"/greet\") @RequestScoped public class GreetResource { @Uri(\"http://localhost:8081/greet\") private WebTarget target; private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); private final GreetingProvider greetingProvider; @Inject public GreetResource(GreetingProvider greetingConfig) { this.greetingProvider = greetingConfig; } @SuppressWarnings(\"checkstyle:designforextension\") @GET @Produces(MediaType.APPLICATION_JSON) public JsonObject getDefaultMessage() { return createResponse(\"World\"); } @GET @Path(\"/outbound\") public JsonObject outbound() { return target.request().accept(MediaType.APPLICATION_JSON_TYPE).get(JsonObject.class); } private JsonObject createResponse(String who) { String msg = String.format(\"%s %s!\", greetingProvider.getMessage(), who); return JSON.createObjectBuilder().add(\"message\", msg).build(); } } This is the WebTarget needed to send a request to the second service at port 8081 . This is the new endpoint that will call the second service. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl -i http://localhost:8080/greet/outbound The request went to the service on 8080 , which then invoked the service at 8081 to get the greeting. <markup lang=\"json\" >{ \"message\": \"Hello From MP-2 World!\" } Notice the greeting came from the second service. Refresh the Jaeger UI trace listing page and notice that there is a trace across two services. Tracing across multiple services detail view In the image above, you can see that the trace includes spans from two services. You will notice there is a gap before the sixth span, which is a get operation. This is a one-time client initialization delay. Run the /outbound curl command again and look at the new trace to see that the delay no longer exists. You can now stop your second service, it is no longer used in this guide. ",
            "title": "Modify the first service"
        },
        {
            "location": "/mp/guides/tracing",
            "text": " Helidon automatically traces across services as long as the services use the same tracer, for example, the same instance of Jaeger. This means a single trace can include spans from multiple services and hosts. OpenTracing uses a SpanContext to propagate tracing information across process boundaries. When you make client API calls, Helidon will internally call OpenTracing APIs to propagate the SpanContext . There is nothing you need to do in your application to make this work. To demonstrate distributed tracing, you will need to create a second project, where the server listens on port 8081. Create a new root directory to hold this new project, then do the following steps, similar to what you did at the start of this guide: Create a second service <markup lang=\"bash\" title=\"Run the Maven archetype:\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-mp \\ -DarchetypeVersion=4.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-mp-2 \\ -Dpackage=io.helidon.examples.quickstart.mp <markup lang=\"bash\" title=\"The project will be built and run from the helidon-quickstart-mp directory:\" >cd helidon-quickstart-mp-2 <markup lang=\"xml\" title=\"Add the following dependency to pom.xml :\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-providers-jaeger&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"bash\" title=\"Replace META-INF/microprofile-config.properties with the following:\" >app.greeting=Hello From MP-2 tracing.service=helidon-mp-2 # Microprofile server properties server.port=8081 server.host=0.0.0.0 <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-mp-2.jar <markup lang=\"bash\" title=\"Run the curl command in a new terminal window and check the response ( notice the port is 8081 ) :\" >curl http://localhost:8081/greet <markup lang=\"json\" >{ \"message\": \"Hello From MP-2 World!\" } Modify the first service Once you have validated that the second service is running correctly, you need to modify the original application to call it. <markup lang=\"java\" title=\"Replace the GreetResource class with the following code:\" >package io.helidon.examples.quickstart.se; import java.util.Collections; import jakarta.enterprise.context.RequestScoped; import jakarta.inject.Inject; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.client.WebTarget; import jakarta.ws.rs.core.MediaType; import org.glassfish.jersey.server.Uri; @Path(\"/greet\") @RequestScoped public class GreetResource { @Uri(\"http://localhost:8081/greet\") private WebTarget target; private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); private final GreetingProvider greetingProvider; @Inject public GreetResource(GreetingProvider greetingConfig) { this.greetingProvider = greetingConfig; } @SuppressWarnings(\"checkstyle:designforextension\") @GET @Produces(MediaType.APPLICATION_JSON) public JsonObject getDefaultMessage() { return createResponse(\"World\"); } @GET @Path(\"/outbound\") public JsonObject outbound() { return target.request().accept(MediaType.APPLICATION_JSON_TYPE).get(JsonObject.class); } private JsonObject createResponse(String who) { String msg = String.format(\"%s %s!\", greetingProvider.getMessage(), who); return JSON.createObjectBuilder().add(\"message\", msg).build(); } } This is the WebTarget needed to send a request to the second service at port 8081 . This is the new endpoint that will call the second service. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl -i http://localhost:8080/greet/outbound The request went to the service on 8080 , which then invoked the service at 8081 to get the greeting. <markup lang=\"json\" >{ \"message\": \"Hello From MP-2 World!\" } Notice the greeting came from the second service. Refresh the Jaeger UI trace listing page and notice that there is a trace across two services. Tracing across multiple services detail view In the image above, you can see that the trace includes spans from two services. You will notice there is a gap before the sixth span, which is a get operation. This is a one-time client initialization delay. Run the /outbound curl command again and look at the new trace to see that the delay no longer exists. You can now stop your second service, it is no longer used in this guide. ",
            "title": "Trace Across Services"
        },
        {
            "location": "/mp/guides/tracing",
            "text": " The examples in this guide demonstrate how to integrate tracing with Helidon, how to view traces, how to trace across multiple services, and how to integrate tracing with Kubernetes. All examples use Jaeger and traces will be viewed using Jaeger UI. Create a Sample Helidon MP project Use the Helidon MP Maven archetype to create a simple project that can be used for the examples in this guide. <markup lang=\"bash\" title=\"Run the Maven archetype:\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-mp \\ -DarchetypeVersion=4.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-mp \\ -Dpackage=io.helidon.examples.quickstart.mp <markup lang=\"bash\" title=\"The project will be built and run from the helidon-quickstart-mp directory:\" >cd helidon-quickstart-mp Set up Jaeger First, you need to run the Jaeger tracer. Helidon will communicate with this tracer at runtime. <markup lang=\"bash\" title=\"Run Jaeger within a docker container, then check the Jaeger server working:\" >docker run -d --name jaeger \\ -e COLLECTOR_OTLP_ENABLED=true \\ -p 6831:6831/udp \\ -p 6832:6832/udp \\ -p 5778:5778 \\ -p 16686:16686 \\ -p 4317:4317 \\ -p 4318:4318 \\ -p 14250:14250 \\ -p 14268:14268 \\ -p 14269:14269 \\ -p 9411:9411 \\ jaegertracing/all-in-one:1.50 Run the Jaeger docker image. <markup lang=\"bash\" title=\"Check the Jaeger server by opening in browser:\" >http://localhost:16686/search Enable Tracing in the Helidon Application Update the pom.xml file and add the following Jaeger dependency to the &lt;dependencies&gt; section ( not &lt;dependencyManagement&gt; ). This will enable Helidon to use Jaeger at the default host and port, localhost:14250 . <markup lang=\"xml\" title=\"Add the following dependency to pom.xml :\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-tracing&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-providers-jaeger&lt;/artifactId&gt; &lt;/dependency&gt; All spans sent by Helidon to Jaeger need to be associated with a service. Specify the service name below. <markup lang=\"bash\" title=\"Add the following line to META-INF/microprofile-config.properties :\" >tracing.service=helidon-mp-1 <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-mp.jar <markup lang=\"bash\" title=\"Run the curl command in a new terminal window and check the response:\" >curl http://localhost:8080/greet <markup lang=\"json\" >{ \"message\": \"Hello World!\" } View Tracing Using Jaeger UI The tracing output data is verbose and can be difficult to interpret using the REST API, especially since it represents a structure of spans. Jaeger provides a web-based UI at http://localhost:16686/search , where you can see a visual representation of the same data and the relationship between spans within a trace. If you see a Lens UI button at the top center then click on it and it will take you to the specific UI used by this guide. Click on the UI Find traces button (the search icon) as shown in the image below. Jaeger UI The image below shows the trace summary, including start time and duration of each trace. There are several traces, each one generated in response to a curl http://localhost:8080/greet invocation. The oldest trace will have a much longer duration since there is one-time initialization that occurs. Tracing list view Click on a trace and you will see the trace detail page where the spans are listed. You can clearly see the root span and the relationship among all the spans in the trace, along with timing information. Trace detail page A parent span might not depend on the result of the child. This is called a FollowsFrom reference, see Open Tracing Semantic Spec . Note that the last span that writes the response after the root span ends falls into this category. You can examine span details by clicking on the span row. Refer to the image below, which shows the security span details, including timing information. You can see times for each space relative to the root span. These rows are annotated with Server Start and Server Finish , as shown in the third column. Enable Tracing on CDI Beans So far in this tutorial, you have used tracing with JAX-RS without needing to annotate. You can enable tracing on other CDI beans, either at the class level or at the method level, as shown by the following examples. Tracing at the Method Level To trace at the method level, you just annotate a method with @Traced. <markup lang=\"java\" title=\"Update the GreetingProvider class; 1) Add a new import and 2) Add the @Traced annotation to the getMessage method:\" >import org.eclipse.microprofile.opentracing.Traced; class MyClass{ @Traced String getMessage() { return message.get(); } } Import the Traced annotation. Enable tracing for getMessage. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints and check the response:\" >curl http://localhost:8080/greet Click the back button on your browser, then click on the UI refresh button to see the new trace. Select the newest trace in the list to see the trace detail page like the one below. Notice the new span named io.helidon.examples.quickstart.mp.greetingprovider.getmessage . Tracing at the Class Level To trace at the class level, annotate the class with @Traced. This will enable tracing for all class methods, except for the constructor and private methods. <markup lang=\"java\" title=\"Update the GreetingProvider class; 1) Add @Traced to the GreetingProvider class and 2) Remove @Traced from the getMessage method:\" >@Traced @ApplicationScoped public class GreetingProvider { String getMessage() { return message.get(); } } This will enable tracing for all class methods, except for the constructor and methods that are private. Remove @Traced for the getMessage method. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints and check the response:\" >curl http://localhost:8080/greet You can refresh the UI view and drill down the trace to see the new spans. Methods invoked directly by your code are not enabled for tracing, even if you explicitly annotate them with @Traced. Tracing only works for methods invoked on CDI beans. See the example below. <markup lang=\"java\" title=\"Update the GreetingProvider class with the following code:\" >@ApplicationScoped public class GreetingProvider { private final AtomicReference&lt;String&gt; message = new AtomicReference&lt;&gt;(); @Inject public GreetingProvider(@ConfigProperty(name = \"app.greeting\") String message) { this.message.set(message); } @Traced String getMessage() { return getMessage2(); } @Traced String getMessage2() { return message.get(); } void setMessage(String message) { this.message.set(message); } } The getMessage method will be traced since it is externally invoked by GreetResource . The getMessage2 method will not be traced, even with the @Traced annotation, since it is called internally by getMessage . <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints:\" >curl http://localhost:8080/greet Then check the response in the Jaeger UI in the browser. Trace Across Services Helidon automatically traces across services as long as the services use the same tracer, for example, the same instance of Jaeger. This means a single trace can include spans from multiple services and hosts. OpenTracing uses a SpanContext to propagate tracing information across process boundaries. When you make client API calls, Helidon will internally call OpenTracing APIs to propagate the SpanContext . There is nothing you need to do in your application to make this work. To demonstrate distributed tracing, you will need to create a second project, where the server listens on port 8081. Create a new root directory to hold this new project, then do the following steps, similar to what you did at the start of this guide: Create a second service <markup lang=\"bash\" title=\"Run the Maven archetype:\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-mp \\ -DarchetypeVersion=4.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-mp-2 \\ -Dpackage=io.helidon.examples.quickstart.mp <markup lang=\"bash\" title=\"The project will be built and run from the helidon-quickstart-mp directory:\" >cd helidon-quickstart-mp-2 <markup lang=\"xml\" title=\"Add the following dependency to pom.xml :\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-providers-jaeger&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"bash\" title=\"Replace META-INF/microprofile-config.properties with the following:\" >app.greeting=Hello From MP-2 tracing.service=helidon-mp-2 # Microprofile server properties server.port=8081 server.host=0.0.0.0 <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-mp-2.jar <markup lang=\"bash\" title=\"Run the curl command in a new terminal window and check the response ( notice the port is 8081 ) :\" >curl http://localhost:8081/greet <markup lang=\"json\" >{ \"message\": \"Hello From MP-2 World!\" } Modify the first service Once you have validated that the second service is running correctly, you need to modify the original application to call it. <markup lang=\"java\" title=\"Replace the GreetResource class with the following code:\" >package io.helidon.examples.quickstart.se; import java.util.Collections; import jakarta.enterprise.context.RequestScoped; import jakarta.inject.Inject; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.client.WebTarget; import jakarta.ws.rs.core.MediaType; import org.glassfish.jersey.server.Uri; @Path(\"/greet\") @RequestScoped public class GreetResource { @Uri(\"http://localhost:8081/greet\") private WebTarget target; private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); private final GreetingProvider greetingProvider; @Inject public GreetResource(GreetingProvider greetingConfig) { this.greetingProvider = greetingConfig; } @SuppressWarnings(\"checkstyle:designforextension\") @GET @Produces(MediaType.APPLICATION_JSON) public JsonObject getDefaultMessage() { return createResponse(\"World\"); } @GET @Path(\"/outbound\") public JsonObject outbound() { return target.request().accept(MediaType.APPLICATION_JSON_TYPE).get(JsonObject.class); } private JsonObject createResponse(String who) { String msg = String.format(\"%s %s!\", greetingProvider.getMessage(), who); return JSON.createObjectBuilder().add(\"message\", msg).build(); } } This is the WebTarget needed to send a request to the second service at port 8081 . This is the new endpoint that will call the second service. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl -i http://localhost:8080/greet/outbound The request went to the service on 8080 , which then invoked the service at 8081 to get the greeting. <markup lang=\"json\" >{ \"message\": \"Hello From MP-2 World!\" } Notice the greeting came from the second service. Refresh the Jaeger UI trace listing page and notice that there is a trace across two services. Tracing across multiple services detail view In the image above, you can see that the trace includes spans from two services. You will notice there is a gap before the sixth span, which is a get operation. This is a one-time client initialization delay. Run the /outbound curl command again and look at the new trace to see that the delay no longer exists. You can now stop your second service, it is no longer used in this guide. ",
            "title": "Getting Started with Tracing"
        },
        {
            "location": "/mp/guides/tracing",
            "text": "<markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named jaeger.yaml , with the following contents:\" >apiVersion: v1 kind: Service metadata: name: jaeger spec: ports: - port: 16686 protocol: TCP selector: app: jaeger --- kind: Pod apiVersion: v1 metadata: name: jaeger labels: app: jaeger spec: containers: - name: jaeger image: jaegertracing/all-in-one imagePullPolicy: IfNotPresent ports: - containerPort: 16686 <markup lang=\"bash\" title=\"Create the Jaeger pod and ClusterIP service:\" >kubectl apply -f ./jaeger.yaml <markup lang=\"bash\" title=\"Create a Jaeger external server and expose it on port 9142:\" >kubectl expose pod jaeger --name=jaeger-external --port=16687 --target-port=16686 --type=LoadBalancer Create a service so that you can access the Jaeger UI. Navigate to http://localhost:16687/search to validate that you can access Jaeger running in Kubernetes. It may take a few seconds before it is ready. ",
            "title": "Deploy Jaeger into Kubernetes"
        },
        {
            "location": "/mp/guides/tracing",
            "text": "<markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named tracing.yaml , with the following contents:\" >kind: Service apiVersion: v1 metadata: name: helidon-tracing labels: app: helidon-tracing spec: type: NodePort selector: app: helidon-tracing ports: - port: 8080 targetPort: 8080 name: http --- kind: Deployment apiVersion: apps/v1 metadata: name: helidon-tracing spec: replicas: 1 selector: matchLabels: app: helidon-tracing template: metadata: labels: app: helidon-tracing version: v1 spec: containers: - name: helidon-tracing image: helidon-tracing-mp imagePullPolicy: IfNotPresent ports: - containerPort: 8080 A service of type NodePort that serves the default routes on port 8080 . A deployment with one replica of a pod. <markup lang=\"bash\" title=\"Create and deploy the application into Kubernetes:\" >kubectl apply -f ./tracing.yaml ",
            "title": "Deploy Your Helidon Application into Kubernetes"
        },
        {
            "location": "/mp/guides/tracing",
            "text": "<markup lang=\"bash\" title=\"Get the application service information:\" >kubectl get service/helidon-tracing <markup lang=\"bash\" >NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE helidon-tracing NodePort 10.99.159.2 &lt;none&gt; 8080:31143/TCP 8s A service of type NodePort that serves the default routes on port 31143 . <markup lang=\"bash\" title=\"Verify the tracing endpoint using port 31143 , your port will likely be different:\" >curl http://localhost:31143/greet <markup lang=\"json\" >{ \"message\": \"Hello World!\" } Access the Jaeger UI at http://localhost:16687/search and click on the refresh icon to see the trace that was just created. ",
            "title": "Access Your Application and the Jaeger Trace"
        },
        {
            "location": "/mp/guides/tracing",
            "text": " You can now delete the Kubernetes resources that were just created during this example. <markup lang=\"bash\" title=\"Delete the Kubernetes resources:\" >kubectl delete -f ./jaeger.yaml kubectl delete -f ./tracing.yaml kubectl delete service jaeger-external docker rm -f jaeger ",
            "title": "Cleanup"
        },
        {
            "location": "/mp/guides/tracing",
            "text": " The following example demonstrate how to use Jaeger from a Helidon application running in Kubernetes. <markup lang=\"bash\" title=\"Add the following line to META-INF/microprofile-config.properties :\" >tracing.host=jaeger <markup lang=\"bash\" title=\"Stop the application and build the docker image for your application:\" >docker build -t helidon-tracing-mp . Deploy Jaeger into Kubernetes <markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named jaeger.yaml , with the following contents:\" >apiVersion: v1 kind: Service metadata: name: jaeger spec: ports: - port: 16686 protocol: TCP selector: app: jaeger --- kind: Pod apiVersion: v1 metadata: name: jaeger labels: app: jaeger spec: containers: - name: jaeger image: jaegertracing/all-in-one imagePullPolicy: IfNotPresent ports: - containerPort: 16686 <markup lang=\"bash\" title=\"Create the Jaeger pod and ClusterIP service:\" >kubectl apply -f ./jaeger.yaml <markup lang=\"bash\" title=\"Create a Jaeger external server and expose it on port 9142:\" >kubectl expose pod jaeger --name=jaeger-external --port=16687 --target-port=16686 --type=LoadBalancer Create a service so that you can access the Jaeger UI. Navigate to http://localhost:16687/search to validate that you can access Jaeger running in Kubernetes. It may take a few seconds before it is ready. Deploy Your Helidon Application into Kubernetes <markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named tracing.yaml , with the following contents:\" >kind: Service apiVersion: v1 metadata: name: helidon-tracing labels: app: helidon-tracing spec: type: NodePort selector: app: helidon-tracing ports: - port: 8080 targetPort: 8080 name: http --- kind: Deployment apiVersion: apps/v1 metadata: name: helidon-tracing spec: replicas: 1 selector: matchLabels: app: helidon-tracing template: metadata: labels: app: helidon-tracing version: v1 spec: containers: - name: helidon-tracing image: helidon-tracing-mp imagePullPolicy: IfNotPresent ports: - containerPort: 8080 A service of type NodePort that serves the default routes on port 8080 . A deployment with one replica of a pod. <markup lang=\"bash\" title=\"Create and deploy the application into Kubernetes:\" >kubectl apply -f ./tracing.yaml Access Your Application and the Jaeger Trace <markup lang=\"bash\" title=\"Get the application service information:\" >kubectl get service/helidon-tracing <markup lang=\"bash\" >NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE helidon-tracing NodePort 10.99.159.2 &lt;none&gt; 8080:31143/TCP 8s A service of type NodePort that serves the default routes on port 31143 . <markup lang=\"bash\" title=\"Verify the tracing endpoint using port 31143 , your port will likely be different:\" >curl http://localhost:31143/greet <markup lang=\"json\" >{ \"message\": \"Hello World!\" } Access the Jaeger UI at http://localhost:16687/search and click on the refresh icon to see the trace that was just created. Cleanup You can now delete the Kubernetes resources that were just created during this example. <markup lang=\"bash\" title=\"Delete the Kubernetes resources:\" >kubectl delete -f ./jaeger.yaml kubectl delete -f ./tracing.yaml kubectl delete service jaeger-external docker rm -f jaeger ",
            "title": "Integration with Kubernetes"
        },
        {
            "location": "/mp/guides/tracing",
            "text": " This guide has demonstrated how to use the Helidon MP tracing feature with Jaeger. You have learned to do the following: Enable tracing within a service Use tracing with JAX-RS and CDI beans Use the Jaeger UI Use tracing across multiple services Integrate tracing with Kubernetes Refer to the following references for additional information: MicroProfile OpenTracing specification MicroProfile OpenTracing Javadoc Helidon Javadoc ",
            "title": "Summary"
        },
        {
            "location": "/mp/guides/upgrade",
            "text": " In Helidon 2.x we have made some changes to APIs and runtime behavior. This guide will help you migrate a Helidon MP 1.x application to 2.x. ",
            "title": "preambule"
        },
        {
            "location": "/mp/guides/upgrade",
            "text": " Java 8 is no longer supported in Helidon 2. Java 11 or newer is required. ",
            "title": "Java 11 Runtime"
        },
        {
            "location": "/mp/guides/upgrade",
            "text": " We have upgraded to OpenTracing version 0.33.0 that is not backward compatible. OpenTracing introduced the following breaking changes: Removed Replacement ScopeManager.active() Tracer.activeSpan() ScopeManager.activate(Span, boolean) ScopeManager.activate(Span) - second parameter is now always false SpanBuilder.startActive() Tracer.activateSpan(Span) TextMapExtractAdapter and TextMapInjectAdapter TextMapAdapter Module name changed opentracing.api io.opentracing.api (same for noop and util ) If you use the TracerBuilder abstraction in Helidon and have no custom Spans, there is no change required ",
            "title": "Tracing"
        },
        {
            "location": "/mp/guides/upgrade",
            "text": " When the OIDC provider is configured to use cookie (default configuration) to carry authentication information, the cookie Same-Site is now set to Lax (used to be Strict ). This is to prevent infinite redirects, as browsers would refuse to set the cookie on redirected requests (due to this setting). Only in the case of the frontend host and identity host match, we leave Strict as the default ",
            "title": "Security: OIDC"
        },
        {
            "location": "/mp/guides/upgrade",
            "text": " We have removed the versioned MicroProfile bundles (i.e. helidon-microprofile-x.x ), and introduced unversioned core and full bundles: io.helidon.microprofile.bundles:helidon-microprofile-core - contains only MP Server and Config. Allows you to add only the specifications needed by your application. io.helidon.microprofile.bundles:helidon-microprofile - contains the latest full MicroProfile version implemented by Helidon ",
            "title": "MicroProfile Bundles"
        },
        {
            "location": "/mp/guides/upgrade",
            "text": " io.helidon.microprofile.server.Main has been deprecated. Use io.helidon.microprofile.cdi.Main instead. io.helidon.microprofile.server.Server is still available, although the features are much reduced. You no longer need to initialize Java Util Logging explicitly. Put logging.properties on the classpath or in the current directory to be automatically picked up to configure Java Util Logging. ",
            "title": "Application Main and Startup"
        },
        {
            "location": "/mp/guides/upgrade",
            "text": " Helidon 1.x usually required that you have an Application subclass that returned the Application classes to scan. For common cases this is no longer necessary, and you might be able to remove your Application class. JAX-RS applications now work similarly to how they work in application servers: if there is an Application subclass that returns anything from getClasses or getSingletons , it is used as is if there is an Application subclass that returns empty sets from these methods, all available resource classes will be part of such an application if there is no Application subclass, a synthetic application will be created with all available resource classes Application subclasses MUST be annotated with @ApplicationScoped , otherwise they are ignored ",
            "title": "JAX-RS Applications"
        },
        {
            "location": "/mp/guides/upgrade",
            "text": " If a JAX-RS application exists that is annotated with @LoginConfig with value MP-JWT, the correct authentication provider is added to security. The startup would fail if the provider is required yet not configured. ",
            "title": "MicroProfile JWT-Auth"
        },
        {
            "location": "/mp/guides/upgrade",
            "text": " If there is no authentication provider configured, authentication will now fail. If there is no authorization provider configured, the ABAC provider will be configured. In Helidon 1.x these were configured if there was no provider configured overall. ",
            "title": "Security in Helidon MP"
        },
        {
            "location": "/mp/guides/upgrade",
            "text": " In order to support GraalVM native-image we have had to re-implement how CDI is initialized and started. This has resulted in some changes in APIs and behavior: You can no longer start the CDI container yourself. You can only run a single instance of Server in a JVM. If you use SeContainerInitializer you will get an exception. This can be worked around by configuration property mp.initializer.allow=true , and warning can be removed using mp.initializer.no-warn=true Once SeContainerInitializer is used you can no longer use MP with native-image You can no longer provide a Context instance. The root context is now built-in. MpService and MpServiceContext have been removed. Methods from context have been moved to JaxRsCdiExtension and ServerCdiExtension . These can be accessed from CDI extension through BeanManager.getExtension . Methods register can be used on current io.helidon.context.Context MpService equivalent is a CDI extension. All Helidon services were refactored to CDI extension (you can use these for reference). Server.cdiContainer is removed, use CDI.current() instead. ",
            "title": "CDI and MicroProfile Server"
        },
        {
            "location": "/mp/guides/upgrade",
            "text": " Helidon now supports only MicroProfile Metrics 2.x. Support for Metrics 1.x has been removed, and modules for 2.x have been renamed from metrics2 to metrics . ",
            "title": "Metrics"
        },
        {
            "location": "/mp/guides/upgrade",
            "text": " We have moved from dependencies in groupId javax (Java EE modules) to dependencies in groupId jakarta (Jakarta EE modules). In case you declared a dependency on a javax module, you should change it to a jakarta one. Example: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;javax.activation&lt;/groupId&gt; &lt;artifactId&gt;javax.activation-api&lt;/artifactId&gt; &lt;/dependency&gt; should be changed to <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;jakarta.activation&lt;/groupId&gt; &lt;artifactId&gt;jakarta.activation-api&lt;/artifactId&gt; &lt;/dependency&gt; As the javax module is no longer in dependency management of Helidon parent pom files. ",
            "title": "Java EE dependencies"
        },
        {
            "location": "/mp/guides/upgrade_3x",
            "text": " In Helidon 3.x we have made some changes to APIs and runtime behavior. This guide will help you upgrade a Helidon MP 2.x application to 3.x. ",
            "title": "preambule"
        },
        {
            "location": "/mp/guides/upgrade_3x",
            "text": " Java 11 is no longer supported in Helidon 3. Java 17 or newer is required. Please follow the instructions in Prerequisites for proper installation. ",
            "title": "Java 17 Runtime"
        },
        {
            "location": "/mp/guides/upgrade_3x",
            "text": " Helidon 3 supports MicroProfile 5.0 and selected Jakarta EE 9.1 APIs. In Jakarta EE 9.1 the Java package namespace was changed from javax to jakarta . Therefore, you must change your application to use jakarta instead of corresponding javax for Jakarta EE packages. In version 3.x Helidon supports MicroProfile 5.0 specification, which now is fully migrated to jakarta namespace. As a result, javax module is no longer in dependency management of Helidon parent pom files. ",
            "title": "javax.* namespace to jakarta.* namespace"
        },
        {
            "location": "/mp/guides/upgrade_3x",
            "text": " MicroProfile Config 3.0.3 : Incompatible changes described in MicroProfile Config 3.0.3 Specification MicroProfile Fault Tolerance 4.0.2 : Incompatible changes described in MicroProfile Fault Tolerance 4.0.2 Specification MicroProfile Health 4.0 : Incompatible changes described in MicroProfile Health 4.0 Specification MicroProfile JWT Authentication 2.1 : Incompatible changes described in MicroProfile JWT Authentication 2.1 Specification MicroProfile Metrics 5.0.1 : Incompatible changes described in MicroProfile Metrics 5.0.1 Specification MicroProfile OpenAPI 3.1 : Incompatible changes described in MicroProfile OpenAPI 3.1 Specification MicroProfile OpenTracing 3.0 : Incompatible changes described in MicroProfile OpenTracing 3.0 Specification MicroProfile Rest Client 3.0 : Incompatible changes described in MicroProfile Rest Client 3.0 Specification ",
            "title": "MicroProfile specifications"
        },
        {
            "location": "/mp/guides/upgrade_3x",
            "text": " Migration from javax to jakarta namespace is making this release backward incompatible with previous version of MicroProfile. For each specification there are also API and functional changes, described below. MicroProfile specifications MicroProfile Config 3.0.3 : Incompatible changes described in MicroProfile Config 3.0.3 Specification MicroProfile Fault Tolerance 4.0.2 : Incompatible changes described in MicroProfile Fault Tolerance 4.0.2 Specification MicroProfile Health 4.0 : Incompatible changes described in MicroProfile Health 4.0 Specification MicroProfile JWT Authentication 2.1 : Incompatible changes described in MicroProfile JWT Authentication 2.1 Specification MicroProfile Metrics 5.0.1 : Incompatible changes described in MicroProfile Metrics 5.0.1 Specification MicroProfile OpenAPI 3.1 : Incompatible changes described in MicroProfile OpenAPI 3.1 Specification MicroProfile OpenTracing 3.0 : Incompatible changes described in MicroProfile OpenTracing 3.0 Specification MicroProfile Rest Client 3.0 : Incompatible changes described in MicroProfile Rest Client 3.0 Specification ",
            "title": "Incompatible changes for each specification"
        },
        {
            "location": "/mp/guides/upgrade_3x",
            "text": " CDI (Jakarta Contexts and Dependency Injection) 4.0.1 : Changes described in CDI (Jakarta Contexts and Dependency Injection) 4.0.1 Specification JAX-RS (Jakarta RESTful Web Services) 3.1.0 : Moved to jakarta namespace. Changes described in JAX-RS (Jakarta RESTful Web Services) 3.1.0Specification JSON-B (Jakarta JSON Binding) 3.0 : Moved to jakarta namespace. Changes described in JSON-B (Jakarta JSON Binding) 3.0 Specification JSON-P (Jakarta JSON Processing) 2.1.1 : Moved to jakarta namespace. Jakarta Annotations 2.1.1 : Moved to jakarta namespace. Moved to jakarta namespace. Full information in Jakarta Annotations 2.1.1 Specification Jakarta Persistence API 3.1.0 : Moved to jakarta namespace. Changes described in Jakarta Persistence API 3.1.0 Specification Jakarta Transactions API 2.0 : Moved to jakarta namespace. Changes described in Jakarta Transactions API 2.0 Specification Jakarta WebSocket API 2.1.0 : Moved to jakarta namespace. Changes described in Jakarta WebSocket API 2.1.0 Specification Jakarta Bean Validation 3.0 : Moved to jakarta namespace. Changes described in Jakarta Bean Validation 3.0 Specification Please, read each specification carefully for incompatible changes! ",
            "title": "Supported Jakarta EE specifications"
        },
        {
            "location": "/mp/guides/upgrade_3x",
            "text": " MicroProfile 5.0 enables MicroProfile APIs to be used together with Jakarta EE 9.1 (Jakarta EE namespace). This release was mainly focused on updating dependencies from javax to jakarta , as well as overall stability and usability improvements. MicroProfile 5.0 lays the foundation for the rapid innovation of MicroProfile APIs for its 2022 releases. MicroProfile 5.0 is an umbrella for the following specifications and their corresponding versions: MicroProfile Config 3.0.3 MicroProfile Fault Tolerance 4.0.2 MicroProfile Health 4.0 MicroProfile JWT Authentication 2.1 MicroProfile Metrics 5.0.1 MicroProfile OpenAPI 3.1 MicroProfile OpenTracing 3.0 MicroProfile Rest Client 3.0 Helidon 3.x supports the following Jakarta EE specifications: CDI (Jakarta Contexts and Dependency Injection) 4.0.1 JAX-RS (Jakarta RESTful Web Services) 3.1.0 JSON-B (Jakarta JSON Binding) 3.0 JSON-P (Jakarta JSON Processing) 2.1.1 Jakarta Annotations 2.1.1 Jakarta Persistence API 3.1.0 Jakarta Transactions API 2.0 Jakarta WebSocket API 2.1.0 Jakarta Bean Validation 3.0 Corresponding changes to Helidon code were made to support the corresponding specifications' versions. Incompatible changes for each specification Migration from javax to jakarta namespace is making this release backward incompatible with previous version of MicroProfile. For each specification there are also API and functional changes, described below. MicroProfile specifications MicroProfile Config 3.0.3 : Incompatible changes described in MicroProfile Config 3.0.3 Specification MicroProfile Fault Tolerance 4.0.2 : Incompatible changes described in MicroProfile Fault Tolerance 4.0.2 Specification MicroProfile Health 4.0 : Incompatible changes described in MicroProfile Health 4.0 Specification MicroProfile JWT Authentication 2.1 : Incompatible changes described in MicroProfile JWT Authentication 2.1 Specification MicroProfile Metrics 5.0.1 : Incompatible changes described in MicroProfile Metrics 5.0.1 Specification MicroProfile OpenAPI 3.1 : Incompatible changes described in MicroProfile OpenAPI 3.1 Specification MicroProfile OpenTracing 3.0 : Incompatible changes described in MicroProfile OpenTracing 3.0 Specification MicroProfile Rest Client 3.0 : Incompatible changes described in MicroProfile Rest Client 3.0 Specification Supported Jakarta EE specifications CDI (Jakarta Contexts and Dependency Injection) 4.0.1 : Changes described in CDI (Jakarta Contexts and Dependency Injection) 4.0.1 Specification JAX-RS (Jakarta RESTful Web Services) 3.1.0 : Moved to jakarta namespace. Changes described in JAX-RS (Jakarta RESTful Web Services) 3.1.0Specification JSON-B (Jakarta JSON Binding) 3.0 : Moved to jakarta namespace. Changes described in JSON-B (Jakarta JSON Binding) 3.0 Specification JSON-P (Jakarta JSON Processing) 2.1.1 : Moved to jakarta namespace. Jakarta Annotations 2.1.1 : Moved to jakarta namespace. Moved to jakarta namespace. Full information in Jakarta Annotations 2.1.1 Specification Jakarta Persistence API 3.1.0 : Moved to jakarta namespace. Changes described in Jakarta Persistence API 3.1.0 Specification Jakarta Transactions API 2.0 : Moved to jakarta namespace. Changes described in Jakarta Transactions API 2.0 Specification Jakarta WebSocket API 2.1.0 : Moved to jakarta namespace. Changes described in Jakarta WebSocket API 2.1.0 Specification Jakarta Bean Validation 3.0 : Moved to jakarta namespace. Changes described in Jakarta Bean Validation 3.0 Specification Please, read each specification carefully for incompatible changes! ",
            "title": "MicroProfile 5.0 support"
        },
        {
            "location": "/mp/guides/upgrade_3x",
            "text": " Deprecations in the following classes: Resource - old configuration approach (since 2.0) ThreadPoolSupplier - Named thread pools (since 2.4.2) More information in the following Task . ",
            "title": "Helidon Common"
        },
        {
            "location": "/mp/guides/upgrade_3x",
            "text": " Deprecations in the following classes: ContentReaders - Methods with alternatives (since 2.0) ContentTypeCharset - Class with alternative (since 2.0) ContentWriters - Methods with alternatives (since 2.0) MessageBodyReaderContext - Methods with alternatives (since 2.0) MessageBodyWriterContext - Methods with alternatives (since 2.0) ReadableByteChannelPublisher - Class with alternative (since 2.0) More information in the following Task . ",
            "title": "Media Common"
        },
        {
            "location": "/mp/guides/upgrade_3x",
            "text": " Deprecations in the following classes: MetricsSupport - 3 methods, replacing Config with metrics settings KeyPerformanceIndicatorMetricsSettings - New class in metrics API, for backward compatibility only RegistryFactory - New class in metrics API, for backward compatibility only More information in the following Task . ",
            "title": "Metrics"
        },
        {
            "location": "/mp/guides/upgrade_3x",
            "text": " Deprecations in the following class: DataPropagationProvider - clearData should use new method More information in the following Task . ",
            "title": "Common Context"
        },
        {
            "location": "/mp/guides/upgrade_3x",
            "text": " Deprecations: JavaMarshaller - removed support for JavaMarshaller More information in the following Task . ",
            "title": "GRPC core"
        },
        {
            "location": "/mp/guides/upgrade_3x",
            "text": " Deprecations in the following class: CoordinatorClient - multiple methods Headers More information in the following Task . ",
            "title": "LRA"
        },
        {
            "location": "/mp/guides/upgrade_3x",
            "text": " Deprecations in the following class: MessagingCdiExtension - Alternative methods used More information in the following Task . ",
            "title": "MP Messaging"
        },
        {
            "location": "/mp/guides/upgrade_3x",
            "text": " Deprecations in the following class: Jwt - Audience can be a list (since 2.4.0) More information in the following Task . ",
            "title": "JWT"
        },
        {
            "location": "/mp/guides/upgrade_3x",
            "text": " Deprecations in the following class: MetricUtil - multiple methods MetricsCdiExtension - multiple methods More information in the following Task . ",
            "title": "MP Metrics"
        },
        {
            "location": "/mp/guides/upgrade_3x",
            "text": " backwardCompatibleEol - set to false More information in the following Task . ",
            "title": "HTTP Signature Security Provider"
        },
        {
            "location": "/mp/guides/upgrade_3x",
            "text": " Deprecations in the following class: HelidonRestServiceSupport - method configureEndpoint(Rules) More information in the following Task . ",
            "title": "Service Common"
        },
        {
            "location": "/mp/guides/upgrade_3x",
            "text": " Static content support in WebServer - moved to a separate module. Fully removed from WebServer module. More information in the following Task . ",
            "title": "WebServer"
        },
        {
            "location": "/mp/guides/upgrade_3x",
            "text": " The custom Helidon OCI clients have been deprecated. Use the OCI Java SDK instead. If you use Helidon MP you can inject OCI SDK clients by adding the dependency io.helidon.integrations.oci.sdk:helidon-integrations-oci-sdk-cdi . See Resolving compatibility issue with OCI SDK for detailed information on how to work around this issue. The MultiPart buffered readers have been deprecated. Use the MultiPart stream readers instead. Helidon Common Deprecations in the following classes: Resource - old configuration approach (since 2.0) ThreadPoolSupplier - Named thread pools (since 2.4.2) More information in the following Task . Media Common Deprecations in the following classes: ContentReaders - Methods with alternatives (since 2.0) ContentTypeCharset - Class with alternative (since 2.0) ContentWriters - Methods with alternatives (since 2.0) MessageBodyReaderContext - Methods with alternatives (since 2.0) MessageBodyWriterContext - Methods with alternatives (since 2.0) ReadableByteChannelPublisher - Class with alternative (since 2.0) More information in the following Task . Metrics Deprecations in the following classes: MetricsSupport - 3 methods, replacing Config with metrics settings KeyPerformanceIndicatorMetricsSettings - New class in metrics API, for backward compatibility only RegistryFactory - New class in metrics API, for backward compatibility only More information in the following Task . Common Context Deprecations in the following class: DataPropagationProvider - clearData should use new method More information in the following Task . GRPC core Deprecations: JavaMarshaller - removed support for JavaMarshaller More information in the following Task . LRA Deprecations in the following class: CoordinatorClient - multiple methods Headers More information in the following Task . MP Messaging Deprecations in the following class: MessagingCdiExtension - Alternative methods used More information in the following Task . JWT Deprecations in the following class: Jwt - Audience can be a list (since 2.4.0) More information in the following Task . MP Metrics Deprecations in the following class: MetricUtil - multiple methods MetricsCdiExtension - multiple methods More information in the following Task . HTTP Signature Security Provider backwardCompatibleEol - set to false More information in the following Task . Service Common Deprecations in the following class: HelidonRestServiceSupport - method configureEndpoint(Rules) More information in the following Task . WebServer Static content support in WebServer - moved to a separate module. Fully removed from WebServer module. More information in the following Task . ",
            "title": "Deprecations"
        },
        {
            "location": "/mp/guides/upgrade_4x",
            "text": " In Helidon 4.x we have made some changes to APIs and runtime behavior. This guide will help you upgrade a Helidon MP 3.x application to 4.x. ",
            "title": "preambule"
        },
        {
            "location": "/mp/guides/upgrade_4x",
            "text": " Java 17 is no longer supported in Helidon 4. Java 21 or newer is required. Please follow the instructions in Prerequisites for proper installation. Helidon 4 no longer uses Netty. Helidon MP is now running on Helidon WebServer which is based on virtual threads technology, available in Java 21. ",
            "title": "Java 21 Runtime"
        },
        {
            "location": "/mp/guides/upgrade_4x",
            "text": " Most of the MicroProfile specifications had relatively minor changes. The exception is Metrics which had substantial changes. MicroProfile Config 3.0.3 : Incompatible changes described in MicroProfile Config 3.0.3 Specification MicroProfile Fault Tolerance 4.0.2 : Incompatible changes described in MicroProfile Fault Tolerance 4.0.2 Specification MicroProfile Health 4.0 : Incompatible changes described in MicroProfile Health 4.0 Specification MicroProfile JWT Authentication 2.1 : Incompatible changes described in MicroProfile JWT Authentication 2.1 Specification MicroProfile Metrics 5.0.1 : Incompatible changes described in MicroProfile Metrics 5.0.1 Specification MicroProfile OpenAPI 3.1 : Incompatible changes described in MicroProfile OpenAPI 3.1 Specification MicroProfile Rest Client 3.0 : Incompatible changes described in MicroProfile Rest Client 3.0 Specification MicroProfile Telemetry Tracing 1.0 : Incompatible changes described in MicroProfile Telemetry Tracing 1.0 Specification ",
            "title": "MicroProfile specifications"
        },
        {
            "location": "/mp/guides/upgrade_4x",
            "text": " CDI (Jakarta Contexts and Dependency Injection) 4.0.1 : Changes described in CDI (Jakarta Contexts and Dependency Injection) 4.0.1 Specification JAX-RS (Jakarta RESTful Web Services) 3.1.0 : Changes described in JAX-RS (Jakarta RESTful Web Services) 3.1.0 Specification JSON-B (Jakarta JSON Binding) 3.0 : Changes described in JSON-B (Jakarta JSON Binding) 3.0 Specification JSON-P (Jakarta JSON Processing) 2.1.1 : Changes described in JSON-P (Jakarta JSON Parsing) 2.1.1 Specification Jakarta Annotations 2.1.1 : Full information in Jakarta Annotations 2.1.1 Specification Jakarta Persistence API 3.1.0 : Changes described in Jakarta Persistence API 3.1.0 Specification Jakarta Transactions API 2.0 : Changes described in Jakarta Transactions API 2.0 Specification Jakarta WebSocket API 2.1.0 : Changes described in Jakarta WebSocket API 2.1.0 Specification Jakarta Bean Validation 3.0 : Changes described in Jakarta Bean Validation 3.0 Specification Please, read each specification carefully for incompatible changes! ",
            "title": "Supported Jakarta EE specifications"
        },
        {
            "location": "/mp/guides/upgrade_4x",
            "text": " Jandex group id was org.jboss.jandex and now is io.smallrye . ",
            "title": "Jandex"
        },
        {
            "location": "/mp/guides/upgrade_4x",
            "text": " Testing is now in a new package. It was: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.tests&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-tests-junit5&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; Now is: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.testing&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-testing-junit5&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; And the Java package has changed from io.helidon.microprofile.tests.junit5 to io.helidon.microprofile.testing.junit5 ",
            "title": "Testing"
        },
        {
            "location": "/mp/guides/upgrade_4x",
            "text": " Jandex Jandex group id was org.jboss.jandex and now is io.smallrye . Testing Testing is now in a new package. It was: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.tests&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-tests-junit5&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; Now is: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.testing&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-testing-junit5&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; And the Java package has changed from io.helidon.microprofile.tests.junit5 to io.helidon.microprofile.testing.junit5 ",
            "title": "Significant changes"
        },
        {
            "location": "/mp/guides/upgrade_4x",
            "text": " The Helidon console handler has changed from io.helidon.common.HelidonConsoleHandler to io.helidon.logging.jul.HelidonConsoleHandler . If you use this handler in your logging.properties you will need to update it and add the following dependency: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.logging&lt;/groupId&gt; &lt;artifactId&gt;helidon-logging-jul&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; ",
            "title": "Logging"
        },
        {
            "location": "/mp/guides/upgrade_4x",
            "text": " MicroProfile 6.0 enables MicroProfile APIs to be used together with Jakarta EE 10 Core Profile. MicroProfile specifications Most of the MicroProfile specifications had relatively minor changes. The exception is Metrics which had substantial changes. MicroProfile Config 3.0.3 : Incompatible changes described in MicroProfile Config 3.0.3 Specification MicroProfile Fault Tolerance 4.0.2 : Incompatible changes described in MicroProfile Fault Tolerance 4.0.2 Specification MicroProfile Health 4.0 : Incompatible changes described in MicroProfile Health 4.0 Specification MicroProfile JWT Authentication 2.1 : Incompatible changes described in MicroProfile JWT Authentication 2.1 Specification MicroProfile Metrics 5.0.1 : Incompatible changes described in MicroProfile Metrics 5.0.1 Specification MicroProfile OpenAPI 3.1 : Incompatible changes described in MicroProfile OpenAPI 3.1 Specification MicroProfile Rest Client 3.0 : Incompatible changes described in MicroProfile Rest Client 3.0 Specification MicroProfile Telemetry Tracing 1.0 : Incompatible changes described in MicroProfile Telemetry Tracing 1.0 Specification Supported Jakarta EE specifications CDI (Jakarta Contexts and Dependency Injection) 4.0.1 : Changes described in CDI (Jakarta Contexts and Dependency Injection) 4.0.1 Specification JAX-RS (Jakarta RESTful Web Services) 3.1.0 : Changes described in JAX-RS (Jakarta RESTful Web Services) 3.1.0 Specification JSON-B (Jakarta JSON Binding) 3.0 : Changes described in JSON-B (Jakarta JSON Binding) 3.0 Specification JSON-P (Jakarta JSON Processing) 2.1.1 : Changes described in JSON-P (Jakarta JSON Parsing) 2.1.1 Specification Jakarta Annotations 2.1.1 : Full information in Jakarta Annotations 2.1.1 Specification Jakarta Persistence API 3.1.0 : Changes described in Jakarta Persistence API 3.1.0 Specification Jakarta Transactions API 2.0 : Changes described in Jakarta Transactions API 2.0 Specification Jakarta WebSocket API 2.1.0 : Changes described in Jakarta WebSocket API 2.1.0 Specification Jakarta Bean Validation 3.0 : Changes described in Jakarta Bean Validation 3.0 Specification Please, read each specification carefully for incompatible changes! Significant changes Jandex Jandex group id was org.jboss.jandex and now is io.smallrye . Testing Testing is now in a new package. It was: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.tests&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-tests-junit5&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; Now is: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.testing&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-testing-junit5&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; And the Java package has changed from io.helidon.microprofile.tests.junit5 to io.helidon.microprofile.testing.junit5 Logging The Helidon console handler has changed from io.helidon.common.HelidonConsoleHandler to io.helidon.logging.jul.HelidonConsoleHandler . If you use this handler in your logging.properties you will need to update it and add the following dependency: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.logging&lt;/groupId&gt; &lt;artifactId&gt;helidon-logging-jul&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; ",
            "title": "MicroProfile 6.0 support"
        },
        {
            "location": "/mp/guides/upgrade_4x",
            "text": " Please proceed to Helidon MP Introduction to find more information and documentation about each module. ",
            "title": "Conclusion"
        },
        {
            "location": "/mp/health",
            "text": " Overview Maven Coordinates Usage REST Endpoints Configuration Examples Reference ",
            "title": "Contents"
        },
        {
            "location": "/mp/health",
            "text": " Microservices expose their health status primarily so external tools (for example, an orchestrator such as Kubernetes) can monitor each service and take action, such as restarting a service instance if it has failed or temporarily shunting traffic away from the instance if the service is unable to process incoming requests normally. ",
            "title": "Overview"
        },
        {
            "location": "/mp/health",
            "text": " To enable MicroProfile Health add the helidon-microprofile bundle dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.bundles&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile&lt;/artifactId&gt; &lt;/dependency&gt; MicroProfile Health is already included in the bundle. If full control over the dependencies is required, and you want to minimize the quantity of the dependencies - Helidon MicroProfile Core budnle should be used. In this case the following dependencies should be included in your project&#8217;s pom.xml : <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.bundles&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-core&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.health&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-health&lt;/artifactId&gt; &lt;/dependency&gt; To enable built-in health checks add the following dependency (or use the helidon-microprofile bundle ) <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.health&lt;/groupId&gt; &lt;artifactId&gt;helidon-health-checks&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/health",
            "text": " MicroProfile Health supports three types of health checks: Liveness checks report whether the runtime environment in which the service is running is sufficient to support the work the service performs. The environment is beyond the control of the service itself and typically cannot improve without outside intervention. If a microservice instance reports a DOWN liveness check, it should never report UP later. It will need to be stopped and a replacement instance created. Readiness checks report whether the service is currently capable of performing its work. A service that reports DOWN for its readiness cannot at the moment do its job, but at some future point it might become able to do so without requiring a restart. Startup checks indicate whether the service has started to the point where liveness and readiness checks even make sense. A service reporting DOWN for a startup check is still initializing itself and normally will report UP soon, assuming it is able to start successfully. ",
            "title": "Concepts - Liveness, Readiness, and Startup Checks"
        },
        {
            "location": "/mp/health",
            "text": " Helidon implements MicroProfile Health Specification. The spec prescribes how external tools probe a service&#8217;s health checks and how you implement health checks as part of your microservice that are specific to your service&#8217;s needs. Concepts - Liveness, Readiness, and Startup Checks MicroProfile Health supports three types of health checks: Liveness checks report whether the runtime environment in which the service is running is sufficient to support the work the service performs. The environment is beyond the control of the service itself and typically cannot improve without outside intervention. If a microservice instance reports a DOWN liveness check, it should never report UP later. It will need to be stopped and a replacement instance created. Readiness checks report whether the service is currently capable of performing its work. A service that reports DOWN for its readiness cannot at the moment do its job, but at some future point it might become able to do so without requiring a restart. Startup checks indicate whether the service has started to the point where liveness and readiness checks even make sense. A service reporting DOWN for a startup check is still initializing itself and normally will report UP soon, assuming it is able to start successfully. ",
            "title": "Usage"
        },
        {
            "location": "/mp/health",
            "text": " A MicroProfile-compliant service reports its health via known REST endpoints. Helidon MP provides these endpoints automatically as part of every MP microservice that includes health support.. External management tools (or curl or browsers) retrieve health checks using the REST endpoints in the table below which summarizes the types of health checks in MicroProfile Health. Responses from the health endpoints report 200 (OK), 204 (no content), or 503 (service unavailable) depending on the outcome of running the health checks. HTTP GET responses include JSON content showing the detailed results of all the health checks which the server executed after receiving the request. HTTP HEAD requests return only the status with no payload. Types of Health Checks Type Meaning REST endpoint Kubernetes response on failure liveness whether the runtime environment is suitable /health/live Restarts container. readiness whether the microservice is currently capable of doing its work /health/ready Diverts requests away from the instance; periodically rechecks readiness and resumes traffic once the microservice reports itself as ready. startup whether the microservice has initialized to the point where liveness and readiness checks might pass /health/started Treats the instance as still starting up; does not check liveness or readiness until the startup probe reports success or times out according to its configuration. ",
            "title": "REST Endpoints"
        },
        {
            "location": "/mp/health",
            "text": " Optional configuration options key type default value description details boolean false Whether details should be printed. By default, health only returns a io.helidon.http.Status#NO_CONTENT_204 for success, io.helidon.http.Status#SERVICE_UNAVAILABLE_503 for health down, and io.helidon.http.Status#INTERNAL_SERVER_ERROR_500 in case of error with no entity. When details are enabled, health returns io.helidon.http.Status#OK_200 for success, same codes otherwise and a JSON entity with detailed information about each health check executed. @return set to `true` to enable details endpoint string health use-system-services boolean true Whether to use services discovered by java.util.ServiceLoader. By default, all io.helidon.health.spi.HealthCheckProvider based health checks are added. @return set to `false` to disable discovery Properties may be set in application.yaml or in microprofile-config.properties , in both cases using the health prefix. For example, you can specify a custom port and root context for the root health endpoint path. However, you cannot use different ports, such as http://localhost:8080/myhealth and http://localhost:8081/myhealth/live . Likewise, you cannot use different paths, such as http://localhost:8080/health and http://localhost:8080/probe/live . The example below will change the root path. <markup lang=\"properties\" title=\"Create a file named microprofile-config.properties in the resources/META-INF directory with the following contents:\" >health.endpoint=/myhealth The endpoint setting specifies the root path for the health endpoint. ",
            "title": "Configuration options"
        },
        {
            "location": "/mp/health",
            "text": " Health checks may be configured using the following properties. The class responsible for configuration is: Type: io.helidon.webserver.observe.health.HealthObserver This is a standalone configuration type, prefix from configuration root: health This type provides the following service implementations: io.helidon.webserver.observe.spi.ObserveProvider Configuration options Optional configuration options key type default value description details boolean false Whether details should be printed. By default, health only returns a io.helidon.http.Status#NO_CONTENT_204 for success, io.helidon.http.Status#SERVICE_UNAVAILABLE_503 for health down, and io.helidon.http.Status#INTERNAL_SERVER_ERROR_500 in case of error with no entity. When details are enabled, health returns io.helidon.http.Status#OK_200 for success, same codes otherwise and a JSON entity with detailed information about each health check executed. @return set to `true` to enable details endpoint string health use-system-services boolean true Whether to use services discovered by java.util.ServiceLoader. By default, all io.helidon.health.spi.HealthCheckProvider based health checks are added. @return set to `false` to disable discovery Properties may be set in application.yaml or in microprofile-config.properties , in both cases using the health prefix. For example, you can specify a custom port and root context for the root health endpoint path. However, you cannot use different ports, such as http://localhost:8080/myhealth and http://localhost:8081/myhealth/live . Likewise, you cannot use different paths, such as http://localhost:8080/health and http://localhost:8080/probe/live . The example below will change the root path. <markup lang=\"properties\" title=\"Create a file named microprofile-config.properties in the resources/META-INF directory with the following contents:\" >health.endpoint=/myhealth The endpoint setting specifies the root path for the health endpoint. ",
            "title": "Configuration"
        },
        {
            "location": "/mp/health",
            "text": " Helidon has a set of built-in health checks that can report various conditions: deadlock detection available disk space available heap memory The following example will demonstrate how to use the built-in health checks. These examples are all executed from the root directory of your project (helidon-quickstart-mp). <markup lang=\"xml\" title=\"Include the built-in health checks dependency in your pom.xml :\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.health&lt;/groupId&gt; &lt;artifactId&gt;helidon-health-checks&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"bash\" title=\"Build the application, then run it:\" >mvn package java -jar target/helidon-quickstart-mp.jar <markup lang=\"bash\" title=\"Verify the health endpoint in a new terminal window:\" >curl http://localhost:8080/health <markup lang=\"json\" title=\"JSON response:\" >{ \"status\": \"UP\", \"checks\": [ { \"name\": \"deadlock\", \"status\": \"UP\" }, { \"name\": \"diskSpace\", \"status\": \"UP\", \"data\": { \"free\": \"325.54 GB\", \"freeBytes\": 349543358464, \"percentFree\": \"69.91%\", \"total\": \"465.63 GB\", \"totalBytes\": 499963174912 } }, { \"name\": \"heapMemory\", \"status\": \"UP\", \"data\": { \"free\": \"230.87 MB\", \"freeBytes\": 242085696, \"max\": \"3.56 GB\", \"maxBytes\": 3817865216, \"percentFree\": \"98.90%\", \"total\": \"271.00 MB\", \"totalBytes\": 284164096 } } ] } ",
            "title": "Using the Built-In Health Checks"
        },
        {
            "location": "/mp/health",
            "text": " You can create application-specific custom health checks and integrate them with Helidon using CDI. The following example shows how to add a custom liveness health check. <markup lang=\"java\" title=\"Create a new GreetLivenessCheck class with the following content:\" >@Liveness @ApplicationScoped public class GreetLivenessCheck implements HealthCheck { @Override public HealthCheckResponse call() { return HealthCheckResponse.named(\"LivenessCheck\") .up() .withData(\"time\", System.currentTimeMillis()) .build(); } } Annotation indicating this is a liveness health check. Annotation indicating this is a bean instantiated once per application (in Helidon this means just once per runtime). Build the HealthCheckResponse with status UP and the current time. <markup lang=\"bash\" title=\"Build and run the application, then verify the custom liveness health endpoint:\" >curl http://localhost:8080/health/live <markup lang=\"json\" title=\"JSON response:\" >{ \"status\": \"UP\", \"checks\": [ { \"name\": \"LivenessCheck\", \"status\": \"UP\", \"data\": { \"time\": 1566338255331 } } ] } ",
            "title": "Custom Liveness Health Checks"
        },
        {
            "location": "/mp/health",
            "text": " You can add a readiness check to indicate that the application is ready to be used. In this example, the server will wait five seconds before it becomes ready. <markup lang=\"java\" title=\"Create a new GreetReadinessCheck class with the following content:\" >@Readiness @ApplicationScoped public class GreetReadinessCheck implements HealthCheck { private final AtomicLong readyTime = new AtomicLong(0); @Override public HealthCheckResponse call() { return HealthCheckResponse.named(\"ReadinessCheck\") .status(isReady()) .withData(\"time\", readyTime.get()) .build(); } public void onStartUp( @Observes @Initialized(ApplicationScoped.class) Object init) { readyTime.set(System.currentTimeMillis()); } private boolean isReady() { return Duration.ofMillis(System.currentTimeMillis() - readyTime.get()).getSeconds() &gt;= 5; } } Annotation indicating that this is a readiness health check. Build the HealthCheckResponse with status UP after five seconds, else DOWN . Record the time at startup. Become ready after 5 seconds. <markup lang=\"bash\" title=\"Build and run the application. Issue the curl command with -v within five seconds and you will see that the application is not ready:\" >curl -v http://localhost:8080/health/ready <markup title=\"HTTP response status\" >&lt; HTTP/1.1 503 Service Unavailable The HTTP status is 503 since the application is not ready. <markup lang=\"json\" title=\"JSON response body:\" >{ \"status\": \"DOWN\", \"checks\": [ { \"name\": \"ReadinessCheck\", \"status\": \"DOWN\", \"data\": { \"time\": 1566399775700 } } ] } <markup lang=\"bash\" title=\"After five seconds you will see the application is ready:\" >curl -v http://localhost:8080/health/ready <markup title=\"HTTP response status\" >&lt; HTTP/1.1 200 OK The HTTP status is 200 indicating that the application is ready. <markup lang=\"json\" title=\"JSON response body:\" >{ \"status\": \"UP\", \"checks\": [ { \"name\": \"ReadinessCheck\", \"status\": \"UP\", \"data\": { \"time\": 1566399775700 } } ] } Full example code is available here . ",
            "title": "Custom Readiness Health Checks"
        },
        {
            "location": "/mp/health",
            "text": " You can add a startup check to indicate whether or not the application has initialized to the point that the other health checks make sense. In this example, the server will wait eight seconds before it declares itself started. <markup lang=\"java\" title=\"Create a new GreetStartedCheck class with the following content:\" >@Startup @ApplicationScoped public class GreetStartedCheck implements HealthCheck { private final AtomicLong readyTime = new AtomicLong(0); @Override public HealthCheckResponse call() { return HealthCheckResponse.named(\"StartedCheck\") .status(isStarted()) .withData(\"time\", readyTime.get()) .build(); } public void onStartUp( @Observes @Initialized(ApplicationScoped.class) Object init) { readyTime.set(System.currentTimeMillis()); } private boolean isStarted() { return Duration.ofMillis(System.currentTimeMillis() - readyTime.get()).getSeconds() &gt;= 8; } } Annotation indicating that this is a startup health check. Build the HealthCheckResponse with status UP after eight seconds, else DOWN . Record the time at startup of Helidon; the application will declare itself as started eight seconds later. Become ready after 5 seconds. <markup lang=\"bash\" title=\"Build and run the application. Issue the curl command with -v within five seconds and you will see that the application has not yet started:\" >curl -v http://localhost:8080/health/started <markup title=\"HTTP response status:\" >&lt; HTTP/1.1 503 Service Unavailable The HTTP status is 503 since the application has not started. <markup lang=\"json\" title=\"JSON response body:\" >{ \"status\": \"DOWN\", \"checks\": [ { \"name\": \"StartedCheck\", \"status\": \"DOWN\", \"data\": { \"time\": 1566399775700 } } ] } <markup lang=\"bash\" title=\"After eight seconds you will see the application has started:\" >curl -v http://localhost:8080/health/started <markup title=\"HTTP response status:\" >&lt; HTTP/1.1 200 OK The HTTP status is 200 indicating that the application is started. <markup lang=\"json\" title=\"JSON response body:\" >{ \"status\": \"UP\", \"checks\": [ { \"name\": \"StartedCheck\", \"status\": \"UP\", \"data\": { \"time\": 1566399775700 } } ] } When using the health check URLs, you can get the following health check data: liveness only - http://localhost:8080/health/live readiness only - http://localhost:8080/health/ready startup checks only - http://localhost:8080/health/started all health check data - http://localhost:8080/health <markup lang=\"bash\" title=\"Get all the health check data, including custom data:\" >curl http://localhost:8080/health <markup lang=\"json\" title=\"JSON response:\" >{ \"status\": \"UP\", \"checks\": [ { \"name\": \"LivenessCheck\", \"status\": \"UP\", \"data\": { \"time\": 1566403431536 } } ] } Full example code is available here . ",
            "title": "Custom Startup Health Checks"
        },
        {
            "location": "/mp/health",
            "text": " Generate Helidon MP Quickstart project following these instructions . Using the Built-In Health Checks Helidon has a set of built-in health checks that can report various conditions: deadlock detection available disk space available heap memory The following example will demonstrate how to use the built-in health checks. These examples are all executed from the root directory of your project (helidon-quickstart-mp). <markup lang=\"xml\" title=\"Include the built-in health checks dependency in your pom.xml :\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.health&lt;/groupId&gt; &lt;artifactId&gt;helidon-health-checks&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"bash\" title=\"Build the application, then run it:\" >mvn package java -jar target/helidon-quickstart-mp.jar <markup lang=\"bash\" title=\"Verify the health endpoint in a new terminal window:\" >curl http://localhost:8080/health <markup lang=\"json\" title=\"JSON response:\" >{ \"status\": \"UP\", \"checks\": [ { \"name\": \"deadlock\", \"status\": \"UP\" }, { \"name\": \"diskSpace\", \"status\": \"UP\", \"data\": { \"free\": \"325.54 GB\", \"freeBytes\": 349543358464, \"percentFree\": \"69.91%\", \"total\": \"465.63 GB\", \"totalBytes\": 499963174912 } }, { \"name\": \"heapMemory\", \"status\": \"UP\", \"data\": { \"free\": \"230.87 MB\", \"freeBytes\": 242085696, \"max\": \"3.56 GB\", \"maxBytes\": 3817865216, \"percentFree\": \"98.90%\", \"total\": \"271.00 MB\", \"totalBytes\": 284164096 } } ] } Custom Liveness Health Checks You can create application-specific custom health checks and integrate them with Helidon using CDI. The following example shows how to add a custom liveness health check. <markup lang=\"java\" title=\"Create a new GreetLivenessCheck class with the following content:\" >@Liveness @ApplicationScoped public class GreetLivenessCheck implements HealthCheck { @Override public HealthCheckResponse call() { return HealthCheckResponse.named(\"LivenessCheck\") .up() .withData(\"time\", System.currentTimeMillis()) .build(); } } Annotation indicating this is a liveness health check. Annotation indicating this is a bean instantiated once per application (in Helidon this means just once per runtime). Build the HealthCheckResponse with status UP and the current time. <markup lang=\"bash\" title=\"Build and run the application, then verify the custom liveness health endpoint:\" >curl http://localhost:8080/health/live <markup lang=\"json\" title=\"JSON response:\" >{ \"status\": \"UP\", \"checks\": [ { \"name\": \"LivenessCheck\", \"status\": \"UP\", \"data\": { \"time\": 1566338255331 } } ] } Custom Readiness Health Checks You can add a readiness check to indicate that the application is ready to be used. In this example, the server will wait five seconds before it becomes ready. <markup lang=\"java\" title=\"Create a new GreetReadinessCheck class with the following content:\" >@Readiness @ApplicationScoped public class GreetReadinessCheck implements HealthCheck { private final AtomicLong readyTime = new AtomicLong(0); @Override public HealthCheckResponse call() { return HealthCheckResponse.named(\"ReadinessCheck\") .status(isReady()) .withData(\"time\", readyTime.get()) .build(); } public void onStartUp( @Observes @Initialized(ApplicationScoped.class) Object init) { readyTime.set(System.currentTimeMillis()); } private boolean isReady() { return Duration.ofMillis(System.currentTimeMillis() - readyTime.get()).getSeconds() &gt;= 5; } } Annotation indicating that this is a readiness health check. Build the HealthCheckResponse with status UP after five seconds, else DOWN . Record the time at startup. Become ready after 5 seconds. <markup lang=\"bash\" title=\"Build and run the application. Issue the curl command with -v within five seconds and you will see that the application is not ready:\" >curl -v http://localhost:8080/health/ready <markup title=\"HTTP response status\" >&lt; HTTP/1.1 503 Service Unavailable The HTTP status is 503 since the application is not ready. <markup lang=\"json\" title=\"JSON response body:\" >{ \"status\": \"DOWN\", \"checks\": [ { \"name\": \"ReadinessCheck\", \"status\": \"DOWN\", \"data\": { \"time\": 1566399775700 } } ] } <markup lang=\"bash\" title=\"After five seconds you will see the application is ready:\" >curl -v http://localhost:8080/health/ready <markup title=\"HTTP response status\" >&lt; HTTP/1.1 200 OK The HTTP status is 200 indicating that the application is ready. <markup lang=\"json\" title=\"JSON response body:\" >{ \"status\": \"UP\", \"checks\": [ { \"name\": \"ReadinessCheck\", \"status\": \"UP\", \"data\": { \"time\": 1566399775700 } } ] } Full example code is available here . Custom Startup Health Checks You can add a startup check to indicate whether or not the application has initialized to the point that the other health checks make sense. In this example, the server will wait eight seconds before it declares itself started. <markup lang=\"java\" title=\"Create a new GreetStartedCheck class with the following content:\" >@Startup @ApplicationScoped public class GreetStartedCheck implements HealthCheck { private final AtomicLong readyTime = new AtomicLong(0); @Override public HealthCheckResponse call() { return HealthCheckResponse.named(\"StartedCheck\") .status(isStarted()) .withData(\"time\", readyTime.get()) .build(); } public void onStartUp( @Observes @Initialized(ApplicationScoped.class) Object init) { readyTime.set(System.currentTimeMillis()); } private boolean isStarted() { return Duration.ofMillis(System.currentTimeMillis() - readyTime.get()).getSeconds() &gt;= 8; } } Annotation indicating that this is a startup health check. Build the HealthCheckResponse with status UP after eight seconds, else DOWN . Record the time at startup of Helidon; the application will declare itself as started eight seconds later. Become ready after 5 seconds. <markup lang=\"bash\" title=\"Build and run the application. Issue the curl command with -v within five seconds and you will see that the application has not yet started:\" >curl -v http://localhost:8080/health/started <markup title=\"HTTP response status:\" >&lt; HTTP/1.1 503 Service Unavailable The HTTP status is 503 since the application has not started. <markup lang=\"json\" title=\"JSON response body:\" >{ \"status\": \"DOWN\", \"checks\": [ { \"name\": \"StartedCheck\", \"status\": \"DOWN\", \"data\": { \"time\": 1566399775700 } } ] } <markup lang=\"bash\" title=\"After eight seconds you will see the application has started:\" >curl -v http://localhost:8080/health/started <markup title=\"HTTP response status:\" >&lt; HTTP/1.1 200 OK The HTTP status is 200 indicating that the application is started. <markup lang=\"json\" title=\"JSON response body:\" >{ \"status\": \"UP\", \"checks\": [ { \"name\": \"StartedCheck\", \"status\": \"UP\", \"data\": { \"time\": 1566399775700 } } ] } When using the health check URLs, you can get the following health check data: liveness only - http://localhost:8080/health/live readiness only - http://localhost:8080/health/ready startup checks only - http://localhost:8080/health/started all health check data - http://localhost:8080/health <markup lang=\"bash\" title=\"Get all the health check data, including custom data:\" >curl http://localhost:8080/health <markup lang=\"json\" title=\"JSON response:\" >{ \"status\": \"UP\", \"checks\": [ { \"name\": \"LivenessCheck\", \"status\": \"UP\", \"data\": { \"time\": 1566403431536 } } ] } Full example code is available here . ",
            "title": "Examples"
        },
        {
            "location": "/mp/health",
            "text": " Helidon MicroProfile Health JavaDoc Helidon Built-in Checks JavaDoc MicroProfile Health Specification MicroProfile Health on GitHub ",
            "title": "Reference"
        },
        {
            "location": "/mp/integrations/hcv",
            "text": " Overview Maven Coordinates Usage Examples Local Testing References ",
            "title": "Contents"
        },
        {
            "location": "/mp/integrations/hcv",
            "text": " HashiCorp Vault is a commonly used Vault in many microservices. The APIs are REST-based and Helidon implements them using WebClient . ",
            "title": "Overview"
        },
        {
            "location": "/mp/integrations/hcv",
            "text": " To enable HashiCorp Vault add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.vault&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-vault-cdi&lt;/artifactId&gt; &lt;/dependency&gt; The following is a list of maven coordinates of all Vault modules available: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.vault.auths&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-vault-auths-token&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.vault.auths&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-vault-auths-approle&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.vault.auths&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-vault-auths-k8s&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.vault.secrets&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-vault-secrets-kv1&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.vault.secrets&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-vault-secrets-kv2&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.vault.secrets&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-vault-secrets-cubbyhole&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.vault.secrets&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-vault-secrets-transit&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.vault.secrets&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-vault-secrets-database&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.vault.sys&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-vault-sys&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/integrations/hcv",
            "text": " New secret engines and authentication methods can be implemented quite easily, as the integration is based on service providers (using ServiceLoader). This gives us (or you, as the users) the option to add new secret engines and/or authentication methods without adding a plethora of methods to the Vault class. See the following SPIs: <markup lang=\"listing\" >io.helidon.integrations.vault.spi.AuthMethodProvider io.helidon.integrations.vault.spi.SecretsEngineProvider io.helidon.integrations.vault.spi.SysProvider io.helidon.integrations.vault.spi.VaultAuth io.helidon.integrations.vault.spi.InjectionProvider ",
            "title": "Extensibility"
        },
        {
            "location": "/mp/integrations/hcv",
            "text": " Vault integration supports the following: Secret Engines : Key/Value version 2, Key/Value version 1, Cubbyhole, PKI, Transit, Database Authentication Methods : Token, Kubernetes (k8s), AppRole Other Sys Operations and Configurations Each of these features is implemented as a separate module, with the Vault class binding them together. In Helidon MP, with injection, this binding is done automatically, and you can simply inject your favorite secret engine. The following classes can be injected into any CDI bean (if appropriate module is on the classpath): Kv2Secrets - Key/Value Version 2 Secrets (versioned secrets, default) Kv1Secrets - Key/Value Version 1 Secrets (un-versioned secrets, legacy) CubbyholeSecrets - Cubbyhole secrets (token bound secrets) DbSecrets - Database secrets (for generating temporary DB credentials) PkiSecrets - PKI secrets (for generating keys and X.509 certificates) TransitSecrets - Transit operations (encryption, signatures, HMAC) AppRoleAuth - AppRole authentication method (management operations) K8sAuth - Kubernetes authentication method (management operations) TokenAuth - Token authentication method (management operations) Sys - System operations (management of Vault - enabling/disabling secret engines and authentication methods) In addition to these features, Vault itself can be authenticated as follows: Token authentication - token is configured when connecting to Vault vault.address=http://localhost:8200 vault.token=my-token AppRole authentication - AppRole ID and secret ID are configured, integration exchanges these for a temporary token that is used to connect to Vault vault.auth.app-role.role-id=app-role-id vault.auth.app-role.secret-id=app-role-secret-id K8s authentication - the k8s JWT token is discovered on current node and used to obtain a temporary token that is used to connect to Vault vault.auth.k8s.token-role=my-role The token role must be configured in Vault Extensibility New secret engines and authentication methods can be implemented quite easily, as the integration is based on service providers (using ServiceLoader). This gives us (or you, as the users) the option to add new secret engines and/or authentication methods without adding a plethora of methods to the Vault class. See the following SPIs: <markup lang=\"listing\" >io.helidon.integrations.vault.spi.AuthMethodProvider io.helidon.integrations.vault.spi.SecretsEngineProvider io.helidon.integrations.vault.spi.SysProvider io.helidon.integrations.vault.spi.VaultAuth io.helidon.integrations.vault.spi.InjectionProvider ",
            "title": "Usage"
        },
        {
            "location": "/mp/integrations/hcv",
            "text": " Cubbyhole example: <markup lang=\"java\" >@Path(\"/cubbyhole\") public class CubbyholeResource { private final CubbyholeSecrets secrets; @Inject CubbyholeResource(CubbyholeSecrets secrets) { this.secrets = secrets; } @POST @Path(\"/secrets/{path: .*}\") public Response createSecret(@PathParam(\"path\") String path, String secret) { CreateCubbyhole.Response response = secrets.create(path, Map.of(\"secret\", secret)); return Response.ok() .entity(\"Created secret on path: \" + path + \", key is \\\"secret\\\", original status: \" + response.status().code()) .build(); } @DELETE @Path(\"/secrets/{path: .*}\") public Response deleteSecret(@PathParam(\"path\") String path) { DeleteCubbyhole.Response response = secrets.delete(path); return Response.ok() .entity(\"Deleted secret on path: \" + path + \". Original status: \" + response.status().code()) .build(); } @GET @Path(\"/secrets/{path: .*}\") public Response getSecret(@PathParam(\"path\") String path) { Optional&lt;Secret&gt; secret = secrets.get(path); if (secret.isPresent()) { Secret kv1Secret = secret.get(); return Response.ok() .entity(\"Secret: \" + secret.get().values().toString()) .build(); } else { return Response.status(Response.Status.NOT_FOUND).build(); } } } Create a secret from request entity, the name of the value is {@code secret}. Delete the secret on a specified path. Get the secret on a specified path. ",
            "title": "Cubbyhole secrets"
        },
        {
            "location": "/mp/integrations/hcv",
            "text": " Key/Value version 1 secrets engine operations: <markup lang=\"java\" >@Path(\"/kv1\") public class Kv1Resource { private final Sys sys; private final Kv1Secrets secrets; @Inject Kv1Resource(Sys sys, Kv1Secrets secrets) { this.sys = sys; this.secrets = secrets; } @Path(\"/engine\") @GET public Response enableEngine() { EnableEngine.Response response = sys.enableEngine(Kv1SecretsRx.ENGINE); return Response.ok() .entity(\"Key/value version 1 secret engine is now enabled. Original status: \" + response.status().code()) .build(); } @Path(\"/engine\") @DELETE public Response disableEngine() { DisableEngine.Response response = sys.disableEngine(Kv1SecretsRx.ENGINE); return Response.ok() .entity(\"Key/value version 1 secret engine is now disabled. Original status: \" + response.status().code()) .build(); } @POST @Path(\"/secrets/{path: .*}\") public Response createSecret(@PathParam(\"path\") String path, String secret) { CreateKv&lt;1&gt;Response response = secrets.create(path, Map.of(\"secret\", secret)); return Response.ok() .entity(\"Created secret on path: \" + path + \", key is \\\"secret\\\", original status: \" + response.status().code()) .build(); } @DELETE @Path(\"/secrets/{path: .*}\") public Response deleteSecret(@PathParam(\"path\") String path) { DeleteKv&lt;1&gt;Response response = secrets.delete(path); return Response.ok() .entity(\"Deleted secret on path: \" + path + \". Original status: \" + response.status().code()) .build(); } @GET @Path(\"/secrets/{path: .*}\") public Response getSecret(@PathParam(\"path\") String path) { Optional&lt;Secret&gt; secret = secrets.get(path); if (secret.isPresent()) { Secret kv1Secret = secret.get(); return Response.ok() .entity(\"Secret: \" + secret.get().values().toString()) .build(); } else { return Response.status(Response.Status.NOT_FOUND).build(); } } } Enable the secrets engine on the default path. Disable the secrets engine on the default path. Create a secret from request entity, the name of the value is secret . Delete the secret on a specified path. Get the secret on a specified path. ",
            "title": "KV1 secrets"
        },
        {
            "location": "/mp/integrations/hcv",
            "text": " Key/Value version 2 secrets engine operations: <markup lang=\"java\" >@Path(\"/kv2\") public class Kv2Resource { private final Kv2Secrets secrets; @Inject Kv2Resource(@VaultName(\"app-role\") @VaultPath(\"custom\") Kv2Secrets secrets) { this.secrets = secrets; } @POST @Path(\"/secrets/{path: .*}\") public Response createSecret(@PathParam(\"path\") String path, String secret) { CreateKv&lt;2&gt;Response response = secrets.create(path, Map.of(\"secret\", secret)); return Response.ok() .entity(\"Created secret on path: \" + path + \", key is \\\"secret\\\", original status: \" + response.status().code()) .build(); } @DELETE @Path(\"/secrets/{path: .*}\") public Response deleteSecret(@PathParam(\"path\") String path) { DeleteAllKv&lt;2&gt;Response response = secrets.deleteAll(path); return Response.ok() .entity(\"Deleted secret on path: \" + path + \". Original status: \" + response.status().code()) .build(); } @GET @Path(\"/secrets/{path: .*}\") public Response getSecret(@PathParam(\"path\") String path) { Optional&lt;Kv2Secret&gt; secret = secrets.get(path); if (secret.isPresent()) { Kv2Secret kv2Secret = secret.get(); return Response.ok() .entity(\"Version \" + kv2Secret.metadata().version() + \", secret: \" + kv2Secret.values().toString()) .build(); } else { return Response.status(Response.Status.NOT_FOUND).build(); } } } Create a secret from request entity, the name of the value is secret . Delete the secret on a specified path. Get the secret on a specified path. ",
            "title": "KV2 secrets"
        },
        {
            "location": "/mp/integrations/hcv",
            "text": " Transit secrets engine operations: <markup lang=\"java\" >@Path(\"/transit\") public class TransitResource { private static final String ENCRYPTION_KEY = \"encryption-key\"; private static final String SIGNATURE_KEY = \"signature-key\"; private final Sys sys; private final TransitSecrets secrets; @Inject TransitResource(Sys sys, TransitSecrets secrets) { this.sys = sys; this.secrets = secrets; } @Path(\"/engine\") @GET public Response enableEngine() { EnableEngine.Response response = sys.enableEngine(TransitSecretsRx.ENGINE); return Response.ok() .entity(\"Transit secret engine is now enabled. Original status: \" + response.status().code()) .build(); } @Path(\"/engine\") @DELETE public Response disableEngine() { DisableEngine.Response response = sys.disableEngine(TransitSecretsRx.ENGINE); return Response.ok() .entity(\"Transit secret engine is now disabled. Original status: \" + response.status()) .build(); } @Path(\"/keys\") @GET public Response createKeys() { secrets.createKey(CreateKey.Request.builder() .name(ENCRYPTION_KEY)); secrets.createKey(CreateKey.Request.builder() .name(SIGNATURE_KEY) .type(\"rsa-2048\")); return Response.ok() .entity(\"Created encryption (and HMAC), and signature keys\") .build(); } @Path(\"/keys\") @DELETE public Response deleteKeys() { // we must first enable deletion of the key (by default it cannot be deleted) secrets.updateKeyConfig(UpdateKeyConfig.Request.builder() .name(ENCRYPTION_KEY) .allowDeletion(true)); secrets.updateKeyConfig(UpdateKeyConfig.Request.builder() .name(SIGNATURE_KEY) .allowDeletion(true)); secrets.deleteKey(DeleteKey.Request.create(ENCRYPTION_KEY)); secrets.deleteKey(DeleteKey.Request.create(SIGNATURE_KEY)); return Response.ok() .entity(\"Deleted encryption (and HMAC), and signature keys\") .build(); } @Path(\"/encrypt/{secret: .*}\") @GET public String encryptSecret(@PathParam(\"secret\") String secret) { return secrets.encrypt(Encrypt.Request.builder() .encryptionKeyName(ENCRYPTION_KEY) .data(Base64Value.create(secret))) .encrypted() .cipherText(); } @Path(\"/decrypt/{cipherText: .*}\") @GET public String decryptSecret(@PathParam(\"cipherText\") String cipherText) { return secrets.decrypt(Decrypt.Request.builder() .encryptionKeyName(ENCRYPTION_KEY) .cipherText(cipherText)) .decrypted() .toDecodedString(); } @Path(\"/hmac/{text}\") @GET public String hmac(@PathParam(\"text\") String text) { return secrets.hmac(Hmac.Request.builder() .hmacKeyName(ENCRYPTION_KEY) .data(Base64Value.create(text))) .hmac(); } @Path(\"/sign/{text}\") @GET public String sign(@PathParam(\"text\") String text) { return secrets.sign(Sign.Request.builder() .signatureKeyName(SIGNATURE_KEY) .data(Base64Value.create(text))) .signature(); } @Path(\"/verify/hmac/{secret}/{hmac: .*}\") @GET public String verifyHmac(@PathParam(\"secret\") String secret, @PathParam(\"hmac\") String hmac) { boolean isValid = secrets.verify(Verify.Request.builder() .digestKeyName(ENCRYPTION_KEY) .data(Base64Value.create(secret)) .hmac(hmac)) .isValid(); return (isValid ? \"HMAC Valid\" : \"HMAC Invalid\"); } @Path(\"/verify/sign/{secret}/{signature: .*}\") @GET public String verifySignature(@PathParam(\"secret\") String secret, @PathParam(\"signature\") String signature) { boolean isValid = secrets.verify(Verify.Request.builder() .digestKeyName(SIGNATURE_KEY) .data(Base64Value.create(secret)) .signature(signature)) .isValid(); return (isValid ? \"Signature Valid\" : \"Signature Invalid\"); } } Enable the secrets engine on the default path. Disable the secrets engine on the default path. Create the encrypting and signature keys. Delete the encryption and signature keys. Encrypt a secret. Decrypt a secret. Create an HMAC for text. Create a signature for text. Verify HMAC. Verify signature. ",
            "title": "Transit secrets"
        },
        {
            "location": "/mp/integrations/hcv",
            "text": " The following example shows usage of Vault to encrypt a secret using the default Vault configuration (in a JAX-RS resource): <markup lang=\"java\" >@Path(\"/transit\") class TransitResource { private final TransitSecrets secrets; @Inject TransitResource(TransitSecrets secrets) { this.secrets = secrets; } @Path(\"/encrypt/{secret: .*}\") @GET public String encrypt(@PathParam(\"secret\") String secret) { return secrets.encrypt(Encrypt.Request.builder() .encryptionKeyName(ENCRYPTION_KEY) .data(Base64Value.create(secret))) .encrypted() .cipherText(); } } Cubbyhole secrets Cubbyhole example: <markup lang=\"java\" >@Path(\"/cubbyhole\") public class CubbyholeResource { private final CubbyholeSecrets secrets; @Inject CubbyholeResource(CubbyholeSecrets secrets) { this.secrets = secrets; } @POST @Path(\"/secrets/{path: .*}\") public Response createSecret(@PathParam(\"path\") String path, String secret) { CreateCubbyhole.Response response = secrets.create(path, Map.of(\"secret\", secret)); return Response.ok() .entity(\"Created secret on path: \" + path + \", key is \\\"secret\\\", original status: \" + response.status().code()) .build(); } @DELETE @Path(\"/secrets/{path: .*}\") public Response deleteSecret(@PathParam(\"path\") String path) { DeleteCubbyhole.Response response = secrets.delete(path); return Response.ok() .entity(\"Deleted secret on path: \" + path + \". Original status: \" + response.status().code()) .build(); } @GET @Path(\"/secrets/{path: .*}\") public Response getSecret(@PathParam(\"path\") String path) { Optional&lt;Secret&gt; secret = secrets.get(path); if (secret.isPresent()) { Secret kv1Secret = secret.get(); return Response.ok() .entity(\"Secret: \" + secret.get().values().toString()) .build(); } else { return Response.status(Response.Status.NOT_FOUND).build(); } } } Create a secret from request entity, the name of the value is {@code secret}. Delete the secret on a specified path. Get the secret on a specified path. KV1 secrets Key/Value version 1 secrets engine operations: <markup lang=\"java\" >@Path(\"/kv1\") public class Kv1Resource { private final Sys sys; private final Kv1Secrets secrets; @Inject Kv1Resource(Sys sys, Kv1Secrets secrets) { this.sys = sys; this.secrets = secrets; } @Path(\"/engine\") @GET public Response enableEngine() { EnableEngine.Response response = sys.enableEngine(Kv1SecretsRx.ENGINE); return Response.ok() .entity(\"Key/value version 1 secret engine is now enabled. Original status: \" + response.status().code()) .build(); } @Path(\"/engine\") @DELETE public Response disableEngine() { DisableEngine.Response response = sys.disableEngine(Kv1SecretsRx.ENGINE); return Response.ok() .entity(\"Key/value version 1 secret engine is now disabled. Original status: \" + response.status().code()) .build(); } @POST @Path(\"/secrets/{path: .*}\") public Response createSecret(@PathParam(\"path\") String path, String secret) { CreateKv&lt;1&gt;Response response = secrets.create(path, Map.of(\"secret\", secret)); return Response.ok() .entity(\"Created secret on path: \" + path + \", key is \\\"secret\\\", original status: \" + response.status().code()) .build(); } @DELETE @Path(\"/secrets/{path: .*}\") public Response deleteSecret(@PathParam(\"path\") String path) { DeleteKv&lt;1&gt;Response response = secrets.delete(path); return Response.ok() .entity(\"Deleted secret on path: \" + path + \". Original status: \" + response.status().code()) .build(); } @GET @Path(\"/secrets/{path: .*}\") public Response getSecret(@PathParam(\"path\") String path) { Optional&lt;Secret&gt; secret = secrets.get(path); if (secret.isPresent()) { Secret kv1Secret = secret.get(); return Response.ok() .entity(\"Secret: \" + secret.get().values().toString()) .build(); } else { return Response.status(Response.Status.NOT_FOUND).build(); } } } Enable the secrets engine on the default path. Disable the secrets engine on the default path. Create a secret from request entity, the name of the value is secret . Delete the secret on a specified path. Get the secret on a specified path. KV2 secrets Key/Value version 2 secrets engine operations: <markup lang=\"java\" >@Path(\"/kv2\") public class Kv2Resource { private final Kv2Secrets secrets; @Inject Kv2Resource(@VaultName(\"app-role\") @VaultPath(\"custom\") Kv2Secrets secrets) { this.secrets = secrets; } @POST @Path(\"/secrets/{path: .*}\") public Response createSecret(@PathParam(\"path\") String path, String secret) { CreateKv&lt;2&gt;Response response = secrets.create(path, Map.of(\"secret\", secret)); return Response.ok() .entity(\"Created secret on path: \" + path + \", key is \\\"secret\\\", original status: \" + response.status().code()) .build(); } @DELETE @Path(\"/secrets/{path: .*}\") public Response deleteSecret(@PathParam(\"path\") String path) { DeleteAllKv&lt;2&gt;Response response = secrets.deleteAll(path); return Response.ok() .entity(\"Deleted secret on path: \" + path + \". Original status: \" + response.status().code()) .build(); } @GET @Path(\"/secrets/{path: .*}\") public Response getSecret(@PathParam(\"path\") String path) { Optional&lt;Kv2Secret&gt; secret = secrets.get(path); if (secret.isPresent()) { Kv2Secret kv2Secret = secret.get(); return Response.ok() .entity(\"Version \" + kv2Secret.metadata().version() + \", secret: \" + kv2Secret.values().toString()) .build(); } else { return Response.status(Response.Status.NOT_FOUND).build(); } } } Create a secret from request entity, the name of the value is secret . Delete the secret on a specified path. Get the secret on a specified path. Transit secrets Transit secrets engine operations: <markup lang=\"java\" >@Path(\"/transit\") public class TransitResource { private static final String ENCRYPTION_KEY = \"encryption-key\"; private static final String SIGNATURE_KEY = \"signature-key\"; private final Sys sys; private final TransitSecrets secrets; @Inject TransitResource(Sys sys, TransitSecrets secrets) { this.sys = sys; this.secrets = secrets; } @Path(\"/engine\") @GET public Response enableEngine() { EnableEngine.Response response = sys.enableEngine(TransitSecretsRx.ENGINE); return Response.ok() .entity(\"Transit secret engine is now enabled. Original status: \" + response.status().code()) .build(); } @Path(\"/engine\") @DELETE public Response disableEngine() { DisableEngine.Response response = sys.disableEngine(TransitSecretsRx.ENGINE); return Response.ok() .entity(\"Transit secret engine is now disabled. Original status: \" + response.status()) .build(); } @Path(\"/keys\") @GET public Response createKeys() { secrets.createKey(CreateKey.Request.builder() .name(ENCRYPTION_KEY)); secrets.createKey(CreateKey.Request.builder() .name(SIGNATURE_KEY) .type(\"rsa-2048\")); return Response.ok() .entity(\"Created encryption (and HMAC), and signature keys\") .build(); } @Path(\"/keys\") @DELETE public Response deleteKeys() { // we must first enable deletion of the key (by default it cannot be deleted) secrets.updateKeyConfig(UpdateKeyConfig.Request.builder() .name(ENCRYPTION_KEY) .allowDeletion(true)); secrets.updateKeyConfig(UpdateKeyConfig.Request.builder() .name(SIGNATURE_KEY) .allowDeletion(true)); secrets.deleteKey(DeleteKey.Request.create(ENCRYPTION_KEY)); secrets.deleteKey(DeleteKey.Request.create(SIGNATURE_KEY)); return Response.ok() .entity(\"Deleted encryption (and HMAC), and signature keys\") .build(); } @Path(\"/encrypt/{secret: .*}\") @GET public String encryptSecret(@PathParam(\"secret\") String secret) { return secrets.encrypt(Encrypt.Request.builder() .encryptionKeyName(ENCRYPTION_KEY) .data(Base64Value.create(secret))) .encrypted() .cipherText(); } @Path(\"/decrypt/{cipherText: .*}\") @GET public String decryptSecret(@PathParam(\"cipherText\") String cipherText) { return secrets.decrypt(Decrypt.Request.builder() .encryptionKeyName(ENCRYPTION_KEY) .cipherText(cipherText)) .decrypted() .toDecodedString(); } @Path(\"/hmac/{text}\") @GET public String hmac(@PathParam(\"text\") String text) { return secrets.hmac(Hmac.Request.builder() .hmacKeyName(ENCRYPTION_KEY) .data(Base64Value.create(text))) .hmac(); } @Path(\"/sign/{text}\") @GET public String sign(@PathParam(\"text\") String text) { return secrets.sign(Sign.Request.builder() .signatureKeyName(SIGNATURE_KEY) .data(Base64Value.create(text))) .signature(); } @Path(\"/verify/hmac/{secret}/{hmac: .*}\") @GET public String verifyHmac(@PathParam(\"secret\") String secret, @PathParam(\"hmac\") String hmac) { boolean isValid = secrets.verify(Verify.Request.builder() .digestKeyName(ENCRYPTION_KEY) .data(Base64Value.create(secret)) .hmac(hmac)) .isValid(); return (isValid ? \"HMAC Valid\" : \"HMAC Invalid\"); } @Path(\"/verify/sign/{secret}/{signature: .*}\") @GET public String verifySignature(@PathParam(\"secret\") String secret, @PathParam(\"signature\") String signature) { boolean isValid = secrets.verify(Verify.Request.builder() .digestKeyName(SIGNATURE_KEY) .data(Base64Value.create(secret)) .signature(signature)) .isValid(); return (isValid ? \"Signature Valid\" : \"Signature Invalid\"); } } Enable the secrets engine on the default path. Disable the secrets engine on the default path. Create the encrypting and signature keys. Delete the encryption and signature keys. Encrypt a secret. Decrypt a secret. Create an HMAC for text. Create a signature for text. Verify HMAC. Verify signature. ",
            "title": "Examples"
        },
        {
            "location": "/mp/integrations/hcv",
            "text": " Vault is available as a docker image, so to test locally, you can simply: <markup lang=\"bash\" >docker run -e VAULT_DEV_ROOT_TOKEN_ID=my-token -d --name=vault -p8200:8200 vault This will create a Vault docker image, run it in background and open it on localhost:8200 with a custom root token my-token, using name vault. This is of course only suitable for local testing, as the root token has too many rights, but it can be easily used with the examples below. ",
            "title": "Local Testing"
        },
        {
            "location": "/mp/integrations/hcv",
            "text": " Hashicorp Vault Usage Examples ",
            "title": "References"
        },
        {
            "location": "/mp/integrations/neo4j",
            "text": " Overview Maven Coordinates Usage Configuration Examples Additional Information References ",
            "title": "Contents"
        },
        {
            "location": "/mp/integrations/neo4j",
            "text": " Neo4j is a graph database management system developed by Neo4j, Inc. It is an ACID-compliant transactional database with native graph storage and processing. Neo4j is available in a GPL3-licensed open-source “community edition”. ",
            "title": "Overview"
        },
        {
            "location": "/mp/integrations/neo4j",
            "text": " To enable Neo4j add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.neo4j&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-neo4j&lt;/artifactId&gt; &lt;/dependency&gt; Check Neo4j Metrics propagation and Neo4j Health Checks for additional dependencies for Neo4j Metrics and Health Checks integration. ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/integrations/neo4j",
            "text": " The support for Neo4j is implemented in Neo4j driver level. Just add the dependency, add configuration in microprofile-config.properties file and Neo4j driver will be configured by Helidon and can be injected using CDI. First describe Neo4j connection properties: <markup lang=\"properties\" ># Neo4j settings neo4j.uri=bolt://localhost:7687 neo4j.authentication.username=neo4j neo4j.authentication.password: secret neo4j.pool.metricsEnabled: true Then just inject the driver: <markup lang=\"java\" >@Inject public MovieRepository(Driver driver) { this.driver = driver; } The driver can be used according to the Neo4j documentation . ",
            "title": "Usage"
        },
        {
            "location": "/mp/integrations/neo4j",
            "text": " /include::/home/ytakahas/git_us_top/helidon/docs/src/main/asciidoc/mp/integrations/../../config/io_helidon_integrations_neo4j_Neo4j.adoc[leveloffset=+1,tag=config] ",
            "title": "Configuration"
        },
        {
            "location": "/mp/integrations/neo4j",
            "text": " This example implements a simple Neo4j REST service using MicroProfile. For this example a working Neo4j database is required. The Neo4j Movie database is used for this example. Bring up a Neo4j instance via Docker <markup lang=\"bash\" >docker run --publish=7474:7474 --publish=7687:7687 -e 'NEO4J_AUTH=neo4j/secret' neo4j:latest Go to the Neo4j browser and play the first step of the movies graph: :play movies Now go to the pom.xml and add the following dependencies: <markup lang=\"xml\" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.neo4j&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-neo4j&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.neo4j&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-neo4j-metrics&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.neo4j&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-neo4j-health&lt;/artifactId&gt; &lt;/dependency&gt; Next add the connection configuration properties for Neo4j: <markup lang=\"properties\" ># Neo4j settings neo4j.uri=bolt://localhost:7687 neo4j.authentication.username=neo4j neo4j.authentication.password: secret neo4j.pool.metricsEnabled: true # Enable the optional MicroProfile Metrics REST.request metrics metrics.rest-request.enabled=true This includes both connection information and enables Neo4j metrics propagation. Finally, we are able to inject and use the Neo4j driver. <markup lang=\"java\" >@ApplicationScoped public class MovieRepository { private final Driver driver; @Inject public MovieRepository(Driver driver) { this.driver = driver; } public List&lt;Movie&gt; findAll() { try (var session = driver.session()) { var query = \"\" + \"match (m:Movie) \" + \"match (m) &lt;- [:DIRECTED] - (d:Person) \" + \"match (m) &lt;- [r:ACTED_IN] - (a:Person) \" + \"return m, collect(d) as directors, collect({name:a.name, roles: r.roles}) as actors\"; return session.readTransaction(tx -&gt; tx.run(query).list(r -&gt; { var movieNode = r.get(\"m\").asNode(); var directors = r.get(\"directors\").asList(v -&gt; { var personNode = v.asNode(); return new Person(personNode.get(\"born\").asInt(), personNode.get(\"name\").asString()); }); var actors = r.get(\"actors\").asList(v -&gt; { return new Actor(v.get(\"name\").asString(), v.get(\"roles\").asList(Value::asString)); }); var m = new Movie(movieNode.get(\"title\").asString(), movieNode.get(\"tagline\").asString()); m.setReleased(movieNode.get(\"released\").asInt()); m.setDirectorss(directors); m.setActors(actors); return m; })); } } } Neo4j driver constructor injection Use of Neo4j driver to extract all Movies Movies can now be returned as JSON objects: <markup lang=\"java\" >@GET @Produces(MediaType.APPLICATION_JSON) public List&lt;Movie&gt; getAllMovies() { return movieRepository.findAll(); } Now build and run with JDK17+ <markup lang=\"bash\" >mvn package java -jar target/helidon-examples-integration-neo4j-mp.jar Exercise the application: <markup lang=\"bash\" >curl -X GET http://localhost:8080/movies {. . .} # Try health and metrics curl -s -X GET http://localhost:8080/health {\"outcome\":\"UP\",... . . . # Prometheus Format curl -s -X GET http://localhost:8080/metrics # TYPE base:gc_g1_young_generation_count gauge . . . # JSON Format curl -H 'Accept: application/json' -X GET http://localhost:8080/metrics {\"base\":... . . . Full example code is available in Helidon GitHub Repository . ",
            "title": "Examples"
        },
        {
            "location": "/mp/integrations/neo4j",
            "text": " Neo4j metrics can be propagated to the user as MicroProfile metrics. This is implemented in a separate Maven module. Just add <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.neo4j&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-neo4j-metrics&lt;/artifactId&gt; &lt;/dependency&gt; Works with Neo4j Integration main dependency described in Maven Coordinates . To enable metrics in Neo4j, add the following property to microprofile-config.properties : <markup lang=\"properties\" >neo4j.pool.metricsEnabled=true By applying these two actions, Neo4j metrics will be automatically added to the output of the /metrics endpoint. ",
            "title": "Neo4j Metrics propagation"
        },
        {
            "location": "/mp/integrations/neo4j",
            "text": " If your application is highly dependent on Neo4j database, health and liveness checks are essential for this application to work correctly. MicroProfile Health checks for Neo4j are implemented in a separate Maven module: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.neo4j&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-neo4j-health&lt;/artifactId&gt; &lt;/dependency&gt; Works with Neo4j Integration main dependency described in Maven Coordinates . Health checks for Neo4j will be included in /health endpoint output. ",
            "title": "Neo4j Health Checks"
        },
        {
            "location": "/mp/integrations/neo4j",
            "text": " Neo4j Metrics propagation Neo4j metrics can be propagated to the user as MicroProfile metrics. This is implemented in a separate Maven module. Just add <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.neo4j&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-neo4j-metrics&lt;/artifactId&gt; &lt;/dependency&gt; Works with Neo4j Integration main dependency described in Maven Coordinates . To enable metrics in Neo4j, add the following property to microprofile-config.properties : <markup lang=\"properties\" >neo4j.pool.metricsEnabled=true By applying these two actions, Neo4j metrics will be automatically added to the output of the /metrics endpoint. Neo4j Health Checks If your application is highly dependent on Neo4j database, health and liveness checks are essential for this application to work correctly. MicroProfile Health checks for Neo4j are implemented in a separate Maven module: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.neo4j&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-neo4j-health&lt;/artifactId&gt; &lt;/dependency&gt; Works with Neo4j Integration main dependency described in Maven Coordinates . Health checks for Neo4j will be included in /health endpoint output. ",
            "title": "Additional Information"
        },
        {
            "location": "/mp/integrations/neo4j",
            "text": " Neo4j official website Neo4j Java developer guide ",
            "title": "References"
        },
        {
            "location": "/mp/integrations/oci",
            "text": " Overview Maven Coordinates Usage Examples References ",
            "title": "Contents"
        },
        {
            "location": "/mp/integrations/oci",
            "text": " Helidon MP OCI Integration provides easy access to Oracle Cloud Infrastructure using the OCI Java SDK.` ",
            "title": "Overview"
        },
        {
            "location": "/mp/integrations/oci",
            "text": " To enable OCI Integration add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.oci.sdk&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-oci-sdk-cdi&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/integrations/oci",
            "text": " When you inject an OCI SDK Client object, the Helidon OCI SDK extension configures and constructs the object for you. The configuration primarily consists of initializing an OCI AuthenticationDetailsProvider . By default, the extension will examine your environment and select the best AuthenticationDetailsProvider and configure it for you. This means if your environment is already set up to work with the OCI SDK or the OCI command line, then it is very likely you do not need to do any additional configuration of the extension. Just add it as a dependency, and it will self-configure. If for some reason you require full control over the OCI configuration you have that as well. For more information concerning the extension and its configuration and authentication options see the OciExtension javadocs. In particular the oci.auth-strategies property lets you control which AuthenticationDetailsProvider will be used. ",
            "title": "Configuring the Helidon OCI SDK Extension"
        },
        {
            "location": "/mp/integrations/oci",
            "text": " Since the Helidon OCI SDK extension supports injecting any OCI client from the OCI SDK, you can use it to access any OCI service supported by the OCI SDK. In addition to adding the Helidon OCI SDK Extension dependency (as described above) you will need to add dependencies for the specific ODI SDK clients you will use. You will also need to configure your environment to authenticate with OCI. It is recommended that you do this first, and verify your configuration by using the OCI CLI to access the service. ",
            "title": "Accessing OCI Services"
        },
        {
            "location": "/mp/integrations/oci",
            "text": " When added to your application Helidon OCI SDK CDI portable extension provides support for injecting Oracle Cloud Infrastructure SDK Clients in your Helidon MicroProfile application. The extension also handles authenticating with OCI by automatically picking up OCI credentials from your environment. Configuring the Helidon OCI SDK Extension When you inject an OCI SDK Client object, the Helidon OCI SDK extension configures and constructs the object for you. The configuration primarily consists of initializing an OCI AuthenticationDetailsProvider . By default, the extension will examine your environment and select the best AuthenticationDetailsProvider and configure it for you. This means if your environment is already set up to work with the OCI SDK or the OCI command line, then it is very likely you do not need to do any additional configuration of the extension. Just add it as a dependency, and it will self-configure. If for some reason you require full control over the OCI configuration you have that as well. For more information concerning the extension and its configuration and authentication options see the OciExtension javadocs. In particular the oci.auth-strategies property lets you control which AuthenticationDetailsProvider will be used. Accessing OCI Services Since the Helidon OCI SDK extension supports injecting any OCI client from the OCI SDK, you can use it to access any OCI service supported by the OCI SDK. In addition to adding the Helidon OCI SDK Extension dependency (as described above) you will need to add dependencies for the specific ODI SDK clients you will use. You will also need to configure your environment to authenticate with OCI. It is recommended that you do this first, and verify your configuration by using the OCI CLI to access the service. ",
            "title": "Usage"
        },
        {
            "location": "/mp/integrations/oci",
            "text": " Now you can inject OCI SDK Clients. <markup lang=\"java\" title=\"Field-injection example\" >@Inject private ObjectStorage client; <markup lang=\"java\" title=\"Constructor-injection example\" >public class MyClass { private final ObjectStorage client; @Inject public YourConstructor(@Named(\"orders\") ObjectStorage client) { this.client = client; } } The extension implements this injection point by creating an Object Storage client object in the singleton scope . ",
            "title": "Injecting an Object Storage Client"
        },
        {
            "location": "/mp/integrations/oci",
            "text": " Once you have injected an ObjectStorage client you can use it as described in: OCI SDK Object Storage Javadocs OCI Object Storage Overview ",
            "title": "Using the Object Storage client"
        },
        {
            "location": "/mp/integrations/oci",
            "text": " This example describes how to use Helidon OCI SDK Extension to access OCI Object Storage. As mentioned above in , you need to add a dependency on the OCI SDK Object Storage API: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;com.oracle.oci.sdk&lt;/groupId&gt; &lt;artifactId&gt;oci-java-sdk-objectstorage&lt;/artifactId&gt; &lt;/dependency&gt; Injecting an Object Storage Client Now you can inject OCI SDK Clients. <markup lang=\"java\" title=\"Field-injection example\" >@Inject private ObjectStorage client; <markup lang=\"java\" title=\"Constructor-injection example\" >public class MyClass { private final ObjectStorage client; @Inject public YourConstructor(@Named(\"orders\") ObjectStorage client) { this.client = client; } } The extension implements this injection point by creating an Object Storage client object in the singleton scope . Using the Object Storage client Once you have injected an ObjectStorage client you can use it as described in: OCI SDK Object Storage Javadocs OCI Object Storage Overview ",
            "title": "Examples"
        },
        {
            "location": "/mp/integrations/oci",
            "text": " OciExtension Javadocs OCI SDK Usage Examples ",
            "title": "References"
        },
        {
            "location": "/mp/introduction",
            "text": " Helidon MP is an Eclipse MicroProfile 6.0 runtime that allows the Jakarta EE community to run microservices in a portable way. It is designed for ease of use and provides Spring Boot like development experience with heavy usage of dependency injection and annotations. Even though Helidon MP supports Jakarta EE APIs it does not require an application server. Helidon MP applications are stand-alone Java applications running in their own JVM powered by Helidon WebServer. So you get all the benefits of a low overhead server built on Java virtual threads. ",
            "title": "Introduction"
        },
        {
            "location": "/mp/introduction",
            "text": " Specification Version Description Jakarta Bean Validation 3.0 Object level constraint declaration and validation facility Jakarta Context and Dependency Injection (CDI) 4.0.1 Declarative dependency injection and supporting services Jakarta JSON Processing (JSON-P) 2.1.1 API to parse, generate, transform, and query JSON docs Jakarta JSON Binding (JSON-B) 3.0 Binding framework for converting POJOs to/from JSON docs Jakarta RESTful Web Services (JAX-RS) 3.1.0 API to develop web services following the REST pattern Jakarta Persistence (JPA) 3.1.0 Management of persistence and object/relational mapping Jakarta Transactions (JTA) 2.0 Allows handling transactions consistent with X/Open XA-spec Jakarta WebSocket 2.1.0 API for Server and Client Endpoints for WebSocket protocol ",
            "title": "Supported Jakarta EE Specifications"
        },
        {
            "location": "/mp/introduction",
            "text": " Specification Version Description MicroProfile Config 3.0.3 A flexible configuration framework with support for multiple sources and formats MicroProfile Fault Tolerance 4.0.2 Common strategies for various system problems such as time-outs, retries, Circuit Breaker, etc. MicroProfile GraphQL 2.0 API for working with GraphQL MicroProfile Health 4.0 Health checks for automatic service restart/shutdown MicroProfile JWT Auth 2.1 Defines a compact and self-contained way for securely transmitting information between parties as a JSON object MicroProfile Long-Running Actions (LRA) 2.0 Distributed transactions for microservices following SAGA pattern MicroProfile Metrics 5.0.1 Defining and exposing telemetry data in Prometheus and JSON formats MicroProfile Open API 3.1 Annotations for documenting your application endpoints MicroProfile OpenTracing 3.0 Profile and monitor your applications across multiple services MicroProfile Reactive Messaging 3.0 Standard API for sending and receiving messages/events using streams MicroProfile Reactive Streams Operators 3.1.1 Control flow and error processing for event streams MicroProfile REST Client 3.0 Type-safe API for RESTful Web Services ",
            "title": "Supported MicroProfile Specifications"
        },
        {
            "location": "/mp/introduction",
            "text": " Component Description CORS Cross Origin Resource Sharing – API to control if and how REST resources served by their applications can be shared across origins gRPC gRPC server and client OCI SDK Full set of APIs for working with OCI services Scheduling Scheduling functionality based on Cron-utils Security A tool-chain to handle authentication, authorization and context propagation ",
            "title": "Other Components"
        },
        {
            "location": "/mp/introduction",
            "text": " In case you need to upgrade the version of Helidon, follow the Upgrade Guides . For upgrade from Helidon 1.x to 2.x: Helidon MP 2x Upgrade Guide For upgrade from Helidon 2.x to 3.x: Helidon MP 3x Upgrade Guide For upgrade from Helidon 3.x to 4.x: Helidon MP 4x Upgrade Guide ",
            "title": "Upgrade"
        },
        {
            "location": "/mp/introduction",
            "text": " Try the Helidon MP quickstart guides to get your first Helidon MP application up and running in minutes. Browse the Helidon Javadocs ",
            "title": "Next Steps"
        },
        {
            "location": "/mp/introduction/microprofile",
            "text": " Complete these tasks to get started with your MicroProfile application. ",
            "title": "preambule"
        },
        {
            "location": "/mp/introduction/microprofile",
            "text": " The Managing Dependencies page describes how you should declare dependency management for Helidon applications. Then declare the following dependency in your project: <markup lang=\"xml\" title=\"Maven Dependency for full MicroProfile\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.bundles&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile&lt;/artifactId&gt; &lt;/dependency&gt; The above dependency adds all the features available in MicroProfile. If you want to start with a smaller core set of features then you can use the core bundle instead. This bundle includes the base feature in MicroProfile (such as JAX-RS, CDI, JSON-P/B, and Config) and leaves out some of the additional features such as Metrics and Tracing. You can add those dependencies individually if you choose. <markup lang=\"xml\" title=\"Maven Dependency for MicroProfile core features only\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.bundles&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-core&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/introduction/microprofile",
            "text": " Create a JAX-RS Resource class with at least one resource method. <markup lang=\"java\" title=\"Sample JAX-RS Resource Class\" >@Path(\"/\") @RequestScoped public class HelloWorldResource { @GET @Produces(MediaType.TEXT_PLAIN) public String message() { return \"Hello World\"; } } And create a JAX-RS application. <markup lang=\"java\" title=\"Sample JAX-RS Application\" >@ApplicationScoped @ApplicationPath(\"/\") public class HelloWorldApplication extends Application { @Override public Set&lt;Class&lt;?&gt;&gt; getClasses() { return Set.of( HelloWorldResource.class ); } } Add beans.xml in src/main/resources/META-INF so the CDI implementation can pick up your classes. <markup lang=\"xml\" title=\"beans.xml\" >&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;beans/&gt; As a last step, add a main method to your application (or a dedicated Main class) to start everything up. <markup lang=\"java\" title=\"Sample JAX-RS Application\" >public static void main(String[] args) { io.helidon.microprofile.server.Main.main(args); } Run the main class. The server will start on port 7001 and serve your resources. ",
            "title": "Project files"
        },
        {
            "location": "/mp/introduction/microprofile",
            "text": " Jandex is an indexing tool for Weld (the CDI implementation used by Helidon) that helps speed up the boot time of an application. To use Jandex, configure a Maven plugin that adds the index to your JAR file and a dependency on Jandex. <markup lang=\"xml\" title=\"jandex dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.smallrye&lt;/groupId&gt; &lt;artifactId&gt;jandex&lt;/artifactId&gt; &lt;version&gt;{version.plugin.jandex}&lt;/version&gt; &lt;/dependency&gt; <markup lang=\"xml\" title=\"jandex plugin configuration\" >&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;io.smallrye&lt;/groupId&gt; &lt;artifactId&gt;jandex-maven-plugin&lt;/artifactId&gt; &lt;version&gt;3.1.2&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;make-index&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;jandex&lt;/goal&gt; &lt;/goals&gt; &lt;phase&gt;process-classes&lt;/phase&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; ",
            "title": "Adding Jandex"
        },
        {
            "location": "/mp/introduction/microprofile",
            "text": " Helidon provides a MicroProfile server implementation ( io.helidon.microprofile.server ) that encapsulates the Helidon WebServer. You can either instantiate the server directly as is done in the Helidon MP Quickstart example or use its built-in main as shown below. Maven Coordinates The Managing Dependencies page describes how you should declare dependency management for Helidon applications. Then declare the following dependency in your project: <markup lang=\"xml\" title=\"Maven Dependency for full MicroProfile\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.bundles&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile&lt;/artifactId&gt; &lt;/dependency&gt; The above dependency adds all the features available in MicroProfile. If you want to start with a smaller core set of features then you can use the core bundle instead. This bundle includes the base feature in MicroProfile (such as JAX-RS, CDI, JSON-P/B, and Config) and leaves out some of the additional features such as Metrics and Tracing. You can add those dependencies individually if you choose. <markup lang=\"xml\" title=\"Maven Dependency for MicroProfile core features only\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.bundles&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-core&lt;/artifactId&gt; &lt;/dependency&gt; Project files Create a JAX-RS Resource class with at least one resource method. <markup lang=\"java\" title=\"Sample JAX-RS Resource Class\" >@Path(\"/\") @RequestScoped public class HelloWorldResource { @GET @Produces(MediaType.TEXT_PLAIN) public String message() { return \"Hello World\"; } } And create a JAX-RS application. <markup lang=\"java\" title=\"Sample JAX-RS Application\" >@ApplicationScoped @ApplicationPath(\"/\") public class HelloWorldApplication extends Application { @Override public Set&lt;Class&lt;?&gt;&gt; getClasses() { return Set.of( HelloWorldResource.class ); } } Add beans.xml in src/main/resources/META-INF so the CDI implementation can pick up your classes. <markup lang=\"xml\" title=\"beans.xml\" >&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;beans/&gt; As a last step, add a main method to your application (or a dedicated Main class) to start everything up. <markup lang=\"java\" title=\"Sample JAX-RS Application\" >public static void main(String[] args) { io.helidon.microprofile.server.Main.main(args); } Run the main class. The server will start on port 7001 and serve your resources. Adding Jandex Jandex is an indexing tool for Weld (the CDI implementation used by Helidon) that helps speed up the boot time of an application. To use Jandex, configure a Maven plugin that adds the index to your JAR file and a dependency on Jandex. <markup lang=\"xml\" title=\"jandex dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.smallrye&lt;/groupId&gt; &lt;artifactId&gt;jandex&lt;/artifactId&gt; &lt;version&gt;{version.plugin.jandex}&lt;/version&gt; &lt;/dependency&gt; <markup lang=\"xml\" title=\"jandex plugin configuration\" >&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;io.smallrye&lt;/groupId&gt; &lt;artifactId&gt;jandex-maven-plugin&lt;/artifactId&gt; &lt;version&gt;3.1.2&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;make-index&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;jandex&lt;/goal&gt; &lt;/goals&gt; &lt;phase&gt;process-classes&lt;/phase&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; ",
            "title": "Getting Started with Helidon MicroProfile"
        },
        {
            "location": "/mp/jaxrs/application-configuration",
            "text": " Your application can use the MicroProfile Config or Helidon Config (or both). MicroProfile Config offers portability to other MicroProfile servers. Helidon Config supports a full tree structure, including repeating elements. ",
            "title": "preambule"
        },
        {
            "location": "/mp/jaxrs/application-configuration",
            "text": " You can inject values that the application can access from both MicroProfile Config and from Helidon Config. <markup lang=\"java\" title=\"Jakarta REST - inject a single config property\" >@Inject public MyResource(@ConfigProperty(name=\"app.name\") String appName) { this.applicationName = appName; } You can also inject the whole configuration instance, either io.helidon.config.Config or org.eclipse.microprofile.config.Config . <markup lang=\"java\" title=\"Jakarta REST - inject config\" >@Inject public MyResource(Config config) { this.config = config; } ",
            "title": "Configuring the Application"
        },
        {
            "location": "/mp/jaxrs/helidon-connector",
            "text": " Overview Maven Coordinates API Configuration Examples Additional Information Reference ",
            "title": "Contents"
        },
        {
            "location": "/mp/jaxrs/helidon-connector",
            "text": " Helidon uses Jersey as the Jakarta REST (JAX-RS) implementation. Jersey supports the concept of connectors which is an SPI to handle low-level HTTP connections when using the Jakarta REST Client API. Helidon provides a connector that is based on its WebClient implementation and that has a few benefits, most notably, configuration using Config and support for HTTP/2. ",
            "title": "Overview"
        },
        {
            "location": "/mp/jaxrs/helidon-connector",
            "text": " To enable Helidon Connector add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.jersey&lt;/groupId&gt; &lt;artifactId&gt;helidon-jersey-connector&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/jaxrs/helidon-connector",
            "text": " Enabling the Helidon connector is possible at creation time using Jersey&#8217;s ClientConfig instance as shown below: <markup lang=\"java\" > ClientConfig clientConfig = new ClientConfig(); clientConfig.connectorProvider(HelidonConnectorProvider.create()); // Helidon connector Client client = ClientBuilder.newClient(clientConfig); Any subsequent requests using a Client instance configured this way will defer to the Helidon connector to handle the underlying HTTP connection. ",
            "title": "API"
        },
        {
            "location": "/mp/jaxrs/helidon-connector",
            "text": " One clear advantage of using the Helidon connector, as opposed to the default one provided by Jersey, is the ability to issue HTTP/2 requests. There are three ways to enable HTTP/2: Via content negotiation from HTTP/1.1, where the initial request is HTTP/1.1 (text) and the first response is HTTP/2 (binary), assuming the negotiation is successful. Similar to (1) except that a TLS extension called ALPN is used to convey the upgrade negotiation. Naturally, this only works with secure connections, so TLS is a requirement here. Using prior knowledge, where the client simply sends an HTTP/2 request knowing a priori that the server is capable of handling it. This option always requires TLS. ",
            "title": "HTTP/2 Support"
        },
        {
            "location": "/mp/jaxrs/helidon-connector",
            "text": " The Helidon connector implementation is based on WebClient , so it can be configured using config in the same way as any other instance of that class. The config root used by the Helidon connector to initialize all instances of WebClient is rooted at jersey.connector.helidon.config . Thus, if using a properties file, use this prefix for all the properties that you want to set in the connector. For example, suppose you need to enable automatic storage for server cookies and to turn off redirects, you can add the following lines to your microprofile-config.properties file: <markup lang=\"properties\" > jersey.connector.helidon.config.cookie-manager.automatic-store-enabled=true jersey.connector.helidon.config.follow-redirects=false Alternatively, assuming the root of the WebClient configuration is located at my.webclient , this can be done programmatically when building the ClientConfig instance as follows: <markup lang=\"java\" > clientConfig.property(HelidonProperties.CONFIG, config.get(\"my.webclient\")); There are additional properties that can be set programmatically and that shall override any related property set via config. The following table lists all the properties supported by the connector, their types, scopes and default values. Property Name Type Scope Default jersey.config.client.connectTimeout Integer client 10000 (millis) jersey.config.client.readTimeout Integer client, invocation 10000 (millis) jersey.config.client.followRedirects Boolean client, invocation true jersey.connector.helidon.config io.helidon.config.Config client (none) jersey.connector.helidon.tls io.helidon.common.tls.Tls client (none) jersey.connector.helidon.protocolConfigs List&lt;? extends ProtocolConfig&gt; client (none) jersey.connector.helidon.defaultHeaders Map&lt;String, String&gt; client (none) jersey.connector.helidon.protocolId String invocation (none) jersey.connector.helidon.shareConnectionCache Boolean client false HTTP/2 Support One clear advantage of using the Helidon connector, as opposed to the default one provided by Jersey, is the ability to issue HTTP/2 requests. There are three ways to enable HTTP/2: Via content negotiation from HTTP/1.1, where the initial request is HTTP/1.1 (text) and the first response is HTTP/2 (binary), assuming the negotiation is successful. Similar to (1) except that a TLS extension called ALPN is used to convey the upgrade negotiation. Naturally, this only works with secure connections, so TLS is a requirement here. Using prior knowledge, where the client simply sends an HTTP/2 request knowing a priori that the server is capable of handling it. This option always requires TLS. ",
            "title": "Configuration"
        },
        {
            "location": "/mp/jaxrs/helidon-connector",
            "text": " Without TLS, HTTP/2 negotiation is accomplished by setting a single property. In the example below, the property is set on the correspoding WebTarget , which indicates that it applies to all requests created from it. <markup lang=\"java\" > ClientConfig clientConfig = new ClientConfig(); clientConfig.connectorProvider(HelidonConnectorProvider.create()); Client client = ClientBuilder.newClient(clientConfig); WebTarget webTarget = client.target(...).path(...) .property(HelidonProperties.PROTOCOL_ID, Http2Client.PROTOCOL_ID); // HTTP/2 upgrade try (Response response = webTarget.request().get()) { // ... } Properties in the Jakarta REST Client API can be set on Client , WebTarget and Invocation and are inherited accordingly. The request invocation in the example above will include an HTTP/2 protocol upgrade request which may be granted by the server if HTTP/2 support is enabled. ",
            "title": "HTTP/2 Negotiation Without TLS"
        },
        {
            "location": "/mp/jaxrs/helidon-connector",
            "text": " ALPN is a TLS extension that can be used for HTTP/2 negotiation. The Helidon connector accepts a Tls instance to enable protocol security and also to negotiate an HTTP/2 upgrade as shown below. <markup lang=\"java\" > Tls tls = Tls.builder() .trustAll(true) .addApplicationProtocol(Http2Client.PROTOCOL_ID) // HTTP/2 upgrade .endpointIdentificationAlgorithm(Tls.ENDPOINT_IDENTIFICATION_NONE) .build(); ClientConfig clientConfig = new ClientConfig(); clientConfig.connectorProvider(HelidonConnectorProvider.create()); config.property(HelidonProperties.TLS, tls); Client client = ClientBuilder.newClient(clientConfig); WebTarget webTarget = client.target(...).path(...); try (Response response = webTarget.request().get()) { // ... } The call to addApplicationProtocol() indicates the desire to negotiate a protocol upgrade. Naturally, ALPN only works on secure connections, so TLS is always configured at the same time. ",
            "title": "HTTP/2 Negotiation With TLS/ALPN"
        },
        {
            "location": "/mp/jaxrs/helidon-connector",
            "text": " The last example shows how to enable HTTP/2 when prior knowledge of the server&#8217;s capabilities is known ahead of time. In order to force HTTP/2 for the initial request, we must provide an Http2ClientProtocolConfig instance that is properly configured for that purpose. Passing protocol configurations is a general mechanism supported by the connector; in this example, we take advantage of this mechanism to pre-configure the desired HTTP/2 support as shown next. <markup lang=\"java\" > Tls tls = Tls.builder() .trustAll(true) .endpointIdentificationAlgorithm(Tls.ENDPOINT_IDENTIFICATION_NONE) .build(); ClientConfig clientConfig = new ClientConfig(); clientConfig.connectorProvider(HelidonConnectorProvider.create()); clientConfig.property(HelidonProperties.TLS, tls); clientConfig.property(HelidonProperties.PROTOCOL_CONFIGS, List.of(Http2ClientProtocolConfig.builder() .priorKnowledge(true) // HTTP/2 knowlege .build())); Client client = ClientBuilder.newClient(clientConfig); WebTarget webTarget = client.target(...).path(...); try (Response response = webTarget.request().get()) { // ... } The property HelidonProperties.PROTOCOL_CONFIGS accepts a list of protocol configurations that are passed directly to the underlying WebClient layer. ",
            "title": "HTTP/2 Prior Knowledge"
        },
        {
            "location": "/mp/jaxrs/helidon-connector",
            "text": " HTTP/2 Negotiation Without TLS Without TLS, HTTP/2 negotiation is accomplished by setting a single property. In the example below, the property is set on the correspoding WebTarget , which indicates that it applies to all requests created from it. <markup lang=\"java\" > ClientConfig clientConfig = new ClientConfig(); clientConfig.connectorProvider(HelidonConnectorProvider.create()); Client client = ClientBuilder.newClient(clientConfig); WebTarget webTarget = client.target(...).path(...) .property(HelidonProperties.PROTOCOL_ID, Http2Client.PROTOCOL_ID); // HTTP/2 upgrade try (Response response = webTarget.request().get()) { // ... } Properties in the Jakarta REST Client API can be set on Client , WebTarget and Invocation and are inherited accordingly. The request invocation in the example above will include an HTTP/2 protocol upgrade request which may be granted by the server if HTTP/2 support is enabled. HTTP/2 Negotiation With TLS/ALPN ALPN is a TLS extension that can be used for HTTP/2 negotiation. The Helidon connector accepts a Tls instance to enable protocol security and also to negotiate an HTTP/2 upgrade as shown below. <markup lang=\"java\" > Tls tls = Tls.builder() .trustAll(true) .addApplicationProtocol(Http2Client.PROTOCOL_ID) // HTTP/2 upgrade .endpointIdentificationAlgorithm(Tls.ENDPOINT_IDENTIFICATION_NONE) .build(); ClientConfig clientConfig = new ClientConfig(); clientConfig.connectorProvider(HelidonConnectorProvider.create()); config.property(HelidonProperties.TLS, tls); Client client = ClientBuilder.newClient(clientConfig); WebTarget webTarget = client.target(...).path(...); try (Response response = webTarget.request().get()) { // ... } The call to addApplicationProtocol() indicates the desire to negotiate a protocol upgrade. Naturally, ALPN only works on secure connections, so TLS is always configured at the same time. HTTP/2 Prior Knowledge The last example shows how to enable HTTP/2 when prior knowledge of the server&#8217;s capabilities is known ahead of time. In order to force HTTP/2 for the initial request, we must provide an Http2ClientProtocolConfig instance that is properly configured for that purpose. Passing protocol configurations is a general mechanism supported by the connector; in this example, we take advantage of this mechanism to pre-configure the desired HTTP/2 support as shown next. <markup lang=\"java\" > Tls tls = Tls.builder() .trustAll(true) .endpointIdentificationAlgorithm(Tls.ENDPOINT_IDENTIFICATION_NONE) .build(); ClientConfig clientConfig = new ClientConfig(); clientConfig.connectorProvider(HelidonConnectorProvider.create()); clientConfig.property(HelidonProperties.TLS, tls); clientConfig.property(HelidonProperties.PROTOCOL_CONFIGS, List.of(Http2ClientProtocolConfig.builder() .priorKnowledge(true) // HTTP/2 knowlege .build())); Client client = ClientBuilder.newClient(clientConfig); WebTarget webTarget = client.target(...).path(...); try (Response response = webTarget.request().get()) { // ... } The property HelidonProperties.PROTOCOL_CONFIGS accepts a list of protocol configurations that are passed directly to the underlying WebClient layer. ",
            "title": "Examples"
        },
        {
            "location": "/mp/jaxrs/helidon-connector",
            "text": " For additional information, see the Jakarta REST Javadocs . ",
            "title": "Additional Information"
        },
        {
            "location": "/mp/jaxrs/helidon-connector",
            "text": " Jakarta REST Client Specification Jersey User Guide ",
            "title": "Reference"
        },
        {
            "location": "/mp/jaxrs/jaxrs-applications",
            "text": " The Jakarta REST specification (formerly JAX-RS) defines the notion of an Application subclass whose methods return resource and provider classes, singletons and properties. This is the mechanism developers can use to define what comprises a REST application. Unless otherwise stated by the runtime environment in which the application runs, every REST application must include exactly one Application subclass. Helidon provides an extension to Jakarta REST in which 0 or more Application subclasses are allowed. If no Application subclasses are provided, then a so-called synthetic subclass will be created automatically. This synthetic subclass shall include all resource and provider classes discovered by Helidon. Most Helidon applications should simply rely on this mechanism in accordance to convention over configuration practices. ",
            "title": "Jakarta REST Applications"
        },
        {
            "location": "/mp/jaxrs/jaxrs-applications",
            "text": " CDI scanning is controlled by the bean-discovery-mode attribute in beans.xml files &mdash; the default value for this attribute is annotated . In the default mode, CDI scans for beans decorated by bean-defining annotations such as @ApplicationScoped , @RequestScoped , etc. With the help of CDI, Helidon looks for REST Application subclasses in your Helidon application. If none are found, a synthetic application will be created by gathering all resources and providers found during the discovery phase. If an Application subclass has no bean-defining annotations, and bean discovery is set to the default annotated value, it will be ignored. The discovery phase is carried out as follows (in no particular order): Collect all beans that extend Application Collect all beans annotated with @Path Collect all beans annotated with @Provider If no Application subclasses are found, create a synthetic Application subclass that includes all beans gathered in steps (2) and (3) and set the application path to be \"/\" &mdash;this is the path normally defined using the @ApplicationPath annotation. If one or more Application subclasses are found, call the getClasses and getSingletons methods in each subclass using the collections in steps (2) and (3) only as defaults, i.e. if these methods both return empty sets. Helidon treats @Path and @Provided as bean-defining annotations but, as stated above, Application subclasses may require additional annotations depending on the discovery mode. ",
            "title": "Discovery of REST Beans"
        },
        {
            "location": "/mp/jaxrs/jaxrs-applications",
            "text": " Jakarta REST provides access to the Application subclass instance via injection using @Context . This form of access is still supported in Helidon but this is not enough if two or more subclasses are present. Given that support for two or more Application subclasses is a Helidon extension, a new mechanism is provided via the ServerRequest 's context object as shown next. <markup lang=\"java\" >import io.helidon.webserver.ServerRequest; @Path(\"myresource\") public class MyResource { @GET public void get(@Context ServerRequest serverRequest) { Application app = serverRequest.context().get(Application.class).get(); } } This approach effectively moves the scope of Application subclass instances to request scope in order to access the correct subclass for the resource method being executed. ",
            "title": "Access to Application Instances"
        },
        {
            "location": "/mp/jaxrs/jaxrs-applications",
            "text": " The Oracle implementation of Jakarta REST, known as Jersey, does not currently provide support for multiple Application subclasses. As a result, it creates a single internal injection manager for your entire application, but this is insufficient when multiple Application subclasses are present. Helidon creates a separate injection manager for each Application subclass, and a single parent injection manager for your application. Each Application subclass injection manager delegates to the parent injection manager. Due to an implementation strategy in Jersey, ParamConverterProvider 's must be registered in the parent manager for proper registration and initialization. Thus, providers of this type will be shared and accessible by all Application subclasses, even if your code tries to limit their access. This is likely to change in future versions of Jersey/Helidon and does not typically impact how your application runs. ",
            "title": "Injection Managers in Helidon"
        },
        {
            "location": "/mp/jaxrs/jaxrs-client",
            "text": " Overview Maven Coordinates API Configuration Examples Additional Information Reference ",
            "title": "Contents"
        },
        {
            "location": "/mp/jaxrs/jaxrs-client",
            "text": " The Jakarta REST Client defines a programmatic API to access REST resources. This API sits at a higher level than traditional HTTP client APIs and provides full integration with server-side API concepts like providers. It differs from the Rest Client API in that it does not support annotations or proxies, but instead uses builders and a fluent API to create and execute requests. ",
            "title": "Overview"
        },
        {
            "location": "/mp/jaxrs/jaxrs-client",
            "text": " To enable Jakarta REST Client add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.jersey&lt;/groupId&gt; &lt;artifactId&gt;helidon-jersey-client&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/jaxrs/jaxrs-client",
            "text": " Bootstrapping the API is done by obtaining an instance of Client . A single instance of this class can be used to create multiple service requests that share the same basic configuration, e.g., the same set of providers . More precisely, from a Client we can create multiple WebTarget s, and in turn, from each WebTarget we can create multiple Invocation s. <markup lang=\"java\" >Client client = ClientBuilder.newClient(); Response res = client .target(\"http://localhost:8080/greet\") .request(\"text/plain\") .get(); In the snippet above, the call to target returns a WebTarget , and the call to request returns an Invocation.Builder ; finally, the call to get returns the Response that results from accessing the remote resource. Given that this API is fully integrated with message body readers and writers, it is possible to request the response body be provided after conversion to a Java type&#8201;&#8212;&#8201;such as a String in the example below. <markup lang=\"java\" >Client client = ClientBuilder.newClient(); String res = client .target(\"http://localhost:8080/greet\") .request(\"text/plain\") .get(String.class); Alternatively, there are also methods in Response that can trigger similar conversions. Configuration can be specified at the Client or WebTarget level, as both types implement Configurable&lt;T&gt; . This enables common configuration to be inherited by a WebTarget created from a Client instance. In either case, several register methods can be used to configure providers such as filters and exception mappers. <markup lang=\"java\" >Client client = ClientBuilder.newClient(); client.register(GreetFilter.class); String res = client .target(\"http://localhost:8080/greet\") .register(GreetExceptionMapper.class) .request(\"text/plain\") .get(String.class); The example above shows registration of GreetFilter.class for all targets and registration of GreetExceptionMapper.class for just one of them. The same logic applies to other types of configuration such as properties and features. The Jakarta REST Client API has support for asynchronous invocations. Accessing a resource asynchronously prevents the calling thread from blocking for the duration of the call. By default, all invocations are synchronous but can be turned into either asynchronous or reactive calls by simply inserting the corresponding fluent method call during the creation phase. Using Future : <markup lang=\"java\" >Client client = ClientBuilder.newClient(); Future&lt;String&gt; res = client .target(\"http://localhost:8080/greet\") .request(\"text/plain\") .async() // now asynchronous .get(String.class); Or using a more modern, reactive style: <markup lang=\"java\" >Client client = ClientBuilder.newClient(); CompletionStage&lt;String&gt; res = client .target(\"http://localhost:8080/greet\") .request(\"text/plain\") .rx() // now reactive .get(String.class); In either case, the implementation will ensure the calling thread is not blocked and that the result from the invocation is available upon request or via a callback mechanism. ",
            "title": "API"
        },
        {
            "location": "/mp/jaxrs/jaxrs-client",
            "text": " Configuration for this API is all done programmatically as shown in the previous sections. ",
            "title": "Configuration"
        },
        {
            "location": "/mp/jaxrs/jaxrs-client",
            "text": " See for same simple examples. For additional information, refer to the Jakarta REST Client Specification . ",
            "title": "Examples"
        },
        {
            "location": "/mp/jaxrs/jaxrs-client",
            "text": " For additional information, see the Jakarta REST Javadocs . ",
            "title": "Additional Information"
        },
        {
            "location": "/mp/jaxrs/jaxrs-client",
            "text": " Jakarta REST Client Specification ",
            "title": "Reference"
        },
        {
            "location": "/mp/jwt",
            "text": " Overview Maven Coordinates Usage API Configuration Examples Additional Information Reference ",
            "title": "Contents"
        },
        {
            "location": "/mp/jwt",
            "text": " JSON Web Tokens (JWT) are an open, industry standard (RFC 7519) method for representing claims securely between two parties. JSON Web Token defines a compact and self-contained way for securely transmitting information between parties as a JSON object. With JWT Auth you can integrate security features such as single sign on into your Helidon MP applications. ",
            "title": "Overview"
        },
        {
            "location": "/mp/jwt",
            "text": " To enable JWT Authentication either add a dependency on the helidon-microprofile bundle or add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.jwt&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-jwt-auth&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/jwt",
            "text": " The main configuration point for JWT Auth is a JAX-RS Application class. As this class is discovered using CDI, it must have a bean defining annotation. Minimal required setup is done using @LoginConfig(authMethod = \"MP-JWT\") : <markup lang=\"java\" >@LoginConfig(authMethod = \"MP-JWT\") @ApplicationScoped public class ProtectedApplication extends Application{ } ",
            "title": "Usage"
        },
        {
            "location": "/mp/jwt",
            "text": " The following interfaces and annotations are used to work with JWT in Helidon MP: JsonWebToken - an interface used in CDI beans (@RequestScoped) dependency injection to obtain the JWT of the currently executing caller. @Claim - an annotation used by CDI bean (@RequestScoped) dependency injection to obtain individual claims from the caller’s JWT. ClaimValue - a proxy interface used with @Claim annotation to оbtain the value of a claim by calling getValue() . ",
            "title": "API"
        },
        {
            "location": "/mp/jwt",
            "text": " MicroProfile configuration options: key type default value description mp.jwt.verify.publickey string &#160; The property allows the Public Verification Key text itself to be supplied as a string. mp.jwt.verify.publickey.location string &#160; The property allows for an external or internal location of Public Verification Key to be specified. The value may be a relative path or a URL. mp.jwt.verify.publickey.algorithm string &#160; The configuration property allows for specifying which Public Key Signature Algorithm is supported by the MP JWT endpoint. This property can be set to either RS256 or ES256 . Default value is RS256 . Support for the other asymmetric signature algorithms such as RS512 , ES512 and others is optional. mp.jwt.verify.issuer string &#160; Configuration key for expected issuer of incoming tokens. mp.jwt.verify.audiences string &#160; Configuration key for expected audiences of incoming tokens. mp.jwt.verify.token.age int &#160; Max number of seconds since token issue time. If this number of second accedes configured value, validation will fail. mp.jwt.verify.clock.skew int &#160; Number of seconds for the clock skew during the token age verification and expiry. mp.jwt.token.cookie string &#160; Cookie property name which is expected to contain a JWT token. mp.jwt.token.header string &#160; Header name which is expected to contain a JWT token. mp.jwt.decrypt.key.location string &#160; The property allows for an external or internal location of Private Decryption Key to be specified. The value may be a relative path or a URL. mp.jwt.decrypt.key.algorithm string &#160; The configuration property allows for specifying which key management algorithm is supported by the MP JWT endpoint. Supported algorithms are either RSA-OAEP or RSA-OAEP-256 . If no algorithm is set, both algorithms must be accepted. Helidon configuration options: key type default value description optional boolean false If set to true , failure to authenticate will return ABSTAIN result instead of FAILURE . This is an important distinction when more than one provider is used authenticate boolean true Whether to attempt authentication propagate boolean true Whether to attempt identity propagation/JWT creation principal-type string USER Whether we authenticate a user or a service (other option is SERVICE) atn-token string &#160; A group for configuring authentication of the request atn-token.verify-signature boolean true Whether to verify signature in incoming JWT. If disabled, ANY JWT will be accepted atn-token.jwt-audience string &#160; Expected audience of the JWT. If not defined, any audience is accepted (and we may accept JWT not inteded for us) atn-token.jwk.resource Resource &#160; Configuration of the JWK to obtain key(s) to validate signatures of inbound token. The JWK should contain public keys. atn-token.handler string Authorization header with `bearer ` prefix A handler configuration for inbound token - e.g. how to extract it atn-token.handler.header string &#160; Name of a header the token is expected in atn-token.handler.prefix string &#160; Prefix before the token value (optional) atn-token.handler.regexp string &#160; Regular expression to obtain the token, first matching group is used (optional) sign-token string &#160; A group for configuring outbound security sign-token.jwk.resource Resource &#160; Configuration of the JWK to use when generating tokens (follows the same rules as atn-token.jwk above). The JWK must contain private keys when using asymmetric ciphers. sign-token.jwt-issuer string &#160; When we issue a new token, this is the issuer to be placed into it (validated by target service) sign-token.outbound string &#160; A group for configuring outbound rules (based on transport, host and.or path) sign-token.outbound.*.name string &#160; A short descriptive name for configured target service(s) sign-token.outbound.*.transports string any An array of transports this outbound matches (e.g. https) sign-token.outbound.*.hosts string any An array of hosts this outbound matches, may use * as a wild-card (e.g. *.oracle.com) sign-token.outbound.*.paths string any An array of paths on the host this outbound matches, may use * as a wild-card (e.g. /some/path/*) sign-token.outbound.*.outbound-token string Authorization header with `bearer ` prefix Configuration of outbound token handler (same as atn-token.handler) sign-token.outbound.*.outbound-token.format string &#160; Java text format for generating the value of outbound token header (e.g. \"bearer %1$s\") sign-token.outbound.*.jwk-kid string &#160; If this key is defined, we are generating a new token, otherwise we propagate existing. Defines the key id of a key definition in the JWK file to use for signing the outbound token sign-token.outbound.*.jwt-kid string &#160; A key to use in the generated JWT - this is for the other service to locate the verification key in their JWK sign-token.outbound.*.jwt-audience string &#160; Audience this key is generated for (e.g. http://www.example.org/api/myService ) - validated by the other service sign-token.outbound.*.jwt-not-before-seconds string 5 Makes this key valid this amount of seconds into the past. Allows a certain time-skew for the generated token to be valid before current time (e.g. when we expect a certain misalignment of clocks) sign-token.outbound.*.jwt-validity-seconds string 1 day Token validity in seconds A configuration example in microprofile-config.properties : <markup lang=\"properties\" >mp.jwt.verify.issuer=https://{PublicIssuerDomain}/oauth2/default mp.jwt.verify.publickey.location=${mp.jwt.verify.issuer}/v1/keys ",
            "title": "Configuration options"
        },
        {
            "location": "/mp/jwt",
            "text": " Configuration options MicroProfile configuration options: key type default value description mp.jwt.verify.publickey string &#160; The property allows the Public Verification Key text itself to be supplied as a string. mp.jwt.verify.publickey.location string &#160; The property allows for an external or internal location of Public Verification Key to be specified. The value may be a relative path or a URL. mp.jwt.verify.publickey.algorithm string &#160; The configuration property allows for specifying which Public Key Signature Algorithm is supported by the MP JWT endpoint. This property can be set to either RS256 or ES256 . Default value is RS256 . Support for the other asymmetric signature algorithms such as RS512 , ES512 and others is optional. mp.jwt.verify.issuer string &#160; Configuration key for expected issuer of incoming tokens. mp.jwt.verify.audiences string &#160; Configuration key for expected audiences of incoming tokens. mp.jwt.verify.token.age int &#160; Max number of seconds since token issue time. If this number of second accedes configured value, validation will fail. mp.jwt.verify.clock.skew int &#160; Number of seconds for the clock skew during the token age verification and expiry. mp.jwt.token.cookie string &#160; Cookie property name which is expected to contain a JWT token. mp.jwt.token.header string &#160; Header name which is expected to contain a JWT token. mp.jwt.decrypt.key.location string &#160; The property allows for an external or internal location of Private Decryption Key to be specified. The value may be a relative path or a URL. mp.jwt.decrypt.key.algorithm string &#160; The configuration property allows for specifying which key management algorithm is supported by the MP JWT endpoint. Supported algorithms are either RSA-OAEP or RSA-OAEP-256 . If no algorithm is set, both algorithms must be accepted. Helidon configuration options: key type default value description optional boolean false If set to true , failure to authenticate will return ABSTAIN result instead of FAILURE . This is an important distinction when more than one provider is used authenticate boolean true Whether to attempt authentication propagate boolean true Whether to attempt identity propagation/JWT creation principal-type string USER Whether we authenticate a user or a service (other option is SERVICE) atn-token string &#160; A group for configuring authentication of the request atn-token.verify-signature boolean true Whether to verify signature in incoming JWT. If disabled, ANY JWT will be accepted atn-token.jwt-audience string &#160; Expected audience of the JWT. If not defined, any audience is accepted (and we may accept JWT not inteded for us) atn-token.jwk.resource Resource &#160; Configuration of the JWK to obtain key(s) to validate signatures of inbound token. The JWK should contain public keys. atn-token.handler string Authorization header with `bearer ` prefix A handler configuration for inbound token - e.g. how to extract it atn-token.handler.header string &#160; Name of a header the token is expected in atn-token.handler.prefix string &#160; Prefix before the token value (optional) atn-token.handler.regexp string &#160; Regular expression to obtain the token, first matching group is used (optional) sign-token string &#160; A group for configuring outbound security sign-token.jwk.resource Resource &#160; Configuration of the JWK to use when generating tokens (follows the same rules as atn-token.jwk above). The JWK must contain private keys when using asymmetric ciphers. sign-token.jwt-issuer string &#160; When we issue a new token, this is the issuer to be placed into it (validated by target service) sign-token.outbound string &#160; A group for configuring outbound rules (based on transport, host and.or path) sign-token.outbound.*.name string &#160; A short descriptive name for configured target service(s) sign-token.outbound.*.transports string any An array of transports this outbound matches (e.g. https) sign-token.outbound.*.hosts string any An array of hosts this outbound matches, may use * as a wild-card (e.g. *.oracle.com) sign-token.outbound.*.paths string any An array of paths on the host this outbound matches, may use * as a wild-card (e.g. /some/path/*) sign-token.outbound.*.outbound-token string Authorization header with `bearer ` prefix Configuration of outbound token handler (same as atn-token.handler) sign-token.outbound.*.outbound-token.format string &#160; Java text format for generating the value of outbound token header (e.g. \"bearer %1$s\") sign-token.outbound.*.jwk-kid string &#160; If this key is defined, we are generating a new token, otherwise we propagate existing. Defines the key id of a key definition in the JWK file to use for signing the outbound token sign-token.outbound.*.jwt-kid string &#160; A key to use in the generated JWT - this is for the other service to locate the verification key in their JWK sign-token.outbound.*.jwt-audience string &#160; Audience this key is generated for (e.g. http://www.example.org/api/myService ) - validated by the other service sign-token.outbound.*.jwt-not-before-seconds string 5 Makes this key valid this amount of seconds into the past. Allows a certain time-skew for the generated token to be valid before current time (e.g. when we expect a certain misalignment of clocks) sign-token.outbound.*.jwt-validity-seconds string 1 day Token validity in seconds A configuration example in microprofile-config.properties : <markup lang=\"properties\" >mp.jwt.verify.issuer=https://{PublicIssuerDomain}/oauth2/default mp.jwt.verify.publickey.location=${mp.jwt.verify.issuer}/v1/keys ",
            "title": "Configuration"
        },
        {
            "location": "/mp/jwt",
            "text": "<markup lang=\"java\" >@Path(\"/hello\") public class HelloResource { @GET @Produces(TEXT_PLAIN) public String hello(@Context SecurityContext context) { Optional&lt;Principal&gt; userPrincipal = context.userPrincipal(); return \"Hello, \" + userPrincipal.get().getName() + \"!\"; } } Do not forget to annotate the HelloApplication class to enable JWT: <markup lang=\"java\" >@LoginConfig(authMethod = \"MP-JWT\") @ApplicationScoped public class HelloApplication extends Application { @Override public Set&lt;Class&lt;?&gt;&gt; getClasses() { return Set.of(HelloResource.class); } } Add the following configuration in microprofile-config.properties : <markup lang=\"properties\" >mp.jwt.verify.issuer=https://{IssuerPublicDomain}/oauth2/default mp.jwt.verify.publickey.location=${mp.jwt.verify.issuer}/v1/keys Obtain the Security Token from external issuer: <markup lang=\"bash\" >TOKEN=sdf4dDSWFcswdsffDSasEgv... Run the application and execute an http request against it: <markup lang=\"bash\" >curl -X GET -I -H \"Authorization: Bearer $TOKEN\" http://localhost:8080/hello The result should be: <markup lang=\"bash\" >HTTP/1.1 200 OK Date: 08.06.2022 10:33:47 EEST connection: keep-alive content-length: 28 Hello, secure@helidon.io! which means that the request successfully passed authentication. ",
            "title": "Examples"
        },
        {
            "location": "/mp/jwt",
            "text": " Learn more about JWT authentication at: Eclipse MicroProfile Interoperable JWT RBAC ",
            "title": "Additional Information"
        },
        {
            "location": "/mp/jwt",
            "text": " MicroProfile JWT Auth Spec MicroProfile JWT Auth GitHub Repository ",
            "title": "Reference"
        },
        {
            "location": "/mp/lra",
            "text": " Overview Maven Coordinates Usage API Configuration Examples Additional Information Coordinator Helidon LRA Coordinator Narayana Reference ",
            "title": "Contents"
        },
        {
            "location": "/mp/lra",
            "text": " Distributed transactions for microservices are known as SAGA design patterns and are defined by the MicroProfile Long Running Actions specification . Unlike well known XA protocol, LRA is asynchronous and therefore much more scalable. Every LRA JAX-RS resource ( participant ) defines endpoints to be invoked when transaction needs to be completed or compensated . ",
            "title": "Overview"
        },
        {
            "location": "/mp/lra",
            "text": " To enable Long Running Actions add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.lra&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-lra&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Support for Narayana coordinator --&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.lra&lt;/groupId&gt; &lt;artifactId&gt;helidon-lra-coordinator-narayana-client&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/lra",
            "text": " The LRA transactions need to be coordinated over REST API by the LRA coordinator. Coordinator keeps track of all transactions and calls the @Compensate or @Complete endpoints for all participants involved in the particular transaction. LRA transaction is first started, then joined by participant . The participant reports the successful finish of the transaction by calling it complete. The coordinator then calls the JAX-RS complete endpoint that was registered during the join of each participant . As the completed or compensated participants don&#8217;t have to be on same instance, the whole architecture is highly scalable. If an error occurs during the LRA transaction, the participant reports a cancellation of LRA to the coordinator. Coordinator calls compensate on all the joined participants. When a participant joins the LRA with timeout defined @LRA(value = LRA.Type.REQUIRES_NEW, timeLimit = 5, timeUnit = ChronoUnit.MINUTES) , the coordinator compensates if the timeout occurred before the close is reported by the participants. ",
            "title": "Usage"
        },
        {
            "location": "/mp/lra",
            "text": " The Participant, or Compensator, is an LRA resource with at least one of the JAX-RS(or non-JAX-RS) methods annotated with @Compensate or @AfterLRA . ",
            "title": "Participant"
        },
        {
            "location": "/mp/lra",
            "text": " javadoc Marks JAX-RS method which should run in LRA context and needs to be accompanied by at least minimal set of mandatory participant methods( Compensate or AfterLRA ). LRA options: value REQUIRED join incoming LRA or create and join new REQUIRES_NEW create and join new LRA MANDATORY join incoming LRA or fail SUPPORTS join incoming LRA or continue outside LRA context NOT_SUPPORTED always continue outside LRA context NEVER Fail with 412 if executed in LRA context NESTED create and join new LRA nested in the incoming LRA context timeLimit max time limit before LRA gets cancelled automatically by coordinator timeUnit time unit if the timeLimit value end when false LRA is not closed after successful method execution cancelOn which HTTP response codes of the method causes LRA to cancel cancelOnFamily which family of HTTP response codes causes LRA to cancel Method parameters: Header LRA_HTTP_CONTEXT_HEADER - ID of the LRA transaction <markup lang=\"java\" >@PUT @LRA(LRA.Type.REQUIRES_NEW, timeLimit = 500, timeUnit = ChronoUnit.MILLIS) @Path(\"start-example\") public Response startLra(@HeaderParam(LRA_HTTP_CONTEXT_HEADER) URI lraId, String data) ",
            "title": "@LRA"
        },
        {
            "location": "/mp/lra",
            "text": " Header LRA_HTTP_CONTEXT_HEADER - ID of the LRA transaction Header LRA_HTTP_PARENT_CONTEXT_HEADER - parent LRA ID in case of nested LRA <markup lang=\"java\" >@PUT @Path(\"/compensate\") @Compensate public Response compensateWork(@HeaderParam(LRA_HTTP_CONTEXT_HEADER) URI lraId, @HeaderParam(LRA_HTTP_PARENT_CONTEXT_HEADER) URI parent){ return LRAResponse.compensated(); } ",
            "title": "JAX-RS variant with supported LRA context values:"
        },
        {
            "location": "/mp/lra",
            "text": " URI with LRA ID <markup lang=\"java\" >@Compensate public void compensate(URI lraId) ",
            "title": "Non JAX-RS variant with supported LRA context values:"
        },
        {
            "location": "/mp/lra",
            "text": " javadoc Expected to be called by LRA coordinator only! Compensate method is called by a coordinator when LRA is cancelled, usually by error during execution of method body of @LRA annotated method . If the method responds with 500 or 202, coordinator will eventually try the call again. If participant has @Status annotated method , coordinator retrieves the status to find out if retry should be done. JAX-RS variant with supported LRA context values: Header LRA_HTTP_CONTEXT_HEADER - ID of the LRA transaction Header LRA_HTTP_PARENT_CONTEXT_HEADER - parent LRA ID in case of nested LRA <markup lang=\"java\" >@PUT @Path(\"/compensate\") @Compensate public Response compensateWork(@HeaderParam(LRA_HTTP_CONTEXT_HEADER) URI lraId, @HeaderParam(LRA_HTTP_PARENT_CONTEXT_HEADER) URI parent){ return LRAResponse.compensated(); } Non JAX-RS variant with supported LRA context values: URI with LRA ID <markup lang=\"java\" >@Compensate public void compensate(URI lraId) ",
            "title": "@Compensate"
        },
        {
            "location": "/mp/lra",
            "text": " Header LRA_HTTP_CONTEXT_HEADER - ID of the LRA transaction Header LRA_HTTP_PARENT_CONTEXT_HEADER - parent LRA ID in case of nested LRA <markup lang=\"java\" >@PUT @Path(\"/complete\") @Complete public Response complete(@HeaderParam(LRA_HTTP_CONTEXT_HEADER) URI lraId, @HeaderParam(LRA_HTTP_PARENT_CONTEXT_HEADER) URI parentLraId) ",
            "title": "JAX-RS variant with supported LRA context values:"
        },
        {
            "location": "/mp/lra",
            "text": " URI with LRA ID <markup lang=\"java\" >@Complete public void complete(URI lraId) ",
            "title": "Non JAX-RS variant with supported LRA context values:"
        },
        {
            "location": "/mp/lra",
            "text": " javadoc Expected to be called by LRA coordinator only! Complete method is called by coordinator when LRA is successfully closed. If the method responds with 500 or 202, coordinator will eventually try the call again. If participant has @Status annotated method , coordinator retrieves the status to find out if retry should be done. JAX-RS variant with supported LRA context values: Header LRA_HTTP_CONTEXT_HEADER - ID of the LRA transaction Header LRA_HTTP_PARENT_CONTEXT_HEADER - parent LRA ID in case of nested LRA <markup lang=\"java\" >@PUT @Path(\"/complete\") @Complete public Response complete(@HeaderParam(LRA_HTTP_CONTEXT_HEADER) URI lraId, @HeaderParam(LRA_HTTP_PARENT_CONTEXT_HEADER) URI parentLraId) Non JAX-RS variant with supported LRA context values: URI with LRA ID <markup lang=\"java\" >@Complete public void complete(URI lraId) ",
            "title": "@Complete"
        },
        {
            "location": "/mp/lra",
            "text": " Header LRA_HTTP_CONTEXT_HEADER - ID of the LRA transaction Header LRA_HTTP_PARENT_CONTEXT_HEADER - parent LRA ID in case of nested LRA <markup lang=\"java\" >@DELETE @Path(\"/forget\") @Forget public Response forget(@HeaderParam(LRA_HTTP_CONTEXT_HEADER) URI lraId, @HeaderParam(LRA_HTTP_PARENT_CONTEXT_HEADER) URI parent) ",
            "title": "JAX-RS variant with supported LRA context values:"
        },
        {
            "location": "/mp/lra",
            "text": " URI with LRA ID <markup lang=\"java\" >@Forget public void forget(URI lraId) } ",
            "title": "Non JAX-RS variant with supported LRA context values:"
        },
        {
            "location": "/mp/lra",
            "text": " javadoc Expected to be called by LRA coordinator only! Complete and compensate methods can fail(500) or report that compensation/completion is in progress(202). In such case participant needs to be prepared to report its status over @Status annotated method to coordinator . When coordinator decides all the participants have finished, method annotated with @Forget is called. JAX-RS variant with supported LRA context values: Header LRA_HTTP_CONTEXT_HEADER - ID of the LRA transaction Header LRA_HTTP_PARENT_CONTEXT_HEADER - parent LRA ID in case of nested LRA <markup lang=\"java\" >@DELETE @Path(\"/forget\") @Forget public Response forget(@HeaderParam(LRA_HTTP_CONTEXT_HEADER) URI lraId, @HeaderParam(LRA_HTTP_PARENT_CONTEXT_HEADER) URI parent) Non JAX-RS variant with supported LRA context values: URI with LRA ID <markup lang=\"java\" >@Forget public void forget(URI lraId) } ",
            "title": "@Forget"
        },
        {
            "location": "/mp/lra",
            "text": " javadoc Method annotated with @Leave called with LRA context(with header LRA_HTTP_CONTEXT_HEADER ) informs coordinator that current participant is leaving the LRA. Method body is executed after leave signal is sent. As a result, participant methods complete and compensate won&#8217;t be called when the particular LRA ends. Header LRA_HTTP_CONTEXT_HEADER - ID of the LRA transaction <markup lang=\"java\" >@PUT @Path(\"/leave\") @Leave public Response leaveLRA(@HeaderParam(LRA_HTTP_CONTEXT_HEADER) URI lraIdtoLeave) ",
            "title": "@Leave"
        },
        {
            "location": "/mp/lra",
            "text": " Header LRA_HTTP_CONTEXT_HEADER - ID of the LRA transaction ParticipantStatus - Status of the participant reported to coordinator <markup lang=\"java\" >@GET @Path(\"/status\") @Status public Response reportStatus(@HeaderParam(LRA_HTTP_CONTEXT_HEADER) URI lraId) { return Response.status(ParticipantStatus.FailedToCompensate).build(); } ",
            "title": "JAX-RS variant with supported LRA context values:"
        },
        {
            "location": "/mp/lra",
            "text": " URI with LRA ID ParticipantStatus - Status of the participant reported to coordinator <markup lang=\"java\" >@Status public Response reportStatus(URI lraId){ return Response.ok(ParticipantStatus.FailedToCompensate).build(); } ",
            "title": "Non JAX-RS variant with supported LRA context values:"
        },
        {
            "location": "/mp/lra",
            "text": " javadoc Expected to be called by LRA coordinator only! If the coordinator&#8217;s call to the participant&#8217;s method fails, then it will retry the call. If the participant is not idempotent, then it may need to report its state to coordinator by declaring method annotated with @Status for reporting if previous call did change participant status. Coordinator can call it and decide if compensate or complete retry is needed. JAX-RS variant with supported LRA context values: Header LRA_HTTP_CONTEXT_HEADER - ID of the LRA transaction ParticipantStatus - Status of the participant reported to coordinator <markup lang=\"java\" >@GET @Path(\"/status\") @Status public Response reportStatus(@HeaderParam(LRA_HTTP_CONTEXT_HEADER) URI lraId) { return Response.status(ParticipantStatus.FailedToCompensate).build(); } Non JAX-RS variant with supported LRA context values: URI with LRA ID ParticipantStatus - Status of the participant reported to coordinator <markup lang=\"java\" >@Status public Response reportStatus(URI lraId){ return Response.ok(ParticipantStatus.FailedToCompensate).build(); } ",
            "title": "@Status"
        },
        {
            "location": "/mp/lra",
            "text": " Header LRA_HTTP_ENDED_CONTEXT_HEADER - ID of the finished LRA transaction Header LRA_HTTP_PARENT_CONTEXT_HEADER - parent LRA ID in case of nested LRA LRAStatus - Final status of the LRA ( Cancelled , Closed , FailedToCancel , FailedToClose ) <markup lang=\"java\" >@PUT @Path(\"/finished\") @AfterLRA public Response whenLRAFinishes(@HeaderParam(LRA_HTTP_ENDED_CONTEXT_HEADER) URI lraId, @HeaderParam(LRA_HTTP_PARENT_CONTEXT_HEADER) URI parentLraId, LRAStatus status) ",
            "title": "JAX-RS variant with supported LRA context values:"
        },
        {
            "location": "/mp/lra",
            "text": " URI with finished LRA ID LRAStatus - Final status of the LRA ( Cancelled , Closed , FailedToCancel , FailedToClose ) <markup lang=\"java\" >public void whenLRAFinishes(URI lraId, LRAStatus status) ",
            "title": "Non JAX-RS variant with supported LRA context values:"
        },
        {
            "location": "/mp/lra",
            "text": " javadoc Expected to be called by LRA coordinator only! Method annotated with @AfterLRA in the same class as the one with @LRA annotation gets invoked after particular LRA finishes. JAX-RS variant with supported LRA context values: Header LRA_HTTP_ENDED_CONTEXT_HEADER - ID of the finished LRA transaction Header LRA_HTTP_PARENT_CONTEXT_HEADER - parent LRA ID in case of nested LRA LRAStatus - Final status of the LRA ( Cancelled , Closed , FailedToCancel , FailedToClose ) <markup lang=\"java\" >@PUT @Path(\"/finished\") @AfterLRA public Response whenLRAFinishes(@HeaderParam(LRA_HTTP_ENDED_CONTEXT_HEADER) URI lraId, @HeaderParam(LRA_HTTP_PARENT_CONTEXT_HEADER) URI parentLraId, LRAStatus status) Non JAX-RS variant with supported LRA context values: URI with finished LRA ID LRAStatus - Final status of the LRA ( Cancelled , Closed , FailedToCancel , FailedToClose ) <markup lang=\"java\" >public void whenLRAFinishes(URI lraId, LRAStatus status) ",
            "title": "@AfterLRA"
        },
        {
            "location": "/mp/lra",
            "text": " Participant The Participant, or Compensator, is an LRA resource with at least one of the JAX-RS(or non-JAX-RS) methods annotated with @Compensate or @AfterLRA . @LRA javadoc Marks JAX-RS method which should run in LRA context and needs to be accompanied by at least minimal set of mandatory participant methods( Compensate or AfterLRA ). LRA options: value REQUIRED join incoming LRA or create and join new REQUIRES_NEW create and join new LRA MANDATORY join incoming LRA or fail SUPPORTS join incoming LRA or continue outside LRA context NOT_SUPPORTED always continue outside LRA context NEVER Fail with 412 if executed in LRA context NESTED create and join new LRA nested in the incoming LRA context timeLimit max time limit before LRA gets cancelled automatically by coordinator timeUnit time unit if the timeLimit value end when false LRA is not closed after successful method execution cancelOn which HTTP response codes of the method causes LRA to cancel cancelOnFamily which family of HTTP response codes causes LRA to cancel Method parameters: Header LRA_HTTP_CONTEXT_HEADER - ID of the LRA transaction <markup lang=\"java\" >@PUT @LRA(LRA.Type.REQUIRES_NEW, timeLimit = 500, timeUnit = ChronoUnit.MILLIS) @Path(\"start-example\") public Response startLra(@HeaderParam(LRA_HTTP_CONTEXT_HEADER) URI lraId, String data) @Compensate javadoc Expected to be called by LRA coordinator only! Compensate method is called by a coordinator when LRA is cancelled, usually by error during execution of method body of @LRA annotated method . If the method responds with 500 or 202, coordinator will eventually try the call again. If participant has @Status annotated method , coordinator retrieves the status to find out if retry should be done. JAX-RS variant with supported LRA context values: Header LRA_HTTP_CONTEXT_HEADER - ID of the LRA transaction Header LRA_HTTP_PARENT_CONTEXT_HEADER - parent LRA ID in case of nested LRA <markup lang=\"java\" >@PUT @Path(\"/compensate\") @Compensate public Response compensateWork(@HeaderParam(LRA_HTTP_CONTEXT_HEADER) URI lraId, @HeaderParam(LRA_HTTP_PARENT_CONTEXT_HEADER) URI parent){ return LRAResponse.compensated(); } Non JAX-RS variant with supported LRA context values: URI with LRA ID <markup lang=\"java\" >@Compensate public void compensate(URI lraId) @Complete javadoc Expected to be called by LRA coordinator only! Complete method is called by coordinator when LRA is successfully closed. If the method responds with 500 or 202, coordinator will eventually try the call again. If participant has @Status annotated method , coordinator retrieves the status to find out if retry should be done. JAX-RS variant with supported LRA context values: Header LRA_HTTP_CONTEXT_HEADER - ID of the LRA transaction Header LRA_HTTP_PARENT_CONTEXT_HEADER - parent LRA ID in case of nested LRA <markup lang=\"java\" >@PUT @Path(\"/complete\") @Complete public Response complete(@HeaderParam(LRA_HTTP_CONTEXT_HEADER) URI lraId, @HeaderParam(LRA_HTTP_PARENT_CONTEXT_HEADER) URI parentLraId) Non JAX-RS variant with supported LRA context values: URI with LRA ID <markup lang=\"java\" >@Complete public void complete(URI lraId) @Forget javadoc Expected to be called by LRA coordinator only! Complete and compensate methods can fail(500) or report that compensation/completion is in progress(202). In such case participant needs to be prepared to report its status over @Status annotated method to coordinator . When coordinator decides all the participants have finished, method annotated with @Forget is called. JAX-RS variant with supported LRA context values: Header LRA_HTTP_CONTEXT_HEADER - ID of the LRA transaction Header LRA_HTTP_PARENT_CONTEXT_HEADER - parent LRA ID in case of nested LRA <markup lang=\"java\" >@DELETE @Path(\"/forget\") @Forget public Response forget(@HeaderParam(LRA_HTTP_CONTEXT_HEADER) URI lraId, @HeaderParam(LRA_HTTP_PARENT_CONTEXT_HEADER) URI parent) Non JAX-RS variant with supported LRA context values: URI with LRA ID <markup lang=\"java\" >@Forget public void forget(URI lraId) } @Leave javadoc Method annotated with @Leave called with LRA context(with header LRA_HTTP_CONTEXT_HEADER ) informs coordinator that current participant is leaving the LRA. Method body is executed after leave signal is sent. As a result, participant methods complete and compensate won&#8217;t be called when the particular LRA ends. Header LRA_HTTP_CONTEXT_HEADER - ID of the LRA transaction <markup lang=\"java\" >@PUT @Path(\"/leave\") @Leave public Response leaveLRA(@HeaderParam(LRA_HTTP_CONTEXT_HEADER) URI lraIdtoLeave) @Status javadoc Expected to be called by LRA coordinator only! If the coordinator&#8217;s call to the participant&#8217;s method fails, then it will retry the call. If the participant is not idempotent, then it may need to report its state to coordinator by declaring method annotated with @Status for reporting if previous call did change participant status. Coordinator can call it and decide if compensate or complete retry is needed. JAX-RS variant with supported LRA context values: Header LRA_HTTP_CONTEXT_HEADER - ID of the LRA transaction ParticipantStatus - Status of the participant reported to coordinator <markup lang=\"java\" >@GET @Path(\"/status\") @Status public Response reportStatus(@HeaderParam(LRA_HTTP_CONTEXT_HEADER) URI lraId) { return Response.status(ParticipantStatus.FailedToCompensate).build(); } Non JAX-RS variant with supported LRA context values: URI with LRA ID ParticipantStatus - Status of the participant reported to coordinator <markup lang=\"java\" >@Status public Response reportStatus(URI lraId){ return Response.ok(ParticipantStatus.FailedToCompensate).build(); } @AfterLRA javadoc Expected to be called by LRA coordinator only! Method annotated with @AfterLRA in the same class as the one with @LRA annotation gets invoked after particular LRA finishes. JAX-RS variant with supported LRA context values: Header LRA_HTTP_ENDED_CONTEXT_HEADER - ID of the finished LRA transaction Header LRA_HTTP_PARENT_CONTEXT_HEADER - parent LRA ID in case of nested LRA LRAStatus - Final status of the LRA ( Cancelled , Closed , FailedToCancel , FailedToClose ) <markup lang=\"java\" >@PUT @Path(\"/finished\") @AfterLRA public Response whenLRAFinishes(@HeaderParam(LRA_HTTP_ENDED_CONTEXT_HEADER) URI lraId, @HeaderParam(LRA_HTTP_PARENT_CONTEXT_HEADER) URI parentLraId, LRAStatus status) Non JAX-RS variant with supported LRA context values: URI with finished LRA ID LRAStatus - Final status of the LRA ( Cancelled , Closed , FailedToCancel , FailedToClose ) <markup lang=\"java\" >public void whenLRAFinishes(URI lraId, LRAStatus status) ",
            "title": "API"
        },
        {
            "location": "/mp/lra",
            "text": "<markup lang=\"text\" title=\"Type\" >io.helidon.microprofile.lra Optional configuration options Key Type Default value Description mp.lra.coordinator.url string http://localhost:8070/lra-coordinator Url of coordinator. mp.lra.coordinator.propagation.active boolean &#160; Propagate LRA headers LRA_HTTP_CONTEXT_HEADER and LRA_HTTP_PARENT_CONTEXT_HEADER through non-LRA endpoints. mp.lara.participant.url string &#160; Url of the LRA enabled service overrides standard base uri, so coordinator can call load-balancer instead of the service. mp.lra.coordinator.timeout string &#160; Timeout for synchronous communication with coordinator. mp.lra.coordinator.timeout-unit string &#160; Timeout unit for synchronous communication with coordinator. <markup lang=\"yaml\" title=\"Example of LRA configuration\" >mp.lra: coordinator.url: http://localhost:8070/lra-coordinator propagation.active: true participant.url: http://coordinator.visible.host:80/awesomeapp Url of coordinator Propagate LRA headers LRA_HTTP_CONTEXT_HEADER and LRA_HTTP_PARENT_CONTEXT_HEADER through non-LRA endpoints Url of the LRA enabled service overrides standard base uri, so coordinator can call load-balancer instead of the service For more information continue to MicroProfile Long Running Actions specification . ",
            "title": "Configuration"
        },
        {
            "location": "/mp/lra",
            "text": " The following example shows how a simple LRA participant starts and joins a transaction after calling the '/start-example' resource. When startExample method finishes successfully, close is reported to coordinator and /complete-example endpoint is called by coordinator to confirm successful closure of the LRA. If an exception occurs during startExample method execution, coordinator receives cancel call and /compensate-example is called by coordinator to compensate for cancelled LRA transaction. <markup lang=\"java\" title=\"Example of simple LRA participant\" >@PUT @LRA(LRA.Type.REQUIRES_NEW) @Path(\"start-example\") public Response startExample(@HeaderParam(LRA_HTTP_CONTEXT_HEADER) URI lraId, String data) { if (data.contains(\"BOOM\")) { throw new RuntimeException(\"BOOM 💥\"); } LOGGER.info(\"Data \" + data + \" processed 🏭\"); return Response.ok().build(); } @PUT @Complete @Path(\"complete-example\") public Response completeExample(@HeaderParam(LRA_HTTP_CONTEXT_HEADER) URI lraId) { LOGGER.log(Level.INFO, \"LRA ID: {0} completed 🎉\", lraId); return LRAResponse.completed(); } @PUT @Compensate @Path(\"compensate-example\") public Response compensateExample(@HeaderParam(LRA_HTTP_CONTEXT_HEADER) URI lraId) { LOGGER.log(Level.SEVERE, \"LRA ID: {0} compensated 🦺\", lraId); return LRAResponse.compensated(); } This JAX-RS PUT method will start new LRA transactions and join it before method body gets executed LRA ID assigned by coordinator to this LRA transaction When method execution finishes exceptionally, cancel signal for this particular LRA is sent to coordinator When method execution finishes successfully, complete signal for this particular LRA is sent to coordinator Method which will be called by coordinator when LRA is completed Method which will be called by coordinator when LRA is canceled ",
            "title": "Examples"
        },
        {
            "location": "/mp/lra",
            "text": " Coordinator is a service that tracks all LRA transactions and calls the compensate REST endpoints of the participants when the LRA transaction gets cancelled or completes (in case it gets closed). In addition, participant also keeps track of timeouts, retries participant calls, and assigns LRA ids. Helidon LRA coordinator Narayana coordinator . ",
            "title": "Coordinator"
        },
        {
            "location": "/mp/lra",
            "text": " Experimental tool, usage in production is not advised. <markup lang=\"bash\" title=\"Build and run Helidon LRA coordinator\" >docker build -t helidon/lra-coordinator https://github.com/oracle/helidon.git#:lra/coordinator/server docker run --name lra-coordinator --network=\"host\" helidon/lra-coordinator Helidon LRA coordinator is compatible with Narayana clients, you need to add an additional dependency for Narayana client: <markup lang=\"xml\" title=\"Dependency needed for using Helidon LRA with Narayana compatible coordinator\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.lra&lt;/groupId&gt; &lt;artifactId&gt;helidon-lra-coordinator-narayana-client&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Helidon LRA Coordinator"
        },
        {
            "location": "/mp/lra",
            "text": " Narayana is a transaction manager supporting LRA. To use Narayana LRA coordinator with Helidon LRA client you need to add an additional dependency for Narayana client: <markup lang=\"xml\" title=\"Dependency needed for using Helidon LRA with Narayana coordinator\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.lra&lt;/groupId&gt; &lt;artifactId&gt;helidon-lra-coordinator-narayana-client&lt;/artifactId&gt; &lt;/dependency&gt; The simplest way to run Narayana LRA coordinator locally: <markup lang=\"bash\" title=\"Downloading and running Narayana LRA coordinator\" >wget https://search.maven.org/remotecontent?filepath=org/jboss/narayana/rts/lra-coordinator-quarkus/5.11.1.Final/lra-coordinator-quarkus-5.11.1.Final-runner.jar \\ -O narayana-coordinator.jar \\ &amp;&amp; java -Dquarkus.http.port=8070 -jar narayana-coordinator.jar Narayana LRA coordinator is running by default under lra-coordinator context, with port 8070 defined in the snippet above you need to configure your Helidon LRA app as follows: mp.lra.coordinator.url=http://localhost:8070/lra-coordinator ",
            "title": "Narayana"
        },
        {
            "location": "/mp/lra",
            "text": " Coordinator Coordinator is a service that tracks all LRA transactions and calls the compensate REST endpoints of the participants when the LRA transaction gets cancelled or completes (in case it gets closed). In addition, participant also keeps track of timeouts, retries participant calls, and assigns LRA ids. Helidon LRA coordinator Narayana coordinator . Helidon LRA Coordinator Experimental tool, usage in production is not advised. <markup lang=\"bash\" title=\"Build and run Helidon LRA coordinator\" >docker build -t helidon/lra-coordinator https://github.com/oracle/helidon.git#:lra/coordinator/server docker run --name lra-coordinator --network=\"host\" helidon/lra-coordinator Helidon LRA coordinator is compatible with Narayana clients, you need to add an additional dependency for Narayana client: <markup lang=\"xml\" title=\"Dependency needed for using Helidon LRA with Narayana compatible coordinator\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.lra&lt;/groupId&gt; &lt;artifactId&gt;helidon-lra-coordinator-narayana-client&lt;/artifactId&gt; &lt;/dependency&gt; Narayana Narayana is a transaction manager supporting LRA. To use Narayana LRA coordinator with Helidon LRA client you need to add an additional dependency for Narayana client: <markup lang=\"xml\" title=\"Dependency needed for using Helidon LRA with Narayana coordinator\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.lra&lt;/groupId&gt; &lt;artifactId&gt;helidon-lra-coordinator-narayana-client&lt;/artifactId&gt; &lt;/dependency&gt; The simplest way to run Narayana LRA coordinator locally: <markup lang=\"bash\" title=\"Downloading and running Narayana LRA coordinator\" >wget https://search.maven.org/remotecontent?filepath=org/jboss/narayana/rts/lra-coordinator-quarkus/5.11.1.Final/lra-coordinator-quarkus-5.11.1.Final-runner.jar \\ -O narayana-coordinator.jar \\ &amp;&amp; java -Dquarkus.http.port=8070 -jar narayana-coordinator.jar Narayana LRA coordinator is running by default under lra-coordinator context, with port 8070 defined in the snippet above you need to configure your Helidon LRA app as follows: mp.lra.coordinator.url=http://localhost:8070/lra-coordinator ",
            "title": "Additional Information"
        },
        {
            "location": "/mp/lra",
            "text": " MicroProfile LRA GitHub Repository MicroProfile Long Running Actions specification Microprofile LRA JavaDoc Helidon LRA Client JavaDoc ",
            "title": "Reference"
        },
        {
            "location": "/mp/metrics/metrics-capable-components",
            "text": " Overview Usage Examples ",
            "title": "Contents"
        },
        {
            "location": "/mp/metrics/metrics-capable-components",
            "text": " The Helidon metrics API This API allows your code to register, look-up, remove, and update metrics using the RegistryFactory , MetricRegistry , and individual metrics interfaces. The Helidon metrics REST service API This API allows your code to set up and respond to the /metrics endpoint so clients can retreive metrics information. ",
            "title": "APIs"
        },
        {
            "location": "/mp/metrics/metrics-capable-components",
            "text": " Implementations of the Helidon metrics API. Helidon provides two&#8212;&#8203;minimal and full-featured&#8212;&#8203;and selects which one to use at runtime, based on what components are present on the runtime path and whether metrics is configured to be enabled or disabled. By default, Helidon MP services use the full-featured implementation. Implementations of the Helidon metrics REST service API. Helidon provides two&#8212;&#8203;minimal and full-featured&#8212;&#8203;and selects which one to use at runtime. By default, Helidon MP apps which use metrics use the full-featured metrics REST service by default. As you plan and write Helidon components and applications, you make some choices about exactly how your code will use metrics. This document gives some background information, describes each option and its effect, and provides some code examples. ",
            "title": "Implementations of the APIs"
        },
        {
            "location": "/mp/metrics/metrics-capable-components",
            "text": " This document explains Helidon MP metrics-capable components and applications and describes how to create and control them. Think of Helidon metrics in several related but different parts: APIs The Helidon metrics API This API allows your code to register, look-up, remove, and update metrics using the RegistryFactory , MetricRegistry , and individual metrics interfaces. The Helidon metrics REST service API This API allows your code to set up and respond to the /metrics endpoint so clients can retreive metrics information. Implementations of the APIs Implementations of the Helidon metrics API. Helidon provides two&#8212;&#8203;minimal and full-featured&#8212;&#8203;and selects which one to use at runtime, based on what components are present on the runtime path and whether metrics is configured to be enabled or disabled. By default, Helidon MP services use the full-featured implementation. Implementations of the Helidon metrics REST service API. Helidon provides two&#8212;&#8203;minimal and full-featured&#8212;&#8203;and selects which one to use at runtime. By default, Helidon MP apps which use metrics use the full-featured metrics REST service by default. As you plan and write Helidon components and applications, you make some choices about exactly how your code will use metrics. This document gives some background information, describes each option and its effect, and provides some code examples. ",
            "title": "Overview"
        },
        {
            "location": "/mp/metrics/metrics-capable-components",
            "text": " We can place each Helidon component and Helidon application into one of three categories based on how it relies on metrics. The type of module dictates the compile-time dependency you declare in the project pom.xml . Types of Metrics Usage Registers, updates, removes metrics? Refers to metrics values? Category times times metrics-independent check times metrics-capable check check metrics-dependent Whenever possible, if your component or application uses metrics, then write it as metrics-capable code. ",
            "title": "Categorizing Metrics Usage"
        },
        {
            "location": "/mp/metrics/metrics-capable-components",
            "text": " Helidon provides two metrics implementations: Full-featured metrics allows registering, removing, and updating metrics and observing metrics' changing values. The helidon-metrics component contains full-featured metrics. Minimal metrics supports registering, removing, and updating metrics. The metrics objects provided by the minimal implementation are no-ops: their values never change. The minimal implementation is part of the helidon-metrics-api component. Any code compiled with helidon-metrics-api can assume that the runtime path will include the minimal implementation. Both implementations support all the operations of the RegistryFactory and the MetricRegistry . The full implementation provides fully-functional metrics instances (counters, timers, etc.). In the minimal implementations, metrics do not update their values. For Helidon to use the full implementation, two conditions must hold: The helidon-metrics component must be on the runtime path. Metrics must be enabled, using either a builder or configuration. (Enabled is the default.) Otherwise, provided that the runtime path includes helidon-metrics-api , Helidon activates the minimal implementation. ",
            "title": "Understanding the Two Metrics Implementations"
        },
        {
            "location": "/mp/metrics/metrics-capable-components",
            "text": " Helidon includes two implementations of support for the metrics web service endpoint /metrics (or whatever context value is configured). The full-service implementation sends responses which describe the metadata and current values for the metrics registered in metric registries. The helidon-metrics component contains this implementation. The helidon-metrics-service-api component contains the API for the metrics web service support (the MetricsSupport interface) and also a minimal implementation. This implementation simply responds with 404 and an explanatory message that metrics are disabled. Any code compiled with helidon-metrics-service-api can assume that the runtime path will contain the minimal implementation. Helidon activates the full implementation if the runtime path includes the full implementation and metrics is configured as enabled; Helidon uses the minimal implementation otherwise. ",
            "title": "Understanding the Two Metrics Service Implementations"
        },
        {
            "location": "/mp/metrics/metrics-capable-components",
            "text": " Using configuration, your component can let end users control at runtime whether Helidon should use full-featured metrics. If an end user sets metrics.enabled to false , then Helidon activates the minimal metrics and metrics service implementations provided they are in the runtime path. Further, users can set component-name.metrics.enabled to false which disables metrics for just that component so long as the component was written to check that setting and act on it accordingly. ",
            "title": "Enabling and Disabling Metrics"
        },
        {
            "location": "/mp/metrics/metrics-capable-components",
            "text": " Include this dependency: <markup lang=\"xml\" title=\"Dependency for Helidon metrics API\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics-api&lt;/artifactId&gt; &lt;/dependency&gt; This module defines the metrics API: RegistryFactory , MetricRegistry , and the various metrics themselves. Declare an explicit runtime dependency on the full-featured metrics implementation: <markup lang=\"xml\" title=\"Dependency for full metrics and metrics service implementations\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; ",
            "title": "Declaring Dependencies"
        },
        {
            "location": "/mp/metrics/metrics-capable-components",
            "text": " Whoever packages and deploys your application or component can control what code will be on the runtime path and whether metrics is enabled or not. As a result, wherever possible, construct your modules which use metrics so that they do not make decisions based on the values of metrics; that is, design them to be metrics-capable, not metrics-dependent. Doing so allows your code to operate regardless of whether the full-featured metrics implementation is active at runtime. Declaring Dependencies Include this dependency: <markup lang=\"xml\" title=\"Dependency for Helidon metrics API\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics-api&lt;/artifactId&gt; &lt;/dependency&gt; This module defines the metrics API: RegistryFactory , MetricRegistry , and the various metrics themselves. Declare an explicit runtime dependency on the full-featured metrics implementation: <markup lang=\"xml\" title=\"Dependency for full metrics and metrics service implementations\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; ",
            "title": "Designing and Writing Metrics-capable Applications and Components"
        },
        {
            "location": "/mp/metrics/metrics-capable-components",
            "text": " When your MP application code uses @Inject for either a RegistryFactory or a MetricRegistry , Helidon injects either the full-featured instance or the minimal instance according to whether the runtime path includes the full implementation and, if so, whether metrics is enabled. By choosing and injecting the appropriate implementation, Helidon allows you to write your code without concern for which implementation is available at runtime. ",
            "title": "Writing a Helidon MP Application"
        },
        {
            "location": "/mp/metrics/metrics-capable-components",
            "text": " The Helidon MP metrics implementation depends on the metrics and metrics service APIs as well as helidon-metrics which contains the full implementation of each. Therefore, by default, Helidon MP applications have full-featured metrics and endpoint support. Application code can @Inject the RegistryFactory and MetricRegistry instances. Helidon MP itself uses metrics settings in the configuration to make the correct RegistryFactory and MetricRegistry instances available at injection sites. Helidon&#8217;s MicroProfile metrics component helidon-microprofile-metrics has its own runtime dependency on the minimal implementation, so that implementation, at least, is available at runtime. By default, Helidon MP applications use the full implementation, because Helidon&#8217;s MP metrics depends also on the full metrics implementation. That said, a developer of a Helidon MP app can explicitly exclude the dependency on the full implementation: <markup lang=\"xml\" title=\"Explicit exclusion of helidon-metrics \" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.bundles&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; In the resulting Helidon MP application, Helidon will use the minimal metrics and metrics support implementations. ",
            "title": "Packaging a Metrics-capable Helidon MP Application "
        },
        {
            "location": "/mp/metrics/metrics-capable-components",
            "text": " Write your non-application component to accept component-specific configuration that includes an optional metrics section which can include an optional enabled setting. Helidon defaults the value to true . The following example shows one way to accomplish this: <markup lang=\"java\" title=\"Example code to support disabling metrics usage in a component\" >import io.helidon.config.Config; import io.helidon.metrics.api.ComponentMetricsSettings; import io.helidon.metrics.api.MetricsSettings; import io.helidon.metrics.api.RegistryFactory; import org.eclipse.microprofile.metrics.MetricRegistry; public class UtilComponent { private final MetricRegistry metricRegistry; public static class Builder implements io.helidon.common.Builder&lt;UtilComponent&gt; { private ComponentMetricsSettings.Builder componentMetricsSettingsBuilder = ComponentMetricsSettings.builder(); public Builder componentMetricsSettings(ComponentMetricsSettings.Builder componentMetricsSettingsBuilder) { this.componentMetricsSettingsBuilder = componentMetricsSettingsBuilder; return this; } public Builder config(Config componentConfig) { componentConfig .get(ComponentMetricsSettings.Builder.METRICS_CONFIG_KEY) .as(ComponentMetricsSettings::create) .ifPresent(this::componentMetricsSettings); return this; } public UtilComponent build() { return new UtilComponent(this); } } private UtilComponent(Builder builder) { metricRegistry = RegistryFactory .getInstance(builder.componentMetricsSettingsBuilder.build()) .getRegistry(MetricRegistry.Type.VENDOR); } MetricRegistry metricRegistry() { return metricRegistry; } } Other code in the component uses this metric registry for registering, looking up, and removing metrics. Applications which use instances of MyComponent use this Builder to set up and create those instances. Applications which layer on your component invoke this method to set up the component-level metrics behavior they want your component to use. If an application supports configuration, it passes the util config to this method. The constructor for your component obtains the MetricRegistry which the rest of your component will use. Provides easy access to the MetricRegistry which the component&#8217;s metrics code should use. Helidon returns either a full-featured RegistryFactory or a minimal one, depending on: whether the full-featured metrics implementation is on the runtime path, whether metrics overall is enabled or disabled, and whether the component metrics settings requests enabled or disabled metrics. ",
            "title": "Writing a Non-application Component "
        },
        {
            "location": "/mp/metrics/metrics-capable-components",
            "text": " The way you write a metrics-capable module depends on whether it is a component (that is, not an application) or an application . Writing a Helidon MP Application When your MP application code uses @Inject for either a RegistryFactory or a MetricRegistry , Helidon injects either the full-featured instance or the minimal instance according to whether the runtime path includes the full implementation and, if so, whether metrics is enabled. By choosing and injecting the appropriate implementation, Helidon allows you to write your code without concern for which implementation is available at runtime. Packaging a Metrics-capable Helidon MP Application The Helidon MP metrics implementation depends on the metrics and metrics service APIs as well as helidon-metrics which contains the full implementation of each. Therefore, by default, Helidon MP applications have full-featured metrics and endpoint support. Application code can @Inject the RegistryFactory and MetricRegistry instances. Helidon MP itself uses metrics settings in the configuration to make the correct RegistryFactory and MetricRegistry instances available at injection sites. Helidon&#8217;s MicroProfile metrics component helidon-microprofile-metrics has its own runtime dependency on the minimal implementation, so that implementation, at least, is available at runtime. By default, Helidon MP applications use the full implementation, because Helidon&#8217;s MP metrics depends also on the full metrics implementation. That said, a developer of a Helidon MP app can explicitly exclude the dependency on the full implementation: <markup lang=\"xml\" title=\"Explicit exclusion of helidon-metrics \" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.bundles&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; In the resulting Helidon MP application, Helidon will use the minimal metrics and metrics support implementations. Writing a Non-application Component Write your non-application component to accept component-specific configuration that includes an optional metrics section which can include an optional enabled setting. Helidon defaults the value to true . The following example shows one way to accomplish this: <markup lang=\"java\" title=\"Example code to support disabling metrics usage in a component\" >import io.helidon.config.Config; import io.helidon.metrics.api.ComponentMetricsSettings; import io.helidon.metrics.api.MetricsSettings; import io.helidon.metrics.api.RegistryFactory; import org.eclipse.microprofile.metrics.MetricRegistry; public class UtilComponent { private final MetricRegistry metricRegistry; public static class Builder implements io.helidon.common.Builder&lt;UtilComponent&gt; { private ComponentMetricsSettings.Builder componentMetricsSettingsBuilder = ComponentMetricsSettings.builder(); public Builder componentMetricsSettings(ComponentMetricsSettings.Builder componentMetricsSettingsBuilder) { this.componentMetricsSettingsBuilder = componentMetricsSettingsBuilder; return this; } public Builder config(Config componentConfig) { componentConfig .get(ComponentMetricsSettings.Builder.METRICS_CONFIG_KEY) .as(ComponentMetricsSettings::create) .ifPresent(this::componentMetricsSettings); return this; } public UtilComponent build() { return new UtilComponent(this); } } private UtilComponent(Builder builder) { metricRegistry = RegistryFactory .getInstance(builder.componentMetricsSettingsBuilder.build()) .getRegistry(MetricRegistry.Type.VENDOR); } MetricRegistry metricRegistry() { return metricRegistry; } } Other code in the component uses this metric registry for registering, looking up, and removing metrics. Applications which use instances of MyComponent use this Builder to set up and create those instances. Applications which layer on your component invoke this method to set up the component-level metrics behavior they want your component to use. If an application supports configuration, it passes the util config to this method. The constructor for your component obtains the MetricRegistry which the rest of your component will use. Provides easy access to the MetricRegistry which the component&#8217;s metrics code should use. Helidon returns either a full-featured RegistryFactory or a minimal one, depending on: whether the full-featured metrics implementation is on the runtime path, whether metrics overall is enabled or disabled, and whether the component metrics settings requests enabled or disabled metrics. ",
            "title": "Writing Metrics-capable Code"
        },
        {
            "location": "/mp/metrics/metrics-capable-components",
            "text": " This section helps you decide how incorporate metrics into your software by describing the categories of metrics usage, explaining generally how Helidon implements metrics, and illustrating how to write the metrics-related code accordingly. Categorizing Metrics Usage We can place each Helidon component and Helidon application into one of three categories based on how it relies on metrics. The type of module dictates the compile-time dependency you declare in the project pom.xml . Types of Metrics Usage Registers, updates, removes metrics? Refers to metrics values? Category times times metrics-independent check times metrics-capable check check metrics-dependent Whenever possible, if your component or application uses metrics, then write it as metrics-capable code. Understanding the Two Metrics Implementations Helidon provides two metrics implementations: Full-featured metrics allows registering, removing, and updating metrics and observing metrics' changing values. The helidon-metrics component contains full-featured metrics. Minimal metrics supports registering, removing, and updating metrics. The metrics objects provided by the minimal implementation are no-ops: their values never change. The minimal implementation is part of the helidon-metrics-api component. Any code compiled with helidon-metrics-api can assume that the runtime path will include the minimal implementation. Both implementations support all the operations of the RegistryFactory and the MetricRegistry . The full implementation provides fully-functional metrics instances (counters, timers, etc.). In the minimal implementations, metrics do not update their values. For Helidon to use the full implementation, two conditions must hold: The helidon-metrics component must be on the runtime path. Metrics must be enabled, using either a builder or configuration. (Enabled is the default.) Otherwise, provided that the runtime path includes helidon-metrics-api , Helidon activates the minimal implementation. Understanding the Two Metrics Service Implementations Helidon includes two implementations of support for the metrics web service endpoint /metrics (or whatever context value is configured). The full-service implementation sends responses which describe the metadata and current values for the metrics registered in metric registries. The helidon-metrics component contains this implementation. The helidon-metrics-service-api component contains the API for the metrics web service support (the MetricsSupport interface) and also a minimal implementation. This implementation simply responds with 404 and an explanatory message that metrics are disabled. Any code compiled with helidon-metrics-service-api can assume that the runtime path will contain the minimal implementation. Helidon activates the full implementation if the runtime path includes the full implementation and metrics is configured as enabled; Helidon uses the minimal implementation otherwise. Enabling and Disabling Metrics Using configuration, your component can let end users control at runtime whether Helidon should use full-featured metrics. If an end user sets metrics.enabled to false , then Helidon activates the minimal metrics and metrics service implementations provided they are in the runtime path. Further, users can set component-name.metrics.enabled to false which disables metrics for just that component so long as the component was written to check that setting and act on it accordingly. Designing and Writing Metrics-capable Applications and Components Whoever packages and deploys your application or component can control what code will be on the runtime path and whether metrics is enabled or not. As a result, wherever possible, construct your modules which use metrics so that they do not make decisions based on the values of metrics; that is, design them to be metrics-capable, not metrics-dependent. Doing so allows your code to operate regardless of whether the full-featured metrics implementation is active at runtime. Declaring Dependencies Include this dependency: <markup lang=\"xml\" title=\"Dependency for Helidon metrics API\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics-api&lt;/artifactId&gt; &lt;/dependency&gt; This module defines the metrics API: RegistryFactory , MetricRegistry , and the various metrics themselves. Declare an explicit runtime dependency on the full-featured metrics implementation: <markup lang=\"xml\" title=\"Dependency for full metrics and metrics service implementations\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; Writing Metrics-capable Code The way you write a metrics-capable module depends on whether it is a component (that is, not an application) or an application . Writing a Helidon MP Application When your MP application code uses @Inject for either a RegistryFactory or a MetricRegistry , Helidon injects either the full-featured instance or the minimal instance according to whether the runtime path includes the full implementation and, if so, whether metrics is enabled. By choosing and injecting the appropriate implementation, Helidon allows you to write your code without concern for which implementation is available at runtime. Packaging a Metrics-capable Helidon MP Application The Helidon MP metrics implementation depends on the metrics and metrics service APIs as well as helidon-metrics which contains the full implementation of each. Therefore, by default, Helidon MP applications have full-featured metrics and endpoint support. Application code can @Inject the RegistryFactory and MetricRegistry instances. Helidon MP itself uses metrics settings in the configuration to make the correct RegistryFactory and MetricRegistry instances available at injection sites. Helidon&#8217;s MicroProfile metrics component helidon-microprofile-metrics has its own runtime dependency on the minimal implementation, so that implementation, at least, is available at runtime. By default, Helidon MP applications use the full implementation, because Helidon&#8217;s MP metrics depends also on the full metrics implementation. That said, a developer of a Helidon MP app can explicitly exclude the dependency on the full implementation: <markup lang=\"xml\" title=\"Explicit exclusion of helidon-metrics \" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.bundles&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; In the resulting Helidon MP application, Helidon will use the minimal metrics and metrics support implementations. Writing a Non-application Component Write your non-application component to accept component-specific configuration that includes an optional metrics section which can include an optional enabled setting. Helidon defaults the value to true . The following example shows one way to accomplish this: <markup lang=\"java\" title=\"Example code to support disabling metrics usage in a component\" >import io.helidon.config.Config; import io.helidon.metrics.api.ComponentMetricsSettings; import io.helidon.metrics.api.MetricsSettings; import io.helidon.metrics.api.RegistryFactory; import org.eclipse.microprofile.metrics.MetricRegistry; public class UtilComponent { private final MetricRegistry metricRegistry; public static class Builder implements io.helidon.common.Builder&lt;UtilComponent&gt; { private ComponentMetricsSettings.Builder componentMetricsSettingsBuilder = ComponentMetricsSettings.builder(); public Builder componentMetricsSettings(ComponentMetricsSettings.Builder componentMetricsSettingsBuilder) { this.componentMetricsSettingsBuilder = componentMetricsSettingsBuilder; return this; } public Builder config(Config componentConfig) { componentConfig .get(ComponentMetricsSettings.Builder.METRICS_CONFIG_KEY) .as(ComponentMetricsSettings::create) .ifPresent(this::componentMetricsSettings); return this; } public UtilComponent build() { return new UtilComponent(this); } } private UtilComponent(Builder builder) { metricRegistry = RegistryFactory .getInstance(builder.componentMetricsSettingsBuilder.build()) .getRegistry(MetricRegistry.Type.VENDOR); } MetricRegistry metricRegistry() { return metricRegistry; } } Other code in the component uses this metric registry for registering, looking up, and removing metrics. Applications which use instances of MyComponent use this Builder to set up and create those instances. Applications which layer on your component invoke this method to set up the component-level metrics behavior they want your component to use. If an application supports configuration, it passes the util config to this method. The constructor for your component obtains the MetricRegistry which the rest of your component will use. Provides easy access to the MetricRegistry which the component&#8217;s metrics code should use. Helidon returns either a full-featured RegistryFactory or a minimal one, depending on: whether the full-featured metrics implementation is on the runtime path, whether metrics overall is enabled or disabled, and whether the component metrics settings requests enabled or disabled metrics. ",
            "title": "Usage"
        },
        {
            "location": "/mp/metrics/metrics-capable-components",
            "text": " The following example shows how useful metrics-capable code can be in the context of building Docker images. You (or others) could assemble a Docker image with your metrics-capable app as its top layer or your metrics-capable component in a middle layer, built on a lower layer containing several Helidon modules including the full metrics implementation. When that Docker image runs, your app will run with full-featured metrics support. Separately, someone could build a similar Docker image which does not include the Helidon metrics implementation. In this Docker image, your app or component will run successfully but will not incur the overhead of actually updating the metrics it uses. Users can create different Docker images, some with full metrics support and some without, which all use a single version of your metrics-capable app or component which runs properly in either environment without change. ",
            "title": "Examples"
        },
        {
            "location": "/mp/metrics/metrics-capable-components",
            "text": " By writing a metrics-capable app or component, you give packagers and deployers of your code the flexibility to include or exclude the full metrics implementation at runtime as they see fit. Because your one module works correctly in either environment: The consumers of your app benefit by not needing to understand and choose between two different implementations of your module, or having to add both your main module and an optional add-on which adds metrics support to your module. You benefit by writing and maintaining a single module, not two: one that is metrics-independent and one that is metrics-dependent. ",
            "title": "Advantages of Writing Metrics-capable Modules"
        },
        {
            "location": "/mp/metrics/metrics-capable-components",
            "text": " Advantages of Writing Metrics-capable Modules By writing a metrics-capable app or component, you give packagers and deployers of your code the flexibility to include or exclude the full metrics implementation at runtime as they see fit. Because your one module works correctly in either environment: The consumers of your app benefit by not needing to understand and choose between two different implementations of your module, or having to add both your main module and an optional add-on which adds metrics support to your module. You benefit by writing and maintaining a single module, not two: one that is metrics-independent and one that is metrics-dependent. ",
            "title": "Additional Information"
        },
        {
            "location": "/mp/metrics/metrics",
            "text": " Overview Maven Coordinates Usage API Configuration Examples Additional Information ",
            "title": "Contents"
        },
        {
            "location": "/mp/metrics/metrics",
            "text": " Helidon MP metrics implements the MicroProfile Metrics specification, providing: a unified way for MicroProfile servers to export monitoring data&#8212;&#8203;telemetry&#8212;&#8203;to management agents, and a unified Java API which all application programmers can use to register and update metrics to expose telemetry data from their services. support for metrics-related annotations. Learn more about the MicroProfile Metrics specification . Metrics is one of the Helidon observability features. ",
            "title": "Overview"
        },
        {
            "location": "/mp/metrics/metrics",
            "text": " To enable metrics add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-metrics&lt;/artifactId&gt; &lt;/dependency&gt; Adding this dependency packages the full-featured metrics implementation with your service. ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/metrics/metrics",
            "text": " You add metrics to your service in these ways: Annotate bean methods&#8212;&#8203;typically your REST resource endpoint methods (the Java code that receives incoming REST requests); Helidon automatically registers these metrics and updates them when the annotated methods are invoked via CDI. Write code which explicitly invokes the metrics API to register metrics, retrieve previously-registered metrics, and update metric values. Configure some simple REST.request metrics which Helidon automatically registers and updates for all REST resource endpoints. Later sections of this document describe how to do each of these. ",
            "title": "Instrumenting Your Service"
        },
        {
            "location": "/mp/metrics/metrics",
            "text": " Helidon distinguishes among scopes , or types, of metrics as described in the MP metrics specification . Helidon includes metrics in the built-in scopes described below. Applications often register their own metrics in the application scope but can create their own scopes and register metrics within them. Built-in metric scopes Built-in Scope Typical Usage base OS or Java runtime measurements (available heap, disk space, etc.). Mandated by the MP metrics specification vendor Implemented by vendors, including the REST.request metrics and other key performance indicator measurements (described in later sections). application Declared via annotations or programmatically registered by your service code. When you add metrics annotations to your service code, Helidon registers the resulting metrics in the application scope. ",
            "title": "Categorizing Types of Metrics"
        },
        {
            "location": "/mp/metrics/metrics",
            "text": " A metric registry collects registered metrics of a given scope. Helidon supports one metrics registry for each scope. When you add code to your service to create a metric programmatically, the code first locates the appropriate registry and then registers the metric with that registry. ",
            "title": "Metric Registries"
        },
        {
            "location": "/mp/metrics/metrics",
            "text": " When you add the metrics dependency to your project, Helidon automatically provides a built-in REST endpoint /metrics which responds with a report of the registered metrics and their values. Clients can request a particular output format. Formats for /metrics output Format Requested by OpenMetrics (Prometheus) default ( text/plain ) JSON Header Accept: application/json Clients can also limit the report by specifying the scope as a query parameter in the request URL: /metrics?scope=base /metrics?scope=vendor /metrics?scope=application Further, clients can narrow down to a specific metric name by adding the name as another query parameter, such as /metrics?scope=application&amp;name=myCount . <markup lang=\"bash\" title=\"Example Reporting: Prometheus format\" >curl -s -H 'Accept: text/plain' -X GET http://localhost:8080/metrics # TYPE base:classloader_total_loaded_class_count counter # HELP base:classloader_total_loaded_class_count Displays the total number of classes that have been loaded since the Java virtual machine has started execution. base:classloader_total_loaded_class_count 3157 <markup lang=\"bash\" title=\"Example Reporting: JSON format\" >curl -s -H 'Accept: application/json' -X GET http://localhost:8080/metrics { \"base\" : { \"memory.maxHeap\" : 3817865216, \"memory.committedHeap\" : 335544320, } } In addition to your application metrics, the reports contain other metrics of interest such as system and VM information. ",
            "title": "Retrieving Metrics Reports from your Service"
        },
        {
            "location": "/mp/metrics/metrics",
            "text": " Instrumenting Your Service You add metrics to your service in these ways: Annotate bean methods&#8212;&#8203;typically your REST resource endpoint methods (the Java code that receives incoming REST requests); Helidon automatically registers these metrics and updates them when the annotated methods are invoked via CDI. Write code which explicitly invokes the metrics API to register metrics, retrieve previously-registered metrics, and update metric values. Configure some simple REST.request metrics which Helidon automatically registers and updates for all REST resource endpoints. Later sections of this document describe how to do each of these. Categorizing Types of Metrics Helidon distinguishes among scopes , or types, of metrics as described in the MP metrics specification . Helidon includes metrics in the built-in scopes described below. Applications often register their own metrics in the application scope but can create their own scopes and register metrics within them. Built-in metric scopes Built-in Scope Typical Usage base OS or Java runtime measurements (available heap, disk space, etc.). Mandated by the MP metrics specification vendor Implemented by vendors, including the REST.request metrics and other key performance indicator measurements (described in later sections). application Declared via annotations or programmatically registered by your service code. When you add metrics annotations to your service code, Helidon registers the resulting metrics in the application scope. Metric Registries A metric registry collects registered metrics of a given scope. Helidon supports one metrics registry for each scope. When you add code to your service to create a metric programmatically, the code first locates the appropriate registry and then registers the metric with that registry. Retrieving Metrics Reports from your Service When you add the metrics dependency to your project, Helidon automatically provides a built-in REST endpoint /metrics which responds with a report of the registered metrics and their values. Clients can request a particular output format. Formats for /metrics output Format Requested by OpenMetrics (Prometheus) default ( text/plain ) JSON Header Accept: application/json Clients can also limit the report by specifying the scope as a query parameter in the request URL: /metrics?scope=base /metrics?scope=vendor /metrics?scope=application Further, clients can narrow down to a specific metric name by adding the name as another query parameter, such as /metrics?scope=application&amp;name=myCount . <markup lang=\"bash\" title=\"Example Reporting: Prometheus format\" >curl -s -H 'Accept: text/plain' -X GET http://localhost:8080/metrics # TYPE base:classloader_total_loaded_class_count counter # HELP base:classloader_total_loaded_class_count Displays the total number of classes that have been loaded since the Java virtual machine has started execution. base:classloader_total_loaded_class_count 3157 <markup lang=\"bash\" title=\"Example Reporting: JSON format\" >curl -s -H 'Accept: application/json' -X GET http://localhost:8080/metrics { \"base\" : { \"memory.maxHeap\" : 3817865216, \"memory.committedHeap\" : 335544320, } } In addition to your application metrics, the reports contain other metrics of interest such as system and VM information. ",
            "title": "Usage"
        },
        {
            "location": "/mp/metrics/metrics",
            "text": " The MicroProfile Metrics specification describes several metric types you can create using annotations, summarized in the following table: Metrics Annotations Annotation Usage @Counted Monotonically increasing count of events. @Gauge Access to a value managed by other code in the service. @Timed Frequency of invocations and the distribution of how long the invocations take. Place annotations on constructors or methods to measure those specific executables. If you annotate the class instead, Helidon applies that annotation to all constructors and methods which the class declares. ",
            "title": "Metric-defining Annotations"
        },
        {
            "location": "/mp/metrics/metrics",
            "text": " To get a reference to a specific metric, use a metric-referencing annotation in any bean, including your REST resource classes. You can @Inject a field of the correct type. Helidon uses the MicroProfile Metrics naming conventions to select which specific metric to inject. Use the @Metric annotation to control that selection. You can also add @Metric on a constructor or method parameter to trigger injection there. Helidon automatically looks up the metric referenced from any injection site and provides a reference to the metric. Your code then simply invokes methods on the injected metric. ",
            "title": "Metric-referencing Annotations"
        },
        {
            "location": "/mp/metrics/metrics",
            "text": " You can very easily instrument your service and refer to registered metrics by annotating methods to be measured and injecting metrics which your code needs to observe. Metric-defining Annotations The MicroProfile Metrics specification describes several metric types you can create using annotations, summarized in the following table: Metrics Annotations Annotation Usage @Counted Monotonically increasing count of events. @Gauge Access to a value managed by other code in the service. @Timed Frequency of invocations and the distribution of how long the invocations take. Place annotations on constructors or methods to measure those specific executables. If you annotate the class instead, Helidon applies that annotation to all constructors and methods which the class declares. Metric-referencing Annotations To get a reference to a specific metric, use a metric-referencing annotation in any bean, including your REST resource classes. You can @Inject a field of the correct type. Helidon uses the MicroProfile Metrics naming conventions to select which specific metric to inject. Use the @Metric annotation to control that selection. You can also add @Metric on a constructor or method parameter to trigger injection there. Helidon automatically looks up the metric referenced from any injection site and provides a reference to the metric. Your code then simply invokes methods on the injected metric. ",
            "title": "Metrics Annotations"
        },
        {
            "location": "/mp/metrics/metrics",
            "text": " To register or look up metrics programmatically, your service code uses the MetricRegistry instance for the scope of interest: base , vendor , application , or a custom scope. To get a MetricRegistry reference @Inject the metric registry you want, perhaps also using the @RegistryScope annotation to select the registry type, or Get a Helidon RegistryFactory ; either @Inject RegistryFactory or Invoke one of the static getInstance methods on RegistryFactory Then invoke getRegistry on the RegistryFactory instance. The MetricRegistry allows your code to register new metrics, look up previously-registered metrics, and remove metrics. ",
            "title": "The MetricRegistry API"
        },
        {
            "location": "/mp/metrics/metrics",
            "text": " The MicroProfile Metrics API prescribes all the standard interfaces related to metrics. This section summarizes a few key points about using that API and explains some Helidon-specific interfaces. Metrics Annotations You can very easily instrument your service and refer to registered metrics by annotating methods to be measured and injecting metrics which your code needs to observe. Metric-defining Annotations The MicroProfile Metrics specification describes several metric types you can create using annotations, summarized in the following table: Metrics Annotations Annotation Usage @Counted Monotonically increasing count of events. @Gauge Access to a value managed by other code in the service. @Timed Frequency of invocations and the distribution of how long the invocations take. Place annotations on constructors or methods to measure those specific executables. If you annotate the class instead, Helidon applies that annotation to all constructors and methods which the class declares. Metric-referencing Annotations To get a reference to a specific metric, use a metric-referencing annotation in any bean, including your REST resource classes. You can @Inject a field of the correct type. Helidon uses the MicroProfile Metrics naming conventions to select which specific metric to inject. Use the @Metric annotation to control that selection. You can also add @Metric on a constructor or method parameter to trigger injection there. Helidon automatically looks up the metric referenced from any injection site and provides a reference to the metric. Your code then simply invokes methods on the injected metric. The MetricRegistry API To register or look up metrics programmatically, your service code uses the MetricRegistry instance for the scope of interest: base , vendor , application , or a custom scope. To get a MetricRegistry reference @Inject the metric registry you want, perhaps also using the @RegistryScope annotation to select the registry type, or Get a Helidon RegistryFactory ; either @Inject RegistryFactory or Invoke one of the static getInstance methods on RegistryFactory Then invoke getRegistry on the RegistryFactory instance. The MetricRegistry allows your code to register new metrics, look up previously-registered metrics, and remove metrics. ",
            "title": "API"
        },
        {
            "location": "/mp/metrics/metrics",
            "text": " Optional configuration options key type default value description app-name string &#160; Value for the application tag to be added to each meter ID. @return application tag value app-tag-name string &#160; Name for the application tag to be added to each meter ID. @return application tag name enabled boolean true Whether metrics functionality is enabled. @return if metrics are configured to be enabled endpoint string metrics key-performance-indicators KeyPerformanceIndicatorMetricsConfig &#160; Key performance indicator metrics settings. @return key performance indicator metrics settings permit-all boolean &#160; Whether to allow anybody to access the endpoint. @return whether to permit access to metrics endpoint to anybody, defaults to `true` @see #roles() rest-request-enabled boolean &#160; Whether automatic REST request metrics should be measured. @return true/false roles string[&#93; &#160; Hints for role names the user is expected to be in. @return list of hints scoping ScopingConfig &#160; Settings related to scoping management. @return scoping settings tags Tag[&#93; &#160; Global tags. @return name/value pairs for global tags ",
            "title": "Configuration options"
        },
        {
            "location": "/mp/metrics/metrics",
            "text": " To control how the Helidon metrics subsystem behaves, add a metrics section to your META-INF/microprofile-config.properties file. Type: io.helidon.webserver.observe.metrics.MetricsObserver This is a standalone configuration type, prefix from configuration root: metrics This type provides the following service implementations: io.helidon.webserver.observe.spi.ObserveProvider Configuration options Optional configuration options key type default value description app-name string &#160; Value for the application tag to be added to each meter ID. @return application tag value app-tag-name string &#160; Name for the application tag to be added to each meter ID. @return application tag name enabled boolean true Whether metrics functionality is enabled. @return if metrics are configured to be enabled endpoint string metrics key-performance-indicators KeyPerformanceIndicatorMetricsConfig &#160; Key performance indicator metrics settings. @return key performance indicator metrics settings permit-all boolean &#160; Whether to allow anybody to access the endpoint. @return whether to permit access to metrics endpoint to anybody, defaults to `true` @see #roles() rest-request-enabled boolean &#160; Whether automatic REST request metrics should be measured. @return true/false roles string[&#93; &#160; Hints for role names the user is expected to be in. @return list of hints scoping ScopingConfig &#160; Settings related to scoping management. @return scoping settings tags Tag[&#93; &#160; Global tags. @return name/value pairs for global tags ",
            "title": "Configuration"
        },
        {
            "location": "/mp/metrics/metrics",
            "text": " The following example adds a new resource class, GreetingCards , to the Helidon MP QuickStart example. It shows how to use the @Counted annotation to track the number of times the /cards endpoint is called. <markup lang=\"java\" title=\"Create a new class GreetingCards with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import jakarta.enterprise.context.RequestScoped; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.annotation.Counted; @Path(\"/cards\") @RequestScoped public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"any-card\") public JsonObject anyCard() throws InterruptedException { return createResponse(\"Here are some random cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } } This class is annotated with Path which sets the path for this resource as /cards . The @RequestScoped annotation defines that this bean is request scoped. The request scope is active only for the duration of one web service invocation and it is destroyed at the end of that invocation. The annotation @Counted will register a Counter metric for this method, creating it if needed. The counter is incremented each time the anyCards method is called. The name attribute is optional. <markup lang=\"bash\" title=\"Build and run the application\" >mvn package java -jar target/helidon-quickstart-mp.jar <markup lang=\"base\" title=\"Access the application endpoints\" >curl http://localhost:8080/cards curl http://localhost:8080/cards curl -H \"Accept: application/json\" 'http://localhost:8080/metrics?scope=application' <markup lang=\"json\" title=\"JSON response:\" >{ \"io.helidon.examples.quickstart.mp.GreetingCards.any-card\": 2, // \"personalizedGets\": 0, \"allGets\": { \"count\": 0, \"elapsedTime\": 0, \"max\": 0, \"mean\": 0 } } The any-card count is two, since you invoked the endpoint twice. The other metrics are from the SimpleGreetResource class. Notice the counter name is fully qualified with the class and method names. You can remove the prefix by using the absolute=true field in the @Counted annotation. You must use absolute=false (the default) for class-level annotations. ",
            "title": "Adding Method-level Annotations"
        },
        {
            "location": "/mp/metrics/metrics",
            "text": " You can also use the @Timed` annotation with a method. For the following example. you can just annotate the same method with @Timed . Timers significant information about the measured methods, but at a cost of some overhead and more complicated output. Note that when using multiple annotations on a method, you must give the metrics different names as shown below (although they do not have to be absolute). <markup lang=\"java\" title=\"Update the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import jakarta.enterprise.context.RequestScoped; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.MetricUnits; import org.eclipse.microprofile.metrics.annotation.Counted; import org.eclipse.microprofile.metrics.annotation.Metered; import org.eclipse.microprofile.metrics.annotation.Timed; @Path(\"/cards\") @RequestScoped public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"cardCount\", absolute = true) @Timed(name = \"cardTimer\", absolute = true, unit = MetricUnits.MILLISECONDS) public JsonObject anyCard() { return createResponse(\"Here are some random cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } } Specify a custom name for the Counter metric and set absolute=true to remove the path prefix from the name. &lt;2&gt;Add the @Timed annotation to get a Timer metric. <markup lang=\"bash\" title=\"Build and run the application\" >mvn package java -jar target/helidon-quickstart-mp.jar <markup lang=\"base\" title=\"Access the application endpoints\" >curl http://localhost:8080/cards curl http://localhost:8080/cards curl -H \"Accept: application/json\" 'http://localhost:8080/metrics?scope=application' <markup lang=\"json\" title=\"JSON response:\" >{ \"cardTimer\": { \"count\": 2, \"elapsedTime\": 0.002941925, \"max\": 0.002919973, \"mean\": 0.0014709625 }, \"personalizedGets\": 0, \"allGets\": { \"count\": 0, \"elapsedTime\": 0, \"max\": 0, \"mean\": 0 }, \"cardCount\": 2 } ",
            "title": "Additional Method-level Metrics"
        },
        {
            "location": "/mp/metrics/metrics",
            "text": " You can collect metrics at the class level to aggregate data from all methods in that class using the same metric. The following example introduces a metric to count all card queries. In the following example, the method-level metrics are not needed to aggregate the counts, but they are left in the example to demonstrate the combined output of all three metrics. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import jakarta.enterprise.context.RequestScoped; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.annotation.Counted; @Path(\"/cards\") @RequestScoped @Counted(name = \"totalCards\") public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) @Counted(absolute = true) public JsonObject anyCard() throws InterruptedException { return createResponse(\"Here are some random cards ...\"); } @Path(\"/birthday\") @GET @Produces(MediaType.APPLICATION_JSON) @Counted(absolute = true) public JsonObject birthdayCard() throws InterruptedException { return createResponse(\"Here are some birthday cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } } This class is now annotated with @Counted , which aggregates count data from all the method that have a Count annotation. Use absolute=true to remove path prefix for method-level annotations. Add a method with a Counter metric to get birthday cards. <markup lang=\"bash\" title=\"Build and run the application\" >mvn package java -jar target/helidon-quickstart-mp.jar <markup lang=\"bash\" title=\"Access the application endpoints\" >curl http://localhost:8080/cards curl http://localhost:8080/cards/birthday curl -H \"Accept: application/json\" 'http://localhost:8080/metrics?scope=application' <markup lang=\"json\" title=\"JSON response from /metrics?scope=application :\" >{ \"birthdayCard\": 1, \"personalizedGets\": 0, \"allGets\": { \"count\": 0, \"elapsedTime\": 0, \"max\": 0, \"mean\": 0 }, \"anyCard\": 1, \"io.helidon.examples.quickstart.mp.totalCards.GreetingCards\": 2 } The totalCards.GreetingCards count is a total of all the method-level Counter metrics. Class level metric names are always fully qualified. ",
            "title": "Class-level Metrics"
        },
        {
            "location": "/mp/metrics/metrics",
            "text": " Field level metrics can be injected into managed objects, but they need to be updated by the application code. This annotation can be used on fields of type Timer , Counter , and Histogram . The following example shows how to use a field-level Counter metric to track cache hits. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import java.util.Random; import jakarta.enterprise.context.RequestScoped; import jakarta.inject.Inject; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.Counter; import org.eclipse.microprofile.metrics.annotation.Counted; import org.eclipse.microprofile.metrics.annotation.Metric; @Path(\"/cards\") @RequestScoped @Counted(name = \"totalCards\") public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @Inject @Metric(name = \"cacheHits\", absolute = true) private Counter cacheHits; @GET @Produces(MediaType.APPLICATION_JSON) @Counted(absolute = true) public JsonObject anyCard() throws InterruptedException { updateStats(); return createResponse(\"Here are some random cards ...\"); } @Path(\"/birthday\") @GET @Produces(MediaType.APPLICATION_JSON) @Counted(absolute = true) public JsonObject birthdayCard() throws InterruptedException { updateStats(); return createResponse(\"Here are some birthday cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } private void updateStats() { if (new Random().nextInt(3) == 1) { cacheHits.inc(); } } } A Counter metric field, cacheHits , is automatically injected by Helidon. Call updateStats() to update the cache hits. Call updateStats() to update the cache hits. Randomly increment the cacheHits counter. <markup lang=\"bash\" title=\"Build and run the application, then invoke the following endpoints:\" >curl http://localhost:8080/cards curl http://localhost:8080/cards curl http://localhost:8080/cards/birthday curl http://localhost:8080/cards/birthday curl http://localhost:8080/cards/birthday curl -H \"Accept: application/json\" 'http://localhost:8080/metrics?scope=application' <markup lang=\"json\" title=\"JSON response from /metrics/application :\" >{ \"birthdayCard\": 3, \"personalizedGets\": 0, \"allGets\": { \"count\": 0, \"elapsedTime\": 0, \"max\": 0, \"mean\": 0 }, \"anyCard\": 2, \"cacheHits\": 2, \"io.helidon.examples.quickstart.mp.totalCards.GreetingCards\": 5 } The cache was hit two times out of five queries. ",
            "title": "Field Level Metrics"
        },
        {
            "location": "/mp/metrics/metrics",
            "text": " The metrics you have tested so far are updated in response to an application REST request, i.e GET /cards . These metrics can be declared in a request scoped class and Helidon will store the metric in the MetricRegistry , so the value persists across requests. When GET /metrics?scope=application is invoked, Helidon will return the current value of the metric stored in the MetricRegistry . The Gauge annotation is different from the other metric annotations. The application must provide a method to return the gauge value in an application-scoped class. When GET /metrics?scope=application is invoked, Helidon will call the Gauge method, using the returned value as the value of the gauge as part of the metrics response. The following example demonstrates how to use a Gauge to track application up-time. <markup lang=\"java\" title=\"Create a new GreetingCardsAppMetrics class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.time.Duration; import java.util.concurrent.atomic.AtomicLong; import jakarta.enterprise.context.ApplicationScoped; import jakarta.enterprise.context.Initialized; import jakarta.enterprise.event.Observes; import org.eclipse.microprofile.metrics.annotation.Gauge; @ApplicationScoped public class GreetingCardsAppMetrics { private AtomicLong startTime = new AtomicLong(0); public void onStartUp(@Observes @Initialized(ApplicationScoped.class) Object init) { startTime = new AtomicLong(System.currentTimeMillis()); } @Gauge(unit = \"TimeSeconds\") public long appUpTimeSeconds() { return Duration.ofMillis(System.currentTimeMillis() - startTime.get()).getSeconds(); } } This managed object must be application scoped to properly register and use the annotated Gauge metric. Declare an AtomicLong field to hold the start time of the application. Initialize the application start time. Return the application appUpTimeSeconds metric, which will be included in the application metrics. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code to simplify the metrics output:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import jakarta.enterprise.context.RequestScoped; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.annotation.Counted; @Path(\"/cards\") @RequestScoped public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"cardCount\", absolute = true) public JsonObject anyCard() throws InterruptedException { return createResponse(\"Here are some random cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } } <markup lang=\"bash\" title=\"Build and run the application, then invoke the application metrics endpoint:\" >curl -H \"Accept: application/json\" 'http://localhost:8080/metrics?scope=application' <markup lang=\"json\" title=\"JSON response from /metrics/application :\" >{ \"personalizedGets\": 0, \"allGets\": { \"count\": 0, \"elapsedTime\": 0, \"max\": 0, \"mean\": 0 }, \"io.helidon.examples.quickstart.mp.GreetingCardsAppMetrics.appUpTimeSeconds\": 23, \"cardCount\": 0 } The application has been running for 23 seconds. ",
            "title": "Gauge Metric"
        },
        {
            "location": "/mp/metrics/metrics",
            "text": " Adding Method-level Annotations The following example adds a new resource class, GreetingCards , to the Helidon MP QuickStart example. It shows how to use the @Counted annotation to track the number of times the /cards endpoint is called. <markup lang=\"java\" title=\"Create a new class GreetingCards with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import jakarta.enterprise.context.RequestScoped; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.annotation.Counted; @Path(\"/cards\") @RequestScoped public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"any-card\") public JsonObject anyCard() throws InterruptedException { return createResponse(\"Here are some random cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } } This class is annotated with Path which sets the path for this resource as /cards . The @RequestScoped annotation defines that this bean is request scoped. The request scope is active only for the duration of one web service invocation and it is destroyed at the end of that invocation. The annotation @Counted will register a Counter metric for this method, creating it if needed. The counter is incremented each time the anyCards method is called. The name attribute is optional. <markup lang=\"bash\" title=\"Build and run the application\" >mvn package java -jar target/helidon-quickstart-mp.jar <markup lang=\"base\" title=\"Access the application endpoints\" >curl http://localhost:8080/cards curl http://localhost:8080/cards curl -H \"Accept: application/json\" 'http://localhost:8080/metrics?scope=application' <markup lang=\"json\" title=\"JSON response:\" >{ \"io.helidon.examples.quickstart.mp.GreetingCards.any-card\": 2, // \"personalizedGets\": 0, \"allGets\": { \"count\": 0, \"elapsedTime\": 0, \"max\": 0, \"mean\": 0 } } The any-card count is two, since you invoked the endpoint twice. The other metrics are from the SimpleGreetResource class. Notice the counter name is fully qualified with the class and method names. You can remove the prefix by using the absolute=true field in the @Counted annotation. You must use absolute=false (the default) for class-level annotations. Additional Method-level Metrics You can also use the @Timed` annotation with a method. For the following example. you can just annotate the same method with @Timed . Timers significant information about the measured methods, but at a cost of some overhead and more complicated output. Note that when using multiple annotations on a method, you must give the metrics different names as shown below (although they do not have to be absolute). <markup lang=\"java\" title=\"Update the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import jakarta.enterprise.context.RequestScoped; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.MetricUnits; import org.eclipse.microprofile.metrics.annotation.Counted; import org.eclipse.microprofile.metrics.annotation.Metered; import org.eclipse.microprofile.metrics.annotation.Timed; @Path(\"/cards\") @RequestScoped public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"cardCount\", absolute = true) @Timed(name = \"cardTimer\", absolute = true, unit = MetricUnits.MILLISECONDS) public JsonObject anyCard() { return createResponse(\"Here are some random cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } } Specify a custom name for the Counter metric and set absolute=true to remove the path prefix from the name. &lt;2&gt;Add the @Timed annotation to get a Timer metric. <markup lang=\"bash\" title=\"Build and run the application\" >mvn package java -jar target/helidon-quickstart-mp.jar <markup lang=\"base\" title=\"Access the application endpoints\" >curl http://localhost:8080/cards curl http://localhost:8080/cards curl -H \"Accept: application/json\" 'http://localhost:8080/metrics?scope=application' <markup lang=\"json\" title=\"JSON response:\" >{ \"cardTimer\": { \"count\": 2, \"elapsedTime\": 0.002941925, \"max\": 0.002919973, \"mean\": 0.0014709625 }, \"personalizedGets\": 0, \"allGets\": { \"count\": 0, \"elapsedTime\": 0, \"max\": 0, \"mean\": 0 }, \"cardCount\": 2 } Class-level Metrics You can collect metrics at the class level to aggregate data from all methods in that class using the same metric. The following example introduces a metric to count all card queries. In the following example, the method-level metrics are not needed to aggregate the counts, but they are left in the example to demonstrate the combined output of all three metrics. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import jakarta.enterprise.context.RequestScoped; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.annotation.Counted; @Path(\"/cards\") @RequestScoped @Counted(name = \"totalCards\") public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) @Counted(absolute = true) public JsonObject anyCard() throws InterruptedException { return createResponse(\"Here are some random cards ...\"); } @Path(\"/birthday\") @GET @Produces(MediaType.APPLICATION_JSON) @Counted(absolute = true) public JsonObject birthdayCard() throws InterruptedException { return createResponse(\"Here are some birthday cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } } This class is now annotated with @Counted , which aggregates count data from all the method that have a Count annotation. Use absolute=true to remove path prefix for method-level annotations. Add a method with a Counter metric to get birthday cards. <markup lang=\"bash\" title=\"Build and run the application\" >mvn package java -jar target/helidon-quickstart-mp.jar <markup lang=\"bash\" title=\"Access the application endpoints\" >curl http://localhost:8080/cards curl http://localhost:8080/cards/birthday curl -H \"Accept: application/json\" 'http://localhost:8080/metrics?scope=application' <markup lang=\"json\" title=\"JSON response from /metrics?scope=application :\" >{ \"birthdayCard\": 1, \"personalizedGets\": 0, \"allGets\": { \"count\": 0, \"elapsedTime\": 0, \"max\": 0, \"mean\": 0 }, \"anyCard\": 1, \"io.helidon.examples.quickstart.mp.totalCards.GreetingCards\": 2 } The totalCards.GreetingCards count is a total of all the method-level Counter metrics. Class level metric names are always fully qualified. Field Level Metrics Field level metrics can be injected into managed objects, but they need to be updated by the application code. This annotation can be used on fields of type Timer , Counter , and Histogram . The following example shows how to use a field-level Counter metric to track cache hits. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import java.util.Random; import jakarta.enterprise.context.RequestScoped; import jakarta.inject.Inject; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.Counter; import org.eclipse.microprofile.metrics.annotation.Counted; import org.eclipse.microprofile.metrics.annotation.Metric; @Path(\"/cards\") @RequestScoped @Counted(name = \"totalCards\") public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @Inject @Metric(name = \"cacheHits\", absolute = true) private Counter cacheHits; @GET @Produces(MediaType.APPLICATION_JSON) @Counted(absolute = true) public JsonObject anyCard() throws InterruptedException { updateStats(); return createResponse(\"Here are some random cards ...\"); } @Path(\"/birthday\") @GET @Produces(MediaType.APPLICATION_JSON) @Counted(absolute = true) public JsonObject birthdayCard() throws InterruptedException { updateStats(); return createResponse(\"Here are some birthday cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } private void updateStats() { if (new Random().nextInt(3) == 1) { cacheHits.inc(); } } } A Counter metric field, cacheHits , is automatically injected by Helidon. Call updateStats() to update the cache hits. Call updateStats() to update the cache hits. Randomly increment the cacheHits counter. <markup lang=\"bash\" title=\"Build and run the application, then invoke the following endpoints:\" >curl http://localhost:8080/cards curl http://localhost:8080/cards curl http://localhost:8080/cards/birthday curl http://localhost:8080/cards/birthday curl http://localhost:8080/cards/birthday curl -H \"Accept: application/json\" 'http://localhost:8080/metrics?scope=application' <markup lang=\"json\" title=\"JSON response from /metrics/application :\" >{ \"birthdayCard\": 3, \"personalizedGets\": 0, \"allGets\": { \"count\": 0, \"elapsedTime\": 0, \"max\": 0, \"mean\": 0 }, \"anyCard\": 2, \"cacheHits\": 2, \"io.helidon.examples.quickstart.mp.totalCards.GreetingCards\": 5 } The cache was hit two times out of five queries. Gauge Metric The metrics you have tested so far are updated in response to an application REST request, i.e GET /cards . These metrics can be declared in a request scoped class and Helidon will store the metric in the MetricRegistry , so the value persists across requests. When GET /metrics?scope=application is invoked, Helidon will return the current value of the metric stored in the MetricRegistry . The Gauge annotation is different from the other metric annotations. The application must provide a method to return the gauge value in an application-scoped class. When GET /metrics?scope=application is invoked, Helidon will call the Gauge method, using the returned value as the value of the gauge as part of the metrics response. The following example demonstrates how to use a Gauge to track application up-time. <markup lang=\"java\" title=\"Create a new GreetingCardsAppMetrics class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.time.Duration; import java.util.concurrent.atomic.AtomicLong; import jakarta.enterprise.context.ApplicationScoped; import jakarta.enterprise.context.Initialized; import jakarta.enterprise.event.Observes; import org.eclipse.microprofile.metrics.annotation.Gauge; @ApplicationScoped public class GreetingCardsAppMetrics { private AtomicLong startTime = new AtomicLong(0); public void onStartUp(@Observes @Initialized(ApplicationScoped.class) Object init) { startTime = new AtomicLong(System.currentTimeMillis()); } @Gauge(unit = \"TimeSeconds\") public long appUpTimeSeconds() { return Duration.ofMillis(System.currentTimeMillis() - startTime.get()).getSeconds(); } } This managed object must be application scoped to properly register and use the annotated Gauge metric. Declare an AtomicLong field to hold the start time of the application. Initialize the application start time. Return the application appUpTimeSeconds metric, which will be included in the application metrics. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code to simplify the metrics output:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import jakarta.enterprise.context.RequestScoped; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.annotation.Counted; @Path(\"/cards\") @RequestScoped public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"cardCount\", absolute = true) public JsonObject anyCard() throws InterruptedException { return createResponse(\"Here are some random cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } } <markup lang=\"bash\" title=\"Build and run the application, then invoke the application metrics endpoint:\" >curl -H \"Accept: application/json\" 'http://localhost:8080/metrics?scope=application' <markup lang=\"json\" title=\"JSON response from /metrics/application :\" >{ \"personalizedGets\": 0, \"allGets\": { \"count\": 0, \"elapsedTime\": 0, \"max\": 0, \"mean\": 0 }, \"io.helidon.examples.quickstart.mp.GreetingCardsAppMetrics.appUpTimeSeconds\": 23, \"cardCount\": 0 } The application has been running for 23 seconds. ",
            "title": "Example Application Code"
        },
        {
            "location": "/mp/metrics/metrics",
            "text": "<markup lang=\"properties\" title=\"Disabling metrics entirely\" >metrics.enabled=false Helidon does not update metrics, and the /metrics endpoints respond with 404 .. ",
            "title": "Disable Metrics Subsystem"
        },
        {
            "location": "/mp/metrics/metrics",
            "text": " Any time you include the Helidon metrics module in your application, Helidon tracks a basic performance indicator metric: a Counter of all requests received ( requests.count ) Helidon MP also includes additional, extended KPI metrics which are disabled by default: current number of requests in-flight - a Gauge ( requests.inFlight ) of requests currently being processed long-running requests - a Counter ( requests.longRunning ) measuring the total number of requests which take at least a given amount of time to complete; configurable, defaults to 10000 milliseconds (10 seconds) load - a Counter ( requests.load ) measuring the number of requests worked on (as opposed to received) deferred - a Gauge ( requests.deferred ) measuring delayed request processing (work on a request was delayed after Helidon received the request) You can enable and control these metrics using configuration: <markup lang=\"properties\" title=\"Controlling extended KPI metrics\" >metrics.key-performance-indicators.extended = true metrics.key-performance-indicators.long-running.threshold-ms = 2000 ",
            "title": "Collecting Basic and Extended Key Performance Indicator (KPI) Metrics"
        },
        {
            "location": "/mp/metrics/metrics",
            "text": "<markup lang=\"properties\" title=\"Controlling REST request metrics\" >metrics.rest-request-enabled=true Helidon automatically registers and updates Timer metrics for every REST endpoint in your service. ",
            "title": "Enable REST.request Metrics"
        },
        {
            "location": "/mp/metrics/metrics",
            "text": " Metrics configuration is quite extensive and powerful and, therefore, a bit complicated. The rest of this section illustrates some of the most common scenarios: Disable metrics entirely. Choose whether to collect extended key performance indicator metrics. Control REST.request metrics collection. Disable Metrics Subsystem <markup lang=\"properties\" title=\"Disabling metrics entirely\" >metrics.enabled=false Helidon does not update metrics, and the /metrics endpoints respond with 404 .. Collecting Basic and Extended Key Performance Indicator (KPI) Metrics Any time you include the Helidon metrics module in your application, Helidon tracks a basic performance indicator metric: a Counter of all requests received ( requests.count ) Helidon MP also includes additional, extended KPI metrics which are disabled by default: current number of requests in-flight - a Gauge ( requests.inFlight ) of requests currently being processed long-running requests - a Counter ( requests.longRunning ) measuring the total number of requests which take at least a given amount of time to complete; configurable, defaults to 10000 milliseconds (10 seconds) load - a Counter ( requests.load ) measuring the number of requests worked on (as opposed to received) deferred - a Gauge ( requests.deferred ) measuring delayed request processing (work on a request was delayed after Helidon received the request) You can enable and control these metrics using configuration: <markup lang=\"properties\" title=\"Controlling extended KPI metrics\" >metrics.key-performance-indicators.extended = true metrics.key-performance-indicators.long-running.threshold-ms = 2000 Enable REST.request Metrics <markup lang=\"properties\" title=\"Controlling REST request metrics\" >metrics.rest-request-enabled=true Helidon automatically registers and updates Timer metrics for every REST endpoint in your service. ",
            "title": "Example Configuration"
        },
        {
            "location": "/mp/metrics/metrics",
            "text": " Helidon MP includes a prewritten example application illustrating enabling/disabling metrics using configuration. The rest of this section contains other examples of working with metrics: Example Application Code Example Configuration Example Application Code Adding Method-level Annotations The following example adds a new resource class, GreetingCards , to the Helidon MP QuickStart example. It shows how to use the @Counted annotation to track the number of times the /cards endpoint is called. <markup lang=\"java\" title=\"Create a new class GreetingCards with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import jakarta.enterprise.context.RequestScoped; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.annotation.Counted; @Path(\"/cards\") @RequestScoped public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"any-card\") public JsonObject anyCard() throws InterruptedException { return createResponse(\"Here are some random cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } } This class is annotated with Path which sets the path for this resource as /cards . The @RequestScoped annotation defines that this bean is request scoped. The request scope is active only for the duration of one web service invocation and it is destroyed at the end of that invocation. The annotation @Counted will register a Counter metric for this method, creating it if needed. The counter is incremented each time the anyCards method is called. The name attribute is optional. <markup lang=\"bash\" title=\"Build and run the application\" >mvn package java -jar target/helidon-quickstart-mp.jar <markup lang=\"base\" title=\"Access the application endpoints\" >curl http://localhost:8080/cards curl http://localhost:8080/cards curl -H \"Accept: application/json\" 'http://localhost:8080/metrics?scope=application' <markup lang=\"json\" title=\"JSON response:\" >{ \"io.helidon.examples.quickstart.mp.GreetingCards.any-card\": 2, // \"personalizedGets\": 0, \"allGets\": { \"count\": 0, \"elapsedTime\": 0, \"max\": 0, \"mean\": 0 } } The any-card count is two, since you invoked the endpoint twice. The other metrics are from the SimpleGreetResource class. Notice the counter name is fully qualified with the class and method names. You can remove the prefix by using the absolute=true field in the @Counted annotation. You must use absolute=false (the default) for class-level annotations. Additional Method-level Metrics You can also use the @Timed` annotation with a method. For the following example. you can just annotate the same method with @Timed . Timers significant information about the measured methods, but at a cost of some overhead and more complicated output. Note that when using multiple annotations on a method, you must give the metrics different names as shown below (although they do not have to be absolute). <markup lang=\"java\" title=\"Update the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import jakarta.enterprise.context.RequestScoped; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.MetricUnits; import org.eclipse.microprofile.metrics.annotation.Counted; import org.eclipse.microprofile.metrics.annotation.Metered; import org.eclipse.microprofile.metrics.annotation.Timed; @Path(\"/cards\") @RequestScoped public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"cardCount\", absolute = true) @Timed(name = \"cardTimer\", absolute = true, unit = MetricUnits.MILLISECONDS) public JsonObject anyCard() { return createResponse(\"Here are some random cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } } Specify a custom name for the Counter metric and set absolute=true to remove the path prefix from the name. &lt;2&gt;Add the @Timed annotation to get a Timer metric. <markup lang=\"bash\" title=\"Build and run the application\" >mvn package java -jar target/helidon-quickstart-mp.jar <markup lang=\"base\" title=\"Access the application endpoints\" >curl http://localhost:8080/cards curl http://localhost:8080/cards curl -H \"Accept: application/json\" 'http://localhost:8080/metrics?scope=application' <markup lang=\"json\" title=\"JSON response:\" >{ \"cardTimer\": { \"count\": 2, \"elapsedTime\": 0.002941925, \"max\": 0.002919973, \"mean\": 0.0014709625 }, \"personalizedGets\": 0, \"allGets\": { \"count\": 0, \"elapsedTime\": 0, \"max\": 0, \"mean\": 0 }, \"cardCount\": 2 } Class-level Metrics You can collect metrics at the class level to aggregate data from all methods in that class using the same metric. The following example introduces a metric to count all card queries. In the following example, the method-level metrics are not needed to aggregate the counts, but they are left in the example to demonstrate the combined output of all three metrics. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import jakarta.enterprise.context.RequestScoped; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.annotation.Counted; @Path(\"/cards\") @RequestScoped @Counted(name = \"totalCards\") public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) @Counted(absolute = true) public JsonObject anyCard() throws InterruptedException { return createResponse(\"Here are some random cards ...\"); } @Path(\"/birthday\") @GET @Produces(MediaType.APPLICATION_JSON) @Counted(absolute = true) public JsonObject birthdayCard() throws InterruptedException { return createResponse(\"Here are some birthday cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } } This class is now annotated with @Counted , which aggregates count data from all the method that have a Count annotation. Use absolute=true to remove path prefix for method-level annotations. Add a method with a Counter metric to get birthday cards. <markup lang=\"bash\" title=\"Build and run the application\" >mvn package java -jar target/helidon-quickstart-mp.jar <markup lang=\"bash\" title=\"Access the application endpoints\" >curl http://localhost:8080/cards curl http://localhost:8080/cards/birthday curl -H \"Accept: application/json\" 'http://localhost:8080/metrics?scope=application' <markup lang=\"json\" title=\"JSON response from /metrics?scope=application :\" >{ \"birthdayCard\": 1, \"personalizedGets\": 0, \"allGets\": { \"count\": 0, \"elapsedTime\": 0, \"max\": 0, \"mean\": 0 }, \"anyCard\": 1, \"io.helidon.examples.quickstart.mp.totalCards.GreetingCards\": 2 } The totalCards.GreetingCards count is a total of all the method-level Counter metrics. Class level metric names are always fully qualified. Field Level Metrics Field level metrics can be injected into managed objects, but they need to be updated by the application code. This annotation can be used on fields of type Timer , Counter , and Histogram . The following example shows how to use a field-level Counter metric to track cache hits. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import java.util.Random; import jakarta.enterprise.context.RequestScoped; import jakarta.inject.Inject; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.Counter; import org.eclipse.microprofile.metrics.annotation.Counted; import org.eclipse.microprofile.metrics.annotation.Metric; @Path(\"/cards\") @RequestScoped @Counted(name = \"totalCards\") public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @Inject @Metric(name = \"cacheHits\", absolute = true) private Counter cacheHits; @GET @Produces(MediaType.APPLICATION_JSON) @Counted(absolute = true) public JsonObject anyCard() throws InterruptedException { updateStats(); return createResponse(\"Here are some random cards ...\"); } @Path(\"/birthday\") @GET @Produces(MediaType.APPLICATION_JSON) @Counted(absolute = true) public JsonObject birthdayCard() throws InterruptedException { updateStats(); return createResponse(\"Here are some birthday cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } private void updateStats() { if (new Random().nextInt(3) == 1) { cacheHits.inc(); } } } A Counter metric field, cacheHits , is automatically injected by Helidon. Call updateStats() to update the cache hits. Call updateStats() to update the cache hits. Randomly increment the cacheHits counter. <markup lang=\"bash\" title=\"Build and run the application, then invoke the following endpoints:\" >curl http://localhost:8080/cards curl http://localhost:8080/cards curl http://localhost:8080/cards/birthday curl http://localhost:8080/cards/birthday curl http://localhost:8080/cards/birthday curl -H \"Accept: application/json\" 'http://localhost:8080/metrics?scope=application' <markup lang=\"json\" title=\"JSON response from /metrics/application :\" >{ \"birthdayCard\": 3, \"personalizedGets\": 0, \"allGets\": { \"count\": 0, \"elapsedTime\": 0, \"max\": 0, \"mean\": 0 }, \"anyCard\": 2, \"cacheHits\": 2, \"io.helidon.examples.quickstart.mp.totalCards.GreetingCards\": 5 } The cache was hit two times out of five queries. Gauge Metric The metrics you have tested so far are updated in response to an application REST request, i.e GET /cards . These metrics can be declared in a request scoped class and Helidon will store the metric in the MetricRegistry , so the value persists across requests. When GET /metrics?scope=application is invoked, Helidon will return the current value of the metric stored in the MetricRegistry . The Gauge annotation is different from the other metric annotations. The application must provide a method to return the gauge value in an application-scoped class. When GET /metrics?scope=application is invoked, Helidon will call the Gauge method, using the returned value as the value of the gauge as part of the metrics response. The following example demonstrates how to use a Gauge to track application up-time. <markup lang=\"java\" title=\"Create a new GreetingCardsAppMetrics class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.time.Duration; import java.util.concurrent.atomic.AtomicLong; import jakarta.enterprise.context.ApplicationScoped; import jakarta.enterprise.context.Initialized; import jakarta.enterprise.event.Observes; import org.eclipse.microprofile.metrics.annotation.Gauge; @ApplicationScoped public class GreetingCardsAppMetrics { private AtomicLong startTime = new AtomicLong(0); public void onStartUp(@Observes @Initialized(ApplicationScoped.class) Object init) { startTime = new AtomicLong(System.currentTimeMillis()); } @Gauge(unit = \"TimeSeconds\") public long appUpTimeSeconds() { return Duration.ofMillis(System.currentTimeMillis() - startTime.get()).getSeconds(); } } This managed object must be application scoped to properly register and use the annotated Gauge metric. Declare an AtomicLong field to hold the start time of the application. Initialize the application start time. Return the application appUpTimeSeconds metric, which will be included in the application metrics. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code to simplify the metrics output:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import jakarta.enterprise.context.RequestScoped; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.annotation.Counted; @Path(\"/cards\") @RequestScoped public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"cardCount\", absolute = true) public JsonObject anyCard() throws InterruptedException { return createResponse(\"Here are some random cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } } <markup lang=\"bash\" title=\"Build and run the application, then invoke the application metrics endpoint:\" >curl -H \"Accept: application/json\" 'http://localhost:8080/metrics?scope=application' <markup lang=\"json\" title=\"JSON response from /metrics/application :\" >{ \"personalizedGets\": 0, \"allGets\": { \"count\": 0, \"elapsedTime\": 0, \"max\": 0, \"mean\": 0 }, \"io.helidon.examples.quickstart.mp.GreetingCardsAppMetrics.appUpTimeSeconds\": 23, \"cardCount\": 0 } The application has been running for 23 seconds. Example Configuration Metrics configuration is quite extensive and powerful and, therefore, a bit complicated. The rest of this section illustrates some of the most common scenarios: Disable metrics entirely. Choose whether to collect extended key performance indicator metrics. Control REST.request metrics collection. Disable Metrics Subsystem <markup lang=\"properties\" title=\"Disabling metrics entirely\" >metrics.enabled=false Helidon does not update metrics, and the /metrics endpoints respond with 404 .. Collecting Basic and Extended Key Performance Indicator (KPI) Metrics Any time you include the Helidon metrics module in your application, Helidon tracks a basic performance indicator metric: a Counter of all requests received ( requests.count ) Helidon MP also includes additional, extended KPI metrics which are disabled by default: current number of requests in-flight - a Gauge ( requests.inFlight ) of requests currently being processed long-running requests - a Counter ( requests.longRunning ) measuring the total number of requests which take at least a given amount of time to complete; configurable, defaults to 10000 milliseconds (10 seconds) load - a Counter ( requests.load ) measuring the number of requests worked on (as opposed to received) deferred - a Gauge ( requests.deferred ) measuring delayed request processing (work on a request was delayed after Helidon received the request) You can enable and control these metrics using configuration: <markup lang=\"properties\" title=\"Controlling extended KPI metrics\" >metrics.key-performance-indicators.extended = true metrics.key-performance-indicators.long-running.threshold-ms = 2000 Enable REST.request Metrics <markup lang=\"properties\" title=\"Controlling REST request metrics\" >metrics.rest-request-enabled=true Helidon automatically registers and updates Timer metrics for every REST endpoint in your service. ",
            "title": "Examples"
        },
        {
            "location": "/mp/metrics/metrics",
            "text": " The following example shows how to integrate the Helidon MP application with Kubernetes. <markup lang=\"bash\" title=\"Stop the application and build the docker image:\" >docker build -t helidon-metrics-mp . <markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named metrics.yaml , with the following content:\" >kind: Service apiVersion: v1 metadata: name: helidon-metrics labels: app: helidon-metrics annotations: prometheus.io/scrape: true spec: type: NodePort selector: app: helidon-metrics ports: - port: 8080 targetPort: 8080 name: http --- kind: Deployment apiVersion: apps/v1 metadata: name: helidon-metrics spec: replicas: 1 selector: matchLabels: app: helidon-metrics template: metadata: labels: app: helidon-metrics version: v1 spec: containers: - name: helidon-metrics image: helidon-metrics-mp imagePullPolicy: IfNotPresent ports: - containerPort: 8080 A service of type NodePort that serves the default routes on port 8080 . An annotation that will allow Prometheus to discover and scrape the application pod. A deployment with one replica of a pod. <markup lang=\"bash\" title=\"Create and deploy the application into Kubernetes:\" >kubectl apply -f ./metrics.yaml <markup lang=\"bash\" title=\"Get the service information:\" >kubectl get service/helidon-metrics <markup lang=\"bash\" >NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE helidon-metrics NodePort 10.99.159.2 &lt;none&gt; 8080:31143/TCP 8s A service of type NodePort that serves the default routes on port 31143 . <markup lang=\"bash\" title=\"Verify the metrics endpoint using port 30116 , your port will likely be different:\" >curl http://localhost:31143/metrics Leave the application running in Kubernetes since it will be used for Prometheus integration. ",
            "title": "Kubernetes Integration"
        },
        {
            "location": "/mp/metrics/metrics",
            "text": " The metrics service that you just deployed into Kubernetes is already annotated with prometheus.io/scrape: . This will allow Prometheus to discover the service and scrape the metrics. This example shows how to install Prometheus into Kubernetes, then verify that it discovered the Helidon metrics in your application. <markup lang=\"bash\" title=\"Install Prometheus and wait until the pod is ready:\" >helm install stable/prometheus --name metrics export POD_NAME=$(kubectl get pods --namespace default -l \"app=prometheus,component=server\" -o jsonpath=\"{.items[0].metadata.name}\") kubectl get pod $POD_NAME You will see output similar to the following. Repeat the kubectl get pod command until you see 2/2 and Running . This may take up to one minute. <markup lang=\"bash\" >metrics-prometheus-server-5fc5dc86cb-79lk4 2/2 Running 0 46s <markup lang=\"bash\" title=\"Create a port-forward so you can access the server URL:\" >kubectl --namespace default port-forward $POD_NAME 7090:9090 Now open your browser and navigate to http://localhost:7090/targets . Search for helidon on the page and you will see your Helidon application as one of the Prometheus targets. ",
            "title": "Prometheus Integration"
        },
        {
            "location": "/mp/metrics/metrics",
            "text": " You can now delete the Kubernetes resources that were just created during this example. <markup lang=\"bash\" title=\"Delete the Prometheus Kubernetes resources:\" >helm delete --purge metrics <markup lang=\"bash\" title=\"Delete the application Kubernetes resources:\" >kubectl delete -f ./metrics.yaml ",
            "title": "Final Cleanup"
        },
        {
            "location": "/mp/metrics/metrics",
            "text": " Kubernetes Integration The following example shows how to integrate the Helidon MP application with Kubernetes. <markup lang=\"bash\" title=\"Stop the application and build the docker image:\" >docker build -t helidon-metrics-mp . <markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named metrics.yaml , with the following content:\" >kind: Service apiVersion: v1 metadata: name: helidon-metrics labels: app: helidon-metrics annotations: prometheus.io/scrape: true spec: type: NodePort selector: app: helidon-metrics ports: - port: 8080 targetPort: 8080 name: http --- kind: Deployment apiVersion: apps/v1 metadata: name: helidon-metrics spec: replicas: 1 selector: matchLabels: app: helidon-metrics template: metadata: labels: app: helidon-metrics version: v1 spec: containers: - name: helidon-metrics image: helidon-metrics-mp imagePullPolicy: IfNotPresent ports: - containerPort: 8080 A service of type NodePort that serves the default routes on port 8080 . An annotation that will allow Prometheus to discover and scrape the application pod. A deployment with one replica of a pod. <markup lang=\"bash\" title=\"Create and deploy the application into Kubernetes:\" >kubectl apply -f ./metrics.yaml <markup lang=\"bash\" title=\"Get the service information:\" >kubectl get service/helidon-metrics <markup lang=\"bash\" >NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE helidon-metrics NodePort 10.99.159.2 &lt;none&gt; 8080:31143/TCP 8s A service of type NodePort that serves the default routes on port 31143 . <markup lang=\"bash\" title=\"Verify the metrics endpoint using port 30116 , your port will likely be different:\" >curl http://localhost:31143/metrics Leave the application running in Kubernetes since it will be used for Prometheus integration. Prometheus Integration The metrics service that you just deployed into Kubernetes is already annotated with prometheus.io/scrape: . This will allow Prometheus to discover the service and scrape the metrics. This example shows how to install Prometheus into Kubernetes, then verify that it discovered the Helidon metrics in your application. <markup lang=\"bash\" title=\"Install Prometheus and wait until the pod is ready:\" >helm install stable/prometheus --name metrics export POD_NAME=$(kubectl get pods --namespace default -l \"app=prometheus,component=server\" -o jsonpath=\"{.items[0].metadata.name}\") kubectl get pod $POD_NAME You will see output similar to the following. Repeat the kubectl get pod command until you see 2/2 and Running . This may take up to one minute. <markup lang=\"bash\" >metrics-prometheus-server-5fc5dc86cb-79lk4 2/2 Running 0 46s <markup lang=\"bash\" title=\"Create a port-forward so you can access the server URL:\" >kubectl --namespace default port-forward $POD_NAME 7090:9090 Now open your browser and navigate to http://localhost:7090/targets . Search for helidon on the page and you will see your Helidon application as one of the Prometheus targets. Final Cleanup You can now delete the Kubernetes resources that were just created during this example. <markup lang=\"bash\" title=\"Delete the Prometheus Kubernetes resources:\" >helm delete --purge metrics <markup lang=\"bash\" title=\"Delete the application Kubernetes resources:\" >kubectl delete -f ./metrics.yaml ",
            "title": "Integration with Kubernetes and Prometheus"
        },
        {
            "location": "/mp/metrics/metrics",
            "text": " MicroProfile Metrics specification MicroProfile Metrics API ",
            "title": "References"
        },
        {
            "location": "/mp/metrics/metrics",
            "text": " Integration with Kubernetes and Prometheus Kubernetes Integration The following example shows how to integrate the Helidon MP application with Kubernetes. <markup lang=\"bash\" title=\"Stop the application and build the docker image:\" >docker build -t helidon-metrics-mp . <markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named metrics.yaml , with the following content:\" >kind: Service apiVersion: v1 metadata: name: helidon-metrics labels: app: helidon-metrics annotations: prometheus.io/scrape: true spec: type: NodePort selector: app: helidon-metrics ports: - port: 8080 targetPort: 8080 name: http --- kind: Deployment apiVersion: apps/v1 metadata: name: helidon-metrics spec: replicas: 1 selector: matchLabels: app: helidon-metrics template: metadata: labels: app: helidon-metrics version: v1 spec: containers: - name: helidon-metrics image: helidon-metrics-mp imagePullPolicy: IfNotPresent ports: - containerPort: 8080 A service of type NodePort that serves the default routes on port 8080 . An annotation that will allow Prometheus to discover and scrape the application pod. A deployment with one replica of a pod. <markup lang=\"bash\" title=\"Create and deploy the application into Kubernetes:\" >kubectl apply -f ./metrics.yaml <markup lang=\"bash\" title=\"Get the service information:\" >kubectl get service/helidon-metrics <markup lang=\"bash\" >NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE helidon-metrics NodePort 10.99.159.2 &lt;none&gt; 8080:31143/TCP 8s A service of type NodePort that serves the default routes on port 31143 . <markup lang=\"bash\" title=\"Verify the metrics endpoint using port 30116 , your port will likely be different:\" >curl http://localhost:31143/metrics Leave the application running in Kubernetes since it will be used for Prometheus integration. Prometheus Integration The metrics service that you just deployed into Kubernetes is already annotated with prometheus.io/scrape: . This will allow Prometheus to discover the service and scrape the metrics. This example shows how to install Prometheus into Kubernetes, then verify that it discovered the Helidon metrics in your application. <markup lang=\"bash\" title=\"Install Prometheus and wait until the pod is ready:\" >helm install stable/prometheus --name metrics export POD_NAME=$(kubectl get pods --namespace default -l \"app=prometheus,component=server\" -o jsonpath=\"{.items[0].metadata.name}\") kubectl get pod $POD_NAME You will see output similar to the following. Repeat the kubectl get pod command until you see 2/2 and Running . This may take up to one minute. <markup lang=\"bash\" >metrics-prometheus-server-5fc5dc86cb-79lk4 2/2 Running 0 46s <markup lang=\"bash\" title=\"Create a port-forward so you can access the server URL:\" >kubectl --namespace default port-forward $POD_NAME 7090:9090 Now open your browser and navigate to http://localhost:7090/targets . Search for helidon on the page and you will see your Helidon application as one of the Prometheus targets. Final Cleanup You can now delete the Kubernetes resources that were just created during this example. <markup lang=\"bash\" title=\"Delete the Prometheus Kubernetes resources:\" >helm delete --purge metrics <markup lang=\"bash\" title=\"Delete the application Kubernetes resources:\" >kubectl delete -f ./metrics.yaml References MicroProfile Metrics specification MicroProfile Metrics API ",
            "title": "Additional Information"
        },
        {
            "location": "/mp/metrics/micrometer",
            "text": " Overview Maven Coordinates Usage API Configuration Examples Additional Information ",
            "title": "Contents"
        },
        {
            "location": "/mp/metrics/micrometer",
            "text": " Helidon MP simplifies how you can use Micrometer for application-specific metrics: The endpoint /micrometer : A configurable endpoint that exposes metrics according to which Micrometer meter registry responds to the HTTP request. The Micrometer annotations @Timed and @Counted . Configuration to tailor the Prometheus and other Micrometer meter registries. In Helidon 4.0.2, Micrometer support is separate from the Helidon MP metrics API and the built-in Helidon metrics. ",
            "title": "Overview"
        },
        {
            "location": "/mp/metrics/micrometer",
            "text": " To enable Micrometer support add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.micrometer&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-micrometer-cdi&lt;/artifactId&gt; &lt;/dependency&gt; Micrometer supports different types of meter registries which have different output styles and formats. Helidon provides built-in support for the Prometheus meter registry. To use other meter registry types, you will need to add dependencies for them to your pom.xml and, optionally, add configuration to set them up as you wish. ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/metrics/micrometer",
            "text": " To use Micrometer support, you can simply add the Micrometer @Timed and @Counted annotations to methods in your application. Helidon automatically registers those meters with the Micrometer composite MeterRegistry . In addition to annotating your methods, your code can create, look up, and update metrics programmatically using the Micrometer MeterRegistry API. The Micrometer concepts document provides a good starting point for learning how to use Micrometer&#8217;s interfaces and classes. ",
            "title": "Registering and Updating Meters"
        },
        {
            "location": "/mp/metrics/micrometer",
            "text": " Helidon MP Micrometer integration automatically creates a REST endpoint which clients can access to retrieve Micrometer metrics, by default at the /micrometer endpoint. ",
            "title": "Accessing the Helidon Micrometer Endpoint"
        },
        {
            "location": "/mp/metrics/micrometer",
            "text": " Your application registers and updates Micrometer meters using annotations or direct use of the Micrometer API. Your users retrieve Micrometer meters using an endpoint which Helidon creates automatically. Registering and Updating Meters To use Micrometer support, you can simply add the Micrometer @Timed and @Counted annotations to methods in your application. Helidon automatically registers those meters with the Micrometer composite MeterRegistry . In addition to annotating your methods, your code can create, look up, and update metrics programmatically using the Micrometer MeterRegistry API. The Micrometer concepts document provides a good starting point for learning how to use Micrometer&#8217;s interfaces and classes. Accessing the Helidon Micrometer Endpoint Helidon MP Micrometer integration automatically creates a REST endpoint which clients can access to retrieve Micrometer metrics, by default at the /micrometer endpoint. ",
            "title": "Usage"
        },
        {
            "location": "/mp/metrics/micrometer",
            "text": " Helidon automatically registers and updates meters associated with methods in your service where you add the Micrometer annotations. If you want to use the Micrometer MeterRegistry directly from your own code, simply @Inject the MeterRegistry into one of your REST resource classes or any other bean which CDI recognizes. Helidon injects the same Micrometer MeterRegistry that it uses for handling Micrometer annotations you add to your code. ",
            "title": "The Helidon Micrometer API"
        },
        {
            "location": "/mp/metrics/micrometer",
            "text": " Your code can create, look up, and update metrics programmatically using the Micrometer MeterRegistry API. The Micrometer concepts document provides a good starting point for learning how to use Micrometer&#8217;s interfaces and classes. ",
            "title": "The Micrometer API"
        },
        {
            "location": "/mp/metrics/micrometer",
            "text": " To incorporate Micrometer metrics into your code, you will work with two APIs: a small one specific to Helidon, and the Micrometer API itself. The Helidon Micrometer API Helidon automatically registers and updates meters associated with methods in your service where you add the Micrometer annotations. If you want to use the Micrometer MeterRegistry directly from your own code, simply @Inject the MeterRegistry into one of your REST resource classes or any other bean which CDI recognizes. Helidon injects the same Micrometer MeterRegistry that it uses for handling Micrometer annotations you add to your code. The Micrometer API Your code can create, look up, and update metrics programmatically using the Micrometer MeterRegistry API. The Micrometer concepts document provides a good starting point for learning how to use Micrometer&#8217;s interfaces and classes. ",
            "title": "API"
        },
        {
            "location": "/mp/metrics/micrometer",
            "text": " Optional configuration options key type default value description cross-origin-config CrossOriginConfig &#160; Set the CORS config from the specified CrossOriginConfig object. web-context string &#160; Set the root context for the REST API of the service. By default, Helidon Micrometer integration exposes the /micrometer endpoint. You can override the path using the micrometer.web-context configuration key. <markup lang=\"properties\" title=\"Overriding the default Micrometer path\" >micrometer.web-context=my-micrometer ",
            "title": "Configuration options"
        },
        {
            "location": "/mp/metrics/micrometer",
            "text": " You can configure the Helidon Micrometer REST service as you can other built-in Helidon services by adding configuration settings under the micrometer top-level key. Type: io.helidon.integrations.micrometer.MicrometerFeature <markup lang=\"text\" title=\"Config key\" >micrometer Configuration options Optional configuration options key type default value description cross-origin-config CrossOriginConfig &#160; Set the CORS config from the specified CrossOriginConfig object. web-context string &#160; Set the root context for the REST API of the service. By default, Helidon Micrometer integration exposes the /micrometer endpoint. You can override the path using the micrometer.web-context configuration key. <markup lang=\"properties\" title=\"Overriding the default Micrometer path\" >micrometer.web-context=my-micrometer ",
            "title": "Configuration"
        },
        {
            "location": "/mp/metrics/micrometer",
            "text": "<markup lang=\"java\" title=\"Adding Micrometer annotations to JAX-RS resource GET methods\" >import io.micrometer.core.annotation.Counted; import io.micrometer.core.annotation.Timed; private static final String PERSONALIZED_GETS_COUNTER_NAME = \"personalizedGets\"; private static final String PERSONALIZED_GETS_COUNTER_DESCRIPTION = \"Counts personalized GET operations\"; private static final String GETS_TIMER_NAME = \"allGets\"; private static final String GETS_TIMER_DESCRIPTION = \"Tracks all GET operations\"; @GET @Produces(MediaType.APPLICATION_JSON) @Timed(value = GETS_TIMER_NAME, description = GETS_TIMER_DESCRIPTION, histogram = true) public JsonObject getDefaultMessage() { return createResponse(\"World\"); } @Path(\"/{name}\") @GET @Produces(MediaType.APPLICATION_JSON) @Counted(value = PERSONALIZED_GETS_COUNTER_NAME, description = PERSONALIZED_GETS_COUNTER_DESCRIPTION) @Timed(value = GETS_TIMER_NAME, description = GETS_TIMER_DESCRIPTION, histogram = true) public JsonObject getMessage(@PathParam(\"name\") String name) { return createResponse(name); } Declare constants used in annotating multiple methods. Use @Timed to time and count both GET methods. Use @Counted to count the accesses to the GET method that returns a personalized greeting. ",
            "title": "Add Micrometer annotations"
        },
        {
            "location": "/mp/metrics/micrometer",
            "text": " Unless you specify otherwise, Helidon uses defaults for any built-in Micrometer meter registry. For example, Helidon configures the built-in Prometheus registry using PrometheusConfig.DEFAULT . To use configuration to control the selection and behavior of Helidon&#8217;s built-in Micrometer meter registries, include in your configuration (such as application.yaml ) a micrometer.builtin-registries section. <markup lang=\"properties\" title=\"Enroll Prometheus built-in meter registry using default configuration\" >micrometer.builtin-registries.0.type=prometheus <markup lang=\"properties\" title=\"Enroll Prometheus built-in meter registry with non-default configuration\" >micrometer.builtin-registries.0.type=prometheus micrometer.builtin-registries.0.prefix=myPrefix Note that the first config example is equivalent to the default Helidon Micrometer behavior; Helidon by default supports the Prometheus meter registry. The configuration keys that are valid for the builtin-registries child entries depend on the type of Micrometer meter registry. For example, support in Helidon for the Prometheus meter registry respects the prefix configuration setting but other meter registries might not and might support other settings. Refer to the documentation for the meter registry you want to configure to find out what items apply to that registry type. Helidon does not validate the configuration keys you specify for meter registries. ",
            "title": "Overriding Defaults for Built-in Meter Registry Types"
        },
        {
            "location": "/mp/metrics/micrometer",
            "text": " In addition to annotating your methods, you can create, look up, and update metrics explicitly in your code. Add the following injection to a bean: <markup lang=\"java\" title=\"Inject the MeterRegistry \" >@Inject private MeterRegistry registry; Helidon automatically injects a reference to the MeterRegistry it manages into your code. Your code can use the normal Micrometer API with this registry to create, find, update, and even delete meters. Overriding Defaults for Built-in Meter Registry Types Unless you specify otherwise, Helidon uses defaults for any built-in Micrometer meter registry. For example, Helidon configures the built-in Prometheus registry using PrometheusConfig.DEFAULT . To use configuration to control the selection and behavior of Helidon&#8217;s built-in Micrometer meter registries, include in your configuration (such as application.yaml ) a micrometer.builtin-registries section. <markup lang=\"properties\" title=\"Enroll Prometheus built-in meter registry using default configuration\" >micrometer.builtin-registries.0.type=prometheus <markup lang=\"properties\" title=\"Enroll Prometheus built-in meter registry with non-default configuration\" >micrometer.builtin-registries.0.type=prometheus micrometer.builtin-registries.0.prefix=myPrefix Note that the first config example is equivalent to the default Helidon Micrometer behavior; Helidon by default supports the Prometheus meter registry. The configuration keys that are valid for the builtin-registries child entries depend on the type of Micrometer meter registry. For example, support in Helidon for the Prometheus meter registry respects the prefix configuration setting but other meter registries might not and might support other settings. Refer to the documentation for the meter registry you want to configure to find out what items apply to that registry type. Helidon does not validate the configuration keys you specify for meter registries. ",
            "title": "Using the Helidon-provided Micrometer MeterRegistry from Code"
        },
        {
            "location": "/mp/metrics/micrometer",
            "text": " Helidon MP includes an example application which uses Micrometer support. The examples below take you step-by-step through the process of enhancing the Helidon MP QuickStart application to track (by time and invocation count) all GET methods and to count all requests for a personalized greeting. Add Micrometer annotations <markup lang=\"java\" title=\"Adding Micrometer annotations to JAX-RS resource GET methods\" >import io.micrometer.core.annotation.Counted; import io.micrometer.core.annotation.Timed; private static final String PERSONALIZED_GETS_COUNTER_NAME = \"personalizedGets\"; private static final String PERSONALIZED_GETS_COUNTER_DESCRIPTION = \"Counts personalized GET operations\"; private static final String GETS_TIMER_NAME = \"allGets\"; private static final String GETS_TIMER_DESCRIPTION = \"Tracks all GET operations\"; @GET @Produces(MediaType.APPLICATION_JSON) @Timed(value = GETS_TIMER_NAME, description = GETS_TIMER_DESCRIPTION, histogram = true) public JsonObject getDefaultMessage() { return createResponse(\"World\"); } @Path(\"/{name}\") @GET @Produces(MediaType.APPLICATION_JSON) @Counted(value = PERSONALIZED_GETS_COUNTER_NAME, description = PERSONALIZED_GETS_COUNTER_DESCRIPTION) @Timed(value = GETS_TIMER_NAME, description = GETS_TIMER_DESCRIPTION, histogram = true) public JsonObject getMessage(@PathParam(\"name\") String name) { return createResponse(name); } Declare constants used in annotating multiple methods. Use @Timed to time and count both GET methods. Use @Counted to count the accesses to the GET method that returns a personalized greeting. Using the Helidon-provided Micrometer MeterRegistry from Code In addition to annotating your methods, you can create, look up, and update metrics explicitly in your code. Add the following injection to a bean: <markup lang=\"java\" title=\"Inject the MeterRegistry \" >@Inject private MeterRegistry registry; Helidon automatically injects a reference to the MeterRegistry it manages into your code. Your code can use the normal Micrometer API with this registry to create, find, update, and even delete meters. Overriding Defaults for Built-in Meter Registry Types Unless you specify otherwise, Helidon uses defaults for any built-in Micrometer meter registry. For example, Helidon configures the built-in Prometheus registry using PrometheusConfig.DEFAULT . To use configuration to control the selection and behavior of Helidon&#8217;s built-in Micrometer meter registries, include in your configuration (such as application.yaml ) a micrometer.builtin-registries section. <markup lang=\"properties\" title=\"Enroll Prometheus built-in meter registry using default configuration\" >micrometer.builtin-registries.0.type=prometheus <markup lang=\"properties\" title=\"Enroll Prometheus built-in meter registry with non-default configuration\" >micrometer.builtin-registries.0.type=prometheus micrometer.builtin-registries.0.prefix=myPrefix Note that the first config example is equivalent to the default Helidon Micrometer behavior; Helidon by default supports the Prometheus meter registry. The configuration keys that are valid for the builtin-registries child entries depend on the type of Micrometer meter registry. For example, support in Helidon for the Prometheus meter registry respects the prefix configuration setting but other meter registries might not and might support other settings. Refer to the documentation for the meter registry you want to configure to find out what items apply to that registry type. Helidon does not validate the configuration keys you specify for meter registries. ",
            "title": "Examples"
        },
        {
            "location": "/mp/metrics/micrometer",
            "text": " The Micrometer website describes the project as a whole and has links to more information. ",
            "title": "Additional Information"
        },
        {
            "location": "/mp/metrics/prometheus-exemplar-support",
            "text": " Overview Maven Coordinates Usage Examples Additional Information ",
            "title": "Contents"
        },
        {
            "location": "/mp/metrics/prometheus-exemplar-support",
            "text": " A meter typically reflects the usage of a single point in your service which processes multiple requests over time. A value such as the total time consumed by a given REST endpoint which can be invoked multiple times underscores the aggregate nature of meter values; Helidon accumulates the time from all requests in the total duration. Tracing, on the other hand, captures the usage of multiple parts of your code as your service responds to a single request. Metrics and tracing come together in Helidon&#8217;s support for exemplars. Note exemplar - one that serves as a model or example &#8201;&#8212;&#8201;Merriam-Webster Dictionary In the context of metrics, an exemplar for a given meter is a specific sample which, in some sense, made a typical contribution to the meter&#8217;s value. For example, an exemplar for a Counter might be the most recent sample which updated the counter. The metrics output identifies the exemplar sample using the span and trace IDs of the span and trace which triggered that sample. Exemplar support in Helidon relies on the exemplar support provided by the underlying metrics implementation. Currently, Helidon&#8217;s Micrometer implementation supports exemplars as recorded by Micrometer&#8217;s Prometheus meter registry and exposed by the OpenMetrics output (media type application/openmetrics-text ). ",
            "title": "Overview"
        },
        {
            "location": "/mp/metrics/prometheus-exemplar-support",
            "text": " To enable OpenMetrics exemplar support add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics-trace-exemplar&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; Also, include the Helidon integration module for a tracing implementation (such as Helidon Zipkin ) <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-providers-zipkin&lt;/artifactId&gt; &lt;/dependency&gt; Add the Helidon tracing component itself: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-tracing&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/metrics/prometheus-exemplar-support",
            "text": " Each exemplar reflects a sample described by a label, a value, and a timestamp. When a client accesses the /metrics endpoint and specifies that it accepts the application/openmetrics-text media type, the label, value, and timestamp appear in the OpenMetrics response for meters that support exemplars. The exemplar information in the output describes a single, actual sample that is representative of the statistical value as recorded by the underlying Micrometer Prometheus meter registry. ",
            "title": "Interpreting Exemplars"
        },
        {
            "location": "/mp/metrics/prometheus-exemplar-support",
            "text": " In the OpenMetrics output, an exemplar actually appears as a comment appended to the normal OpenMetrics output. <markup title=\"OpenMetrics format with exemplars\" > meter-identifier meter-value # exemplar-label sample-timestamp Even downstream consumers of OpenMetrics output that do not recognize the exemplar format should continue to work correctly (as long as they do recognize comments). But some consumers, such as trace collectors and their UIs, understand the exemplar format, and they allow you to browse meters and then navigate directly to the trace for the meter&#8217;s exemplar. ",
            "title": "Output Format"
        },
        {
            "location": "/mp/metrics/prometheus-exemplar-support",
            "text": " Once you add the appropriate dependencies to your project, exemplar support runs automatically as part of the Helidon metrics implementation using Micrometer. You do not need to change your application or configuration. Interpreting Exemplars Each exemplar reflects a sample described by a label, a value, and a timestamp. When a client accesses the /metrics endpoint and specifies that it accepts the application/openmetrics-text media type, the label, value, and timestamp appear in the OpenMetrics response for meters that support exemplars. The exemplar information in the output describes a single, actual sample that is representative of the statistical value as recorded by the underlying Micrometer Prometheus meter registry. Output Format In the OpenMetrics output, an exemplar actually appears as a comment appended to the normal OpenMetrics output. <markup title=\"OpenMetrics format with exemplars\" > meter-identifier meter-value # exemplar-label sample-timestamp Even downstream consumers of OpenMetrics output that do not recognize the exemplar format should continue to work correctly (as long as they do recognize comments). But some consumers, such as trace collectors and their UIs, understand the exemplar format, and they allow you to browse meters and then navigate directly to the trace for the meter&#8217;s exemplar. ",
            "title": "Usage"
        },
        {
            "location": "/mp/metrics/prometheus-exemplar-support",
            "text": " Once you enable exemplar support you can see the exemplars in the metrics output. # TYPE counterForPersonalizedGreetings counter # HELP counterForPersonalizedGreetings counterForPersonalizedGreetings_total{scope=\"application\"} 4.0 # {span_id=\"6b1fc9f9fd42fb0c\",trace_id=\"6b1fc9f9fd42fb0c\"} 1.0 1696889651.779 The exemplar (the portion following the # ) is a sample corresponding to an update to the counter, showing the span and trace identifiers, the amount by which the counter was updated ( 1.0 ), and the timestamp recording when the update occurred expressed as seconds in the UNIX epoch ( 1696889651.779 ). ",
            "title": "Examples"
        },
        {
            "location": "/mp/metrics/prometheus-exemplar-support",
            "text": " Brief discussion of exemplars in the OpenMetrics spec ",
            "title": "Additional Information"
        },
        {
            "location": "/mp/openapi/openapi-generator",
            "text": " Overview Maven Coordinates Configuration Usage References ",
            "title": "Contents"
        },
        {
            "location": "/mp/openapi/openapi-generator",
            "text": " The OpenAPI specification provides a standard way to express RESTful APIs. Separately, the OpenAPI generator project has created a powerful code generator tool which accepts an OpenAPI document and generates client and server code for many languages and frameworks. The Helidon team contributes to this tool to ensure that it provides strong support for Helidon MP clients and servers. As a result, you can use the generator to create code that fits smoothly into your Helidon applications. The OpenAPI generator release 6.2.1 gained particularly strong support for Helidon. This document applies to that release and later ones. In the vocabulary of the tool, there are two generators for Helidon: java-helidon-client (hereafter the Helidon client generator) java-helidon-server (hereafter the Helidon server generator). Each of these generators supports two libraries : mp - for Helidon MP code generation se - for Helidon SE code generation Use the Helidon client generator and its mp library to create a Helidon MicroProfile REST client . The resulting client library works with any server that implements the API declared in the OpenAPI document you specified when you ran the generator. The client library provides an abstraction similar to remote procedure calls (RPC). To access a remote service that implements the endpoints declared in the OpenAPI document, your code uses the generated client library first to establish a connection to the remote service and then to call remote service endpoints by invoking local methods passing POJO business objects or Java types as arguments. Use the tool&#8217;s Helidon server generator and its mp library to create server endpoint stubs for a Helidon MP service. You build on these stubs by extending a generated class or implementing a generated interface, adding your specific business logic to finish the implementation of the endpoints. The combination of the generated server code plus Helidon MP underneath it allows you to focus on the business details instead of resource boilerplate. You can run the OpenAPI generators in three ways: using the OpenAPI generator CLI using the OpenAPI generator Maven plug-in using the online OpenAPI generator website The rest of this document walks you through how to use each technique and how to configure the generators to produce the code you want. ",
            "title": "Overview"
        },
        {
            "location": "/mp/openapi/openapi-generator",
            "text": " Your project does not need any dependencies on the OpenAPI generator. To use the OpenAPI generator plug-in to generate or regenerate files during your project build, add the following to your project&#8217;s pom.xml file to declare the plug-in. Choose whichever version of the generator plug-in meets your needs as long as it is at least 6.2.1. <markup lang=\"xml\" title=\"Declaring the OpenAPI Generator Plug-in\" >&lt;properties&gt; &lt;openapi-generator-version&gt;6.2.1&lt;/openapi-generator-version&gt; &lt;/properties&gt; ... &lt;build&gt; ... &lt;plugin-management&gt; ... &lt;plugin&gt; &lt;groupId&gt;org.openapitools&lt;/groupId&gt; &lt;artifactId&gt;openapi-generator-maven-plugin&lt;/artifactId&gt; &lt;version&gt;${openapi-generator-version}&lt;/version&gt; &lt;/plugin&gt; ... &lt;/plugin-management&gt; ... &lt;/build&gt; A later section describes how to invoke the plug-in during your build. ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/openapi/openapi-generator",
            "text": " You must specify the following options: Required OpenAPI Generator Options Option Short Option Plug-in Setting Description Values --inputSpec -i &lt;inputSpec&gt; Path to the OpenAPI document defining the REST API --generatorName -g &lt;generatorName&gt; Generator you want to use ( java-helidon-server or java-helidon-client ) java-helidon-server java-helidon-client ",
            "title": "Required Settings"
        },
        {
            "location": "/mp/openapi/openapi-generator",
            "text": " Your project might have different needs, but in general we advise developers to use the following settings when using the OpenAPI generator. Recommended OpenAPI Generator Additional Properties Property Description Default apiPackage Name of the package for generated API interfaces/classes org.openapitools.server.api or org.openapitools.client.api modelPackage Name of the package for generated model (POJO) classes org.openapitools.server.model or org.openapitools.client.model invokerPackage Name of the package for generated driver classes org.openapitools.server or org.openapitools.client groupId Group ID in the generated pom.xml org.openapitools artifactId Artifact ID in the generated pom.xml openapi-java-server or openapi-java-client artifactVersion Artifact version in the generated pom.xml 1.0.0 Note The next table contains recommendations only for using the OpenAPI generator plug-in (not for using the CLI). Recommended OpenAPI Generator Plug-in Options Plug-in Option Description Default &lt;output&gt; Directory where the generator should place files. + We strongly recommend &lt;output&gt;target/generated-sources&lt;/output&gt; or a subdirectory below there. . (current directory) &lt;addCompileSourceRoot&gt; Whether Maven should include the output directory as a source root (that is, include it automatically in the build). + We advise &lt;addCompileSourceRoot&gt;true&lt;/addCompileSourceRoot&gt; . false ",
            "title": "Recommended Settings for the OpenAPI Generator"
        },
        {
            "location": "/mp/openapi/openapi-generator",
            "text": " Among the many configuration settings available to you, some you should particularly consider are summarized in the table below. Refer to the earlier links for complete lists. Common OpenAPI Generator Additional Properties Property Description Values Default Notes helidonVersion Version of Helidon for which to generate the files &#160; 2.5.2 Affects: Helidon version for the &lt;parent&gt; Dependencies ( javax vs. jakarta ) java import statements in generated code ( javax vs. jakarta ) fullProject Whether to generate all the normal files or only API files true / false false The \"API files\" include files developers do not normally modify after they are generated: the interfaces or classes for the declared API and the model classes. serializationLibrary which Java library to use for serializing JSON jsonb , jackson jackson ",
            "title": "Common Settings"
        },
        {
            "location": "/mp/openapi/openapi-generator",
            "text": " The OpenAPI generators support a substantial, powerful, and sometimes bewildering group of configuration settings. For complete lists see these pages: generic options Helidon client generator options and Helidon server generator options The OpenAPI generator loosely divides its settings into three types: global properties These settings generally govern the overall behavior of the tool, regardless of which specific generator you use. For the CLI, use the common option style: -i petstore.yaml --input-spec petstore.yaml For the Maven plug-in, use elements within the &lt;configuration&gt; section of the plug-in: <markup lang=\"xml\" >&lt;configuration&gt; &lt;inputSpec&gt;petstore.yaml&lt;/inputSpec&gt; &lt;/configuration&gt; options These settings typically affect how particular generators operate. For the CLI, specify config options as additional properties: --additional-properties=groupId=com.mycompany.test,artifactId=my-example or <markup lang=\"bash\" >-p groupId=com.mycompany.test -p artifactId=my-example For the Maven plug-in, use the &lt;configOptions&gt; section within &lt;configuration&gt; : <markup lang=\"xml\" >&lt;configuration&gt; ... &lt;configOptions&gt; &lt;groupId&gt;com.mycompany.test&lt;/groupId&gt; &lt;artifactId&gt;my-example&lt;/artifactId&gt; &lt;/configOptions&gt; ... &lt;/configuration&gt; additional properties Settings in this category typically are passed to the templates used in generating the files, although generators can use additional properties in deciding how to generate the files. For the CLI: --additional-properties \"useAbstractClasses=false,returnResponse=true\" or <markup lang=\"bash\" >-p useAbstractClasses=false -p returnResponse=true For the Maven plug-in, use an &lt;additionalProperties&gt; section within the &lt;configuration&gt; section for the plug-in: <markup lang=\"xml\" >&lt;configuration&gt; .... &lt;additionalProperties&gt; &lt;additionalProperty&gt;useAbstractClasses=false&lt;/additionalProperty&gt; &lt;additionalProperty&gt;returnResponse=true&lt;/additionalProperty&gt; &lt;/additionalProperties&gt; &lt;/configuration&gt; Keep this distinction among global options, config options, and additional properties in mind so you know how to express the configuration you want. The earlier links to the lists of configuration options for the Helidon generators groups options and additional properties in separate tables. The next few sections describe, in turn, required settings, settings we recommend, and other common settings most developers will want to use. Required Settings You must specify the following options: Required OpenAPI Generator Options Option Short Option Plug-in Setting Description Values --inputSpec -i &lt;inputSpec&gt; Path to the OpenAPI document defining the REST API --generatorName -g &lt;generatorName&gt; Generator you want to use ( java-helidon-server or java-helidon-client ) java-helidon-server java-helidon-client Recommended Settings for the OpenAPI Generator Your project might have different needs, but in general we advise developers to use the following settings when using the OpenAPI generator. Recommended OpenAPI Generator Additional Properties Property Description Default apiPackage Name of the package for generated API interfaces/classes org.openapitools.server.api or org.openapitools.client.api modelPackage Name of the package for generated model (POJO) classes org.openapitools.server.model or org.openapitools.client.model invokerPackage Name of the package for generated driver classes org.openapitools.server or org.openapitools.client groupId Group ID in the generated pom.xml org.openapitools artifactId Artifact ID in the generated pom.xml openapi-java-server or openapi-java-client artifactVersion Artifact version in the generated pom.xml 1.0.0 Note The next table contains recommendations only for using the OpenAPI generator plug-in (not for using the CLI). Recommended OpenAPI Generator Plug-in Options Plug-in Option Description Default &lt;output&gt; Directory where the generator should place files. + We strongly recommend &lt;output&gt;target/generated-sources&lt;/output&gt; or a subdirectory below there. . (current directory) &lt;addCompileSourceRoot&gt; Whether Maven should include the output directory as a source root (that is, include it automatically in the build). + We advise &lt;addCompileSourceRoot&gt;true&lt;/addCompileSourceRoot&gt; . false Common Settings Among the many configuration settings available to you, some you should particularly consider are summarized in the table below. Refer to the earlier links for complete lists. Common OpenAPI Generator Additional Properties Property Description Values Default Notes helidonVersion Version of Helidon for which to generate the files &#160; 2.5.2 Affects: Helidon version for the &lt;parent&gt; Dependencies ( javax vs. jakarta ) java import statements in generated code ( javax vs. jakarta ) fullProject Whether to generate all the normal files or only API files true / false false The \"API files\" include files developers do not normally modify after they are generated: the interfaces or classes for the declared API and the model classes. serializationLibrary which Java library to use for serializing JSON jsonb , jackson jackson ",
            "title": "Configuration"
        },
        {
            "location": "/mp/openapi/openapi-generator",
            "text": " You can use the OpenAPI generator to create a new project or to generate files into an existing project. Some developers do both, using the generator to create the project at first and then to update the project as they evolve the OpenAPI document or change the generation options they select. Others create the project in some other way&#8212;&#8203;for example, using the Helidon CLI . The OpenAPI generator CLI and plug-in both support each type of usage. If the OpenAPI generator finds a pre-existing API or model file, it overwrites it with the latest content. It does not overwrite a pom.xml file or test files. This is important because certain generation settings can influence the generated dependencies in the pom.xml file. For example, the serializationLibrary setting creates dependencies on either JSON-B or Jackson artifacts. As a result, changing the generation options can change the dependencies your project should have. If you rerun the generator, the old pom.xml remains and does not reflect the revised depencencies. As a practical matter, many developers use the OpenAPI generators in one of the following ways: Use the generator CLI once to create a new project. By default, the generator CLI creates files in the normal Maven project structure: src/main/java , etc. Then you add your own files to that same project structure. Because the generated files are in the standard places, the project build includes them by default. Note You can run the generator CLI again to update the generated files. Because this happens outside the project&#8217;s build lifecycle, you need to remember to rerun the CLI yourself when you change the OpenAPI document. You also need to identify and manually remove any previously-generated files that become obsolete. Similarly, you must understand how changes in the OpenAPI document or the generation options affect the project dependencies and update the project pom.xml accordingly. Use the generator plug-in to (re)generate files during each build. Specify in the plug-in configuration that the generated files should reside in target/generated-sources directory (the conventional location for generated sources) or a subdirectory below there. Each project build runs the OpenAPI generator which reads the then-current OpenAPI document file. With the generated files under target , you can use mvn clean to remove any obsolete generated files left over from previous builds. Note In particular, with mvn clean each build regenerates the candidate pom.xml under target/generated-sources . You can inspect the generated pom.xml file for changes in dependencies and make any necessary changes in the actual project pom.xml file. ",
            "title": "Generating a New Project and Generating Into an Existing Project"
        },
        {
            "location": "/mp/openapi/openapi-generator",
            "text": " As you generate a Helidon MP server , you can choose whether you want Java interfaces or classes to represent the RESTful API endpoints. By default, the Helidon OpenAPI server generator creates classes. You write your own concrete subclasses which extend those generated classes, supplying the business logic for each REST endpoint. Do not modify the generated classes. If you set useAbstractClasses=false then the generator creates Java interfaces instead of classes. You then write classes which implement those generated interfaces. Either way, you can safely regenerate the code later so long as you have not edited the generated code. The generator replaces the generated classes or interfaces but does not touch other classes you wrote. The Helidon client generator always creates concrete classes. Typically, you do not need to customize the behavior in the generated client API classes. If you choose to do so, write your own subclass of the generated client API class; do not modify the generated files. ",
            "title": "Generating Interfaces or Classes"
        },
        {
            "location": "/mp/openapi/openapi-generator",
            "text": " Each operation in an OpenAPI document can have a tags attribute. The generators group operations with the same tags value into the same API. When you generate a Helidon MP server, the generator creates a separate interface or class for each API your service exposes . You implement each interface or extend each class to add your business logic for that API. When you generate a Helidon MP client, the generated code contains a separate API class for each distinct API your code might invoke . ",
            "title": "Grouping Operations into \"APIs\""
        },
        {
            "location": "/mp/openapi/openapi-generator",
            "text": " Beyond the settings listed above, there are several important choices you need to make when planning your project and when running the OpenAPI generators. This section addresses those choices. Generating a New Project and Generating Into an Existing Project You can use the OpenAPI generator to create a new project or to generate files into an existing project. Some developers do both, using the generator to create the project at first and then to update the project as they evolve the OpenAPI document or change the generation options they select. Others create the project in some other way&#8212;&#8203;for example, using the Helidon CLI . The OpenAPI generator CLI and plug-in both support each type of usage. If the OpenAPI generator finds a pre-existing API or model file, it overwrites it with the latest content. It does not overwrite a pom.xml file or test files. This is important because certain generation settings can influence the generated dependencies in the pom.xml file. For example, the serializationLibrary setting creates dependencies on either JSON-B or Jackson artifacts. As a result, changing the generation options can change the dependencies your project should have. If you rerun the generator, the old pom.xml remains and does not reflect the revised depencencies. As a practical matter, many developers use the OpenAPI generators in one of the following ways: Use the generator CLI once to create a new project. By default, the generator CLI creates files in the normal Maven project structure: src/main/java , etc. Then you add your own files to that same project structure. Because the generated files are in the standard places, the project build includes them by default. Note You can run the generator CLI again to update the generated files. Because this happens outside the project&#8217;s build lifecycle, you need to remember to rerun the CLI yourself when you change the OpenAPI document. You also need to identify and manually remove any previously-generated files that become obsolete. Similarly, you must understand how changes in the OpenAPI document or the generation options affect the project dependencies and update the project pom.xml accordingly. Use the generator plug-in to (re)generate files during each build. Specify in the plug-in configuration that the generated files should reside in target/generated-sources directory (the conventional location for generated sources) or a subdirectory below there. Each project build runs the OpenAPI generator which reads the then-current OpenAPI document file. With the generated files under target , you can use mvn clean to remove any obsolete generated files left over from previous builds. Note In particular, with mvn clean each build regenerates the candidate pom.xml under target/generated-sources . You can inspect the generated pom.xml file for changes in dependencies and make any necessary changes in the actual project pom.xml file. Generating Interfaces or Classes As you generate a Helidon MP server , you can choose whether you want Java interfaces or classes to represent the RESTful API endpoints. By default, the Helidon OpenAPI server generator creates classes. You write your own concrete subclasses which extend those generated classes, supplying the business logic for each REST endpoint. Do not modify the generated classes. If you set useAbstractClasses=false then the generator creates Java interfaces instead of classes. You then write classes which implement those generated interfaces. Either way, you can safely regenerate the code later so long as you have not edited the generated code. The generator replaces the generated classes or interfaces but does not touch other classes you wrote. The Helidon client generator always creates concrete classes. Typically, you do not need to customize the behavior in the generated client API classes. If you choose to do so, write your own subclass of the generated client API class; do not modify the generated files. Grouping Operations into \"APIs\" Each operation in an OpenAPI document can have a tags attribute. The generators group operations with the same tags value into the same API. When you generate a Helidon MP server, the generator creates a separate interface or class for each API your service exposes . You implement each interface or extend each class to add your business logic for that API. When you generate a Helidon MP client, the generated code contains a separate API class for each distinct API your code might invoke . ",
            "title": "Planning Your Use of the OpenAPI Generators"
        },
        {
            "location": "/mp/openapi/openapi-generator",
            "text": " Downloading the OpenAPI Generator CLI You need to download the CLI .jar file before you can run the CLI. Follow these instructions and remember where you save the .jar file. The examples below use the placeholder path-to-generator to represent the directory where you store that downloaded file. The following example uses the Helidon server generator to create a project or regenerate files into an existing project. <markup lang=\"bash\" title=\"Creating or updating a server project using the OpenAPI generator CLI\" >java -jar ${path-to-generator}/openapi-generator-cli.jar \\ generate \\ -i src/main/resources/petstore.yaml \\ -g java-helidon-server \\ --library mp \\ -p groupId=io.helidon.examples \\ -p artifactId=helidon-openapigen-mp-server \\ -p artifactVersion=1.0.0-SNAPSHOT \\ -p apiPackage=io.helidon.examples.openapigen.mp.server.api \\ -p modelPackage=io.helidon.examples.openapigen.mp.server.model \\ -p invokerPackage=io.helidon.examples.openapigen.mp.server The next example runs the Helidon client generator using the same input file. <markup lang=\"bash\" title=\"Creating or updating a client project using the OpenAPI generator CLI\" >java -jar ${path-to-generator}/openapi-generator-cli.jar \\ generate \\ -i src/main/resources/petstore.yaml \\ -g java-helidon-client \\ --library mp \\ -p groupId=io.helidon.examples \\ -p artifactId=helidon-openapigen-mp-client \\ -p artifactVersion=1.0.0-SNAPSHOT \\ -p apiPackage=io.helidon.examples.openapigen.mp.client.api \\ -p modelPackage=io.helidon.examples.openapigen.mp.client.model \\ -p invokerPackage=io.helidon.examples.openapigen.mp.client The key differences between the commands are: the generator selected by the -g option ( client vs. server ), the artifact ID and package names ( client vs. server ). You could use these two commands together to generate a server submodule and a client submodule in a pre-existing multi-module Maven project. Remember that the resulting client project can access any server which implements the API described in the petstore.yaml OpenAPI document, whether it was generated using the OpenAPI generator tool or not. In both examples, the generator creates the entire project if it does not exist and recreates the generated API and model files if the project already exists. The generator does not overwrite an existing pom.xml file, previously-generated test files, or files you create yourself. ",
            "title": "Using the OpenAPI Generator CLI"
        },
        {
            "location": "/mp/openapi/openapi-generator",
            "text": " You can run the OpenAPI generator plug-in as part of your project build to generate or regenerate files. First, declare the plug-in as explained in the earlier section on Maven coordinates . Then, in the &lt;build&gt; section of your pom.xml file, add an execution of the plug-in with the configuration you want. By default, the plug-in runs during the generate-sources phase of the Maven build. The plug-in execution in the following example is equivalent to the CLI example above for generating server files: <markup lang=\"xml\" title=\"Creating or updating a client project using the OpenAPI Maven plug-in\" >&lt;plugin&gt; &lt;groupId&gt;org.openapitools&lt;/groupId&gt; &lt;artifactId&gt;openapi-generator-maven-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;generate&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;inputSpec&gt;${project.basedir}/src/main/resources/petstore.yaml&lt;/inputSpec&gt; &lt;generatorName&gt;java-helidon-client&lt;/generatorName&gt; &lt;library&gt;mp&lt;/library&gt; &lt;output&gt;${project.build.directory}/generated-sources/client&lt;/output&gt; &lt;addCompileSourceRoot&gt;true&lt;/addCompileSourceRoot&gt; &lt;configOptions&gt; &lt;groupId&gt;io.helidon.examples&lt;/groupId&gt; &lt;artifactId&gt;helidon-openapigen-mp-client&lt;/artifactId&gt; &lt;artifactVersion&gt;1.0.0-SNAPSHOT&lt;/artifactVersion&gt; &lt;apiPackage&gt;io.helidon.examples.openapigen.mp.client.api&lt;/apiPackage&gt; &lt;modelPackage&gt;io.helidon.examples.openapigen.mp.client.model&lt;/modelPackage&gt; &lt;invokerPackage&gt;io.helidon.examples.openapigen.mp.client&lt;/invokerPackage&gt; &lt;/configOptions&gt; &lt;additionalProperties&gt; &lt;additionalProperty&gt;returnResponse=true&lt;/additionalProperty&gt; &lt;/additionalProperties&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; Specifies that the generated files should reside in the target/generated-sources/client directory. ",
            "title": "Invoking the OpenAPI Generator Maven Plug-in"
        },
        {
            "location": "/mp/openapi/openapi-generator",
            "text": " The OpenAPI tools project hosts and maintains the online OpenAPI generator at http://api.openapi-generator.tech . You can use the site&#8217;s API browser to explore the available generators and the settings each supports, expressed as JSON. To generate your project, you supply the options and additional properties as JSON. The online generator provides you with a file ID, and you refer to the file ID in a subsequent HTTP request to retrieve your project. Note The online generator stores your project on the server which you then retrieve using a separate HTTP request. Before you use the online generator, consider whether any of the input you provide&#8212;&#8203;the OpenAPI document, package or Maven coordinates&#8212;&#8203;and therefore the generated project will reveal any sensitive information. This document does not explore further the use of the online generator. ",
            "title": "Using the Online Generator"
        },
        {
            "location": "/mp/openapi/openapi-generator",
            "text": " Earlier we listed the ways you can run the OpenAPI generator: using the OpenAPI generator CLI using the OpenAPI generator Maven plug-in using the online OpenAPI generator website The next sections describe each of these techniques in detail. Using the OpenAPI Generator CLI Downloading the OpenAPI Generator CLI You need to download the CLI .jar file before you can run the CLI. Follow these instructions and remember where you save the .jar file. The examples below use the placeholder path-to-generator to represent the directory where you store that downloaded file. The following example uses the Helidon server generator to create a project or regenerate files into an existing project. <markup lang=\"bash\" title=\"Creating or updating a server project using the OpenAPI generator CLI\" >java -jar ${path-to-generator}/openapi-generator-cli.jar \\ generate \\ -i src/main/resources/petstore.yaml \\ -g java-helidon-server \\ --library mp \\ -p groupId=io.helidon.examples \\ -p artifactId=helidon-openapigen-mp-server \\ -p artifactVersion=1.0.0-SNAPSHOT \\ -p apiPackage=io.helidon.examples.openapigen.mp.server.api \\ -p modelPackage=io.helidon.examples.openapigen.mp.server.model \\ -p invokerPackage=io.helidon.examples.openapigen.mp.server The next example runs the Helidon client generator using the same input file. <markup lang=\"bash\" title=\"Creating or updating a client project using the OpenAPI generator CLI\" >java -jar ${path-to-generator}/openapi-generator-cli.jar \\ generate \\ -i src/main/resources/petstore.yaml \\ -g java-helidon-client \\ --library mp \\ -p groupId=io.helidon.examples \\ -p artifactId=helidon-openapigen-mp-client \\ -p artifactVersion=1.0.0-SNAPSHOT \\ -p apiPackage=io.helidon.examples.openapigen.mp.client.api \\ -p modelPackage=io.helidon.examples.openapigen.mp.client.model \\ -p invokerPackage=io.helidon.examples.openapigen.mp.client The key differences between the commands are: the generator selected by the -g option ( client vs. server ), the artifact ID and package names ( client vs. server ). You could use these two commands together to generate a server submodule and a client submodule in a pre-existing multi-module Maven project. Remember that the resulting client project can access any server which implements the API described in the petstore.yaml OpenAPI document, whether it was generated using the OpenAPI generator tool or not. In both examples, the generator creates the entire project if it does not exist and recreates the generated API and model files if the project already exists. The generator does not overwrite an existing pom.xml file, previously-generated test files, or files you create yourself. Invoking the OpenAPI Generator Maven Plug-in You can run the OpenAPI generator plug-in as part of your project build to generate or regenerate files. First, declare the plug-in as explained in the earlier section on Maven coordinates . Then, in the &lt;build&gt; section of your pom.xml file, add an execution of the plug-in with the configuration you want. By default, the plug-in runs during the generate-sources phase of the Maven build. The plug-in execution in the following example is equivalent to the CLI example above for generating server files: <markup lang=\"xml\" title=\"Creating or updating a client project using the OpenAPI Maven plug-in\" >&lt;plugin&gt; &lt;groupId&gt;org.openapitools&lt;/groupId&gt; &lt;artifactId&gt;openapi-generator-maven-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;generate&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;inputSpec&gt;${project.basedir}/src/main/resources/petstore.yaml&lt;/inputSpec&gt; &lt;generatorName&gt;java-helidon-client&lt;/generatorName&gt; &lt;library&gt;mp&lt;/library&gt; &lt;output&gt;${project.build.directory}/generated-sources/client&lt;/output&gt; &lt;addCompileSourceRoot&gt;true&lt;/addCompileSourceRoot&gt; &lt;configOptions&gt; &lt;groupId&gt;io.helidon.examples&lt;/groupId&gt; &lt;artifactId&gt;helidon-openapigen-mp-client&lt;/artifactId&gt; &lt;artifactVersion&gt;1.0.0-SNAPSHOT&lt;/artifactVersion&gt; &lt;apiPackage&gt;io.helidon.examples.openapigen.mp.client.api&lt;/apiPackage&gt; &lt;modelPackage&gt;io.helidon.examples.openapigen.mp.client.model&lt;/modelPackage&gt; &lt;invokerPackage&gt;io.helidon.examples.openapigen.mp.client&lt;/invokerPackage&gt; &lt;/configOptions&gt; &lt;additionalProperties&gt; &lt;additionalProperty&gt;returnResponse=true&lt;/additionalProperty&gt; &lt;/additionalProperties&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; Specifies that the generated files should reside in the target/generated-sources/client directory. Using the Online Generator The OpenAPI tools project hosts and maintains the online OpenAPI generator at http://api.openapi-generator.tech . You can use the site&#8217;s API browser to explore the available generators and the settings each supports, expressed as JSON. To generate your project, you supply the options and additional properties as JSON. The online generator provides you with a file ID, and you refer to the file ID in a subsequent HTTP request to retrieve your project. Note The online generator stores your project on the server which you then retrieve using a separate HTTP request. Before you use the online generator, consider whether any of the input you provide&#8212;&#8203;the OpenAPI document, package or Maven coordinates&#8212;&#8203;and therefore the generated project will reveal any sensitive information. This document does not explore further the use of the online generator. ",
            "title": "Running the OpenAPI Generators"
        },
        {
            "location": "/mp/openapi/openapi-generator",
            "text": " This section covers two major topics: Planning your use of the OpenAPI generators Running the generators Planning Your Use of the OpenAPI Generators Beyond the settings listed above, there are several important choices you need to make when planning your project and when running the OpenAPI generators. This section addresses those choices. Generating a New Project and Generating Into an Existing Project You can use the OpenAPI generator to create a new project or to generate files into an existing project. Some developers do both, using the generator to create the project at first and then to update the project as they evolve the OpenAPI document or change the generation options they select. Others create the project in some other way&#8212;&#8203;for example, using the Helidon CLI . The OpenAPI generator CLI and plug-in both support each type of usage. If the OpenAPI generator finds a pre-existing API or model file, it overwrites it with the latest content. It does not overwrite a pom.xml file or test files. This is important because certain generation settings can influence the generated dependencies in the pom.xml file. For example, the serializationLibrary setting creates dependencies on either JSON-B or Jackson artifacts. As a result, changing the generation options can change the dependencies your project should have. If you rerun the generator, the old pom.xml remains and does not reflect the revised depencencies. As a practical matter, many developers use the OpenAPI generators in one of the following ways: Use the generator CLI once to create a new project. By default, the generator CLI creates files in the normal Maven project structure: src/main/java , etc. Then you add your own files to that same project structure. Because the generated files are in the standard places, the project build includes them by default. Note You can run the generator CLI again to update the generated files. Because this happens outside the project&#8217;s build lifecycle, you need to remember to rerun the CLI yourself when you change the OpenAPI document. You also need to identify and manually remove any previously-generated files that become obsolete. Similarly, you must understand how changes in the OpenAPI document or the generation options affect the project dependencies and update the project pom.xml accordingly. Use the generator plug-in to (re)generate files during each build. Specify in the plug-in configuration that the generated files should reside in target/generated-sources directory (the conventional location for generated sources) or a subdirectory below there. Each project build runs the OpenAPI generator which reads the then-current OpenAPI document file. With the generated files under target , you can use mvn clean to remove any obsolete generated files left over from previous builds. Note In particular, with mvn clean each build regenerates the candidate pom.xml under target/generated-sources . You can inspect the generated pom.xml file for changes in dependencies and make any necessary changes in the actual project pom.xml file. Generating Interfaces or Classes As you generate a Helidon MP server , you can choose whether you want Java interfaces or classes to represent the RESTful API endpoints. By default, the Helidon OpenAPI server generator creates classes. You write your own concrete subclasses which extend those generated classes, supplying the business logic for each REST endpoint. Do not modify the generated classes. If you set useAbstractClasses=false then the generator creates Java interfaces instead of classes. You then write classes which implement those generated interfaces. Either way, you can safely regenerate the code later so long as you have not edited the generated code. The generator replaces the generated classes or interfaces but does not touch other classes you wrote. The Helidon client generator always creates concrete classes. Typically, you do not need to customize the behavior in the generated client API classes. If you choose to do so, write your own subclass of the generated client API class; do not modify the generated files. Grouping Operations into \"APIs\" Each operation in an OpenAPI document can have a tags attribute. The generators group operations with the same tags value into the same API. When you generate a Helidon MP server, the generator creates a separate interface or class for each API your service exposes . You implement each interface or extend each class to add your business logic for that API. When you generate a Helidon MP client, the generated code contains a separate API class for each distinct API your code might invoke . Running the OpenAPI Generators Earlier we listed the ways you can run the OpenAPI generator: using the OpenAPI generator CLI using the OpenAPI generator Maven plug-in using the online OpenAPI generator website The next sections describe each of these techniques in detail. Using the OpenAPI Generator CLI Downloading the OpenAPI Generator CLI You need to download the CLI .jar file before you can run the CLI. Follow these instructions and remember where you save the .jar file. The examples below use the placeholder path-to-generator to represent the directory where you store that downloaded file. The following example uses the Helidon server generator to create a project or regenerate files into an existing project. <markup lang=\"bash\" title=\"Creating or updating a server project using the OpenAPI generator CLI\" >java -jar ${path-to-generator}/openapi-generator-cli.jar \\ generate \\ -i src/main/resources/petstore.yaml \\ -g java-helidon-server \\ --library mp \\ -p groupId=io.helidon.examples \\ -p artifactId=helidon-openapigen-mp-server \\ -p artifactVersion=1.0.0-SNAPSHOT \\ -p apiPackage=io.helidon.examples.openapigen.mp.server.api \\ -p modelPackage=io.helidon.examples.openapigen.mp.server.model \\ -p invokerPackage=io.helidon.examples.openapigen.mp.server The next example runs the Helidon client generator using the same input file. <markup lang=\"bash\" title=\"Creating or updating a client project using the OpenAPI generator CLI\" >java -jar ${path-to-generator}/openapi-generator-cli.jar \\ generate \\ -i src/main/resources/petstore.yaml \\ -g java-helidon-client \\ --library mp \\ -p groupId=io.helidon.examples \\ -p artifactId=helidon-openapigen-mp-client \\ -p artifactVersion=1.0.0-SNAPSHOT \\ -p apiPackage=io.helidon.examples.openapigen.mp.client.api \\ -p modelPackage=io.helidon.examples.openapigen.mp.client.model \\ -p invokerPackage=io.helidon.examples.openapigen.mp.client The key differences between the commands are: the generator selected by the -g option ( client vs. server ), the artifact ID and package names ( client vs. server ). You could use these two commands together to generate a server submodule and a client submodule in a pre-existing multi-module Maven project. Remember that the resulting client project can access any server which implements the API described in the petstore.yaml OpenAPI document, whether it was generated using the OpenAPI generator tool or not. In both examples, the generator creates the entire project if it does not exist and recreates the generated API and model files if the project already exists. The generator does not overwrite an existing pom.xml file, previously-generated test files, or files you create yourself. Invoking the OpenAPI Generator Maven Plug-in You can run the OpenAPI generator plug-in as part of your project build to generate or regenerate files. First, declare the plug-in as explained in the earlier section on Maven coordinates . Then, in the &lt;build&gt; section of your pom.xml file, add an execution of the plug-in with the configuration you want. By default, the plug-in runs during the generate-sources phase of the Maven build. The plug-in execution in the following example is equivalent to the CLI example above for generating server files: <markup lang=\"xml\" title=\"Creating or updating a client project using the OpenAPI Maven plug-in\" >&lt;plugin&gt; &lt;groupId&gt;org.openapitools&lt;/groupId&gt; &lt;artifactId&gt;openapi-generator-maven-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;generate&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;inputSpec&gt;${project.basedir}/src/main/resources/petstore.yaml&lt;/inputSpec&gt; &lt;generatorName&gt;java-helidon-client&lt;/generatorName&gt; &lt;library&gt;mp&lt;/library&gt; &lt;output&gt;${project.build.directory}/generated-sources/client&lt;/output&gt; &lt;addCompileSourceRoot&gt;true&lt;/addCompileSourceRoot&gt; &lt;configOptions&gt; &lt;groupId&gt;io.helidon.examples&lt;/groupId&gt; &lt;artifactId&gt;helidon-openapigen-mp-client&lt;/artifactId&gt; &lt;artifactVersion&gt;1.0.0-SNAPSHOT&lt;/artifactVersion&gt; &lt;apiPackage&gt;io.helidon.examples.openapigen.mp.client.api&lt;/apiPackage&gt; &lt;modelPackage&gt;io.helidon.examples.openapigen.mp.client.model&lt;/modelPackage&gt; &lt;invokerPackage&gt;io.helidon.examples.openapigen.mp.client&lt;/invokerPackage&gt; &lt;/configOptions&gt; &lt;additionalProperties&gt; &lt;additionalProperty&gt;returnResponse=true&lt;/additionalProperty&gt; &lt;/additionalProperties&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; Specifies that the generated files should reside in the target/generated-sources/client directory. Using the Online Generator The OpenAPI tools project hosts and maintains the online OpenAPI generator at http://api.openapi-generator.tech . You can use the site&#8217;s API browser to explore the available generators and the settings each supports, expressed as JSON. To generate your project, you supply the options and additional properties as JSON. The online generator provides you with a file ID, and you refer to the file ID in a subsequent HTTP request to retrieve your project. Note The online generator stores your project on the server which you then retrieve using a separate HTTP request. Before you use the online generator, consider whether any of the input you provide&#8212;&#8203;the OpenAPI document, package or Maven coordinates&#8212;&#8203;and therefore the generated project will reveal any sensitive information. This document does not explore further the use of the online generator. ",
            "title": "Usage"
        },
        {
            "location": "/mp/openapi/openapi-generator",
            "text": " Recall from earlier how the OpenAPI generator gathers operations into one or more \"APIs\" and generates either a class or an interface&#8212;&#8203;your choice&#8212;&#8203;for each API. You need to extend each generated API class or implement each generated API interface by writing your own classes. Any input parameters to the endpoints are expressed as POJO model objects or Java types, as declared in the OpenAPI document. Your server code uses each of the input parameters to accomplish whatever business purpose that endpoint is responsible for, possibly returning a result as a POJO or Java type as indicated for that operation in the OpenAPI document. In some cases, you might need more control over the response sent to the client. In that case, specify the additional property returnResponse=true when you run the Helidon server generator. The return type for the generated methods is the Jakarta RESTful web services Response and your code has complete control&#8212;&#8203;and therefore responsibility&#8212;&#8203;over setting the status, writing the response entity (if any), and assigning any returned headers. Your code plus the server code from the Helidon generator&#8212;&#8203;all running on Helidon MP&#8212;&#8203;combine to fully implement the server API declared in the original OpenAPI document. Build your project to get a tailored Helidon MP server .jar file or Docker image and your server is ready to run. ",
            "title": "Completing the Server"
        },
        {
            "location": "/mp/openapi/openapi-generator",
            "text": " The generated client code represents a true library. Typically, you do not need to customize the generated client code itself. You do need to write code to invoke the code in that library. The Helidon MP client generator creates a MicroProfile REST client interface for each API. Each generated API interface is annotated so your code can @Inject the API into one of your own beans and then use the interface directly to invoke the remote service. Alternatively, you can also explicitly use the RestClientBuilder to create an instance programmatically and then invoke its methods to contact the remote service. The Helidon MP REST Client documentation describes both approaches in more detail. In the following example, ExampleResource (itself running in a server) invokes a remote Pet service and shows one way to use the generated PetApi REST client interface. <markup lang=\"java\" title=\"Using the generated PetApi from a separate service\" >@Path(\"/exampleServiceCallingService\") public class ExampleResource { @Inject @RestClient private PetApi petApi; @GET @Path(\"/getPet/{petId}\") public Response getPetUsingId(@PathParam(\"petId\") Long petId) { Pet pet = petApi.getPetById(petId); //... } } Uses a bean-defining annotation so CDI can inject into this class. Requests that CDI inject the following field. Identifies to Helidon MP that the following field is a REST client. Declares the field using the generated PetApi type. Invokes the remote service using the injected field and the parameter from the incoming request. ",
            "title": "Using the Client Library"
        },
        {
            "location": "/mp/openapi/openapi-generator",
            "text": " The Helidon generators go a long way in helping you write your client or server. Even so, there are important parts of your project only you can provide. This section describes your next steps after you have run the generator. Completing the Server Recall from earlier how the OpenAPI generator gathers operations into one or more \"APIs\" and generates either a class or an interface&#8212;&#8203;your choice&#8212;&#8203;for each API. You need to extend each generated API class or implement each generated API interface by writing your own classes. Any input parameters to the endpoints are expressed as POJO model objects or Java types, as declared in the OpenAPI document. Your server code uses each of the input parameters to accomplish whatever business purpose that endpoint is responsible for, possibly returning a result as a POJO or Java type as indicated for that operation in the OpenAPI document. In some cases, you might need more control over the response sent to the client. In that case, specify the additional property returnResponse=true when you run the Helidon server generator. The return type for the generated methods is the Jakarta RESTful web services Response and your code has complete control&#8212;&#8203;and therefore responsibility&#8212;&#8203;over setting the status, writing the response entity (if any), and assigning any returned headers. Your code plus the server code from the Helidon generator&#8212;&#8203;all running on Helidon MP&#8212;&#8203;combine to fully implement the server API declared in the original OpenAPI document. Build your project to get a tailored Helidon MP server .jar file or Docker image and your server is ready to run. Using the Client Library The generated client code represents a true library. Typically, you do not need to customize the generated client code itself. You do need to write code to invoke the code in that library. The Helidon MP client generator creates a MicroProfile REST client interface for each API. Each generated API interface is annotated so your code can @Inject the API into one of your own beans and then use the interface directly to invoke the remote service. Alternatively, you can also explicitly use the RestClientBuilder to create an instance programmatically and then invoke its methods to contact the remote service. The Helidon MP REST Client documentation describes both approaches in more detail. In the following example, ExampleResource (itself running in a server) invokes a remote Pet service and shows one way to use the generated PetApi REST client interface. <markup lang=\"java\" title=\"Using the generated PetApi from a separate service\" >@Path(\"/exampleServiceCallingService\") public class ExampleResource { @Inject @RestClient private PetApi petApi; @GET @Path(\"/getPet/{petId}\") public Response getPetUsingId(@PathParam(\"petId\") Long petId) { Pet pet = petApi.getPetById(petId); //... } } Uses a bean-defining annotation so CDI can inject into this class. Requests that CDI inject the following field. Identifies to Helidon MP that the following field is a REST client. Declares the field using the generated PetApi type. Invokes the remote service using the injected field and the parameter from the incoming request. ",
            "title": "Using the Generated Code"
        },
        {
            "location": "/mp/openapi/openapi-generator",
            "text": " OpenAPI Generator Official Website OpenAPI Generator GitHub Repository OpenAPI specification MicroProfile REST Client specification ",
            "title": "References"
        },
        {
            "location": "/mp/openapi/openapi-ui",
            "text": " Overview Maven Coordinates Usage API Configuration Additional Information ",
            "title": "Contents"
        },
        {
            "location": "/mp/openapi/openapi-ui",
            "text": " SmallRye offers an OpenAPI user interface component which displays a web page based on your application&#8217;s OpenAPI document. Through that UI, users can invoke the operations declared in the document. Note The Helidon team discourages including the OpenAPI UI in production applications. The OpenAPI UI can be useful for demonstrating and testing your service&#8217;s endpoints prior to deployment. The Helidon OpenAPI component allows you to integrate the SmallRye UI into your application, adding the UI web page to your application very simply. ",
            "title": "Overview"
        },
        {
            "location": "/mp/openapi/openapi-ui",
            "text": " To enable Helidon OpenAPI UI support add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.openapi-ui&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-openapi-ui&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; And add a runtime dependency on the SmallRye UI. <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.smallrye&lt;/groupId&gt; &lt;artifactId&gt;smallrye-open-api-ui&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; Also make sure your project has the following dependency to include OpenAPI support in your Helidon MP application. <markup lang=\"xml\" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.openapi&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-openapi&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/openapi/openapi-ui",
            "text": " After you modify, build, and start your Helidon MP service, you can access the OpenAPI UI by default at http://your-host:your-port/openapi/ui . Helidon also uses conventional content negotiation at http://your-host:your-port/openapi returning the UI to browsers (or any client that accepts HTML) and the OpenAPI document otherwise. You can customize the path using configuration . The example below shows the UI for the Helidon MP QuickStart greeting application. Example OpenAPI UI Screen With the OpenAPI UI displayed, follow these steps to access one of your service&#8217;s operations. Find the operation you want to run and click on its row in the list. The UI expands the operation, showing any input parameters and the possible responses. Click the \"Try it out\" button in the operation&#8217;s row. The UI now allows you to type into the input parameter field(s) to the right of each parameter name. Enter any required parameter values (first highlighted rectangle) and any non-required values you wish, then click \"Execute\" (highlighted arrow). Just below the \"Execute\" button the UI shows several sections: the equivalent curl command for submitting the request with your inputs, the URL used for the request, and a new \"Server response\" section (second highlighted rectangle) containing several items from the response: HTTP status code body headers The next image shows the screen after you submit the \"Returns a personalized greeting\" operation. Note that the UI shows the actual response from invoking the operation in the \"Server response\" section. The \"Responses\" section farther below describes the possible responses from the operation as declared in the OpenAPI document for the application. Example OpenAPI UI Screen ",
            "title": "Usage"
        },
        {
            "location": "/mp/openapi/openapi-ui",
            "text": " Your Helidon MP application does not use any API to enable or control Helidon OpenAPI UI support. Adding the dependency as described earlier is sufficient, and you can control the UI behavior using configuration . ",
            "title": "API"
        },
        {
            "location": "/mp/openapi/openapi-ui",
            "text": " Optional configuration options key type default value description enabled boolean true Sets whether the service should be enabled. @return `true` if enabled, `false` otherwise options Map&lt;string, string&gt; &#160; Merges implementation-specific UI options. @return options for the UI to merge web-context string &#160; Full web context (not just the suffix). @return full web context path The default UI web-context value is the web context for your OpenApiFeature service with the added suffix /ui . If you use the default web context for both OpenApiFeature and the UI, the UI responds at /openapi/ui . You can use configuration to affect the UI path in two ways: Configure the OpenAPI endpoint path (the /openapi part). Recall that you can configure the Helidon OpenAPI component to change where it serves the OpenAPI document. <markup lang=\"properties\" title=\"Configuring the OpenAPI web context\" >mp.openapi.web-context=/my-openapi In this case, the path for the UI component is your customized OpenAPI path with /ui as a suffix. With the example above, the UI responds at /my-openapi/ui and Helidon uses standard content negotiation at /my-openapi to return either the OpenAPI document or the UI. Separately, configure the entire web context path for the UI independently from the web context for OpenAPI. <markup lang=\"properties\" title=\"Configuring the OpenAPI UI web context\" >mp.openapi.services.ui.web-context=/my-ui Note The mp.openapi.services.ui.web-context setting assigns the entire web-context for the UI, not the suffix appended to the OpenApiFeature endpoint. With this configuration, the UI responds at /my-ui regardless of the path for OpenAPI itself. The SmallRye OpenAPI UI component accepts several options, but they are of minimal use to application developers and they must be passed to the SmallRye UI code programmatically. Helidon allows you to specify these values using configuration in the mp.openapi.services.ui.options section. Helidon then passes the corresponding options to SmallRye for you. To configure any of these settings, use the enum values&#8212;&#8203;they are all lower case&#8212;&#8203;declared in the SmallRye Option.java class as the keys in your Helidon configuration. Note Helidon prepares several of the SmallRye options automatically based on other settings. Any options you configure override the values Helidon assigns, possibly interfering with the proper operation of the UI. ",
            "title": "Configuration options"
        },
        {
            "location": "/mp/openapi/openapi-ui",
            "text": " To use configuration to control how the Helidon OpenAPI UI service behaves, add mp.openapi.services.ui settings to your META-INF/microprofile-config.properties file. Type: io.helidon.integrations.openapi.ui.OpenApiUi Configuration options Optional configuration options key type default value description enabled boolean true Sets whether the service should be enabled. @return `true` if enabled, `false` otherwise options Map&lt;string, string&gt; &#160; Merges implementation-specific UI options. @return options for the UI to merge web-context string &#160; Full web context (not just the suffix). @return full web context path The default UI web-context value is the web context for your OpenApiFeature service with the added suffix /ui . If you use the default web context for both OpenApiFeature and the UI, the UI responds at /openapi/ui . You can use configuration to affect the UI path in two ways: Configure the OpenAPI endpoint path (the /openapi part). Recall that you can configure the Helidon OpenAPI component to change where it serves the OpenAPI document. <markup lang=\"properties\" title=\"Configuring the OpenAPI web context\" >mp.openapi.web-context=/my-openapi In this case, the path for the UI component is your customized OpenAPI path with /ui as a suffix. With the example above, the UI responds at /my-openapi/ui and Helidon uses standard content negotiation at /my-openapi to return either the OpenAPI document or the UI. Separately, configure the entire web context path for the UI independently from the web context for OpenAPI. <markup lang=\"properties\" title=\"Configuring the OpenAPI UI web context\" >mp.openapi.services.ui.web-context=/my-ui Note The mp.openapi.services.ui.web-context setting assigns the entire web-context for the UI, not the suffix appended to the OpenApiFeature endpoint. With this configuration, the UI responds at /my-ui regardless of the path for OpenAPI itself. The SmallRye OpenAPI UI component accepts several options, but they are of minimal use to application developers and they must be passed to the SmallRye UI code programmatically. Helidon allows you to specify these values using configuration in the mp.openapi.services.ui.options section. Helidon then passes the corresponding options to SmallRye for you. To configure any of these settings, use the enum values&#8212;&#8203;they are all lower case&#8212;&#8203;declared in the SmallRye Option.java class as the keys in your Helidon configuration. Note Helidon prepares several of the SmallRye options automatically based on other settings. Any options you configure override the values Helidon assigns, possibly interfering with the proper operation of the UI. ",
            "title": "Configuration"
        },
        {
            "location": "/mp/openapi/openapi-ui",
            "text": " Helidon OpenAPI MP documentation SmallRye OpenAPI UI GitHub site ",
            "title": "Additional Information"
        },
        {
            "location": "/mp/openapi/openapi",
            "text": " Overview Maven Coordinates Usage Configuration Examples Additional Information Reference ",
            "title": "Contents"
        },
        {
            "location": "/mp/openapi/openapi",
            "text": " The OpenAPI specification defines a standard way to express the interface exposed by a REST service. The MicroProfile OpenAPI spec explains how MicroProfile embraces OpenAPI, adding annotations, configuration, and a service provider interface (SPI). Helidon MP implements the MicroProfile OpenAPI specification. The OpenAPI support in Helidon MP performs two main tasks: Build an in-memory model of the REST API your service implements. Expose the model in text format (YAML or JSON) via the /openapi endpoint. To construct the model, Helidon gathers information about the service API from whichever of these sources are present in the application: a static OpenAPI document file packaged as part of your service; a model reader The SPI defines an interface you can implement in your application for programmatically providing part or all of the model; OpenAPI annotations; a filter class The SPI defines an interface you can implement in your application which can mask parts of the model. ",
            "title": "Overview"
        },
        {
            "location": "/mp/openapi/openapi",
            "text": " To enable MicroProfile OpenAPI either add a dependency on the helidon-microprofile bundle or add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.openapi&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-openapi&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; If you do not use the helidon-microprofile-bundle also add the following dependency which defines the MicroProfile OpenAPI annotations so you can use them in your code: <markup lang=\"xml\" > &lt;dependency&gt; &lt;groupId&gt;org.eclipse.microprofile.openapi&lt;/groupId&gt; &lt;artifactId&gt;microprofile-openapi-api&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/openapi/openapi",
            "text": " You can very simply add support for OpenAPI to your Helidon MP application. This document shows what changes you need to make to your application and how to access the OpenAPI document for your application at runtime. ",
            "title": "OpenAPI support in Helidon MP"
        },
        {
            "location": "/mp/openapi/openapi",
            "text": " You can add MicroProfile OpenAPI annotations to the endpoints in your source code. These annotations allow the Helidon MP OpenAPI runtime to discover the endpoints and information about them via CDI at app start-up. Here is one of the endpoints, annotated for OpenAPI, from the example mentioned earlier: <markup lang=\"java\" >@GET @Operation(summary = \"Returns a generic greeting\", description = \"Greets the user generically\") @APIResponse(description = \"Simple JSON containing the greeting\", content = @Content(mediaType = \"application/json\", schema = @Schema(implementation = GreetingMessage.class))) @Produces(MediaType.APPLICATION_JSON) public JsonObject getDefaultMessage() {...} @Operation gives information about this endpoint. @APIResponse describes the HTTP response and declares its media type and contents. You can also define any request parameters the endpoint expects, although this endpoint uses none. This excerpt shows only a few annotations for illustration. The Helidon MP OpenAPI example illustrates more, and the MicroProfile OpenAPI spec describes them all. ",
            "title": "Annotations on the endpoints in your app"
        },
        {
            "location": "/mp/openapi/openapi",
            "text": " Add a static file at META-INF/openapi.yml , META-INF/openapi.yaml , or META-INF/openapi.json . Tools such as Swagger let you describe your app&#8217;s API and they then generate an OpenAPI document file which you can include in your application so OpenAPI can use it. ",
            "title": "A static OpenAPI file"
        },
        {
            "location": "/mp/openapi/openapi",
            "text": " Write a Java class that implements the OpenAPI org.eclipse.microprofile.openapi.OASModelReader interface. Your model reader code programmatically adds elements to the internal model that OpenAPI builds. Then set the mp.openapi.model.reader configuration property to the fully-qualified name of your model reader class. ",
            "title": "A model reader class your application provides"
        },
        {
            "location": "/mp/openapi/openapi",
            "text": " Write a Java class that implements the OpenAPI org.eclipse.microprofile.openapi.OASFilter interface. Helidon invokes your filter methods for each element of the in-memory model, allowing your code to modify an element or completely remove it from the model. Then set the mp.openapi.filter configuration property to the fully-qualified name of your filter class. ",
            "title": "A filter class your application provides"
        },
        {
            "location": "/mp/openapi/openapi",
            "text": " Helidon MP OpenAPI combines information from all of the following sources as it builds its in-memory model of your application&#8217;s API. It constructs the OpenAPI document from this internal model. Your application can use one or more of these techniques. Annotations on the endpoints in your app You can add MicroProfile OpenAPI annotations to the endpoints in your source code. These annotations allow the Helidon MP OpenAPI runtime to discover the endpoints and information about them via CDI at app start-up. Here is one of the endpoints, annotated for OpenAPI, from the example mentioned earlier: <markup lang=\"java\" >@GET @Operation(summary = \"Returns a generic greeting\", description = \"Greets the user generically\") @APIResponse(description = \"Simple JSON containing the greeting\", content = @Content(mediaType = \"application/json\", schema = @Schema(implementation = GreetingMessage.class))) @Produces(MediaType.APPLICATION_JSON) public JsonObject getDefaultMessage() {...} @Operation gives information about this endpoint. @APIResponse describes the HTTP response and declares its media type and contents. You can also define any request parameters the endpoint expects, although this endpoint uses none. This excerpt shows only a few annotations for illustration. The Helidon MP OpenAPI example illustrates more, and the MicroProfile OpenAPI spec describes them all. A static OpenAPI file Add a static file at META-INF/openapi.yml , META-INF/openapi.yaml , or META-INF/openapi.json . Tools such as Swagger let you describe your app&#8217;s API and they then generate an OpenAPI document file which you can include in your application so OpenAPI can use it. A model reader class your application provides Write a Java class that implements the OpenAPI org.eclipse.microprofile.openapi.OASModelReader interface. Your model reader code programmatically adds elements to the internal model that OpenAPI builds. Then set the mp.openapi.model.reader configuration property to the fully-qualified name of your model reader class. A filter class your application provides Write a Java class that implements the OpenAPI org.eclipse.microprofile.openapi.OASFilter interface. Helidon invokes your filter methods for each element of the in-memory model, allowing your code to modify an element or completely remove it from the model. Then set the mp.openapi.filter configuration property to the fully-qualified name of your filter class. ",
            "title": "Furnish OpenAPI information about your endpoints"
        },
        {
            "location": "/mp/openapi/openapi",
            "text": " To use OpenAPI from your Helidon MP app, in addition to adding dependencies as described above: Furnish OpenAPI information about your application&#8217;s endpoints. Update your application&#8217;s configuration (optional). Furnish OpenAPI information about your endpoints Helidon MP OpenAPI combines information from all of the following sources as it builds its in-memory model of your application&#8217;s API. It constructs the OpenAPI document from this internal model. Your application can use one or more of these techniques. Annotations on the endpoints in your app You can add MicroProfile OpenAPI annotations to the endpoints in your source code. These annotations allow the Helidon MP OpenAPI runtime to discover the endpoints and information about them via CDI at app start-up. Here is one of the endpoints, annotated for OpenAPI, from the example mentioned earlier: <markup lang=\"java\" >@GET @Operation(summary = \"Returns a generic greeting\", description = \"Greets the user generically\") @APIResponse(description = \"Simple JSON containing the greeting\", content = @Content(mediaType = \"application/json\", schema = @Schema(implementation = GreetingMessage.class))) @Produces(MediaType.APPLICATION_JSON) public JsonObject getDefaultMessage() {...} @Operation gives information about this endpoint. @APIResponse describes the HTTP response and declares its media type and contents. You can also define any request parameters the endpoint expects, although this endpoint uses none. This excerpt shows only a few annotations for illustration. The Helidon MP OpenAPI example illustrates more, and the MicroProfile OpenAPI spec describes them all. A static OpenAPI file Add a static file at META-INF/openapi.yml , META-INF/openapi.yaml , or META-INF/openapi.json . Tools such as Swagger let you describe your app&#8217;s API and they then generate an OpenAPI document file which you can include in your application so OpenAPI can use it. A model reader class your application provides Write a Java class that implements the OpenAPI org.eclipse.microprofile.openapi.OASModelReader interface. Your model reader code programmatically adds elements to the internal model that OpenAPI builds. Then set the mp.openapi.model.reader configuration property to the fully-qualified name of your model reader class. A filter class your application provides Write a Java class that implements the OpenAPI org.eclipse.microprofile.openapi.OASFilter interface. Helidon invokes your filter methods for each element of the in-memory model, allowing your code to modify an element or completely remove it from the model. Then set the mp.openapi.filter configuration property to the fully-qualified name of your filter class. ",
            "title": "Changing your application"
        },
        {
            "location": "/mp/openapi/openapi",
            "text": " Beyond the two config properties that denote the model reader and filter, Helidon MP OpenAPI supports a number of other mandated settings. These are described in the configuration section of the MicroProfile OpenAPI spec. ",
            "title": "Update your application configuration"
        },
        {
            "location": "/mp/openapi/openapi",
            "text": " Once you have added the MP OpenAPI dependency to your project, then your application responds to the built-in endpoint&#8201;&#8212;&#8201; /openapi &#8201;&#8212;&#8201;and returns the OpenAPI document describing the endpoints in your application. Per the MicroProfile OpenAPI spec, the default format of the OpenAPI document is YAML. There is not yet an adopted IANA YAML media type, but a proposed one specifically for OpenAPI documents that has some support is application/vnd.oai.openapi . That is what Helidon returns by default. In addition, a client can specify the HTTP header Accept as either application/vnd.oai.openapi+json or application/json to request JSON. Alternatively, the client can pass the query parameter format as either JSON or YAML to receive application/json or application/vnd.oai.openapi (YAML) output, respectively. ",
            "title": "Accessing the REST Endpoint"
        },
        {
            "location": "/mp/openapi/openapi",
            "text": " OpenAPI support in Helidon MP You can very simply add support for OpenAPI to your Helidon MP application. This document shows what changes you need to make to your application and how to access the OpenAPI document for your application at runtime. Changing your application To use OpenAPI from your Helidon MP app, in addition to adding dependencies as described above: Furnish OpenAPI information about your application&#8217;s endpoints. Update your application&#8217;s configuration (optional). Furnish OpenAPI information about your endpoints Helidon MP OpenAPI combines information from all of the following sources as it builds its in-memory model of your application&#8217;s API. It constructs the OpenAPI document from this internal model. Your application can use one or more of these techniques. Annotations on the endpoints in your app You can add MicroProfile OpenAPI annotations to the endpoints in your source code. These annotations allow the Helidon MP OpenAPI runtime to discover the endpoints and information about them via CDI at app start-up. Here is one of the endpoints, annotated for OpenAPI, from the example mentioned earlier: <markup lang=\"java\" >@GET @Operation(summary = \"Returns a generic greeting\", description = \"Greets the user generically\") @APIResponse(description = \"Simple JSON containing the greeting\", content = @Content(mediaType = \"application/json\", schema = @Schema(implementation = GreetingMessage.class))) @Produces(MediaType.APPLICATION_JSON) public JsonObject getDefaultMessage() {...} @Operation gives information about this endpoint. @APIResponse describes the HTTP response and declares its media type and contents. You can also define any request parameters the endpoint expects, although this endpoint uses none. This excerpt shows only a few annotations for illustration. The Helidon MP OpenAPI example illustrates more, and the MicroProfile OpenAPI spec describes them all. A static OpenAPI file Add a static file at META-INF/openapi.yml , META-INF/openapi.yaml , or META-INF/openapi.json . Tools such as Swagger let you describe your app&#8217;s API and they then generate an OpenAPI document file which you can include in your application so OpenAPI can use it. A model reader class your application provides Write a Java class that implements the OpenAPI org.eclipse.microprofile.openapi.OASModelReader interface. Your model reader code programmatically adds elements to the internal model that OpenAPI builds. Then set the mp.openapi.model.reader configuration property to the fully-qualified name of your model reader class. A filter class your application provides Write a Java class that implements the OpenAPI org.eclipse.microprofile.openapi.OASFilter interface. Helidon invokes your filter methods for each element of the in-memory model, allowing your code to modify an element or completely remove it from the model. Then set the mp.openapi.filter configuration property to the fully-qualified name of your filter class. Update your application configuration Beyond the two config properties that denote the model reader and filter, Helidon MP OpenAPI supports a number of other mandated settings. These are described in the configuration section of the MicroProfile OpenAPI spec. Accessing the REST Endpoint Once you have added the MP OpenAPI dependency to your project, then your application responds to the built-in endpoint&#8201;&#8212;&#8201; /openapi &#8201;&#8212;&#8201;and returns the OpenAPI document describing the endpoints in your application. Per the MicroProfile OpenAPI spec, the default format of the OpenAPI document is YAML. There is not yet an adopted IANA YAML media type, but a proposed one specifically for OpenAPI documents that has some support is application/vnd.oai.openapi . That is what Helidon returns by default. In addition, a client can specify the HTTP header Accept as either application/vnd.oai.openapi+json or application/json to request JSON. Alternatively, the client can pass the query parameter format as either JSON or YAML to receive application/json or application/vnd.oai.openapi (YAML) output, respectively. ",
            "title": "Usage"
        },
        {
            "location": "/mp/openapi/openapi",
            "text": " The MicroProfile OpenAPI specification gives a listing and brief examples of the annotations you can add to your code to convey OpenAPI information. The MicroProfile OpenAPI JavaDocs give full details of the annotations and the other classes and interfaces you can use in your code. ",
            "title": "API"
        },
        {
            "location": "/mp/openapi/openapi",
            "text": " Optional configuration options key type default value description cors CrossOriginConfig &#160; CORS config. @return CORS config enabled boolean true Sets whether the feature should be enabled. @return `true` if enabled, `false` otherwise manager io.helidon.openapi.OpenApiManager (service provider interface) &#160; OpenAPI manager. @return the OpenAPI manager permit-all boolean &#160; Whether to allow anybody to access the endpoint. @return whether to permit access to metrics endpoint to anybody, defaults to `true` @see #roles() roles string[&#93; &#160; Hints for role names the user is expected to be in. @return list of hints services io.helidon.openapi.OpenApiService[&#93; (service provider interface) &#160; OpenAPI services. @return the OpenAPI services static-file string &#160; Path of the static OpenAPI document file. Default types are json , yaml , and yml . @return location of the static OpenAPI document file web-context string /openapi Web context path for the OpenAPI endpoint. @return webContext to use Further, Helidon OpenAPI supports the MicroProfile OpenAPI settings described in the MicroProfile OpenAPI specification . ",
            "title": "Configuration options"
        },
        {
            "location": "/mp/openapi/openapi",
            "text": " Helidon OpenAPI configuration supports the following settings: Type: io.helidon.openapi.OpenApiFeature This is a standalone configuration type, prefix from configuration root: openapi Configuration options Optional configuration options key type default value description cors CrossOriginConfig &#160; CORS config. @return CORS config enabled boolean true Sets whether the feature should be enabled. @return `true` if enabled, `false` otherwise manager io.helidon.openapi.OpenApiManager (service provider interface) &#160; OpenAPI manager. @return the OpenAPI manager permit-all boolean &#160; Whether to allow anybody to access the endpoint. @return whether to permit access to metrics endpoint to anybody, defaults to `true` @see #roles() roles string[&#93; &#160; Hints for role names the user is expected to be in. @return list of hints services io.helidon.openapi.OpenApiService[&#93; (service provider interface) &#160; OpenAPI services. @return the OpenAPI services static-file string &#160; Path of the static OpenAPI document file. Default types are json , yaml , and yml . @return location of the static OpenAPI document file web-context string /openapi Web context path for the OpenAPI endpoint. @return webContext to use Further, Helidon OpenAPI supports the MicroProfile OpenAPI settings described in the MicroProfile OpenAPI specification . ",
            "title": "Configuration"
        },
        {
            "location": "/mp/openapi/openapi",
            "text": " This example shows a simple greeting application, similar to the one from the Helidon MP QuickStart, enhanced with OpenAPI support. <markup lang=\"java\" >@Path(\"/greeting\") @PUT @Operation(summary = \"Set the greeting prefix\", description = \"Permits the client to set the prefix part of the greeting (\\\"Hello\\\")\") @RequestBody( name = \"greeting\", description = \"Conveys the new greeting prefix to use in building greetings\", content = @Content( mediaType = \"application/json\", schema = @Schema(implementation = GreetingUpdateMessage.class), examples = @ExampleObject( name = \"greeting\", summary = \"Example greeting message to update\", value = \"{\\\"greeting\\\": \\\"New greeting message\\\"}\"))) @Consumes(MediaType.APPLICATION_JSON) @Produces(MediaType.APPLICATION_JSON) public Response updateGreeting(JsonObject jsonObject) { ... } With @Operation annotation we document the current method. With @RequestBody annotation we document the content produced. Internal annotations @Content , @Schema and @ExampleObjects are used to give more details about the returned data. If we want to hide a specific path an OASFilter is used. The OASFilter interface allows application developers to receive callbacks for various key OpenAPI elements. The interface has a default implementation for every method, which allows application developers to only override the methods they care about. To use it, simply create an implementation of this interface and register it using the mp.openapi.filter configuration key, where the value is the fully qualified name of the filter class. The following example filter prevents information about a given path from appearing in the OpenAPI document. <markup lang=\"java\" >import org.eclipse.microprofile.openapi.models.Operation; import org.eclipse.microprofile.openapi.models.PathItem; public class SimpleAPIFilter implements OASFilter { @Override public PathItem filterPathItem(PathItem pathItem) { for (Map.Entry&lt;PathItem.HttpMethod, Operation&gt; methodOp : pathItem.getOperations().entrySet()) { if (SimpleAPIModelReader.DOOMED_OPERATION_ID .equals(methodOp.getValue().getOperationId())) { return null; } } return OASFilter.super.filterPathItem(pathItem); } } You can implement a model reader to provide all or part of the in-memory OpenAPI model programmatically. Helidon OpenAPI merges the model from the model reader with models from the other sources (a static file and annotations). The example model reader below creates an OpenAPI object describing two paths. It turns out that the filter described earlier will suppress one of the paths, but the model reader does not know or care. <markup lang=\"java\" >import org.eclipse.microprofile.openapi.OASFactory; import org.eclipse.microprofile.openapi.OASModelReader; import org.eclipse.microprofile.openapi.models.OpenAPI; import org.eclipse.microprofile.openapi.models.PathItem; import org.eclipse.microprofile.openapi.models.Paths; /** * Defines two paths using the OpenAPI model reader mechanism, one that should * be suppressed by the filter class and one that should appear in the published * OpenAPI document. */ public class SimpleAPIModelReader implements OASModelReader { /** * Path for the example endpoint added by this model reader that should be visible. */ public static final String MODEL_READER_PATH = \"/test/newpath\"; /** * Path for an endpoint that the filter should hide. */ public static final String DOOMED_PATH = \"/test/doomed\"; /** * ID for an endpoint that the filter should hide. */ public static final String DOOMED_OPERATION_ID = \"doomedPath\"; /** * Summary text for the endpoint. */ public static final String SUMMARY = \"A sample test endpoint from ModelReader\"; @Override public OpenAPI buildModel() { /* * Add two path items, one of which we expect to be removed by * the filter and a very simple one that will appear in the * published OpenAPI document. */ PathItem newPathItem = OASFactory.createPathItem() .GET(OASFactory.createOperation() .operationId(\"newPath\") .summary(SUMMARY)); PathItem doomedPathItem = OASFactory.createPathItem() .GET(OASFactory.createOperation() .operationId(DOOMED_OPERATION_ID) .summary(\"This should become invisible\")); OpenAPI openAPI = OASFactory.createOpenAPI(); Paths paths = OASFactory.createPaths() .addPathItem(MODEL_READER_PATH, newPathItem) .addPathItem(DOOMED_PATH, doomedPathItem); openAPI.paths(paths); return openAPI; } } Having written the filter and model reader classes, identify them by adding configuration to META-INF/microprofile-config.properties as the following example shows. <markup lang=\"properties\" >mp.openapi.filter=io.helidon.microprofile.examples.openapi.internal.SimpleAPIFilter mp.openapi.model.reader=io.helidon.microprofile.examples.openapi.internal.SimpleAPIModelReader Now just build and run: <markup lang=\"bash\" >mvn package java -jar target/helidon-examples-microprofile-openapi.jar Try the endpoints: <markup lang=\"bash\" >curl -X GET http://localhost:8080/greet {\"message\":\"Hello World!\"} curl -X GET http://localhost:8080/openapi [lengthy OpenAPI document] The output describes not only then endpoints from GreetResource but also one contributed by the SimpleAPIModelReader . Full example is available in our official repository ",
            "title": "Helidon MP OpenAPI Example"
        },
        {
            "location": "/mp/openapi/openapi",
            "text": " Helidon MP includes a complete OpenAPI example based on the MP quick-start sample app. The rest of this section shows, step-by-step, how one might change the original QuickStart service to adopt OpenAPI. Helidon MP OpenAPI Example This example shows a simple greeting application, similar to the one from the Helidon MP QuickStart, enhanced with OpenAPI support. <markup lang=\"java\" >@Path(\"/greeting\") @PUT @Operation(summary = \"Set the greeting prefix\", description = \"Permits the client to set the prefix part of the greeting (\\\"Hello\\\")\") @RequestBody( name = \"greeting\", description = \"Conveys the new greeting prefix to use in building greetings\", content = @Content( mediaType = \"application/json\", schema = @Schema(implementation = GreetingUpdateMessage.class), examples = @ExampleObject( name = \"greeting\", summary = \"Example greeting message to update\", value = \"{\\\"greeting\\\": \\\"New greeting message\\\"}\"))) @Consumes(MediaType.APPLICATION_JSON) @Produces(MediaType.APPLICATION_JSON) public Response updateGreeting(JsonObject jsonObject) { ... } With @Operation annotation we document the current method. With @RequestBody annotation we document the content produced. Internal annotations @Content , @Schema and @ExampleObjects are used to give more details about the returned data. If we want to hide a specific path an OASFilter is used. The OASFilter interface allows application developers to receive callbacks for various key OpenAPI elements. The interface has a default implementation for every method, which allows application developers to only override the methods they care about. To use it, simply create an implementation of this interface and register it using the mp.openapi.filter configuration key, where the value is the fully qualified name of the filter class. The following example filter prevents information about a given path from appearing in the OpenAPI document. <markup lang=\"java\" >import org.eclipse.microprofile.openapi.models.Operation; import org.eclipse.microprofile.openapi.models.PathItem; public class SimpleAPIFilter implements OASFilter { @Override public PathItem filterPathItem(PathItem pathItem) { for (Map.Entry&lt;PathItem.HttpMethod, Operation&gt; methodOp : pathItem.getOperations().entrySet()) { if (SimpleAPIModelReader.DOOMED_OPERATION_ID .equals(methodOp.getValue().getOperationId())) { return null; } } return OASFilter.super.filterPathItem(pathItem); } } You can implement a model reader to provide all or part of the in-memory OpenAPI model programmatically. Helidon OpenAPI merges the model from the model reader with models from the other sources (a static file and annotations). The example model reader below creates an OpenAPI object describing two paths. It turns out that the filter described earlier will suppress one of the paths, but the model reader does not know or care. <markup lang=\"java\" >import org.eclipse.microprofile.openapi.OASFactory; import org.eclipse.microprofile.openapi.OASModelReader; import org.eclipse.microprofile.openapi.models.OpenAPI; import org.eclipse.microprofile.openapi.models.PathItem; import org.eclipse.microprofile.openapi.models.Paths; /** * Defines two paths using the OpenAPI model reader mechanism, one that should * be suppressed by the filter class and one that should appear in the published * OpenAPI document. */ public class SimpleAPIModelReader implements OASModelReader { /** * Path for the example endpoint added by this model reader that should be visible. */ public static final String MODEL_READER_PATH = \"/test/newpath\"; /** * Path for an endpoint that the filter should hide. */ public static final String DOOMED_PATH = \"/test/doomed\"; /** * ID for an endpoint that the filter should hide. */ public static final String DOOMED_OPERATION_ID = \"doomedPath\"; /** * Summary text for the endpoint. */ public static final String SUMMARY = \"A sample test endpoint from ModelReader\"; @Override public OpenAPI buildModel() { /* * Add two path items, one of which we expect to be removed by * the filter and a very simple one that will appear in the * published OpenAPI document. */ PathItem newPathItem = OASFactory.createPathItem() .GET(OASFactory.createOperation() .operationId(\"newPath\") .summary(SUMMARY)); PathItem doomedPathItem = OASFactory.createPathItem() .GET(OASFactory.createOperation() .operationId(DOOMED_OPERATION_ID) .summary(\"This should become invisible\")); OpenAPI openAPI = OASFactory.createOpenAPI(); Paths paths = OASFactory.createPaths() .addPathItem(MODEL_READER_PATH, newPathItem) .addPathItem(DOOMED_PATH, doomedPathItem); openAPI.paths(paths); return openAPI; } } Having written the filter and model reader classes, identify them by adding configuration to META-INF/microprofile-config.properties as the following example shows. <markup lang=\"properties\" >mp.openapi.filter=io.helidon.microprofile.examples.openapi.internal.SimpleAPIFilter mp.openapi.model.reader=io.helidon.microprofile.examples.openapi.internal.SimpleAPIModelReader Now just build and run: <markup lang=\"bash\" >mvn package java -jar target/helidon-examples-microprofile-openapi.jar Try the endpoints: <markup lang=\"bash\" >curl -X GET http://localhost:8080/greet {\"message\":\"Hello World!\"} curl -X GET http://localhost:8080/openapi [lengthy OpenAPI document] The output describes not only then endpoints from GreetResource but also one contributed by the SimpleAPIModelReader . Full example is available in our official repository ",
            "title": "Examples"
        },
        {
            "location": "/mp/openapi/openapi",
            "text": " A Jandex index stores information about the classes and methods in your app and what annotations they have. It allows CDI to process annotations faster during your application&#8217;s start-up. Add the Jandex maven plug-in to the &lt;build&gt;&lt;plugins&gt; section of your pom.xml : <markup lang=\"xml\" >&lt;plugin&gt; &lt;groupId&gt;io.smallrye&lt;/groupId&gt; &lt;artifactId&gt;jandex-maven-plugin&lt;/artifactId&gt; &lt;version&gt;{jandex-plugin-version}&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;make-index&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;jandex&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; When you build your app maven should include the index META-INF/jandex.idx in the JAR. Note If you do not modify your build to create the index then the Helidon MP OpenAPI runtime automatically creates one in memory during app start-up. This slows down your app start-up and, depending on how CDI is configured, might inadvertently miss information. We strongly recommend using the Jandex plug-in to build the index into your app. ",
            "title": "Building the Jandex index"
        },
        {
            "location": "/mp/openapi/openapi",
            "text": " Building the Jandex index A Jandex index stores information about the classes and methods in your app and what annotations they have. It allows CDI to process annotations faster during your application&#8217;s start-up. Add the Jandex maven plug-in to the &lt;build&gt;&lt;plugins&gt; section of your pom.xml : <markup lang=\"xml\" >&lt;plugin&gt; &lt;groupId&gt;io.smallrye&lt;/groupId&gt; &lt;artifactId&gt;jandex-maven-plugin&lt;/artifactId&gt; &lt;version&gt;{jandex-plugin-version}&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;make-index&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;jandex&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; When you build your app maven should include the index META-INF/jandex.idx in the JAR. Note If you do not modify your build to create the index then the Helidon MP OpenAPI runtime automatically creates one in memory during app start-up. This slows down your app start-up and, depending on how CDI is configured, might inadvertently miss information. We strongly recommend using the Jandex plug-in to build the index into your app. ",
            "title": "Additional Information"
        },
        {
            "location": "/mp/openapi/openapi",
            "text": " MicroProfile OpenAPI GitHub Repository MicroProfile OpenAPI Specification ",
            "title": "Reference"
        },
        {
            "location": "/mp/persistence",
            "text": " Overview Named Data Source Integration Project Setup Setting Up a Connection Pool Setting Up the HikariCP Connection Pool Maven Coordinates (HikariCP) Setting Up the Oracle Universal Connection Pool Maven Coordinates (Oracle Universal Connection Pool) Setting Up a Database Driver Setting Up H2 Maven Coordinates (H2) Setting Up Oracle JDBC Maven Coordinates (Oracle JDBC) Configuration Examples Usage Jakarta Transactions (JTA) Integration Maven Coordinates Configuration Usage Jakarta Persistence (JPA) Integration Project Setup Common Maven Coordinates Setting Up Static Metamodel Generation Maven Coordinates (Hibernate ORM) Setting Up Static Weaving (Hibernate ORM) Maven Coordinates (Eclipselink) Setting Up Static Weaving (Eclipselink) Configuration Usage Examples References ",
            "title": "Contents"
        },
        {
            "location": "/mp/persistence",
            "text": " Helidon MP comes with deep integration for three specification-defined, broadly persistence-related technologies that can be used together or separately: Named data sources Jakarta Transactions (JTA) Jakarta Persistence (JPA) Each integration&#8217;s setup, configuration, and usage are described below. ",
            "title": "Overview"
        },
        {
            "location": "/mp/persistence",
            "text": " Helidon MP&#8217;s named data source integration allows you to safely inject managed javax.sql.DataSource instances that are annotated with jakarta.inject.Named annotations into your Helidon MP application. java.sql.Connection objects acquired from these data sources will be pooled by your choice of one of two possible connection pool implementations. The connections managed by the connection pool will be supplied by your relational database vendor&#8217;s JDBC driver. How you set up Helidon MP&#8217;s named data source integration differs depending on which of these two connection pools, which JDBC driver, and which relational database product you use. Representative setups are described below. This list of setups is not exhaustive. ",
            "title": "Overview"
        },
        {
            "location": "/mp/persistence",
            "text": " Helidon MP&#8217;s named data source integration requires a connection pool implementation. Helidon MP comes with support for two connection pools: HikariCP Oracle Universal Connection Pool You can choose to use either, but not both. Details concerning each connection pool&#8217;s setup are described below. ",
            "title": "Overview"
        },
        {
            "location": "/mp/persistence",
            "text": " To include the HikariCP connection pool in your Helidon MP application: Ensure your dependencies are managed Ensure the following &lt;dependency&gt; element is present as a child element of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.cdi&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-cdi-datasource-hikaricp&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; The scope is runtime , indicating that the HikariCP integration will be available on the runtime classpath. ",
            "title": "Maven Coordinates (HikariCP)"
        },
        {
            "location": "/mp/persistence",
            "text": " Maven Coordinates (HikariCP) To include the HikariCP connection pool in your Helidon MP application: Ensure your dependencies are managed Ensure the following &lt;dependency&gt; element is present as a child element of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.cdi&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-cdi-datasource-hikaricp&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; The scope is runtime , indicating that the HikariCP integration will be available on the runtime classpath. ",
            "title": "Setting Up the HikariCP Connection Pool"
        },
        {
            "location": "/mp/persistence",
            "text": " To include the Oracle Universal Connection Pool in your Helidon MP application: Ensure your dependencies are managed Ensure the following &lt;dependency&gt; element is present as a child element of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.cdi&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-cdi-datasource-ucp&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; The scope is runtime , indicating that the Oracle Universal Connection Pool integration will be available on the runtime classpath. ",
            "title": "Maven Coordinates (Oracle Universal Connection Pool)"
        },
        {
            "location": "/mp/persistence",
            "text": " Maven Coordinates (Oracle Universal Connection Pool) To include the Oracle Universal Connection Pool in your Helidon MP application: Ensure your dependencies are managed Ensure the following &lt;dependency&gt; element is present as a child element of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.cdi&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-cdi-datasource-ucp&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; The scope is runtime , indicating that the Oracle Universal Connection Pool integration will be available on the runtime classpath. ",
            "title": "Setting up the Oracle Universal Connection Pool"
        },
        {
            "location": "/mp/persistence",
            "text": " Overview Helidon MP&#8217;s named data source integration requires a connection pool implementation. Helidon MP comes with support for two connection pools: HikariCP Oracle Universal Connection Pool You can choose to use either, but not both. Details concerning each connection pool&#8217;s setup are described below. Setting Up the HikariCP Connection Pool Maven Coordinates (HikariCP) To include the HikariCP connection pool in your Helidon MP application: Ensure your dependencies are managed Ensure the following &lt;dependency&gt; element is present as a child element of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.cdi&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-cdi-datasource-hikaricp&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; The scope is runtime , indicating that the HikariCP integration will be available on the runtime classpath. Setting up the Oracle Universal Connection Pool Maven Coordinates (Oracle Universal Connection Pool) To include the Oracle Universal Connection Pool in your Helidon MP application: Ensure your dependencies are managed Ensure the following &lt;dependency&gt; element is present as a child element of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.cdi&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-cdi-datasource-ucp&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; The scope is runtime , indicating that the Oracle Universal Connection Pool integration will be available on the runtime classpath. ",
            "title": "Setting Up a Connection Pool"
        },
        {
            "location": "/mp/persistence",
            "text": " Regardless of which connection pool you use, at the lowest level, JDBC database driver classes are what is ultimately responsible for making any connections to a relational database. JDBC database driver classes are database-product-specific. Once you have decided upon a relational database product to use, and JDBC driver classes to use to connect to it, ensure your dependencies are managed , and then ensure that a runtime -scoped &lt;dependency&gt; element describing your JDBC driver classes is present as a child element of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element. See the JDBC 4.3 Specification for more information about JDBC. Representative setups are described below. This list of setups is not exhaustive. ",
            "title": "Overview"
        },
        {
            "location": "/mp/persistence",
            "text": " To include the H2 JDBC driver classes in your Helidon MP application so your application can connect to an H2 database (whether in-memory or persistent): Ensure your dependencies are managed Ensure the following &lt;dependency&gt; element is present as a child element of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;com.h2database&lt;/groupId&gt; &lt;artifactId&gt;h2&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; The scope is runtime , indicating that the H2 JDBC driver classes will be available on the runtime classpath. ",
            "title": "Maven Coordinates (H2)"
        },
        {
            "location": "/mp/persistence",
            "text": " Maven Coordinates (H2) To include the H2 JDBC driver classes in your Helidon MP application so your application can connect to an H2 database (whether in-memory or persistent): Ensure your dependencies are managed Ensure the following &lt;dependency&gt; element is present as a child element of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;com.h2database&lt;/groupId&gt; &lt;artifactId&gt;h2&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; The scope is runtime , indicating that the H2 JDBC driver classes will be available on the runtime classpath. ",
            "title": "Setting Up H2"
        },
        {
            "location": "/mp/persistence",
            "text": " To include the Oracle JDBC driver classes in your Helidon MP application so your application can connect to an Oracle database : Ensure your dependencies are managed Read and understand Developer&#8217;s Guide For Oracle JDBC 21c on Maven Central For a basic setup, ensure the following &lt;dependency&gt; element is present as a child element of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;com.oracle.database.jdbc&lt;/groupId&gt; &lt;artifactId&gt;ojdbc11&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; See [Developer&#8217;s Guide For Oracle JDBC 21c on Maven Central for more details. The ojdbc11 artifact implements relevant parts of the JDBC 4.3 specification , which forms part of Java 21, which is the Java version targeted by Helidon 4. The scope is runtime , indicating that the Oracle JDBC driver classes will be available on the runtime classpath. ",
            "title": "Maven Coordinates (Oracle JDBC)"
        },
        {
            "location": "/mp/persistence",
            "text": " Maven Coordinates (Oracle JDBC) To include the Oracle JDBC driver classes in your Helidon MP application so your application can connect to an Oracle database : Ensure your dependencies are managed Read and understand Developer&#8217;s Guide For Oracle JDBC 21c on Maven Central For a basic setup, ensure the following &lt;dependency&gt; element is present as a child element of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;com.oracle.database.jdbc&lt;/groupId&gt; &lt;artifactId&gt;ojdbc11&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; See [Developer&#8217;s Guide For Oracle JDBC 21c on Maven Central for more details. The ojdbc11 artifact implements relevant parts of the JDBC 4.3 specification , which forms part of Java 21, which is the Java version targeted by Helidon 4. The scope is runtime , indicating that the Oracle JDBC driver classes will be available on the runtime classpath. ",
            "title": "Setting Up Oracle JDBC"
        },
        {
            "location": "/mp/persistence",
            "text": " Overview Regardless of which connection pool you use, at the lowest level, JDBC database driver classes are what is ultimately responsible for making any connections to a relational database. JDBC database driver classes are database-product-specific. Once you have decided upon a relational database product to use, and JDBC driver classes to use to connect to it, ensure your dependencies are managed , and then ensure that a runtime -scoped &lt;dependency&gt; element describing your JDBC driver classes is present as a child element of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element. See the JDBC 4.3 Specification for more information about JDBC. Representative setups are described below. This list of setups is not exhaustive. Setting Up H2 Maven Coordinates (H2) To include the H2 JDBC driver classes in your Helidon MP application so your application can connect to an H2 database (whether in-memory or persistent): Ensure your dependencies are managed Ensure the following &lt;dependency&gt; element is present as a child element of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;com.h2database&lt;/groupId&gt; &lt;artifactId&gt;h2&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; The scope is runtime , indicating that the H2 JDBC driver classes will be available on the runtime classpath. Setting Up Oracle JDBC Maven Coordinates (Oracle JDBC) To include the Oracle JDBC driver classes in your Helidon MP application so your application can connect to an Oracle database : Ensure your dependencies are managed Read and understand Developer&#8217;s Guide For Oracle JDBC 21c on Maven Central For a basic setup, ensure the following &lt;dependency&gt; element is present as a child element of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;com.oracle.database.jdbc&lt;/groupId&gt; &lt;artifactId&gt;ojdbc11&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; See [Developer&#8217;s Guide For Oracle JDBC 21c on Maven Central for more details. The ojdbc11 artifact implements relevant parts of the JDBC 4.3 specification , which forms part of Java 21, which is the Java version targeted by Helidon 4. The scope is runtime , indicating that the Oracle JDBC driver classes will be available on the runtime classpath. ",
            "title": "Setting Up a Database Driver"
        },
        {
            "location": "/mp/persistence",
            "text": " Setting Up a Connection Pool Overview Helidon MP&#8217;s named data source integration requires a connection pool implementation. Helidon MP comes with support for two connection pools: HikariCP Oracle Universal Connection Pool You can choose to use either, but not both. Details concerning each connection pool&#8217;s setup are described below. Setting Up the HikariCP Connection Pool Maven Coordinates (HikariCP) To include the HikariCP connection pool in your Helidon MP application: Ensure your dependencies are managed Ensure the following &lt;dependency&gt; element is present as a child element of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.cdi&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-cdi-datasource-hikaricp&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; The scope is runtime , indicating that the HikariCP integration will be available on the runtime classpath. Setting up the Oracle Universal Connection Pool Maven Coordinates (Oracle Universal Connection Pool) To include the Oracle Universal Connection Pool in your Helidon MP application: Ensure your dependencies are managed Ensure the following &lt;dependency&gt; element is present as a child element of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.cdi&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-cdi-datasource-ucp&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; The scope is runtime , indicating that the Oracle Universal Connection Pool integration will be available on the runtime classpath. Setting Up a Database Driver Overview Regardless of which connection pool you use, at the lowest level, JDBC database driver classes are what is ultimately responsible for making any connections to a relational database. JDBC database driver classes are database-product-specific. Once you have decided upon a relational database product to use, and JDBC driver classes to use to connect to it, ensure your dependencies are managed , and then ensure that a runtime -scoped &lt;dependency&gt; element describing your JDBC driver classes is present as a child element of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element. See the JDBC 4.3 Specification for more information about JDBC. Representative setups are described below. This list of setups is not exhaustive. Setting Up H2 Maven Coordinates (H2) To include the H2 JDBC driver classes in your Helidon MP application so your application can connect to an H2 database (whether in-memory or persistent): Ensure your dependencies are managed Ensure the following &lt;dependency&gt; element is present as a child element of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;com.h2database&lt;/groupId&gt; &lt;artifactId&gt;h2&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; The scope is runtime , indicating that the H2 JDBC driver classes will be available on the runtime classpath. Setting Up Oracle JDBC Maven Coordinates (Oracle JDBC) To include the Oracle JDBC driver classes in your Helidon MP application so your application can connect to an Oracle database : Ensure your dependencies are managed Read and understand Developer&#8217;s Guide For Oracle JDBC 21c on Maven Central For a basic setup, ensure the following &lt;dependency&gt; element is present as a child element of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;com.oracle.database.jdbc&lt;/groupId&gt; &lt;artifactId&gt;ojdbc11&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; See [Developer&#8217;s Guide For Oracle JDBC 21c on Maven Central for more details. The ojdbc11 artifact implements relevant parts of the JDBC 4.3 specification , which forms part of Java 21, which is the Java version targeted by Helidon 4. The scope is runtime , indicating that the Oracle JDBC driver classes will be available on the runtime classpath. ",
            "title": "Project Setup"
        },
        {
            "location": "/mp/persistence",
            "text": " Each connection pool supported by Helidon&#8217;s named data source integration support is, itself, a DataSource that wraps a vendor-supplied DataSource present in the JDBC driver classes you added to your project. You must configure both the pool and the vendor-supplied DataSource . To configure Helidon MP&#8217;s named data source integration: Decide where each property of the configuration will reside, as permitted by Helidon MP&#8217;s MicroProfile Config implementation Create configuration suitable for the combination of your selected connection pool and your selected vendor-supplied DataSource implementation in those locations Helidon MP&#8217;s named data source integration relies on Helidon MP&#8217;s usage of MicroProfile Config , so you have many choices for each configuration property when deciding on your configuration&#8217;s location in (1) above. The configuration property values themselves are necessarily specific to the connection pool you selected, and to the vendor-supplied DataSource responsible for actually connecting to your relational database. In general, at a minimum, in your configuration you typically supply: Information so the connection pool knows which vendor-supplied DataSource implementation to manage A JDBC URL specific to the vendor-supplied DataSource describing where the database is located, so the managed vendor-supplied DataSource knows how to connect to it Information required for the vendor-supplied DataSource to authenticate to the database and otherwise tailor itself to it Some examples for representative configurations follow. This list of configurations is not exhaustive. ",
            "title": "Overview"
        },
        {
            "location": "/mp/persistence",
            "text": " All MicroProfile Config-compatible property names for Helidon MP&#8217;s named data source integration follow a common pattern: objecttype . datasourcename . propertyname The name of a given configuration property always begins with the objecttype portion: a fully-qualified Java class name of the object being configured. Configuration for Helidon MP&#8217;s named data source integration concerns the behavior of javax.sql.DataSource objects, so Helidon MP&#8217;s named data source integration configuration property names begin with javax.sql.DataSource . A period ( . ) separates the objecttype portion from the rest of the property name. The datasourcename portion, the name of the data source being configured, comes next. It cannot contain a period ( . ). A period ( . ) separates the datasourcename portion from the rest of the property name. The propertyname portion, identifying the connection-pool- or vendor-supplied- DataSource -specific configuration property name, comes last. It may contain periods ( . ). As an example, configuration to set an imaginary foo.bar property on the test data source&#8217;s associated connection pool or vendor-specific DataSource to baz looks like this in Java .properties format: <markup lang=\"properties\" >javax.sql.DataSource.test.foo.bar=baz The objecttype portion of the configuration property name is javax.sql.DataSource . The datasourcename portion of the configuration property name is test . The propertyname portion of the configuration property name is foo.bar . ",
            "title": "Configuration Prefixes"
        },
        {
            "location": "/mp/persistence",
            "text": " Here is an example of some named data source configuration as might be found in a src/main/resources/META-INF/microprofile-config.properties configuration source: <markup lang=\"properties\" >javax.sql.DataSource.yourDataSourceName.somePropertyOfYourConnectionPoolAndDataSource = itsValue javax.sql.DataSource.yourDataSourceName.someOtherPropertyOfYourConnectionPoolAndDataSource = anotherValue ",
            "title": "Example: META-INF/microprofile-config.properties Classpath Resource"
        },
        {
            "location": "/mp/persistence",
            "text": " Here is an example of some named data source configuration using system properties on the command line instead: <markup lang=\"bash\" >java \\ -Djavax.sql.DataSource.yourDataSourceName.somePropertyOfYourConnectionPoolAndDataSource=itsValue \\ -Djavax.sql.DataSource.yourDataSourceName.someOtherPropertyOfYourConnectionPoolAndDataSource=anotherValue \\ # ... ",
            "title": "Example: System Properties Set on the Command Line"
        },
        {
            "location": "/mp/persistence",
            "text": " Here is an example of some named data source configuration using environment variables as typed directly into a command line shell, relying on MicroProfile Config&#8217;s mapping rules , since many shells will not understand environment variable names with periods (.) in them: <markup lang=\"bash\" >JAVAX_SQL_DATASOURCE_YOURDATASOURCENAME_SOMEPROPERTYOFYOURCONNECTIONPOOLANDDATASOURCE=itsValue \\ JAVAX_SQL_DATASOURCE_YOURDATASOURCENAME_SOMEOTHERPROPERTYOFYOURCONNECTIONPOOLANDDATASOURCE=anotherValue \\ java # ... ",
            "title": "Example: Environment Variables Set on the Command Line"
        },
        {
            "location": "/mp/persistence",
            "text": " Here is an example of some named data source configuration using environment variables as supplied via the env shell command , thus removing the need for MicroProfile Config&#8217;s mapping rules : <markup lang=\"bash\" >env 'javax.sql.DataSource.yourDataSourceName.somePropertyOfYourConnectionPoolAndDataSource=itsValue' \\ 'javax.sql.DataSource.yourDataSourceName.someOtherPropertyOfYourConnectionPoolAndDataSource=anotherValue' \\ java # ... ",
            "title": "Example: Environment Variables Set By the env Command"
        },
        {
            "location": "/mp/persistence",
            "text": " Here is an example of some named data source configuration as might be found in a src/main/resources/application.yaml classpath resource: <markup lang=\"yaml\" >javax: sql: DataSource: yourDataSourceName: somePropertyOfYourConnectionPoolAndDataSource: itsValue someOtherPropertyOfYourConnectionPoolAndDataSource: anotherValue ",
            "title": "Example: application.yaml Classpath Resource"
        },
        {
            "location": "/mp/persistence",
            "text": " This example presumes you have: set up the Oracle Universal Connection Pool set up Oracle JDBC This example, in Java properties file format, configures an Oracle Universal Connection Pool-managed data source named main to connect to an Oracle Database on localhost port 1521 , using the oracle.jdbc.poolOracleDataSource vendor-supplied DataSource , with a service name of XE , a user of scott , and a password of tiger : <markup lang=\"properties\" >javax.sql.DataSource.main.connectionFactoryClassName = oracle.jdbc.pool.OracleDataSource javax.sql.DataSource.main.url = jdbc:oracle:thin://@localhost:1521/XE javax.sql.DataSource.main.user = scott javax.sql.DataSource.main.password = tiger Why connectionFactoryClassName ? See PoolDataSourceImpl#setConnectionFactoryClassName(String) . See Thin-style Service Name Syntax . In general, the properties that can be set on the Oracle Universal Connection Pool can be inferred from the \"setter\" methods found in the javadoc for the PoolDataSourceImpl class . In general, the properties that can be set on the oracle.jdbc.pool.OracleDataSource DataSource implementation can be inferred from the \"setter\" methods found in its javadoc . Unlike HikariCP , the Oracle Universal Connection Pool does not distinguish cleanly between configuration properties that affect its behavior and those that affect the behavior of the vendor-supplied DataSource implementation whose connections it pools. For example, in the example above it is not possible to tell that connectionFactoryClassName is a property of the Oracle Universal Connection Pool , and user is a property of the oracle.jdbc.pool.OracleDataSource DataSource implementation . In some cases, the Oracle Universal Connection Pool will set the given property on both the connection pool itself and on the vendor-supplied DataSource it manages . ",
            "title": "Example: Configuring the Oracle Universal Connection Pool and Oracle JDBC"
        },
        {
            "location": "/mp/persistence",
            "text": " This example presumes you have: set up the HikariCP connection pool set up H2 This example, in Java properties file format, configures a HikariCP-managed data source named test to connect to an in-memory H2 database named unit-testing with a user of sa and an empty password: <markup lang=\"properties\" >javax.sql.DataSource.test.dataSourceClassName = org.h2.jdbcx.JdbcDataSource javax.sql.DataSource.test.dataSource.url = jdbc:h2:mem:unit-testing;DB_CLOSE_DELAY=-1 javax.sql.DataSource.test.dataSource.user = sa javax.sql.DataSource.test.dataSource.password = Why dataSourceClassName ? See HikariCP&#8217;s configuration documentation for information about how HikariCP separates configuration of the connection pool itself from configuration of the vendor-supplied DataSource . Why dataSource. ? See PropertyElf.java , lines 47–49 . See the H2 database&#8217;s documentation about its URL format . HikariCP&#8217;s configuration properties are described on its Github repository . Properties that should be forwarded on to the vendor-supplied DataSource are prefixed with dataSource. as seen in the example above. In general, the properties that can be set on the org.h2.jdbcx.JdbcDataSource vendor-supplied DataSource can be inferred from the \"setter\" methods found in its javadoc . ",
            "title": "Example: Configuring the HikariCP Connection Pool and H2"
        },
        {
            "location": "/mp/persistence",
            "text": " Here are some examples illustrating general named data source configuration patterns in various common MicroProfile Config-compatible locations . Example: META-INF/microprofile-config.properties Classpath Resource Here is an example of some named data source configuration as might be found in a src/main/resources/META-INF/microprofile-config.properties configuration source: <markup lang=\"properties\" >javax.sql.DataSource.yourDataSourceName.somePropertyOfYourConnectionPoolAndDataSource = itsValue javax.sql.DataSource.yourDataSourceName.someOtherPropertyOfYourConnectionPoolAndDataSource = anotherValue Example: System Properties Set on the Command Line Here is an example of some named data source configuration using system properties on the command line instead: <markup lang=\"bash\" >java \\ -Djavax.sql.DataSource.yourDataSourceName.somePropertyOfYourConnectionPoolAndDataSource=itsValue \\ -Djavax.sql.DataSource.yourDataSourceName.someOtherPropertyOfYourConnectionPoolAndDataSource=anotherValue \\ # ... Example: Environment Variables Set on the Command Line Here is an example of some named data source configuration using environment variables as typed directly into a command line shell, relying on MicroProfile Config&#8217;s mapping rules , since many shells will not understand environment variable names with periods (.) in them: <markup lang=\"bash\" >JAVAX_SQL_DATASOURCE_YOURDATASOURCENAME_SOMEPROPERTYOFYOURCONNECTIONPOOLANDDATASOURCE=itsValue \\ JAVAX_SQL_DATASOURCE_YOURDATASOURCENAME_SOMEOTHERPROPERTYOFYOURCONNECTIONPOOLANDDATASOURCE=anotherValue \\ java # ... Example: Environment Variables Set By the env Command Here is an example of some named data source configuration using environment variables as supplied via the env shell command , thus removing the need for MicroProfile Config&#8217;s mapping rules : <markup lang=\"bash\" >env 'javax.sql.DataSource.yourDataSourceName.somePropertyOfYourConnectionPoolAndDataSource=itsValue' \\ 'javax.sql.DataSource.yourDataSourceName.someOtherPropertyOfYourConnectionPoolAndDataSource=anotherValue' \\ java # ... Example: application.yaml Classpath Resource Here is an example of some named data source configuration as might be found in a src/main/resources/application.yaml classpath resource: <markup lang=\"yaml\" >javax: sql: DataSource: yourDataSourceName: somePropertyOfYourConnectionPoolAndDataSource: itsValue someOtherPropertyOfYourConnectionPoolAndDataSource: anotherValue Example: Configuring the Oracle Universal Connection Pool and Oracle JDBC This example presumes you have: set up the Oracle Universal Connection Pool set up Oracle JDBC This example, in Java properties file format, configures an Oracle Universal Connection Pool-managed data source named main to connect to an Oracle Database on localhost port 1521 , using the oracle.jdbc.poolOracleDataSource vendor-supplied DataSource , with a service name of XE , a user of scott , and a password of tiger : <markup lang=\"properties\" >javax.sql.DataSource.main.connectionFactoryClassName = oracle.jdbc.pool.OracleDataSource javax.sql.DataSource.main.url = jdbc:oracle:thin://@localhost:1521/XE javax.sql.DataSource.main.user = scott javax.sql.DataSource.main.password = tiger Why connectionFactoryClassName ? See PoolDataSourceImpl#setConnectionFactoryClassName(String) . See Thin-style Service Name Syntax . In general, the properties that can be set on the Oracle Universal Connection Pool can be inferred from the \"setter\" methods found in the javadoc for the PoolDataSourceImpl class . In general, the properties that can be set on the oracle.jdbc.pool.OracleDataSource DataSource implementation can be inferred from the \"setter\" methods found in its javadoc . Unlike HikariCP , the Oracle Universal Connection Pool does not distinguish cleanly between configuration properties that affect its behavior and those that affect the behavior of the vendor-supplied DataSource implementation whose connections it pools. For example, in the example above it is not possible to tell that connectionFactoryClassName is a property of the Oracle Universal Connection Pool , and user is a property of the oracle.jdbc.pool.OracleDataSource DataSource implementation . In some cases, the Oracle Universal Connection Pool will set the given property on both the connection pool itself and on the vendor-supplied DataSource it manages . Example: Configuring the HikariCP Connection Pool and H2 This example presumes you have: set up the HikariCP connection pool set up H2 This example, in Java properties file format, configures a HikariCP-managed data source named test to connect to an in-memory H2 database named unit-testing with a user of sa and an empty password: <markup lang=\"properties\" >javax.sql.DataSource.test.dataSourceClassName = org.h2.jdbcx.JdbcDataSource javax.sql.DataSource.test.dataSource.url = jdbc:h2:mem:unit-testing;DB_CLOSE_DELAY=-1 javax.sql.DataSource.test.dataSource.user = sa javax.sql.DataSource.test.dataSource.password = Why dataSourceClassName ? See HikariCP&#8217;s configuration documentation for information about how HikariCP separates configuration of the connection pool itself from configuration of the vendor-supplied DataSource . Why dataSource. ? See PropertyElf.java , lines 47–49 . See the H2 database&#8217;s documentation about its URL format . HikariCP&#8217;s configuration properties are described on its Github repository . Properties that should be forwarded on to the vendor-supplied DataSource are prefixed with dataSource. as seen in the example above. In general, the properties that can be set on the org.h2.jdbcx.JdbcDataSource vendor-supplied DataSource can be inferred from the \"setter\" methods found in its javadoc . ",
            "title": "Examples"
        },
        {
            "location": "/mp/persistence",
            "text": " You use Helidon MP&#8217;s named data source integration in the same way, regardless of your choices of vendor-supplied DataSource and connection pool. To use Helidon MP&#8217;s named data source integration in your application, once it has been set up and configured , create an ordinary DataSource -typed injection point in a Java class representing a CDI bean somewhere in your application, annotated with the name of the data source you wish to use. Here is how to define such a field-backed injection point: <markup lang=\"java\" >import javax.sql.DataSource; import jakarta.inject.Inject; import jakarta.inject.Named; // ... @Inject @Named(\"test\") private DataSource ds; @Inject marks the field as an injection point. Its behavior is defined by the Jakarta Dependency Injection specification . @Named(\"test\") says to use the data source named test (as declared by the datasourcename portion of a named data source configuration property). The field injection point has a type of javax.sql.DataSource , and the field itselfmay be named anything you like. Here is how to define such a constructor parameter injection point: <markup lang=\"java\" >import javax.sql.DataSource; import jakarta.inject.Inject; import jakarta.inject.Named; // ... private final DataSource ds; @Inject public SomeObject(@Named(\"test\") DataSource ds) { this.ds = ds; } This is the field whose value will be set in the constructor. @Inject marks the constructor as one containing parameter injection points. Its behavior is defined by the Jakarta Dependency Injection specification . @Named(\"test\") says to use the data source named test (as declared by the datasourcename portion of a named data source configuration property). The parameter injection point has a type of javax.sql.DataSource , and the parameter itself may be named anything you like. The injected argument will never be null . ",
            "title": "Usage"
        },
        {
            "location": "/mp/persistence",
            "text": " Overview Each connection pool supported by Helidon&#8217;s named data source integration support is, itself, a DataSource that wraps a vendor-supplied DataSource present in the JDBC driver classes you added to your project. You must configure both the pool and the vendor-supplied DataSource . To configure Helidon MP&#8217;s named data source integration: Decide where each property of the configuration will reside, as permitted by Helidon MP&#8217;s MicroProfile Config implementation Create configuration suitable for the combination of your selected connection pool and your selected vendor-supplied DataSource implementation in those locations Helidon MP&#8217;s named data source integration relies on Helidon MP&#8217;s usage of MicroProfile Config , so you have many choices for each configuration property when deciding on your configuration&#8217;s location in (1) above. The configuration property values themselves are necessarily specific to the connection pool you selected, and to the vendor-supplied DataSource responsible for actually connecting to your relational database. In general, at a minimum, in your configuration you typically supply: Information so the connection pool knows which vendor-supplied DataSource implementation to manage A JDBC URL specific to the vendor-supplied DataSource describing where the database is located, so the managed vendor-supplied DataSource knows how to connect to it Information required for the vendor-supplied DataSource to authenticate to the database and otherwise tailor itself to it Some examples for representative configurations follow. This list of configurations is not exhaustive. Configuration Prefixes All MicroProfile Config-compatible property names for Helidon MP&#8217;s named data source integration follow a common pattern: objecttype . datasourcename . propertyname The name of a given configuration property always begins with the objecttype portion: a fully-qualified Java class name of the object being configured. Configuration for Helidon MP&#8217;s named data source integration concerns the behavior of javax.sql.DataSource objects, so Helidon MP&#8217;s named data source integration configuration property names begin with javax.sql.DataSource . A period ( . ) separates the objecttype portion from the rest of the property name. The datasourcename portion, the name of the data source being configured, comes next. It cannot contain a period ( . ). A period ( . ) separates the datasourcename portion from the rest of the property name. The propertyname portion, identifying the connection-pool- or vendor-supplied- DataSource -specific configuration property name, comes last. It may contain periods ( . ). As an example, configuration to set an imaginary foo.bar property on the test data source&#8217;s associated connection pool or vendor-specific DataSource to baz looks like this in Java .properties format: <markup lang=\"properties\" >javax.sql.DataSource.test.foo.bar=baz The objecttype portion of the configuration property name is javax.sql.DataSource . The datasourcename portion of the configuration property name is test . The propertyname portion of the configuration property name is foo.bar . Examples Here are some examples illustrating general named data source configuration patterns in various common MicroProfile Config-compatible locations . Example: META-INF/microprofile-config.properties Classpath Resource Here is an example of some named data source configuration as might be found in a src/main/resources/META-INF/microprofile-config.properties configuration source: <markup lang=\"properties\" >javax.sql.DataSource.yourDataSourceName.somePropertyOfYourConnectionPoolAndDataSource = itsValue javax.sql.DataSource.yourDataSourceName.someOtherPropertyOfYourConnectionPoolAndDataSource = anotherValue Example: System Properties Set on the Command Line Here is an example of some named data source configuration using system properties on the command line instead: <markup lang=\"bash\" >java \\ -Djavax.sql.DataSource.yourDataSourceName.somePropertyOfYourConnectionPoolAndDataSource=itsValue \\ -Djavax.sql.DataSource.yourDataSourceName.someOtherPropertyOfYourConnectionPoolAndDataSource=anotherValue \\ # ... Example: Environment Variables Set on the Command Line Here is an example of some named data source configuration using environment variables as typed directly into a command line shell, relying on MicroProfile Config&#8217;s mapping rules , since many shells will not understand environment variable names with periods (.) in them: <markup lang=\"bash\" >JAVAX_SQL_DATASOURCE_YOURDATASOURCENAME_SOMEPROPERTYOFYOURCONNECTIONPOOLANDDATASOURCE=itsValue \\ JAVAX_SQL_DATASOURCE_YOURDATASOURCENAME_SOMEOTHERPROPERTYOFYOURCONNECTIONPOOLANDDATASOURCE=anotherValue \\ java # ... Example: Environment Variables Set By the env Command Here is an example of some named data source configuration using environment variables as supplied via the env shell command , thus removing the need for MicroProfile Config&#8217;s mapping rules : <markup lang=\"bash\" >env 'javax.sql.DataSource.yourDataSourceName.somePropertyOfYourConnectionPoolAndDataSource=itsValue' \\ 'javax.sql.DataSource.yourDataSourceName.someOtherPropertyOfYourConnectionPoolAndDataSource=anotherValue' \\ java # ... Example: application.yaml Classpath Resource Here is an example of some named data source configuration as might be found in a src/main/resources/application.yaml classpath resource: <markup lang=\"yaml\" >javax: sql: DataSource: yourDataSourceName: somePropertyOfYourConnectionPoolAndDataSource: itsValue someOtherPropertyOfYourConnectionPoolAndDataSource: anotherValue Example: Configuring the Oracle Universal Connection Pool and Oracle JDBC This example presumes you have: set up the Oracle Universal Connection Pool set up Oracle JDBC This example, in Java properties file format, configures an Oracle Universal Connection Pool-managed data source named main to connect to an Oracle Database on localhost port 1521 , using the oracle.jdbc.poolOracleDataSource vendor-supplied DataSource , with a service name of XE , a user of scott , and a password of tiger : <markup lang=\"properties\" >javax.sql.DataSource.main.connectionFactoryClassName = oracle.jdbc.pool.OracleDataSource javax.sql.DataSource.main.url = jdbc:oracle:thin://@localhost:1521/XE javax.sql.DataSource.main.user = scott javax.sql.DataSource.main.password = tiger Why connectionFactoryClassName ? See PoolDataSourceImpl#setConnectionFactoryClassName(String) . See Thin-style Service Name Syntax . In general, the properties that can be set on the Oracle Universal Connection Pool can be inferred from the \"setter\" methods found in the javadoc for the PoolDataSourceImpl class . In general, the properties that can be set on the oracle.jdbc.pool.OracleDataSource DataSource implementation can be inferred from the \"setter\" methods found in its javadoc . Unlike HikariCP , the Oracle Universal Connection Pool does not distinguish cleanly between configuration properties that affect its behavior and those that affect the behavior of the vendor-supplied DataSource implementation whose connections it pools. For example, in the example above it is not possible to tell that connectionFactoryClassName is a property of the Oracle Universal Connection Pool , and user is a property of the oracle.jdbc.pool.OracleDataSource DataSource implementation . In some cases, the Oracle Universal Connection Pool will set the given property on both the connection pool itself and on the vendor-supplied DataSource it manages . Example: Configuring the HikariCP Connection Pool and H2 This example presumes you have: set up the HikariCP connection pool set up H2 This example, in Java properties file format, configures a HikariCP-managed data source named test to connect to an in-memory H2 database named unit-testing with a user of sa and an empty password: <markup lang=\"properties\" >javax.sql.DataSource.test.dataSourceClassName = org.h2.jdbcx.JdbcDataSource javax.sql.DataSource.test.dataSource.url = jdbc:h2:mem:unit-testing;DB_CLOSE_DELAY=-1 javax.sql.DataSource.test.dataSource.user = sa javax.sql.DataSource.test.dataSource.password = Why dataSourceClassName ? See HikariCP&#8217;s configuration documentation for information about how HikariCP separates configuration of the connection pool itself from configuration of the vendor-supplied DataSource . Why dataSource. ? See PropertyElf.java , lines 47–49 . See the H2 database&#8217;s documentation about its URL format . HikariCP&#8217;s configuration properties are described on its Github repository . Properties that should be forwarded on to the vendor-supplied DataSource are prefixed with dataSource. as seen in the example above. In general, the properties that can be set on the org.h2.jdbcx.JdbcDataSource vendor-supplied DataSource can be inferred from the \"setter\" methods found in its javadoc . Usage You use Helidon MP&#8217;s named data source integration in the same way, regardless of your choices of vendor-supplied DataSource and connection pool. To use Helidon MP&#8217;s named data source integration in your application, once it has been set up and configured , create an ordinary DataSource -typed injection point in a Java class representing a CDI bean somewhere in your application, annotated with the name of the data source you wish to use. Here is how to define such a field-backed injection point: <markup lang=\"java\" >import javax.sql.DataSource; import jakarta.inject.Inject; import jakarta.inject.Named; // ... @Inject @Named(\"test\") private DataSource ds; @Inject marks the field as an injection point. Its behavior is defined by the Jakarta Dependency Injection specification . @Named(\"test\") says to use the data source named test (as declared by the datasourcename portion of a named data source configuration property). The field injection point has a type of javax.sql.DataSource , and the field itselfmay be named anything you like. Here is how to define such a constructor parameter injection point: <markup lang=\"java\" >import javax.sql.DataSource; import jakarta.inject.Inject; import jakarta.inject.Named; // ... private final DataSource ds; @Inject public SomeObject(@Named(\"test\") DataSource ds) { this.ds = ds; } This is the field whose value will be set in the constructor. @Inject marks the constructor as one containing parameter injection points. Its behavior is defined by the Jakarta Dependency Injection specification . @Named(\"test\") says to use the data source named test (as declared by the datasourcename portion of a named data source configuration property). The parameter injection point has a type of javax.sql.DataSource , and the parameter itself may be named anything you like. The injected argument will never be null . ",
            "title": "Configuration"
        },
        {
            "location": "/mp/persistence",
            "text": " Overview Helidon MP&#8217;s named data source integration allows you to safely inject managed javax.sql.DataSource instances that are annotated with jakarta.inject.Named annotations into your Helidon MP application. java.sql.Connection objects acquired from these data sources will be pooled by your choice of one of two possible connection pool implementations. The connections managed by the connection pool will be supplied by your relational database vendor&#8217;s JDBC driver. How you set up Helidon MP&#8217;s named data source integration differs depending on which of these two connection pools, which JDBC driver, and which relational database product you use. Representative setups are described below. This list of setups is not exhaustive. Project Setup Setting Up a Connection Pool Overview Helidon MP&#8217;s named data source integration requires a connection pool implementation. Helidon MP comes with support for two connection pools: HikariCP Oracle Universal Connection Pool You can choose to use either, but not both. Details concerning each connection pool&#8217;s setup are described below. Setting Up the HikariCP Connection Pool Maven Coordinates (HikariCP) To include the HikariCP connection pool in your Helidon MP application: Ensure your dependencies are managed Ensure the following &lt;dependency&gt; element is present as a child element of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.cdi&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-cdi-datasource-hikaricp&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; The scope is runtime , indicating that the HikariCP integration will be available on the runtime classpath. Setting up the Oracle Universal Connection Pool Maven Coordinates (Oracle Universal Connection Pool) To include the Oracle Universal Connection Pool in your Helidon MP application: Ensure your dependencies are managed Ensure the following &lt;dependency&gt; element is present as a child element of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.cdi&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-cdi-datasource-ucp&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; The scope is runtime , indicating that the Oracle Universal Connection Pool integration will be available on the runtime classpath. Setting Up a Database Driver Overview Regardless of which connection pool you use, at the lowest level, JDBC database driver classes are what is ultimately responsible for making any connections to a relational database. JDBC database driver classes are database-product-specific. Once you have decided upon a relational database product to use, and JDBC driver classes to use to connect to it, ensure your dependencies are managed , and then ensure that a runtime -scoped &lt;dependency&gt; element describing your JDBC driver classes is present as a child element of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element. See the JDBC 4.3 Specification for more information about JDBC. Representative setups are described below. This list of setups is not exhaustive. Setting Up H2 Maven Coordinates (H2) To include the H2 JDBC driver classes in your Helidon MP application so your application can connect to an H2 database (whether in-memory or persistent): Ensure your dependencies are managed Ensure the following &lt;dependency&gt; element is present as a child element of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;com.h2database&lt;/groupId&gt; &lt;artifactId&gt;h2&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; The scope is runtime , indicating that the H2 JDBC driver classes will be available on the runtime classpath. Setting Up Oracle JDBC Maven Coordinates (Oracle JDBC) To include the Oracle JDBC driver classes in your Helidon MP application so your application can connect to an Oracle database : Ensure your dependencies are managed Read and understand Developer&#8217;s Guide For Oracle JDBC 21c on Maven Central For a basic setup, ensure the following &lt;dependency&gt; element is present as a child element of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;com.oracle.database.jdbc&lt;/groupId&gt; &lt;artifactId&gt;ojdbc11&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; See [Developer&#8217;s Guide For Oracle JDBC 21c on Maven Central for more details. The ojdbc11 artifact implements relevant parts of the JDBC 4.3 specification , which forms part of Java 21, which is the Java version targeted by Helidon 4. The scope is runtime , indicating that the Oracle JDBC driver classes will be available on the runtime classpath. Configuration Overview Each connection pool supported by Helidon&#8217;s named data source integration support is, itself, a DataSource that wraps a vendor-supplied DataSource present in the JDBC driver classes you added to your project. You must configure both the pool and the vendor-supplied DataSource . To configure Helidon MP&#8217;s named data source integration: Decide where each property of the configuration will reside, as permitted by Helidon MP&#8217;s MicroProfile Config implementation Create configuration suitable for the combination of your selected connection pool and your selected vendor-supplied DataSource implementation in those locations Helidon MP&#8217;s named data source integration relies on Helidon MP&#8217;s usage of MicroProfile Config , so you have many choices for each configuration property when deciding on your configuration&#8217;s location in (1) above. The configuration property values themselves are necessarily specific to the connection pool you selected, and to the vendor-supplied DataSource responsible for actually connecting to your relational database. In general, at a minimum, in your configuration you typically supply: Information so the connection pool knows which vendor-supplied DataSource implementation to manage A JDBC URL specific to the vendor-supplied DataSource describing where the database is located, so the managed vendor-supplied DataSource knows how to connect to it Information required for the vendor-supplied DataSource to authenticate to the database and otherwise tailor itself to it Some examples for representative configurations follow. This list of configurations is not exhaustive. Configuration Prefixes All MicroProfile Config-compatible property names for Helidon MP&#8217;s named data source integration follow a common pattern: objecttype . datasourcename . propertyname The name of a given configuration property always begins with the objecttype portion: a fully-qualified Java class name of the object being configured. Configuration for Helidon MP&#8217;s named data source integration concerns the behavior of javax.sql.DataSource objects, so Helidon MP&#8217;s named data source integration configuration property names begin with javax.sql.DataSource . A period ( . ) separates the objecttype portion from the rest of the property name. The datasourcename portion, the name of the data source being configured, comes next. It cannot contain a period ( . ). A period ( . ) separates the datasourcename portion from the rest of the property name. The propertyname portion, identifying the connection-pool- or vendor-supplied- DataSource -specific configuration property name, comes last. It may contain periods ( . ). As an example, configuration to set an imaginary foo.bar property on the test data source&#8217;s associated connection pool or vendor-specific DataSource to baz looks like this in Java .properties format: <markup lang=\"properties\" >javax.sql.DataSource.test.foo.bar=baz The objecttype portion of the configuration property name is javax.sql.DataSource . The datasourcename portion of the configuration property name is test . The propertyname portion of the configuration property name is foo.bar . Examples Here are some examples illustrating general named data source configuration patterns in various common MicroProfile Config-compatible locations . Example: META-INF/microprofile-config.properties Classpath Resource Here is an example of some named data source configuration as might be found in a src/main/resources/META-INF/microprofile-config.properties configuration source: <markup lang=\"properties\" >javax.sql.DataSource.yourDataSourceName.somePropertyOfYourConnectionPoolAndDataSource = itsValue javax.sql.DataSource.yourDataSourceName.someOtherPropertyOfYourConnectionPoolAndDataSource = anotherValue Example: System Properties Set on the Command Line Here is an example of some named data source configuration using system properties on the command line instead: <markup lang=\"bash\" >java \\ -Djavax.sql.DataSource.yourDataSourceName.somePropertyOfYourConnectionPoolAndDataSource=itsValue \\ -Djavax.sql.DataSource.yourDataSourceName.someOtherPropertyOfYourConnectionPoolAndDataSource=anotherValue \\ # ... Example: Environment Variables Set on the Command Line Here is an example of some named data source configuration using environment variables as typed directly into a command line shell, relying on MicroProfile Config&#8217;s mapping rules , since many shells will not understand environment variable names with periods (.) in them: <markup lang=\"bash\" >JAVAX_SQL_DATASOURCE_YOURDATASOURCENAME_SOMEPROPERTYOFYOURCONNECTIONPOOLANDDATASOURCE=itsValue \\ JAVAX_SQL_DATASOURCE_YOURDATASOURCENAME_SOMEOTHERPROPERTYOFYOURCONNECTIONPOOLANDDATASOURCE=anotherValue \\ java # ... Example: Environment Variables Set By the env Command Here is an example of some named data source configuration using environment variables as supplied via the env shell command , thus removing the need for MicroProfile Config&#8217;s mapping rules : <markup lang=\"bash\" >env 'javax.sql.DataSource.yourDataSourceName.somePropertyOfYourConnectionPoolAndDataSource=itsValue' \\ 'javax.sql.DataSource.yourDataSourceName.someOtherPropertyOfYourConnectionPoolAndDataSource=anotherValue' \\ java # ... Example: application.yaml Classpath Resource Here is an example of some named data source configuration as might be found in a src/main/resources/application.yaml classpath resource: <markup lang=\"yaml\" >javax: sql: DataSource: yourDataSourceName: somePropertyOfYourConnectionPoolAndDataSource: itsValue someOtherPropertyOfYourConnectionPoolAndDataSource: anotherValue Example: Configuring the Oracle Universal Connection Pool and Oracle JDBC This example presumes you have: set up the Oracle Universal Connection Pool set up Oracle JDBC This example, in Java properties file format, configures an Oracle Universal Connection Pool-managed data source named main to connect to an Oracle Database on localhost port 1521 , using the oracle.jdbc.poolOracleDataSource vendor-supplied DataSource , with a service name of XE , a user of scott , and a password of tiger : <markup lang=\"properties\" >javax.sql.DataSource.main.connectionFactoryClassName = oracle.jdbc.pool.OracleDataSource javax.sql.DataSource.main.url = jdbc:oracle:thin://@localhost:1521/XE javax.sql.DataSource.main.user = scott javax.sql.DataSource.main.password = tiger Why connectionFactoryClassName ? See PoolDataSourceImpl#setConnectionFactoryClassName(String) . See Thin-style Service Name Syntax . In general, the properties that can be set on the Oracle Universal Connection Pool can be inferred from the \"setter\" methods found in the javadoc for the PoolDataSourceImpl class . In general, the properties that can be set on the oracle.jdbc.pool.OracleDataSource DataSource implementation can be inferred from the \"setter\" methods found in its javadoc . Unlike HikariCP , the Oracle Universal Connection Pool does not distinguish cleanly between configuration properties that affect its behavior and those that affect the behavior of the vendor-supplied DataSource implementation whose connections it pools. For example, in the example above it is not possible to tell that connectionFactoryClassName is a property of the Oracle Universal Connection Pool , and user is a property of the oracle.jdbc.pool.OracleDataSource DataSource implementation . In some cases, the Oracle Universal Connection Pool will set the given property on both the connection pool itself and on the vendor-supplied DataSource it manages . Example: Configuring the HikariCP Connection Pool and H2 This example presumes you have: set up the HikariCP connection pool set up H2 This example, in Java properties file format, configures a HikariCP-managed data source named test to connect to an in-memory H2 database named unit-testing with a user of sa and an empty password: <markup lang=\"properties\" >javax.sql.DataSource.test.dataSourceClassName = org.h2.jdbcx.JdbcDataSource javax.sql.DataSource.test.dataSource.url = jdbc:h2:mem:unit-testing;DB_CLOSE_DELAY=-1 javax.sql.DataSource.test.dataSource.user = sa javax.sql.DataSource.test.dataSource.password = Why dataSourceClassName ? See HikariCP&#8217;s configuration documentation for information about how HikariCP separates configuration of the connection pool itself from configuration of the vendor-supplied DataSource . Why dataSource. ? See PropertyElf.java , lines 47–49 . See the H2 database&#8217;s documentation about its URL format . HikariCP&#8217;s configuration properties are described on its Github repository . Properties that should be forwarded on to the vendor-supplied DataSource are prefixed with dataSource. as seen in the example above. In general, the properties that can be set on the org.h2.jdbcx.JdbcDataSource vendor-supplied DataSource can be inferred from the \"setter\" methods found in its javadoc . Usage You use Helidon MP&#8217;s named data source integration in the same way, regardless of your choices of vendor-supplied DataSource and connection pool. To use Helidon MP&#8217;s named data source integration in your application, once it has been set up and configured , create an ordinary DataSource -typed injection point in a Java class representing a CDI bean somewhere in your application, annotated with the name of the data source you wish to use. Here is how to define such a field-backed injection point: <markup lang=\"java\" >import javax.sql.DataSource; import jakarta.inject.Inject; import jakarta.inject.Named; // ... @Inject @Named(\"test\") private DataSource ds; @Inject marks the field as an injection point. Its behavior is defined by the Jakarta Dependency Injection specification . @Named(\"test\") says to use the data source named test (as declared by the datasourcename portion of a named data source configuration property). The field injection point has a type of javax.sql.DataSource , and the field itselfmay be named anything you like. Here is how to define such a constructor parameter injection point: <markup lang=\"java\" >import javax.sql.DataSource; import jakarta.inject.Inject; import jakarta.inject.Named; // ... private final DataSource ds; @Inject public SomeObject(@Named(\"test\") DataSource ds) { this.ds = ds; } This is the field whose value will be set in the constructor. @Inject marks the constructor as one containing parameter injection points. Its behavior is defined by the Jakarta Dependency Injection specification . @Named(\"test\") says to use the data source named test (as declared by the datasourcename portion of a named data source configuration property). The parameter injection point has a type of javax.sql.DataSource , and the parameter itself may be named anything you like. The injected argument will never be null . ",
            "title": "Named Data Source Integration"
        },
        {
            "location": "/mp/persistence",
            "text": " Helidon MP&#8217;s Jakarta Transactions integration integrates the Naryana transaction engine , an implementation of the Jakarta Transactions Specification , into Helidon MP. It lets you use @jakarta.transaction.Transactional to declare JTA transactions in your Java code. ",
            "title": "Overview"
        },
        {
            "location": "/mp/persistence",
            "text": " To include Helidon&#8217;s JTA integration in your application: Ensure your dependencies are managed Ensure the following &lt;dependency&gt; elements are present as child elements of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;jakarta.transaction&lt;/groupId&gt; &lt;artifactId&gt;jakarta.transaction-api&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.cdi&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-cdi-jta-weld&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; The scope is provided , which ensures that the JTA classes required for compilation are available at compile time. The implementation of these API classes (provided by Narayana ) will be available at runtime. ",
            "title": "Maven Coordinates (JTA)"
        },
        {
            "location": "/mp/persistence",
            "text": " Helidon MP&#8217;s Jakarta Transactions integration does not require configuration, but configuration is possible. Because configuration is of the underlying Narayana transaction engine , any restrictions are those of the engine, not of Helidon itself. Narayana, unlike Helidon MP, does not use MicroProfile Config, so its configuration options are less flexible. Some common examples of Narayana configuration follow. ",
            "title": "Overview"
        },
        {
            "location": "/mp/persistence",
            "text": " Narayana features an object store directory which it uses to store information about transaction outcomes. To set its location, you may set the ObjectStoreEnvironmentBean.objectStoreDir system property to the full path of a writeable directory: <markup lang=\"bash\" >java -DObjectStoreEnvironmentBean.objectStoreDir=/var/tmp # ... See Specifying the object store location for more information. ",
            "title": "Configuring the Object Store Directory"
        },
        {
            "location": "/mp/persistence",
            "text": " To configure Narayana&#8217;s default transaction manager timeout , set the com.arjuna.ats.arjuna.coordinator.defaultTimeout system property to an integral value in seconds: <markup lang=\"bash\" >java -Dcom.arjuna.ats.arjuna.coordinator.defaultTimeout=60 # ... For more on configuring Narayana, see Setting Properties in the Naryana documentation. ",
            "title": "Configuring the Default Transaction Manager Timeout"
        },
        {
            "location": "/mp/persistence",
            "text": " Overview Helidon MP&#8217;s Jakarta Transactions integration does not require configuration, but configuration is possible. Because configuration is of the underlying Narayana transaction engine , any restrictions are those of the engine, not of Helidon itself. Narayana, unlike Helidon MP, does not use MicroProfile Config, so its configuration options are less flexible. Some common examples of Narayana configuration follow. Configuring the Object Store Directory Narayana features an object store directory which it uses to store information about transaction outcomes. To set its location, you may set the ObjectStoreEnvironmentBean.objectStoreDir system property to the full path of a writeable directory: <markup lang=\"bash\" >java -DObjectStoreEnvironmentBean.objectStoreDir=/var/tmp # ... See Specifying the object store location for more information. Configuring the Default Transaction Manager Timeout To configure Narayana&#8217;s default transaction manager timeout , set the com.arjuna.ats.arjuna.coordinator.defaultTimeout system property to an integral value in seconds: <markup lang=\"bash\" >java -Dcom.arjuna.ats.arjuna.coordinator.defaultTimeout=60 # ... For more on configuring Narayana, see Setting Properties in the Naryana documentation. ",
            "title": "Configuration"
        },
        {
            "location": "/mp/persistence",
            "text": " To use Helidon MP&#8217;s Jakarta Transactions integration, annotate a method with the jakarta.transaction.Transactional annotation: <markup lang=\"java\" >import jakarta.transaction.Transactional; // ... @Transactional public String getGreeting(Integer id) { // Use a JTA-aware facility to do something transactional here. } The @Transactional annotation indicates that this method should be invoked in the scope of a JTA transaction. The object on which the method is invoked must be one that Helidon MP&#8217;s CDI container has created , i.e. it must be managed. ( CDI beans are managed , as are Jakarta RESTful Web Services resource classes .) For @Transactional to have any effect, whatever is used inside the method must be JTA-aware (such as a Jakarta Persistence object like a managed EntityManager ). ",
            "title": "Usage"
        },
        {
            "location": "/mp/persistence",
            "text": " Overview Helidon MP&#8217;s Jakarta Transactions integration integrates the Naryana transaction engine , an implementation of the Jakarta Transactions Specification , into Helidon MP. It lets you use @jakarta.transaction.Transactional to declare JTA transactions in your Java code. Maven Coordinates (JTA) To include Helidon&#8217;s JTA integration in your application: Ensure your dependencies are managed Ensure the following &lt;dependency&gt; elements are present as child elements of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;jakarta.transaction&lt;/groupId&gt; &lt;artifactId&gt;jakarta.transaction-api&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.cdi&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-cdi-jta-weld&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; The scope is provided , which ensures that the JTA classes required for compilation are available at compile time. The implementation of these API classes (provided by Narayana ) will be available at runtime. Configuration Overview Helidon MP&#8217;s Jakarta Transactions integration does not require configuration, but configuration is possible. Because configuration is of the underlying Narayana transaction engine , any restrictions are those of the engine, not of Helidon itself. Narayana, unlike Helidon MP, does not use MicroProfile Config, so its configuration options are less flexible. Some common examples of Narayana configuration follow. Configuring the Object Store Directory Narayana features an object store directory which it uses to store information about transaction outcomes. To set its location, you may set the ObjectStoreEnvironmentBean.objectStoreDir system property to the full path of a writeable directory: <markup lang=\"bash\" >java -DObjectStoreEnvironmentBean.objectStoreDir=/var/tmp # ... See Specifying the object store location for more information. Configuring the Default Transaction Manager Timeout To configure Narayana&#8217;s default transaction manager timeout , set the com.arjuna.ats.arjuna.coordinator.defaultTimeout system property to an integral value in seconds: <markup lang=\"bash\" >java -Dcom.arjuna.ats.arjuna.coordinator.defaultTimeout=60 # ... For more on configuring Narayana, see Setting Properties in the Naryana documentation. Usage To use Helidon MP&#8217;s Jakarta Transactions integration, annotate a method with the jakarta.transaction.Transactional annotation: <markup lang=\"java\" >import jakarta.transaction.Transactional; // ... @Transactional public String getGreeting(Integer id) { // Use a JTA-aware facility to do something transactional here. } The @Transactional annotation indicates that this method should be invoked in the scope of a JTA transaction. The object on which the method is invoked must be one that Helidon MP&#8217;s CDI container has created , i.e. it must be managed. ( CDI beans are managed , as are Jakarta RESTful Web Services resource classes .) For @Transactional to have any effect, whatever is used inside the method must be JTA-aware (such as a Jakarta Persistence object like a managed EntityManager ). ",
            "title": "Jakarta Transactions (JTA) Integration"
        },
        {
            "location": "/mp/persistence",
            "text": " Helidon MP&#8217;s Jakarta Persistence integration allows you to interact with Jakarta Persistence (JPA) objects as if your code were running in an application server, handling automatic creation and management of objects such as EntityManager and EntityManagerFactory instances. More pragmatically, it allows you to inject managed EntityManager instances using the @PersistenceContext annotation. Jakarta Persistence is a Jakarta EE specification that describes, among other things, how its implementations: Map Java objects to relational database tables Manage such persistent Java objects Interact with Jakarta Transactions Interact with named data sources Jakarta Persistence may be used in an entirely application-managed manner, which requires no integration at all. This application-managed mode places the burden of error handling, thread safety, transaction management, and other concerns on the user. This documentation does not cover application-managed mode JPA. Jakarta Persistence may also (preferably) be used in a fully container-managed manner, which requires that a container, like Helidon MP, handle error management, thread safety and transaction management on behalf of the user. This documentation covers this container-managed mode of JPA exclusively. Helidon MP&#8217;s Jakarta Persistence integration comes with support for two JPA implementations, known as JPA providers : Hibernate ORM Eclipselink In any given project, you use one or the other, but not both. How you set up Helidon MP&#8217;s Jakarta Persistence integration differs depending on which of these JPA providers you choose to use. Jakarta Persistence requires Jakarta Transactions and makes use of named data sources , so as you set up your project you will need to understand: Helidon MP&#8217;s named data source integration Helidon MP&#8217;s Jakarta Transactions integration ",
            "title": "Overview"
        },
        {
            "location": "/mp/persistence",
            "text": " While the Jakarta Persistence specification standardizes many aspects around programming and usage, it deliberately leaves many required setup and configuration aspects up to the JPA provider. You will need to set up your project differently depending on which JPA provider you choose. To set up Helidon MP&#8217;s Jakarta Persistence integration in your application to work with your chosen JPA provider, you must: Set up and configure named data sources as appropriate Set up and configure Helidon MP&#8217;s Jakarta Transactions support Include the proper Jakarta Persistence-related dependencies Set up your project to generate and compile the static metamodel Set up your project for static weaving Details and examples for each supported JPA provider are below. ",
            "title": "Overview"
        },
        {
            "location": "/mp/persistence",
            "text": " To include the Jakarta Persistence APIs that you will need and to include the core of Helidon&#8217;s Jakarta Persistence integration: Ensure your dependencies are managed Ensure you have set up and configured named data sources as appropriate Ensure you have set up and configured Helidon MP&#8217;s Jakarta Transactions support Ensure the following &lt;dependency&gt; elements are present as child elements of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;jakarta.persistence&lt;/groupId&gt; &lt;artifactId&gt;jakarta.persistence-api&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.cdi&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-cdi-jpa&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; The scope is provided , which ensures that the JPA classes required for compilation are available at compile time. The scope is runtime , which ensures that Helidon&#8217;s core, provider-independent Jakarta Persistence integration is available at runtime. These &lt;dependency&gt; elements do not set up a JPA provider. See details below for the JPA provider you have chosen to use. ",
            "title": "Maven Coordinates (Common)"
        },
        {
            "location": "/mp/persistence",
            "text": " To generate and compile the Jakarta Persistence static metamodel for your application, regardless of whether you are using Hibernate ORM or Eclipselink, ensure your dependencies are managed , and then make sure the &lt;plugin&gt; element in the following code snippet is present as a child element of the &lt;pluginManagement&gt;&lt;plugins&gt; element sequence as shown below: <markup lang=\"xml\" >&lt;pluginManagement&gt; &lt;plugins&gt; &lt;!-- ... --&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;default-compile&lt;/id&gt; &lt;configuration&gt; &lt;annotationProcessorPaths&gt; &lt;annotationProcessorPath&gt; &lt;groupId&gt;org.hibernate.orm&lt;/groupId&gt; &lt;artifactId&gt;hibernate-jpamodelgen&lt;/artifactId&gt; &lt;version&gt;${version.lib.hibernate}&lt;/version&gt; &lt;/annotationProcessorPath&gt; &lt;/annotationProcessorPaths&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;!-- ... --&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; This adds the hibernate-jpamodelgen jar, which contains a Java annotation processor that generates the static metamodel source code , to the Java compiler&#8217;s annotation processor path so that it is active at compile time. Because your dependencies are managed , this will resolve to the currently supported version of Hibernate ORM. For more on the Hibernate ORM hibernate-jpamodelgen annotation processor, see Hibernate Metamodel Generator in Hibernate ORM&#8217;s documentation. Many parts of Hibernate ORM&#8217;s documentation of this feature are outdated. ",
            "title": "Setting Up Static Metamodel Generation"
        },
        {
            "location": "/mp/persistence",
            "text": " To include Helidon&#8217;s Jakarta Persistence-related integration for Hibernate ORM: Ensure your dependencies are managed Ensure the basics of your JPA project are set up properly Ensure the following &lt;dependency&gt; elements are present as child elements of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.cdi&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-cdi-hibernate&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; The scope is runtime , which ensures that Helidon MP&#8217;s Hibernate ORM integration is available at runtime. ",
            "title": "Maven Coordinates (Hibernate ORM)"
        },
        {
            "location": "/mp/persistence",
            "text": " Hibernate ORM can alter your classes' bytecode at build time to keep track of changes made to objects participating in Jakarta Persistence workflows. To set up this required static weaving for Hibernate ORM, ensure that the following &lt;plugin&gt; element is present as a child element of your project&#8217;s pom.xml file&#8217;s &lt;plugins&gt; element: <markup lang=\"xml\" >&lt;plugin&gt; &lt;groupId&gt;org.hibernate.orm.tooling&lt;/groupId&gt; &lt;artifactId&gt;hibernate-enhance-maven-plugin&lt;/artifactId&gt; &lt;!-- Ideally, your plugin versions are managed via a &lt;pluginManagement&gt; element, which is why the &lt;version&gt; element is commented out below. If, nevertheless, you opt for the explicit version, check https://search.maven.org/artifact/org.hibernate.orm/hibernate-enhance-maven-plugin for up-to-date versions, and make sure the version is the same as that of Hibernate ORM itself. --&gt; &lt;!-- &lt;version&gt;6.3.1.Final&lt;/version&gt; --&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;Statically enhance JPA entities for Hibernate&lt;/id&gt; &lt;phase&gt;compile&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;enhance&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;failOnError&gt;true&lt;/failOnError&gt; &lt;enableDirtyTracking&gt;true&lt;/enableDirtyTracking&gt; &lt;enableLazyInitialization&gt;true&lt;/enableLazyInitialization&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; For more on the hibernate-enhance-maven-plugin in particular, see its documentation . For more on Hibernate ORM&#8217;s bytecode enhancement (weaving) in general, see Bytecode Enhancement in Hibernate ORM&#8217;s documentation. For more on bytecode enhancement properties, see Bytecode Enhancement Properties in Hibernate ORM&#8217;s documentation. ",
            "title": "Setting Up Static Weaving (Hibernate ORM)"
        },
        {
            "location": "/mp/persistence",
            "text": " To include Helidon&#8217;s Jakarta Persistence-related integration for Eclipselink: Ensure your dependencies are managed Ensure the basics of your JPA project are set up properly Ensure the following &lt;dependency&gt; elements are present as child elements of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.cdi&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-cdi-eclipselink&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; The scope is runtime , which ensures that Helidon MP&#8217;s Eclipselink integration is available at runtime. ",
            "title": "Maven Coordinates (Eclipselink)"
        },
        {
            "location": "/mp/persistence",
            "text": " Eclipselink can alter your classes' bytecode at build time to keep track of changes made to objects participating in Jakarta Persistence workflows. To set up this required static weaving for Eclipselink, ensure that the following &lt;plugin&gt; element is present as a child element of your project&#8217;s pom.xml file&#8217;s &lt;plugins&gt; element: <markup lang=\"xml\" >&lt;plugin&gt; &lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt; &lt;artifactId&gt;exec-maven-plugin&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;weave&lt;/id&gt; &lt;phase&gt;process-classes&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;java&lt;/goal&gt; &lt;/goals&gt; &lt;configuration combine.self=\"override\"&gt; &lt;classpathScope&gt;compile&lt;/classpathScope&gt; &lt;mainClass&gt;org.eclipse.persistence.tools.weaving.jpa.StaticWeave&lt;/mainClass&gt; &lt;arguments&gt; &lt;argument&gt;-loglevel&lt;/argument&gt; &lt;argument&gt;INFO&lt;/argument&gt; &lt;argument&gt;-persistenceinfo&lt;/argument&gt; &lt;argument&gt;${project.build.outputDirectory}&lt;/argument&gt; &lt;argument&gt;${project.build.outputDirectory}&lt;/argument&gt; &lt;argument&gt;${project.build.outputDirectory}&lt;/argument&gt; &lt;/arguments&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; Always check Maven Central for up-to-date versions. For more on the Eclipselink static weaving command-line utility, see Static Weaving in the Eclipselink documentation. ",
            "title": "Setting Up Static Weaving (Eclipselink)"
        },
        {
            "location": "/mp/persistence",
            "text": " Overview While the Jakarta Persistence specification standardizes many aspects around programming and usage, it deliberately leaves many required setup and configuration aspects up to the JPA provider. You will need to set up your project differently depending on which JPA provider you choose. To set up Helidon MP&#8217;s Jakarta Persistence integration in your application to work with your chosen JPA provider, you must: Set up and configure named data sources as appropriate Set up and configure Helidon MP&#8217;s Jakarta Transactions support Include the proper Jakarta Persistence-related dependencies Set up your project to generate and compile the static metamodel Set up your project for static weaving Details and examples for each supported JPA provider are below. Maven Coordinates (Common) To include the Jakarta Persistence APIs that you will need and to include the core of Helidon&#8217;s Jakarta Persistence integration: Ensure your dependencies are managed Ensure you have set up and configured named data sources as appropriate Ensure you have set up and configured Helidon MP&#8217;s Jakarta Transactions support Ensure the following &lt;dependency&gt; elements are present as child elements of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;jakarta.persistence&lt;/groupId&gt; &lt;artifactId&gt;jakarta.persistence-api&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.cdi&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-cdi-jpa&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; The scope is provided , which ensures that the JPA classes required for compilation are available at compile time. The scope is runtime , which ensures that Helidon&#8217;s core, provider-independent Jakarta Persistence integration is available at runtime. These &lt;dependency&gt; elements do not set up a JPA provider. See details below for the JPA provider you have chosen to use. Setting Up Static Metamodel Generation To generate and compile the Jakarta Persistence static metamodel for your application, regardless of whether you are using Hibernate ORM or Eclipselink, ensure your dependencies are managed , and then make sure the &lt;plugin&gt; element in the following code snippet is present as a child element of the &lt;pluginManagement&gt;&lt;plugins&gt; element sequence as shown below: <markup lang=\"xml\" >&lt;pluginManagement&gt; &lt;plugins&gt; &lt;!-- ... --&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;default-compile&lt;/id&gt; &lt;configuration&gt; &lt;annotationProcessorPaths&gt; &lt;annotationProcessorPath&gt; &lt;groupId&gt;org.hibernate.orm&lt;/groupId&gt; &lt;artifactId&gt;hibernate-jpamodelgen&lt;/artifactId&gt; &lt;version&gt;${version.lib.hibernate}&lt;/version&gt; &lt;/annotationProcessorPath&gt; &lt;/annotationProcessorPaths&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;!-- ... --&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; This adds the hibernate-jpamodelgen jar, which contains a Java annotation processor that generates the static metamodel source code , to the Java compiler&#8217;s annotation processor path so that it is active at compile time. Because your dependencies are managed , this will resolve to the currently supported version of Hibernate ORM. For more on the Hibernate ORM hibernate-jpamodelgen annotation processor, see Hibernate Metamodel Generator in Hibernate ORM&#8217;s documentation. Many parts of Hibernate ORM&#8217;s documentation of this feature are outdated. Maven Coordinates (Hibernate ORM) To include Helidon&#8217;s Jakarta Persistence-related integration for Hibernate ORM: Ensure your dependencies are managed Ensure the basics of your JPA project are set up properly Ensure the following &lt;dependency&gt; elements are present as child elements of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.cdi&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-cdi-hibernate&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; The scope is runtime , which ensures that Helidon MP&#8217;s Hibernate ORM integration is available at runtime. Setting Up Static Weaving (Hibernate ORM) Hibernate ORM can alter your classes' bytecode at build time to keep track of changes made to objects participating in Jakarta Persistence workflows. To set up this required static weaving for Hibernate ORM, ensure that the following &lt;plugin&gt; element is present as a child element of your project&#8217;s pom.xml file&#8217;s &lt;plugins&gt; element: <markup lang=\"xml\" >&lt;plugin&gt; &lt;groupId&gt;org.hibernate.orm.tooling&lt;/groupId&gt; &lt;artifactId&gt;hibernate-enhance-maven-plugin&lt;/artifactId&gt; &lt;!-- Ideally, your plugin versions are managed via a &lt;pluginManagement&gt; element, which is why the &lt;version&gt; element is commented out below. If, nevertheless, you opt for the explicit version, check https://search.maven.org/artifact/org.hibernate.orm/hibernate-enhance-maven-plugin for up-to-date versions, and make sure the version is the same as that of Hibernate ORM itself. --&gt; &lt;!-- &lt;version&gt;6.3.1.Final&lt;/version&gt; --&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;Statically enhance JPA entities for Hibernate&lt;/id&gt; &lt;phase&gt;compile&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;enhance&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;failOnError&gt;true&lt;/failOnError&gt; &lt;enableDirtyTracking&gt;true&lt;/enableDirtyTracking&gt; &lt;enableLazyInitialization&gt;true&lt;/enableLazyInitialization&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; For more on the hibernate-enhance-maven-plugin in particular, see its documentation . For more on Hibernate ORM&#8217;s bytecode enhancement (weaving) in general, see Bytecode Enhancement in Hibernate ORM&#8217;s documentation. For more on bytecode enhancement properties, see Bytecode Enhancement Properties in Hibernate ORM&#8217;s documentation. Maven Coordinates (Eclipselink) To include Helidon&#8217;s Jakarta Persistence-related integration for Eclipselink: Ensure your dependencies are managed Ensure the basics of your JPA project are set up properly Ensure the following &lt;dependency&gt; elements are present as child elements of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.cdi&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-cdi-eclipselink&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; The scope is runtime , which ensures that Helidon MP&#8217;s Eclipselink integration is available at runtime. Setting Up Static Weaving (Eclipselink) Eclipselink can alter your classes' bytecode at build time to keep track of changes made to objects participating in Jakarta Persistence workflows. To set up this required static weaving for Eclipselink, ensure that the following &lt;plugin&gt; element is present as a child element of your project&#8217;s pom.xml file&#8217;s &lt;plugins&gt; element: <markup lang=\"xml\" >&lt;plugin&gt; &lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt; &lt;artifactId&gt;exec-maven-plugin&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;weave&lt;/id&gt; &lt;phase&gt;process-classes&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;java&lt;/goal&gt; &lt;/goals&gt; &lt;configuration combine.self=\"override\"&gt; &lt;classpathScope&gt;compile&lt;/classpathScope&gt; &lt;mainClass&gt;org.eclipse.persistence.tools.weaving.jpa.StaticWeave&lt;/mainClass&gt; &lt;arguments&gt; &lt;argument&gt;-loglevel&lt;/argument&gt; &lt;argument&gt;INFO&lt;/argument&gt; &lt;argument&gt;-persistenceinfo&lt;/argument&gt; &lt;argument&gt;${project.build.outputDirectory}&lt;/argument&gt; &lt;argument&gt;${project.build.outputDirectory}&lt;/argument&gt; &lt;argument&gt;${project.build.outputDirectory}&lt;/argument&gt; &lt;/arguments&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; Always check Maven Central for up-to-date versions. For more on the Eclipselink static weaving command-line utility, see Static Weaving in the Eclipselink documentation. ",
            "title": "Setting Up a JPA Provider"
        },
        {
            "location": "/mp/persistence",
            "text": " Setting Up a JPA Provider Overview While the Jakarta Persistence specification standardizes many aspects around programming and usage, it deliberately leaves many required setup and configuration aspects up to the JPA provider. You will need to set up your project differently depending on which JPA provider you choose. To set up Helidon MP&#8217;s Jakarta Persistence integration in your application to work with your chosen JPA provider, you must: Set up and configure named data sources as appropriate Set up and configure Helidon MP&#8217;s Jakarta Transactions support Include the proper Jakarta Persistence-related dependencies Set up your project to generate and compile the static metamodel Set up your project for static weaving Details and examples for each supported JPA provider are below. Maven Coordinates (Common) To include the Jakarta Persistence APIs that you will need and to include the core of Helidon&#8217;s Jakarta Persistence integration: Ensure your dependencies are managed Ensure you have set up and configured named data sources as appropriate Ensure you have set up and configured Helidon MP&#8217;s Jakarta Transactions support Ensure the following &lt;dependency&gt; elements are present as child elements of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;jakarta.persistence&lt;/groupId&gt; &lt;artifactId&gt;jakarta.persistence-api&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.cdi&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-cdi-jpa&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; The scope is provided , which ensures that the JPA classes required for compilation are available at compile time. The scope is runtime , which ensures that Helidon&#8217;s core, provider-independent Jakarta Persistence integration is available at runtime. These &lt;dependency&gt; elements do not set up a JPA provider. See details below for the JPA provider you have chosen to use. Setting Up Static Metamodel Generation To generate and compile the Jakarta Persistence static metamodel for your application, regardless of whether you are using Hibernate ORM or Eclipselink, ensure your dependencies are managed , and then make sure the &lt;plugin&gt; element in the following code snippet is present as a child element of the &lt;pluginManagement&gt;&lt;plugins&gt; element sequence as shown below: <markup lang=\"xml\" >&lt;pluginManagement&gt; &lt;plugins&gt; &lt;!-- ... --&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;default-compile&lt;/id&gt; &lt;configuration&gt; &lt;annotationProcessorPaths&gt; &lt;annotationProcessorPath&gt; &lt;groupId&gt;org.hibernate.orm&lt;/groupId&gt; &lt;artifactId&gt;hibernate-jpamodelgen&lt;/artifactId&gt; &lt;version&gt;${version.lib.hibernate}&lt;/version&gt; &lt;/annotationProcessorPath&gt; &lt;/annotationProcessorPaths&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;!-- ... --&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; This adds the hibernate-jpamodelgen jar, which contains a Java annotation processor that generates the static metamodel source code , to the Java compiler&#8217;s annotation processor path so that it is active at compile time. Because your dependencies are managed , this will resolve to the currently supported version of Hibernate ORM. For more on the Hibernate ORM hibernate-jpamodelgen annotation processor, see Hibernate Metamodel Generator in Hibernate ORM&#8217;s documentation. Many parts of Hibernate ORM&#8217;s documentation of this feature are outdated. Maven Coordinates (Hibernate ORM) To include Helidon&#8217;s Jakarta Persistence-related integration for Hibernate ORM: Ensure your dependencies are managed Ensure the basics of your JPA project are set up properly Ensure the following &lt;dependency&gt; elements are present as child elements of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.cdi&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-cdi-hibernate&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; The scope is runtime , which ensures that Helidon MP&#8217;s Hibernate ORM integration is available at runtime. Setting Up Static Weaving (Hibernate ORM) Hibernate ORM can alter your classes' bytecode at build time to keep track of changes made to objects participating in Jakarta Persistence workflows. To set up this required static weaving for Hibernate ORM, ensure that the following &lt;plugin&gt; element is present as a child element of your project&#8217;s pom.xml file&#8217;s &lt;plugins&gt; element: <markup lang=\"xml\" >&lt;plugin&gt; &lt;groupId&gt;org.hibernate.orm.tooling&lt;/groupId&gt; &lt;artifactId&gt;hibernate-enhance-maven-plugin&lt;/artifactId&gt; &lt;!-- Ideally, your plugin versions are managed via a &lt;pluginManagement&gt; element, which is why the &lt;version&gt; element is commented out below. If, nevertheless, you opt for the explicit version, check https://search.maven.org/artifact/org.hibernate.orm/hibernate-enhance-maven-plugin for up-to-date versions, and make sure the version is the same as that of Hibernate ORM itself. --&gt; &lt;!-- &lt;version&gt;6.3.1.Final&lt;/version&gt; --&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;Statically enhance JPA entities for Hibernate&lt;/id&gt; &lt;phase&gt;compile&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;enhance&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;failOnError&gt;true&lt;/failOnError&gt; &lt;enableDirtyTracking&gt;true&lt;/enableDirtyTracking&gt; &lt;enableLazyInitialization&gt;true&lt;/enableLazyInitialization&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; For more on the hibernate-enhance-maven-plugin in particular, see its documentation . For more on Hibernate ORM&#8217;s bytecode enhancement (weaving) in general, see Bytecode Enhancement in Hibernate ORM&#8217;s documentation. For more on bytecode enhancement properties, see Bytecode Enhancement Properties in Hibernate ORM&#8217;s documentation. Maven Coordinates (Eclipselink) To include Helidon&#8217;s Jakarta Persistence-related integration for Eclipselink: Ensure your dependencies are managed Ensure the basics of your JPA project are set up properly Ensure the following &lt;dependency&gt; elements are present as child elements of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.cdi&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-cdi-eclipselink&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; The scope is runtime , which ensures that Helidon MP&#8217;s Eclipselink integration is available at runtime. Setting Up Static Weaving (Eclipselink) Eclipselink can alter your classes' bytecode at build time to keep track of changes made to objects participating in Jakarta Persistence workflows. To set up this required static weaving for Eclipselink, ensure that the following &lt;plugin&gt; element is present as a child element of your project&#8217;s pom.xml file&#8217;s &lt;plugins&gt; element: <markup lang=\"xml\" >&lt;plugin&gt; &lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt; &lt;artifactId&gt;exec-maven-plugin&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;weave&lt;/id&gt; &lt;phase&gt;process-classes&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;java&lt;/goal&gt; &lt;/goals&gt; &lt;configuration combine.self=\"override\"&gt; &lt;classpathScope&gt;compile&lt;/classpathScope&gt; &lt;mainClass&gt;org.eclipse.persistence.tools.weaving.jpa.StaticWeave&lt;/mainClass&gt; &lt;arguments&gt; &lt;argument&gt;-loglevel&lt;/argument&gt; &lt;argument&gt;INFO&lt;/argument&gt; &lt;argument&gt;-persistenceinfo&lt;/argument&gt; &lt;argument&gt;${project.build.outputDirectory}&lt;/argument&gt; &lt;argument&gt;${project.build.outputDirectory}&lt;/argument&gt; &lt;argument&gt;${project.build.outputDirectory}&lt;/argument&gt; &lt;/arguments&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; Always check Maven Central for up-to-date versions. For more on the Eclipselink static weaving command-line utility, see Static Weaving in the Eclipselink documentation. ",
            "title": "Project Setup"
        },
        {
            "location": "/mp/persistence",
            "text": " Like any configuration, a META-INF/persistence.xml file is normally an application-level concern, not a component-level concern. In other words, your Java application, made up of various components, or libraries, some of which you may have written, and many of which you have not, should normally have exactly one META-INF/persistence.xml on its classpath, describing the persistence-related aspects of the application in its particular environment. There are very few use cases where multiple META-INF/persistence.xml classpath resources are called for. A common mistake is to write a component or library&mdash;by definition intended for use in possibly more than one application&mdash;and include a src/main/resources/META-INF/persistence.xml in its Maven project. If two components or libraries containing META-INF/persistence.xml classpath resources like this are deployed as part of an application, it can make for a confusing state of affairs at application runtime, and may lead to exceptions indicating more persistence units are present than are expected. Most library projects that work with JPA artifacts should probably have a src/test/resources/META-INF/persistence.xml in their Maven projects instead. This allows you to test your JPA-centric work against a test configuration, rather than a \"main\" or production one, which is almost certainly what you want in nearly all cases. ",
            "title": "Use Only One META-INF/persistence.xml Per Application"
        },
        {
            "location": "/mp/persistence",
            "text": " Fundamentally, a META-INF/persistence.xml file contains a collection of persistence units . A persistence unit represents a collection of entities in a relational database loosely coupled to a named data source that knows how to connect to it. Your META-INF/persistence.xml file must begin (and end) with the following XML: <markup lang=\"xml\" title=\" META-INF/persistence.xml \" >&lt;persistence xmlns=\"https://jakarta.ee/xml/ns/persistence\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"https://jakarta.ee/xml/ns/persistence https://jakarta.ee/xml/ns/persistence/persistence_3_1.xsd\" version=\"3.1\"&gt; &lt;/persistence&gt; Helidon MP&#8217;s Jakarta Persistence integration supports Jakarta Persistence version 3.1 . `&lt;persistence-unit&gt; elements are listed here. ",
            "title": "Persistence Units"
        },
        {
            "location": "/mp/persistence",
            "text": " Here is a partial example of a persistence unit named test with a helpful description: <markup lang=\"xml\" title=\" META-INF/persistence.xml \" >&lt;!-- ... --&gt; &lt;persistence-unit name=\"test\" transaction-type=\"JTA\"&gt; &lt;description&gt;A testing database&lt;/description&gt; &lt;/persistence-unit&gt; &lt;!-- ... --&gt; Because Helidon MP&#8217;s JPA integration is for container-managed JPA, the transaction-type attribute must in practice always be set to JTA . The order of subsequent child elements is significant and governed by the XML schema . In most microservices, there will be only one persistence unit. A &lt;persistence-unit&gt; is represented in Jakarta Persistence as an instance of the PersistenceUnitInfo class. ",
            "title": "Example: Persistence Unit Skeleton"
        },
        {
            "location": "/mp/persistence",
            "text": " Here is a partial example of a persistence unit named test , with a helpful description, linked with a JTA data source named main : <markup lang=\"xml\" title=\" META-INF/persistence.xml \" >&lt;!-- ... ---&gt; &lt;persistence-unit name=\"test\" transaction-type=\"JTA\"&gt; &lt;description&gt;A testing database&lt;/description&gt; &lt;jta-data-source&gt;main&lt;/jta-data-source&gt; &lt;/persistence-unit&gt; &lt;!-- ... --&gt; This links this persistence unit to a data source named main , whose connectivity information can be found in a MicroProfile-Config-compatible location, as detailed in the data source configuration section above. Other persistence unit characteristics go here. ",
            "title": "Example: Persistence Unit with JTA Data Source"
        },
        {
            "location": "/mp/persistence",
            "text": " A persistence unit is always associated with exactly one named data source . Because Helidon MP&#8217;s Jakarta Persistence integration provides support for container-managed JPA, and because container-managed JPA requires Jakarta Transactions (JTA), the kind of named data source a persistence unit is associated with is always a JTA data source. The &lt;jta-data-source&gt; element, a child of the &lt;persistence-unit&gt; element, is how you link a persistence unit to a named data source you previously configured . Example: Persistence Unit with JTA Data Source Here is a partial example of a persistence unit named test , with a helpful description, linked with a JTA data source named main : <markup lang=\"xml\" title=\" META-INF/persistence.xml \" >&lt;!-- ... ---&gt; &lt;persistence-unit name=\"test\" transaction-type=\"JTA\"&gt; &lt;description&gt;A testing database&lt;/description&gt; &lt;jta-data-source&gt;main&lt;/jta-data-source&gt; &lt;/persistence-unit&gt; &lt;!-- ... --&gt; This links this persistence unit to a data source named main , whose connectivity information can be found in a MicroProfile-Config-compatible location, as detailed in the data source configuration section above. Other persistence unit characteristics go here. ",
            "title": "JTA Data Source"
        },
        {
            "location": "/mp/persistence",
            "text": " Here is a partial example of a persistence unit named test , with a helpful description, linked with a JTA data source named main , containing two entity classes: <markup lang=\"xml\" title=\" META-INF/persistence.xml \" >&lt;!-- ... ---&gt; &lt;persistence-unit name=\"test\" transaction-type=\"JTA\"&gt; &lt;description&gt;A testing database&lt;/description&gt; &lt;jta-data-source&gt;main&lt;/jta-data-source&gt; &lt;class&gt;com.example.ExampleEntity0&lt;/class&gt; &lt;class&gt;com.example.ExampleEntity1&lt;/class&gt; &lt;/persistence-unit&gt; &lt;!-- ... --&gt; Each entity class is listed with a separate &lt;class&gt; element, and there is no containing &lt;classes&gt; element or similar. Other persistence unit characteristics go here. ",
            "title": "Example: Persistence Unit with Class Elements"
        },
        {
            "location": "/mp/persistence",
            "text": " A persistence unit lists the classes that should be managed and that will take part in Jakarta Persistence workflows. You must list: Entity classes Embeddable classes Mapped superclasses Converter classes You use a sequence of &lt;class&gt; elements to do this. Each &lt;class&gt; element contains the fully-qualified class name of one of the types of managed classes listed above. There are other mechanisms that can be used in a META-INF/persistence.xml file to describe managed classes , but they may or may not be honored by a given JPA provider. Example: Persistence Unit with Class Elements Here is a partial example of a persistence unit named test , with a helpful description, linked with a JTA data source named main , containing two entity classes: <markup lang=\"xml\" title=\" META-INF/persistence.xml \" >&lt;!-- ... ---&gt; &lt;persistence-unit name=\"test\" transaction-type=\"JTA\"&gt; &lt;description&gt;A testing database&lt;/description&gt; &lt;jta-data-source&gt;main&lt;/jta-data-source&gt; &lt;class&gt;com.example.ExampleEntity0&lt;/class&gt; &lt;class&gt;com.example.ExampleEntity1&lt;/class&gt; &lt;/persistence-unit&gt; &lt;!-- ... --&gt; Each entity class is listed with a separate &lt;class&gt; element, and there is no containing &lt;classes&gt; element or similar. Other persistence unit characteristics go here. ",
            "title": "Classes"
        },
        {
            "location": "/mp/persistence",
            "text": " Here is a partial exmaple of a persistence unit named test , with a helpful description, linked with a JTA data source named sample , containing two entity classes, configuring a Hibernate ORM-specific property: <markup lang=\"xml\" title=\" META-INF/persistence.xml \" >&lt;!-- ... ---&gt; &lt;persistence-unit name=\"test\" transaction-type=\"JTA\"&gt; &lt;description&gt;A testing database&lt;/description&gt; &lt;jta-data-source&gt;sample&lt;/jta-data-source&gt; &lt;class&gt;com.example.ExampleEntity0&lt;/class&gt; &lt;class&gt;com.example.ExampleEntity1&lt;/class&gt; &lt;properties&gt; &lt;property name=\"hibernate.show_sql\" value=\"true\"/&gt; &lt;property name=\"eclipselink.weaving\" value=\"false\"/&gt; &lt;/properties&gt; &lt;/persistence-unit&gt; &lt;!-- ... --&gt; The name identifies a name present in the datasourcename portion of a named datasource configuration . There is no need for any kind of reserved prefix (like java:comp/env ). This is a Hibernate ORM-specific property and will be properly ignored if the JPA provider you have set up is Eclipselink. See Statement logging and statistics in the Hibernate ORM documentation for more details about the hibernate.show_sql property. This is an Eclipselink-specific property (and (a) is required and (b) must be set to false if you are using Eclipselink), and will be properly ignored if the JPA provider you have set up is Hibernate ORM. See weaving in the Eclipselink documentation for more details about the eclipselink.weaving property. For an exhaustive list of Hibernate ORM-specific properties, see Configurations in the Hibernate ORM documentation. For an exhaustive list of Eclipselink-specific properties, see Persistence Property Extensions Reference in the Eclipselink documentation. ",
            "title": "Example: Persistence Unit with Properties"
        },
        {
            "location": "/mp/persistence",
            "text": " Persistence units can have simple properties attached to them to further configure the backing JPA provider. You use the &lt;properties&gt; element to specify them. Helidon MP&#8217;s Jakarta Persistence integration is for container-managed JPA, so the vendor-independent properties described in the specification directly concerned with database connectivity information, such as jakarta.persistence.jdbc.url , do not apply and will be ignored if present. See the JTA Data Source section above for how a persistence unit is linked to a named data source . Example: Persistence Unit with Properties Here is a partial exmaple of a persistence unit named test , with a helpful description, linked with a JTA data source named sample , containing two entity classes, configuring a Hibernate ORM-specific property: <markup lang=\"xml\" title=\" META-INF/persistence.xml \" >&lt;!-- ... ---&gt; &lt;persistence-unit name=\"test\" transaction-type=\"JTA\"&gt; &lt;description&gt;A testing database&lt;/description&gt; &lt;jta-data-source&gt;sample&lt;/jta-data-source&gt; &lt;class&gt;com.example.ExampleEntity0&lt;/class&gt; &lt;class&gt;com.example.ExampleEntity1&lt;/class&gt; &lt;properties&gt; &lt;property name=\"hibernate.show_sql\" value=\"true\"/&gt; &lt;property name=\"eclipselink.weaving\" value=\"false\"/&gt; &lt;/properties&gt; &lt;/persistence-unit&gt; &lt;!-- ... --&gt; The name identifies a name present in the datasourcename portion of a named datasource configuration . There is no need for any kind of reserved prefix (like java:comp/env ). This is a Hibernate ORM-specific property and will be properly ignored if the JPA provider you have set up is Eclipselink. See Statement logging and statistics in the Hibernate ORM documentation for more details about the hibernate.show_sql property. This is an Eclipselink-specific property (and (a) is required and (b) must be set to false if you are using Eclipselink), and will be properly ignored if the JPA provider you have set up is Hibernate ORM. See weaving in the Eclipselink documentation for more details about the eclipselink.weaving property. For an exhaustive list of Hibernate ORM-specific properties, see Configurations in the Hibernate ORM documentation. For an exhaustive list of Eclipselink-specific properties, see Persistence Property Extensions Reference in the Eclipselink documentation. ",
            "title": "Properties"
        },
        {
            "location": "/mp/persistence",
            "text": " You list your application&#8217;s persistence units as &lt;persistence-unit&gt; child elements of the enclosing &lt;persistence&gt; element. Each &lt;persistence-unit&gt; element identifies a named persistence unit that will correspond to an EntityManager in your code, and represents a collection of entities in a relational database. Example: Persistence Unit Skeleton Here is a partial example of a persistence unit named test with a helpful description: <markup lang=\"xml\" title=\" META-INF/persistence.xml \" >&lt;!-- ... --&gt; &lt;persistence-unit name=\"test\" transaction-type=\"JTA\"&gt; &lt;description&gt;A testing database&lt;/description&gt; &lt;/persistence-unit&gt; &lt;!-- ... --&gt; Because Helidon MP&#8217;s JPA integration is for container-managed JPA, the transaction-type attribute must in practice always be set to JTA . The order of subsequent child elements is significant and governed by the XML schema . In most microservices, there will be only one persistence unit. A &lt;persistence-unit&gt; is represented in Jakarta Persistence as an instance of the PersistenceUnitInfo class. JTA Data Source A persistence unit is always associated with exactly one named data source . Because Helidon MP&#8217;s Jakarta Persistence integration provides support for container-managed JPA, and because container-managed JPA requires Jakarta Transactions (JTA), the kind of named data source a persistence unit is associated with is always a JTA data source. The &lt;jta-data-source&gt; element, a child of the &lt;persistence-unit&gt; element, is how you link a persistence unit to a named data source you previously configured . Example: Persistence Unit with JTA Data Source Here is a partial example of a persistence unit named test , with a helpful description, linked with a JTA data source named main : <markup lang=\"xml\" title=\" META-INF/persistence.xml \" >&lt;!-- ... ---&gt; &lt;persistence-unit name=\"test\" transaction-type=\"JTA\"&gt; &lt;description&gt;A testing database&lt;/description&gt; &lt;jta-data-source&gt;main&lt;/jta-data-source&gt; &lt;/persistence-unit&gt; &lt;!-- ... --&gt; This links this persistence unit to a data source named main , whose connectivity information can be found in a MicroProfile-Config-compatible location, as detailed in the data source configuration section above. Other persistence unit characteristics go here. Classes A persistence unit lists the classes that should be managed and that will take part in Jakarta Persistence workflows. You must list: Entity classes Embeddable classes Mapped superclasses Converter classes You use a sequence of &lt;class&gt; elements to do this. Each &lt;class&gt; element contains the fully-qualified class name of one of the types of managed classes listed above. There are other mechanisms that can be used in a META-INF/persistence.xml file to describe managed classes , but they may or may not be honored by a given JPA provider. Example: Persistence Unit with Class Elements Here is a partial example of a persistence unit named test , with a helpful description, linked with a JTA data source named main , containing two entity classes: <markup lang=\"xml\" title=\" META-INF/persistence.xml \" >&lt;!-- ... ---&gt; &lt;persistence-unit name=\"test\" transaction-type=\"JTA\"&gt; &lt;description&gt;A testing database&lt;/description&gt; &lt;jta-data-source&gt;main&lt;/jta-data-source&gt; &lt;class&gt;com.example.ExampleEntity0&lt;/class&gt; &lt;class&gt;com.example.ExampleEntity1&lt;/class&gt; &lt;/persistence-unit&gt; &lt;!-- ... --&gt; Each entity class is listed with a separate &lt;class&gt; element, and there is no containing &lt;classes&gt; element or similar. Other persistence unit characteristics go here. Properties Persistence units can have simple properties attached to them to further configure the backing JPA provider. You use the &lt;properties&gt; element to specify them. Helidon MP&#8217;s Jakarta Persistence integration is for container-managed JPA, so the vendor-independent properties described in the specification directly concerned with database connectivity information, such as jakarta.persistence.jdbc.url , do not apply and will be ignored if present. See the JTA Data Source section above for how a persistence unit is linked to a named data source . Example: Persistence Unit with Properties Here is a partial exmaple of a persistence unit named test , with a helpful description, linked with a JTA data source named sample , containing two entity classes, configuring a Hibernate ORM-specific property: <markup lang=\"xml\" title=\" META-INF/persistence.xml \" >&lt;!-- ... ---&gt; &lt;persistence-unit name=\"test\" transaction-type=\"JTA\"&gt; &lt;description&gt;A testing database&lt;/description&gt; &lt;jta-data-source&gt;sample&lt;/jta-data-source&gt; &lt;class&gt;com.example.ExampleEntity0&lt;/class&gt; &lt;class&gt;com.example.ExampleEntity1&lt;/class&gt; &lt;properties&gt; &lt;property name=\"hibernate.show_sql\" value=\"true\"/&gt; &lt;property name=\"eclipselink.weaving\" value=\"false\"/&gt; &lt;/properties&gt; &lt;/persistence-unit&gt; &lt;!-- ... --&gt; The name identifies a name present in the datasourcename portion of a named datasource configuration . There is no need for any kind of reserved prefix (like java:comp/env ). This is a Hibernate ORM-specific property and will be properly ignored if the JPA provider you have set up is Eclipselink. See Statement logging and statistics in the Hibernate ORM documentation for more details about the hibernate.show_sql property. This is an Eclipselink-specific property (and (a) is required and (b) must be set to false if you are using Eclipselink), and will be properly ignored if the JPA provider you have set up is Hibernate ORM. See weaving in the Eclipselink documentation for more details about the eclipselink.weaving property. For an exhaustive list of Hibernate ORM-specific properties, see Configurations in the Hibernate ORM documentation. For an exhaustive list of Eclipselink-specific properties, see Persistence Property Extensions Reference in the Eclipselink documentation. ",
            "title": "Persistence Unit"
        },
        {
            "location": "/mp/persistence",
            "text": " To configure Helidon MP&#8217;s Jakarta Persistence integration, you author a META-INF/persistence.xml file . It contains a mix of standardized elements and JPA provider-specific properties. If you are writing a component or a library, then you place this in your Maven project&#8217;s src/test/resources directory (because a library or component is not itself an application, and by definition can be included in many applications, so it is inappropriate to put application-level configuration in your component). If you are working on a project that contains the main method (or similar) that starts your application, then and only then do you place a META-INF/persistence.xml in your persistence-oriented Maven project&#8217;s src/main/resources directory. For details about the structure and syntax of the META-INF/persistence.xml file, see persistence.xml file in the Jakarta Persistence specification. Use Only One META-INF/persistence.xml Per Application Like any configuration, a META-INF/persistence.xml file is normally an application-level concern, not a component-level concern. In other words, your Java application, made up of various components, or libraries, some of which you may have written, and many of which you have not, should normally have exactly one META-INF/persistence.xml on its classpath, describing the persistence-related aspects of the application in its particular environment. There are very few use cases where multiple META-INF/persistence.xml classpath resources are called for. A common mistake is to write a component or library&mdash;by definition intended for use in possibly more than one application&mdash;and include a src/main/resources/META-INF/persistence.xml in its Maven project. If two components or libraries containing META-INF/persistence.xml classpath resources like this are deployed as part of an application, it can make for a confusing state of affairs at application runtime, and may lead to exceptions indicating more persistence units are present than are expected. Most library projects that work with JPA artifacts should probably have a src/test/resources/META-INF/persistence.xml in their Maven projects instead. This allows you to test your JPA-centric work against a test configuration, rather than a \"main\" or production one, which is almost certainly what you want in nearly all cases. Persistence Units Fundamentally, a META-INF/persistence.xml file contains a collection of persistence units . A persistence unit represents a collection of entities in a relational database loosely coupled to a named data source that knows how to connect to it. Your META-INF/persistence.xml file must begin (and end) with the following XML: <markup lang=\"xml\" title=\" META-INF/persistence.xml \" >&lt;persistence xmlns=\"https://jakarta.ee/xml/ns/persistence\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"https://jakarta.ee/xml/ns/persistence https://jakarta.ee/xml/ns/persistence/persistence_3_1.xsd\" version=\"3.1\"&gt; &lt;/persistence&gt; Helidon MP&#8217;s Jakarta Persistence integration supports Jakarta Persistence version 3.1 . `&lt;persistence-unit&gt; elements are listed here. Persistence Unit You list your application&#8217;s persistence units as &lt;persistence-unit&gt; child elements of the enclosing &lt;persistence&gt; element. Each &lt;persistence-unit&gt; element identifies a named persistence unit that will correspond to an EntityManager in your code, and represents a collection of entities in a relational database. Example: Persistence Unit Skeleton Here is a partial example of a persistence unit named test with a helpful description: <markup lang=\"xml\" title=\" META-INF/persistence.xml \" >&lt;!-- ... --&gt; &lt;persistence-unit name=\"test\" transaction-type=\"JTA\"&gt; &lt;description&gt;A testing database&lt;/description&gt; &lt;/persistence-unit&gt; &lt;!-- ... --&gt; Because Helidon MP&#8217;s JPA integration is for container-managed JPA, the transaction-type attribute must in practice always be set to JTA . The order of subsequent child elements is significant and governed by the XML schema . In most microservices, there will be only one persistence unit. A &lt;persistence-unit&gt; is represented in Jakarta Persistence as an instance of the PersistenceUnitInfo class. JTA Data Source A persistence unit is always associated with exactly one named data source . Because Helidon MP&#8217;s Jakarta Persistence integration provides support for container-managed JPA, and because container-managed JPA requires Jakarta Transactions (JTA), the kind of named data source a persistence unit is associated with is always a JTA data source. The &lt;jta-data-source&gt; element, a child of the &lt;persistence-unit&gt; element, is how you link a persistence unit to a named data source you previously configured . Example: Persistence Unit with JTA Data Source Here is a partial example of a persistence unit named test , with a helpful description, linked with a JTA data source named main : <markup lang=\"xml\" title=\" META-INF/persistence.xml \" >&lt;!-- ... ---&gt; &lt;persistence-unit name=\"test\" transaction-type=\"JTA\"&gt; &lt;description&gt;A testing database&lt;/description&gt; &lt;jta-data-source&gt;main&lt;/jta-data-source&gt; &lt;/persistence-unit&gt; &lt;!-- ... --&gt; This links this persistence unit to a data source named main , whose connectivity information can be found in a MicroProfile-Config-compatible location, as detailed in the data source configuration section above. Other persistence unit characteristics go here. Classes A persistence unit lists the classes that should be managed and that will take part in Jakarta Persistence workflows. You must list: Entity classes Embeddable classes Mapped superclasses Converter classes You use a sequence of &lt;class&gt; elements to do this. Each &lt;class&gt; element contains the fully-qualified class name of one of the types of managed classes listed above. There are other mechanisms that can be used in a META-INF/persistence.xml file to describe managed classes , but they may or may not be honored by a given JPA provider. Example: Persistence Unit with Class Elements Here is a partial example of a persistence unit named test , with a helpful description, linked with a JTA data source named main , containing two entity classes: <markup lang=\"xml\" title=\" META-INF/persistence.xml \" >&lt;!-- ... ---&gt; &lt;persistence-unit name=\"test\" transaction-type=\"JTA\"&gt; &lt;description&gt;A testing database&lt;/description&gt; &lt;jta-data-source&gt;main&lt;/jta-data-source&gt; &lt;class&gt;com.example.ExampleEntity0&lt;/class&gt; &lt;class&gt;com.example.ExampleEntity1&lt;/class&gt; &lt;/persistence-unit&gt; &lt;!-- ... --&gt; Each entity class is listed with a separate &lt;class&gt; element, and there is no containing &lt;classes&gt; element or similar. Other persistence unit characteristics go here. Properties Persistence units can have simple properties attached to them to further configure the backing JPA provider. You use the &lt;properties&gt; element to specify them. Helidon MP&#8217;s Jakarta Persistence integration is for container-managed JPA, so the vendor-independent properties described in the specification directly concerned with database connectivity information, such as jakarta.persistence.jdbc.url , do not apply and will be ignored if present. See the JTA Data Source section above for how a persistence unit is linked to a named data source . Example: Persistence Unit with Properties Here is a partial exmaple of a persistence unit named test , with a helpful description, linked with a JTA data source named sample , containing two entity classes, configuring a Hibernate ORM-specific property: <markup lang=\"xml\" title=\" META-INF/persistence.xml \" >&lt;!-- ... ---&gt; &lt;persistence-unit name=\"test\" transaction-type=\"JTA\"&gt; &lt;description&gt;A testing database&lt;/description&gt; &lt;jta-data-source&gt;sample&lt;/jta-data-source&gt; &lt;class&gt;com.example.ExampleEntity0&lt;/class&gt; &lt;class&gt;com.example.ExampleEntity1&lt;/class&gt; &lt;properties&gt; &lt;property name=\"hibernate.show_sql\" value=\"true\"/&gt; &lt;property name=\"eclipselink.weaving\" value=\"false\"/&gt; &lt;/properties&gt; &lt;/persistence-unit&gt; &lt;!-- ... --&gt; The name identifies a name present in the datasourcename portion of a named datasource configuration . There is no need for any kind of reserved prefix (like java:comp/env ). This is a Hibernate ORM-specific property and will be properly ignored if the JPA provider you have set up is Eclipselink. See Statement logging and statistics in the Hibernate ORM documentation for more details about the hibernate.show_sql property. This is an Eclipselink-specific property (and (a) is required and (b) must be set to false if you are using Eclipselink), and will be properly ignored if the JPA provider you have set up is Hibernate ORM. See weaving in the Eclipselink documentation for more details about the eclipselink.weaving property. For an exhaustive list of Hibernate ORM-specific properties, see Configurations in the Hibernate ORM documentation. For an exhaustive list of Eclipselink-specific properties, see Persistence Property Extensions Reference in the Eclipselink documentation. ",
            "title": "Configuration"
        },
        {
            "location": "/mp/persistence",
            "text": " To use Helidon MP&#8217;s Jakarta Persistence integration, once you have set up and configured your project, you use the Jakarta Persistence APIs in almost the same manner as if your project were deployed to a Jakarta EE application server. Specifically, you: Annotate your managed classes (entities, mapped superclasses, etc.) appropriately (using @Entity and similar annotations) Inject EntityManager instances appropriately with the @PersistenceContext annotation Use an injected EntityManager to work with your managed objects In addition, you use Helidon MP&#8217;s JTA integration to declare transactional boundaries where appropriate. A full tutorial of Jakarta Persistence is well beyond the scope of this documentation. Consult the specification for details on how to map your entity classes to relational database tables, and how to perform other related tasks. ",
            "title": "Usage"
        },
        {
            "location": "/mp/persistence",
            "text": " JPA Pokemons Example ",
            "title": "Examples"
        },
        {
            "location": "/mp/persistence",
            "text": " Overview Helidon MP&#8217;s Jakarta Persistence integration allows you to interact with Jakarta Persistence (JPA) objects as if your code were running in an application server, handling automatic creation and management of objects such as EntityManager and EntityManagerFactory instances. More pragmatically, it allows you to inject managed EntityManager instances using the @PersistenceContext annotation. Jakarta Persistence is a Jakarta EE specification that describes, among other things, how its implementations: Map Java objects to relational database tables Manage such persistent Java objects Interact with Jakarta Transactions Interact with named data sources Jakarta Persistence may be used in an entirely application-managed manner, which requires no integration at all. This application-managed mode places the burden of error handling, thread safety, transaction management, and other concerns on the user. This documentation does not cover application-managed mode JPA. Jakarta Persistence may also (preferably) be used in a fully container-managed manner, which requires that a container, like Helidon MP, handle error management, thread safety and transaction management on behalf of the user. This documentation covers this container-managed mode of JPA exclusively. Helidon MP&#8217;s Jakarta Persistence integration comes with support for two JPA implementations, known as JPA providers : Hibernate ORM Eclipselink In any given project, you use one or the other, but not both. How you set up Helidon MP&#8217;s Jakarta Persistence integration differs depending on which of these JPA providers you choose to use. Jakarta Persistence requires Jakarta Transactions and makes use of named data sources , so as you set up your project you will need to understand: Helidon MP&#8217;s named data source integration Helidon MP&#8217;s Jakarta Transactions integration Project Setup Setting Up a JPA Provider Overview While the Jakarta Persistence specification standardizes many aspects around programming and usage, it deliberately leaves many required setup and configuration aspects up to the JPA provider. You will need to set up your project differently depending on which JPA provider you choose. To set up Helidon MP&#8217;s Jakarta Persistence integration in your application to work with your chosen JPA provider, you must: Set up and configure named data sources as appropriate Set up and configure Helidon MP&#8217;s Jakarta Transactions support Include the proper Jakarta Persistence-related dependencies Set up your project to generate and compile the static metamodel Set up your project for static weaving Details and examples for each supported JPA provider are below. Maven Coordinates (Common) To include the Jakarta Persistence APIs that you will need and to include the core of Helidon&#8217;s Jakarta Persistence integration: Ensure your dependencies are managed Ensure you have set up and configured named data sources as appropriate Ensure you have set up and configured Helidon MP&#8217;s Jakarta Transactions support Ensure the following &lt;dependency&gt; elements are present as child elements of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;jakarta.persistence&lt;/groupId&gt; &lt;artifactId&gt;jakarta.persistence-api&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.cdi&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-cdi-jpa&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; The scope is provided , which ensures that the JPA classes required for compilation are available at compile time. The scope is runtime , which ensures that Helidon&#8217;s core, provider-independent Jakarta Persistence integration is available at runtime. These &lt;dependency&gt; elements do not set up a JPA provider. See details below for the JPA provider you have chosen to use. Setting Up Static Metamodel Generation To generate and compile the Jakarta Persistence static metamodel for your application, regardless of whether you are using Hibernate ORM or Eclipselink, ensure your dependencies are managed , and then make sure the &lt;plugin&gt; element in the following code snippet is present as a child element of the &lt;pluginManagement&gt;&lt;plugins&gt; element sequence as shown below: <markup lang=\"xml\" >&lt;pluginManagement&gt; &lt;plugins&gt; &lt;!-- ... --&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;default-compile&lt;/id&gt; &lt;configuration&gt; &lt;annotationProcessorPaths&gt; &lt;annotationProcessorPath&gt; &lt;groupId&gt;org.hibernate.orm&lt;/groupId&gt; &lt;artifactId&gt;hibernate-jpamodelgen&lt;/artifactId&gt; &lt;version&gt;${version.lib.hibernate}&lt;/version&gt; &lt;/annotationProcessorPath&gt; &lt;/annotationProcessorPaths&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;!-- ... --&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; This adds the hibernate-jpamodelgen jar, which contains a Java annotation processor that generates the static metamodel source code , to the Java compiler&#8217;s annotation processor path so that it is active at compile time. Because your dependencies are managed , this will resolve to the currently supported version of Hibernate ORM. For more on the Hibernate ORM hibernate-jpamodelgen annotation processor, see Hibernate Metamodel Generator in Hibernate ORM&#8217;s documentation. Many parts of Hibernate ORM&#8217;s documentation of this feature are outdated. Maven Coordinates (Hibernate ORM) To include Helidon&#8217;s Jakarta Persistence-related integration for Hibernate ORM: Ensure your dependencies are managed Ensure the basics of your JPA project are set up properly Ensure the following &lt;dependency&gt; elements are present as child elements of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.cdi&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-cdi-hibernate&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; The scope is runtime , which ensures that Helidon MP&#8217;s Hibernate ORM integration is available at runtime. Setting Up Static Weaving (Hibernate ORM) Hibernate ORM can alter your classes' bytecode at build time to keep track of changes made to objects participating in Jakarta Persistence workflows. To set up this required static weaving for Hibernate ORM, ensure that the following &lt;plugin&gt; element is present as a child element of your project&#8217;s pom.xml file&#8217;s &lt;plugins&gt; element: <markup lang=\"xml\" >&lt;plugin&gt; &lt;groupId&gt;org.hibernate.orm.tooling&lt;/groupId&gt; &lt;artifactId&gt;hibernate-enhance-maven-plugin&lt;/artifactId&gt; &lt;!-- Ideally, your plugin versions are managed via a &lt;pluginManagement&gt; element, which is why the &lt;version&gt; element is commented out below. If, nevertheless, you opt for the explicit version, check https://search.maven.org/artifact/org.hibernate.orm/hibernate-enhance-maven-plugin for up-to-date versions, and make sure the version is the same as that of Hibernate ORM itself. --&gt; &lt;!-- &lt;version&gt;6.3.1.Final&lt;/version&gt; --&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;Statically enhance JPA entities for Hibernate&lt;/id&gt; &lt;phase&gt;compile&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;enhance&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;failOnError&gt;true&lt;/failOnError&gt; &lt;enableDirtyTracking&gt;true&lt;/enableDirtyTracking&gt; &lt;enableLazyInitialization&gt;true&lt;/enableLazyInitialization&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; For more on the hibernate-enhance-maven-plugin in particular, see its documentation . For more on Hibernate ORM&#8217;s bytecode enhancement (weaving) in general, see Bytecode Enhancement in Hibernate ORM&#8217;s documentation. For more on bytecode enhancement properties, see Bytecode Enhancement Properties in Hibernate ORM&#8217;s documentation. Maven Coordinates (Eclipselink) To include Helidon&#8217;s Jakarta Persistence-related integration for Eclipselink: Ensure your dependencies are managed Ensure the basics of your JPA project are set up properly Ensure the following &lt;dependency&gt; elements are present as child elements of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.cdi&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-cdi-eclipselink&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; The scope is runtime , which ensures that Helidon MP&#8217;s Eclipselink integration is available at runtime. Setting Up Static Weaving (Eclipselink) Eclipselink can alter your classes' bytecode at build time to keep track of changes made to objects participating in Jakarta Persistence workflows. To set up this required static weaving for Eclipselink, ensure that the following &lt;plugin&gt; element is present as a child element of your project&#8217;s pom.xml file&#8217;s &lt;plugins&gt; element: <markup lang=\"xml\" >&lt;plugin&gt; &lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt; &lt;artifactId&gt;exec-maven-plugin&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;weave&lt;/id&gt; &lt;phase&gt;process-classes&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;java&lt;/goal&gt; &lt;/goals&gt; &lt;configuration combine.self=\"override\"&gt; &lt;classpathScope&gt;compile&lt;/classpathScope&gt; &lt;mainClass&gt;org.eclipse.persistence.tools.weaving.jpa.StaticWeave&lt;/mainClass&gt; &lt;arguments&gt; &lt;argument&gt;-loglevel&lt;/argument&gt; &lt;argument&gt;INFO&lt;/argument&gt; &lt;argument&gt;-persistenceinfo&lt;/argument&gt; &lt;argument&gt;${project.build.outputDirectory}&lt;/argument&gt; &lt;argument&gt;${project.build.outputDirectory}&lt;/argument&gt; &lt;argument&gt;${project.build.outputDirectory}&lt;/argument&gt; &lt;/arguments&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; Always check Maven Central for up-to-date versions. For more on the Eclipselink static weaving command-line utility, see Static Weaving in the Eclipselink documentation. Configuration To configure Helidon MP&#8217;s Jakarta Persistence integration, you author a META-INF/persistence.xml file . It contains a mix of standardized elements and JPA provider-specific properties. If you are writing a component or a library, then you place this in your Maven project&#8217;s src/test/resources directory (because a library or component is not itself an application, and by definition can be included in many applications, so it is inappropriate to put application-level configuration in your component). If you are working on a project that contains the main method (or similar) that starts your application, then and only then do you place a META-INF/persistence.xml in your persistence-oriented Maven project&#8217;s src/main/resources directory. For details about the structure and syntax of the META-INF/persistence.xml file, see persistence.xml file in the Jakarta Persistence specification. Use Only One META-INF/persistence.xml Per Application Like any configuration, a META-INF/persistence.xml file is normally an application-level concern, not a component-level concern. In other words, your Java application, made up of various components, or libraries, some of which you may have written, and many of which you have not, should normally have exactly one META-INF/persistence.xml on its classpath, describing the persistence-related aspects of the application in its particular environment. There are very few use cases where multiple META-INF/persistence.xml classpath resources are called for. A common mistake is to write a component or library&mdash;by definition intended for use in possibly more than one application&mdash;and include a src/main/resources/META-INF/persistence.xml in its Maven project. If two components or libraries containing META-INF/persistence.xml classpath resources like this are deployed as part of an application, it can make for a confusing state of affairs at application runtime, and may lead to exceptions indicating more persistence units are present than are expected. Most library projects that work with JPA artifacts should probably have a src/test/resources/META-INF/persistence.xml in their Maven projects instead. This allows you to test your JPA-centric work against a test configuration, rather than a \"main\" or production one, which is almost certainly what you want in nearly all cases. Persistence Units Fundamentally, a META-INF/persistence.xml file contains a collection of persistence units . A persistence unit represents a collection of entities in a relational database loosely coupled to a named data source that knows how to connect to it. Your META-INF/persistence.xml file must begin (and end) with the following XML: <markup lang=\"xml\" title=\" META-INF/persistence.xml \" >&lt;persistence xmlns=\"https://jakarta.ee/xml/ns/persistence\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"https://jakarta.ee/xml/ns/persistence https://jakarta.ee/xml/ns/persistence/persistence_3_1.xsd\" version=\"3.1\"&gt; &lt;/persistence&gt; Helidon MP&#8217;s Jakarta Persistence integration supports Jakarta Persistence version 3.1 . `&lt;persistence-unit&gt; elements are listed here. Persistence Unit You list your application&#8217;s persistence units as &lt;persistence-unit&gt; child elements of the enclosing &lt;persistence&gt; element. Each &lt;persistence-unit&gt; element identifies a named persistence unit that will correspond to an EntityManager in your code, and represents a collection of entities in a relational database. Example: Persistence Unit Skeleton Here is a partial example of a persistence unit named test with a helpful description: <markup lang=\"xml\" title=\" META-INF/persistence.xml \" >&lt;!-- ... --&gt; &lt;persistence-unit name=\"test\" transaction-type=\"JTA\"&gt; &lt;description&gt;A testing database&lt;/description&gt; &lt;/persistence-unit&gt; &lt;!-- ... --&gt; Because Helidon MP&#8217;s JPA integration is for container-managed JPA, the transaction-type attribute must in practice always be set to JTA . The order of subsequent child elements is significant and governed by the XML schema . In most microservices, there will be only one persistence unit. A &lt;persistence-unit&gt; is represented in Jakarta Persistence as an instance of the PersistenceUnitInfo class. JTA Data Source A persistence unit is always associated with exactly one named data source . Because Helidon MP&#8217;s Jakarta Persistence integration provides support for container-managed JPA, and because container-managed JPA requires Jakarta Transactions (JTA), the kind of named data source a persistence unit is associated with is always a JTA data source. The &lt;jta-data-source&gt; element, a child of the &lt;persistence-unit&gt; element, is how you link a persistence unit to a named data source you previously configured . Example: Persistence Unit with JTA Data Source Here is a partial example of a persistence unit named test , with a helpful description, linked with a JTA data source named main : <markup lang=\"xml\" title=\" META-INF/persistence.xml \" >&lt;!-- ... ---&gt; &lt;persistence-unit name=\"test\" transaction-type=\"JTA\"&gt; &lt;description&gt;A testing database&lt;/description&gt; &lt;jta-data-source&gt;main&lt;/jta-data-source&gt; &lt;/persistence-unit&gt; &lt;!-- ... --&gt; This links this persistence unit to a data source named main , whose connectivity information can be found in a MicroProfile-Config-compatible location, as detailed in the data source configuration section above. Other persistence unit characteristics go here. Classes A persistence unit lists the classes that should be managed and that will take part in Jakarta Persistence workflows. You must list: Entity classes Embeddable classes Mapped superclasses Converter classes You use a sequence of &lt;class&gt; elements to do this. Each &lt;class&gt; element contains the fully-qualified class name of one of the types of managed classes listed above. There are other mechanisms that can be used in a META-INF/persistence.xml file to describe managed classes , but they may or may not be honored by a given JPA provider. Example: Persistence Unit with Class Elements Here is a partial example of a persistence unit named test , with a helpful description, linked with a JTA data source named main , containing two entity classes: <markup lang=\"xml\" title=\" META-INF/persistence.xml \" >&lt;!-- ... ---&gt; &lt;persistence-unit name=\"test\" transaction-type=\"JTA\"&gt; &lt;description&gt;A testing database&lt;/description&gt; &lt;jta-data-source&gt;main&lt;/jta-data-source&gt; &lt;class&gt;com.example.ExampleEntity0&lt;/class&gt; &lt;class&gt;com.example.ExampleEntity1&lt;/class&gt; &lt;/persistence-unit&gt; &lt;!-- ... --&gt; Each entity class is listed with a separate &lt;class&gt; element, and there is no containing &lt;classes&gt; element or similar. Other persistence unit characteristics go here. Properties Persistence units can have simple properties attached to them to further configure the backing JPA provider. You use the &lt;properties&gt; element to specify them. Helidon MP&#8217;s Jakarta Persistence integration is for container-managed JPA, so the vendor-independent properties described in the specification directly concerned with database connectivity information, such as jakarta.persistence.jdbc.url , do not apply and will be ignored if present. See the JTA Data Source section above for how a persistence unit is linked to a named data source . Example: Persistence Unit with Properties Here is a partial exmaple of a persistence unit named test , with a helpful description, linked with a JTA data source named sample , containing two entity classes, configuring a Hibernate ORM-specific property: <markup lang=\"xml\" title=\" META-INF/persistence.xml \" >&lt;!-- ... ---&gt; &lt;persistence-unit name=\"test\" transaction-type=\"JTA\"&gt; &lt;description&gt;A testing database&lt;/description&gt; &lt;jta-data-source&gt;sample&lt;/jta-data-source&gt; &lt;class&gt;com.example.ExampleEntity0&lt;/class&gt; &lt;class&gt;com.example.ExampleEntity1&lt;/class&gt; &lt;properties&gt; &lt;property name=\"hibernate.show_sql\" value=\"true\"/&gt; &lt;property name=\"eclipselink.weaving\" value=\"false\"/&gt; &lt;/properties&gt; &lt;/persistence-unit&gt; &lt;!-- ... --&gt; The name identifies a name present in the datasourcename portion of a named datasource configuration . There is no need for any kind of reserved prefix (like java:comp/env ). This is a Hibernate ORM-specific property and will be properly ignored if the JPA provider you have set up is Eclipselink. See Statement logging and statistics in the Hibernate ORM documentation for more details about the hibernate.show_sql property. This is an Eclipselink-specific property (and (a) is required and (b) must be set to false if you are using Eclipselink), and will be properly ignored if the JPA provider you have set up is Hibernate ORM. See weaving in the Eclipselink documentation for more details about the eclipselink.weaving property. For an exhaustive list of Hibernate ORM-specific properties, see Configurations in the Hibernate ORM documentation. For an exhaustive list of Eclipselink-specific properties, see Persistence Property Extensions Reference in the Eclipselink documentation. Usage To use Helidon MP&#8217;s Jakarta Persistence integration, once you have set up and configured your project, you use the Jakarta Persistence APIs in almost the same manner as if your project were deployed to a Jakarta EE application server. Specifically, you: Annotate your managed classes (entities, mapped superclasses, etc.) appropriately (using @Entity and similar annotations) Inject EntityManager instances appropriately with the @PersistenceContext annotation Use an injected EntityManager to work with your managed objects In addition, you use Helidon MP&#8217;s JTA integration to declare transactional boundaries where appropriate. A full tutorial of Jakarta Persistence is well beyond the scope of this documentation. Consult the specification for details on how to map your entity classes to relational database tables, and how to perform other related tasks. Examples JPA Pokemons Example ",
            "title": "Jakarta Persistence (JPA)"
        },
        {
            "location": "/mp/persistence",
            "text": " Managing Dependencies in Helidon MP MicroProfile Config in Helidon MP JDBC 4.3 Specification HikariCP 5.0.1 documentation Developers Guide For Oracle JDBC 21c on Maven Central Oracle® Universal Connection Pool Developer&#8217;s Guide, Release 21c Oracle® Universal Connection Pool Java API Reference, Release 21c Oracle® Database JDBC Developer&#8217;s Guide and Reference, Release 21c Oracle® Database JDBC Java API Reference, Release 21c H2 Database Engine documentation Jakarta Transactions 2.0 Specification Jakarta Transactions 2.0 API Reference Narayana Project Documentation Narayana API Reference Jakarta Persistence {persistence-lib-jakarta-persistence-api} Specification Jakarta Persistence {persistence-lib-jakarta-persistence-api} API Reference Hibernate ORM User Guide Eclipselink documentation ",
            "title": "References"
        },
        {
            "location": "/mp/reactivemessaging/aq",
            "text": " Overview Maven Coordinates Configuration Usage ",
            "title": "Contents"
        },
        {
            "location": "/mp/reactivemessaging/aq",
            "text": " Connecting streams to Oracle AQ with Reactive Messaging couldn&#8217;t be easier. This connector extends Helidon&#8217;s JMS connector with Oracle&#8217;s AQ-specific API. ",
            "title": "Overview"
        },
        {
            "location": "/mp/reactivemessaging/aq",
            "text": " To enable AQ Connector add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.messaging.aq&lt;/groupId&gt; &lt;artifactId&gt;helidon-messaging-aq&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/reactivemessaging/aq",
            "text": " The simplest possible usage is leaving construction of AQjmsConnectionFactory to the connector. <markup lang=\"yaml\" title=\"Example of connector config:\" >mp: messaging: connector: helidon-aq: transacted: false acknowledge-mode: CLIENT_ACKNOWLEDGE url: jdbc:oracle:thin:@(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(Host=192.168.0.123)(Port=1521))(CONNECT_DATA=(SID=TESTSID))) user: gandalf password: mellon outgoing.to-aq: connector: helidon-aq destination: TESTQUEUE type: queue incoming.from-aq: connector: helidon-aq destination: TESTQUEUE type: queue Its also possible and preferable to refer to configured datasource , in our example Oracle UCP datasource : <markup lang=\"yaml\" title=\"Example of connector config with Oracle UCP datasource:\" >javax: sql: DataSource: aq-test-ds: connectionFactoryClassName: oracle.jdbc.pool.OracleDataSource URL: jdbc:oracle:thin:@exampledb_high?TNS_ADMIN=/home/gandalf/wallets/Wallet_EXAMPLEDB user: gandalf password: SuperSecretPassword1234 mp: messaging: connector: helidon-aq: transacted: false acknowledge-mode: CLIENT_ACKNOWLEDGE data-source: aq-test-ds outgoing.toJms: connector: helidon-aq destination: TESTQUEUE type: queue incoming.fromJms: connector: helidon-aq destination: TESTQUEUE type: queue ",
            "title": "Configured JMS Factory"
        },
        {
            "location": "/mp/reactivemessaging/aq",
            "text": " If you need more advanced configurations, connector can work with injected AQjmsConnectionFactory : <markup lang=\"java\" title=\"Inject:\" > @Produces @ApplicationScoped @Named(\"aq-orderdb-factory\") public AQjmsConnectionFactory connectionFactory() throws JMSException { AQjmsQueueConnectionFactory fact = new AQjmsQueueConnectionFactory(); fact.setJdbcURL(config.get(\"jdbc.url\").asString().get()); fact.setUsername(config.get(\"jdbc.user\").asString().get()); fact.setPassword(config.get(\"jdbc.pass\").asString().get()); return fact; } <markup lang=\"yaml\" title=\"Config:\" >jdbc: url: jdbc:oracle:thin:@(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(Host=192.168.0.123)(Port=1521))(CONNECT_DATA=(SID=TESTSID))) user: gandalf pass: mellon mp: messaging: connector: helidon-aq: named-factory: aq-orderdb-factory outgoing.to-aq: connector: helidon-aq session-group-id: order-connection-1 destination: TESTQUEUE type: queue incoming.from-aq: connector: helidon-aq session-group-id: order-connection-1 destination: TESTQUEUE type: queue ",
            "title": "Injected JMS factory"
        },
        {
            "location": "/mp/reactivemessaging/aq",
            "text": " Connector name: helidon-aq Attributes datasource name of the datasource bean used to connect Oracle DB with AQ url jdbc connection string used to connect Oracle DB with AQ (forbidden when datasource is specified) username User name used to connect Oracle DB with AQ (forbidden when datasource is specified) password Password to connect Oracle DB with AQ (forbidden when datasource is specified) type Possible values are: queue , topic destination Queue or topic name acknowledge-mode Possible values are: AUTO_ACKNOWLEDGE - session automatically acknowledges a client’s receipt of a message, CLIENT_ACKNOWLEDGE - receipt of a message is acknowledged only when Message.ack() is called manually, DUPS_OK_ACKNOWLEDGE - session lazily acknowledges the delivery of messages. Default value: AUTO_ACKNOWLEDGE transacted Indicates whether the session will use a local transaction. Default value: false message-selector JMS API message selector expression based on a subset of the SQL92. Expression can only access headers and properties, not the payload. client-id Client identifier for JMS connection. durable True for creating durable consumer (only for topic). Default value: false subscriber-name Subscriber name for durable consumer used to identify subscription. non-local If true then any messages published to the topic using this session&#8217;s connection, or any other connection with the same client identifier, will not be added to the durable subscription. Default value: false named-factory Select in case factory is injected as a named bean or configured with name. poll-timeout Timeout for polling for next message in every poll cycle in millis. Default value: 50 period-executions Period for executing poll cycles in millis. Default value: 100 session-group-id When multiple channels share same session-group-id , they share same JMS session and same JDBC connection as well. Configured JMS Factory The simplest possible usage is leaving construction of AQjmsConnectionFactory to the connector. <markup lang=\"yaml\" title=\"Example of connector config:\" >mp: messaging: connector: helidon-aq: transacted: false acknowledge-mode: CLIENT_ACKNOWLEDGE url: jdbc:oracle:thin:@(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(Host=192.168.0.123)(Port=1521))(CONNECT_DATA=(SID=TESTSID))) user: gandalf password: mellon outgoing.to-aq: connector: helidon-aq destination: TESTQUEUE type: queue incoming.from-aq: connector: helidon-aq destination: TESTQUEUE type: queue Its also possible and preferable to refer to configured datasource , in our example Oracle UCP datasource : <markup lang=\"yaml\" title=\"Example of connector config with Oracle UCP datasource:\" >javax: sql: DataSource: aq-test-ds: connectionFactoryClassName: oracle.jdbc.pool.OracleDataSource URL: jdbc:oracle:thin:@exampledb_high?TNS_ADMIN=/home/gandalf/wallets/Wallet_EXAMPLEDB user: gandalf password: SuperSecretPassword1234 mp: messaging: connector: helidon-aq: transacted: false acknowledge-mode: CLIENT_ACKNOWLEDGE data-source: aq-test-ds outgoing.toJms: connector: helidon-aq destination: TESTQUEUE type: queue incoming.fromJms: connector: helidon-aq destination: TESTQUEUE type: queue Injected JMS factory If you need more advanced configurations, connector can work with injected AQjmsConnectionFactory : <markup lang=\"java\" title=\"Inject:\" > @Produces @ApplicationScoped @Named(\"aq-orderdb-factory\") public AQjmsConnectionFactory connectionFactory() throws JMSException { AQjmsQueueConnectionFactory fact = new AQjmsQueueConnectionFactory(); fact.setJdbcURL(config.get(\"jdbc.url\").asString().get()); fact.setUsername(config.get(\"jdbc.user\").asString().get()); fact.setPassword(config.get(\"jdbc.pass\").asString().get()); return fact; } <markup lang=\"yaml\" title=\"Config:\" >jdbc: url: jdbc:oracle:thin:@(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(Host=192.168.0.123)(Port=1521))(CONNECT_DATA=(SID=TESTSID))) user: gandalf pass: mellon mp: messaging: connector: helidon-aq: named-factory: aq-orderdb-factory outgoing.to-aq: connector: helidon-aq session-group-id: order-connection-1 destination: TESTQUEUE type: queue incoming.from-aq: connector: helidon-aq session-group-id: order-connection-1 destination: TESTQUEUE type: queue ",
            "title": "Configuration"
        },
        {
            "location": "/mp/reactivemessaging/aq",
            "text": "<markup lang=\"java\" title=\"Consuming one by one unwrapped value:\" >@Incoming(\"from-aq\") public void consumeAq(String msg) { System.out.println(\"Oracle AQ says: \" + msg); } <markup lang=\"java\" title=\"Consuming one by one, manual ack:\" >@Incoming(\"from-aq\") @Acknowledgment(Acknowledgment.Strategy.MANUAL) public CompletionStage&lt;?&gt; consumeAq(AqMessage&lt;String&gt; msg) { // direct commit //msg.getDbConnection().commit(); System.out.println(\"Oracle AQ says: \" + msg.getPayload()); // ack commits only in non-transacted mode return msg.ack(); } ",
            "title": "Consuming"
        },
        {
            "location": "/mp/reactivemessaging/aq",
            "text": "<markup lang=\"java\" title=\"Producing to AQ:\" >@Outgoing(\"to-aq\") public PublisherBuilder&lt;String&gt; produceToAq() { return ReactiveStreams.of(\"test1\", \"test2\"); } ",
            "title": "Producing"
        },
        {
            "location": "/mp/reactivemessaging/aq",
            "text": " Consuming <markup lang=\"java\" title=\"Consuming one by one unwrapped value:\" >@Incoming(\"from-aq\") public void consumeAq(String msg) { System.out.println(\"Oracle AQ says: \" + msg); } <markup lang=\"java\" title=\"Consuming one by one, manual ack:\" >@Incoming(\"from-aq\") @Acknowledgment(Acknowledgment.Strategy.MANUAL) public CompletionStage&lt;?&gt; consumeAq(AqMessage&lt;String&gt; msg) { // direct commit //msg.getDbConnection().commit(); System.out.println(\"Oracle AQ says: \" + msg.getPayload()); // ack commits only in non-transacted mode return msg.ack(); } Producing <markup lang=\"java\" title=\"Producing to AQ:\" >@Outgoing(\"to-aq\") public PublisherBuilder&lt;String&gt; produceToAq() { return ReactiveStreams.of(\"test1\", \"test2\"); } ",
            "title": "Usage"
        },
        {
            "location": "/mp/reactivemessaging/introduction",
            "text": " Overview Maven Coordinates Usage Configuration Reference ",
            "title": "Contents"
        },
        {
            "location": "/mp/reactivemessaging/introduction",
            "text": " Reactive messaging offers a new way of processing messages that is different from the older method of using message-driven beans. One significant difference is that blocking is no longer the only way to apply backpressure to the message source. Reactive messaging uses reactive streams as message channels so you can construct very effective pipelines for working with the messages or, if you prefer, you can continue to use older messaging methods. Like the message-driven beans, MicroProfile Reactive Messaging uses CDI beans to produce, consume or process messages over Reactive Streams. These messaging beans are expected to be either ApplicationScoped or Dependent scoped. Messages are managed by methods annotated by @Incoming and @Outgoing and the invocation is always driven by message core - either at assembly time, or for every message coming from the stream. ",
            "title": "Overview"
        },
        {
            "location": "/mp/reactivemessaging/introduction",
            "text": " To enable MicroProfile Reactive Messaging add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.messaging&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-messaging&lt;/artifactId&gt; &lt;/dependency&gt; To include health checks for Messaging add the following dependency: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.messaging&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-messaging-health&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/reactivemessaging/introduction",
            "text": " Consuming methods can be connected to the channel&#8217;s downstream to consume the message coming through the channel. The incoming annotation has one required attribute value that defines the channel name. Consuming method can function in two ways: consume every message coming from the stream connected to the channels - invoked per each message prepare reactive stream&#8217;s subscriber and connect it to the channel - invoked only once during the channel construction <markup lang=\"java\" title=\"Example consuming every message from channel example-channel-2 :\" >@Incoming(\"example-channel-2\") public void printMessage(String msg) { System.out.println(\"Just received message: \" + msg); } <markup lang=\"java\" title=\"Example preparing reactive stream subscriber for channel example-channel-1 :\" >@Incoming(\"example-channel-2\") public Subscriber&lt;String&gt; printMessage() { return ReactiveStreams.&lt;String&gt;builder() .forEach(msg -&gt; System.out.println(\"Just received message: \" + msg)) .build(); } ",
            "title": "Consuming Method"
        },
        {
            "location": "/mp/reactivemessaging/introduction",
            "text": " Directly injected publisher can be connected as a channel downstream, you can consume the data from the channel by subscribing to it. Helidon can inject following types of publishers: Publisher&lt;PAYLOAD&gt; - Reactive streams publisher with unwrapped payload Publisher&lt;Message&lt;PAYLOAD&gt;&gt; - Reactive streams publisher with whole message PublisherBuilder&lt;PAYLOAD&gt; - MP Reactive streams operators publisher builder with unwrapped payload PublisherBuilder&lt;Message&lt;PAYLOAD&gt;&gt; - MP Reactive streams operators publisher builder with whole message Flow.Publisher&lt;PAYLOAD&gt; - JDK&#8217;s flow publisher with unwrapped payload Flow.Publisher&lt;Message&lt;PAYLOAD&gt;&gt; - JDK&#8217;s flow publisher with whole message Multi&lt;PAYLOAD&gt; - Helidon flow reactive operators with unwrapped payload Multi&lt;Message&lt;PAYLOAD&gt;&gt; - Helidon flow reactive operators with whole message <markup lang=\"java\" title=\"Example of consuming payloads from channel example-channel-1 with injected publisher:\" >@Inject public MyBean(@Channel(\"example-channel-1\") Multi&lt;String&gt; multiChannel) { multiChannel .map(String::toUpperCase) .forEach(s -&gt; System.out.println(\"Received \" + s)); } ",
            "title": "Injected Publisher"
        },
        {
            "location": "/mp/reactivemessaging/introduction",
            "text": " The annotation has one required attribute value that defines the channel name. The annotated messaging method can function in two ways: produce exactly one message to the stream connected to the channel prepare reactive stream&#8217;s publisher and connect it to the channel <markup lang=\"java\" title=\"Example producing exactly one message to channel example-channel-1 :\" >@Outgoing(\"example-channel-1\") public String produceMessage() { return \"foo\"; } <markup lang=\"java\" title=\"Example preparing reactive stream publisher publishing three messages to the channel example-channel-1 :\" >@Outgoing(\"example-channel-1\") public Publisher&lt;String&gt; printMessage() { return ReactiveStreams.of(\"foo\", \"bar\", \"baz\").buildRs(); } Messaging methods are not meant to be invoked directly! ",
            "title": "Producing Method"
        },
        {
            "location": "/mp/reactivemessaging/introduction",
            "text": " Reactive messaging uses named channels to connect one source (upstream) with one consumer (downstream). Each channel needs to have both ends connected otherwise the container cannot successfully start. Channels can be connected either to emitter (1), producing method (2) or connector (3) on the upstream side. And injected publisher (4), consuming method (5) or connector (6) on the downstream. Consuming Method Consuming methods can be connected to the channel&#8217;s downstream to consume the message coming through the channel. The incoming annotation has one required attribute value that defines the channel name. Consuming method can function in two ways: consume every message coming from the stream connected to the channels - invoked per each message prepare reactive stream&#8217;s subscriber and connect it to the channel - invoked only once during the channel construction <markup lang=\"java\" title=\"Example consuming every message from channel example-channel-2 :\" >@Incoming(\"example-channel-2\") public void printMessage(String msg) { System.out.println(\"Just received message: \" + msg); } <markup lang=\"java\" title=\"Example preparing reactive stream subscriber for channel example-channel-1 :\" >@Incoming(\"example-channel-2\") public Subscriber&lt;String&gt; printMessage() { return ReactiveStreams.&lt;String&gt;builder() .forEach(msg -&gt; System.out.println(\"Just received message: \" + msg)) .build(); } Injected Publisher Directly injected publisher can be connected as a channel downstream, you can consume the data from the channel by subscribing to it. Helidon can inject following types of publishers: Publisher&lt;PAYLOAD&gt; - Reactive streams publisher with unwrapped payload Publisher&lt;Message&lt;PAYLOAD&gt;&gt; - Reactive streams publisher with whole message PublisherBuilder&lt;PAYLOAD&gt; - MP Reactive streams operators publisher builder with unwrapped payload PublisherBuilder&lt;Message&lt;PAYLOAD&gt;&gt; - MP Reactive streams operators publisher builder with whole message Flow.Publisher&lt;PAYLOAD&gt; - JDK&#8217;s flow publisher with unwrapped payload Flow.Publisher&lt;Message&lt;PAYLOAD&gt;&gt; - JDK&#8217;s flow publisher with whole message Multi&lt;PAYLOAD&gt; - Helidon flow reactive operators with unwrapped payload Multi&lt;Message&lt;PAYLOAD&gt;&gt; - Helidon flow reactive operators with whole message <markup lang=\"java\" title=\"Example of consuming payloads from channel example-channel-1 with injected publisher:\" >@Inject public MyBean(@Channel(\"example-channel-1\") Multi&lt;String&gt; multiChannel) { multiChannel .map(String::toUpperCase) .forEach(s -&gt; System.out.println(\"Received \" + s)); } Producing Method The annotation has one required attribute value that defines the channel name. The annotated messaging method can function in two ways: produce exactly one message to the stream connected to the channel prepare reactive stream&#8217;s publisher and connect it to the channel <markup lang=\"java\" title=\"Example producing exactly one message to channel example-channel-1 :\" >@Outgoing(\"example-channel-1\") public String produceMessage() { return \"foo\"; } <markup lang=\"java\" title=\"Example preparing reactive stream publisher publishing three messages to the channel example-channel-1 :\" >@Outgoing(\"example-channel-1\") public Publisher&lt;String&gt; printMessage() { return ReactiveStreams.of(\"foo\", \"bar\", \"baz\").buildRs(); } Messaging methods are not meant to be invoked directly! ",
            "title": "Channels"
        },
        {
            "location": "/mp/reactivemessaging/introduction",
            "text": " Such methods acts as processors, consuming messages from one channel and producing to another. Diagram shows how processing method (2) serves as a downstream to the my-channel (1) and an upstream to the other-channel (3), connecting them together. Processing method can function in multiple ways: process every message prepare reactive stream&#8217;s processor and connect it between the channels on every message prepare new publisher(equivalent to flatMap operator) <markup lang=\"java\" title=\"Example processing every message from channel example-channel-1 to channel example-channel-2 :\" >@Incoming(\"example-channel-1\") @Outgoing(\"example-channel-2\") public String processMessage(String msg) { return msg.toUpperCase(); } <markup lang=\"java\" title=\"Example preparing processor stream to be connected between channels example-channel-1 and example-channel-2 :\" >@Incoming(\"example-channel-1\") @Outgoing(\"example-channel-2\") public Processor&lt;String, String&gt; processMessage() { return ReactiveStreams.&lt;String&gt;builder() .map(String::toUpperCase) .buildRs(); } <markup lang=\"java\" title=\"Example processing every message from channel example-channel-1`as stream to be flattened to channel `example-channel-2 :\" >@Incoming(\"example-channel-1\") @Outgoing(\"example-channel-2\") public String processMessage(String msg) { return ReactiveStreams.of(msg.toUpperCase(), msg.toLowerCase()).buildRs(); } ",
            "title": "Processing Method"
        },
        {
            "location": "/mp/reactivemessaging/introduction",
            "text": " To send messages from imperative code, you can inject a special channel source called an emitter. Emitter can serve only as an upstream, source of the messages, for messaging channel. <markup lang=\"java\" title=\"Example of sending message from JAX-RS method to channel example-channel-1 \" >@Inject @Channel(\"example-channel-1\") private Emitter&lt;String&gt; emitter; @PUT @Path(\"/sendMessage\") @Consumes(MediaType.TEXT_PLAIN) public Response sendMessage(final String payload) { emitter.send(payload); } Emitters, as a source of messages for reactive channels, need to address possible backpressure from the downstream side of the channel. In case there is not enough demand from the downstream, you can configure a buffer size strategy using the @OnOverflow annotation. Additional overflow strategies are described below. Overflow strategies Strategy Description BUFFER Buffer unconsumed values until configured bufferSize is reached, when reached calling Emitter.emit throws IllegalStateException . Buffer size can be configured with @OnOverflow or with config key mp.messaging.emitter.default-buffer-size . Default value is 128 . UNBOUNDED_BUFFER Buffer unconsumed values until application runs out of memory. THROW_EXCEPTION Calling Emitter.emit throws IllegalStateException if there is not enough items requested by downstream. DROP If there is not enough items requested by downstream, emitted message is silently dropped. FAIL If there is not enough items requested by downstream, emitting message causes error signal being send to downstream. Whole channel is terminated. No other messages can be sent. LATEST Keeps only the latest item. Any previous unconsumed message is silently dropped. NONE Messages are sent to downstream even if there is no demand. Backpressure is effectively ignored. Processing Method Such methods acts as processors, consuming messages from one channel and producing to another. Diagram shows how processing method (2) serves as a downstream to the my-channel (1) and an upstream to the other-channel (3), connecting them together. Processing method can function in multiple ways: process every message prepare reactive stream&#8217;s processor and connect it between the channels on every message prepare new publisher(equivalent to flatMap operator) <markup lang=\"java\" title=\"Example processing every message from channel example-channel-1 to channel example-channel-2 :\" >@Incoming(\"example-channel-1\") @Outgoing(\"example-channel-2\") public String processMessage(String msg) { return msg.toUpperCase(); } <markup lang=\"java\" title=\"Example preparing processor stream to be connected between channels example-channel-1 and example-channel-2 :\" >@Incoming(\"example-channel-1\") @Outgoing(\"example-channel-2\") public Processor&lt;String, String&gt; processMessage() { return ReactiveStreams.&lt;String&gt;builder() .map(String::toUpperCase) .buildRs(); } <markup lang=\"java\" title=\"Example processing every message from channel example-channel-1`as stream to be flattened to channel `example-channel-2 :\" >@Incoming(\"example-channel-1\") @Outgoing(\"example-channel-2\") public String processMessage(String msg) { return ReactiveStreams.of(msg.toUpperCase(), msg.toLowerCase()).buildRs(); } ",
            "title": "Emitter"
        },
        {
            "location": "/mp/reactivemessaging/introduction",
            "text": " Messaging connector is an application-scoped bean that implements one or both of following interfaces: IncomingConnectorFactory - connector can create an upstream publisher to produce messages to a channel OutgoingConnectorFactory - connector can create a downstream subscriber to consume messages from a channel <markup lang=\"java\" title=\"Example connector example-connector :\" >@ApplicationScoped @Connector(\"example-connector\") public class ExampleConnector implements IncomingConnectorFactory, OutgoingConnectorFactory { @Override public PublisherBuilder&lt;? extends Message&lt;?&gt;&gt; getPublisherBuilder(Config config) { return ReactiveStreams.of(\"foo\", \"bar\") .map(Message::of); } @Override public SubscriberBuilder&lt;? extends Message&lt;?&gt;, Void&gt; getSubscriberBuilder(Config config) { return ReactiveStreams.&lt;Message&lt;?&gt;&gt;builder() .map(Message::getPayload) .forEach(o -&gt; System.out.println(\"Connector says: \" + o)); } } ",
            "title": "Connector"
        },
        {
            "location": "/mp/reactivemessaging/introduction",
            "text": " The Reactive Messaging Message class can be used to wrap or unwrap data items between methods and connectors. The message wrapping and unwrapping can be performed explicitly by using org.eclipse.microprofile.reactive.messaging.Message#of(T) or implicitly through the messaging core. <markup lang=\"java\" title=\"Example of explicit and implicit wrapping and unwrapping\" >@Outgoing(\"publisher-payload\") public PublisherBuilder&lt;Integer&gt; streamOfMessages() { return ReactiveStreams.of(0, 1, 2, 3, 4, 5, 6, 7, 8, 9); } @Incoming(\"publisher-payload\") @Outgoing(\"wrapped-message\") public Message&lt;String&gt; rewrapMessageManually(Message&lt;Integer&gt; message) { return Message.of(Integer.toString(message.getPayload())); } @Incoming(\"wrapped-message\") public void consumeImplicitlyUnwrappedMessage(String value) { System.out.println(\"Consuming message: \" + value); } ",
            "title": "Message"
        },
        {
            "location": "/mp/reactivemessaging/introduction",
            "text": " Messages carry a callback for reception acknowledgement (ack) and negative acknowledgement (nack). An acknowledgement in messaging methods is possible manually by org.eclipse.microprofile.reactive.messaging.Message#ack or automatically according explicit or implicit acknowledgement strategy by the messaging core. Explicit strategy configuration is possible with @Acknowledgment annotation which has one required attribute value that expects the strategy type from enum org.eclipse.microprofile.reactive.messaging.Acknowledgment.Strategy . More information about supported signatures and implicit automatic acknowledgement can be found in specification Message acknowledgement . Acknowledgement strategies @Acknowledgment(Acknowledgment.Strategy.NONE) No acknowledgment @Acknowledgment(Acknowledgment.Strategy.MANUAL) No automatic acknowledgment @Acknowledgment(Acknowledgment.Strategy.PRE_PROCESSING) Ack automatically before method invocation or processing @Acknowledgment(Acknowledgment.Strategy.POST_PROCESSING) Ack automatically after method invocation or processing <markup lang=\"java\" title=\"Example of manual acknowledgment\" >@Outgoing(\"consume-and-ack\") public PublisherBuilder&lt;Integer&gt; streamOfMessages() { return ReactiveStreams.of(Message.of(\"This is Payload\", () -&gt; { System.out.println(\"This particular message was acked!\"); return CompletableFuture.completedFuture(null); })).buildRs(); } @Incoming(\"consume-and-ack\") @Acknowledgment(Acknowledgment.Strategy.MANUAL) public CompletionStage&lt;Void&gt; receiveAndAckMessage(Message&lt;String&gt; msg) { return msg.ack(); } Calling ack() will print \"This particular message was acked!\" to System.out <markup lang=\"java\" title=\"Example of manual acknowledgment\" >@Outgoing(\"consume-and-ack\") public PublisherBuilder&lt;Integer&gt; streamOfMessages() { return ReactiveStreams.of(Message.of(\"This is Payload\", () -&gt; { System.out.println(\"This particular message was acked!\"); return CompletableFuture.completedFuture(null); })).buildRs(); } @Incoming(\"consume-and-ack\") @Acknowledgment(Acknowledgment.Strategy.MANUAL) public CompletionStage&lt;Void&gt; receiveAndAckMessage(Message&lt;String&gt; msg) { return msg.ack(); } Calling ack() will print \"This particular message was acked!\" to System.out <markup lang=\"java\" title=\"Example of explicit pre-process acknowledgment\" >@Outgoing(\"consume-and-ack\") public PublisherBuilder&lt;Integer&gt; streamOfMessages() { return ReactiveStreams.of(Message.of(\"This is Payload\", () -&gt; { System.out.println(\"This particular message was acked!\"); return CompletableFuture.completedFuture(null); })).buildRs(); } /** * Prints to the console: * &gt; This particular message was acked! * &gt; Method invocation! */ @Incoming(\"consume-and-ack\") @Acknowledgment(Acknowledgment.Strategy.PRE_PROCESSING) public CompletionStage&lt;Void&gt; receiveAndAckMessage(Message&lt;String&gt; msg) { System.out.println(\"Method invocation!\"); return CompletableFuture.completedFuture(null); } <markup lang=\"java\" title=\"Example of explicit post-process acknowledgment\" >@Outgoing(\"consume-and-ack\") public PublisherBuilder&lt;Integer&gt; streamOfMessages() { return ReactiveStreams.of(Message.of(\"This is Payload\", () -&gt; { System.out.println(\"This particular message was acked!\"); return CompletableFuture.completedFuture(null); })).buildRs(); } /** * Prints to the console: * &gt; Method invocation! * &gt; This particular message was acked! */ @Incoming(\"consume-and-ack\") @Acknowledgment(Acknowledgment.Strategy.POST_PROCESSING) public CompletionStage&lt;Void&gt; receiveAndAckMessage(Message&lt;String&gt; msg) { System.out.println(\"Method invocation!\"); return CompletableFuture.completedFuture(null); } ",
            "title": "Acknowledgement"
        },
        {
            "location": "/mp/reactivemessaging/introduction",
            "text": " Messaging in Helidon has built in health probes for liveness and readiness. To activate it add the health check dependency . Liveness - channel is considered UP until cancel or onError signal is intercepted on it. Readiness - channel is considered DOWN until onSubscribe signal is intercepted on it. If you check your health endpoints /health/live and /health/ready you will discover every messaging channel to have its own probe. <markup lang=\"json\" >{ \"name\": \"messaging\", \"state\": \"UP\", \"status\": \"UP\", \"data\": { \"my-channel-1\": \"UP\", \"my-channel-2\": \"UP\" } } Due to the nack support are exceptions thrown in messaging methods NOT translated to error and cancel signals implicitly anymore ",
            "title": "Health Check"
        },
        {
            "location": "/mp/reactivemessaging/introduction",
            "text": " Channels Emitter Connector Message Acknowledgement Health Check Channels Reactive messaging uses named channels to connect one source (upstream) with one consumer (downstream). Each channel needs to have both ends connected otherwise the container cannot successfully start. Channels can be connected either to emitter (1), producing method (2) or connector (3) on the upstream side. And injected publisher (4), consuming method (5) or connector (6) on the downstream. Consuming Method Consuming methods can be connected to the channel&#8217;s downstream to consume the message coming through the channel. The incoming annotation has one required attribute value that defines the channel name. Consuming method can function in two ways: consume every message coming from the stream connected to the channels - invoked per each message prepare reactive stream&#8217;s subscriber and connect it to the channel - invoked only once during the channel construction <markup lang=\"java\" title=\"Example consuming every message from channel example-channel-2 :\" >@Incoming(\"example-channel-2\") public void printMessage(String msg) { System.out.println(\"Just received message: \" + msg); } <markup lang=\"java\" title=\"Example preparing reactive stream subscriber for channel example-channel-1 :\" >@Incoming(\"example-channel-2\") public Subscriber&lt;String&gt; printMessage() { return ReactiveStreams.&lt;String&gt;builder() .forEach(msg -&gt; System.out.println(\"Just received message: \" + msg)) .build(); } Injected Publisher Directly injected publisher can be connected as a channel downstream, you can consume the data from the channel by subscribing to it. Helidon can inject following types of publishers: Publisher&lt;PAYLOAD&gt; - Reactive streams publisher with unwrapped payload Publisher&lt;Message&lt;PAYLOAD&gt;&gt; - Reactive streams publisher with whole message PublisherBuilder&lt;PAYLOAD&gt; - MP Reactive streams operators publisher builder with unwrapped payload PublisherBuilder&lt;Message&lt;PAYLOAD&gt;&gt; - MP Reactive streams operators publisher builder with whole message Flow.Publisher&lt;PAYLOAD&gt; - JDK&#8217;s flow publisher with unwrapped payload Flow.Publisher&lt;Message&lt;PAYLOAD&gt;&gt; - JDK&#8217;s flow publisher with whole message Multi&lt;PAYLOAD&gt; - Helidon flow reactive operators with unwrapped payload Multi&lt;Message&lt;PAYLOAD&gt;&gt; - Helidon flow reactive operators with whole message <markup lang=\"java\" title=\"Example of consuming payloads from channel example-channel-1 with injected publisher:\" >@Inject public MyBean(@Channel(\"example-channel-1\") Multi&lt;String&gt; multiChannel) { multiChannel .map(String::toUpperCase) .forEach(s -&gt; System.out.println(\"Received \" + s)); } Producing Method The annotation has one required attribute value that defines the channel name. The annotated messaging method can function in two ways: produce exactly one message to the stream connected to the channel prepare reactive stream&#8217;s publisher and connect it to the channel <markup lang=\"java\" title=\"Example producing exactly one message to channel example-channel-1 :\" >@Outgoing(\"example-channel-1\") public String produceMessage() { return \"foo\"; } <markup lang=\"java\" title=\"Example preparing reactive stream publisher publishing three messages to the channel example-channel-1 :\" >@Outgoing(\"example-channel-1\") public Publisher&lt;String&gt; printMessage() { return ReactiveStreams.of(\"foo\", \"bar\", \"baz\").buildRs(); } Messaging methods are not meant to be invoked directly! Emitter To send messages from imperative code, you can inject a special channel source called an emitter. Emitter can serve only as an upstream, source of the messages, for messaging channel. <markup lang=\"java\" title=\"Example of sending message from JAX-RS method to channel example-channel-1 \" >@Inject @Channel(\"example-channel-1\") private Emitter&lt;String&gt; emitter; @PUT @Path(\"/sendMessage\") @Consumes(MediaType.TEXT_PLAIN) public Response sendMessage(final String payload) { emitter.send(payload); } Emitters, as a source of messages for reactive channels, need to address possible backpressure from the downstream side of the channel. In case there is not enough demand from the downstream, you can configure a buffer size strategy using the @OnOverflow annotation. Additional overflow strategies are described below. Overflow strategies Strategy Description BUFFER Buffer unconsumed values until configured bufferSize is reached, when reached calling Emitter.emit throws IllegalStateException . Buffer size can be configured with @OnOverflow or with config key mp.messaging.emitter.default-buffer-size . Default value is 128 . UNBOUNDED_BUFFER Buffer unconsumed values until application runs out of memory. THROW_EXCEPTION Calling Emitter.emit throws IllegalStateException if there is not enough items requested by downstream. DROP If there is not enough items requested by downstream, emitted message is silently dropped. FAIL If there is not enough items requested by downstream, emitting message causes error signal being send to downstream. Whole channel is terminated. No other messages can be sent. LATEST Keeps only the latest item. Any previous unconsumed message is silently dropped. NONE Messages are sent to downstream even if there is no demand. Backpressure is effectively ignored. Processing Method Such methods acts as processors, consuming messages from one channel and producing to another. Diagram shows how processing method (2) serves as a downstream to the my-channel (1) and an upstream to the other-channel (3), connecting them together. Processing method can function in multiple ways: process every message prepare reactive stream&#8217;s processor and connect it between the channels on every message prepare new publisher(equivalent to flatMap operator) <markup lang=\"java\" title=\"Example processing every message from channel example-channel-1 to channel example-channel-2 :\" >@Incoming(\"example-channel-1\") @Outgoing(\"example-channel-2\") public String processMessage(String msg) { return msg.toUpperCase(); } <markup lang=\"java\" title=\"Example preparing processor stream to be connected between channels example-channel-1 and example-channel-2 :\" >@Incoming(\"example-channel-1\") @Outgoing(\"example-channel-2\") public Processor&lt;String, String&gt; processMessage() { return ReactiveStreams.&lt;String&gt;builder() .map(String::toUpperCase) .buildRs(); } <markup lang=\"java\" title=\"Example processing every message from channel example-channel-1`as stream to be flattened to channel `example-channel-2 :\" >@Incoming(\"example-channel-1\") @Outgoing(\"example-channel-2\") public String processMessage(String msg) { return ReactiveStreams.of(msg.toUpperCase(), msg.toLowerCase()).buildRs(); } Connector Messaging connector is an application-scoped bean that implements one or both of following interfaces: IncomingConnectorFactory - connector can create an upstream publisher to produce messages to a channel OutgoingConnectorFactory - connector can create a downstream subscriber to consume messages from a channel <markup lang=\"java\" title=\"Example connector example-connector :\" >@ApplicationScoped @Connector(\"example-connector\") public class ExampleConnector implements IncomingConnectorFactory, OutgoingConnectorFactory { @Override public PublisherBuilder&lt;? extends Message&lt;?&gt;&gt; getPublisherBuilder(Config config) { return ReactiveStreams.of(\"foo\", \"bar\") .map(Message::of); } @Override public SubscriberBuilder&lt;? extends Message&lt;?&gt;, Void&gt; getSubscriberBuilder(Config config) { return ReactiveStreams.&lt;Message&lt;?&gt;&gt;builder() .map(Message::getPayload) .forEach(o -&gt; System.out.println(\"Connector says: \" + o)); } } Message The Reactive Messaging Message class can be used to wrap or unwrap data items between methods and connectors. The message wrapping and unwrapping can be performed explicitly by using org.eclipse.microprofile.reactive.messaging.Message#of(T) or implicitly through the messaging core. <markup lang=\"java\" title=\"Example of explicit and implicit wrapping and unwrapping\" >@Outgoing(\"publisher-payload\") public PublisherBuilder&lt;Integer&gt; streamOfMessages() { return ReactiveStreams.of(0, 1, 2, 3, 4, 5, 6, 7, 8, 9); } @Incoming(\"publisher-payload\") @Outgoing(\"wrapped-message\") public Message&lt;String&gt; rewrapMessageManually(Message&lt;Integer&gt; message) { return Message.of(Integer.toString(message.getPayload())); } @Incoming(\"wrapped-message\") public void consumeImplicitlyUnwrappedMessage(String value) { System.out.println(\"Consuming message: \" + value); } Acknowledgement Messages carry a callback for reception acknowledgement (ack) and negative acknowledgement (nack). An acknowledgement in messaging methods is possible manually by org.eclipse.microprofile.reactive.messaging.Message#ack or automatically according explicit or implicit acknowledgement strategy by the messaging core. Explicit strategy configuration is possible with @Acknowledgment annotation which has one required attribute value that expects the strategy type from enum org.eclipse.microprofile.reactive.messaging.Acknowledgment.Strategy . More information about supported signatures and implicit automatic acknowledgement can be found in specification Message acknowledgement . Acknowledgement strategies @Acknowledgment(Acknowledgment.Strategy.NONE) No acknowledgment @Acknowledgment(Acknowledgment.Strategy.MANUAL) No automatic acknowledgment @Acknowledgment(Acknowledgment.Strategy.PRE_PROCESSING) Ack automatically before method invocation or processing @Acknowledgment(Acknowledgment.Strategy.POST_PROCESSING) Ack automatically after method invocation or processing <markup lang=\"java\" title=\"Example of manual acknowledgment\" >@Outgoing(\"consume-and-ack\") public PublisherBuilder&lt;Integer&gt; streamOfMessages() { return ReactiveStreams.of(Message.of(\"This is Payload\", () -&gt; { System.out.println(\"This particular message was acked!\"); return CompletableFuture.completedFuture(null); })).buildRs(); } @Incoming(\"consume-and-ack\") @Acknowledgment(Acknowledgment.Strategy.MANUAL) public CompletionStage&lt;Void&gt; receiveAndAckMessage(Message&lt;String&gt; msg) { return msg.ack(); } Calling ack() will print \"This particular message was acked!\" to System.out <markup lang=\"java\" title=\"Example of manual acknowledgment\" >@Outgoing(\"consume-and-ack\") public PublisherBuilder&lt;Integer&gt; streamOfMessages() { return ReactiveStreams.of(Message.of(\"This is Payload\", () -&gt; { System.out.println(\"This particular message was acked!\"); return CompletableFuture.completedFuture(null); })).buildRs(); } @Incoming(\"consume-and-ack\") @Acknowledgment(Acknowledgment.Strategy.MANUAL) public CompletionStage&lt;Void&gt; receiveAndAckMessage(Message&lt;String&gt; msg) { return msg.ack(); } Calling ack() will print \"This particular message was acked!\" to System.out <markup lang=\"java\" title=\"Example of explicit pre-process acknowledgment\" >@Outgoing(\"consume-and-ack\") public PublisherBuilder&lt;Integer&gt; streamOfMessages() { return ReactiveStreams.of(Message.of(\"This is Payload\", () -&gt; { System.out.println(\"This particular message was acked!\"); return CompletableFuture.completedFuture(null); })).buildRs(); } /** * Prints to the console: * &gt; This particular message was acked! * &gt; Method invocation! */ @Incoming(\"consume-and-ack\") @Acknowledgment(Acknowledgment.Strategy.PRE_PROCESSING) public CompletionStage&lt;Void&gt; receiveAndAckMessage(Message&lt;String&gt; msg) { System.out.println(\"Method invocation!\"); return CompletableFuture.completedFuture(null); } <markup lang=\"java\" title=\"Example of explicit post-process acknowledgment\" >@Outgoing(\"consume-and-ack\") public PublisherBuilder&lt;Integer&gt; streamOfMessages() { return ReactiveStreams.of(Message.of(\"This is Payload\", () -&gt; { System.out.println(\"This particular message was acked!\"); return CompletableFuture.completedFuture(null); })).buildRs(); } /** * Prints to the console: * &gt; Method invocation! * &gt; This particular message was acked! */ @Incoming(\"consume-and-ack\") @Acknowledgment(Acknowledgment.Strategy.POST_PROCESSING) public CompletionStage&lt;Void&gt; receiveAndAckMessage(Message&lt;String&gt; msg) { System.out.println(\"Method invocation!\"); return CompletableFuture.completedFuture(null); } Health Check Messaging in Helidon has built in health probes for liveness and readiness. To activate it add the health check dependency . Liveness - channel is considered UP until cancel or onError signal is intercepted on it. Readiness - channel is considered DOWN until onSubscribe signal is intercepted on it. If you check your health endpoints /health/live and /health/ready you will discover every messaging channel to have its own probe. <markup lang=\"json\" >{ \"name\": \"messaging\", \"state\": \"UP\", \"status\": \"UP\", \"data\": { \"my-channel-1\": \"UP\", \"my-channel-2\": \"UP\" } } Due to the nack support are exceptions thrown in messaging methods NOT translated to error and cancel signals implicitly anymore ",
            "title": "Usage"
        },
        {
            "location": "/mp/reactivemessaging/introduction",
            "text": " The channel must be configured to use connector as its upstream or downstream. <markup lang=\"yaml\" title=\"Example of channel to connector mapping config:\" >mp.messaging.outgoing.to-connector-channel.connector: example-connector mp.messaging.incoming.from-connector-channel.connector: example-connector Use connector example-connector as a downstream for channel to-connector-channel to consume the messages from the channel Use connector example-connector as an upstream for channel to-connector-channel to produce messages to the channel <markup lang=\"java\" title=\"Example producing to connector:\" >@Outgoing(\"to-connector-channel\") public Publisher&lt;String&gt; produce() { return Flowable.just(\"fee\", \"fie\"); } &gt; Connector says: fee &gt; Connector says: fie <markup lang=\"java\" title=\"Example consuming from connector:\" >@Incoming(\"from-connector-channel\") public void consume(String value) { System.out.println(\"Consuming: \" + value); } &gt; Consuming: foo &gt; Consuming: bar When the connector constructs a publisher or subscriber for a given channel, it can access general connector configuration and channel-specific properties merged together with special synthetic property channel-name . Connector specific config (1) merged together with global connector config (2). <markup lang=\"java\" title=\"Example connector accessing configuration:\" >@ApplicationScoped @Connector(\"example-connector\") public class ExampleConnector implements IncomingConnectorFactory { @Override public PublisherBuilder&lt;? extends Message&lt;?&gt;&gt; getPublisherBuilder(final Config config) { String firstPropValue = config.getValue(\"channel-specific-prop\", String.class); String secondPropValue = config.getValue(\"connector-specific-prop\", String.class); String secondPropValue = config.getValue(\"channel-name\", String.class); return ReactiveStreams.of(firstPropValue, secondPropValue) .map(Message::of); } } Config context is merged from channel and connector contexts Name of the channel requesting publisher as it&#8217;s upstream from this connector <markup lang=\"yaml\" title=\"Example of channel to connector mapping config with custom properties:\" >mp.messaging.incoming.from-connector-channel.connector: example-connector mp.messaging.incoming.from-connector-channel.channel-specific-prop: foo mp.messaging.connector.example-connector.connector-specific-prop: bar Channel &#8594; Connector mapping Channel configuration properties Connector configuration properties <markup lang=\"java\" title=\"Example consuming from connector:\" >@Incoming(\"from-connector-channel\") public void consume(String value) { System.out.println(\"Consuming: \" + value); } &gt; Consuming: foo &gt; Consuming: bar ",
            "title": "Configuration"
        },
        {
            "location": "/mp/reactivemessaging/introduction",
            "text": " Helidon MicroProfile Reactive Messaging MicroProfile Reactive Messaging Specification MicroProfile Reactive Messaging on GitHub ",
            "title": "Reference"
        },
        {
            "location": "/mp/reactivemessaging/jms",
            "text": " Overview Maven Coordinates Configuration Usage ",
            "title": "Contents"
        },
        {
            "location": "/mp/reactivemessaging/jms",
            "text": " Connecting streams to JMS with Reactive Messaging couldn&#8217;t be easier. ",
            "title": "Overview"
        },
        {
            "location": "/mp/reactivemessaging/jms",
            "text": " To enable JMS Connector add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.messaging.jms&lt;/groupId&gt; &lt;artifactId&gt;helidon-messaging-jms&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/reactivemessaging/jms",
            "text": " The simplest possible usage is looking up JMS ConnectionFactory in the naming context. <markup lang=\"yaml\" title=\"Example of connector config:\" >mp.messaging: incoming.from-jms: connector: helidon-jms destination: messaging-test-queue-1 type: queue outgoing.to-jms: connector: helidon-jms destination: messaging-test-queue-1 type: queue connector: helidon-jms: user: Gandalf password: mellon jndi: jms-factory: ConnectionFactory env-properties: java.naming: factory.initial: org.apache.activemq.jndi.ActiveMQInitialContextFactory provider.url: tcp://localhost:61616 ",
            "title": "Configured JMS factory"
        },
        {
            "location": "/mp/reactivemessaging/jms",
            "text": " In case you need more advanced setup, connector can work with injected factory instance. <markup lang=\"java\" title=\"Inject:\" > @Produces @ApplicationScoped @Named(\"active-mq-factory\") public ConnectionFactory connectionFactory() { return new ActiveMQConnectionFactory(config.get(\"jms.url\").asString().get()); } <markup lang=\"yaml\" title=\"Config:\" >jms: url: tcp://127.0.0.1:61616 mp: messaging: connector: helidon-jms: named-factory: active-mq-factory outgoing.to-jms: connector: helidon-jms session-group-id: order-connection-1 destination: TESTQUEUE type: queue incoming.from-jms: connector: helidon-jms session-group-id: order-connection-1 destination: TESTQUEUE type: queue ",
            "title": "Injected JMS factory"
        },
        {
            "location": "/mp/reactivemessaging/jms",
            "text": " Connector name: helidon-jms Attributes username User name used to connect JMS session password Password to connect JMS session type Possible values are: queue , topic destination Queue or topic name acknowledge-mode Possible values are: AUTO_ACKNOWLEDGE - session automatically acknowledges a client&#8217;s receipt of a message, CLIENT_ACKNOWLEDGE - receipt of a message is acknowledged only when Message.ack() is called manually, DUPS_OK_ACKNOWLEDGE - session lazily acknowledges the delivery of messages. Default value: AUTO_ACKNOWLEDGE transacted Indicates whether the session will use a local transaction. Default value: false message-selector JMS API message selector expression based on a subset of the SQL92. Expression can only access headers and properties, not the payload. client-id Client identifier for JMS connection. durable True for creating durable consumer (only for topic). Default value: false subscriber-name Subscriber name for durable consumer used to identify subscription. non-local If true then any messages published to the topic using this session&#8217;s connection, or any other connection with the same client identifier, will not be added to the durable subscription. Default value: false named-factory Select in case factory is injected as a named bean or configured with name. poll-timeout Timeout for polling for next message in every poll cycle in millis. Default value: 50 period-executions Period for executing poll cycles in millis. Default value: 100 session-group-id When multiple channels share same session-group-id , they share same JMS session and same JDBC connection as well. jndi.jms-factory JNDI name of JMS factory. jndi.destination JNDI destination identifier. jndi.env-properties Environment properties used for creating initial context java.naming.factory.initial , java.naming.provider.url &#8230;&#8203; producer.someproperty property with producer prefix is set to producer instance (for example WLS Unit-of-Order WLMessageProducer.setUnitOfOrder(\"unit-1\") can be configured as producer.unit-of-order=unit-1 ) Configured JMS factory The simplest possible usage is looking up JMS ConnectionFactory in the naming context. <markup lang=\"yaml\" title=\"Example of connector config:\" >mp.messaging: incoming.from-jms: connector: helidon-jms destination: messaging-test-queue-1 type: queue outgoing.to-jms: connector: helidon-jms destination: messaging-test-queue-1 type: queue connector: helidon-jms: user: Gandalf password: mellon jndi: jms-factory: ConnectionFactory env-properties: java.naming: factory.initial: org.apache.activemq.jndi.ActiveMQInitialContextFactory provider.url: tcp://localhost:61616 Injected JMS factory In case you need more advanced setup, connector can work with injected factory instance. <markup lang=\"java\" title=\"Inject:\" > @Produces @ApplicationScoped @Named(\"active-mq-factory\") public ConnectionFactory connectionFactory() { return new ActiveMQConnectionFactory(config.get(\"jms.url\").asString().get()); } <markup lang=\"yaml\" title=\"Config:\" >jms: url: tcp://127.0.0.1:61616 mp: messaging: connector: helidon-jms: named-factory: active-mq-factory outgoing.to-jms: connector: helidon-jms session-group-id: order-connection-1 destination: TESTQUEUE type: queue incoming.from-jms: connector: helidon-jms session-group-id: order-connection-1 destination: TESTQUEUE type: queue ",
            "title": "Configuration"
        },
        {
            "location": "/mp/reactivemessaging/jms",
            "text": "<markup lang=\"java\" title=\"Consuming one by one unwrapped value:\" >@Incoming(\"from-jms\") public void consumeJms(String msg) { System.out.println(\"JMS says: \" + msg); } <markup lang=\"java\" title=\"Consuming one by one, manual ack:\" >@Incoming(\"from-jms\") @Acknowledgment(Acknowledgment.Strategy.MANUAL) public CompletionStage&lt;?&gt; consumeJms(JmsMessage&lt;String&gt; msg) { System.out.println(\"JMS says: \" + msg.getPayload()); return msg.ack(); } ",
            "title": "Consuming"
        },
        {
            "location": "/mp/reactivemessaging/jms",
            "text": "<markup lang=\"java\" title=\"Example of producing to JMS:\" >@Outgoing(\"to-jms\") public PublisherBuilder&lt;String&gt; produceToJms() { return ReactiveStreams.of(\"test1\", \"test2\"); } <markup lang=\"java\" title=\"Example of more advanced producing to JMS:\" >@Outgoing(\"to-jms\") public PublisherBuilder&lt;String&gt; produceToJms() { return ReactiveStreams.of(\"test1\", \"test2\") .map(s -&gt; JmsMessage.builder(s) .correlationId(UUID.randomUUID().toString()) .property(\"stringProp\", \"cool property\") .property(\"byteProp\", 4) .property(\"intProp\", 5) .onAck(() -&gt; System.out.println(\"Acked!\")) .build()); } <markup lang=\"java\" title=\"Example of even more advanced producing to JMS with custom mapper:\" >@Outgoing(\"to-jms\") public PublisherBuilder&lt;String&gt; produceToJms() { return ReactiveStreams.of(\"test1\", \"test2\") .map(s -&gt; JmsMessage.builder(s) .customMapper((p, session) -&gt; { TextMessage textMessage = session.createTextMessage(p); textMessage.setStringProperty(\"custom-mapped-property\", \"XXX\" + p); return textMessage; }) .build() ); } ",
            "title": "Producing"
        },
        {
            "location": "/mp/reactivemessaging/jms",
            "text": " Consuming <markup lang=\"java\" title=\"Consuming one by one unwrapped value:\" >@Incoming(\"from-jms\") public void consumeJms(String msg) { System.out.println(\"JMS says: \" + msg); } <markup lang=\"java\" title=\"Consuming one by one, manual ack:\" >@Incoming(\"from-jms\") @Acknowledgment(Acknowledgment.Strategy.MANUAL) public CompletionStage&lt;?&gt; consumeJms(JmsMessage&lt;String&gt; msg) { System.out.println(\"JMS says: \" + msg.getPayload()); return msg.ack(); } Producing <markup lang=\"java\" title=\"Example of producing to JMS:\" >@Outgoing(\"to-jms\") public PublisherBuilder&lt;String&gt; produceToJms() { return ReactiveStreams.of(\"test1\", \"test2\"); } <markup lang=\"java\" title=\"Example of more advanced producing to JMS:\" >@Outgoing(\"to-jms\") public PublisherBuilder&lt;String&gt; produceToJms() { return ReactiveStreams.of(\"test1\", \"test2\") .map(s -&gt; JmsMessage.builder(s) .correlationId(UUID.randomUUID().toString()) .property(\"stringProp\", \"cool property\") .property(\"byteProp\", 4) .property(\"intProp\", 5) .onAck(() -&gt; System.out.println(\"Acked!\")) .build()); } <markup lang=\"java\" title=\"Example of even more advanced producing to JMS with custom mapper:\" >@Outgoing(\"to-jms\") public PublisherBuilder&lt;String&gt; produceToJms() { return ReactiveStreams.of(\"test1\", \"test2\") .map(s -&gt; JmsMessage.builder(s) .customMapper((p, session) -&gt; { TextMessage textMessage = session.createTextMessage(p); textMessage.setStringProperty(\"custom-mapped-property\", \"XXX\" + p); return textMessage; }) .build() ); } ",
            "title": "Usage"
        },
        {
            "location": "/mp/reactivemessaging/kafka",
            "text": " Overview Maven Coordinates Config Example NACK Strategy Examples ",
            "title": "Contents"
        },
        {
            "location": "/mp/reactivemessaging/kafka",
            "text": " Connecting streams to Kafka with Reactive Messaging is easy to do. There is a standard Kafka client behind the scenes, all the producer and consumer configs can be propagated through messaging config. ",
            "title": "Overview"
        },
        {
            "location": "/mp/reactivemessaging/kafka",
            "text": " To enable Reactive Kafka Connector add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.messaging.kafka&lt;/groupId&gt; &lt;artifactId&gt;helidon-messaging-kafka&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/reactivemessaging/kafka",
            "text": "<markup lang=\"yaml\" title=\"Example of connector config:\" >mp.messaging: incoming.from-kafka: connector: helidon-kafka topic: messaging-test-topic-1 auto.offset.reset: latest enable.auto.commit: true group.id: example-group-id outgoing.to-kafka: connector: helidon-kafka topic: messaging-test-topic-1 connector: helidon-kafka: bootstrap.servers: localhost:9092 key.serializer: org.apache.kafka.common.serialization.StringSerializer value.serializer: org.apache.kafka.common.serialization.StringSerializer key.deserializer: org.apache.kafka.common.serialization.StringDeserializer value.deserializer: org.apache.kafka.common.serialization.StringDeserializer Kafka client consumer&#8217;s property auto.offset.reset configuration for from-kafka channel only Kafka client&#8217;s property bootstrap.servers configuration for all channels using the connector <markup lang=\"java\" title=\"Example of consuming from Kafka:\" >@Incoming(\"from-kafka\") public void consumeKafka(String msg) { System.out.println(\"Kafka says: \" + msg); } <markup lang=\"java\" title=\"Example of producing to Kafka:\" >@Outgoing(\"to-kafka\") public PublisherBuilder&lt;String&gt; produceToKafka() { return ReactiveStreams.of(\"test1\", \"test2\"); } ",
            "title": "Config Example"
        },
        {
            "location": "/mp/reactivemessaging/kafka",
            "text": " Default NACK strategy for Kafka connector. When ",
            "title": "Kill channel"
        },
        {
            "location": "/mp/reactivemessaging/kafka",
            "text": " Sends nacked messages to error topic, DLQ is well known pattern for dealing with unprocessed messages. Helidon can derive connection settings for DLQ topic automatically if the error topic is present on the same Kafka cluster. Serializers are derived from deserializers used for consumption org.apache.kafka.common.serialization.StringDeserializer &gt; org.apache.kafka.common.serialization.StringSerializer . Note that the name of the error topic is needed only in this case. <markup lang=\"yaml\" title=\"Example of derived DLQ config:\" >mp.messaging: incoming: my-channel: nack-dlq: dql_topic_name If a custom connection is needed, then use the 'nack-dlq' key for all of the producer configuration. <markup lang=\"yaml\" title=\"Example of custom DLQ config:\" >mp.messaging: incoming: my-channel: nack-dlq: topic: dql_topic_name bootstrap.servers: localhost:9092 key.serializer: org.apache.kafka.common.serialization.StringSerializer value.serializer: org.apache.kafka.common.serialization.StringSerializer ",
            "title": "Dead Letter Queue"
        },
        {
            "location": "/mp/reactivemessaging/kafka",
            "text": " Only logs nacked messages and throws them away, offset is committed and channel continues normally consuming subsequent messages. <markup lang=\"yaml\" title=\"Example of log only enabled nack strategy\" >mp.messaging: incoming: my-channel: nack-log-only: true ",
            "title": "Log only"
        },
        {
            "location": "/mp/reactivemessaging/kafka",
            "text": " Strategy Description Kill channel Nacked message sends error signal and causes channel failure so Messaging Health check can report it as DOWN DLQ Nacked messages are sent to specified dead-letter-queue Log only Nacked message is logged and channel continues normally Kill channel Default NACK strategy for Kafka connector. When Dead Letter Queue Sends nacked messages to error topic, DLQ is well known pattern for dealing with unprocessed messages. Helidon can derive connection settings for DLQ topic automatically if the error topic is present on the same Kafka cluster. Serializers are derived from deserializers used for consumption org.apache.kafka.common.serialization.StringDeserializer &gt; org.apache.kafka.common.serialization.StringSerializer . Note that the name of the error topic is needed only in this case. <markup lang=\"yaml\" title=\"Example of derived DLQ config:\" >mp.messaging: incoming: my-channel: nack-dlq: dql_topic_name If a custom connection is needed, then use the 'nack-dlq' key for all of the producer configuration. <markup lang=\"yaml\" title=\"Example of custom DLQ config:\" >mp.messaging: incoming: my-channel: nack-dlq: topic: dql_topic_name bootstrap.servers: localhost:9092 key.serializer: org.apache.kafka.common.serialization.StringSerializer value.serializer: org.apache.kafka.common.serialization.StringSerializer Log only Only logs nacked messages and throws them away, offset is committed and channel continues normally consuming subsequent messages. <markup lang=\"yaml\" title=\"Example of log only enabled nack strategy\" >mp.messaging: incoming: my-channel: nack-log-only: true ",
            "title": "NACK Strategy"
        },
        {
            "location": "/mp/reactivemessaging/kafka",
            "text": " Don&#8217;t forget to check out the examples with pre-configured Kafka docker image, for easy testing: https://github.com/oracle/helidon/tree/4.0.2/examples/messaging ",
            "title": "Examples"
        },
        {
            "location": "/mp/reactivemessaging/mock",
            "text": " Overview Maven Coordinates Usage Configuration Helidon Test ",
            "title": "Contents"
        },
        {
            "location": "/mp/reactivemessaging/mock",
            "text": " Mock connector is a simple application scoped bean that can be used for emitting to a channel or asserting received data in a test environment. All data received are kept in memory only. ",
            "title": "Overview"
        },
        {
            "location": "/mp/reactivemessaging/mock",
            "text": " To enable Mock Connector add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.messaging.mock&lt;/groupId&gt; &lt;artifactId&gt;helidon-messaging-mock&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/reactivemessaging/mock",
            "text": "<markup lang=\"java\" title=\"Emitting String values a , b , c \" >mockConnector .incoming(\"my-incoming-channel\", String.class) .emit(\"a\", \"b\", \"c\"); Get incoming channel of given name and payload type ",
            "title": "Emitting Data"
        },
        {
            "location": "/mp/reactivemessaging/mock",
            "text": "<markup lang=\"java\" title=\"Awaiting and asserting payloads with custom mapper\" >mockConnector .outgoing(\"my-outgoing-channel\", String.class) .awaitData(TIMEOUT, Message::getPayload, \"a\", \"b\", \"c\"); Get outgoing channel of given name and payload type Request number of expected items and block the thread until items arrive then assert the payloads ",
            "title": "Asserting Data"
        },
        {
            "location": "/mp/reactivemessaging/mock",
            "text": " Mock connector should be used in the test environment only! For injecting Mock Connector use @TestConnector qualifier: <markup lang=\"java\" >@Inject @TestConnector MockConnector mockConnector; Emitting Data <markup lang=\"java\" title=\"Emitting String values a , b , c \" >mockConnector .incoming(\"my-incoming-channel\", String.class) .emit(\"a\", \"b\", \"c\"); Get incoming channel of given name and payload type Asserting Data <markup lang=\"java\" title=\"Awaiting and asserting payloads with custom mapper\" >mockConnector .outgoing(\"my-outgoing-channel\", String.class) .awaitData(TIMEOUT, Message::getPayload, \"a\", \"b\", \"c\"); Get outgoing channel of given name and payload type Request number of expected items and block the thread until items arrive then assert the payloads ",
            "title": "Usage"
        },
        {
            "location": "/mp/reactivemessaging/mock",
            "text": " Key Default value Description mock-data Initial data emitted to the channel immediately after subscription mock-data-type java.lang.String Type of the emitted initial data to be emitted ",
            "title": "Configuration"
        },
        {
            "location": "/mp/reactivemessaging/mock",
            "text": " Mock connector works great with built-in Helidon test support for JUnit 5 or TestNG . As Helidon test support makes a bean out of your test, you can inject MockConnector directly into it. <markup lang=\"java\" >@HelidonTest @DisableDiscovery @AddBean(MockConnector.class) @AddExtension(MessagingCdiExtension.class) @AddConfig(key = \"mp.messaging.incoming.test-channel-in.connector\", value = MockConnector.CONNECTOR_NAME) @AddConfig(key = \"mp.messaging.incoming.test-channel-in.mock-data-type\", value = \"java.lang.Integer\") @AddConfig(key = \"mp.messaging.incoming.test-channel-in.mock-data\", value = \"6,7,8\") @AddConfig(key = \"mp.messaging.outgoing.test-channel-out.connector\", value = MockConnector.CONNECTOR_NAME) public class MessagingTest { private static final Duration TIMEOUT = Duration.ofSeconds(15); @Inject @TestConnector private MockConnector mockConnector; @Incoming(\"test-channel-in\") @Outgoing(\"test-channel-out\") int multiply(int payload) { return payload * 10; } @Test void testMultiplyChannel() { mockConnector.outgoing(\"test-channel-out\", Integer.TYPE) .awaitPayloads(TIMEOUT, 60, 70, 80); } } If you want to add all the beans manually Manually add MockConnector bean, so it is accessible by messaging for constructing the channels Messaging support in Helidon MP is provided by this CDI extension Instruct messaging to use mock-connector as an upstream for channel test-channel-in Generate mock data of java.lang.Integer , String is default Generate mock data Instruct messaging to use mock-connector as a downstream for channel test-channel-out Inject mock connector so we can access publishers and subscribers registered within the mock connector Messaging processing method connecting together channels test-channel-in and test-channel-out Actual JUnit 5 test method which is going to block the thread until 3 items are intercepted on test-channel-out channel&#8217;s downstream and assert those with expected values. ",
            "title": "Helidon Test with Mock Connector"
        },
        {
            "location": "/mp/reactivemessaging/weblogic",
            "text": " Overview Maven Coordinates Configuration Usage ",
            "title": "Contents"
        },
        {
            "location": "/mp/reactivemessaging/weblogic",
            "text": " WebLogic JMS Connector extends Helidon JMS connector with special handling for legacy WebLogic T3 thin clients. Legacy versions of thin client can be found in server/lib directory( WL_HOME/server/lib/wlthint3client.jar ) of any WebLogic Server installation. Helidon supports Jakarta EE {version-lib-jakarta-ee}. Legacy versions of javax based thin T3 client will not work correctly when added to the classpath. Legacy thin T3 clients must be loaded from a filesystem location specified by the thin-jar property. Do not place legacy wlthint3client.jar on the Helidon classpath. The client library location needs to be configured and loaded by the Helidon messaging connector. When using the legacy WebLogic T3 thin clients, make sure to start the Helidon application with --add-opens=java.base/java.io=ALL-UNNAMED to allow reflection with the legacy wlthint3client. Updated versions of thin T3 clients that are compatible with modern Jakarta runtimes can be downloaded from {osdc-link} as wlthint3client.jakarta . However, Jakarta based thin clients can be placed on the Helidon classpath and used with this specialized connector or the JMS connector After the download, the thin T3 client artefact needs to be installed in the Maven repository accessible from the application build. ",
            "title": "Overview"
        },
        {
            "location": "/mp/reactivemessaging/weblogic",
            "text": " To enable WebLogic JMS connector add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.messaging.wls-jms&lt;/groupId&gt; &lt;artifactId&gt;helidon-messaging-wls-jms&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/reactivemessaging/weblogic",
            "text": " Connector name: helidon-weblogic-jms Attributes jms-factory The JNDI name of the JMS factory configured in WebLogic. url t3, t3s, or http address of WebLogic Server. thin-jar Filepath to the WebLogic thin T3 client jar ( wlthint3client.jar ); this path can be usually found within the WebLogic Server installation. WL_HOME/server/lib/wlthint3client.jar principal The WebLogic initial context principal (user). credentials The WebLogic initial context credential (password) type The possible values are: queue , topic . Default value is: topic destination The queue or topic name in WebLogic CDI (Create Destination Identifier) Syntax. jndi.destination JNDI destination identifier. When no such JNDI destination is found, falls back to destination with CDI syntax. acknowledge-mode The possible values are: AUTO_ACKNOWLEDGE - session automatically acknowledges a client’s receipt of a message, CLIENT_ACKNOWLEDGE - receipt of a message is acknowledged only when Message.ack() is called manually, DUPS_OK_ACKNOWLEDGE - session lazily acknowledges the delivery of messages. Default value: AUTO_ACKNOWLEDGE transacted Indicates whether the session will use a local transaction. Default value: false message-selector The JMS API message selector expression based on a subset of the SQL92. Expression can access only headers and properties, not the payload. client-id The client identifier for JMS connection. durable True for creating durable consumer (only for topic). Default value: false subscriber-name The subscriber name for the durable consumer used to identify subscription. non-local If true then any message that is published to the topic using this session&#8217;s connection or any other connection with the same client identifier, will not be added to the durable subscription. Default value: false named-factory Select in case factory is injected as a named bean or configured with name. poll-timeout The timeout interval (in millis) for polling for the next message in every poll cycle. Default value: 50 period-executions The period for executing poll cycles in millis. Default value: 100 session-group-id When multiple channels share the same session-group-id , they also share the same JMS session and JDBC connection. producer.unit-of-order All messages from the same unit of order will be processed sequentially in the order they were created. Configuration is straight forward. Use JNDI for localizing and configuring of JMS ConnectionFactory from WebLogic. Notice the destination property which is used to define the queue with WebLogic CDI Syntax . <markup lang=\"yaml\" title=\"Example config:\" >mp: messaging: connector: helidon-weblogic-jms: # JMS factory configured in WebLogic jms-factory: jms/TestConnectionFactory # Path to the WLS Thin T3 client jar thin-jar: wlthint3client.jar url: t3://localhost:7001 incoming: from-wls: connector: helidon-weblogic-jms # WebLogic CDI Syntax(CDI stands for Create Destination Identifier) destination: ./TestJMSModule!TestQueue outgoing: to-wls: connector: helidon-weblogic-jms # JNDI identifier for the same queue jndi.destination: jms/TestQueue When configuring destination with WebLogic CDI, apply the following syntax: jms-server-name/jms-module-name!destination-name In our example, we are replacing jms-server-name with . as we don’t have to look up the server we are connected to. jms-server-name/jms-module-name!jms-server-name@udd-name Destination for UDD doesn&#8217;t have ./ prefix, because distributed destinations can be served by multiple servers within a cluster. ",
            "title": "Configuration"
        },
        {
            "location": "/mp/reactivemessaging/weblogic",
            "text": "<markup lang=\"java\" title=\"Consuming one by one unwrapped value:\" >@Incoming(\"from-wls\") public void consumeWls(String msg) { System.out.println(\"WebLogic says: \" + msg); } <markup lang=\"java\" title=\"Consuming one by one, manual ack:\" >@Incoming(\"from-wls\") @Acknowledgment(Acknowledgment.Strategy.MANUAL) public CompletionStage&lt;?&gt; consumewls(JmsMessage&lt;String&gt; msg) { System.out.println(\"WebLogic says: \" + msg.getPayload()); return msg.ack(); } ",
            "title": "Consuming"
        },
        {
            "location": "/mp/reactivemessaging/weblogic",
            "text": "<markup lang=\"java\" title=\"Producing to WebLogic JMS:\" >@Outgoing(\"to-wls\") public PublisherBuilder&lt;String&gt; produceToWls() { return ReactiveStreams.of(\"test1\", \"test2\"); } <markup lang=\"java\" title=\"Example of more advanced producing to WebLogic JMS:\" >@Outgoing(\"to-wls\") public PublisherBuilder&lt;String&gt; produceToJms() { return ReactiveStreams.of(\"test1\", \"test2\") .map(s -&gt; JmsMessage.builder(s) .correlationId(UUID.randomUUID().toString()) .property(\"stringProp\", \"cool property\") .property(\"byteProp\", 4) .property(\"intProp\", 5) .onAck(() -&gt; System.out.println(\"Acked!\")) .build()); } <markup lang=\"java\" title=\"Example of even more advanced producing to WebLogic JMS with custom mapper:\" >@Outgoing(\"to-wls\") public PublisherBuilder&lt;String&gt; produceToJms() { return ReactiveStreams.of(\"test1\", \"test2\") .map(s -&gt; JmsMessage.builder(s) .customMapper((p, session) -&gt; { TextMessage textMessage = session.createTextMessage(p); textMessage.setStringProperty(\"custom-mapped-property\", \"XXX\" + p); return textMessage; }) .build() ); } ",
            "title": "Producing"
        },
        {
            "location": "/mp/reactivemessaging/weblogic",
            "text": " For initiating SSL secured t3 connection, trust keystore with WLS public certificate is needed. Standard WLS installation has pre-configured Demo trust store: WL_HOME/server/lib/DemoTrust.jks , we can store it locally for connecting WLS over t3s. <markup lang=\"yaml\" title=\"Example config:\" >mp: messaging: connector: helidon-weblogic-jms: jms-factory: jms/TestConnectionFactory thin-jar: wlthint3client.jar # Notice t3s protocol is used url: t3s://localhost:7002 Helidon application needs to be aware about our WLS SSL public certificate. <markup lang=\"bash\" title=\"Running example with WLS truststore\" >java --add-opens=java.base/java.io=ALL-UNNAMED \\ -Djavax.net.ssl.trustStore=DemoTrust.jks \\ -Djavax.net.ssl.trustStorePassword=DemoTrustKeyStorePassPhrase \\ -jar ./target/helidon-wls-jms-demo.jar ",
            "title": "Secured t3 over SSL(t3s)"
        },
        {
            "location": "/mp/reactivemessaging/weblogic",
            "text": " Consuming <markup lang=\"java\" title=\"Consuming one by one unwrapped value:\" >@Incoming(\"from-wls\") public void consumeWls(String msg) { System.out.println(\"WebLogic says: \" + msg); } <markup lang=\"java\" title=\"Consuming one by one, manual ack:\" >@Incoming(\"from-wls\") @Acknowledgment(Acknowledgment.Strategy.MANUAL) public CompletionStage&lt;?&gt; consumewls(JmsMessage&lt;String&gt; msg) { System.out.println(\"WebLogic says: \" + msg.getPayload()); return msg.ack(); } Producing <markup lang=\"java\" title=\"Producing to WebLogic JMS:\" >@Outgoing(\"to-wls\") public PublisherBuilder&lt;String&gt; produceToWls() { return ReactiveStreams.of(\"test1\", \"test2\"); } <markup lang=\"java\" title=\"Example of more advanced producing to WebLogic JMS:\" >@Outgoing(\"to-wls\") public PublisherBuilder&lt;String&gt; produceToJms() { return ReactiveStreams.of(\"test1\", \"test2\") .map(s -&gt; JmsMessage.builder(s) .correlationId(UUID.randomUUID().toString()) .property(\"stringProp\", \"cool property\") .property(\"byteProp\", 4) .property(\"intProp\", 5) .onAck(() -&gt; System.out.println(\"Acked!\")) .build()); } <markup lang=\"java\" title=\"Example of even more advanced producing to WebLogic JMS with custom mapper:\" >@Outgoing(\"to-wls\") public PublisherBuilder&lt;String&gt; produceToJms() { return ReactiveStreams.of(\"test1\", \"test2\") .map(s -&gt; JmsMessage.builder(s) .customMapper((p, session) -&gt; { TextMessage textMessage = session.createTextMessage(p); textMessage.setStringProperty(\"custom-mapped-property\", \"XXX\" + p); return textMessage; }) .build() ); } Secured t3 over SSL(t3s) For initiating SSL secured t3 connection, trust keystore with WLS public certificate is needed. Standard WLS installation has pre-configured Demo trust store: WL_HOME/server/lib/DemoTrust.jks , we can store it locally for connecting WLS over t3s. <markup lang=\"yaml\" title=\"Example config:\" >mp: messaging: connector: helidon-weblogic-jms: jms-factory: jms/TestConnectionFactory thin-jar: wlthint3client.jar # Notice t3s protocol is used url: t3s://localhost:7002 Helidon application needs to be aware about our WLS SSL public certificate. <markup lang=\"bash\" title=\"Running example with WLS truststore\" >java --add-opens=java.base/java.io=ALL-UNNAMED \\ -Djavax.net.ssl.trustStore=DemoTrust.jks \\ -Djavax.net.ssl.trustStorePassword=DemoTrustKeyStorePassPhrase \\ -jar ./target/helidon-wls-jms-demo.jar ",
            "title": "Usage"
        },
        {
            "location": "/mp/reactivestreams/engine",
            "text": " Overview Maven Coordinates Usage ",
            "title": "Contents"
        },
        {
            "location": "/mp/reactivestreams/engine",
            "text": " Helidon has its own set of reactive operators that have no dependencies outside of the Helidon ecosystem. These operators can be used with java.util.concurrent.Flow based reactive streams. ",
            "title": "Overview"
        },
        {
            "location": "/mp/reactivestreams/engine",
            "text": " To enable Reactive Engine add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.common&lt;/groupId&gt; &lt;artifactId&gt;helidon-common-reactive&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/reactivestreams/engine",
            "text": " In the situations when part of the operator chain needs to be prepared in advance, compose and to operators are at hand. <markup lang=\"java\" title=\"Combining operator chains:\" >// Assembly of stream, nothing is streamed yet Multi&lt;String&gt; publisherStage = Multi.just(\"foo\", \"bar\") .map(String::trim); Function&lt;Multi&lt;T&gt;, Multi&lt;T&gt;&gt; processorStage = upstream -&gt; upstream.map(String::toUpperCase); // Execution of pre-prepared stream publisherStage .compose(processorStage) .map(s -&gt; \"Item received: \" + s) .forEach(System.out::println); &gt; Item received: FOO &gt; Item received: BAR ",
            "title": "Operator Chains Composition"
        },
        {
            "location": "/mp/reactivestreams/engine",
            "text": " The stream processing operator chain can be easily constructed by io.helidon.common.reactive.Multi , or io.helidon.common.reactive.Single for streams with single value. <markup lang=\"java\" title=\"Example of Multi usage:\" >AtomicInteger sum = new AtomicInteger(); Multi.just(\"1\", \"2\", \"3\", \"4\", \"5\") .limit(3) .map(Integer::parseInt) .forEach(sum::addAndGet); System.out.println(\"Sum: \" + sum.get()); &gt; Sum: 6 <markup lang=\"java\" title=\"Example of Single usage:\" >Single.just(\"1\") .map(Integer::parseInt) .map(i -&gt; i + 5) .toStage() .whenComplete((i, t) -&gt; System.out.println(\"Result: \" + i)); &gt; Result: 6 Operators defer Call the given supplier function for each individual downstream Subscriber to return a Flow.Publisher to subscribe to. map Map this Multi instance to a new Multi of another type using the given Mapper . defaultIfEmpty Signals the default item if the upstream is empty. switchIfEmpty Switch to the other publisher if the upstream is empty. peek Invoke provided consumer for every item in stream. distinct Filter out all duplicates. filter Filter stream items with provided predicate. takeWhile Take the longest prefix of elements from this stream that satisfy the given predicate. As long as predicate returns true, items from upstream are sent to downstream, when predicate returns false stream is completed. dropWhile Drop the longest prefix of elements from this stream that satisfy the given predicate. As long as predicate returns true, items from upstream are NOT sent to downstream but being dropped, predicate is never called again after it returns false for the first time. limit Limit stream to allow only specified number of items to pass. skip Skip first n items, all the others are emitted. flatMap Transform each upstream item with the supplied function into a Flow.Publisher , subscribe to them and then flatten their items into a single sequence of items emitted to the downstream. flatMap Transform each upstream item with the supplied function and flatten the resulting Flow.Publisher to downstream while limiting the maximum number of concurrent inner `Flow.Publisher`s and their in-flight item count, optionally aggregating and delaying all errors until all sources terminate. flatMapCompletionStage Transform each upstream item with the supplied function and flatten the resulting CompletionStage results to downstream. flatMapIterable Transform each upstream item with the supplied function and flatten the resulting Iterable to the downstream. flatMapOptional Transform each upstream item with the supplied function and flatten the resulting Optional to the downstream as item if present. observeOn Re-emit the upstream&#8217;s signals to the downstream on the given executor&#8217;s thread using a default buffer size of 32 and errors skipping ahead of items. observeOn Re-emit the upstream&#8217;s signals to the downstream on the given executor&#8217;s thread. forEach Terminal stage, invokes provided consumer for every item in the stream with no backpressure. forEachCompletionStage Terminal stage, invokes provided function for every item in the stream with strict backpressure, requests another item only when previous operation is finished. collectList Collect the items of this Multi instance into a Single of List . collect Collect the items of this Multi instance into a Single . collect Collect the items of this Multi into a collection provided via a Supplier and mutated by a BiConsumer callback. collectStream Collects up upstream items with the help of the callbacks of a java.util.stream.Collector . reduce Combine subsequent items via a callback function and emit the final value result as a Single. reduce Combine every upstream item with an accumulator value to produce a new accumulator value and emit the final accumulator value as a Single. first Get the first item of this Multi instance as a Single . from Wrap a CompletionStage into a Multi and signal its outcome non-blockingly. from Wrap a CompletionStage into a Multi and signal its outcome non-blockingly. from Create a Multi instance wrapped around the given publisher. from Create a Multi instance that publishes the given iterable. from Create a Multi instance that publishes the given Stream . just Create a Multi instance that publishes the given items to a single subscriber. just Create a Multi instance that publishes the given items to a single subscriber. singleton Create a Multi that emits a pre-existing item and then completes. error Create a Multi instance that reports the given exception to its subscriber(s). The exception is reported by invoking Subscriber#onError(java.lang.Throwable) when Publisher#subscribe(Subscriber) is called. empty Get a Multi instance that completes immediately. never Get a Multi instance that never completes. concat Concat streams to one. onTerminate Executes given java.lang.Runnable when any of signals onComplete, onCancel or onError is received. ifEmpty Executes given java.lang.Runnable when stream is finished without value(empty stream). onComplete Executes given java.lang.Runnable when onComplete signal is received. onError Executes the given java.util.function.Consumer when an onError signal is received. onCancel Executes given java.lang.Runnable when a cancel signal is received. takeUntil Relay upstream items until the other source signals an item or completes. range Emits a range of ever increasing integers. rangeLong Emits a range of ever increasing longs. timer Signal 0L and complete the sequence after the given time elapsed. interval Signal 0L, 1L and so on periodically to the downstream. interval Signal 0L after an initial delay, then 1L, 2L and so on periodically to the downstream. timeout Signals a TimeoutException if the upstream doesn&#8217;t signal the next item, error or completion within the specified time. timeout Switches to a fallback source if the upstream doesn&#8217;t signal the next item, error or completion within the specified time. onErrorResume java.util.function.Function providing one item to be submitted as onNext in case of onError signal is received. onErrorResumeWith Resume stream from supplied publisher if onError signal is intercepted. retry Retry a failing upstream at most the given number of times before giving up. retry Retry a failing upstream if the predicate returns true. retryWhen Retry a failing upstream when the given function returns a publisher that signals an item. Operator Chains Composition In the situations when part of the operator chain needs to be prepared in advance, compose and to operators are at hand. <markup lang=\"java\" title=\"Combining operator chains:\" >// Assembly of stream, nothing is streamed yet Multi&lt;String&gt; publisherStage = Multi.just(\"foo\", \"bar\") .map(String::trim); Function&lt;Multi&lt;T&gt;, Multi&lt;T&gt;&gt; processorStage = upstream -&gt; upstream.map(String::toUpperCase); // Execution of pre-prepared stream publisherStage .compose(processorStage) .map(s -&gt; \"Item received: \" + s) .forEach(System.out::println); &gt; Item received: FOO &gt; Item received: BAR ",
            "title": "Usage"
        },
        {
            "location": "/mp/reactivestreams/rsoperators",
            "text": " Overview Maven Coordinates Usage Reference ",
            "title": "Contents"
        },
        {
            "location": "/mp/reactivestreams/rsoperators",
            "text": " Helidon implements MicroProfile Reactive Streams Operators specification which defines reactive operators and provides a standardized tool for manipulation with Reactive Streams . You can use MicroProfile Reactive Streams Operators when you want to maintain source-level portability between different implementations. ",
            "title": "Overview"
        },
        {
            "location": "/mp/reactivestreams/rsoperators",
            "text": " To enable Reactive Streams either add a dependency on the helidon-microprofile bundle or add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.reactive-streams&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-reactive-streams&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/reactivestreams/rsoperators",
            "text": " Graphs are pre-prepared stream builders with stages , which can be combined to closed graph with methods via and to . <markup lang=\"java\" title=\"Combining the graphs and running the stream:\" >// Assembly of stream, nothing is streamed yet PublisherBuilder&lt;String&gt; publisherStage = ReactiveStreams.of(\"foo\", \"bar\") .map(String::trim); ProcessorBuilder&lt;String, String&gt; processorStage = ReactiveStreams.&lt;String&gt;builder() .map(String::toUpperCase); SubscriberBuilder&lt;String, Void&gt; subscriberStage = ReactiveStreams.&lt;String&gt;builder() .map(s -&gt; \"Item received: \" + s) .forEach(System.out::println); // Execution of pre-prepared stream publisherStage .via(processorStage) .to(subscriberStage).run(); &gt; Item received: FOO &gt; Item received: BAR ",
            "title": "Graphs"
        },
        {
            "location": "/mp/reactivestreams/rsoperators",
            "text": " The MicroProfile Reactive Streams Operators specification provides a set of operators within stages, as well as the builders used to prepare graphs of stages from which streams can be built. <markup lang=\"java\" title=\"Example of simple closed graph usage:\" >AtomicInteger sum = new AtomicInteger(); ReactiveStreams.of(\"1\", \"2\", \"3\", \"4\", \"5\") .limit(3) .map(Integer::parseInt) .forEach(sum::addAndGet) .run() .whenComplete((r, t) -&gt; System.out.println(\"Sum: \" + sum.get())); &gt; Sum: 6 Operators(Stages) fromIterable Create new PublisherBuilder from supplied Iterable of Create new PublisherBuilder emitting supplied elements ofNullable Empty stream if supplied item is null iterate Create infinite stream with every next item created by supplied operator from previous item generate Create infinite stream with every item created by invocation of supplier empty Create new PublisherBuilder emitting as a first thing complete signal failed Create new PublisherBuilder emitting as a first thing error signal concat Concat two streams coupled Two parallel streams sharing cancel, onError and onComplete signals limit Limit the size of the stream, when limit is reached completes peek Invoke consumer for every item passing this operator filter Drop item when expression result to false map Transform items flatMap Flatten supplied stream to current stream flatMapIterable Flatten supplied iterable to current stream flatMapCompletionStage Map elements to completion stage and wait for each to be completed, keeps the order flatMapRSPublisher Map elements to Publishers and flatten this sub streams to original stream takeWhile Let items pass until expression is true, first time its false completes dropWhile Drop items until expression is true, first time its false let everything pass skip Drop first n items distinct Let pass only distinct items via Connect supplied processor to current stream return supplied processor onError Invoke supplied consumer when onError signal received onErrorResume Emit one last supplied item when onError signal received onErrorResumeWith When onError signal received continue emitting from supplied publisher builder onErrorResumeWithRsPublisher When onError signal received continue emitting from supplied publisher onComplete Invoke supplied runnable when onComplete signal received onTerminate Invoke supplied runnable when onComplete or onError signal received ifEmpty Executes given java.lang.Runnable when stream is finished without value(empty stream). to Connect this stream to supplied subscriber toList Collect all intercepted items to List collect Collect all intercepted items with provided collector forEach Invoke supplied Consumer for each intercepted item ignore Ignore all onNext signals, wait for onComplete reduce Reduction with provided expression cancel Cancel stream immediately findFirst Return first intercepted element Graphs Graphs are pre-prepared stream builders with stages , which can be combined to closed graph with methods via and to . <markup lang=\"java\" title=\"Combining the graphs and running the stream:\" >// Assembly of stream, nothing is streamed yet PublisherBuilder&lt;String&gt; publisherStage = ReactiveStreams.of(\"foo\", \"bar\") .map(String::trim); ProcessorBuilder&lt;String, String&gt; processorStage = ReactiveStreams.&lt;String&gt;builder() .map(String::toUpperCase); SubscriberBuilder&lt;String, Void&gt; subscriberStage = ReactiveStreams.&lt;String&gt;builder() .map(s -&gt; \"Item received: \" + s) .forEach(System.out::println); // Execution of pre-prepared stream publisherStage .via(processorStage) .to(subscriberStage).run(); &gt; Item received: FOO &gt; Item received: BAR ",
            "title": "Usage"
        },
        {
            "location": "/mp/reactivestreams/rsoperators",
            "text": " MicroProfile Reactive Streams Operators Specification MicroProfile Reactive Streams Operators JavaDoc MicroProfile Reactive Streams Operators on GitHub ",
            "title": "Reference"
        },
        {
            "location": "/mp/restclient",
            "text": " Overview Maven Coordinates API Configuration Examples Reference ",
            "title": "Contents"
        },
        {
            "location": "/mp/restclient",
            "text": " MicroProfile Rest Client adds the capability to invoke remote services by defining a Java interface with Jakarta REST (JAX-RS) annotations that resembles a server-side resource class. Helidon will automatically create a proxy class for the interface and map local proxy calls to remote REST calls. For more information, see Rest Client For MicroProfile Specification . ",
            "title": "Overview"
        },
        {
            "location": "/mp/restclient",
            "text": " To enable MicroProfile Rest Client either add a dependency on the helidon-microprofile bundle or add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.rest-client&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-rest-client&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/restclient",
            "text": " MicroProfile Rest Client can be created using a builder obtained from RestClientBuilder.newBuilder() . The builder provides methods to specify the client interface to be proxied as well as to configure additional details such as server URI, SSL context, connection timeouts, etc. Any method call on the resulting proxy object will be automatically translated into a remote call to the service using the provided configuration. <markup lang=\"java\" title=\"Example\" >SomeResource greetResource = RestClientBuilder.newBuilder() .baseUri(URI.create(\"http://localhost:8080/greet\")) .build(GreetRestClient.class); greetResource.getDefaultMessage(); The RestClientBuilder interface extends the Configurable interface from Jakarta REST (JAX-RS), enabling direct registration of providers such as filters, param converters, exception mappers, etc. <markup lang=\"java\" title=\"Example\" >SomeResource greetResource = RestClientBuilder.newBuilder() .baseUri(URI.create(\"http://localhost:8080\")) .register(GreetClientRequestFilter.class) .register(GreetClientExceptionMapper.class) .build(GreetRestClient.class); greetResource.getDefaultMessage(); ",
            "title": "Creating a New Client Using a Builder"
        },
        {
            "location": "/mp/restclient",
            "text": " A client interface can be annotated with @RegisterRestClient to automatically register it with CDI. This annotation has a property called baseUri that can be used to define the base endpoint to be used by the client to access the service. <markup lang=\"java\" title=\"Example\" >@Path(\"/greet\") @RegisterRestClient(baseUri=\"http://localhost:8080\") public interface GreetRestClient { // ... } Any Jakarta REST (JAX-RS) providers for a client can be registered using the (repeatable) @RegisterProvider annotation on the interface as shown below. <markup lang=\"java\" title=\"Example\" >@Path(\"/greet\") @RegisterRestClient(baseUri=\"http://localhost:8080\") @RegisterProvider(GreetClientRequestFilter.class) @RegisterProvider(GreetClientExceptionMapper.class) public interface GreetRestClient { // ... } Once a client interface is annotated, it can be injected into any CDI bean. All properties in annotation RegisterRestClient can be overridden via configuration as described in Configuration options <markup lang=\"java\" title=\"Example\" >public class MyBean { @Inject @RestClient GreetRestClient client; void myMethod() { client.getMessage(\"Helidon\"); } } ",
            "title": "Creating a New Client Using CDI"
        },
        {
            "location": "/mp/restclient",
            "text": " Class Description org.eclipse.microprofile.rest.client.RestClientBuilder Base builder instance. Contains configuration options and a build method that creates the actual client instance. Annotation Description @RegisterRestClient A marker annotation to register a client at runtime. This marker must be applied to any CDI managed clients. @RestClient RestClient qualifier which should be used on an CDI injection points. Creating a New Client Using a Builder MicroProfile Rest Client can be created using a builder obtained from RestClientBuilder.newBuilder() . The builder provides methods to specify the client interface to be proxied as well as to configure additional details such as server URI, SSL context, connection timeouts, etc. Any method call on the resulting proxy object will be automatically translated into a remote call to the service using the provided configuration. <markup lang=\"java\" title=\"Example\" >SomeResource greetResource = RestClientBuilder.newBuilder() .baseUri(URI.create(\"http://localhost:8080/greet\")) .build(GreetRestClient.class); greetResource.getDefaultMessage(); The RestClientBuilder interface extends the Configurable interface from Jakarta REST (JAX-RS), enabling direct registration of providers such as filters, param converters, exception mappers, etc. <markup lang=\"java\" title=\"Example\" >SomeResource greetResource = RestClientBuilder.newBuilder() .baseUri(URI.create(\"http://localhost:8080\")) .register(GreetClientRequestFilter.class) .register(GreetClientExceptionMapper.class) .build(GreetRestClient.class); greetResource.getDefaultMessage(); Creating a New Client Using CDI A client interface can be annotated with @RegisterRestClient to automatically register it with CDI. This annotation has a property called baseUri that can be used to define the base endpoint to be used by the client to access the service. <markup lang=\"java\" title=\"Example\" >@Path(\"/greet\") @RegisterRestClient(baseUri=\"http://localhost:8080\") public interface GreetRestClient { // ... } Any Jakarta REST (JAX-RS) providers for a client can be registered using the (repeatable) @RegisterProvider annotation on the interface as shown below. <markup lang=\"java\" title=\"Example\" >@Path(\"/greet\") @RegisterRestClient(baseUri=\"http://localhost:8080\") @RegisterProvider(GreetClientRequestFilter.class) @RegisterProvider(GreetClientExceptionMapper.class) public interface GreetRestClient { // ... } Once a client interface is annotated, it can be injected into any CDI bean. All properties in annotation RegisterRestClient can be overridden via configuration as described in Configuration options <markup lang=\"java\" title=\"Example\" >public class MyBean { @Inject @RestClient GreetRestClient client; void myMethod() { client.getMessage(\"Helidon\"); } } ",
            "title": "API"
        },
        {
            "location": "/mp/restclient",
            "text": " Required configuration options: key type default value description $restClient/mp-rest/url string &#160; Sets the base URL to use for this service. This option or /mp-rest/uri need to be set if the value is not present in RegisterRestClient#baseUri . $restClient/mp-rest/uri string &#160; Sets the base URI to use for this service. This option or /mp-rest/url need to be set if the value is not present in RegisterRestClient#baseUri . Optional configuration options: key type default value description $restClient/mp-rest/scope string jakarta.enterprise.context.Dependent The fully qualified classname to a CDI scope to use for injection. $restClient/mp-rest/connectTimeout long &#160; Sets timeout in milliseconds to wait to connect to the remote endpoint. $restClient/mp-rest/readTimeout long &#160; Sets timeout in milliseconds to wait for a response from the remote endpoint. $restClient/mp-rest/followRedirects boolean false Sets value used to determine whether the client should follow HTTP redirect responses. $restClient/mp-rest/proxyAddress string &#160; Sets a string value in the form of &lt;proxyHost&gt;:&lt;proxyPort&gt; that specifies the HTTP proxy server hostname (or IP address) and port for requests of this client to use. $restClient/mp-rest/queryParamStyle string (MULTI_PAIRS, COMMA_SEPARATED, ARRAY_PAIRS) MULTI_PAIRS Sets enumerated type string value that specifies the format in which multiple values for the same query parameter is used. $restClient/mp-rest/trustStore string &#160; Sets the trust store location. Can point to either a classpath resource (e.g. classpath:/client-truststore.jks) or a file (e.g. file:/home/user/client-truststore.jks). $restClient/mp-rest/trustStorePassword string &#160; Sets the password for the trust store. $restClient/mp-rest/trustStoreType string JKS Sets the type of the trust store. $restClient/mp-rest/keyStore string &#160; Sets the key store location. Can point to either a classpath resource (e.g. classpath:/client-keystore.jks) or a file (e.g. file:/home/user/client-keystore.jks). $restClient/mp-rest/keyStorePassword string &#160; Sets the password for the keystore. $restClient/mp-rest/keyStoreType string JKS Sets the type of the keystore. $restClient/mp-rest/hostnameVerifier string &#160; Sets the hostname verifier class. This class must have a public no-argument constructor. Configuration options affecting CDI and programmatically created clients: key type default value description $restClient/mp-rest/providers string &#160; A comma separated list of fully-qualified provider classnames to include in the client. $restClient/mp-rest/providers/&lt;fully-qualified-provider-classname&gt;/priority string &#160; Sets the priority of the provider for this interface. org.eclipse.microprofile.rest.client.propagateHeaders string &#160; To specify which headers to propagate from the inbound JAX-RS request to the outbound MP Rest Client request. Should not be prefixed with the rest client class or alias. microprofile.rest.client.disable.default.mapper boolean false Whether to disable default exception mapper. Should not be prefixed with the rest client class or alias. ",
            "title": "Configuration options"
        },
        {
            "location": "/mp/restclient",
            "text": " Configuration is only available for CDI managed client instances, it is not supported for client created programmatically using RestClientBuilder . Most of the configuration properties mentioned below have to be prepended with the fully qualified classname of the client interface to be configured. It is possible to avoid fully qualified classname by using @RegisterRestClient(configKey=\"clientAlias\") , the prefix $restClient is used below to indicate an alias or a class name. Configuration options Required configuration options: key type default value description $restClient/mp-rest/url string &#160; Sets the base URL to use for this service. This option or /mp-rest/uri need to be set if the value is not present in RegisterRestClient#baseUri . $restClient/mp-rest/uri string &#160; Sets the base URI to use for this service. This option or /mp-rest/url need to be set if the value is not present in RegisterRestClient#baseUri . Optional configuration options: key type default value description $restClient/mp-rest/scope string jakarta.enterprise.context.Dependent The fully qualified classname to a CDI scope to use for injection. $restClient/mp-rest/connectTimeout long &#160; Sets timeout in milliseconds to wait to connect to the remote endpoint. $restClient/mp-rest/readTimeout long &#160; Sets timeout in milliseconds to wait for a response from the remote endpoint. $restClient/mp-rest/followRedirects boolean false Sets value used to determine whether the client should follow HTTP redirect responses. $restClient/mp-rest/proxyAddress string &#160; Sets a string value in the form of &lt;proxyHost&gt;:&lt;proxyPort&gt; that specifies the HTTP proxy server hostname (or IP address) and port for requests of this client to use. $restClient/mp-rest/queryParamStyle string (MULTI_PAIRS, COMMA_SEPARATED, ARRAY_PAIRS) MULTI_PAIRS Sets enumerated type string value that specifies the format in which multiple values for the same query parameter is used. $restClient/mp-rest/trustStore string &#160; Sets the trust store location. Can point to either a classpath resource (e.g. classpath:/client-truststore.jks) or a file (e.g. file:/home/user/client-truststore.jks). $restClient/mp-rest/trustStorePassword string &#160; Sets the password for the trust store. $restClient/mp-rest/trustStoreType string JKS Sets the type of the trust store. $restClient/mp-rest/keyStore string &#160; Sets the key store location. Can point to either a classpath resource (e.g. classpath:/client-keystore.jks) or a file (e.g. file:/home/user/client-keystore.jks). $restClient/mp-rest/keyStorePassword string &#160; Sets the password for the keystore. $restClient/mp-rest/keyStoreType string JKS Sets the type of the keystore. $restClient/mp-rest/hostnameVerifier string &#160; Sets the hostname verifier class. This class must have a public no-argument constructor. Configuration options affecting CDI and programmatically created clients: key type default value description $restClient/mp-rest/providers string &#160; A comma separated list of fully-qualified provider classnames to include in the client. $restClient/mp-rest/providers/&lt;fully-qualified-provider-classname&gt;/priority string &#160; Sets the priority of the provider for this interface. org.eclipse.microprofile.rest.client.propagateHeaders string &#160; To specify which headers to propagate from the inbound JAX-RS request to the outbound MP Rest Client request. Should not be prefixed with the rest client class or alias. microprofile.rest.client.disable.default.mapper boolean false Whether to disable default exception mapper. Should not be prefixed with the rest client class or alias. ",
            "title": "Configuration"
        },
        {
            "location": "/mp/restclient",
            "text": " To be able to run and test this example, use the Helidon MP examples/quickstarts . Add a dependency on the Helidon Rest Client implementation and create the following client interface: <markup lang=\"java\" title=\"client interface\" >@Path(\"/greet\") interface GreetRestClient { @GET JsonObject getDefaultMessage(); @Path(\"/{name}\") @GET JsonObject getMessage(@PathParam(\"name\") String name); } Then create a runnable method as described in Creating new client , but with baseUri http://localhost:8080/greet and the above interface. By calling GreetRestClient.getDefaultMessage() you reach the endpoint of Helidon quickstart. ",
            "title": "Examples"
        },
        {
            "location": "/mp/restclient",
            "text": " Helidon MicroProfile RestClient JavaDoc MicroProfile RestClient Specification MicroProfile RestClient on GitHub ",
            "title": "Reference"
        },
        {
            "location": "/mp/scheduling",
            "text": " Overview Maven Coordinates Usage Configuration Examples Reference ",
            "title": "Contents"
        },
        {
            "location": "/mp/scheduling",
            "text": " Scheduling is an essential feature for the Enterprise. Helidon has its own implementation of Scheduling functionality based on Cron-utils . ",
            "title": "Overview"
        },
        {
            "location": "/mp/scheduling",
            "text": " To enable Scheduling add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.scheduling&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-scheduling&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/scheduling",
            "text": " For simple fixed rate invocation interval is @FixedRate the easiest way for scheduling task invocation. <markup lang=\"java\" >@FixedRate(initialDelay = 5, value = 10, timeUnit = TimeUnit.MINUTES) All values defined with the annotation can be overridden from the config. <markup lang=\"yaml\" title=\"Overriding annotated values from config\" >fully.qualified.ClassName.methodName: schedule: initial-delay: 5 delay: 15 time-unit: HOURS Metadata like human-readable interval description or configured values are available through FixedRateInvocation injected as method parameter. <markup lang=\"java\" >@FixedRate(initialDelay = 5, value = 10, timeUnit = TimeUnit.MINUTES) ",
            "title": "Fixed rate"
        },
        {
            "location": "/mp/scheduling",
            "text": " For more complicated interval definition, cron expression can be leveraged with @Schedule annotation. <markup lang=\"java\" >@Scheduled(\"0 15 8 ? * *\", concurrentExecution = false) public void methodName() { ... } ",
            "title": "Cron expression"
        },
        {
            "location": "/mp/scheduling",
            "text": "<markup title=\"Cron expression format\" >&lt;seconds&gt; &lt;minutes&gt; &lt;hours&gt; &lt;day-of-month&gt; &lt;month&gt; &lt;day-of-week&gt; &lt;year&gt; Cron expression fields Order Name Supported values Supported field format Optional 1 seconds 0-59 CONST, LIST, RANGE, WILDCARD, INCREMENT false 2 minutes 0-59 CONST, LIST, RANGE, WILDCARD, INCREMENT false 3 hours 0-23 CONST, LIST, RANGE, WILDCARD, INCREMENT false 4 day-of-month 1-31 CONST, LIST, RANGE, WILDCARD, INCREMENT, ANY, LAST, WEEKDAY false 5 month 1-12 or JAN-DEC CONST, LIST, RANGE, WILDCARD, INCREMENT false 6 day-of-week 1-7 or SUN-SAT CONST, LIST, RANGE, WILDCARD, INCREMENT, ANY, NTH, LAST false 7 year 1970-2099 CONST, LIST, RANGE, WILDCARD, INCREMENT true Field formats Name Regex format Example Description CONST \\d+ 12 exact value LIST \\d+,\\d+(,\\d+)* 1,2,3,4 list of constants RANGE \\d+-\\d+ 15-30 range of values from-to WILDCARD \\* * all values withing the field INCREMENT \\d+\\/\\d+ 0/5 inital number / increments, 2/5 means 2,7,9,11,16,&#8230;&#8203; ANY \\? ? any day(apply only to day-of-week and day-of-month) NTH \\# 1#3 nth day of the month, 2#3 means third monday of the month LAST \\d*L(+\\d+|\\-\\d+)? 3L-3 last day of the month in day-of-month or last nth day in the day-of-week WEEKDAY \\# 1#3 nearest weekday of the nth day of month, 1W is the first monday of the week Examples Cron expression Description * * * * * ? Every second 0/2 * * * * ? * Every 2 seconds 0 45 9 ? * * Every day at 9:45 0 15 8 ? * MON-FRI Every workday at 8:15 Metadata like human-readable interval description or configured values are available through CronInvocation injected as method parameter. <markup lang=\"java\" >@Scheduled(\"0 15 8 ? * *\") public void methodName(CronInvocation inv) { ... } ",
            "title": "Cron expression"
        },
        {
            "location": "/mp/scheduling",
            "text": " For scheduling tasks in Helidon you can choose from @Scheduled or @FixedRate annotations by required complexity of invocation interval. All you need is define method with one of the annotations in application scoped bean. Fixed rate For simple fixed rate invocation interval is @FixedRate the easiest way for scheduling task invocation. <markup lang=\"java\" >@FixedRate(initialDelay = 5, value = 10, timeUnit = TimeUnit.MINUTES) All values defined with the annotation can be overridden from the config. <markup lang=\"yaml\" title=\"Overriding annotated values from config\" >fully.qualified.ClassName.methodName: schedule: initial-delay: 5 delay: 15 time-unit: HOURS Metadata like human-readable interval description or configured values are available through FixedRateInvocation injected as method parameter. <markup lang=\"java\" >@FixedRate(initialDelay = 5, value = 10, timeUnit = TimeUnit.MINUTES) Cron expression For more complicated interval definition, cron expression can be leveraged with @Schedule annotation. <markup lang=\"java\" >@Scheduled(\"0 15 8 ? * *\", concurrentExecution = false) public void methodName() { ... } Cron expression <markup title=\"Cron expression format\" >&lt;seconds&gt; &lt;minutes&gt; &lt;hours&gt; &lt;day-of-month&gt; &lt;month&gt; &lt;day-of-week&gt; &lt;year&gt; Cron expression fields Order Name Supported values Supported field format Optional 1 seconds 0-59 CONST, LIST, RANGE, WILDCARD, INCREMENT false 2 minutes 0-59 CONST, LIST, RANGE, WILDCARD, INCREMENT false 3 hours 0-23 CONST, LIST, RANGE, WILDCARD, INCREMENT false 4 day-of-month 1-31 CONST, LIST, RANGE, WILDCARD, INCREMENT, ANY, LAST, WEEKDAY false 5 month 1-12 or JAN-DEC CONST, LIST, RANGE, WILDCARD, INCREMENT false 6 day-of-week 1-7 or SUN-SAT CONST, LIST, RANGE, WILDCARD, INCREMENT, ANY, NTH, LAST false 7 year 1970-2099 CONST, LIST, RANGE, WILDCARD, INCREMENT true Field formats Name Regex format Example Description CONST \\d+ 12 exact value LIST \\d+,\\d+(,\\d+)* 1,2,3,4 list of constants RANGE \\d+-\\d+ 15-30 range of values from-to WILDCARD \\* * all values withing the field INCREMENT \\d+\\/\\d+ 0/5 inital number / increments, 2/5 means 2,7,9,11,16,&#8230;&#8203; ANY \\? ? any day(apply only to day-of-week and day-of-month) NTH \\# 1#3 nth day of the month, 2#3 means third monday of the month LAST \\d*L(+\\d+|\\-\\d+)? 3L-3 last day of the month in day-of-month or last nth day in the day-of-week WEEKDAY \\# 1#3 nearest weekday of the nth day of month, 1W is the first monday of the week Examples Cron expression Description * * * * * ? Every second 0/2 * * * * ? * Every 2 seconds 0 45 9 ? * * Every day at 9:45 0 15 8 ? * MON-FRI Every workday at 8:15 Metadata like human-readable interval description or configured values are available through CronInvocation injected as method parameter. <markup lang=\"java\" >@Scheduled(\"0 15 8 ? * *\") public void methodName(CronInvocation inv) { ... } ",
            "title": "Usage"
        },
        {
            "location": "/mp/scheduling",
            "text": " Scheduled annotation properties can be overridden using application.yaml properties <markup lang=\"yaml\" title=\"Overriding annotated values from config\" >fully.qualified.ClassName.methodName: schedule: cron: \"* * * * * ?\" concurrent: false Configuration properties Property Description cron String containing cron setup concurrent Boolean, equivalent concurrentExecution property of @Scheduled . Default true . ",
            "title": "Configuration"
        },
        {
            "location": "/mp/scheduling",
            "text": "<markup lang=\"java\" title=\"Example of scheduling with fixed rate\" >@FixedRate(initialDelay = 5, value = 10, timeUnit = TimeUnit.MINUTES) public void methodName() { System.out.println(\"Every 10 minutes, first invocation 5 minutes after start\"); } ",
            "title": "Fixed rate"
        },
        {
            "location": "/mp/scheduling",
            "text": "<markup lang=\"java\" title=\"Example with invocation metadata\" >@FixedRate(initialDelay = 5, value = 10, timeUnit = TimeUnit.MINUTES) public void methodName(FixedRateInvocation inv) { System.out.println(\"Method invoked \" + inv.description()); } ",
            "title": "FixedRate Metadata Injection"
        },
        {
            "location": "/mp/scheduling",
            "text": "<markup lang=\"java\" title=\"Example of scheduling with cron expression\" >@Scheduled(\"0 15 8 ? * *\", concurrentExecution = false) public void methodName() { System.out.println(\"Executer every day at 8:15\"); } ",
            "title": "Cron expression"
        },
        {
            "location": "/mp/scheduling",
            "text": "<markup lang=\"java\" title=\"Example with invocation metadata\" >@Scheduled(\"0 15 8 ? * *\") public void methodName(CronInvocation inv) { System.out.println(\"Method invoked \" + inv.description()); } ",
            "title": "Scheduled Metadata Injection."
        },
        {
            "location": "/mp/scheduling",
            "text": " Fixed rate <markup lang=\"java\" title=\"Example of scheduling with fixed rate\" >@FixedRate(initialDelay = 5, value = 10, timeUnit = TimeUnit.MINUTES) public void methodName() { System.out.println(\"Every 10 minutes, first invocation 5 minutes after start\"); } FixedRate Metadata Injection <markup lang=\"java\" title=\"Example with invocation metadata\" >@FixedRate(initialDelay = 5, value = 10, timeUnit = TimeUnit.MINUTES) public void methodName(FixedRateInvocation inv) { System.out.println(\"Method invoked \" + inv.description()); } Cron expression <markup lang=\"java\" title=\"Example of scheduling with cron expression\" >@Scheduled(\"0 15 8 ? * *\", concurrentExecution = false) public void methodName() { System.out.println(\"Executer every day at 8:15\"); } Scheduled Metadata Injection. <markup lang=\"java\" title=\"Example with invocation metadata\" >@Scheduled(\"0 15 8 ? * *\") public void methodName(CronInvocation inv) { System.out.println(\"Method invoked \" + inv.description()); } ",
            "title": "Examples"
        },
        {
            "location": "/mp/scheduling",
            "text": " Cron-utils GitHub page Helidon Scheduling JavaDoc ",
            "title": "Reference"
        },
        {
            "location": "/mp/security/configuration-secrets",
            "text": " When security requires a configuration with repeating complex elements, use Helidon Config. This example configures a basic authentication provider and protects static content on the web server. It also includes annotations in Jersey. ",
            "title": "preambule"
        },
        {
            "location": "/mp/security/configuration-secrets",
            "text": " The config encryption filter has an option that defines whether encryption is required or not. If it&#8217;s set to true, which is the default, then: Configuration values with ${CLEAR=&#8230;&#8203;} template will cause an exception when requested. The filter fails during bootstrap if security.config.aes.insecure-passphrase is configured. ",
            "title": "Requiring encryption"
        },
        {
            "location": "/mp/security/configuration-secrets",
            "text": " The config encryption filter provides a Main class io.helidon.config.encryption.Main that can be used to encrypt values. <markup lang=\"bash\" title=\"Encrypt secret secretToEncrypt using shared secret masterPassword \" >java -jar &lt;path-to-app-libs-dir&gt;/helidon-config-encryption-{helidon-version}.jar aes masterPassword secretToEncrypt The tool returns the string to be entered into configuration as the value of a property. ",
            "title": "Encrypting values (AES)"
        },
        {
            "location": "/mp/security/configuration-secrets",
            "text": " You can provide a shared secret in a couple of ways: in configuration - for testing/demo purposes only - key is security.config.aes.insecure-passphrase as an environment variable - SECURE_CONFIG_AES_MASTER_PWD ",
            "title": "Shared Secret (AES)"
        },
        {
            "location": "/mp/security/configuration-secrets",
            "text": " Symmetric encryption is based on a shared secret that is known by the person encrypting the value and is also provided to the application. Encrypting values (AES) The config encryption filter provides a Main class io.helidon.config.encryption.Main that can be used to encrypt values. <markup lang=\"bash\" title=\"Encrypt secret secretToEncrypt using shared secret masterPassword \" >java -jar &lt;path-to-app-libs-dir&gt;/helidon-config-encryption-{helidon-version}.jar aes masterPassword secretToEncrypt The tool returns the string to be entered into configuration as the value of a property. Shared Secret (AES) You can provide a shared secret in a couple of ways: in configuration - for testing/demo purposes only - key is security.config.aes.insecure-passphrase as an environment variable - SECURE_CONFIG_AES_MASTER_PWD ",
            "title": "Using symmetric encryption (AES)"
        },
        {
            "location": "/mp/security/configuration-secrets",
            "text": " The config encryption filter provides a Main class io.helidon.config.encryption.Main that can be used to encrypt values. <markup lang=\"bash\" title=\"Encrypt secret secretToEncrypt using public certificate in a keystore\" >java -jar &lt;path-to-app-libs-dir&gt;/helidon-config-encryption-{helidon-version}.jar rsa /path/to/keystore.p12 keystorePassword publicCertAlias secretToEncrypt The tool returns the string to be entered into configuration as the value of a property. ",
            "title": "Encrypting values (RSA)"
        },
        {
            "location": "/mp/security/configuration-secrets",
            "text": " You can configure the properties of a private key in a keystore. These keys are prefixed with security.config.rsa.keystore RSA Configuration Options: Keystore What Configuration Key Environment Variable Description Keystore path resource.path SECURE_CONFIG_RSA_PRIVATE_KEY Keystore is located in file system Keystore resource.resource-path N/A Keystore is located on classpath Private key alias key.alias SECURE_CONFIG_PRIVATE_KEY_ALIAS Alias of the private key (such as \"1\", which is usually the default) Keystore passphrase passphrase SECURE_CONFIG_PRIVATE_KEYSTORE_PASSPHRASE Password for the keystore (and private key). RSA Configuration Options: PEM (PKCS#8) private key What Configuration Key Environment Variable Description Path pem.key.resource.path SECURE_CONFIG_RSA_PEM_KEY Key is located on file system Resource path pem.key.resource.resource-path N/A Key is located on classpath Passphrase pem.key.passphrase SECURE_CONFIG_PRIVATE_KEY_PASSPHRASE Password protecting the private key <markup lang=\"yaml\" title=\"Example yaml configuration\" >security.config: # Set to true for production - if set to true, clear text passwords will cause failure require-encryption: false # The \"master\" password for AES decryption. For production, set this via system property or environment variable. aes.insecure-passphrase: \"myMasterPasswordForEncryption\" # See documentation of pki-util rsa: keystore: # load from classpath resource.resource-path: \".ssh/keystore.p12\" # If keystore is used, alias to use from the keystore (in this example, it is \"1\") key.alias: \"1\" # Password of keystore passphrase: \"helidon\" ",
            "title": "Configure config encryption filter (RSA)"
        },
        {
            "location": "/mp/security/configuration-secrets",
            "text": " This approach is based on a pair of keys: a public key which is known to anybody, and a private key which is known to a limited set of parties (usually a single person or process). For asymmetric encryption, the following is true: a value encrypted by a public key can only be decrypted by the private key When using the config encryption filter, you should encrypt the configuration values using the public key, and give the application process access to the private key to decrypt the values. Encrypting values (RSA) The config encryption filter provides a Main class io.helidon.config.encryption.Main that can be used to encrypt values. <markup lang=\"bash\" title=\"Encrypt secret secretToEncrypt using public certificate in a keystore\" >java -jar &lt;path-to-app-libs-dir&gt;/helidon-config-encryption-{helidon-version}.jar rsa /path/to/keystore.p12 keystorePassword publicCertAlias secretToEncrypt The tool returns the string to be entered into configuration as the value of a property. Configure config encryption filter (RSA) You can configure the properties of a private key in a keystore. These keys are prefixed with security.config.rsa.keystore RSA Configuration Options: Keystore What Configuration Key Environment Variable Description Keystore path resource.path SECURE_CONFIG_RSA_PRIVATE_KEY Keystore is located in file system Keystore resource.resource-path N/A Keystore is located on classpath Private key alias key.alias SECURE_CONFIG_PRIVATE_KEY_ALIAS Alias of the private key (such as \"1\", which is usually the default) Keystore passphrase passphrase SECURE_CONFIG_PRIVATE_KEYSTORE_PASSPHRASE Password for the keystore (and private key). RSA Configuration Options: PEM (PKCS#8) private key What Configuration Key Environment Variable Description Path pem.key.resource.path SECURE_CONFIG_RSA_PEM_KEY Key is located on file system Resource path pem.key.resource.resource-path N/A Key is located on classpath Passphrase pem.key.passphrase SECURE_CONFIG_PRIVATE_KEY_PASSPHRASE Password protecting the private key <markup lang=\"yaml\" title=\"Example yaml configuration\" >security.config: # Set to true for production - if set to true, clear text passwords will cause failure require-encryption: false # The \"master\" password for AES decryption. For production, set this via system property or environment variable. aes.insecure-passphrase: \"myMasterPasswordForEncryption\" # See documentation of pki-util rsa: keystore: # load from classpath resource.resource-path: \".ssh/keystore.p12\" # If keystore is used, alias to use from the keystore (in this example, it is \"1\") key.alias: \"1\" # Password of keystore passphrase: \"helidon\" ",
            "title": "Using asymmetric encryption (RSA)"
        },
        {
            "location": "/mp/security/configuration-secrets",
            "text": " In Helidon MP, the config encryption filter is enabled by default . However, if you don&#8217;t configure it, the filter only supports a template for aliasing that checks that no clear text passwords are present (template ${CLEAR=&#8230;&#8203;}. In Helidon SE, you may add support for this filter with dependency (loaded through a java service mechanism): <markup lang=\"xml\" title=\"Maven Dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.config&lt;/groupId&gt; &lt;artifactId&gt;helidon-config-encryption&lt;/artifactId&gt; &lt;/dependency&gt; Put encrypted values into your configuration file so that it can be stored in a public repository with no danger of exposing the secret values. Be sure to use a strong and secret password. The supported templates are: Templates Template Description Example ${CLEAR=&#8230;&#8203;} Secret in clear text (for testing) - requiresEncryption must be disabled ${CLEAR=knownSecret} ${RSA-P=&#8230;&#8203;} Public/private key encryption, base64 value ${RSA-P=aGr3sFCMQznixrgbIk9qNfoLnO1cdi3H86qweCNjxFvH4dYg5IQM1EuoyTjJaXcSCG5MBskpeA3bjnWYrzeAFFlZHuYSPsb+wJVzGLrfUColTn+BPJjpJ3rmEd3AVkJl1ASfBBMh3q3deC+rvUdhfoTGBO8sC0teUATklCQSxfHOnIxswxqrplnoGXToGiTIfehiN2IZNulRKeoDQ0AeoKREmq5au4L8OOmS+D9BqnlKMc0F1tULZ7+h3Cxla4lXC5WRPoPfHBU4vzRZOGzeDvLkRgrD60caw/wKn5M0Wy1A1cKR8E46ceBXCjJ2eWIcLyhZSAZWDe3ceNrawHZtCg==} ${GCM=&#8230;&#8203;} Shared secret ecryption, base64 value ${GCM=D/UgMzsNb265HU1NDvdzm7tACHdsW6u1PjYEcRkV/OLiWcI+ET6Q4MKCz0zHyEh9} Requiring encryption The config encryption filter has an option that defines whether encryption is required or not. If it&#8217;s set to true, which is the default, then: Configuration values with ${CLEAR=&#8230;&#8203;} template will cause an exception when requested. The filter fails during bootstrap if security.config.aes.insecure-passphrase is configured. Using symmetric encryption (AES) Symmetric encryption is based on a shared secret that is known by the person encrypting the value and is also provided to the application. Encrypting values (AES) The config encryption filter provides a Main class io.helidon.config.encryption.Main that can be used to encrypt values. <markup lang=\"bash\" title=\"Encrypt secret secretToEncrypt using shared secret masterPassword \" >java -jar &lt;path-to-app-libs-dir&gt;/helidon-config-encryption-{helidon-version}.jar aes masterPassword secretToEncrypt The tool returns the string to be entered into configuration as the value of a property. Shared Secret (AES) You can provide a shared secret in a couple of ways: in configuration - for testing/demo purposes only - key is security.config.aes.insecure-passphrase as an environment variable - SECURE_CONFIG_AES_MASTER_PWD Using asymmetric encryption (RSA) This approach is based on a pair of keys: a public key which is known to anybody, and a private key which is known to a limited set of parties (usually a single person or process). For asymmetric encryption, the following is true: a value encrypted by a public key can only be decrypted by the private key When using the config encryption filter, you should encrypt the configuration values using the public key, and give the application process access to the private key to decrypt the values. Encrypting values (RSA) The config encryption filter provides a Main class io.helidon.config.encryption.Main that can be used to encrypt values. <markup lang=\"bash\" title=\"Encrypt secret secretToEncrypt using public certificate in a keystore\" >java -jar &lt;path-to-app-libs-dir&gt;/helidon-config-encryption-{helidon-version}.jar rsa /path/to/keystore.p12 keystorePassword publicCertAlias secretToEncrypt The tool returns the string to be entered into configuration as the value of a property. Configure config encryption filter (RSA) You can configure the properties of a private key in a keystore. These keys are prefixed with security.config.rsa.keystore RSA Configuration Options: Keystore What Configuration Key Environment Variable Description Keystore path resource.path SECURE_CONFIG_RSA_PRIVATE_KEY Keystore is located in file system Keystore resource.resource-path N/A Keystore is located on classpath Private key alias key.alias SECURE_CONFIG_PRIVATE_KEY_ALIAS Alias of the private key (such as \"1\", which is usually the default) Keystore passphrase passphrase SECURE_CONFIG_PRIVATE_KEYSTORE_PASSPHRASE Password for the keystore (and private key). RSA Configuration Options: PEM (PKCS#8) private key What Configuration Key Environment Variable Description Path pem.key.resource.path SECURE_CONFIG_RSA_PEM_KEY Key is located on file system Resource path pem.key.resource.resource-path N/A Key is located on classpath Passphrase pem.key.passphrase SECURE_CONFIG_PRIVATE_KEY_PASSPHRASE Password protecting the private key <markup lang=\"yaml\" title=\"Example yaml configuration\" >security.config: # Set to true for production - if set to true, clear text passwords will cause failure require-encryption: false # The \"master\" password for AES decryption. For production, set this via system property or environment variable. aes.insecure-passphrase: \"myMasterPasswordForEncryption\" # See documentation of pki-util rsa: keystore: # load from classpath resource.resource-path: \".ssh/keystore.p12\" # If keystore is used, alias to use from the keystore (in this example, it is \"1\") key.alias: \"1\" # Password of keystore passphrase: \"helidon\" ",
            "title": "Protecting Configuration Secrets"
        },
        {
            "location": "/mp/security/jep-290",
            "text": " Overview Deserialization setup System property configuration Programmatic configuration ",
            "title": "Contents"
        },
        {
            "location": "/mp/security/jep-290",
            "text": " JEP-290 brought support for deserialization filters to Java programming language. Such filtering allows us to control which classes may be deserialized using Java serialization. ",
            "title": "Overview"
        },
        {
            "location": "/mp/security/jep-290",
            "text": " Helidon default settings forbids any deserialization except for patterns defined in a pattern property of any META-INF/helidon/serial-config.properties on classpath. The patterns are semicolon delimited strings, such as io.myapp.&#42;&#42;;java.util.HashMap (any subpackage of io.myapp and class java.util.HashMap ). Helidon will always add a deny-all filter pattern to the end of the pattern string (to make sure we exclude any unspecified class - we only operate on whitelists) These defaults can be modified either through system properties, or programmatically. ",
            "title": "Deserialization setup"
        },
        {
            "location": "/mp/security/jep-290",
            "text": " The following system properties can be used to control deserialization in Helidon: System properties property default value description helidon.serialFilter.pattern !&#42; Filter pattern to use, deny all is always added helidon.serialFilter.ignoreFiles false Whether to ignore files META-INF/helidon/serial-config.properties in libraries on the classpath helidon.serialFilter.failure.action FAIL Action to do when the configuration of global filter exists and is not consistent with our security expectations (e.g. contains a pattern to include all). Options: FAIL - throw an exception to terminate startup WARN - log a warning IGNORE - ignore this and silently continue helidon.serialFilter.missing.action CONFIGURE Action to do when there is no global configuration. Options: CONFIGURE - configure Helidon defaults FAIL - throw an exception to terminate startup WARN - log a warning IGNORE - ignore this and silently continue helidon.serialFilter.trace NONE Tracing configuration for deserialization. Controls what information (if any) will be logged to a logger io.helidon.common.SerializationConfig.TracingObjectInputFilter in INFO log level. Options: NONE - do not trace BASIC - trace only classes, and only once per class FULL - trace all deserialization filter requests ",
            "title": "System property configuration"
        },
        {
            "location": "/mp/security/jep-290",
            "text": " Custom SerializationConfig may be registered, but it must be done before Helidon server is started. <markup lang=\"java\" title=\"Configure custom Helidon serialization config\" >SerializationConfig.builder() .traceSerialization(SerializationConfig.TraceOption.BASIC) .filterPattern(MyType.class.getName()) .ignoreFiles(true) .onWrongConfig(SerializationConfig.Action.IGNORE) .build() .configure(); Trace first instance of each class that is deserialized Configure a single class filter pattern (only allows deserialization of class MyType Ignore files defined in META-INF/helidon/serial-config.properties In case there is an existing global serialization configuration on JDK, ignore it and continue (global filter cannot be reconfigured) Configure this serialization config as the default for this JVM ",
            "title": "Programmatic configuration"
        },
        {
            "location": "/mp/security/providers",
            "text": "<markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-oidc&lt;/artifactId&gt; &lt;/dependency&gt; Open ID Connect security provider Type: io.helidon.security.providers.oidc.OidcProvider <markup lang=\"text\" title=\"Config key\" >oidc This type provides the following service implementations: io.helidon.security.spi.AuthenticationProvider io.helidon.security.spi.SecurityProvider ",
            "title": "Setup"
        },
        {
            "location": "/mp/security/providers",
            "text": " Optional configuration options key type default value description audience string &#160; Audience of issued tokens. authorization-endpoint-uri URI &#160; URI of an authorization endpoint used to redirect users to for logging-in. If not defined, it is obtained from #oidcMetadata(Resource), if that is not defined an attempt is made to use #identityUri(URI)/oauth2/v1/authorize. base-scopes string openid Configure base scopes. By default, this is DEFAULT_BASE_SCOPES . If scope has a qualifier, it must be used here. check-audience boolean false Configure audience claim check. client-id string &#160; Client ID as generated by OIDC server. client-secret string &#160; Client secret as generated by OIDC server. Used to authenticate this application with the server when requesting JWT based on a code. client-timeout-millis Duration 30000 Timeout of calls using web client. cookie-domain string &#160; Domain the cookie is valid for. Not used by default. cookie-http-only boolean true When using cookie, if set to true, the HttpOnly attribute will be configured. Defaults to OidcCookieHandler.Builder#DEFAULT_HTTP_ONLY . cookie-max-age-seconds long &#160; When using cookie, used to set MaxAge attribute of the cookie, defining how long the cookie is valid. Not used by default. cookie-name string JSESSIONID Name of the cookie to use. Defaults to DEFAULT_COOKIE_NAME . cookie-name-tenant string HELIDON_TENANT The name of the cookie to use for the tenant name. Defaults to DEFAULT_TENANT_COOKIE_NAME . cookie-path string / Path the cookie is valid for. Defaults to \"/\". cookie-same-site SameSite (LAX, STRICT, NONE) LAX When using cookie, used to set the SameSite cookie value. Can be \"Strict\" or \"Lax\". cookie-secure boolean false When using cookie, if set to true, the Secure attribute will be configured. Defaults to false. cookie-use boolean true Whether to use cookie to store JWT between requests. Defaults to DEFAULT_COOKIE_USE . cors CrossOriginConfig &#160; Assign cross-origin resource sharing settings. force-https-redirects boolean false Force HTTPS for redirects to identity provider. Defaults to false . frontend-uri string &#160; Full URI of this application that is visible from user browser. Used to redirect request back from identity server after successful login. header-token TokenHandler &#160; A TokenHandler to process header containing a JWT. Default is \"Authorization\" header with a prefix \"bearer \". header-use boolean true Whether to expect JWT in a header field. identity-uri URI &#160; URI of the identity server, base used to retrieve OIDC metadata. introspect-endpoint-uri URI &#160; Endpoint to use to validate JWT. Either use this or set #signJwk(JwkKeys) or #signJwk(Resource). issuer string &#160; Issuer of issued tokens. max-redirects int 5 Configure maximal number of redirects when redirecting to an OIDC provider within a single authentication attempt. Defaults to `DEFAULT_MAX_REDIRECTS` oidc-metadata-well-known boolean true If set to true, metadata will be loaded from default (well known) location, unless it is explicitly defined using oidc-metadata-resource. If set to false, it would not be loaded even if oidc-metadata-resource is not defined. In such a case all URIs must be explicitly defined (e.g. token-endpoint-uri). oidc-metadata.resource Resource &#160; Resource configuration for OIDC Metadata containing endpoints to various identity services, as well as information about the identity server. optional boolean false Whether authentication is required. By default, request will fail if the authentication cannot be verified. If set to true, request will process and this provider will abstain. optional-audience boolean false Allow audience claim to be optional. outbound OutboundTarget[&#93; &#160; Add a new target configuration. propagate boolean false Whether to propagate identity. proxy-host string &#160; Proxy host to use. When defined, triggers usage of proxy for HTTP requests. Setting to empty String has the same meaning as setting to null - disables proxy. proxy-port int 80 Proxy port. Defaults to DEFAULT_PROXY_PORT proxy-protocol string http Proxy protocol to use when proxy is used. Defaults to DEFAULT_PROXY_PROTOCOL . query-param-name string accessToken Name of a query parameter that contains the JWT token when parameter is used. query-param-tenant-name string h_tenant Name of a query parameter that contains the tenant name when the parameter is used. Defaults to #DEFAULT_TENANT_PARAM_NAME. query-param-use boolean false Whether to use a query parameter to send JWT token from application to this server. redirect boolean false By default, the client should redirect to the identity server for the user to log in. This behavior can be overridden by setting redirect to false. When token is not present in the request, the client will not redirect and just return appropriate error response code. redirect-attempt-param string h_ra Configure the parameter used to store the number of attempts in redirect. Defaults to `DEFAULT_ATTEMPT_PARAM` redirect-uri string /oidc/redirect URI to register web server component on, used by the OIDC server to redirect authorization requests to after a user logs in or approves scopes. Note that usually the redirect URI configured here must be the same one as configured on OIDC server. Defaults to `DEFAULT_REDIRECT_URI` relative-uris boolean false Can be set to true to force the use of relative URIs in all requests, regardless of the presence or absence of proxies or no-proxy lists. By default, requests that use the Proxy will have absolute URIs. Set this flag to true if the host is unable to accept absolute URIs. Defaults to DEFAULT_RELATIVE_URIS . scope-audience string &#160; Audience of the scope required by this application. This is prefixed to the scope name when requesting scopes from the identity server. Defaults to empty string. server-type string @default Configure one of the supported types of identity servers. If the type does not have an explicit mapping, a warning is logged and the default implementation is used. sign-jwk.resource Resource &#160; A resource pointing to JWK with public keys of signing certificates used to validate JWT. tenants TenantConfig &#160; Configurations of the tenants token-endpoint-auth ClientAuthentication (CLIENT_SECRET_BASIC, CLIENT_SECRET_POST, CLIENT_SECRET_JWT, PRIVATE_KEY_JWT, NONE) CLIENT_SECRET_BASIC Type of authentication to use when invoking the token endpoint. Current supported options: io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#CLIENT_SECRET_BASIC io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#CLIENT_SECRET_POST io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#NONE token-endpoint-uri URI &#160; URI of a token endpoint used to obtain a JWT based on the authentication code. If not defined, it is obtained from #oidcMetadata(Resource), if that is not defined an attempt is made to use #identityUri(URI)/oauth2/v1/token. use-jwt-groups boolean true Claim groups from JWT will be used to automatically add groups to current subject (may be used with jakarta.annotation.security.RolesAllowed annotation). validate-jwt-with-jwk boolean true Use JWK (a set of keys to validate signatures of JWT) to validate tokens. Use this method when you want to use default values for JWK or introspection endpoint URI. ",
            "title": "Configuration options"
        },
        {
            "location": "/mp/security/providers",
            "text": " Open ID Connect security provider. Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-oidc&lt;/artifactId&gt; &lt;/dependency&gt; Open ID Connect security provider Type: io.helidon.security.providers.oidc.OidcProvider <markup lang=\"text\" title=\"Config key\" >oidc This type provides the following service implementations: io.helidon.security.spi.AuthenticationProvider io.helidon.security.spi.SecurityProvider Configuration options Optional configuration options key type default value description audience string &#160; Audience of issued tokens. authorization-endpoint-uri URI &#160; URI of an authorization endpoint used to redirect users to for logging-in. If not defined, it is obtained from #oidcMetadata(Resource), if that is not defined an attempt is made to use #identityUri(URI)/oauth2/v1/authorize. base-scopes string openid Configure base scopes. By default, this is DEFAULT_BASE_SCOPES . If scope has a qualifier, it must be used here. check-audience boolean false Configure audience claim check. client-id string &#160; Client ID as generated by OIDC server. client-secret string &#160; Client secret as generated by OIDC server. Used to authenticate this application with the server when requesting JWT based on a code. client-timeout-millis Duration 30000 Timeout of calls using web client. cookie-domain string &#160; Domain the cookie is valid for. Not used by default. cookie-http-only boolean true When using cookie, if set to true, the HttpOnly attribute will be configured. Defaults to OidcCookieHandler.Builder#DEFAULT_HTTP_ONLY . cookie-max-age-seconds long &#160; When using cookie, used to set MaxAge attribute of the cookie, defining how long the cookie is valid. Not used by default. cookie-name string JSESSIONID Name of the cookie to use. Defaults to DEFAULT_COOKIE_NAME . cookie-name-tenant string HELIDON_TENANT The name of the cookie to use for the tenant name. Defaults to DEFAULT_TENANT_COOKIE_NAME . cookie-path string / Path the cookie is valid for. Defaults to \"/\". cookie-same-site SameSite (LAX, STRICT, NONE) LAX When using cookie, used to set the SameSite cookie value. Can be \"Strict\" or \"Lax\". cookie-secure boolean false When using cookie, if set to true, the Secure attribute will be configured. Defaults to false. cookie-use boolean true Whether to use cookie to store JWT between requests. Defaults to DEFAULT_COOKIE_USE . cors CrossOriginConfig &#160; Assign cross-origin resource sharing settings. force-https-redirects boolean false Force HTTPS for redirects to identity provider. Defaults to false . frontend-uri string &#160; Full URI of this application that is visible from user browser. Used to redirect request back from identity server after successful login. header-token TokenHandler &#160; A TokenHandler to process header containing a JWT. Default is \"Authorization\" header with a prefix \"bearer \". header-use boolean true Whether to expect JWT in a header field. identity-uri URI &#160; URI of the identity server, base used to retrieve OIDC metadata. introspect-endpoint-uri URI &#160; Endpoint to use to validate JWT. Either use this or set #signJwk(JwkKeys) or #signJwk(Resource). issuer string &#160; Issuer of issued tokens. max-redirects int 5 Configure maximal number of redirects when redirecting to an OIDC provider within a single authentication attempt. Defaults to `DEFAULT_MAX_REDIRECTS` oidc-metadata-well-known boolean true If set to true, metadata will be loaded from default (well known) location, unless it is explicitly defined using oidc-metadata-resource. If set to false, it would not be loaded even if oidc-metadata-resource is not defined. In such a case all URIs must be explicitly defined (e.g. token-endpoint-uri). oidc-metadata.resource Resource &#160; Resource configuration for OIDC Metadata containing endpoints to various identity services, as well as information about the identity server. optional boolean false Whether authentication is required. By default, request will fail if the authentication cannot be verified. If set to true, request will process and this provider will abstain. optional-audience boolean false Allow audience claim to be optional. outbound OutboundTarget[&#93; &#160; Add a new target configuration. propagate boolean false Whether to propagate identity. proxy-host string &#160; Proxy host to use. When defined, triggers usage of proxy for HTTP requests. Setting to empty String has the same meaning as setting to null - disables proxy. proxy-port int 80 Proxy port. Defaults to DEFAULT_PROXY_PORT proxy-protocol string http Proxy protocol to use when proxy is used. Defaults to DEFAULT_PROXY_PROTOCOL . query-param-name string accessToken Name of a query parameter that contains the JWT token when parameter is used. query-param-tenant-name string h_tenant Name of a query parameter that contains the tenant name when the parameter is used. Defaults to #DEFAULT_TENANT_PARAM_NAME. query-param-use boolean false Whether to use a query parameter to send JWT token from application to this server. redirect boolean false By default, the client should redirect to the identity server for the user to log in. This behavior can be overridden by setting redirect to false. When token is not present in the request, the client will not redirect and just return appropriate error response code. redirect-attempt-param string h_ra Configure the parameter used to store the number of attempts in redirect. Defaults to `DEFAULT_ATTEMPT_PARAM` redirect-uri string /oidc/redirect URI to register web server component on, used by the OIDC server to redirect authorization requests to after a user logs in or approves scopes. Note that usually the redirect URI configured here must be the same one as configured on OIDC server. Defaults to `DEFAULT_REDIRECT_URI` relative-uris boolean false Can be set to true to force the use of relative URIs in all requests, regardless of the presence or absence of proxies or no-proxy lists. By default, requests that use the Proxy will have absolute URIs. Set this flag to true if the host is unable to accept absolute URIs. Defaults to DEFAULT_RELATIVE_URIS . scope-audience string &#160; Audience of the scope required by this application. This is prefixed to the scope name when requesting scopes from the identity server. Defaults to empty string. server-type string @default Configure one of the supported types of identity servers. If the type does not have an explicit mapping, a warning is logged and the default implementation is used. sign-jwk.resource Resource &#160; A resource pointing to JWK with public keys of signing certificates used to validate JWT. tenants TenantConfig &#160; Configurations of the tenants token-endpoint-auth ClientAuthentication (CLIENT_SECRET_BASIC, CLIENT_SECRET_POST, CLIENT_SECRET_JWT, PRIVATE_KEY_JWT, NONE) CLIENT_SECRET_BASIC Type of authentication to use when invoking the token endpoint. Current supported options: io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#CLIENT_SECRET_BASIC io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#CLIENT_SECRET_POST io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#NONE token-endpoint-uri URI &#160; URI of a token endpoint used to obtain a JWT based on the authentication code. If not defined, it is obtained from #oidcMetadata(Resource), if that is not defined an attempt is made to use #identityUri(URI)/oauth2/v1/token. use-jwt-groups boolean true Claim groups from JWT will be used to automatically add groups to current subject (may be used with jakarta.annotation.security.RolesAllowed annotation). validate-jwt-with-jwk boolean true Use JWK (a set of keys to validate signatures of JWT) to validate tokens. Use this method when you want to use default values for JWK or introspection endpoint URI. ",
            "title": "OIDC Provider"
        },
        {
            "location": "/mp/security/providers",
            "text": " See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - oidc: client-id: \"client-id-of-this-service\" client-secret: \"${CLEAR=client-secret-of-this-service}\" identity-uri: \"http://your-tenant.identity-server.com\" frontend-uri: \"http://my-service:8080\" audience: \"http://my-service\" cors: allow-origins: [\"http://foo.com\", \"http://there.com\"] allow-methods: [\"PUT\", \"DELETE\"] outbound: - name: \"internal-services\" hosts: [\"*.example.org\"] outbound-token: header: \"X-Internal-Auth\" ",
            "title": "Example code"
        },
        {
            "location": "/mp/security/providers",
            "text": " At Helidon startup, if OIDC provider is configured, the following will happen: client-id , client-secret , and identityUri are validated - these must provide values Unless all resources are configured as local resources, the provider attempts to contact the oidc-metadata.resource endpoint to retrieve all endpoints At runtime, depending on configuration&#8230;&#8203; If a request comes without a token or with insufficient scopes: If redirect is set to true (default), request is redirected to the authorization endpoint of the identity server. If set to false, 401 is returned User authenticates against the identity server The identity server redirects back to Helidon service with a code Helidon service contacts the identity server&#8217;s token endpoint, to exchange the code for a JWT The JWT is stored in a cookie (if cookie support is enabled, which it is by default) Helidon service redirects to original endpoint (on itself) Helidon obtains a token from request (from cookie, header, or query parameter): Token is parsed as a singed JWT We validate the JWT signature either against local JWK or against the identity server&#8217;s introspection endpoint depending on configuration We validate the issuer and audience of the token if it matches the configured values A subject is created from the JWT, including scopes from the token We validate that we have sufficient scopes to proceed, and return 403 if not Handling is returned to security to process other security providers ",
            "title": "How does it work?"
        },
        {
            "location": "/mp/security/providers",
            "text": " Required configuration options key type default value description name string &#160; Name of the tenant. Optional configuration options key type default value description audience string &#160; Audience of issued tokens. authorization-endpoint-uri URI &#160; URI of an authorization endpoint used to redirect users to for logging-in. If not defined, it is obtained from #oidcMetadata(Resource), if that is not defined an attempt is made to use #identityUri(URI)/oauth2/v1/authorize. base-scopes string openid Configure base scopes. By default, this is DEFAULT_BASE_SCOPES . If scope has a qualifier, it must be used here. check-audience boolean false Configure audience claim check. client-id string &#160; Client ID as generated by OIDC server. client-secret string &#160; Client secret as generated by OIDC server. Used to authenticate this application with the server when requesting JWT based on a code. client-timeout-millis Duration 30000 Timeout of calls using web client. identity-uri URI &#160; URI of the identity server, base used to retrieve OIDC metadata. introspect-endpoint-uri URI &#160; Endpoint to use to validate JWT. Either use this or set #signJwk(JwkKeys) or #signJwk(Resource). issuer string &#160; Issuer of issued tokens. oidc-metadata-well-known boolean true If set to true, metadata will be loaded from default (well known) location, unless it is explicitly defined using oidc-metadata-resource. If set to false, it would not be loaded even if oidc-metadata-resource is not defined. In such a case all URIs must be explicitly defined (e.g. token-endpoint-uri). oidc-metadata.resource Resource &#160; Resource configuration for OIDC Metadata containing endpoints to various identity services, as well as information about the identity server. optional-audience boolean false Allow audience claim to be optional. scope-audience string &#160; Audience of the scope required by this application. This is prefixed to the scope name when requesting scopes from the identity server. Defaults to empty string. server-type string @default Configure one of the supported types of identity servers. If the type does not have an explicit mapping, a warning is logged and the default implementation is used. sign-jwk.resource Resource &#160; A resource pointing to JWK with public keys of signing certificates used to validate JWT. token-endpoint-auth ClientAuthentication (CLIENT_SECRET_BASIC, CLIENT_SECRET_POST, CLIENT_SECRET_JWT, PRIVATE_KEY_JWT, NONE) CLIENT_SECRET_BASIC Type of authentication to use when invoking the token endpoint. Current supported options: io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#CLIENT_SECRET_BASIC io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#CLIENT_SECRET_POST io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#NONE token-endpoint-uri URI &#160; URI of a token endpoint used to obtain a JWT based on the authentication code. If not defined, it is obtained from #oidcMetadata(Resource), if that is not defined an attempt is made to use #identityUri(URI)/oauth2/v1/token. validate-jwt-with-jwk boolean true Use JWK (a set of keys to validate signatures of JWT) to validate tokens. Use this method when you want to use default values for JWK or introspection endpoint URI. ",
            "title": "Configuration options"
        },
        {
            "location": "/mp/security/providers",
            "text": " Open ID Connect tenant configuration Type: io.helidon.security.providers.oidc.common.TenantConfig Configuration options Required configuration options key type default value description name string &#160; Name of the tenant. Optional configuration options key type default value description audience string &#160; Audience of issued tokens. authorization-endpoint-uri URI &#160; URI of an authorization endpoint used to redirect users to for logging-in. If not defined, it is obtained from #oidcMetadata(Resource), if that is not defined an attempt is made to use #identityUri(URI)/oauth2/v1/authorize. base-scopes string openid Configure base scopes. By default, this is DEFAULT_BASE_SCOPES . If scope has a qualifier, it must be used here. check-audience boolean false Configure audience claim check. client-id string &#160; Client ID as generated by OIDC server. client-secret string &#160; Client secret as generated by OIDC server. Used to authenticate this application with the server when requesting JWT based on a code. client-timeout-millis Duration 30000 Timeout of calls using web client. identity-uri URI &#160; URI of the identity server, base used to retrieve OIDC metadata. introspect-endpoint-uri URI &#160; Endpoint to use to validate JWT. Either use this or set #signJwk(JwkKeys) or #signJwk(Resource). issuer string &#160; Issuer of issued tokens. oidc-metadata-well-known boolean true If set to true, metadata will be loaded from default (well known) location, unless it is explicitly defined using oidc-metadata-resource. If set to false, it would not be loaded even if oidc-metadata-resource is not defined. In such a case all URIs must be explicitly defined (e.g. token-endpoint-uri). oidc-metadata.resource Resource &#160; Resource configuration for OIDC Metadata containing endpoints to various identity services, as well as information about the identity server. optional-audience boolean false Allow audience claim to be optional. scope-audience string &#160; Audience of the scope required by this application. This is prefixed to the scope name when requesting scopes from the identity server. Defaults to empty string. server-type string @default Configure one of the supported types of identity servers. If the type does not have an explicit mapping, a warning is logged and the default implementation is used. sign-jwk.resource Resource &#160; A resource pointing to JWK with public keys of signing certificates used to validate JWT. token-endpoint-auth ClientAuthentication (CLIENT_SECRET_BASIC, CLIENT_SECRET_POST, CLIENT_SECRET_JWT, PRIVATE_KEY_JWT, NONE) CLIENT_SECRET_BASIC Type of authentication to use when invoking the token endpoint. Current supported options: io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#CLIENT_SECRET_BASIC io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#CLIENT_SECRET_POST io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#NONE token-endpoint-uri URI &#160; URI of a token endpoint used to obtain a JWT based on the authentication code. If not defined, it is obtained from #oidcMetadata(Resource), if that is not defined an attempt is made to use #identityUri(URI)/oauth2/v1/token. validate-jwt-with-jwk boolean true Use JWK (a set of keys to validate signatures of JWT) to validate tokens. Use this method when you want to use default values for JWK or introspection endpoint URI. ",
            "title": "Available tenant config options"
        },
        {
            "location": "/mp/security/providers",
            "text": " Multitenant support requires to obtain tenant name from the incoming request. OIDC configuration is selected based on the received tenant name. The way this tenant name has to be provided is configured via tenant-id-style configuration. See How to enable tenants for more information. After matching tenant configuration with the received name, the rest of the OIDC flow if exactly the same as in How does OIDC work . Base OIDC configuration is treated as a default tenant, which is used, if no tenant name is provided. This default tenant is having @default name specified. It is also important to note, that each tenant configuration is based on the default tenant configuration (base OIDC configuration), and therefore its configuration do not need to change all the properties, if they do not differ from the base OIDC configuration. ",
            "title": "How does that work?"
        },
        {
            "location": "/mp/security/providers",
            "text": " The OIDC provider also supports multiple tenants. To enable this feature, it is required to do several steps. To enable the default multi-tenant support, add the multi-tenant: true option to the OIDC provider configuration Specify the desired way to provide the tenant name. This step is done over adding the tenant-id-style configuration option. For more information, see the table below Add the tenants section to the OIDC provider configuration <markup lang=\"yaml\" >tenants: - name: \"example-tenant\" ... tenant configuration options There are four ways to provide the required tenant information to Helidon by default. Possible tenant-id-style configuration options key description additional config options host-header Tenant configuration will be selected based on your host present in the Host header value. &#160; domain Similar to the host-header style, but now the tenant name is identified just as a part of the host name. By default, it selects the third domain level. Example: Host header value from inbound request is my.helidon.com &#8594; domain level 3 is my , domain level 2 is helidon and domain level 1 is com . <markup lang=\"yaml\" >tenant-id-domain-level: &lt;domain level&gt; token-handler The tenant name information is expected to be provided through the configured custom header value. <markup lang=\"yaml\" >tenant-id-handler: header: \"my-custom-header\" none No tenant name finding is used. Default tenant name @default is used instead. You can also implement a custom way of discovering the tenant name and tenant configuration. The custom tenant name discovery from request can be done by implementing SPI: io.helidon.security.providers.oidc.common.spi.TenantIdProvider and the custom tenant configuration discovery can be provided by implementing SPI: io.helidon.security.providers.oidc.common.spi.TenantConfigProvider Available tenant config options Open ID Connect tenant configuration Type: io.helidon.security.providers.oidc.common.TenantConfig Configuration options Required configuration options key type default value description name string &#160; Name of the tenant. Optional configuration options key type default value description audience string &#160; Audience of issued tokens. authorization-endpoint-uri URI &#160; URI of an authorization endpoint used to redirect users to for logging-in. If not defined, it is obtained from #oidcMetadata(Resource), if that is not defined an attempt is made to use #identityUri(URI)/oauth2/v1/authorize. base-scopes string openid Configure base scopes. By default, this is DEFAULT_BASE_SCOPES . If scope has a qualifier, it must be used here. check-audience boolean false Configure audience claim check. client-id string &#160; Client ID as generated by OIDC server. client-secret string &#160; Client secret as generated by OIDC server. Used to authenticate this application with the server when requesting JWT based on a code. client-timeout-millis Duration 30000 Timeout of calls using web client. identity-uri URI &#160; URI of the identity server, base used to retrieve OIDC metadata. introspect-endpoint-uri URI &#160; Endpoint to use to validate JWT. Either use this or set #signJwk(JwkKeys) or #signJwk(Resource). issuer string &#160; Issuer of issued tokens. oidc-metadata-well-known boolean true If set to true, metadata will be loaded from default (well known) location, unless it is explicitly defined using oidc-metadata-resource. If set to false, it would not be loaded even if oidc-metadata-resource is not defined. In such a case all URIs must be explicitly defined (e.g. token-endpoint-uri). oidc-metadata.resource Resource &#160; Resource configuration for OIDC Metadata containing endpoints to various identity services, as well as information about the identity server. optional-audience boolean false Allow audience claim to be optional. scope-audience string &#160; Audience of the scope required by this application. This is prefixed to the scope name when requesting scopes from the identity server. Defaults to empty string. server-type string @default Configure one of the supported types of identity servers. If the type does not have an explicit mapping, a warning is logged and the default implementation is used. sign-jwk.resource Resource &#160; A resource pointing to JWK with public keys of signing certificates used to validate JWT. token-endpoint-auth ClientAuthentication (CLIENT_SECRET_BASIC, CLIENT_SECRET_POST, CLIENT_SECRET_JWT, PRIVATE_KEY_JWT, NONE) CLIENT_SECRET_BASIC Type of authentication to use when invoking the token endpoint. Current supported options: io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#CLIENT_SECRET_BASIC io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#CLIENT_SECRET_POST io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#NONE token-endpoint-uri URI &#160; URI of a token endpoint used to obtain a JWT based on the authentication code. If not defined, it is obtained from #oidcMetadata(Resource), if that is not defined an attempt is made to use #identityUri(URI)/oauth2/v1/token. validate-jwt-with-jwk boolean true Use JWK (a set of keys to validate signatures of JWT) to validate tokens. Use this method when you want to use default values for JWK or introspection endpoint URI. How does that work? Multitenant support requires to obtain tenant name from the incoming request. OIDC configuration is selected based on the received tenant name. The way this tenant name has to be provided is configured via tenant-id-style configuration. See How to enable tenants for more information. After matching tenant configuration with the received name, the rest of the OIDC flow if exactly the same as in How does OIDC work . Base OIDC configuration is treated as a default tenant, which is used, if no tenant name is provided. This default tenant is having @default name specified. It is also important to note, that each tenant configuration is based on the default tenant configuration (base OIDC configuration), and therefore its configuration do not need to change all the properties, if they do not differ from the base OIDC configuration. ",
            "title": "Multiple tenants"
        },
        {
            "location": "/mp/security/providers",
            "text": " Helidon provides the following security providers for endpoint protection: Provider Type Outbound supported Description OIDC Provider Authentication ✅ Open ID Connect supporting JWT, Scopes, Groups and OIDC code flow HTTP Basic Authentication Authentication ✅ HTTP Basic Authentication support HTTP Digest Authentication Authentication 🚫 HTTP Digest Authentication support Header Assertion Authentication ✅ Asserting a user based on a header value HTTP Signatures Authentication ✅ Protecting service to service communication through signatures IDCS Roles Role Mapping 🚫 Retrieves roles from IDCS provider for authenticated user ABAC Authorization Authorization 🚫 Attribute based access control authorization policies The following providers are no longer evolved: Provider Type Outbound supported Description Google Login Authentication ✅ Authenticates a token from request against Google servers JWT Provider Authentication ✅ JWT tokens passed from frontend OIDC Provider Open ID Connect security provider. Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-oidc&lt;/artifactId&gt; &lt;/dependency&gt; Open ID Connect security provider Type: io.helidon.security.providers.oidc.OidcProvider <markup lang=\"text\" title=\"Config key\" >oidc This type provides the following service implementations: io.helidon.security.spi.AuthenticationProvider io.helidon.security.spi.SecurityProvider Configuration options Optional configuration options key type default value description audience string &#160; Audience of issued tokens. authorization-endpoint-uri URI &#160; URI of an authorization endpoint used to redirect users to for logging-in. If not defined, it is obtained from #oidcMetadata(Resource), if that is not defined an attempt is made to use #identityUri(URI)/oauth2/v1/authorize. base-scopes string openid Configure base scopes. By default, this is DEFAULT_BASE_SCOPES . If scope has a qualifier, it must be used here. check-audience boolean false Configure audience claim check. client-id string &#160; Client ID as generated by OIDC server. client-secret string &#160; Client secret as generated by OIDC server. Used to authenticate this application with the server when requesting JWT based on a code. client-timeout-millis Duration 30000 Timeout of calls using web client. cookie-domain string &#160; Domain the cookie is valid for. Not used by default. cookie-http-only boolean true When using cookie, if set to true, the HttpOnly attribute will be configured. Defaults to OidcCookieHandler.Builder#DEFAULT_HTTP_ONLY . cookie-max-age-seconds long &#160; When using cookie, used to set MaxAge attribute of the cookie, defining how long the cookie is valid. Not used by default. cookie-name string JSESSIONID Name of the cookie to use. Defaults to DEFAULT_COOKIE_NAME . cookie-name-tenant string HELIDON_TENANT The name of the cookie to use for the tenant name. Defaults to DEFAULT_TENANT_COOKIE_NAME . cookie-path string / Path the cookie is valid for. Defaults to \"/\". cookie-same-site SameSite (LAX, STRICT, NONE) LAX When using cookie, used to set the SameSite cookie value. Can be \"Strict\" or \"Lax\". cookie-secure boolean false When using cookie, if set to true, the Secure attribute will be configured. Defaults to false. cookie-use boolean true Whether to use cookie to store JWT between requests. Defaults to DEFAULT_COOKIE_USE . cors CrossOriginConfig &#160; Assign cross-origin resource sharing settings. force-https-redirects boolean false Force HTTPS for redirects to identity provider. Defaults to false . frontend-uri string &#160; Full URI of this application that is visible from user browser. Used to redirect request back from identity server after successful login. header-token TokenHandler &#160; A TokenHandler to process header containing a JWT. Default is \"Authorization\" header with a prefix \"bearer \". header-use boolean true Whether to expect JWT in a header field. identity-uri URI &#160; URI of the identity server, base used to retrieve OIDC metadata. introspect-endpoint-uri URI &#160; Endpoint to use to validate JWT. Either use this or set #signJwk(JwkKeys) or #signJwk(Resource). issuer string &#160; Issuer of issued tokens. max-redirects int 5 Configure maximal number of redirects when redirecting to an OIDC provider within a single authentication attempt. Defaults to `DEFAULT_MAX_REDIRECTS` oidc-metadata-well-known boolean true If set to true, metadata will be loaded from default (well known) location, unless it is explicitly defined using oidc-metadata-resource. If set to false, it would not be loaded even if oidc-metadata-resource is not defined. In such a case all URIs must be explicitly defined (e.g. token-endpoint-uri). oidc-metadata.resource Resource &#160; Resource configuration for OIDC Metadata containing endpoints to various identity services, as well as information about the identity server. optional boolean false Whether authentication is required. By default, request will fail if the authentication cannot be verified. If set to true, request will process and this provider will abstain. optional-audience boolean false Allow audience claim to be optional. outbound OutboundTarget[&#93; &#160; Add a new target configuration. propagate boolean false Whether to propagate identity. proxy-host string &#160; Proxy host to use. When defined, triggers usage of proxy for HTTP requests. Setting to empty String has the same meaning as setting to null - disables proxy. proxy-port int 80 Proxy port. Defaults to DEFAULT_PROXY_PORT proxy-protocol string http Proxy protocol to use when proxy is used. Defaults to DEFAULT_PROXY_PROTOCOL . query-param-name string accessToken Name of a query parameter that contains the JWT token when parameter is used. query-param-tenant-name string h_tenant Name of a query parameter that contains the tenant name when the parameter is used. Defaults to #DEFAULT_TENANT_PARAM_NAME. query-param-use boolean false Whether to use a query parameter to send JWT token from application to this server. redirect boolean false By default, the client should redirect to the identity server for the user to log in. This behavior can be overridden by setting redirect to false. When token is not present in the request, the client will not redirect and just return appropriate error response code. redirect-attempt-param string h_ra Configure the parameter used to store the number of attempts in redirect. Defaults to `DEFAULT_ATTEMPT_PARAM` redirect-uri string /oidc/redirect URI to register web server component on, used by the OIDC server to redirect authorization requests to after a user logs in or approves scopes. Note that usually the redirect URI configured here must be the same one as configured on OIDC server. Defaults to `DEFAULT_REDIRECT_URI` relative-uris boolean false Can be set to true to force the use of relative URIs in all requests, regardless of the presence or absence of proxies or no-proxy lists. By default, requests that use the Proxy will have absolute URIs. Set this flag to true if the host is unable to accept absolute URIs. Defaults to DEFAULT_RELATIVE_URIS . scope-audience string &#160; Audience of the scope required by this application. This is prefixed to the scope name when requesting scopes from the identity server. Defaults to empty string. server-type string @default Configure one of the supported types of identity servers. If the type does not have an explicit mapping, a warning is logged and the default implementation is used. sign-jwk.resource Resource &#160; A resource pointing to JWK with public keys of signing certificates used to validate JWT. tenants TenantConfig &#160; Configurations of the tenants token-endpoint-auth ClientAuthentication (CLIENT_SECRET_BASIC, CLIENT_SECRET_POST, CLIENT_SECRET_JWT, PRIVATE_KEY_JWT, NONE) CLIENT_SECRET_BASIC Type of authentication to use when invoking the token endpoint. Current supported options: io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#CLIENT_SECRET_BASIC io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#CLIENT_SECRET_POST io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#NONE token-endpoint-uri URI &#160; URI of a token endpoint used to obtain a JWT based on the authentication code. If not defined, it is obtained from #oidcMetadata(Resource), if that is not defined an attempt is made to use #identityUri(URI)/oauth2/v1/token. use-jwt-groups boolean true Claim groups from JWT will be used to automatically add groups to current subject (may be used with jakarta.annotation.security.RolesAllowed annotation). validate-jwt-with-jwk boolean true Use JWK (a set of keys to validate signatures of JWT) to validate tokens. Use this method when you want to use default values for JWK or introspection endpoint URI. Example code See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - oidc: client-id: \"client-id-of-this-service\" client-secret: \"${CLEAR=client-secret-of-this-service}\" identity-uri: \"http://your-tenant.identity-server.com\" frontend-uri: \"http://my-service:8080\" audience: \"http://my-service\" cors: allow-origins: [\"http://foo.com\", \"http://there.com\"] allow-methods: [\"PUT\", \"DELETE\"] outbound: - name: \"internal-services\" hosts: [\"*.example.org\"] outbound-token: header: \"X-Internal-Auth\" How does it work? At Helidon startup, if OIDC provider is configured, the following will happen: client-id , client-secret , and identityUri are validated - these must provide values Unless all resources are configured as local resources, the provider attempts to contact the oidc-metadata.resource endpoint to retrieve all endpoints At runtime, depending on configuration&#8230;&#8203; If a request comes without a token or with insufficient scopes: If redirect is set to true (default), request is redirected to the authorization endpoint of the identity server. If set to false, 401 is returned User authenticates against the identity server The identity server redirects back to Helidon service with a code Helidon service contacts the identity server&#8217;s token endpoint, to exchange the code for a JWT The JWT is stored in a cookie (if cookie support is enabled, which it is by default) Helidon service redirects to original endpoint (on itself) Helidon obtains a token from request (from cookie, header, or query parameter): Token is parsed as a singed JWT We validate the JWT signature either against local JWK or against the identity server&#8217;s introspection endpoint depending on configuration We validate the issuer and audience of the token if it matches the configured values A subject is created from the JWT, including scopes from the token We validate that we have sufficient scopes to proceed, and return 403 if not Handling is returned to security to process other security providers Multiple tenants The OIDC provider also supports multiple tenants. To enable this feature, it is required to do several steps. To enable the default multi-tenant support, add the multi-tenant: true option to the OIDC provider configuration Specify the desired way to provide the tenant name. This step is done over adding the tenant-id-style configuration option. For more information, see the table below Add the tenants section to the OIDC provider configuration <markup lang=\"yaml\" >tenants: - name: \"example-tenant\" ... tenant configuration options There are four ways to provide the required tenant information to Helidon by default. Possible tenant-id-style configuration options key description additional config options host-header Tenant configuration will be selected based on your host present in the Host header value. &#160; domain Similar to the host-header style, but now the tenant name is identified just as a part of the host name. By default, it selects the third domain level. Example: Host header value from inbound request is my.helidon.com &#8594; domain level 3 is my , domain level 2 is helidon and domain level 1 is com . <markup lang=\"yaml\" >tenant-id-domain-level: &lt;domain level&gt; token-handler The tenant name information is expected to be provided through the configured custom header value. <markup lang=\"yaml\" >tenant-id-handler: header: \"my-custom-header\" none No tenant name finding is used. Default tenant name @default is used instead. You can also implement a custom way of discovering the tenant name and tenant configuration. The custom tenant name discovery from request can be done by implementing SPI: io.helidon.security.providers.oidc.common.spi.TenantIdProvider and the custom tenant configuration discovery can be provided by implementing SPI: io.helidon.security.providers.oidc.common.spi.TenantConfigProvider Available tenant config options Open ID Connect tenant configuration Type: io.helidon.security.providers.oidc.common.TenantConfig Configuration options Required configuration options key type default value description name string &#160; Name of the tenant. Optional configuration options key type default value description audience string &#160; Audience of issued tokens. authorization-endpoint-uri URI &#160; URI of an authorization endpoint used to redirect users to for logging-in. If not defined, it is obtained from #oidcMetadata(Resource), if that is not defined an attempt is made to use #identityUri(URI)/oauth2/v1/authorize. base-scopes string openid Configure base scopes. By default, this is DEFAULT_BASE_SCOPES . If scope has a qualifier, it must be used here. check-audience boolean false Configure audience claim check. client-id string &#160; Client ID as generated by OIDC server. client-secret string &#160; Client secret as generated by OIDC server. Used to authenticate this application with the server when requesting JWT based on a code. client-timeout-millis Duration 30000 Timeout of calls using web client. identity-uri URI &#160; URI of the identity server, base used to retrieve OIDC metadata. introspect-endpoint-uri URI &#160; Endpoint to use to validate JWT. Either use this or set #signJwk(JwkKeys) or #signJwk(Resource). issuer string &#160; Issuer of issued tokens. oidc-metadata-well-known boolean true If set to true, metadata will be loaded from default (well known) location, unless it is explicitly defined using oidc-metadata-resource. If set to false, it would not be loaded even if oidc-metadata-resource is not defined. In such a case all URIs must be explicitly defined (e.g. token-endpoint-uri). oidc-metadata.resource Resource &#160; Resource configuration for OIDC Metadata containing endpoints to various identity services, as well as information about the identity server. optional-audience boolean false Allow audience claim to be optional. scope-audience string &#160; Audience of the scope required by this application. This is prefixed to the scope name when requesting scopes from the identity server. Defaults to empty string. server-type string @default Configure one of the supported types of identity servers. If the type does not have an explicit mapping, a warning is logged and the default implementation is used. sign-jwk.resource Resource &#160; A resource pointing to JWK with public keys of signing certificates used to validate JWT. token-endpoint-auth ClientAuthentication (CLIENT_SECRET_BASIC, CLIENT_SECRET_POST, CLIENT_SECRET_JWT, PRIVATE_KEY_JWT, NONE) CLIENT_SECRET_BASIC Type of authentication to use when invoking the token endpoint. Current supported options: io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#CLIENT_SECRET_BASIC io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#CLIENT_SECRET_POST io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#NONE token-endpoint-uri URI &#160; URI of a token endpoint used to obtain a JWT based on the authentication code. If not defined, it is obtained from #oidcMetadata(Resource), if that is not defined an attempt is made to use #identityUri(URI)/oauth2/v1/token. validate-jwt-with-jwk boolean true Use JWK (a set of keys to validate signatures of JWT) to validate tokens. Use this method when you want to use default values for JWK or introspection endpoint URI. How does that work? Multitenant support requires to obtain tenant name from the incoming request. OIDC configuration is selected based on the received tenant name. The way this tenant name has to be provided is configured via tenant-id-style configuration. See How to enable tenants for more information. After matching tenant configuration with the received name, the rest of the OIDC flow if exactly the same as in How does OIDC work . Base OIDC configuration is treated as a default tenant, which is used, if no tenant name is provided. This default tenant is having @default name specified. It is also important to note, that each tenant configuration is based on the default tenant configuration (base OIDC configuration), and therefore its configuration do not need to change all the properties, if they do not differ from the base OIDC configuration. ",
            "title": "Implemented Security Providers"
        },
        {
            "location": "/mp/security/providers",
            "text": "<markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-http-auth&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Setup"
        },
        {
            "location": "/mp/security/providers",
            "text": " HTTP Basic Authentication provider Type: io.helidon.security.providers.httpauth.HttpBasicAuthProvider <markup lang=\"text\" title=\"Config key\" >http-basic-auth This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthenticationProvider ",
            "title": "Overview"
        },
        {
            "location": "/mp/security/providers",
            "text": " Optional configuration options key type default value description optional boolean false Whether authentication is required. By default, request will fail if the authentication cannot be verified. If set to false, request will process and this provider will abstain. outbound OutboundTarget[&#93; &#160; Add a new outbound target to configure identity propagation or explicit username/password. principal-type SubjectType (USER, SERVICE) USER Principal type this provider extracts (and also propagates). realm string helidon Set the realm to use when challenging users. users ConfigUser[&#93; &#160; Set user store to validate users. Removes any other stores added through #addUserStore(SecureUserStore). ",
            "title": "Configuration options"
        },
        {
            "location": "/mp/security/providers",
            "text": " See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - http-basic-auth: realm: \"helidon\" users: - login: \"john\" password: \"${CLEAR=password}\" roles: [\"admin\"] - login: \"jack\" password: \"password\" roles: [\"user\", \"admin\"] outbound: - name: \"internal-services\" hosts: [\"*.example.org\"] # Propagates current user's identity or identity from request property outbound-token: header: \"X-Internal-Auth\" - name: \"partner-service\" hosts: [\"*.partner.org\"] # Uses this username and password username: \"partner-user-1\" password: \"${CLEAR=password}\" ",
            "title": "Example code"
        },
        {
            "location": "/mp/security/providers",
            "text": " See https://tools.ietf.org/html/rfc7617 . Authentication of request When a request is received without the Authorization: basic &#8230;&#8203;. header, a challenge is returned to provide such authentication. When a request is received with the Authorization: basic &#8230;&#8203;. header, the username and password is validated against configured users (and users obtained from custom service if any provided). Subject is created based on the username and roles provided by the user store. Identity propagation When identity propagation is configured, there are several options for identifying username and password to propagate: We propagate the current username and password (inbound request must be authenticated using basic authentication). We use username and password from an explicitly configured property (See EndpointConfig.PROPERTY_OUTBOUND_ID and EndpointConfig.PROPERTY_OUTBOUND_SECRET ) We use username and password associated with an outbound target (see example configuration above) Identity is propagated only if: There is an outbound target configured for the endpoint Or there is an explicitly configured username/password for the current request (through request property) Custom user store Java service loader service io.helidon.security.providers.httpauth.spi.UserStoreService can be implemented to provide users to the provider, such as when validated against an internal database or LDAP server. The user store is defined so you never need the clear text password of the user. Warning on security of HTTP Basic Authentication (or lack thereof) Basic authentication uses base64 encoded username and password and passes it over the network. Base64 is only encoding, not encryption - so anybody that gets hold of the header value can learn the actual username and password of the user. This is a security risk and an attack vector that everybody should be aware of before using HTTP Basic Authentication. We recommend using this approach only for testing and demo purposes. ",
            "title": "How does it work?"
        },
        {
            "location": "/mp/security/providers",
            "text": " HTTP Basic authentication support Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-http-auth&lt;/artifactId&gt; &lt;/dependency&gt; Overview HTTP Basic Authentication provider Type: io.helidon.security.providers.httpauth.HttpBasicAuthProvider <markup lang=\"text\" title=\"Config key\" >http-basic-auth This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthenticationProvider Configuration options Optional configuration options key type default value description optional boolean false Whether authentication is required. By default, request will fail if the authentication cannot be verified. If set to false, request will process and this provider will abstain. outbound OutboundTarget[&#93; &#160; Add a new outbound target to configure identity propagation or explicit username/password. principal-type SubjectType (USER, SERVICE) USER Principal type this provider extracts (and also propagates). realm string helidon Set the realm to use when challenging users. users ConfigUser[&#93; &#160; Set user store to validate users. Removes any other stores added through #addUserStore(SecureUserStore). Example code See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - http-basic-auth: realm: \"helidon\" users: - login: \"john\" password: \"${CLEAR=password}\" roles: [\"admin\"] - login: \"jack\" password: \"password\" roles: [\"user\", \"admin\"] outbound: - name: \"internal-services\" hosts: [\"*.example.org\"] # Propagates current user's identity or identity from request property outbound-token: header: \"X-Internal-Auth\" - name: \"partner-service\" hosts: [\"*.partner.org\"] # Uses this username and password username: \"partner-user-1\" password: \"${CLEAR=password}\" How does it work? See https://tools.ietf.org/html/rfc7617 . Authentication of request When a request is received without the Authorization: basic &#8230;&#8203;. header, a challenge is returned to provide such authentication. When a request is received with the Authorization: basic &#8230;&#8203;. header, the username and password is validated against configured users (and users obtained from custom service if any provided). Subject is created based on the username and roles provided by the user store. Identity propagation When identity propagation is configured, there are several options for identifying username and password to propagate: We propagate the current username and password (inbound request must be authenticated using basic authentication). We use username and password from an explicitly configured property (See EndpointConfig.PROPERTY_OUTBOUND_ID and EndpointConfig.PROPERTY_OUTBOUND_SECRET ) We use username and password associated with an outbound target (see example configuration above) Identity is propagated only if: There is an outbound target configured for the endpoint Or there is an explicitly configured username/password for the current request (through request property) Custom user store Java service loader service io.helidon.security.providers.httpauth.spi.UserStoreService can be implemented to provide users to the provider, such as when validated against an internal database or LDAP server. The user store is defined so you never need the clear text password of the user. Warning on security of HTTP Basic Authentication (or lack thereof) Basic authentication uses base64 encoded username and password and passes it over the network. Base64 is only encoding, not encryption - so anybody that gets hold of the header value can learn the actual username and password of the user. This is a security risk and an attack vector that everybody should be aware of before using HTTP Basic Authentication. We recommend using this approach only for testing and demo purposes. ",
            "title": "HTTP Basic Authentication Provider"
        },
        {
            "location": "/mp/security/providers",
            "text": "<markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-http-auth&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Setup"
        },
        {
            "location": "/mp/security/providers",
            "text": " Http digest authentication security provider Type: io.helidon.security.providers.httpauth.HttpDigestAuthProvider <markup lang=\"text\" title=\"Config key\" >http-digest-auth This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthenticationProvider ",
            "title": "Overview"
        },
        {
            "location": "/mp/security/providers",
            "text": " Optional configuration options key type default value description algorithm Algorithm (MD5) MD5 Digest algorithm to use. nonce-timeout-millis long 86400000 How long will the nonce value be valid. When timed-out, browser will re-request username/password. optional boolean false Whether authentication is required. By default, request will fail if the authentication cannot be verified. If set to false, request will process and this provider will abstain. principal-type SubjectType (USER, SERVICE) USER Principal type this provider extracts (and also propagates). qop Qop (NONE, AUTH) NONE Only AUTH supported. If left empty, uses the legacy approach (older RFC version). AUTH-INT is not supported. realm string Helidon Set the realm to use when challenging users. server-secret string &#160; The nonce is encrypted using this secret - to make sure the nonce we get back was generated by us and to make sure we can safely time-out nonce values. This secret must be the same for all service instances (or all services that want to share the same authentication). Defaults to a random password - e.g. if deployed to multiple servers, the authentication WILL NOT WORK. You MUST provide your own password to work in a distributed environment with non-sticky load balancing. users ConfigUser[&#93; &#160; Set user store to obtain passwords and roles based on logins. ",
            "title": "Configuration options"
        },
        {
            "location": "/mp/security/providers",
            "text": "<markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - http-digest-auth: realm: \"helidon\" server-secret: \"${CLEAR=service-wide-secret-not-known-outside}\" users: - login: \"john\" password: \"${CLEAR=password}\" roles: [\"admin\"] - login: \"jack\" password: \"password\" roles: [\"user\", \"admin\"] ",
            "title": "Example code"
        },
        {
            "location": "/mp/security/providers",
            "text": " See https://tools.ietf.org/html/rfc7616 . Authentication of request When a request is received without the Authorization: digest &#8230;&#8203;. header, a challenge is returned to provide such authentication using WWW-Authenticate header. When a request is received with the Authorization: digest &#8230;&#8203;. header, the request is validated against configured users (and users obtained from custom service if any provided). Subject is created based on the username and roles provided by the user store. Custom user store Java service loader service io.helidon.security.providers.httpauth.spi.UserStoreService can be implemented to provide users to the provider, such as when validated against an internal database or LDAP server. The user store is defined so you never need the clear text password of the user. Note on security of HTTP Digest Authentication These authentication schemes should be obsolete , though they provide a very easy way to test a protected resource. ",
            "title": "How does it work?"
        },
        {
            "location": "/mp/security/providers",
            "text": " HTTP Digest authentication support Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-http-auth&lt;/artifactId&gt; &lt;/dependency&gt; Overview Http digest authentication security provider Type: io.helidon.security.providers.httpauth.HttpDigestAuthProvider <markup lang=\"text\" title=\"Config key\" >http-digest-auth This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthenticationProvider Configuration options Optional configuration options key type default value description algorithm Algorithm (MD5) MD5 Digest algorithm to use. nonce-timeout-millis long 86400000 How long will the nonce value be valid. When timed-out, browser will re-request username/password. optional boolean false Whether authentication is required. By default, request will fail if the authentication cannot be verified. If set to false, request will process and this provider will abstain. principal-type SubjectType (USER, SERVICE) USER Principal type this provider extracts (and also propagates). qop Qop (NONE, AUTH) NONE Only AUTH supported. If left empty, uses the legacy approach (older RFC version). AUTH-INT is not supported. realm string Helidon Set the realm to use when challenging users. server-secret string &#160; The nonce is encrypted using this secret - to make sure the nonce we get back was generated by us and to make sure we can safely time-out nonce values. This secret must be the same for all service instances (or all services that want to share the same authentication). Defaults to a random password - e.g. if deployed to multiple servers, the authentication WILL NOT WORK. You MUST provide your own password to work in a distributed environment with non-sticky load balancing. users ConfigUser[&#93; &#160; Set user store to obtain passwords and roles based on logins. Example code <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - http-digest-auth: realm: \"helidon\" server-secret: \"${CLEAR=service-wide-secret-not-known-outside}\" users: - login: \"john\" password: \"${CLEAR=password}\" roles: [\"admin\"] - login: \"jack\" password: \"password\" roles: [\"user\", \"admin\"] How does it work? See https://tools.ietf.org/html/rfc7616 . Authentication of request When a request is received without the Authorization: digest &#8230;&#8203;. header, a challenge is returned to provide such authentication using WWW-Authenticate header. When a request is received with the Authorization: digest &#8230;&#8203;. header, the request is validated against configured users (and users obtained from custom service if any provided). Subject is created based on the username and roles provided by the user store. Custom user store Java service loader service io.helidon.security.providers.httpauth.spi.UserStoreService can be implemented to provide users to the provider, such as when validated against an internal database or LDAP server. The user store is defined so you never need the clear text password of the user. Note on security of HTTP Digest Authentication These authentication schemes should be obsolete , though they provide a very easy way to test a protected resource. ",
            "title": "HTTP Digest Authentication Provider"
        },
        {
            "location": "/mp/security/providers",
            "text": "<markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-header&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Setup"
        },
        {
            "location": "/mp/security/providers",
            "text": " Security provider that extracts a username (or service name) from a header. Type: io.helidon.security.providers.header.HeaderAtnProvider <markup lang=\"text\" title=\"Config key\" >header-atn This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthenticationProvider ",
            "title": "Overview"
        },
        {
            "location": "/mp/security/providers",
            "text": " Optional configuration options key type default value description atn-token TokenHandler &#160; Token handler to extract username from request. authenticate boolean true Whether to authenticate requests. optional boolean false Whether authentication is required. By default, request will fail if the username cannot be extracted. If set to false, request will process and this provider will abstain. outbound OutboundTarget[&#93; &#160; Configure outbound target for identity propagation. outbound-token TokenHandler &#160; Token handler to create outbound headers to propagate identity. If not defined, #atnTokenHandler will be used. principal-type SubjectType (USER, SERVICE) USER Principal type this provider extracts (and also propagates). propagate boolean false Whether to propagate identity. ",
            "title": "Configuration options"
        },
        {
            "location": "/mp/security/providers",
            "text": "<markup lang=\"yaml\" title=\"Configuration example\" >security: providers: header-atn: atn-token: header: \"X-AUTH-USER\" outbound: - name: \"internal-services\" hosts: [\"*.example.org\"] # propagates the current user or service id using the same header as authentication - name: \"partner-service\" hosts: [\"*.partner.org\"] # propagates an explicit username in a custom header username: \"service-27\" outbound-token: header: \"X-Service-Auth\" ",
            "title": "Example code"
        },
        {
            "location": "/mp/security/providers",
            "text": " This provider inspects a specified request header and extracts the username/service name from it and asserts it as current subject&#8217;s principal. This can be used when we use perimeter authentication (e.g. there is a gateway that takes care of authentication and propagates the user in a header). Identity propagation Identity is propagated only if an outbound target matches the target service. The following options exist when propagating identity: 1. We propagate the current username using the configured header 2. We use username associated with an outbound target (see example configuration above) Caution When using this provider, you must be sure the header cannot be explicitly configured by a user or another service. All requests should go through a gateway that removes this header from inbound traffic, and only configures it for authenticated users/services. Another option is to use this with fully trusted parties (such as services within a single company, on a single protected network not accessible to any users), and of course for testing and demo purposes. ",
            "title": "How does it work?"
        },
        {
            "location": "/mp/security/providers",
            "text": " Asserts user or service identity based on a value of a header. Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-header&lt;/artifactId&gt; &lt;/dependency&gt; Overview Security provider that extracts a username (or service name) from a header. Type: io.helidon.security.providers.header.HeaderAtnProvider <markup lang=\"text\" title=\"Config key\" >header-atn This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthenticationProvider Configuration options Optional configuration options key type default value description atn-token TokenHandler &#160; Token handler to extract username from request. authenticate boolean true Whether to authenticate requests. optional boolean false Whether authentication is required. By default, request will fail if the username cannot be extracted. If set to false, request will process and this provider will abstain. outbound OutboundTarget[&#93; &#160; Configure outbound target for identity propagation. outbound-token TokenHandler &#160; Token handler to create outbound headers to propagate identity. If not defined, #atnTokenHandler will be used. principal-type SubjectType (USER, SERVICE) USER Principal type this provider extracts (and also propagates). propagate boolean false Whether to propagate identity. Example code <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: header-atn: atn-token: header: \"X-AUTH-USER\" outbound: - name: \"internal-services\" hosts: [\"*.example.org\"] # propagates the current user or service id using the same header as authentication - name: \"partner-service\" hosts: [\"*.partner.org\"] # propagates an explicit username in a custom header username: \"service-27\" outbound-token: header: \"X-Service-Auth\" How does it work? This provider inspects a specified request header and extracts the username/service name from it and asserts it as current subject&#8217;s principal. This can be used when we use perimeter authentication (e.g. there is a gateway that takes care of authentication and propagates the user in a header). Identity propagation Identity is propagated only if an outbound target matches the target service. The following options exist when propagating identity: 1. We propagate the current username using the configured header 2. We use username associated with an outbound target (see example configuration above) Caution When using this provider, you must be sure the header cannot be explicitly configured by a user or another service. All requests should go through a gateway that removes this header from inbound traffic, and only configures it for authenticated users/services. Another option is to use this with fully trusted parties (such as services within a single company, on a single protected network not accessible to any users), and of course for testing and demo purposes. ",
            "title": "Header Authentication Provider"
        },
        {
            "location": "/mp/security/providers",
            "text": "<markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-http-sign&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Setup"
        },
        {
            "location": "/mp/security/providers",
            "text": " HTTP header signature provider. Type: io.helidon.security.providers.httpsign.HttpSignProvider <markup lang=\"text\" title=\"Config key\" >http-signatures This type provides the following service implementations: io.helidon.security.spi.AuthenticationProvider ",
            "title": "Overview"
        },
        {
            "location": "/mp/security/providers",
            "text": " Optional configuration options key type default value description backward-compatible-eol boolean false Enable support for Helidon versions before 3.0.0 (exclusive). Until version 3.0.0 (exclusive) there was a trailing end of line added to the signed data. To be able to communicate cross versions, we must configure this when talking to older versions of Helidon. Default value is `false`. In Helidon 2.x, this switch exists as well and the default is `true`, to allow communication between versions as needed. headers HttpSignHeader[&#93; (SIGNATURE, AUTHORIZATION, CUSTOM) &#160; Add a header that is validated on inbound requests. Provider may support more than one header to validate. inbound.keys InboundClientDefinition[&#93; &#160; Add inbound configuration. This is used to validate signature and authenticate the party. The same can be done through configuration: &lt;pre&gt; { name = \"http-signatures\" class = \"HttpSignProvider\" http-signatures { inbound { # This configures the InboundClientDefinition keys: [ { key-id = \"service1\" hmac.secret = \"${CLEAR=password}\" }] } } } &lt;/pre&gt; optional boolean true Set whether the signature is optional. If set to true (default), this provider will SecurityResponse.SecurityStatus#ABSTAIN from this request if signature is not present. If set to false, this provider will SecurityResponse.SecurityStatus#FAILURE fail if signature is not present. outbound OutboundConfig &#160; Add outbound targets to this builder. The targets are used to chose what to do for outbound communication. The targets should have OutboundTargetDefinition attached through OutboundTarget.Builder#customObject(Class, Object) to tell us how to sign the request. The same can be done through configuration: &lt;pre&gt; { name = \"http-signatures\" class = \"HttpSignProvider\" http-signatures { targets: [ { name = \"service2\" hosts = [\"localhost\"] paths = [\"/service2/.*\"] # This configures the OutboundTargetDefinition signature { key-id = \"service1\" hmac.secret = \"${CLEAR=password}\" } }] } } &lt;/pre&gt; realm string helidon Realm to use for challenging inbound requests that do not have \"Authorization\" header in case header is HttpSignHeader#AUTHORIZATION and singatures are not optional. sign-headers HeadersConfig[&#93; &#160; Override the default inbound required headers (e.g. headers that MUST be signed and headers that MUST be signed IF present). Defaults: get, head, delete methods: date, (request-target), host are mandatory; authorization if present (unless we are creating/validating the HttpSignHeader#AUTHORIZATION ourselves put, post: same as above, with addition of: content-length, content-type and digest if present for other methods: date, (request-target) Note that this provider DOES NOT validate the \"Digest\" HTTP header, only the signature. ",
            "title": "Configuration options"
        },
        {
            "location": "/mp/security/providers",
            "text": " See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - http-signatures: inbound: keys: - key-id: \"service1-hmac\" principal-name: \"Service1 - HMAC signature\" hmac.secret: \"${CLEAR=somePasswordForHmacShouldBeEncrypted}\" - key-id: \"service1-rsa\" principal-name: \"Service1 - RSA signature\" public-key: keystore: resource.path: \"src/main/resources/keystore.p12\" passphrase: \"password\" cert.alias: \"service_cert\" outbound: - name: \"service2-hmac\" hosts: [\"localhost\"] paths: [\"/service2\"] signature: key-id: \"service1-hmac\" hmac.secret: \"${CLEAR=somePasswordForHmacShouldBeEncrypted}\" - name: \"service2-rsa\" hosts: [\"localhost\"] paths: [\"/service2-rsa.*\"] signature: key-id: \"service1-rsa\" private-key: keystore: resource.path: \"src/main/resources/keystore.p12\" passphrase: \"password\" key.alias: \"myPrivateKey\" ",
            "title": "Example code"
        },
        {
            "location": "/mp/security/providers",
            "text": " standard: based on https://tools.ietf.org/html/draft-cavage-http-signatures-03 key-id: an arbitrary string used to locate signature configuration - when a request is received the provider locates validation configuration based on this id (e.g. HMAC shared secret or RSA public key). Commonly used meanings are: key fingerprint (RSA); API Key ",
            "title": "Signature basics"
        },
        {
            "location": "/mp/security/providers",
            "text": " Inbound Signatures We act as a server and another party is calling us with a signed HTTP request. We validate the signature and assume identity of the caller. Outbound Signatures We act as a client and we sign our outgoing requests. If there is a matching outbound target specified in configuration, its configuration will be applied for signing the outgoing request, otherwise there is no signature added ",
            "title": "How does it work?"
        },
        {
            "location": "/mp/security/providers",
            "text": " Support for HTTP Signatures. Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-http-sign&lt;/artifactId&gt; &lt;/dependency&gt; Overview HTTP header signature provider. Type: io.helidon.security.providers.httpsign.HttpSignProvider <markup lang=\"text\" title=\"Config key\" >http-signatures This type provides the following service implementations: io.helidon.security.spi.AuthenticationProvider Configuration options Optional configuration options key type default value description backward-compatible-eol boolean false Enable support for Helidon versions before 3.0.0 (exclusive). Until version 3.0.0 (exclusive) there was a trailing end of line added to the signed data. To be able to communicate cross versions, we must configure this when talking to older versions of Helidon. Default value is `false`. In Helidon 2.x, this switch exists as well and the default is `true`, to allow communication between versions as needed. headers HttpSignHeader[&#93; (SIGNATURE, AUTHORIZATION, CUSTOM) &#160; Add a header that is validated on inbound requests. Provider may support more than one header to validate. inbound.keys InboundClientDefinition[&#93; &#160; Add inbound configuration. This is used to validate signature and authenticate the party. The same can be done through configuration: &lt;pre&gt; { name = \"http-signatures\" class = \"HttpSignProvider\" http-signatures { inbound { # This configures the InboundClientDefinition keys: [ { key-id = \"service1\" hmac.secret = \"${CLEAR=password}\" }] } } } &lt;/pre&gt; optional boolean true Set whether the signature is optional. If set to true (default), this provider will SecurityResponse.SecurityStatus#ABSTAIN from this request if signature is not present. If set to false, this provider will SecurityResponse.SecurityStatus#FAILURE fail if signature is not present. outbound OutboundConfig &#160; Add outbound targets to this builder. The targets are used to chose what to do for outbound communication. The targets should have OutboundTargetDefinition attached through OutboundTarget.Builder#customObject(Class, Object) to tell us how to sign the request. The same can be done through configuration: &lt;pre&gt; { name = \"http-signatures\" class = \"HttpSignProvider\" http-signatures { targets: [ { name = \"service2\" hosts = [\"localhost\"] paths = [\"/service2/.*\"] # This configures the OutboundTargetDefinition signature { key-id = \"service1\" hmac.secret = \"${CLEAR=password}\" } }] } } &lt;/pre&gt; realm string helidon Realm to use for challenging inbound requests that do not have \"Authorization\" header in case header is HttpSignHeader#AUTHORIZATION and singatures are not optional. sign-headers HeadersConfig[&#93; &#160; Override the default inbound required headers (e.g. headers that MUST be signed and headers that MUST be signed IF present). Defaults: get, head, delete methods: date, (request-target), host are mandatory; authorization if present (unless we are creating/validating the HttpSignHeader#AUTHORIZATION ourselves put, post: same as above, with addition of: content-length, content-type and digest if present for other methods: date, (request-target) Note that this provider DOES NOT validate the \"Digest\" HTTP header, only the signature. Example code See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - http-signatures: inbound: keys: - key-id: \"service1-hmac\" principal-name: \"Service1 - HMAC signature\" hmac.secret: \"${CLEAR=somePasswordForHmacShouldBeEncrypted}\" - key-id: \"service1-rsa\" principal-name: \"Service1 - RSA signature\" public-key: keystore: resource.path: \"src/main/resources/keystore.p12\" passphrase: \"password\" cert.alias: \"service_cert\" outbound: - name: \"service2-hmac\" hosts: [\"localhost\"] paths: [\"/service2\"] signature: key-id: \"service1-hmac\" hmac.secret: \"${CLEAR=somePasswordForHmacShouldBeEncrypted}\" - name: \"service2-rsa\" hosts: [\"localhost\"] paths: [\"/service2-rsa.*\"] signature: key-id: \"service1-rsa\" private-key: keystore: resource.path: \"src/main/resources/keystore.p12\" passphrase: \"password\" key.alias: \"myPrivateKey\" Signature basics standard: based on https://tools.ietf.org/html/draft-cavage-http-signatures-03 key-id: an arbitrary string used to locate signature configuration - when a request is received the provider locates validation configuration based on this id (e.g. HMAC shared secret or RSA public key). Commonly used meanings are: key fingerprint (RSA); API Key How does it work? Inbound Signatures We act as a server and another party is calling us with a signed HTTP request. We validate the signature and assume identity of the caller. Outbound Signatures We act as a client and we sign our outgoing requests. If there is a matching outbound target specified in configuration, its configuration will be applied for signing the outgoing request, otherwise there is no signature added ",
            "title": "HTTP Signatures Provider"
        },
        {
            "location": "/mp/security/providers",
            "text": "<markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-idcs-mapper&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Setup"
        },
        {
            "location": "/mp/security/providers",
            "text": " IDCS role mapping provider Type: io.helidon.security.providers.idcs.mapper.IdcsRoleMapperProvider <markup lang=\"text\" title=\"Config key\" >idcs-role-mapper This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.SubjectMappingProvider ",
            "title": "Single-tenant IDCS Role Mapper"
        },
        {
            "location": "/mp/security/providers",
            "text": " Optional configuration options key type default value description cache-config EvictableCache &#160; Use explicit io.helidon.security.providers.common.EvictableCache for role caching. default-idcs-subject-type string user Configure subject type to use when requesting roles from IDCS. Can be either #IDCS_SUBJECT_TYPE_USER or #IDCS_SUBJECT_TYPE_CLIENT. Defaults to #IDCS_SUBJECT_TYPE_USER. oidc-config OidcConfig &#160; Use explicit io.helidon.security.providers.oidc.common.OidcConfig instance, e.g. when using it also for OIDC provider. subject-types SubjectType[&#93; (USER, SERVICE) USER Add a supported subject type. If none added, io.helidon.security.SubjectType#USER is used. If any added, only the ones added will be used (e.g. if you want to use both io.helidon.security.SubjectType#USER and io.helidon.security.SubjectType#SERVICE, both need to be added. ",
            "title": "Configuration options"
        },
        {
            "location": "/mp/security/providers",
            "text": " Multitenant IDCS role mapping provider Type: io.helidon.security.providers.idcs.mapper.IdcsMtRoleMapperProvider <markup lang=\"text\" title=\"Config key\" >idcs-role-mapper This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.SubjectMappingProvider ",
            "title": "Multi-tenant IDCS Role Mapper"
        },
        {
            "location": "/mp/security/providers",
            "text": " Optional configuration options key type default value description cache-config EvictableCache &#160; Use explicit io.helidon.security.providers.common.EvictableCache for role caching. default-idcs-subject-type string user Configure subject type to use when requesting roles from IDCS. Can be either #IDCS_SUBJECT_TYPE_USER or #IDCS_SUBJECT_TYPE_CLIENT. Defaults to #IDCS_SUBJECT_TYPE_USER. idcs-app-name-handler TokenHandler &#160; Configure token handler for IDCS Application name. By default the header IdcsMtRoleMapperProvider#IDCS_APP_HEADER is used. idcs-tenant-handler TokenHandler &#160; Configure token handler for IDCS Tenant ID. By default the header IdcsMtRoleMapperProvider#IDCS_TENANT_HEADER is used. oidc-config OidcConfig &#160; Use explicit io.helidon.security.providers.oidc.common.OidcConfig instance, e.g. when using it also for OIDC provider. subject-types SubjectType[&#93; (USER, SERVICE) USER Add a supported subject type. If none added, io.helidon.security.SubjectType#USER is used. If any added, only the ones added will be used (e.g. if you want to use both io.helidon.security.SubjectType#USER and io.helidon.security.SubjectType#SERVICE, both need to be added. ",
            "title": "Configuration options"
        },
        {
            "location": "/mp/security/providers",
            "text": " See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - idcs-role-mapper: multitenant: false oidc-config: client-id: \"client-id\" client-secret: \"client-secret\" identity-uri: \"IDCS identity server address\" ",
            "title": "Example code"
        },
        {
            "location": "/mp/security/providers",
            "text": " The provider asks the IDCS server to provide list of roles for the currently authenticated user. The result is cached for a certain period of time (see cache-config above). ",
            "title": "How does it work?"
        },
        {
            "location": "/mp/security/providers",
            "text": " A role mapper to retrieve roles from Oracle IDCS. Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-idcs-mapper&lt;/artifactId&gt; &lt;/dependency&gt; Single-tenant IDCS Role Mapper IDCS role mapping provider Type: io.helidon.security.providers.idcs.mapper.IdcsRoleMapperProvider <markup lang=\"text\" title=\"Config key\" >idcs-role-mapper This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.SubjectMappingProvider Configuration options Optional configuration options key type default value description cache-config EvictableCache &#160; Use explicit io.helidon.security.providers.common.EvictableCache for role caching. default-idcs-subject-type string user Configure subject type to use when requesting roles from IDCS. Can be either #IDCS_SUBJECT_TYPE_USER or #IDCS_SUBJECT_TYPE_CLIENT. Defaults to #IDCS_SUBJECT_TYPE_USER. oidc-config OidcConfig &#160; Use explicit io.helidon.security.providers.oidc.common.OidcConfig instance, e.g. when using it also for OIDC provider. subject-types SubjectType[&#93; (USER, SERVICE) USER Add a supported subject type. If none added, io.helidon.security.SubjectType#USER is used. If any added, only the ones added will be used (e.g. if you want to use both io.helidon.security.SubjectType#USER and io.helidon.security.SubjectType#SERVICE, both need to be added. Multi-tenant IDCS Role Mapper Multitenant IDCS role mapping provider Type: io.helidon.security.providers.idcs.mapper.IdcsMtRoleMapperProvider <markup lang=\"text\" title=\"Config key\" >idcs-role-mapper This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.SubjectMappingProvider Configuration options Optional configuration options key type default value description cache-config EvictableCache &#160; Use explicit io.helidon.security.providers.common.EvictableCache for role caching. default-idcs-subject-type string user Configure subject type to use when requesting roles from IDCS. Can be either #IDCS_SUBJECT_TYPE_USER or #IDCS_SUBJECT_TYPE_CLIENT. Defaults to #IDCS_SUBJECT_TYPE_USER. idcs-app-name-handler TokenHandler &#160; Configure token handler for IDCS Application name. By default the header IdcsMtRoleMapperProvider#IDCS_APP_HEADER is used. idcs-tenant-handler TokenHandler &#160; Configure token handler for IDCS Tenant ID. By default the header IdcsMtRoleMapperProvider#IDCS_TENANT_HEADER is used. oidc-config OidcConfig &#160; Use explicit io.helidon.security.providers.oidc.common.OidcConfig instance, e.g. when using it also for OIDC provider. subject-types SubjectType[&#93; (USER, SERVICE) USER Add a supported subject type. If none added, io.helidon.security.SubjectType#USER is used. If any added, only the ones added will be used (e.g. if you want to use both io.helidon.security.SubjectType#USER and io.helidon.security.SubjectType#SERVICE, both need to be added. Example code See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - idcs-role-mapper: multitenant: false oidc-config: client-id: \"client-id\" client-secret: \"client-secret\" identity-uri: \"IDCS identity server address\" How does it work? The provider asks the IDCS server to provide list of roles for the currently authenticated user. The result is cached for a certain period of time (see cache-config above). ",
            "title": "IDCS Role Mapper"
        },
        {
            "location": "/mp/security/providers",
            "text": "<markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-abac&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Setup"
        },
        {
            "location": "/mp/security/providers",
            "text": " Attribute Based Access Control provider Type: io.helidon.security.providers.abac.AbacProvider <markup lang=\"text\" title=\"Config key\" >abac This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthorizationProvider ",
            "title": "Overview"
        },
        {
            "location": "/mp/security/providers",
            "text": " Optional configuration options key type default value description fail-if-none-validated boolean true Whether to fail if NONE of the attributes is validated. fail-on-unvalidated boolean true Whether to fail if any attribute is left unvalidated. ",
            "title": "Configuration options"
        },
        {
            "location": "/mp/security/providers",
            "text": " See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - abac: ",
            "title": "Example code"
        },
        {
            "location": "/mp/security/providers",
            "text": " The following table shows all configuration options of the provider and their default values key default value description fail-on-unvalidated true \"Unvalidated\" means: an attribute is defined, but there is no validator available for it fail-if-none-validated true \"None validated\" means: there was not a single attribute that was validated ",
            "title": "Configuration options"
        },
        {
            "location": "/mp/security/providers",
            "text": " ABAC uses available validators and validates them against attributes of the authenticated user. Combinations of fail-on-unvalidated and fail-if-none-validated : true &amp; true : Will fail if any attribute is not validated and if any has failed validation false &amp; true : Will fail if there is one or more attributes present and NONE of them is validated or if any has failed validation, Will NOT fail if there is at least one validated attribute and any number of not validated attributes (and NONE failed) false &amp; false : Will fail if there is any attribute that failed validation, Will NOT fail if there are no failed validation or if there are NONE validated Any attribute of the following objects can be used: environment (such as time of request) - e.g. env.time.year subject (user) - e.g. subject.principal.id subject (service) - e.g. service.principal.id object (must be explicitly invoked by developer in code, as object cannot be automatically added to security context) - e.g. object.owner This provider checks that all defined ABAC validators are validated. If there is a definition for a validator that is not checked, the request is denied (depending on configuration as mentioned above). ABAC provider also allows an object to be used in authorization process, such as when evaluating if an object&#8217;s owner is the current user. The following example uses the Expression language validator to demonstrate the point in a JAX-RS resource: <markup lang=\"java\" title=\"Example of using an object\" >@Authenticated @Path(\"/abac\") public class AbacResource { @GET @Authorized(explicit = true) @PolicyStatement(\"${env.time.year &gt;= 2017 &amp;&amp; object.owner == subject.principal.id}\") public Response process(@Context SecurityContext context) { // probably looked up from a database SomeResource res = new SomeResource(\"user\"); AuthorizationResponse atzResponse = context.authorize(res); if (atzResponse.isPermitted()) { //do the update return Response.ok().entity(\"fine, sir\").build(); } else { return Response.status(Response.Status.FORBIDDEN) .entity(atzResponse.description().orElse(\"Access not granted\")) .build(); } } } The following validators are implemented: Roles Scopes EL Policy ",
            "title": "How does it work?"
        },
        {
            "location": "/mp/security/providers",
            "text": " When using sub-resource locators in JAX-RS, the roles allowed are collected from each \"level\" of execution: - Application class annotations - Resource class annotations + resource method annotations - Sub-resource class annotations + sub-resource method annotations - Sub-resource class annotations + sub-resource method annotations (for every sub-resource on the path) The RolesAllowed or Roles annotation to be used is the last one in the path as defined above. Example 1: There is a RolesAllowed(\"admin\") defined on a sub-resource locator resource class. In this case the required role is admin . Example 2: There is a RolesAllowed(\"admin\") defined on a sub-resource locator resource class and a RolesAllowed(\"user\") defined on the method of the sub-resource that provides the response. In this case the required role is user . ",
            "title": "Interaction with JAX-RS sub-resource locators"
        },
        {
            "location": "/mp/security/providers",
            "text": " Checks whether user/service is in either of the required role(s). Configuration Key: role-validator Annotations: @RolesAllowed , @RoleValidator.Roles <markup lang=\"yaml\" title=\"Configuration example for WebServer \" >security: web-server.paths: - path: \"/user[/{*}]\" roles-allowed: [\"user\"] <markup lang=\"java\" title=\"JAX-RS example\" >@RolesAllowed(\"user\") @RoleValidator.Roles(value = \"service_role\", subjectType = SubjectType.SERVICE) @Authenticated @Path(\"/abac\") public class AbacResource { } Interaction with JAX-RS sub-resource locators When using sub-resource locators in JAX-RS, the roles allowed are collected from each \"level\" of execution: - Application class annotations - Resource class annotations + resource method annotations - Sub-resource class annotations + sub-resource method annotations - Sub-resource class annotations + sub-resource method annotations (for every sub-resource on the path) The RolesAllowed or Roles annotation to be used is the last one in the path as defined above. Example 1: There is a RolesAllowed(\"admin\") defined on a sub-resource locator resource class. In this case the required role is admin . Example 2: There is a RolesAllowed(\"admin\") defined on a sub-resource locator resource class and a RolesAllowed(\"user\") defined on the method of the sub-resource that provides the response. In this case the required role is user . ",
            "title": "Role Validator"
        },
        {
            "location": "/mp/security/providers",
            "text": " Checks whether user has all the required scopes. Configuration Key: scope-validator Annotations: @Scope <markup lang=\"yaml\" title=\"Configuration example for WebServer \" >security: web-server.paths: - path: \"/user[/{*}]\" abac.scopes: [\"calendar_read\", \"calendar_edit\"] <markup lang=\"java\" title=\"JAX-RS example\" >@Scope(\"calendar_read\") @Scope(\"calendar_edit\") @Authenticated @Path(\"/abac\") public class AbacResource { } ",
            "title": "Scope Validator"
        },
        {
            "location": "/mp/security/providers",
            "text": " Policy executor using Java EE policy expression language (EL) Configuration Key: policy-javax-el Annotations: @PolicyStatement Example of a policy statement: ${env.time.year &gt;= 2017} <markup lang=\"yaml\" title=\"Configuration example for WebServer \" >security: web-server.paths: - path: \"/user[/{*}]\" policy: statement: \"hasScopes('calendar_read','calendar_edit') AND timeOfDayBetween('8:15', '17:30')\" <markup lang=\"java\" title=\"JAX-RS example\" >@PolicyStatement(\"${env.time.year &gt;= 2017}\") @Authenticated @Path(\"/abac\") public class AbacResource { } ",
            "title": "Expression Language Policy Validator"
        },
        {
            "location": "/mp/security/providers",
            "text": " Attribute based access control authorization provider. Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-abac&lt;/artifactId&gt; &lt;/dependency&gt; Overview Attribute Based Access Control provider Type: io.helidon.security.providers.abac.AbacProvider <markup lang=\"text\" title=\"Config key\" >abac This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthorizationProvider Configuration options Optional configuration options key type default value description fail-if-none-validated boolean true Whether to fail if NONE of the attributes is validated. fail-on-unvalidated boolean true Whether to fail if any attribute is left unvalidated. Example code See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - abac: Configuration options The following table shows all configuration options of the provider and their default values key default value description fail-on-unvalidated true \"Unvalidated\" means: an attribute is defined, but there is no validator available for it fail-if-none-validated true \"None validated\" means: there was not a single attribute that was validated How does it work? ABAC uses available validators and validates them against attributes of the authenticated user. Combinations of fail-on-unvalidated and fail-if-none-validated : true &amp; true : Will fail if any attribute is not validated and if any has failed validation false &amp; true : Will fail if there is one or more attributes present and NONE of them is validated or if any has failed validation, Will NOT fail if there is at least one validated attribute and any number of not validated attributes (and NONE failed) false &amp; false : Will fail if there is any attribute that failed validation, Will NOT fail if there are no failed validation or if there are NONE validated Any attribute of the following objects can be used: environment (such as time of request) - e.g. env.time.year subject (user) - e.g. subject.principal.id subject (service) - e.g. service.principal.id object (must be explicitly invoked by developer in code, as object cannot be automatically added to security context) - e.g. object.owner This provider checks that all defined ABAC validators are validated. If there is a definition for a validator that is not checked, the request is denied (depending on configuration as mentioned above). ABAC provider also allows an object to be used in authorization process, such as when evaluating if an object&#8217;s owner is the current user. The following example uses the Expression language validator to demonstrate the point in a JAX-RS resource: <markup lang=\"java\" title=\"Example of using an object\" >@Authenticated @Path(\"/abac\") public class AbacResource { @GET @Authorized(explicit = true) @PolicyStatement(\"${env.time.year &gt;= 2017 &amp;&amp; object.owner == subject.principal.id}\") public Response process(@Context SecurityContext context) { // probably looked up from a database SomeResource res = new SomeResource(\"user\"); AuthorizationResponse atzResponse = context.authorize(res); if (atzResponse.isPermitted()) { //do the update return Response.ok().entity(\"fine, sir\").build(); } else { return Response.status(Response.Status.FORBIDDEN) .entity(atzResponse.description().orElse(\"Access not granted\")) .build(); } } } The following validators are implemented: Roles Scopes EL Policy Role Validator Checks whether user/service is in either of the required role(s). Configuration Key: role-validator Annotations: @RolesAllowed , @RoleValidator.Roles <markup lang=\"yaml\" title=\"Configuration example for WebServer \" >security: web-server.paths: - path: \"/user[/{*}]\" roles-allowed: [\"user\"] <markup lang=\"java\" title=\"JAX-RS example\" >@RolesAllowed(\"user\") @RoleValidator.Roles(value = \"service_role\", subjectType = SubjectType.SERVICE) @Authenticated @Path(\"/abac\") public class AbacResource { } Interaction with JAX-RS sub-resource locators When using sub-resource locators in JAX-RS, the roles allowed are collected from each \"level\" of execution: - Application class annotations - Resource class annotations + resource method annotations - Sub-resource class annotations + sub-resource method annotations - Sub-resource class annotations + sub-resource method annotations (for every sub-resource on the path) The RolesAllowed or Roles annotation to be used is the last one in the path as defined above. Example 1: There is a RolesAllowed(\"admin\") defined on a sub-resource locator resource class. In this case the required role is admin . Example 2: There is a RolesAllowed(\"admin\") defined on a sub-resource locator resource class and a RolesAllowed(\"user\") defined on the method of the sub-resource that provides the response. In this case the required role is user . Scope Validator Checks whether user has all the required scopes. Configuration Key: scope-validator Annotations: @Scope <markup lang=\"yaml\" title=\"Configuration example for WebServer \" >security: web-server.paths: - path: \"/user[/{*}]\" abac.scopes: [\"calendar_read\", \"calendar_edit\"] <markup lang=\"java\" title=\"JAX-RS example\" >@Scope(\"calendar_read\") @Scope(\"calendar_edit\") @Authenticated @Path(\"/abac\") public class AbacResource { } Expression Language Policy Validator Policy executor using Java EE policy expression language (EL) Configuration Key: policy-javax-el Annotations: @PolicyStatement Example of a policy statement: ${env.time.year &gt;= 2017} <markup lang=\"yaml\" title=\"Configuration example for WebServer \" >security: web-server.paths: - path: \"/user[/{*}]\" policy: statement: \"hasScopes('calendar_read','calendar_edit') AND timeOfDayBetween('8:15', '17:30')\" <markup lang=\"java\" title=\"JAX-RS example\" >@PolicyStatement(\"${env.time.year &gt;= 2017}\") @Authenticated @Path(\"/abac\") public class AbacResource { } ",
            "title": "ABAC Provider"
        },
        {
            "location": "/mp/security/providers",
            "text": "<markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-google-login&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Setup"
        },
        {
            "location": "/mp/security/providers",
            "text": " Google Authentication provider Type: io.helidon.security.providers.google.login.GoogleTokenProvider <markup lang=\"text\" title=\"Config key\" >google-login This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthenticationProvider ",
            "title": "Overview"
        },
        {
            "location": "/mp/security/providers",
            "text": " Optional configuration options key type default value description client-id string &#160; Google application client id, to validate that the token was generated by Google for us. optional boolean false If set to true, this provider will return io.helidon.security.SecurityResponse.SecurityStatus#ABSTAIN instead of failing in case of invalid request. outbound OutboundConfig &#160; Outbound configuration - a set of outbound targets that will have the token propagated. proxy-host string &#160; Set proxy host when talking to Google. proxy-port int 80 Set proxy port when talking to Google. realm string helidon Set the authentication realm to build challenge, defaults to \"helidon\". token TokenHandler &#x60;Authorization&#x60; header with &#x60;bearer&#x60; prefix Token provider to extract Google access token from request, defaults to \"Authorization\" header with a \"bearer \" prefix. ",
            "title": "Configuration options"
        },
        {
            "location": "/mp/security/providers",
            "text": " See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - provider: client-id: \"Google client id\" ",
            "title": "Example code"
        },
        {
            "location": "/mp/security/providers",
            "text": " We expect to receive a token (with sufficient scopes) from the inbound request, such as when using the Google login button on a page. The page has access to the token in javascript and can send it to backend with every request in a header field ( Authorization with `bearer ` prefix is assumed by default). Once we receive the token in Helidon, we parse it and: Validate if it timed out locally Return a cached response (see EvictableCache with default values) Otherwise verify using Google API - GoogleIdTokenVerifier We build a subject from the Google token with the following attributes filled (if in token): userId email name emailVerified locale family_name given_name picture (URL) Outbound security The token will be propagated to outbound calls if an outbound target exists that matches the invoked endpoint (see outbound configuration above). ",
            "title": "How does it work?"
        },
        {
            "location": "/mp/security/providers",
            "text": " Authenticates a token from request against Google identity provider Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-google-login&lt;/artifactId&gt; &lt;/dependency&gt; Overview Google Authentication provider Type: io.helidon.security.providers.google.login.GoogleTokenProvider <markup lang=\"text\" title=\"Config key\" >google-login This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthenticationProvider Configuration options Optional configuration options key type default value description client-id string &#160; Google application client id, to validate that the token was generated by Google for us. optional boolean false If set to true, this provider will return io.helidon.security.SecurityResponse.SecurityStatus#ABSTAIN instead of failing in case of invalid request. outbound OutboundConfig &#160; Outbound configuration - a set of outbound targets that will have the token propagated. proxy-host string &#160; Set proxy host when talking to Google. proxy-port int 80 Set proxy port when talking to Google. realm string helidon Set the authentication realm to build challenge, defaults to \"helidon\". token TokenHandler &#x60;Authorization&#x60; header with &#x60;bearer&#x60; prefix Token provider to extract Google access token from request, defaults to \"Authorization\" header with a \"bearer \" prefix. Example code See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - provider: client-id: \"Google client id\" How does it work? We expect to receive a token (with sufficient scopes) from the inbound request, such as when using the Google login button on a page. The page has access to the token in javascript and can send it to backend with every request in a header field ( Authorization with `bearer ` prefix is assumed by default). Once we receive the token in Helidon, we parse it and: Validate if it timed out locally Return a cached response (see EvictableCache with default values) Otherwise verify using Google API - GoogleIdTokenVerifier We build a subject from the Google token with the following attributes filled (if in token): userId email name emailVerified locale family_name given_name picture (URL) Outbound security The token will be propagated to outbound calls if an outbound target exists that matches the invoked endpoint (see outbound configuration above). ",
            "title": "Google Login Provider"
        },
        {
            "location": "/mp/security/providers",
            "text": "<markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-jwt&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Setup"
        },
        {
            "location": "/mp/security/providers",
            "text": " JWT authentication provider Type: io.helidon.security.providers.jwt.JwtProvider <markup lang=\"text\" title=\"Config key\" >jwt This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthenticationProvider ",
            "title": "Overview"
        },
        {
            "location": "/mp/security/providers",
            "text": " Optional configuration options key type default value description allow-impersonation boolean false Whether to allow impersonation by explicitly overriding username from outbound requests using io.helidon.security.EndpointConfig#PROPERTY_OUTBOUND_ID property. By default this is not allowed and identity can only be propagated. allow-unsigned boolean false Configure support for unsigned JWT. If this is set to true any JWT that has algorithm set to none and no kid defined will be accepted. Note that this has serious security impact - if JWT can be sent from a third party, this allows the third party to send ANY JWT and it would be accpted as valid. atn-token.handler TokenHandler &#160; Token handler to extract username from request. atn-token.jwk.resource Resource &#160; JWK resource used to verify JWTs created by other parties. atn-token.jwt-audience string &#160; Audience expected in inbound JWTs. atn-token.verify-signature boolean true Configure whether to verify signatures. Signatures verification is enabled by default. You can configure the provider not to verify signatures. &lt;b&gt;Make sure your service is properly secured on network level and only accessible from a secure endpoint that provides the JWTs when signature verification is disabled. If signature verification is disabled, this service will accept &lt;i&gt;ANY&lt;/i&gt; JWT&lt;/b&gt; authenticate boolean true Whether to authenticate requests. optional boolean false Whether authentication is required. By default, request will fail if the username cannot be extracted. If set to false, request will process and this provider will abstain. principal-type SubjectType (USER, SERVICE) USER Principal type this provider extracts (and also propagates). propagate boolean true Whether to propagate identity. sign-token OutboundConfig &#160; Configuration of outbound rules. sign-token.jwk.resource Resource &#160; JWK resource used to sign JWTs created by us. sign-token.jwt-issuer string &#160; Issuer used to create new JWTs. use-jwt-groups boolean true Claim groups from JWT will be used to automatically add groups to current subject (may be used with jakarta.annotation.security.RolesAllowed annotation). ",
            "title": "Configuration options"
        },
        {
            "location": "/mp/security/providers",
            "text": " See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - provider: atn-token: jwk.resource.resource-path: \"verifying-jwk.json\" jwt-audience: \"http://my.service\" sign-token: jwk.resource.resource-path: \"signing-jwk.json\" jwt-issuer: \"http://my.server/identity\" outbound: - name: \"propagate-token\" hosts: [\"*.internal.org\"] - name: \"generate-token\" hosts: [\"1.partner-service\"] jwk-kid: \"partner-1\" jwt-kid: \"helidon\" jwt-audience: \"http://1.partner-service\" ",
            "title": "Example code"
        },
        {
            "location": "/mp/security/providers",
            "text": " JSON Web Token (JWT) provider has support for authentication and outbound security. Authentication is based on validating the token (signature, valid before etc.) and on asserting the subject of the JWT subject claim. For outbound, we support either token propagation (e.g. the token from request is propagated further) or support for generating a brand new token based on configuration of this provider. ",
            "title": "How does it work?"
        },
        {
            "location": "/mp/security/providers",
            "text": " JWT token authentication and outbound security provider. Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-jwt&lt;/artifactId&gt; &lt;/dependency&gt; Overview JWT authentication provider Type: io.helidon.security.providers.jwt.JwtProvider <markup lang=\"text\" title=\"Config key\" >jwt This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthenticationProvider Configuration options Optional configuration options key type default value description allow-impersonation boolean false Whether to allow impersonation by explicitly overriding username from outbound requests using io.helidon.security.EndpointConfig#PROPERTY_OUTBOUND_ID property. By default this is not allowed and identity can only be propagated. allow-unsigned boolean false Configure support for unsigned JWT. If this is set to true any JWT that has algorithm set to none and no kid defined will be accepted. Note that this has serious security impact - if JWT can be sent from a third party, this allows the third party to send ANY JWT and it would be accpted as valid. atn-token.handler TokenHandler &#160; Token handler to extract username from request. atn-token.jwk.resource Resource &#160; JWK resource used to verify JWTs created by other parties. atn-token.jwt-audience string &#160; Audience expected in inbound JWTs. atn-token.verify-signature boolean true Configure whether to verify signatures. Signatures verification is enabled by default. You can configure the provider not to verify signatures. &lt;b&gt;Make sure your service is properly secured on network level and only accessible from a secure endpoint that provides the JWTs when signature verification is disabled. If signature verification is disabled, this service will accept &lt;i&gt;ANY&lt;/i&gt; JWT&lt;/b&gt; authenticate boolean true Whether to authenticate requests. optional boolean false Whether authentication is required. By default, request will fail if the username cannot be extracted. If set to false, request will process and this provider will abstain. principal-type SubjectType (USER, SERVICE) USER Principal type this provider extracts (and also propagates). propagate boolean true Whether to propagate identity. sign-token OutboundConfig &#160; Configuration of outbound rules. sign-token.jwk.resource Resource &#160; JWK resource used to sign JWTs created by us. sign-token.jwt-issuer string &#160; Issuer used to create new JWTs. use-jwt-groups boolean true Claim groups from JWT will be used to automatically add groups to current subject (may be used with jakarta.annotation.security.RolesAllowed annotation). Example code See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - provider: atn-token: jwk.resource.resource-path: \"verifying-jwk.json\" jwt-audience: \"http://my.service\" sign-token: jwk.resource.resource-path: \"signing-jwk.json\" jwt-issuer: \"http://my.server/identity\" outbound: - name: \"propagate-token\" hosts: [\"*.internal.org\"] - name: \"generate-token\" hosts: [\"1.partner-service\"] jwk-kid: \"partner-1\" jwt-kid: \"helidon\" jwt-audience: \"http://1.partner-service\" How does it work? JSON Web Token (JWT) provider has support for authentication and outbound security. Authentication is based on validating the token (signature, valid before etc.) and on asserting the subject of the JWT subject claim. For outbound, we support either token propagation (e.g. the token from request is propagated further) or support for generating a brand new token based on configuration of this provider. ",
            "title": "JWT Provider"
        },
        {
            "location": "/mp/security/providers",
            "text": " As an experimental feature, you can set up cross-origin handling for the redirect and logout endpoints in an optional cors block inside the oidc configuration. The table below lists the configuration keys that identify the CORS characteristics. include::[tag=cors-config-table] The following example of basic cross-origin configuration limits cross-origin resource sharing for PUT and DELETE operations to only foo.com and there.com : <markup lang=\"yaml\" >allow-origins: [\"http://foo.com\", \"http://there.com\"] allow-methods: [\"PUT\", \"DELETE\"] HTTP Basic Authentication Provider HTTP Basic authentication support Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-http-auth&lt;/artifactId&gt; &lt;/dependency&gt; Overview HTTP Basic Authentication provider Type: io.helidon.security.providers.httpauth.HttpBasicAuthProvider <markup lang=\"text\" title=\"Config key\" >http-basic-auth This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthenticationProvider Configuration options Optional configuration options key type default value description optional boolean false Whether authentication is required. By default, request will fail if the authentication cannot be verified. If set to false, request will process and this provider will abstain. outbound OutboundTarget[&#93; &#160; Add a new outbound target to configure identity propagation or explicit username/password. principal-type SubjectType (USER, SERVICE) USER Principal type this provider extracts (and also propagates). realm string helidon Set the realm to use when challenging users. users ConfigUser[&#93; &#160; Set user store to validate users. Removes any other stores added through #addUserStore(SecureUserStore). Example code See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - http-basic-auth: realm: \"helidon\" users: - login: \"john\" password: \"${CLEAR=password}\" roles: [\"admin\"] - login: \"jack\" password: \"password\" roles: [\"user\", \"admin\"] outbound: - name: \"internal-services\" hosts: [\"*.example.org\"] # Propagates current user's identity or identity from request property outbound-token: header: \"X-Internal-Auth\" - name: \"partner-service\" hosts: [\"*.partner.org\"] # Uses this username and password username: \"partner-user-1\" password: \"${CLEAR=password}\" How does it work? See https://tools.ietf.org/html/rfc7617 . Authentication of request When a request is received without the Authorization: basic &#8230;&#8203;. header, a challenge is returned to provide such authentication. When a request is received with the Authorization: basic &#8230;&#8203;. header, the username and password is validated against configured users (and users obtained from custom service if any provided). Subject is created based on the username and roles provided by the user store. Identity propagation When identity propagation is configured, there are several options for identifying username and password to propagate: We propagate the current username and password (inbound request must be authenticated using basic authentication). We use username and password from an explicitly configured property (See EndpointConfig.PROPERTY_OUTBOUND_ID and EndpointConfig.PROPERTY_OUTBOUND_SECRET ) We use username and password associated with an outbound target (see example configuration above) Identity is propagated only if: There is an outbound target configured for the endpoint Or there is an explicitly configured username/password for the current request (through request property) Custom user store Java service loader service io.helidon.security.providers.httpauth.spi.UserStoreService can be implemented to provide users to the provider, such as when validated against an internal database or LDAP server. The user store is defined so you never need the clear text password of the user. Warning on security of HTTP Basic Authentication (or lack thereof) Basic authentication uses base64 encoded username and password and passes it over the network. Base64 is only encoding, not encryption - so anybody that gets hold of the header value can learn the actual username and password of the user. This is a security risk and an attack vector that everybody should be aware of before using HTTP Basic Authentication. We recommend using this approach only for testing and demo purposes. HTTP Digest Authentication Provider HTTP Digest authentication support Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-http-auth&lt;/artifactId&gt; &lt;/dependency&gt; Overview Http digest authentication security provider Type: io.helidon.security.providers.httpauth.HttpDigestAuthProvider <markup lang=\"text\" title=\"Config key\" >http-digest-auth This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthenticationProvider Configuration options Optional configuration options key type default value description algorithm Algorithm (MD5) MD5 Digest algorithm to use. nonce-timeout-millis long 86400000 How long will the nonce value be valid. When timed-out, browser will re-request username/password. optional boolean false Whether authentication is required. By default, request will fail if the authentication cannot be verified. If set to false, request will process and this provider will abstain. principal-type SubjectType (USER, SERVICE) USER Principal type this provider extracts (and also propagates). qop Qop (NONE, AUTH) NONE Only AUTH supported. If left empty, uses the legacy approach (older RFC version). AUTH-INT is not supported. realm string Helidon Set the realm to use when challenging users. server-secret string &#160; The nonce is encrypted using this secret - to make sure the nonce we get back was generated by us and to make sure we can safely time-out nonce values. This secret must be the same for all service instances (or all services that want to share the same authentication). Defaults to a random password - e.g. if deployed to multiple servers, the authentication WILL NOT WORK. You MUST provide your own password to work in a distributed environment with non-sticky load balancing. users ConfigUser[&#93; &#160; Set user store to obtain passwords and roles based on logins. Example code <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - http-digest-auth: realm: \"helidon\" server-secret: \"${CLEAR=service-wide-secret-not-known-outside}\" users: - login: \"john\" password: \"${CLEAR=password}\" roles: [\"admin\"] - login: \"jack\" password: \"password\" roles: [\"user\", \"admin\"] How does it work? See https://tools.ietf.org/html/rfc7616 . Authentication of request When a request is received without the Authorization: digest &#8230;&#8203;. header, a challenge is returned to provide such authentication using WWW-Authenticate header. When a request is received with the Authorization: digest &#8230;&#8203;. header, the request is validated against configured users (and users obtained from custom service if any provided). Subject is created based on the username and roles provided by the user store. Custom user store Java service loader service io.helidon.security.providers.httpauth.spi.UserStoreService can be implemented to provide users to the provider, such as when validated against an internal database or LDAP server. The user store is defined so you never need the clear text password of the user. Note on security of HTTP Digest Authentication These authentication schemes should be obsolete , though they provide a very easy way to test a protected resource. Header Authentication Provider Asserts user or service identity based on a value of a header. Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-header&lt;/artifactId&gt; &lt;/dependency&gt; Overview Security provider that extracts a username (or service name) from a header. Type: io.helidon.security.providers.header.HeaderAtnProvider <markup lang=\"text\" title=\"Config key\" >header-atn This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthenticationProvider Configuration options Optional configuration options key type default value description atn-token TokenHandler &#160; Token handler to extract username from request. authenticate boolean true Whether to authenticate requests. optional boolean false Whether authentication is required. By default, request will fail if the username cannot be extracted. If set to false, request will process and this provider will abstain. outbound OutboundTarget[&#93; &#160; Configure outbound target for identity propagation. outbound-token TokenHandler &#160; Token handler to create outbound headers to propagate identity. If not defined, #atnTokenHandler will be used. principal-type SubjectType (USER, SERVICE) USER Principal type this provider extracts (and also propagates). propagate boolean false Whether to propagate identity. Example code <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: header-atn: atn-token: header: \"X-AUTH-USER\" outbound: - name: \"internal-services\" hosts: [\"*.example.org\"] # propagates the current user or service id using the same header as authentication - name: \"partner-service\" hosts: [\"*.partner.org\"] # propagates an explicit username in a custom header username: \"service-27\" outbound-token: header: \"X-Service-Auth\" How does it work? This provider inspects a specified request header and extracts the username/service name from it and asserts it as current subject&#8217;s principal. This can be used when we use perimeter authentication (e.g. there is a gateway that takes care of authentication and propagates the user in a header). Identity propagation Identity is propagated only if an outbound target matches the target service. The following options exist when propagating identity: 1. We propagate the current username using the configured header 2. We use username associated with an outbound target (see example configuration above) Caution When using this provider, you must be sure the header cannot be explicitly configured by a user or another service. All requests should go through a gateway that removes this header from inbound traffic, and only configures it for authenticated users/services. Another option is to use this with fully trusted parties (such as services within a single company, on a single protected network not accessible to any users), and of course for testing and demo purposes. HTTP Signatures Provider Support for HTTP Signatures. Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-http-sign&lt;/artifactId&gt; &lt;/dependency&gt; Overview HTTP header signature provider. Type: io.helidon.security.providers.httpsign.HttpSignProvider <markup lang=\"text\" title=\"Config key\" >http-signatures This type provides the following service implementations: io.helidon.security.spi.AuthenticationProvider Configuration options Optional configuration options key type default value description backward-compatible-eol boolean false Enable support for Helidon versions before 3.0.0 (exclusive). Until version 3.0.0 (exclusive) there was a trailing end of line added to the signed data. To be able to communicate cross versions, we must configure this when talking to older versions of Helidon. Default value is `false`. In Helidon 2.x, this switch exists as well and the default is `true`, to allow communication between versions as needed. headers HttpSignHeader[&#93; (SIGNATURE, AUTHORIZATION, CUSTOM) &#160; Add a header that is validated on inbound requests. Provider may support more than one header to validate. inbound.keys InboundClientDefinition[&#93; &#160; Add inbound configuration. This is used to validate signature and authenticate the party. The same can be done through configuration: &lt;pre&gt; { name = \"http-signatures\" class = \"HttpSignProvider\" http-signatures { inbound { # This configures the InboundClientDefinition keys: [ { key-id = \"service1\" hmac.secret = \"${CLEAR=password}\" }] } } } &lt;/pre&gt; optional boolean true Set whether the signature is optional. If set to true (default), this provider will SecurityResponse.SecurityStatus#ABSTAIN from this request if signature is not present. If set to false, this provider will SecurityResponse.SecurityStatus#FAILURE fail if signature is not present. outbound OutboundConfig &#160; Add outbound targets to this builder. The targets are used to chose what to do for outbound communication. The targets should have OutboundTargetDefinition attached through OutboundTarget.Builder#customObject(Class, Object) to tell us how to sign the request. The same can be done through configuration: &lt;pre&gt; { name = \"http-signatures\" class = \"HttpSignProvider\" http-signatures { targets: [ { name = \"service2\" hosts = [\"localhost\"] paths = [\"/service2/.*\"] # This configures the OutboundTargetDefinition signature { key-id = \"service1\" hmac.secret = \"${CLEAR=password}\" } }] } } &lt;/pre&gt; realm string helidon Realm to use for challenging inbound requests that do not have \"Authorization\" header in case header is HttpSignHeader#AUTHORIZATION and singatures are not optional. sign-headers HeadersConfig[&#93; &#160; Override the default inbound required headers (e.g. headers that MUST be signed and headers that MUST be signed IF present). Defaults: get, head, delete methods: date, (request-target), host are mandatory; authorization if present (unless we are creating/validating the HttpSignHeader#AUTHORIZATION ourselves put, post: same as above, with addition of: content-length, content-type and digest if present for other methods: date, (request-target) Note that this provider DOES NOT validate the \"Digest\" HTTP header, only the signature. Example code See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - http-signatures: inbound: keys: - key-id: \"service1-hmac\" principal-name: \"Service1 - HMAC signature\" hmac.secret: \"${CLEAR=somePasswordForHmacShouldBeEncrypted}\" - key-id: \"service1-rsa\" principal-name: \"Service1 - RSA signature\" public-key: keystore: resource.path: \"src/main/resources/keystore.p12\" passphrase: \"password\" cert.alias: \"service_cert\" outbound: - name: \"service2-hmac\" hosts: [\"localhost\"] paths: [\"/service2\"] signature: key-id: \"service1-hmac\" hmac.secret: \"${CLEAR=somePasswordForHmacShouldBeEncrypted}\" - name: \"service2-rsa\" hosts: [\"localhost\"] paths: [\"/service2-rsa.*\"] signature: key-id: \"service1-rsa\" private-key: keystore: resource.path: \"src/main/resources/keystore.p12\" passphrase: \"password\" key.alias: \"myPrivateKey\" Signature basics standard: based on https://tools.ietf.org/html/draft-cavage-http-signatures-03 key-id: an arbitrary string used to locate signature configuration - when a request is received the provider locates validation configuration based on this id (e.g. HMAC shared secret or RSA public key). Commonly used meanings are: key fingerprint (RSA); API Key How does it work? Inbound Signatures We act as a server and another party is calling us with a signed HTTP request. We validate the signature and assume identity of the caller. Outbound Signatures We act as a client and we sign our outgoing requests. If there is a matching outbound target specified in configuration, its configuration will be applied for signing the outgoing request, otherwise there is no signature added IDCS Role Mapper A role mapper to retrieve roles from Oracle IDCS. Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-idcs-mapper&lt;/artifactId&gt; &lt;/dependency&gt; Single-tenant IDCS Role Mapper IDCS role mapping provider Type: io.helidon.security.providers.idcs.mapper.IdcsRoleMapperProvider <markup lang=\"text\" title=\"Config key\" >idcs-role-mapper This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.SubjectMappingProvider Configuration options Optional configuration options key type default value description cache-config EvictableCache &#160; Use explicit io.helidon.security.providers.common.EvictableCache for role caching. default-idcs-subject-type string user Configure subject type to use when requesting roles from IDCS. Can be either #IDCS_SUBJECT_TYPE_USER or #IDCS_SUBJECT_TYPE_CLIENT. Defaults to #IDCS_SUBJECT_TYPE_USER. oidc-config OidcConfig &#160; Use explicit io.helidon.security.providers.oidc.common.OidcConfig instance, e.g. when using it also for OIDC provider. subject-types SubjectType[&#93; (USER, SERVICE) USER Add a supported subject type. If none added, io.helidon.security.SubjectType#USER is used. If any added, only the ones added will be used (e.g. if you want to use both io.helidon.security.SubjectType#USER and io.helidon.security.SubjectType#SERVICE, both need to be added. Multi-tenant IDCS Role Mapper Multitenant IDCS role mapping provider Type: io.helidon.security.providers.idcs.mapper.IdcsMtRoleMapperProvider <markup lang=\"text\" title=\"Config key\" >idcs-role-mapper This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.SubjectMappingProvider Configuration options Optional configuration options key type default value description cache-config EvictableCache &#160; Use explicit io.helidon.security.providers.common.EvictableCache for role caching. default-idcs-subject-type string user Configure subject type to use when requesting roles from IDCS. Can be either #IDCS_SUBJECT_TYPE_USER or #IDCS_SUBJECT_TYPE_CLIENT. Defaults to #IDCS_SUBJECT_TYPE_USER. idcs-app-name-handler TokenHandler &#160; Configure token handler for IDCS Application name. By default the header IdcsMtRoleMapperProvider#IDCS_APP_HEADER is used. idcs-tenant-handler TokenHandler &#160; Configure token handler for IDCS Tenant ID. By default the header IdcsMtRoleMapperProvider#IDCS_TENANT_HEADER is used. oidc-config OidcConfig &#160; Use explicit io.helidon.security.providers.oidc.common.OidcConfig instance, e.g. when using it also for OIDC provider. subject-types SubjectType[&#93; (USER, SERVICE) USER Add a supported subject type. If none added, io.helidon.security.SubjectType#USER is used. If any added, only the ones added will be used (e.g. if you want to use both io.helidon.security.SubjectType#USER and io.helidon.security.SubjectType#SERVICE, both need to be added. Example code See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - idcs-role-mapper: multitenant: false oidc-config: client-id: \"client-id\" client-secret: \"client-secret\" identity-uri: \"IDCS identity server address\" How does it work? The provider asks the IDCS server to provide list of roles for the currently authenticated user. The result is cached for a certain period of time (see cache-config above). ABAC Provider Attribute based access control authorization provider. Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-abac&lt;/artifactId&gt; &lt;/dependency&gt; Overview Attribute Based Access Control provider Type: io.helidon.security.providers.abac.AbacProvider <markup lang=\"text\" title=\"Config key\" >abac This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthorizationProvider Configuration options Optional configuration options key type default value description fail-if-none-validated boolean true Whether to fail if NONE of the attributes is validated. fail-on-unvalidated boolean true Whether to fail if any attribute is left unvalidated. Example code See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - abac: Configuration options The following table shows all configuration options of the provider and their default values key default value description fail-on-unvalidated true \"Unvalidated\" means: an attribute is defined, but there is no validator available for it fail-if-none-validated true \"None validated\" means: there was not a single attribute that was validated How does it work? ABAC uses available validators and validates them against attributes of the authenticated user. Combinations of fail-on-unvalidated and fail-if-none-validated : true &amp; true : Will fail if any attribute is not validated and if any has failed validation false &amp; true : Will fail if there is one or more attributes present and NONE of them is validated or if any has failed validation, Will NOT fail if there is at least one validated attribute and any number of not validated attributes (and NONE failed) false &amp; false : Will fail if there is any attribute that failed validation, Will NOT fail if there are no failed validation or if there are NONE validated Any attribute of the following objects can be used: environment (such as time of request) - e.g. env.time.year subject (user) - e.g. subject.principal.id subject (service) - e.g. service.principal.id object (must be explicitly invoked by developer in code, as object cannot be automatically added to security context) - e.g. object.owner This provider checks that all defined ABAC validators are validated. If there is a definition for a validator that is not checked, the request is denied (depending on configuration as mentioned above). ABAC provider also allows an object to be used in authorization process, such as when evaluating if an object&#8217;s owner is the current user. The following example uses the Expression language validator to demonstrate the point in a JAX-RS resource: <markup lang=\"java\" title=\"Example of using an object\" >@Authenticated @Path(\"/abac\") public class AbacResource { @GET @Authorized(explicit = true) @PolicyStatement(\"${env.time.year &gt;= 2017 &amp;&amp; object.owner == subject.principal.id}\") public Response process(@Context SecurityContext context) { // probably looked up from a database SomeResource res = new SomeResource(\"user\"); AuthorizationResponse atzResponse = context.authorize(res); if (atzResponse.isPermitted()) { //do the update return Response.ok().entity(\"fine, sir\").build(); } else { return Response.status(Response.Status.FORBIDDEN) .entity(atzResponse.description().orElse(\"Access not granted\")) .build(); } } } The following validators are implemented: Roles Scopes EL Policy Role Validator Checks whether user/service is in either of the required role(s). Configuration Key: role-validator Annotations: @RolesAllowed , @RoleValidator.Roles <markup lang=\"yaml\" title=\"Configuration example for WebServer \" >security: web-server.paths: - path: \"/user[/{*}]\" roles-allowed: [\"user\"] <markup lang=\"java\" title=\"JAX-RS example\" >@RolesAllowed(\"user\") @RoleValidator.Roles(value = \"service_role\", subjectType = SubjectType.SERVICE) @Authenticated @Path(\"/abac\") public class AbacResource { } Interaction with JAX-RS sub-resource locators When using sub-resource locators in JAX-RS, the roles allowed are collected from each \"level\" of execution: - Application class annotations - Resource class annotations + resource method annotations - Sub-resource class annotations + sub-resource method annotations - Sub-resource class annotations + sub-resource method annotations (for every sub-resource on the path) The RolesAllowed or Roles annotation to be used is the last one in the path as defined above. Example 1: There is a RolesAllowed(\"admin\") defined on a sub-resource locator resource class. In this case the required role is admin . Example 2: There is a RolesAllowed(\"admin\") defined on a sub-resource locator resource class and a RolesAllowed(\"user\") defined on the method of the sub-resource that provides the response. In this case the required role is user . Scope Validator Checks whether user has all the required scopes. Configuration Key: scope-validator Annotations: @Scope <markup lang=\"yaml\" title=\"Configuration example for WebServer \" >security: web-server.paths: - path: \"/user[/{*}]\" abac.scopes: [\"calendar_read\", \"calendar_edit\"] <markup lang=\"java\" title=\"JAX-RS example\" >@Scope(\"calendar_read\") @Scope(\"calendar_edit\") @Authenticated @Path(\"/abac\") public class AbacResource { } Expression Language Policy Validator Policy executor using Java EE policy expression language (EL) Configuration Key: policy-javax-el Annotations: @PolicyStatement Example of a policy statement: ${env.time.year &gt;= 2017} <markup lang=\"yaml\" title=\"Configuration example for WebServer \" >security: web-server.paths: - path: \"/user[/{*}]\" policy: statement: \"hasScopes('calendar_read','calendar_edit') AND timeOfDayBetween('8:15', '17:30')\" <markup lang=\"java\" title=\"JAX-RS example\" >@PolicyStatement(\"${env.time.year &gt;= 2017}\") @Authenticated @Path(\"/abac\") public class AbacResource { } Google Login Provider Authenticates a token from request against Google identity provider Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-google-login&lt;/artifactId&gt; &lt;/dependency&gt; Overview Google Authentication provider Type: io.helidon.security.providers.google.login.GoogleTokenProvider <markup lang=\"text\" title=\"Config key\" >google-login This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthenticationProvider Configuration options Optional configuration options key type default value description client-id string &#160; Google application client id, to validate that the token was generated by Google for us. optional boolean false If set to true, this provider will return io.helidon.security.SecurityResponse.SecurityStatus#ABSTAIN instead of failing in case of invalid request. outbound OutboundConfig &#160; Outbound configuration - a set of outbound targets that will have the token propagated. proxy-host string &#160; Set proxy host when talking to Google. proxy-port int 80 Set proxy port when talking to Google. realm string helidon Set the authentication realm to build challenge, defaults to \"helidon\". token TokenHandler &#x60;Authorization&#x60; header with &#x60;bearer&#x60; prefix Token provider to extract Google access token from request, defaults to \"Authorization\" header with a \"bearer \" prefix. Example code See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - provider: client-id: \"Google client id\" How does it work? We expect to receive a token (with sufficient scopes) from the inbound request, such as when using the Google login button on a page. The page has access to the token in javascript and can send it to backend with every request in a header field ( Authorization with `bearer ` prefix is assumed by default). Once we receive the token in Helidon, we parse it and: Validate if it timed out locally Return a cached response (see EvictableCache with default values) Otherwise verify using Google API - GoogleIdTokenVerifier We build a subject from the Google token with the following attributes filled (if in token): userId email name emailVerified locale family_name given_name picture (URL) Outbound security The token will be propagated to outbound calls if an outbound target exists that matches the invoked endpoint (see outbound configuration above). JWT Provider JWT token authentication and outbound security provider. Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-jwt&lt;/artifactId&gt; &lt;/dependency&gt; Overview JWT authentication provider Type: io.helidon.security.providers.jwt.JwtProvider <markup lang=\"text\" title=\"Config key\" >jwt This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthenticationProvider Configuration options Optional configuration options key type default value description allow-impersonation boolean false Whether to allow impersonation by explicitly overriding username from outbound requests using io.helidon.security.EndpointConfig#PROPERTY_OUTBOUND_ID property. By default this is not allowed and identity can only be propagated. allow-unsigned boolean false Configure support for unsigned JWT. If this is set to true any JWT that has algorithm set to none and no kid defined will be accepted. Note that this has serious security impact - if JWT can be sent from a third party, this allows the third party to send ANY JWT and it would be accpted as valid. atn-token.handler TokenHandler &#160; Token handler to extract username from request. atn-token.jwk.resource Resource &#160; JWK resource used to verify JWTs created by other parties. atn-token.jwt-audience string &#160; Audience expected in inbound JWTs. atn-token.verify-signature boolean true Configure whether to verify signatures. Signatures verification is enabled by default. You can configure the provider not to verify signatures. &lt;b&gt;Make sure your service is properly secured on network level and only accessible from a secure endpoint that provides the JWTs when signature verification is disabled. If signature verification is disabled, this service will accept &lt;i&gt;ANY&lt;/i&gt; JWT&lt;/b&gt; authenticate boolean true Whether to authenticate requests. optional boolean false Whether authentication is required. By default, request will fail if the username cannot be extracted. If set to false, request will process and this provider will abstain. principal-type SubjectType (USER, SERVICE) USER Principal type this provider extracts (and also propagates). propagate boolean true Whether to propagate identity. sign-token OutboundConfig &#160; Configuration of outbound rules. sign-token.jwk.resource Resource &#160; JWK resource used to sign JWTs created by us. sign-token.jwt-issuer string &#160; Issuer used to create new JWTs. use-jwt-groups boolean true Claim groups from JWT will be used to automatically add groups to current subject (may be used with jakarta.annotation.security.RolesAllowed annotation). Example code See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - provider: atn-token: jwk.resource.resource-path: \"verifying-jwk.json\" jwt-audience: \"http://my.service\" sign-token: jwk.resource.resource-path: \"signing-jwk.json\" jwt-issuer: \"http://my.server/identity\" outbound: - name: \"propagate-token\" hosts: [\"*.internal.org\"] - name: \"generate-token\" hosts: [\"1.partner-service\"] jwk-kid: \"partner-1\" jwt-kid: \"helidon\" jwt-audience: \"http://1.partner-service\" How does it work? JSON Web Token (JWT) provider has support for authentication and outbound security. Authentication is based on validating the token (signature, valid before etc.) and on asserting the subject of the JWT subject claim. For outbound, we support either token propagation (e.g. the token from request is propagated further) or support for generating a brand new token based on configuration of this provider. ",
            "title": "CORS Settings"
        },
        {
            "location": "/mp/security/security",
            "text": " To add security, such as protecting resource methods with authentication, to a MicroProfile application, add the Helidon security integration dependency to your project. ",
            "title": "preambule"
        },
        {
            "location": "/mp/security/security",
            "text": " For JAX-RS resources, declare security by adding annotations to a resource class or method. <markup lang=\"java\" title=\"Protected resource method\" >@GET @io.helidon.security.annotations.Authenticated @io.helidon.security.annotations.Authorized // you can also use io.helidon.security.abac.role.RoleValidator.Roles @RolesAllowed(\"admin\") public String adminResource(@Context io.helidon.security.SecurityContext securityContext) { return \"you are \" + securityContext.userName(); } Security in Helidon MicroProfile is built on top of Jersey&#8217;s and can be enabled/disabled using the property security.jersey.enabled=[true|false] . ",
            "title": "Securing a JAX-RS Resource"
        },
        {
            "location": "/mp/security/security",
            "text": " The configuration is usually placed under security.web-server (this can be customized in Helidon SE). The following shows an example we will explain in detail: <markup lang=\"yaml\" title=\"application.yaml\" >security: providers: - abac: - provider-key: web-server: defaults: authenticate: true paths: - path: \"/metrics[/{*}]\" roles-allowed: \"admin\" - path: \"/health[/{*}]\" roles-allowed: \"monitor\" - path: \"/openapi[/{*}]\" abac: scopes: [\"openapi\"] - path: \"/static[/{*}]\" roles-allowed: [\"user\", \"monitor\"] Attribute based access control provider that checks roles and scopes The provider(s) used in your application, such as oidc Default configuration for all configured paths Protection of /metrics and all nested paths with admin role required Protection of /health and all nested paths with monitor role required Protection of /openapi and all nested paths with openapi scope required Protection of static content configured on /static path with either user or monitor role required If you need to use a properties file, such as microprofile-config.properties , you can convert the file by using index based numbers for arrays, such as: <markup lang=\"properties\" title=\"microprofile-config.properties\" >security.providers.0.abac= security.providers.1.provider-key.optional=false security.web-server.defaults.authenticate=true security.web-server.paths.0.path=/metrics[/{*}] security.web-server.paths.0.roles-allowed=admin security.web-server.paths.3.path=/static[/{*}] security.web-server.paths.3.roles-allowed=user,monitor ",
            "title": "Configuring endpoint protection"
        },
        {
            "location": "/mp/security/security",
            "text": " There are several endpoints provided by Helidon services, such as: Health endpoint ( /health ) Metrics endpoint ( /metrics ) OpenAPI endpoint ( /openapi ) Configured static content (can use any path configured) These endpoints are all implemented using Helidon WebServer and as such can be protected only through Security integration with WebServer. The following section describes configuration of such protection using configuration files, in this case using a yaml file, as it provides a tree structure. Configuring endpoint protection The configuration is usually placed under security.web-server (this can be customized in Helidon SE). The following shows an example we will explain in detail: <markup lang=\"yaml\" title=\"application.yaml\" >security: providers: - abac: - provider-key: web-server: defaults: authenticate: true paths: - path: \"/metrics[/{*}]\" roles-allowed: \"admin\" - path: \"/health[/{*}]\" roles-allowed: \"monitor\" - path: \"/openapi[/{*}]\" abac: scopes: [\"openapi\"] - path: \"/static[/{*}]\" roles-allowed: [\"user\", \"monitor\"] Attribute based access control provider that checks roles and scopes The provider(s) used in your application, such as oidc Default configuration for all configured paths Protection of /metrics and all nested paths with admin role required Protection of /health and all nested paths with monitor role required Protection of /openapi and all nested paths with openapi scope required Protection of static content configured on /static path with either user or monitor role required If you need to use a properties file, such as microprofile-config.properties , you can convert the file by using index based numbers for arrays, such as: <markup lang=\"properties\" title=\"microprofile-config.properties\" >security.providers.0.abac= security.providers.1.provider-key.optional=false security.web-server.defaults.authenticate=true security.web-server.paths.0.path=/metrics[/{*}] security.web-server.paths.0.roles-allowed=admin security.web-server.paths.3.path=/static[/{*}] security.web-server.paths.3.roles-allowed=user,monitor ",
            "title": "Protecting Helidon endpoints"
        },
        {
            "location": "/mp/security/security",
            "text": " To enable Security add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-security&lt;/artifactId&gt; &lt;/dependency&gt; Securing a JAX-RS Resource For JAX-RS resources, declare security by adding annotations to a resource class or method. <markup lang=\"java\" title=\"Protected resource method\" >@GET @io.helidon.security.annotations.Authenticated @io.helidon.security.annotations.Authorized // you can also use io.helidon.security.abac.role.RoleValidator.Roles @RolesAllowed(\"admin\") public String adminResource(@Context io.helidon.security.SecurityContext securityContext) { return \"you are \" + securityContext.userName(); } Security in Helidon MicroProfile is built on top of Jersey&#8217;s and can be enabled/disabled using the property security.jersey.enabled=[true|false] . Protecting Helidon endpoints There are several endpoints provided by Helidon services, such as: Health endpoint ( /health ) Metrics endpoint ( /metrics ) OpenAPI endpoint ( /openapi ) Configured static content (can use any path configured) These endpoints are all implemented using Helidon WebServer and as such can be protected only through Security integration with WebServer. The following section describes configuration of such protection using configuration files, in this case using a yaml file, as it provides a tree structure. Configuring endpoint protection The configuration is usually placed under security.web-server (this can be customized in Helidon SE). The following shows an example we will explain in detail: <markup lang=\"yaml\" title=\"application.yaml\" >security: providers: - abac: - provider-key: web-server: defaults: authenticate: true paths: - path: \"/metrics[/{*}]\" roles-allowed: \"admin\" - path: \"/health[/{*}]\" roles-allowed: \"monitor\" - path: \"/openapi[/{*}]\" abac: scopes: [\"openapi\"] - path: \"/static[/{*}]\" roles-allowed: [\"user\", \"monitor\"] Attribute based access control provider that checks roles and scopes The provider(s) used in your application, such as oidc Default configuration for all configured paths Protection of /metrics and all nested paths with admin role required Protection of /health and all nested paths with monitor role required Protection of /openapi and all nested paths with openapi scope required Protection of static content configured on /static path with either user or monitor role required If you need to use a properties file, such as microprofile-config.properties , you can convert the file by using index based numbers for arrays, such as: <markup lang=\"properties\" title=\"microprofile-config.properties\" >security.providers.0.abac= security.providers.1.provider-key.optional=false security.web-server.defaults.authenticate=true security.web-server.paths.0.path=/metrics[/{*}] security.web-server.paths.0.roles-allowed=admin security.web-server.paths.3.path=/static[/{*}] security.web-server.paths.3.roles-allowed=user,monitor ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/server",
            "text": " Overview Maven Coordinates Usage API Configuration Examples Reference ",
            "title": "Content"
        },
        {
            "location": "/mp/server",
            "text": " Helidon provides a MicroProfile server implementation ( io.helidon.microprofile.server.Server ) that encapsulates the Helidon WebServer. ",
            "title": "Overview"
        },
        {
            "location": "/mp/server",
            "text": " To enable MicroProfile Server add the helidon-microprofile-core bundle dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.bundles&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-core&lt;/artifactId&gt; &lt;/dependency&gt; MicroProfile Server is already included in the bundle. If full control over the dependencies is required, and you want to minimize the quantity of the dependencies - Helidon MicroProfile Server should be used. In this case the following dependencies should be included in your project&#8217;s pom.xml : <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.server&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-server&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven-Coordinates"
        },
        {
            "location": "/mp/server",
            "text": " Helidon Microprofile Server is used to collect and deploy JAX-RS application(s). When starting Helidon MP, it is recommended to use the io.helidon.Main main class, which will take care of starting Helidon. CDI will then discover all extensions, including the Server extension and start it. See the Helidon MP Quickstart example . Note that the server lifecycle is bound to CDI. Usage of the io.helidon.microprofile.server.Server API is discouraged, as Helidon MP uses convention to discover and configure features, which makes the applications easier to understand and maintain. ",
            "title": "Usage"
        },
        {
            "location": "/mp/server",
            "text": " The following table provides a brief description of routing annotations, including its parameters. More information in Configuring a WebServer route section. <div class=\"table__overflow elevation-1 flex sm10 \"> Annotation Description @RoutingName( value = \"\" required = false ) Binds a JAX-RS Application or Helidon Service to a specific (named) routing on WebServer .The routing should have a corresponding named socket configured on the WebServer to run the routing on. @RoutingPath(\"/path\") Path of a Helidon Service to register with routing. ",
            "title": "API"
        },
        {
            "location": "/mp/server",
            "text": " Optional configuration options key type default value description backlog int 1024 Accept backlog. @return backlog connection-config ConnectionConfig &#160; Configuration of a connection (established from client against our server). @return connection configuration connection-options SocketOptions &#160; Options for connections accepted by this listener. This is not used to setup server connection. @return socket options content-encoding ContentEncodingContext &#160; Configure the listener specific io.helidon.http.encoding.ContentEncodingContext. This method discards all previously registered ContentEncodingContext. If no content encoding context is registered, content encoding context of the webserver would be used. @return content encoding context features io.helidon.webserver.spi.ServerFeature[&#93; (service provider interface) Such as: observe (ObserveFeature) context (ContextFeature) cors (CorsFeature) security (SecurityFeature) access-log (AccessLogFeature) &#160; Server features allow customization of the server, listeners, or routings. @return server features host string 0.0.0.0 Host of the default socket. Defaults to all host addresses ( 0.0.0.0 ). @return host address to listen on (for the default socket) idle-connection-period Duration PT2M How often should we check for #idleConnectionTimeout(). Defaults to PT2M (2 minutes). @return period of checking for idle connections idle-connection-timeout Duration PT5M How long should we wait before closing a connection that has no traffic on it. Defaults to PT5M (5 minutes). Note that the timestamp is refreshed max. once per second, so this setting would be useless if configured for shorter periods of time (also not a very good support for connection keep alive, if the connections are killed so soon anyway). @return timeout of idle connections max-concurrent-requests int -1 Limits the number of requests that can be executed at the same time (the number of active virtual threads of requests). Defaults to -1 , meaning \"unlimited\" - what the system allows. Also make sure that this number is higher than the expected time it takes to handle a single request in your application, as otherwise you may stop in-progress requests. @return number of requests that can be processed on this listener, regardless of protocol max-in-memory-entity int 131072 If the entity is expected to be smaller that this number of bytes, it would be buffered in memory to optimize performance when writing it. If bigger, streaming will be used. Note that for some entity types we cannot use streaming, as they are already fully in memory (String, byte[]), for such cases, this option is ignored. Default is 128Kb. @return maximal number of bytes to buffer in memory for supported writers max-payload-size long -1 Maximal number of bytes an entity may have. If io.helidon.http.HeaderNames#CONTENT_LENGTH is used, this is checked immediately, if io.helidon.http.HeaderValues#TRANSFER_ENCODING_CHUNKED is used, we will fail when the number of bytes read would exceed the max payload size. Defaults to unlimited ( -1 ). @return maximal number of bytes of entity max-tcp-connections int -1 Limits the number of connections that can be opened at a single point in time. Defaults to -1 , meaning \"unlimited\" - what the system allows. @return number of TCP connections that can be opened to this listener, regardless of protocol media-context MediaContext &#160; Configure the listener specific io.helidon.http.media.MediaContext. This method discards all previously registered MediaContext. If no media context is registered, media context of the webserver would be used. @return media context name string @default Name of this socket. Defaults to @default . Must be defined if more than one socket is needed. @return name of the socket port int 0 Port of the default socket. If configured to 0 (the default), server starts on a random port. @return port to listen on (for the default socket) protocols io.helidon.webserver.spi.ProtocolConfig[&#93; (service provider interface) &#160; Configuration of protocols. This may be either protocol selectors, or protocol upgraders from HTTP/1.1. As the order is not important (providers are ordered by weight by default), we can use a configuration as an object, such as: &lt;pre&gt; protocols: providers: http_1_1: max-prologue-length: 8192 http_2: max-frame-size: 4096 websocket: &#8230;&#8203;. &lt;/pre&gt; @return all defined protocol configurations, loaded from service loader by default receive-buffer-size int &#160; Listener receive buffer size. @return buffer size in bytes shutdown-grace-period Duration PT0.5S Grace period in ISO 8601 duration format to allow running tasks to complete before listener&#8217;s shutdown. Default is 500 milliseconds. Configuration file values example: PT0.5S , PT2S . @return grace period shutdown-hook boolean true When true the webserver registers a shutdown hook with the JVM Runtime. Defaults to true. Set this to false such that a shutdown hook is not registered. @return whether to register a shutdown hook sockets Map&lt;string, ListenerConfig&gt; &#160; Socket configurations. Note that socket named WebServer#DEFAULT_SOCKET_NAME cannot be used, configure the values on the server directly. @return map of listener configurations, except for the default one tls Tls &#160; Listener TLS configuration. @return tls of this configuration write-buffer-size int 512 Initial buffer size in bytes of java.io.BufferedOutputStream created internally to write data to a socket connection. Default is 512 . @return initial buffer size used for writing write-queue-length int 0 Number of buffers queued for write operations. @return maximal number of queued writes, defaults to 0 ",
            "title": "Configuration options"
        },
        {
            "location": "/mp/server",
            "text": " By default, the server uses the MicroProfile Config, but you may also want to use Helidon configuration . In this example, the configuration is in a file, and it includes Helidon configuration options. Configuration reference: Type: io.helidon.webserver.WebServer This is a standalone configuration type, prefix from configuration root: server Configuration options Optional configuration options key type default value description backlog int 1024 Accept backlog. @return backlog connection-config ConnectionConfig &#160; Configuration of a connection (established from client against our server). @return connection configuration connection-options SocketOptions &#160; Options for connections accepted by this listener. This is not used to setup server connection. @return socket options content-encoding ContentEncodingContext &#160; Configure the listener specific io.helidon.http.encoding.ContentEncodingContext. This method discards all previously registered ContentEncodingContext. If no content encoding context is registered, content encoding context of the webserver would be used. @return content encoding context features io.helidon.webserver.spi.ServerFeature[&#93; (service provider interface) Such as: observe (ObserveFeature) context (ContextFeature) cors (CorsFeature) security (SecurityFeature) access-log (AccessLogFeature) &#160; Server features allow customization of the server, listeners, or routings. @return server features host string 0.0.0.0 Host of the default socket. Defaults to all host addresses ( 0.0.0.0 ). @return host address to listen on (for the default socket) idle-connection-period Duration PT2M How often should we check for #idleConnectionTimeout(). Defaults to PT2M (2 minutes). @return period of checking for idle connections idle-connection-timeout Duration PT5M How long should we wait before closing a connection that has no traffic on it. Defaults to PT5M (5 minutes). Note that the timestamp is refreshed max. once per second, so this setting would be useless if configured for shorter periods of time (also not a very good support for connection keep alive, if the connections are killed so soon anyway). @return timeout of idle connections max-concurrent-requests int -1 Limits the number of requests that can be executed at the same time (the number of active virtual threads of requests). Defaults to -1 , meaning \"unlimited\" - what the system allows. Also make sure that this number is higher than the expected time it takes to handle a single request in your application, as otherwise you may stop in-progress requests. @return number of requests that can be processed on this listener, regardless of protocol max-in-memory-entity int 131072 If the entity is expected to be smaller that this number of bytes, it would be buffered in memory to optimize performance when writing it. If bigger, streaming will be used. Note that for some entity types we cannot use streaming, as they are already fully in memory (String, byte[]), for such cases, this option is ignored. Default is 128Kb. @return maximal number of bytes to buffer in memory for supported writers max-payload-size long -1 Maximal number of bytes an entity may have. If io.helidon.http.HeaderNames#CONTENT_LENGTH is used, this is checked immediately, if io.helidon.http.HeaderValues#TRANSFER_ENCODING_CHUNKED is used, we will fail when the number of bytes read would exceed the max payload size. Defaults to unlimited ( -1 ). @return maximal number of bytes of entity max-tcp-connections int -1 Limits the number of connections that can be opened at a single point in time. Defaults to -1 , meaning \"unlimited\" - what the system allows. @return number of TCP connections that can be opened to this listener, regardless of protocol media-context MediaContext &#160; Configure the listener specific io.helidon.http.media.MediaContext. This method discards all previously registered MediaContext. If no media context is registered, media context of the webserver would be used. @return media context name string @default Name of this socket. Defaults to @default . Must be defined if more than one socket is needed. @return name of the socket port int 0 Port of the default socket. If configured to 0 (the default), server starts on a random port. @return port to listen on (for the default socket) protocols io.helidon.webserver.spi.ProtocolConfig[&#93; (service provider interface) &#160; Configuration of protocols. This may be either protocol selectors, or protocol upgraders from HTTP/1.1. As the order is not important (providers are ordered by weight by default), we can use a configuration as an object, such as: &lt;pre&gt; protocols: providers: http_1_1: max-prologue-length: 8192 http_2: max-frame-size: 4096 websocket: &#8230;&#8203;. &lt;/pre&gt; @return all defined protocol configurations, loaded from service loader by default receive-buffer-size int &#160; Listener receive buffer size. @return buffer size in bytes shutdown-grace-period Duration PT0.5S Grace period in ISO 8601 duration format to allow running tasks to complete before listener&#8217;s shutdown. Default is 500 milliseconds. Configuration file values example: PT0.5S , PT2S . @return grace period shutdown-hook boolean true When true the webserver registers a shutdown hook with the JVM Runtime. Defaults to true. Set this to false such that a shutdown hook is not registered. @return whether to register a shutdown hook sockets Map&lt;string, ListenerConfig&gt; &#160; Socket configurations. Note that socket named WebServer#DEFAULT_SOCKET_NAME cannot be used, configure the values on the server directly. @return map of listener configurations, except for the default one tls Tls &#160; Listener TLS configuration. @return tls of this configuration write-buffer-size int 512 Initial buffer size in bytes of java.io.BufferedOutputStream created internally to write data to a socket connection. Default is 512 . @return initial buffer size used for writing write-queue-length int 0 Number of buffers queued for write operations. @return maximal number of queued writes, defaults to 0 ",
            "title": "Configuration"
        },
        {
            "location": "/mp/server",
            "text": " Access logging in Helidon is done by a dedicated module that can be added to Maven and configured. To enable Access logging add the following dependency to project&#8217;s pom.xml : <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-access-log&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Access Log"
        },
        {
            "location": "/mp/server",
            "text": " Access log can be configured as follows: <markup lang=\"properties\" title=\"Access Log configuration file\" >server.port=8080 server.host=0.0.0.0 server.features.access-log.format=helidon ",
            "title": "Configuring Access Log in a configuration file"
        },
        {
            "location": "/mp/server",
            "text": " Access Log Access logging in Helidon is done by a dedicated module that can be added to Maven and configured. To enable Access logging add the following dependency to project&#8217;s pom.xml : <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-access-log&lt;/artifactId&gt; &lt;/dependency&gt; Configuring Access Log in a configuration file Access log can be configured as follows: <markup lang=\"properties\" title=\"Access Log configuration file\" >server.port=8080 server.host=0.0.0.0 server.features.access-log.format=helidon ",
            "title": "Examples"
        },
        {
            "location": "/mp/server",
            "text": " Optional configuration options key type default value description enabled boolean true Whether this feature will be enabled. @return whether enabled format string &#160; The format for log entries (similar to the Apache LogFormat ). &lt;table class=\"config\"&gt; &lt;caption&gt;Log format elements&lt;/caption&gt; &lt;tr&gt; &lt;td&gt;%h&lt;/td&gt; &lt;td&gt;IP address of the remote host&lt;/td&gt; &lt;td&gt;HostLogEntry&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;%l&lt;/td&gt; &lt;td&gt;The client identity. This is always undefined in Helidon.&lt;/td&gt; &lt;td&gt;UserIdLogEntry&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;%u&lt;/td&gt; &lt;td&gt;User ID as asserted by Helidon Security.&lt;/td&gt; &lt;td&gt;UserLogEntry&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;%t&lt;/td&gt; &lt;td&gt;The timestamp&lt;/td&gt; &lt;td&gt;TimestampLogEntry&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;%r&lt;/td&gt; &lt;td&gt;The request line ( \"GET /favicon.ico HTTP/1.0\" )&lt;/td&gt; &lt;td&gt;RequestLineLogEntry&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;%s&lt;/td&gt; &lt;td&gt;The status code returned to the client&lt;/td&gt; &lt;td&gt;StatusLogEntry&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;%b&lt;/td&gt; &lt;td&gt;The entity size in bytes&lt;/td&gt; &lt;td&gt;SizeLogEntry&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;%D&lt;/td&gt; &lt;td&gt;The time taken in microseconds (start of request until last byte written)&lt;/td&gt; &lt;td&gt;TimeTakenLogEntry&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;%T&lt;/td&gt; &lt;td&gt;The time taken in seconds (start of request until last byte written), integer&lt;/td&gt; &lt;td&gt;TimeTakenLogEntry&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;%{header-name}i&lt;/td&gt; &lt;td&gt;Value of header header-name &lt;/td&gt; &lt;td&gt;HeaderLogEntry&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; @return format string, such as `%h %l %u %t %r %b %{Referer`i} logger-name string io.helidon.webserver.AccessLog Name of the logger used to obtain access log logger from System#getLogger(String). Defaults to AccessLogFeature#DEFAULT_LOGGER_NAME . @return name of the logger to use sockets string[&#93; &#160; List of sockets to register this feature on. If empty, it would get registered on all sockets. The logger used will have the expected logger with a suffix of the socket name. @return socket names to register on, defaults to empty (all available sockets) weight double 1000.0 Weight of the access log feature. We need to log access for anything happening on the server, so weight is high: io.helidon.webserver.accesslog.AccessLogFeature#WEIGHT . @return weight of the feature ",
            "title": "Configuration options"
        },
        {
            "location": "/mp/server",
            "text": " Helidon MP also supports custom TLS configuration. You can set the following properties: Server truststore Keystore with trusted certificates Private key and certificate Server certificate which will be used in TLS handshake <markup lang=\"properties\" title=\"META-INF/microprofile-config.properties - Server configuration\" >#Truststore setup server.tls.trust.keystore.resource.resource-path=server.p12 server.tls.trust.keystore.passphrase=password server.tls.trust.keystore.trust-store=true #Keystore with private key and server certificate server.tls.private-key.keystore.resource.resource-path=server.p12 server.tls.private-key.keystore.passphrase=password Or the same configuration done in application.yaml file. <markup lang=\"yaml\" title=\"application.yaml - Server configuration\" >server: tls: #Truststore setup trust: keystore: passphrase: \"password\" trust-store: true resource: resource-path: \"keystore.p12\" #Keystore with private key and server certificate private-key: keystore: passphrase: \"password\" resource: resource-path: \"keystore.p12\" ",
            "title": "Configuring TLS"
        },
        {
            "location": "/mp/server",
            "text": " Helidon MP can expose multiple ports, with the following limitations: The default port is the port that serves your application (JAX-RS applications and resources) Other ports (in this example we configure one \"admin\" port) can be assigned endpoints that are exposed by Helidon components, currently supported by MP Health and MP Metrics For this example, we will use a YAML file: The port 7011 is the default port and will serve your application The port 8011 is named \"admin\" (this is an arbitrary name) MP Metrics are configured to use the \"admin\" port through the routing configuration (reference is by name) MP Health is configured the same way to reference the \"admin\" port <markup lang=\"yaml\" title=\"application.yaml - Server configuration\" >server: port: 7011 host: \"some.host\" sockets: admin: port: 8011 bind-address: \"some.host\" metrics: routing: \"admin\" health: routing: \"admin\" ",
            "title": "Configuring additional ports"
        },
        {
            "location": "/mp/server",
            "text": " The service can be customized using annotations and/or configuration to be registered on a specific path registered with a named routing ",
            "title": "Customizing the HTTP service"
        },
        {
            "location": "/mp/server",
            "text": " You can annotate a service bean with this annotation to assign it to a specific named routing, that is (most likely) going to be bound to a specific port. The annotation has two attributes: - value that defines the routing name - required to mark that the routing name MUST be configured in Helidon server <markup lang=\"java\" title=\" @RoutingName example\" >@ApplicationScoped @RoutingName(value=\"admin\", required=\"true\") @RoutingPath(\"/admin\") public class AdminService implements HttpService { } The example above will be bound to admin routing (and port) and will fail if such a port is not configured. ",
            "title": "Annotation @RoutingName "
        },
        {
            "location": "/mp/server",
            "text": " For each service bean you can define the routing name and its required flag by specifying a configuration option bean-class-name.routing-name.name and bean-class-name.routing-name.required . For service beans produced with producer method replace bean-class-name with class-name.producer-method-name . Example (YAML) configuration for a service bean io.helidon.examples.AdminService that changes the routing name to management and its required flag to false : <markup lang=\"yaml\" >io.helidon.examples.AdminService: routing-name: name: \"management\" required: false ",
            "title": "Configuration override of routing name"
        },
        {
            "location": "/mp/server",
            "text": " Helidon has the concept of named routing. These correspond to the named ports configured with WebServer. You can assign an HTTP service to a named routing (and as a result to a named port) using either an annotation or configuration (or both to override the value from annotation). Annotation @RoutingName You can annotate a service bean with this annotation to assign it to a specific named routing, that is (most likely) going to be bound to a specific port. The annotation has two attributes: - value that defines the routing name - required to mark that the routing name MUST be configured in Helidon server <markup lang=\"java\" title=\" @RoutingName example\" >@ApplicationScoped @RoutingName(value=\"admin\", required=\"true\") @RoutingPath(\"/admin\") public class AdminService implements HttpService { } The example above will be bound to admin routing (and port) and will fail if such a port is not configured. Configuration override of routing name For each service bean you can define the routing name and its required flag by specifying a configuration option bean-class-name.routing-name.name and bean-class-name.routing-name.required . For service beans produced with producer method replace bean-class-name with class-name.producer-method-name . Example (YAML) configuration for a service bean io.helidon.examples.AdminService that changes the routing name to management and its required flag to false : <markup lang=\"yaml\" >io.helidon.examples.AdminService: routing-name: name: \"management\" required: false ",
            "title": "Assigning an HTTP service to named ports"
        },
        {
            "location": "/mp/server",
            "text": " You can configure @RoutingPath to define the path a service is registered on. ",
            "title": "Annotation @RoutingPath "
        },
        {
            "location": "/mp/server",
            "text": " For each HTTP service class you can define the routing path by specifying a configuration option class-name.routing-path.path . Example (YAML) configuration for a class io.helidon.example.AdminService that changes the routing path to /management : <markup lang=\"yaml\" >io.helidon.examples.AdminService: routing-path: path: \"/management\" ",
            "title": "Configuration override of routing path"
        },
        {
            "location": "/mp/server",
            "text": " Each service is registered on a path. If none is configured, then the service would be configured on the root path. You can configure service path using an annotation or configuration (or both to override value from annotation) Annotation @RoutingPath You can configure @RoutingPath to define the path a service is registered on. Configuration override of routing path For each HTTP service class you can define the routing path by specifying a configuration option class-name.routing-path.path . Example (YAML) configuration for a class io.helidon.example.AdminService that changes the routing path to /management : <markup lang=\"yaml\" >io.helidon.examples.AdminService: routing-path: path: \"/management\" ",
            "title": "Configuring an HTTP service path"
        },
        {
            "location": "/mp/server",
            "text": " Helidon MP Server will pick up CDI beans that implement the io.helidon.webserver.HttpService interface and configure them with the underlying WebServer. This allows configuration of WebServer routes to run alongside a JAX-RS application. The bean is expected to be either ApplicationScoped or Dependent and will be requested only once during the boot of the Server . The bean will support injection of ApplicationScoped and Dependent scoped beans. You cannot inject RequestScoped beans. Please use WebServer features to handle request related objects. Customizing the HTTP service The service can be customized using annotations and/or configuration to be registered on a specific path registered with a named routing Assigning an HTTP service to named ports Helidon has the concept of named routing. These correspond to the named ports configured with WebServer. You can assign an HTTP service to a named routing (and as a result to a named port) using either an annotation or configuration (or both to override the value from annotation). Annotation @RoutingName You can annotate a service bean with this annotation to assign it to a specific named routing, that is (most likely) going to be bound to a specific port. The annotation has two attributes: - value that defines the routing name - required to mark that the routing name MUST be configured in Helidon server <markup lang=\"java\" title=\" @RoutingName example\" >@ApplicationScoped @RoutingName(value=\"admin\", required=\"true\") @RoutingPath(\"/admin\") public class AdminService implements HttpService { } The example above will be bound to admin routing (and port) and will fail if such a port is not configured. Configuration override of routing name For each service bean you can define the routing name and its required flag by specifying a configuration option bean-class-name.routing-name.name and bean-class-name.routing-name.required . For service beans produced with producer method replace bean-class-name with class-name.producer-method-name . Example (YAML) configuration for a service bean io.helidon.examples.AdminService that changes the routing name to management and its required flag to false : <markup lang=\"yaml\" >io.helidon.examples.AdminService: routing-name: name: \"management\" required: false Configuring an HTTP service path Each service is registered on a path. If none is configured, then the service would be configured on the root path. You can configure service path using an annotation or configuration (or both to override value from annotation) Annotation @RoutingPath You can configure @RoutingPath to define the path a service is registered on. Configuration override of routing path For each HTTP service class you can define the routing path by specifying a configuration option class-name.routing-path.path . Example (YAML) configuration for a class io.helidon.example.AdminService that changes the routing path to /management : <markup lang=\"yaml\" >io.helidon.examples.AdminService: routing-path: path: \"/management\" ",
            "title": "Configuring A WebServer Route [["
        },
        {
            "location": "/mp/server",
            "text": "<markup lang=\"properties\" title=\"META-INF/microprofile-config.properties - File system static content\" ># Location of content on file system server.static.path.location=/var/www/html # default is index.html server.static.path.welcome=resource.html # static content path - default is \"/\" # server.static.path.context=/static-file <markup lang=\"properties\" title=\"META-INF/microprofile-config.properties - Classpath static content\" ># src/main/resources/WEB in your source tree server.static.classpath.location=/WEB # default is index.html server.static.classpath.welcome=resource.html # static content path - default is \"/\" # server.static.classpath.context=/static-cp ",
            "title": "Serving Static Content"
        },
        {
            "location": "/mp/server",
            "text": " A full configuration example (YAML): <markup lang=\"yaml\" >server: port: 8080 sockets: management: port: 8090 io.helidon.examples.AdminApplication: routing-name: name: \"management\" required: true routing-path: path: \"/management\" ",
            "title": "Example configuration of routing"
        },
        {
            "location": "/mp/server",
            "text": " You can use configuration to set up the requested URI discovery behavior. <markup lang=\"properties\" title=\"Configuring Request URI Discovery (properties format)\" >server.port=8080 server.requested-uri-discovery.types=FORWARDED,X_FORWARDED server.requested-uri-discovery.trusted-proxies.allow.pattern=lb.*\\\\.mycorp\\\\.com server.requested-uri-discovery.trusted-proxies.deny.exact=lbtest.mycorp.com This example might apply if mycorp.com had trusted load balancers named lbxxx.mycorp.com except for an untrusted test load balancer lbtest.mycorp.com . ",
            "title": "Setting Up Requested URI Discovery"
        },
        {
            "location": "/mp/server",
            "text": " Helidon makes the requested URI information available as a property in the request context: <markup lang=\"java\" title=\"Retrieving Requested URI Information\" >import io.helidon.common.uri.UriInfo; public class MyFilter implements ContainerRequestFilter { @Override public void filter(ContainerRequestContext requestContext) { UriInfo uriInfo = (UriInfo) requestContext.getProperty(\"io.helidon.jaxrs.requested-uri\"); // ... } } See the UriInfo JavaDoc for more information. The requestContext.getUriInfo() method returns the Jakarta RESTful web services UriInfo object, not the Helidon-provided requested URI information UriInfo record. ",
            "title": "Obtaining the Requested URI Information"
        },
        {
            "location": "/mp/server",
            "text": " Proxies and reverse proxies between an HTTP client and your Helidon application mask important information (for example Host header, originating IP address, protocol) about the request the client sent. Fortunately, many of these intermediary network nodes set or update either the standard HTTP Forwarded header or the non-standard X-Forwarded-* family of headers to preserve information about the original client request. Helidon&#8217;s requested URI discovery feature allows your application&#8212;&#8203;and Helidon itself&#8212;&#8203;to reconstruct information about the original request using the Forwarded header and the X-Forwarded-* family of headers. When you prepare the connections in your server you can include the following optional requested URI discovery settings: enabled or disabled which type or types of requested URI discovery to use: FORWARDED - uses the Forwarded header X_FORWARDED - uses the X-Forwarded-* headers HOST - uses the Host header what intermediate nodes to trust When your application receives a request Helidon iterates through the discovery types you set up for the receiving connection, gathering information from the corresponding header(s) for that type. If the request does not have the corresponding header(s), or your settings do not trust the intermediate nodes reflected in those headers, then Helidon tries the next discovery type you set up. Helidon uses the HOST discovery type if you do not set up discovery yourself or if, for a particular request, it cannot assemble the request information using any discovery type you did set up for the socket. Setting Up Requested URI Discovery You can use configuration to set up the requested URI discovery behavior. <markup lang=\"properties\" title=\"Configuring Request URI Discovery (properties format)\" >server.port=8080 server.requested-uri-discovery.types=FORWARDED,X_FORWARDED server.requested-uri-discovery.trusted-proxies.allow.pattern=lb.*\\\\.mycorp\\\\.com server.requested-uri-discovery.trusted-proxies.deny.exact=lbtest.mycorp.com This example might apply if mycorp.com had trusted load balancers named lbxxx.mycorp.com except for an untrusted test load balancer lbtest.mycorp.com . Obtaining the Requested URI Information Helidon makes the requested URI information available as a property in the request context: <markup lang=\"java\" title=\"Retrieving Requested URI Information\" >import io.helidon.common.uri.UriInfo; public class MyFilter implements ContainerRequestFilter { @Override public void filter(ContainerRequestContext requestContext) { UriInfo uriInfo = (UriInfo) requestContext.getProperty(\"io.helidon.jaxrs.requested-uri\"); // ... } } See the UriInfo JavaDoc for more information. The requestContext.getUriInfo() method returns the Jakarta RESTful web services UriInfo object, not the Helidon-provided requested URI information UriInfo record. ",
            "title": "Using Requested URI Discovery"
        },
        {
            "location": "/mp/server",
            "text": " Type: io.helidon.webserver.accesslog.AccessLogFeature <markup lang=\"text\" title=\"Config key\" >access-log This type provides the following service implementations: io.helidon.webserver.spi.ServerFeatureProvider Configuration options Optional configuration options key type default value description enabled boolean true Whether this feature will be enabled. @return whether enabled format string &#160; The format for log entries (similar to the Apache LogFormat ). &lt;table class=\"config\"&gt; &lt;caption&gt;Log format elements&lt;/caption&gt; &lt;tr&gt; &lt;td&gt;%h&lt;/td&gt; &lt;td&gt;IP address of the remote host&lt;/td&gt; &lt;td&gt;HostLogEntry&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;%l&lt;/td&gt; &lt;td&gt;The client identity. This is always undefined in Helidon.&lt;/td&gt; &lt;td&gt;UserIdLogEntry&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;%u&lt;/td&gt; &lt;td&gt;User ID as asserted by Helidon Security.&lt;/td&gt; &lt;td&gt;UserLogEntry&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;%t&lt;/td&gt; &lt;td&gt;The timestamp&lt;/td&gt; &lt;td&gt;TimestampLogEntry&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;%r&lt;/td&gt; &lt;td&gt;The request line ( \"GET /favicon.ico HTTP/1.0\" )&lt;/td&gt; &lt;td&gt;RequestLineLogEntry&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;%s&lt;/td&gt; &lt;td&gt;The status code returned to the client&lt;/td&gt; &lt;td&gt;StatusLogEntry&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;%b&lt;/td&gt; &lt;td&gt;The entity size in bytes&lt;/td&gt; &lt;td&gt;SizeLogEntry&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;%D&lt;/td&gt; &lt;td&gt;The time taken in microseconds (start of request until last byte written)&lt;/td&gt; &lt;td&gt;TimeTakenLogEntry&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;%T&lt;/td&gt; &lt;td&gt;The time taken in seconds (start of request until last byte written), integer&lt;/td&gt; &lt;td&gt;TimeTakenLogEntry&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;%{header-name}i&lt;/td&gt; &lt;td&gt;Value of header header-name &lt;/td&gt; &lt;td&gt;HeaderLogEntry&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; @return format string, such as `%h %l %u %t %r %b %{Referer`i} logger-name string io.helidon.webserver.AccessLog Name of the logger used to obtain access log logger from System#getLogger(String). Defaults to AccessLogFeature#DEFAULT_LOGGER_NAME . @return name of the logger to use sockets string[&#93; &#160; List of sockets to register this feature on. If empty, it would get registered on all sockets. The logger used will have the expected logger with a suffix of the socket name. @return socket names to register on, defaults to empty (all available sockets) weight double 1000.0 Weight of the access log feature. We need to log access for anything happening on the server, so weight is high: io.helidon.webserver.accesslog.AccessLogFeature#WEIGHT . @return weight of the feature Configuring TLS Helidon MP also supports custom TLS configuration. You can set the following properties: Server truststore Keystore with trusted certificates Private key and certificate Server certificate which will be used in TLS handshake <markup lang=\"properties\" title=\"META-INF/microprofile-config.properties - Server configuration\" >#Truststore setup server.tls.trust.keystore.resource.resource-path=server.p12 server.tls.trust.keystore.passphrase=password server.tls.trust.keystore.trust-store=true #Keystore with private key and server certificate server.tls.private-key.keystore.resource.resource-path=server.p12 server.tls.private-key.keystore.passphrase=password Or the same configuration done in application.yaml file. <markup lang=\"yaml\" title=\"application.yaml - Server configuration\" >server: tls: #Truststore setup trust: keystore: passphrase: \"password\" trust-store: true resource: resource-path: \"keystore.p12\" #Keystore with private key and server certificate private-key: keystore: passphrase: \"password\" resource: resource-path: \"keystore.p12\" Configuring additional ports Helidon MP can expose multiple ports, with the following limitations: The default port is the port that serves your application (JAX-RS applications and resources) Other ports (in this example we configure one \"admin\" port) can be assigned endpoints that are exposed by Helidon components, currently supported by MP Health and MP Metrics For this example, we will use a YAML file: The port 7011 is the default port and will serve your application The port 8011 is named \"admin\" (this is an arbitrary name) MP Metrics are configured to use the \"admin\" port through the routing configuration (reference is by name) MP Health is configured the same way to reference the \"admin\" port <markup lang=\"yaml\" title=\"application.yaml - Server configuration\" >server: port: 7011 host: \"some.host\" sockets: admin: port: 8011 bind-address: \"some.host\" metrics: routing: \"admin\" health: routing: \"admin\" Configuring A WebServer Route [[ Helidon MP Server will pick up CDI beans that implement the io.helidon.webserver.HttpService interface and configure them with the underlying WebServer. This allows configuration of WebServer routes to run alongside a JAX-RS application. The bean is expected to be either ApplicationScoped or Dependent and will be requested only once during the boot of the Server . The bean will support injection of ApplicationScoped and Dependent scoped beans. You cannot inject RequestScoped beans. Please use WebServer features to handle request related objects. Customizing the HTTP service The service can be customized using annotations and/or configuration to be registered on a specific path registered with a named routing Assigning an HTTP service to named ports Helidon has the concept of named routing. These correspond to the named ports configured with WebServer. You can assign an HTTP service to a named routing (and as a result to a named port) using either an annotation or configuration (or both to override the value from annotation). Annotation @RoutingName You can annotate a service bean with this annotation to assign it to a specific named routing, that is (most likely) going to be bound to a specific port. The annotation has two attributes: - value that defines the routing name - required to mark that the routing name MUST be configured in Helidon server <markup lang=\"java\" title=\" @RoutingName example\" >@ApplicationScoped @RoutingName(value=\"admin\", required=\"true\") @RoutingPath(\"/admin\") public class AdminService implements HttpService { } The example above will be bound to admin routing (and port) and will fail if such a port is not configured. Configuration override of routing name For each service bean you can define the routing name and its required flag by specifying a configuration option bean-class-name.routing-name.name and bean-class-name.routing-name.required . For service beans produced with producer method replace bean-class-name with class-name.producer-method-name . Example (YAML) configuration for a service bean io.helidon.examples.AdminService that changes the routing name to management and its required flag to false : <markup lang=\"yaml\" >io.helidon.examples.AdminService: routing-name: name: \"management\" required: false Configuring an HTTP service path Each service is registered on a path. If none is configured, then the service would be configured on the root path. You can configure service path using an annotation or configuration (or both to override value from annotation) Annotation @RoutingPath You can configure @RoutingPath to define the path a service is registered on. Configuration override of routing path For each HTTP service class you can define the routing path by specifying a configuration option class-name.routing-path.path . Example (YAML) configuration for a class io.helidon.example.AdminService that changes the routing path to /management : <markup lang=\"yaml\" >io.helidon.examples.AdminService: routing-path: path: \"/management\" Serving Static Content <markup lang=\"properties\" title=\"META-INF/microprofile-config.properties - File system static content\" ># Location of content on file system server.static.path.location=/var/www/html # default is index.html server.static.path.welcome=resource.html # static content path - default is \"/\" # server.static.path.context=/static-file <markup lang=\"properties\" title=\"META-INF/microprofile-config.properties - Classpath static content\" ># src/main/resources/WEB in your source tree server.static.classpath.location=/WEB # default is index.html server.static.classpath.welcome=resource.html # static content path - default is \"/\" # server.static.classpath.context=/static-cp Example configuration of routing A full configuration example (YAML): <markup lang=\"yaml\" >server: port: 8080 sockets: management: port: 8090 io.helidon.examples.AdminApplication: routing-name: name: \"management\" required: true routing-path: path: \"/management\" Using Requested URI Discovery Proxies and reverse proxies between an HTTP client and your Helidon application mask important information (for example Host header, originating IP address, protocol) about the request the client sent. Fortunately, many of these intermediary network nodes set or update either the standard HTTP Forwarded header or the non-standard X-Forwarded-* family of headers to preserve information about the original client request. Helidon&#8217;s requested URI discovery feature allows your application&#8212;&#8203;and Helidon itself&#8212;&#8203;to reconstruct information about the original request using the Forwarded header and the X-Forwarded-* family of headers. When you prepare the connections in your server you can include the following optional requested URI discovery settings: enabled or disabled which type or types of requested URI discovery to use: FORWARDED - uses the Forwarded header X_FORWARDED - uses the X-Forwarded-* headers HOST - uses the Host header what intermediate nodes to trust When your application receives a request Helidon iterates through the discovery types you set up for the receiving connection, gathering information from the corresponding header(s) for that type. If the request does not have the corresponding header(s), or your settings do not trust the intermediate nodes reflected in those headers, then Helidon tries the next discovery type you set up. Helidon uses the HOST discovery type if you do not set up discovery yourself or if, for a particular request, it cannot assemble the request information using any discovery type you did set up for the socket. Setting Up Requested URI Discovery You can use configuration to set up the requested URI discovery behavior. <markup lang=\"properties\" title=\"Configuring Request URI Discovery (properties format)\" >server.port=8080 server.requested-uri-discovery.types=FORWARDED,X_FORWARDED server.requested-uri-discovery.trusted-proxies.allow.pattern=lb.*\\\\.mycorp\\\\.com server.requested-uri-discovery.trusted-proxies.deny.exact=lbtest.mycorp.com This example might apply if mycorp.com had trusted load balancers named lbxxx.mycorp.com except for an untrusted test load balancer lbtest.mycorp.com . Obtaining the Requested URI Information Helidon makes the requested URI information available as a property in the request context: <markup lang=\"java\" title=\"Retrieving Requested URI Information\" >import io.helidon.common.uri.UriInfo; public class MyFilter implements ContainerRequestFilter { @Override public void filter(ContainerRequestContext requestContext) { UriInfo uriInfo = (UriInfo) requestContext.getProperty(\"io.helidon.jaxrs.requested-uri\"); // ... } } See the UriInfo JavaDoc for more information. The requestContext.getUriInfo() method returns the Jakarta RESTful web services UriInfo object, not the Helidon-provided requested URI information UriInfo record. ",
            "title": "AccessLogFeature (webserver.accesslog) Configuration"
        },
        {
            "location": "/mp/server",
            "text": " Helidon MicroProfile Server Javadoc Helidon MicroProfile Server on GitHub ",
            "title": "Reference"
        },
        {
            "location": "/mp/telemetry",
            "text": " Overview Maven Coordinates Usage Configuration Examples Reference ",
            "title": "Contents"
        },
        {
            "location": "/mp/telemetry",
            "text": "",
            "title": "Overview"
        },
        {
            "location": "/mp/telemetry",
            "text": " To enable MicroProfile Telemetry either add a dependency on the helidon-microprofile bundle or add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.telemetry&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-telemetry&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/telemetry",
            "text": " You can inject OpenTelemetry Tracer using the regular @Inject annotation and use SpanBuilder to manually create, star and stop spans. <markup lang=\"java\" title=\"SpanBuilder usage\" >@Path(\"/\") public class HelidonEndpoint { @Inject Tracer tracer; @GET @Path(\"/span\") public Response span() { Span span = tracer.spanBuilder(\"new\") .setSpanKind(SpanKind.CLIENT) .setAttribute(\"someAttribute\", \"someValue\") .startSpan(); span.end(); return Response.ok().build(); } } Inject Tracer . Use Tracer.spanBuilder to create and start new Span . Helidon Microprofile Telemetry is integrated with Helidon Tracing API . This means that both APIs can be mixed, and all parent hierarchies will be kept. In the case below, @WithSpan annotated method is mixed with manually created io.helidon.tracing.Span : <markup lang=\"java\" title=\"Inject Helidon Tracer\" >private io.helidon.tracing.Tracer helidonTracerInjected; @Inject GreetResource(io.helidon.tracing.Tracer helidonTracerInjected) { this.helidonTracerInjected = helidonTracerInjected; } @GET @Path(\"mixed_injected\") @Produces(MediaType.APPLICATION_JSON) @WithSpan(\"mixed_parent_injected\") public GreetingMessage mixedSpanInjected() { io.helidon.tracing.Span mixedSpan = helidonTracerInjected.spanBuilder(\"mixed_injected\") .kind(io.helidon.tracing.Span.Kind.SERVER) .tag(\"attribute\", \"value\") .start(); mixedSpan.end(); return new GreetingMessage(\"Mixed Span Injected\" + span); } Inject io.helidon.tracing.Tracer . Use the injected tracer to create io.helidon.tracing.Span using the spanBuilder() method. The span is then started and ended manually. Span parent relations will be preserved. This means that span named \"mixed_injected\" with have parent span named \"mixed_parent_injected\", which will have parent span named \"mixed_injected\". Another option is to use the Global Tracer: <markup lang=\"java\" title=\"Obtain the Global tracer\" >@GET @Path(\"mixed\") @Produces(MediaType.APPLICATION_JSON) @WithSpan(\"mixed_parent\") public GreetingMessage mixedSpan() { io.helidon.tracing.Tracer helidonTracer = io.helidon.tracing.Tracer.global(); io.helidon.tracing.Span mixedSpan = helidonTracer.spanBuilder(\"mixed\") .kind(io.helidon.tracing.Span.Kind.SERVER) .tag(\"attribute\", \"value\") .start(); mixedSpan.end(); return new GreetingMessage(\"Mixed Span\" + span); } Obtain tracer using the io.helidon.tracing.Tracer.global() method; Use the created tracer to create a span. The span is then started and ended manually. Span parent relations will be preserved. ",
            "title": "Working With Tracers"
        },
        {
            "location": "/mp/telemetry",
            "text": " To obtain the current span, it can be injected by CDI. The current span can also be obtained using the static method Span.current() . <markup lang=\"java\" title=\"Inject the current span\" >@Path(\"/\") public class HelidonEndpoint { @Inject Span span; @GET @Path(\"/current\") public Response currentSpan() { return Response.ok(span.getAttribute(\"someAttribute\")).build(); } @GET @Path(\"/current/static\") public Response currentSpanStatic() { return Response.ok(Span.current().getAttribute(\"someAttribute\")).build(); } } Inject the current span. Use the injected span. Use Span.current() to access the current span. ",
            "title": "Working With Spans"
        },
        {
            "location": "/mp/telemetry",
            "text": " The same functionality is available for the Baggage API: <markup lang=\"java\" title=\"Inject the current baggage\" >@Path(\"/\") public class HelidonEndpoint { @Inject Baggage baggage; @GET @Path(\"/current\") public Response currentBaggage() { return Response.ok(baggage.get(\"baggageKey\")).build(); } @GET @Path(\"/current/static\") public Response currentBaggageStatic() { return Response.ok(Baggage.current().get(\"baggageKey\")).build(); } } Inject the current baggage. Use the injected baggage. Use Baggage.current() to access the current baggage. ",
            "title": "Working With Baggage"
        },
        {
            "location": "/mp/telemetry",
            "text": " OpenTelemetry comprises a collection of APIs, SDKs, integration tools, and other software components intended to facilitate the generation and control of telemetry data, including traces, metrics, and logs. In an environment where distributed tracing is enabled via OpenTelemetry (which combines OpenTracing and OpenCensus), this specification establishes the necessary behaviors for MicroProfile applications to participate seamlessly. MicroProfile Telemetry 1.0 allows for the exportation of the data it collects to Jaeger or Zipkin and to other systems using a variety of exporters. In a distributed tracing system, traces are used to capture a series of requests and are composed of multiple spans that represent individual operations within those requests. Each span includes a name, timestamps, and metadata that provide insights into the corresponding operation. Context is included in each span to identify the specific request that it belongs to. This context information is crucial for tracking requests across various components in a distributed system, enabling developers to trace a single request as it traverses through multiple services. Finally, exporters are responsible for transmitting the collected trace data to a backend service for monitoring and visualization. This enables developers to gain a comprehensive understanding of the system&#8217;s behavior and detect any issues or bottlenecks that may arise. There are two ways to work with Telemetry, using: Automatic Instrumentation Manual Instrumentation For Automatic Instrumentation, OpenTelemetry provides a JavaAgent. The Tracing API allows for the automatic participation in distributed tracing of Jakarta RESTful Web Services (both server and client) as well as MicroProfile REST Clients, without requiring any modifications to the code. This is achieved through automatic instrumentation. For Manual Instrumentation, there is a set of annotations and access to OpenTelemetry API. @WithSpan - By adding this annotation to a method in any Jakarta CDI aware bean, a new span will be created and any necessary connections to the current Trace context will be established. Additionally, the SpanAttribute annotation can be used to mark method parameters that should be included in the Trace. Helidon provides full access to OpenTelemetry Tracing API: io.opentelemetry.api.OpenTelemetry io.opentelemetry.api.trace.Tracer io.opentelemetry.api.trace.Span io.opentelemetry.api.baggage.Baggage Accessing and using these objects can be done as follows. For span: <markup lang=\"java\" title=\"Span sample\" >@ApplicationScoped class HelidonBean { @WithSpan void doSomethingWithinSpan() { // do something here } @WithSpan(\"name\") void complexSpan(@SpanAttribute(value = \"arg\") String arg) { // do something here } } Simple @WithSpan annotation usage. Additional attributes can be set on a method. Working With Tracers You can inject OpenTelemetry Tracer using the regular @Inject annotation and use SpanBuilder to manually create, star and stop spans. <markup lang=\"java\" title=\"SpanBuilder usage\" >@Path(\"/\") public class HelidonEndpoint { @Inject Tracer tracer; @GET @Path(\"/span\") public Response span() { Span span = tracer.spanBuilder(\"new\") .setSpanKind(SpanKind.CLIENT) .setAttribute(\"someAttribute\", \"someValue\") .startSpan(); span.end(); return Response.ok().build(); } } Inject Tracer . Use Tracer.spanBuilder to create and start new Span . Helidon Microprofile Telemetry is integrated with Helidon Tracing API . This means that both APIs can be mixed, and all parent hierarchies will be kept. In the case below, @WithSpan annotated method is mixed with manually created io.helidon.tracing.Span : <markup lang=\"java\" title=\"Inject Helidon Tracer\" >private io.helidon.tracing.Tracer helidonTracerInjected; @Inject GreetResource(io.helidon.tracing.Tracer helidonTracerInjected) { this.helidonTracerInjected = helidonTracerInjected; } @GET @Path(\"mixed_injected\") @Produces(MediaType.APPLICATION_JSON) @WithSpan(\"mixed_parent_injected\") public GreetingMessage mixedSpanInjected() { io.helidon.tracing.Span mixedSpan = helidonTracerInjected.spanBuilder(\"mixed_injected\") .kind(io.helidon.tracing.Span.Kind.SERVER) .tag(\"attribute\", \"value\") .start(); mixedSpan.end(); return new GreetingMessage(\"Mixed Span Injected\" + span); } Inject io.helidon.tracing.Tracer . Use the injected tracer to create io.helidon.tracing.Span using the spanBuilder() method. The span is then started and ended manually. Span parent relations will be preserved. This means that span named \"mixed_injected\" with have parent span named \"mixed_parent_injected\", which will have parent span named \"mixed_injected\". Another option is to use the Global Tracer: <markup lang=\"java\" title=\"Obtain the Global tracer\" >@GET @Path(\"mixed\") @Produces(MediaType.APPLICATION_JSON) @WithSpan(\"mixed_parent\") public GreetingMessage mixedSpan() { io.helidon.tracing.Tracer helidonTracer = io.helidon.tracing.Tracer.global(); io.helidon.tracing.Span mixedSpan = helidonTracer.spanBuilder(\"mixed\") .kind(io.helidon.tracing.Span.Kind.SERVER) .tag(\"attribute\", \"value\") .start(); mixedSpan.end(); return new GreetingMessage(\"Mixed Span\" + span); } Obtain tracer using the io.helidon.tracing.Tracer.global() method; Use the created tracer to create a span. The span is then started and ended manually. Span parent relations will be preserved. Working With Spans To obtain the current span, it can be injected by CDI. The current span can also be obtained using the static method Span.current() . <markup lang=\"java\" title=\"Inject the current span\" >@Path(\"/\") public class HelidonEndpoint { @Inject Span span; @GET @Path(\"/current\") public Response currentSpan() { return Response.ok(span.getAttribute(\"someAttribute\")).build(); } @GET @Path(\"/current/static\") public Response currentSpanStatic() { return Response.ok(Span.current().getAttribute(\"someAttribute\")).build(); } } Inject the current span. Use the injected span. Use Span.current() to access the current span. Working With Baggage The same functionality is available for the Baggage API: <markup lang=\"java\" title=\"Inject the current baggage\" >@Path(\"/\") public class HelidonEndpoint { @Inject Baggage baggage; @GET @Path(\"/current\") public Response currentBaggage() { return Response.ok(baggage.get(\"baggageKey\")).build(); } @GET @Path(\"/current/static\") public Response currentBaggageStatic() { return Response.ok(Baggage.current().get(\"baggageKey\")).build(); } } Inject the current baggage. Use the injected baggage. Use Baggage.current() to access the current baggage. ",
            "title": "Usage"
        },
        {
            "location": "/mp/telemetry",
            "text": " The OpenTelemetry Java Agent may influence the work of MicroProfile Telemetry, on how the objects are created and configured. Helidon will do \"best effort\" to detect the use of the agent. But if there is a decision to run the Helidon app with the agent, a configuration property should be set: otel.agent.present=true This way, Helidon will explicitly get all the configuration and objects from the Agent, thus allowing correct span hierarchy settings. ",
            "title": "OpenTelemetry Java Agent"
        },
        {
            "location": "/mp/telemetry",
            "text": " MicroProfile Telemetry is not activated by default. To activate this feature, you need to specify the configuration otel.sdk.disabled=false in one of the MicroProfile Config or other config sources. To configure OpenTelemetry, MicroProfile Config must be used, and the configuration properties outlined in the following sections must be followed: OpenTelemetry SDK Autoconfigure (excluding properties related to Metrics and Logging) Manual Instrumentation Please consult with the links above for all configurations' properties usage. The property should be declared in microprofile-config.properties file to be processed correctly. OpenTelemetry Java Agent The OpenTelemetry Java Agent may influence the work of MicroProfile Telemetry, on how the objects are created and configured. Helidon will do \"best effort\" to detect the use of the agent. But if there is a decision to run the Helidon app with the agent, a configuration property should be set: otel.agent.present=true This way, Helidon will explicitly get all the configuration and objects from the Agent, thus allowing correct span hierarchy settings. ",
            "title": "Configuration"
        },
        {
            "location": "/mp/telemetry",
            "text": " For example, Jaeger will be used for gathering of the tracing information. <markup lang=\"bash\" title=\"Run Jaeger in a docker container.\" >docker run -d --name jaeger \\ -e COLLECTOR_ZIPKIN_HOST_PORT=:9411 \\ -e COLLECTOR_OTLP_ENABLED=true \\ -p 6831:6831/udp \\ -p 6832:6832/udp \\ -p 5778:5778 \\ -p 16686:16686 \\ -p 4317:4317 \\ -p 4318:4318 \\ -p 14250:14250 \\ -p 14268:14268 \\ -p 14269:14269 \\ -p 9411:9411 \\ jaegertracing/all-in-one:1.50 All the tracing information gathered from the examples runs is accessible from the browser in the Jaeger UI under http://localhost:16686/ ",
            "title": "Set Up Jaeger"
        },
        {
            "location": "/mp/telemetry",
            "text": " Together with Helidon Telemetry dependency, an OpenTelemetry Exporter dependency should be added to project&#8217;s pom.xml file. <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.telemetry&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-telemetry&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.opentelemetry&lt;/groupId&gt; &lt;artifactId&gt;opentelemetry-exporter-jaeger&lt;/artifactId&gt; &lt;/dependency&gt; Helidon Telemetry dependency. OpenTelemetry Jaeger exporter. Add these lines to META-INF/microprofile-config.properties : <markup lang=\"properties\" title=\"MicroProfile Telemetry properties\" >otel.sdk.disabled=false otel.traces.exporter=jaeger otel.exporter.name=greeting-service Enable MicroProfile Telemetry. Set exporter to Jaeger. Name of our service. Here we enable MicroProfile Telemetry, set tracer to \"jaeger\" and give a name, which will be used to identify our service in the tracer. Note For this example, you will use Jaeger to manage data tracing. If you prefer to use Zipkin, please set otel.traces.exporter property to \"zipkin\". For more information using about Zipkin, see https://zipkin.io/ . Also, a corresponding Maven dependency for the exporter should be added: &lt;dependency&gt; &lt;groupId&gt;io.opentelemetry&lt;/groupId&gt; &lt;artifactId&gt;opentelemetry-exporter-zipkin&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Enable MicroProfile Telemetry in Helidon Application"
        },
        {
            "location": "/mp/telemetry",
            "text": " To create simple services, use @WithSpan and Tracer to create span and let MicroProfile OpenTelemetry handle them. <markup lang=\"java\" >@Path(\"/greet\") public class GreetResource { @GET @WithSpan(\"default\") public String getDefaultMessage() { return \"Hello World\"; } } Use of @WithSpan with name \"default\". Now let&#8217;s call the Greeting endpoint: <markup lang=\"bash\" >curl localhost:8080/greet Hello World Next, launch the Jaeger UI at http://localhost:16686/ . The expected output is: <markup lang=\"java\" title=\"Custom method\" >@Inject private Tracer tracer; @GET @Path(\"custom\") @Produces(MediaType.APPLICATION_JSON) @WithSpan public JsonObject useCustomSpan(){ Span span = tracer.spanBuilder(\"custom\") .setSpanKind(SpanKind.INTERNAL) .setAttribute(\"attribute\", \"value\") .startSpan(); span.end(); return JSON.createObjectBuilder() .add(\"Custom Span\", span.toString()) .build(); } Inject Opentelemetry Tracer . Create a span around the method useCustomSpan() . Create a custom INTERNAL span and start it. End the custom span. Let us call the custom endpoint: <markup lang=\"bash\" >curl localhost:8080/greeting/custom Again you can launch the Jaeger UI at http://localhost:16686/ . The expected output is: Now let us use multiple services calls. In the example below our main service will call the secondary services. Each method in each service will be annotated with @WithSpan annotation. <markup lang=\"java\" title=\"Outbound method\" >@Uri(\"http://localhost:8081/secondary\") private WebTarget target; @GET @Path(\"/outbound\") @WithSpan(\"outbound\") public String outbound() { return target.request().accept(MediaType.TEXT_PLAIN).get(String.class); } Inject WebTarget pointing to Secondary service. Wrap method using WithSpan . Call the secondary service. The secondary service is basic; it has only one method, which is also annotated with @WithSpan . <markup lang=\"java\" title=\"Secondary service\" >@GET @WithSpan public String getSecondaryMessage() { return \"Secondary\"; } Wrap method in a span. Return a string. Let us call the Outbound endpoint: <markup lang=\"bash\" >curl localhost:8080/greet/outbound Secondary The greeting-service call secondary-service . Each service will create spans with corresponding names, and a service class hierarchy will be created. Launch the Jaeger UI at http://localhost:16686/ to see the expected output (shown below). This example is available at the Helidon official GitHub repository . ",
            "title": "Tracing at Method Level"
        },
        {
            "location": "/mp/telemetry",
            "text": " This guide demonstrates how to incorporate MicroProfile Telemetry into Helidon and provides illustrations of how to view traces. Jaeger is employed in all the examples, and the Jaeger UI is used to view the traces. Set Up Jaeger For example, Jaeger will be used for gathering of the tracing information. <markup lang=\"bash\" title=\"Run Jaeger in a docker container.\" >docker run -d --name jaeger \\ -e COLLECTOR_ZIPKIN_HOST_PORT=:9411 \\ -e COLLECTOR_OTLP_ENABLED=true \\ -p 6831:6831/udp \\ -p 6832:6832/udp \\ -p 5778:5778 \\ -p 16686:16686 \\ -p 4317:4317 \\ -p 4318:4318 \\ -p 14250:14250 \\ -p 14268:14268 \\ -p 14269:14269 \\ -p 9411:9411 \\ jaegertracing/all-in-one:1.50 All the tracing information gathered from the examples runs is accessible from the browser in the Jaeger UI under http://localhost:16686/ Enable MicroProfile Telemetry in Helidon Application Together with Helidon Telemetry dependency, an OpenTelemetry Exporter dependency should be added to project&#8217;s pom.xml file. <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.telemetry&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-telemetry&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.opentelemetry&lt;/groupId&gt; &lt;artifactId&gt;opentelemetry-exporter-jaeger&lt;/artifactId&gt; &lt;/dependency&gt; Helidon Telemetry dependency. OpenTelemetry Jaeger exporter. Add these lines to META-INF/microprofile-config.properties : <markup lang=\"properties\" title=\"MicroProfile Telemetry properties\" >otel.sdk.disabled=false otel.traces.exporter=jaeger otel.exporter.name=greeting-service Enable MicroProfile Telemetry. Set exporter to Jaeger. Name of our service. Here we enable MicroProfile Telemetry, set tracer to \"jaeger\" and give a name, which will be used to identify our service in the tracer. Note For this example, you will use Jaeger to manage data tracing. If you prefer to use Zipkin, please set otel.traces.exporter property to \"zipkin\". For more information using about Zipkin, see https://zipkin.io/ . Also, a corresponding Maven dependency for the exporter should be added: &lt;dependency&gt; &lt;groupId&gt;io.opentelemetry&lt;/groupId&gt; &lt;artifactId&gt;opentelemetry-exporter-zipkin&lt;/artifactId&gt; &lt;/dependency&gt; Tracing at Method Level To create simple services, use @WithSpan and Tracer to create span and let MicroProfile OpenTelemetry handle them. <markup lang=\"java\" >@Path(\"/greet\") public class GreetResource { @GET @WithSpan(\"default\") public String getDefaultMessage() { return \"Hello World\"; } } Use of @WithSpan with name \"default\". Now let&#8217;s call the Greeting endpoint: <markup lang=\"bash\" >curl localhost:8080/greet Hello World Next, launch the Jaeger UI at http://localhost:16686/ . The expected output is: <markup lang=\"java\" title=\"Custom method\" >@Inject private Tracer tracer; @GET @Path(\"custom\") @Produces(MediaType.APPLICATION_JSON) @WithSpan public JsonObject useCustomSpan(){ Span span = tracer.spanBuilder(\"custom\") .setSpanKind(SpanKind.INTERNAL) .setAttribute(\"attribute\", \"value\") .startSpan(); span.end(); return JSON.createObjectBuilder() .add(\"Custom Span\", span.toString()) .build(); } Inject Opentelemetry Tracer . Create a span around the method useCustomSpan() . Create a custom INTERNAL span and start it. End the custom span. Let us call the custom endpoint: <markup lang=\"bash\" >curl localhost:8080/greeting/custom Again you can launch the Jaeger UI at http://localhost:16686/ . The expected output is: Now let us use multiple services calls. In the example below our main service will call the secondary services. Each method in each service will be annotated with @WithSpan annotation. <markup lang=\"java\" title=\"Outbound method\" >@Uri(\"http://localhost:8081/secondary\") private WebTarget target; @GET @Path(\"/outbound\") @WithSpan(\"outbound\") public String outbound() { return target.request().accept(MediaType.TEXT_PLAIN).get(String.class); } Inject WebTarget pointing to Secondary service. Wrap method using WithSpan . Call the secondary service. The secondary service is basic; it has only one method, which is also annotated with @WithSpan . <markup lang=\"java\" title=\"Secondary service\" >@GET @WithSpan public String getSecondaryMessage() { return \"Secondary\"; } Wrap method in a span. Return a string. Let us call the Outbound endpoint: <markup lang=\"bash\" >curl localhost:8080/greet/outbound Secondary The greeting-service call secondary-service . Each service will create spans with corresponding names, and a service class hierarchy will be created. Launch the Jaeger UI at http://localhost:16686/ to see the expected output (shown below). This example is available at the Helidon official GitHub repository . ",
            "title": "Examples"
        },
        {
            "location": "/mp/telemetry",
            "text": " MicroProfile Telemetry Specification OpenTelemetry Documentation ",
            "title": "Reference"
        },
        {
            "location": "/mp/testing-ng",
            "text": " Overview Maven Coordinates Usage API Examples Reference ",
            "title": "Contents"
        },
        {
            "location": "/mp/testing-ng",
            "text": " Helidon provides built-in test support for CDI testing in TestNG. ",
            "title": "Overview"
        },
        {
            "location": "/mp/testing-ng",
            "text": " To enable Testing with TestNG add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.testing&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-testing-testng&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/testing-ng",
            "text": " A test can be annotated with io.helidon.microprofile.testing.testng.HelidonTest annotation to mark it as a CDI test. This annotation will start the CDI container before any test method is invoked, and stop it after the last method is invoked. This annotation also enables injection into the test class itself. ",
            "title": "Usage - default"
        },
        {
            "location": "/mp/testing-ng",
            "text": " A test can be annotated as follows: @HelidonTest(resetPerTest = true) This will change the behavior as follows: A new CDI container is created for each test method invocation annotations to add config, beans and extension can be added for each method in addition to the class you cannot inject fields or constructor parameters of the test class itself (as a single instance is shared by more containers) ",
            "title": "Usage - per method CDI container"
        },
        {
            "location": "/mp/testing-ng",
            "text": " In addition to the @AddConfig annotation, you can also use @Configuration to configure additional classpath properties config sources using configSources , and to mark that a custom configuration is desired. If @Configuration(useExisting=true) , the existing (or default) MicroProfile configuration would be used. In this case it is important to set property mp.initializer.allow=true in order CDI container to start, when used with @HelidonTest . You can set up config in @BeforeAll method and register it with ConfigProviderResolver using MP Config APIs, and declare @Configuration(useExisting=true) . Note that this is not compatible with repeatable tests that use method sources that access CDI, as we must delay the CDI startup to the test class instantiation (which is too late, as the method sources are already invoked by this time). If you want to use method sources that use CDI with repeatable tests, please do not use @Configuration(useExisting=true) Test method parameters are currently not supported. ",
            "title": "Usage - configuration"
        },
        {
            "location": "/mp/testing-ng",
            "text": " A test can be annotated with io.helidon.microprofile.testing.testng.HelidonTest annotation to mark it as a CDI test. This annotation will start the CDI container before any test method is invoked, and stop it after the last method is invoked. This annotation also enables injection into the test class itself. Usage - per method CDI container A test can be annotated as follows: @HelidonTest(resetPerTest = true) This will change the behavior as follows: A new CDI container is created for each test method invocation annotations to add config, beans and extension can be added for each method in addition to the class you cannot inject fields or constructor parameters of the test class itself (as a single instance is shared by more containers) Usage - configuration In addition to the @AddConfig annotation, you can also use @Configuration to configure additional classpath properties config sources using configSources , and to mark that a custom configuration is desired. If @Configuration(useExisting=true) , the existing (or default) MicroProfile configuration would be used. In this case it is important to set property mp.initializer.allow=true in order CDI container to start, when used with @HelidonTest . You can set up config in @BeforeAll method and register it with ConfigProviderResolver using MP Config APIs, and declare @Configuration(useExisting=true) . Note that this is not compatible with repeatable tests that use method sources that access CDI, as we must delay the CDI startup to the test class instantiation (which is too late, as the method sources are already invoked by this time). If you want to use method sources that use CDI with repeatable tests, please do not use @Configuration(useExisting=true) Test method parameters are currently not supported. ",
            "title": "Usage"
        },
        {
            "location": "/mp/testing-ng",
            "text": " The annotations described in this section are inherited (for the non-repeatable ones), and additive (for repeatable). So if you declare @DisableDiscovery on abstract class, all implementations will have discovery disabled, unless you annotate the implementation class with @DisableDiscovery(false) . If you declare @AddBean on both abstract class and implementation class, both beans will be added. In addition to this simplification, the following annotations are supported: Annotation Usage @io.helidon.microprofile.testing.testng.AddBean Used to add one or more beans to the container (if not part of a bean archive, or when discovery is disabled) @io.helidon.microprofile.testing.testng.AddExtension Used to add one or more CDI extensions to the container (if not added through service loader, or when discovery is disabled) @io.helidon.microprofile.testing.testng.AddConfig Used to add one or more configuration properties to MicroProfile config without the need of creating a microprofile-config.properties file @io.helidon.microprofile.testing.testng.DisableDiscovery Used to disable automated discovery of beans and extensions Used @io.helidon.microprofile.testing.junit5.AddJaxRs add JaxRs support to the test class. Only used with @DisableDiscovery annotation, otherwise an exception will be thrown. Automatically adds the following Beans and Extensions to the test class: ServerCdiExtension JaxRsCdiExtension CdiComponentProvider org.glassfish.jersey.ext.cdi1x.internal.ProcessAllAnnotatedTypes org.glassfish.jersey.weld.se.WeldRequestScope ",
            "title": "API"
        },
        {
            "location": "/mp/testing-ng",
            "text": " In the current example, Helidon container will be launched prior test. The Bean Discovery will be disabled. MyBean will be added to the test, so that it can be injected. ConfigCdiExtension will be enabled for this test. And finally, a configuration property will be added using @AddConfig annotation. <markup lang=\"java\" title=\"Code sample\" >@HelidonTest @DisableDiscovery @AddBean(MyBean.class) @AddExtension(ConfigCdiExtension.class) @AddConfig(key = \"app.greeting\", value = \"TestHello\") class TestExample { @Inject private MyBean myBean; @Test void testGreeting() { assertThat(myBean, notNullValue()); assertThat(myBean.greeting(), is(\"TestHello\")); } } Start the Helidon container. Set disabled Bean Discovery for the current test class. Add MyBean to current context. Add a configuration CDI extension to the current test. Add configuration properties. Inject MyBean as it is available in the CDI context. Run rests. To test @RequestScoped bean with JaxRs support: <markup lang=\"java\" title=\"Test RequestScoped bean\" >@HelidonTest @DisableDiscovery @AddJaxRs @AddBean(TestReqScopeDisabledDiscovery.MyController.class) public class TestReqScopeDisabledDiscovery { @Inject private WebTarget target; @Test void testGet() { assertEquals(\"Hallo!\", target .path(\"/greeting\") .request() .get(String.class)); } @Path(\"/greeting\") @RequestScoped public static class MyController { @GET public Response get() { return Response.ok(\"Hallo!\").build(); } } } Start the Helidon container. Set disabled Bean discovery. Add JaxRs support to the current test class. Define a RequestScoped bean. ",
            "title": "Examples"
        },
        {
            "location": "/mp/testing-ng",
            "text": " TestNG User Guide ",
            "title": "Reference"
        },
        {
            "location": "/mp/testing",
            "text": " Overview Maven Coordinates Usage Examples Additional Information Reference ",
            "title": "Contents"
        },
        {
            "location": "/mp/testing",
            "text": " Helidon provides built-in test support for CDI testing in JUnit5. ",
            "title": "Overview"
        },
        {
            "location": "/mp/testing",
            "text": " To enable Testing with JUnit add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.testing&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-testing-junit5&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/testing",
            "text": " A test can be annotated as follows: @HelidonTest(resetPerTest = true) This will change the behavior as follows: A new CDI container is created for each test method invocation annotations to add config, beans and extension can be added for each method in addition to the class you cannot inject fields or constructor parameters of the test class itself (as a single instance is shared by more containers) you can add SeContainer as a method parameter of any test method and you will get the current container ",
            "title": "Usage - per method CDI container"
        },
        {
            "location": "/mp/testing",
            "text": " In addition to the @AddConfig annotation, you can also use @Configuration to configure additional classpath properties config sources using configSources , and to mark that a custom configuration is desired. If @Configuration(useExisting=true) , the existing (or default) MicroProfile configuration would be used. In this case it is important to set property mp.initializer.allow=true in order CDI container to start, when used with @HelidonTest . You can set up config in @BeforeAll method and register it with ConfigProviderResolver using MP Config APIs, and declare @Configuration(useExisting=true) . Note that this is not compatible with repeatable tests that use method sources that access CDI, as we must delay the CDI startup to the test class instantiation (which is too late, as the method sources are already invoked by this time). If you want to use method sources that use CDI with repeatable tests, please do not use @Configuration(useExisting=true) ",
            "title": "Usage - configuration"
        },
        {
            "location": "/mp/testing",
            "text": " The following types are available for injection (when a single CDI container is used per test class): WebTarget - a JAX-RS client&#8217;s target configured for the current hostname and port when helidon-micorprofile-server is on the classpath The following types are available as method parameters (in any type of Helidon tests): WebTarget - a JAX-RS client&#8217;s target configured for the current hostname and port when helidon-micorprofile-server is on the classpath SeContainer - the current container instance ",
            "title": "Usage - added parameters and injection types"
        },
        {
            "location": "/mp/testing",
            "text": " A test can be annotated with io.helidon.microprofile.testing.junit5.HelidonTest annotation to mark it as a CDI test. This annotation will start the CDI container before any test method is invoked, and stop it after the last method is invoked. This annotation also enables injection into the test class itself. Usage - per method CDI container A test can be annotated as follows: @HelidonTest(resetPerTest = true) This will change the behavior as follows: A new CDI container is created for each test method invocation annotations to add config, beans and extension can be added for each method in addition to the class you cannot inject fields or constructor parameters of the test class itself (as a single instance is shared by more containers) you can add SeContainer as a method parameter of any test method and you will get the current container Usage - configuration In addition to the @AddConfig annotation, you can also use @Configuration to configure additional classpath properties config sources using configSources , and to mark that a custom configuration is desired. If @Configuration(useExisting=true) , the existing (or default) MicroProfile configuration would be used. In this case it is important to set property mp.initializer.allow=true in order CDI container to start, when used with @HelidonTest . You can set up config in @BeforeAll method and register it with ConfigProviderResolver using MP Config APIs, and declare @Configuration(useExisting=true) . Note that this is not compatible with repeatable tests that use method sources that access CDI, as we must delay the CDI startup to the test class instantiation (which is too late, as the method sources are already invoked by this time). If you want to use method sources that use CDI with repeatable tests, please do not use @Configuration(useExisting=true) Usage - added parameters and injection types The following types are available for injection (when a single CDI container is used per test class): WebTarget - a JAX-RS client&#8217;s target configured for the current hostname and port when helidon-micorprofile-server is on the classpath The following types are available as method parameters (in any type of Helidon tests): WebTarget - a JAX-RS client&#8217;s target configured for the current hostname and port when helidon-micorprofile-server is on the classpath SeContainer - the current container instance ",
            "title": "Usage"
        },
        {
            "location": "/mp/testing",
            "text": " The annotations described in this section are inherited (for the non-repeatable ones), and additive (for repeatable). So if you declare @DisableDiscovery on abstract class, all implementations will have discovery disabled, unless you annotate the implementation class with @DisableDiscovery(false) . If you declare @AddBean on both abstract class and implementation class, both beans will be added. In addition to this simplification, the following annotations are supported: Annotation Usage @io.helidon.microprofile.testing.junit5.AddBean Used to add one or more beans to the container (if not part of a bean archive, or when discovery is disabled) @io.helidon.microprofile.testing.junit5.AddExtension Used to add one or more CDI extensions to the container (if not added through service loader, or when discovery is disabled) @io.helidon.microprofile.testing.junit5.AddConfig Used to add one or more configuration properties to MicroProfile config without the need of creating a microprofile-config.properties file Used @io.helidon.microprofile.testing.junit5.DisableDiscovery to disable automated discovery of beans and extensions Used @io.helidon.microprofile.testing.junit5.DisableDiscovery to disable automated discovery of beans and extensions Used @io.helidon.microprofile.testing.junit5.AddJaxRs add JaxRs support to the test class. Only used with @DisableDiscovery annotation, otherwise an exception will be thrown. Automatically adds the following Beans and Extensions to the test class: ServerCdiExtension JaxRsCdiExtension CdiComponentProvider org.glassfish.jersey.ext.cdi1x.internal.ProcessAllAnnotatedTypes org.glassfish.jersey.weld.se.WeldRequestScope ",
            "title": "API"
        },
        {
            "location": "/mp/testing",
            "text": " In the current example, Helidon container will be launched prior test. The Bean Discovery will be disabled. MyBean will be added to the test, so that it can be injected. ConfigCdiExtension will be enabled for this test. And finally, a configuration property will be added using @AddConfig annotation. <markup lang=\"java\" title=\"Code sample\" >@HelidonTest @DisableDiscovery @AddBean(MyBean.class) @AddExtension(ConfigCdiExtension.class) @AddConfig(key = \"app.greeting\", value = \"TestHello\") class TestExample { @Inject private MyBean myBean; @Test void testGreeting() { assertThat(myBean, notNullValue()); assertThat(myBean.greeting(), is(\"TestHello\")); } } Start the Helidon container. Set disabled Bean Discovery for the current test class. Add MyBean to current context. Add a configuration CDI extension to the current test. Add configuration properties. Inject MyBean as it is available in the CDI context. Run rests. To test @RequestScoped bean with JaxRs support: <markup lang=\"java\" title=\"Test RequestScoped bean\" >@HelidonTest @DisableDiscovery @AddJaxRs @AddBean(TestReqScopeDisabledDiscovery.MyController.class) public class TestReqScopeDisabledDiscovery { @Inject private WebTarget target; @Test void testGet() { assertEquals(\"Hallo!\", target .path(\"/greeting\") .request() .get(String.class)); } @Path(\"/greeting\") @RequestScoped public static class MyController { @GET public Response get() { return Response.ok(\"Hallo!\").build(); } } } Start the Helidon container. Set disabled Bean discovery. Add JaxRs support to the current test class. Define a RequestScoped bean. ",
            "title": "Examples"
        },
        {
            "location": "/mp/testing",
            "text": " Official blog article about Helidon and JUnit usage ",
            "title": "Additional Information"
        },
        {
            "location": "/mp/testing",
            "text": " JUnit 5 User Guide ",
            "title": "Reference"
        },
        {
            "location": "/mp/tracing",
            "text": " Overview Maven Coordinates Usage Configuration Examples Additional Information Jaeger Tracing Zipkin Tracing Reference ",
            "title": "Contents"
        },
        {
            "location": "/mp/tracing",
            "text": " The OpenTracing Specification that MP OpenTracing is based on is no longer maintained. The MP OpenTracing specification is no longer required by MicroProfile. This feature is marked as @Deprecated in Helidon. The specification is Superseded by MicroProfile Telemetry specification . Distributed tracing is a critical feature of micro-service based applications, since it traces workflow both within a service and across multiple services. This provides insight to sequence and timing data for specific blocks of work, which helps you identify performance and operational issues. Helidon MP includes support for distributed tracing through the OpenTracing API . Tracing is integrated with WebServer and Security. ",
            "title": "Overview"
        },
        {
            "location": "/mp/tracing",
            "text": " To enable MicroProfile Tracing either add a dependency on the helidon-microprofile bundle or add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-tracing&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/tracing",
            "text": " This section explains a few concepts that you need to understand before you get started with tracing. In the context of this document, a service is synonymous with an application. A span is the basic unit of work done within a single service, on a single host. Every span has a name, starting timestamp, and duration. For example, the work done by a REST endpoint is a span. A span is associated to a single service, but its descendants can belong to different services and hosts. A trace contains a collection of spans from one or more services, running on one or more hosts. For example, if you trace a service endpoint that calls another service, then the trace would contain spans from both services. Within a trace, spans are organized as a directed acyclic graph (DAG) and can belong to multiple services, running on multiple hosts. The OpenTracing Data Model describes the details at The OpenTracing Semantic Specification . Spans are automatically created by Helidon as needed during execution of the REST request. Additional spans can be added through MP annotation @Traced or through OpenTracing APIs. ",
            "title": "Usage"
        },
        {
            "location": "/mp/tracing",
            "text": " The following table lists all spans traced by Helidon components: <div class=\"table__overflow elevation-1 flex sm10 \"> component span name description web-server HTTP Request The overall span of the Web Server from request initiation until response Note that in Zipkin the name is replaced with jax-rs span name if jax-rs tracing is used. web-server content-read Span for reading the request entity web-server content-write Span for writing the response entity security security Processing of request security security security:atn Span for request authentication security security:atz Span for request authorization security security:response Processing of response security security security:outbound Processing of outbound security jax-rs A generated name Span for the resource method invocation, name is generated from class and method name jax-rs jersey-client-call Span for outbound client call Some of these spans log to the span. These log events can be (in most cases) configured: <div class=\"table__overflow elevation-1 flex sm10 \"> span name log name configurable enabled by default description HTTP Request handler.class YES YES Each handler has its class and event logged security status YES YES Logs either \"status: PROCEED\" or \"status: DENY\" security:atn security.user YES NO The username of the user if logged in security:atn security.service YES NO The name of the service if logged in security:atn status YES YES Logs the status of security response (such as SUCCESS ) security:atz status YES YES Logs the status of security response (such as SUCCESS ) security:outbound status YES YES Logs the status of security response (such as SUCCESS ) There are also tags that are set by Helidon components. These are not configurable. <div class=\"table__overflow elevation-1 flex sm10 \"> span name tag name description HTTP Request component name of the component - helidon-webserver , or jaxrs when using MP HTTP Request http.method HTTP method of the request, such as GET , POST HTTP Request http.status_code HTTP status code of the response HTTP Request http.url The path of the request (for SE without protocol, host and port) HTTP Request error If the request ends in error, this tag is set to true , usually accompanied by logs with details security security.id ID of the security context created for this request (if security is used) jersey-client-call http.method HTTP method of the client request jersey-client-call http.status_code HTTP status code of client response jersey-client-call http.url Full URL of the request (such as http://localhost:8080/greet ) ",
            "title": "Traced spans"
        },
        {
            "location": "/mp/tracing",
            "text": " You can configure a custom service name using the tracing.service configuration property. If this property is undefined, name is created from JAX-RS Application name, or Helidon MP is used if no application is defined. Jaeger tracer configuration. Type: io.helidon.tracing.Tracer This is a standalone configuration type, prefix from configuration root: tracing ",
            "title": "Enabling and Disabling Tracing"
        },
        {
            "location": "/mp/tracing",
            "text": " Enabling and Disabling Tracing You can configure a custom service name using the tracing.service configuration property. If this property is undefined, name is created from JAX-RS Application name, or Helidon MP is used if no application is defined. Jaeger tracer configuration. Type: io.helidon.tracing.Tracer This is a standalone configuration type, prefix from configuration root: tracing ",
            "title": "Configuration"
        },
        {
            "location": "/mp/tracing",
            "text": " To have a nicer overview in search pane of a tracer, you can customize the top-level span name using configuration. Example: <markup lang=\"properties\" title=\"Configuration properties\" >tracing.components.web-server.spans.0.name=\"HTTP Request\" tracing.components.web-server.spans.0.new-name: \"HTTP %1$s %2$s\" This is supported ONLY for the span named \"HTTP Request\" on component \"web-server\". Parameters provided: Method - HTTP method Path - path of the request (such as '/greet') Query - query of the request (may be null) ",
            "title": "Renaming top level span using request properties"
        },
        {
            "location": "/mp/tracing",
            "text": " For Web Server we have a path based support for configuring tracing, in addition to the configuration described above. Configuration of path can use any path string supported by the Web Server. The configuration itself has the same possibilities as traced configuration described above. The path specific configuration will be merged with global configuration (path is the \"newer\" configuration, global is the \"older\") Renaming top level span using request properties To have a nicer overview in search pane of a tracer, you can customize the top-level span name using configuration. Example: <markup lang=\"properties\" title=\"Configuration properties\" >tracing.components.web-server.spans.0.name=\"HTTP Request\" tracing.components.web-server.spans.0.new-name: \"HTTP %1$s %2$s\" This is supported ONLY for the span named \"HTTP Request\" on component \"web-server\". Parameters provided: Method - HTTP method Path - path of the request (such as '/greet') Query - query of the request (may be null) ",
            "title": "Controlling Tracing Output"
        },
        {
            "location": "/mp/tracing",
            "text": " Optional configuration options key type default value description client-cert-pem Resource &#160; Certificate of client in PEM format. exporter-timeout Duration PT10S Timeout of exporter requests. max-export-batch-size int 512 Maximum Export Batch Size of exporter requests. max-queue-size int 2048 Maximum Queue Size of exporter requests. private-key-pem Resource &#160; Private key in PEM format. propagation PropagationFormat[&#93; (B3, B3_SINGLE, JAEGER, W3C) JAEGER Add propagation format to use. sampler-param Number 1 The sampler parameter (number). sampler-type SamplerType (CONSTANT, RATIO) CONSTANT Sampler type. See &lt;a href=\"https://www.jaegertracing.io/docs/latest/sampling/#client-sampling-configuration\"&gt;Sampler types&lt;/a&gt;. schedule-delay Duration PT5S Schedule Delay of exporter requests. span-processor-type SpanProcessorType (SIMPLE, BATCH) batch Span Processor type used. trusted-cert-pem Resource &#160; Trusted certificates in PEM format. To disable Helidon tracing for web server and security: <markup lang=\"properties\" >tracing.components.web-server.enabled=false tracing.components.security.enabled=false To disables MP Tracing as by specification: <markup lang=\"properties\" >mp.opentracing.server.skip-pattern=.* Tracing configuration can be defined in application.yaml file. <markup lang=\"yaml\" title=\"Tracing configuration example\" >tracing: paths: - path: \"/favicon.ico\" enabled: false - path: \"/metrics\" enabled: false - path: \"/health\" enabled: false components: web-server: spans: - name: \"HTTP Request\" logs: - name: \"content-write\" enabled: false Controlling Tracing Output For Web Server we have a path based support for configuring tracing, in addition to the configuration described above. Configuration of path can use any path string supported by the Web Server. The configuration itself has the same possibilities as traced configuration described above. The path specific configuration will be merged with global configuration (path is the \"newer\" configuration, global is the \"older\") Renaming top level span using request properties To have a nicer overview in search pane of a tracer, you can customize the top-level span name using configuration. Example: <markup lang=\"properties\" title=\"Configuration properties\" >tracing.components.web-server.spans.0.name=\"HTTP Request\" tracing.components.web-server.spans.0.new-name: \"HTTP %1$s %2$s\" This is supported ONLY for the span named \"HTTP Request\" on component \"web-server\". Parameters provided: Method - HTTP method Path - path of the request (such as '/greet') Query - query of the request (may be null) ",
            "title": "Configuration options"
        },
        {
            "location": "/mp/tracing",
            "text": " First, you need to run the Jaeger tracer. Helidon will communicate with this tracer at runtime. <markup lang=\"bash\" title=\"Run Jaeger within a docker container, then check the Jaeger server working:\" >docker run -d --name jaeger \\ -e COLLECTOR_OTLP_ENABLED=true \\ -p 6831:6831/udp \\ -p 6832:6832/udp \\ -p 5778:5778 \\ -p 16686:16686 \\ -p 4317:4317 \\ -p 4318:4318 \\ -p 14250:14250 \\ -p 14268:14268 \\ -p 14269:14269 \\ -p 9411:9411 \\ jaegertracing/all-in-one:1.50 Run the Jaeger docker image. <markup lang=\"bash\" title=\"Check the Jaeger server by opening in browser:\" >http://localhost:16686/search ",
            "title": "Set up Jaeger"
        },
        {
            "location": "/mp/tracing",
            "text": "<markup lang=\"bash\" title=\"Run the Maven archetype:\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-mp \\ -DarchetypeVersion=4.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-mp-2 \\ -Dpackage=io.helidon.examples.quickstart.mp <markup lang=\"bash\" title=\"The project will be built and run from the helidon-quickstart-mp directory:\" >cd helidon-quickstart-mp-2 <markup lang=\"xml\" title=\"Add the following dependency to pom.xml :\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-providers-jaeger&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"bash\" title=\"Replace META-INF/microprofile-config.properties with the following:\" >app.greeting=Hello From MP-2 tracing.service=helidon-mp-2 # Microprofile server properties server.port=8081 <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-mp-2.jar <markup lang=\"bash\" title=\"Run the curl command in a new terminal window and check the response ( notice the port is 8081 ) :\" >curl http://localhost:8081/greet <markup lang=\"json\" title=\"Response body\" >{ \"message\": \"Hello From MP-2 World!\" } ",
            "title": "Create a second service"
        },
        {
            "location": "/mp/tracing",
            "text": " Once you have validated that the second service is running correctly, you need to modify the original application to call it. <markup lang=\"java\" title=\"Replace the GreetResource class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import jakarta.enterprise.context.RequestScoped; import jakarta.inject.Inject; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.client.WebTarget; import jakarta.ws.rs.core.MediaType; import org.glassfish.jersey.server.Uri; @Path(\"/greet\") @RequestScoped public class GreetResource { @Uri(\"http://localhost:8081/greet\") private WebTarget target; private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); private final GreetingProvider greetingProvider; @Inject public GreetResource(GreetingProvider greetingConfig) { this.greetingProvider = greetingConfig; } @GET @Produces(MediaType.APPLICATION_JSON) public JsonObject getDefaultMessage() { return createResponse(\"World\"); } @GET @Path(\"/outbound\") public JsonObject outbound() { return target.request().accept(MediaType.APPLICATION_JSON_TYPE).get(JsonObject.class); } private JsonObject createResponse(String who) { String msg = String.format(\"%s %s!\", greetingProvider.getMessage(), who); return JSON.createObjectBuilder().add(\"message\", msg).build(); } } This is the WebTarget needed to send a request to the second service at port 8081 . This is the new endpoint that will call the second service. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl -i http://localhost:8080/greet/outbound The request went to the service on 8080 , which then invoked the service at 8081 to get the greeting. <markup lang=\"json\" title=\"Response body\" >{ \"message\": \"Hello From MP-2 World!\" } Notice the greeting came from the second service. Refresh the Jaeger UI trace listing page and notice that there is a trace across two services. Tracing across multiple services detail view In the image above, you can see that the trace includes spans from two services. You will notice there is a gap before the sixth span, which is a get operation. This is a one-time client initialization delay. Run the /outbound curl command again and look at the new trace to see that the delay no longer exists. You can now stop your second service, it is no longer used in this guide. ",
            "title": "Modify the first service"
        },
        {
            "location": "/mp/tracing",
            "text": " Helidon automatically traces across services as long as the services use the same tracer, for example, the same instance of Jaeger. This means a single trace can include spans from multiple services and hosts. OpenTracing uses a SpanContext to propagate tracing information across process boundaries. When you make client API calls, Helidon will internally call OpenTracing APIs to propagate the SpanContext . There is nothing you need to do in your application to make this work. To demonstrate distributed tracing, you will need to create a second project, where the server listens on port 8081. Create a new root directory to hold this new project, then do the following steps, similar to what you did at the start of this guide: Create a second service <markup lang=\"bash\" title=\"Run the Maven archetype:\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-mp \\ -DarchetypeVersion=4.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-mp-2 \\ -Dpackage=io.helidon.examples.quickstart.mp <markup lang=\"bash\" title=\"The project will be built and run from the helidon-quickstart-mp directory:\" >cd helidon-quickstart-mp-2 <markup lang=\"xml\" title=\"Add the following dependency to pom.xml :\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-providers-jaeger&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"bash\" title=\"Replace META-INF/microprofile-config.properties with the following:\" >app.greeting=Hello From MP-2 tracing.service=helidon-mp-2 # Microprofile server properties server.port=8081 <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-mp-2.jar <markup lang=\"bash\" title=\"Run the curl command in a new terminal window and check the response ( notice the port is 8081 ) :\" >curl http://localhost:8081/greet <markup lang=\"json\" title=\"Response body\" >{ \"message\": \"Hello From MP-2 World!\" } Modify the first service Once you have validated that the second service is running correctly, you need to modify the original application to call it. <markup lang=\"java\" title=\"Replace the GreetResource class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import jakarta.enterprise.context.RequestScoped; import jakarta.inject.Inject; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.client.WebTarget; import jakarta.ws.rs.core.MediaType; import org.glassfish.jersey.server.Uri; @Path(\"/greet\") @RequestScoped public class GreetResource { @Uri(\"http://localhost:8081/greet\") private WebTarget target; private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); private final GreetingProvider greetingProvider; @Inject public GreetResource(GreetingProvider greetingConfig) { this.greetingProvider = greetingConfig; } @GET @Produces(MediaType.APPLICATION_JSON) public JsonObject getDefaultMessage() { return createResponse(\"World\"); } @GET @Path(\"/outbound\") public JsonObject outbound() { return target.request().accept(MediaType.APPLICATION_JSON_TYPE).get(JsonObject.class); } private JsonObject createResponse(String who) { String msg = String.format(\"%s %s!\", greetingProvider.getMessage(), who); return JSON.createObjectBuilder().add(\"message\", msg).build(); } } This is the WebTarget needed to send a request to the second service at port 8081 . This is the new endpoint that will call the second service. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl -i http://localhost:8080/greet/outbound The request went to the service on 8080 , which then invoked the service at 8081 to get the greeting. <markup lang=\"json\" title=\"Response body\" >{ \"message\": \"Hello From MP-2 World!\" } Notice the greeting came from the second service. Refresh the Jaeger UI trace listing page and notice that there is a trace across two services. Tracing across multiple services detail view In the image above, you can see that the trace includes spans from two services. You will notice there is a gap before the sixth span, which is a get operation. This is a one-time client initialization delay. Run the /outbound curl command again and look at the new trace to see that the delay no longer exists. You can now stop your second service, it is no longer used in this guide. ",
            "title": "Trace Across Services"
        },
        {
            "location": "/mp/tracing",
            "text": " The examples in this guide demonstrate how to integrate tracing with Helidon, how to view traces, how to trace across multiple services, and how to integrate tracing with Kubernetes. All examples use Jaeger and traces will be viewed using both the Jaeger UI. Set up Jaeger First, you need to run the Jaeger tracer. Helidon will communicate with this tracer at runtime. <markup lang=\"bash\" title=\"Run Jaeger within a docker container, then check the Jaeger server working:\" >docker run -d --name jaeger \\ -e COLLECTOR_OTLP_ENABLED=true \\ -p 6831:6831/udp \\ -p 6832:6832/udp \\ -p 5778:5778 \\ -p 16686:16686 \\ -p 4317:4317 \\ -p 4318:4318 \\ -p 14250:14250 \\ -p 14268:14268 \\ -p 14269:14269 \\ -p 9411:9411 \\ jaegertracing/all-in-one:1.50 Run the Jaeger docker image. <markup lang=\"bash\" title=\"Check the Jaeger server by opening in browser:\" >http://localhost:16686/search Trace Across Services Helidon automatically traces across services as long as the services use the same tracer, for example, the same instance of Jaeger. This means a single trace can include spans from multiple services and hosts. OpenTracing uses a SpanContext to propagate tracing information across process boundaries. When you make client API calls, Helidon will internally call OpenTracing APIs to propagate the SpanContext . There is nothing you need to do in your application to make this work. To demonstrate distributed tracing, you will need to create a second project, where the server listens on port 8081. Create a new root directory to hold this new project, then do the following steps, similar to what you did at the start of this guide: Create a second service <markup lang=\"bash\" title=\"Run the Maven archetype:\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-mp \\ -DarchetypeVersion=4.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-mp-2 \\ -Dpackage=io.helidon.examples.quickstart.mp <markup lang=\"bash\" title=\"The project will be built and run from the helidon-quickstart-mp directory:\" >cd helidon-quickstart-mp-2 <markup lang=\"xml\" title=\"Add the following dependency to pom.xml :\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-providers-jaeger&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"bash\" title=\"Replace META-INF/microprofile-config.properties with the following:\" >app.greeting=Hello From MP-2 tracing.service=helidon-mp-2 # Microprofile server properties server.port=8081 <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-mp-2.jar <markup lang=\"bash\" title=\"Run the curl command in a new terminal window and check the response ( notice the port is 8081 ) :\" >curl http://localhost:8081/greet <markup lang=\"json\" title=\"Response body\" >{ \"message\": \"Hello From MP-2 World!\" } Modify the first service Once you have validated that the second service is running correctly, you need to modify the original application to call it. <markup lang=\"java\" title=\"Replace the GreetResource class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import jakarta.enterprise.context.RequestScoped; import jakarta.inject.Inject; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.client.WebTarget; import jakarta.ws.rs.core.MediaType; import org.glassfish.jersey.server.Uri; @Path(\"/greet\") @RequestScoped public class GreetResource { @Uri(\"http://localhost:8081/greet\") private WebTarget target; private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); private final GreetingProvider greetingProvider; @Inject public GreetResource(GreetingProvider greetingConfig) { this.greetingProvider = greetingConfig; } @GET @Produces(MediaType.APPLICATION_JSON) public JsonObject getDefaultMessage() { return createResponse(\"World\"); } @GET @Path(\"/outbound\") public JsonObject outbound() { return target.request().accept(MediaType.APPLICATION_JSON_TYPE).get(JsonObject.class); } private JsonObject createResponse(String who) { String msg = String.format(\"%s %s!\", greetingProvider.getMessage(), who); return JSON.createObjectBuilder().add(\"message\", msg).build(); } } This is the WebTarget needed to send a request to the second service at port 8081 . This is the new endpoint that will call the second service. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl -i http://localhost:8080/greet/outbound The request went to the service on 8080 , which then invoked the service at 8081 to get the greeting. <markup lang=\"json\" title=\"Response body\" >{ \"message\": \"Hello From MP-2 World!\" } Notice the greeting came from the second service. Refresh the Jaeger UI trace listing page and notice that there is a trace across two services. Tracing across multiple services detail view In the image above, you can see that the trace includes spans from two services. You will notice there is a gap before the sixth span, which is a get operation. This is a one-time client initialization delay. Run the /outbound curl command again and look at the new trace to see that the delay no longer exists. You can now stop your second service, it is no longer used in this guide. ",
            "title": "Examples"
        },
        {
            "location": "/mp/tracing",
            "text": "<markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named jaeger.yaml , with the following contents:\" >apiVersion: v1 kind: Service metadata: name: jaeger spec: ports: - port: 16686 protocol: TCP selector: app: jaeger --- kind: Pod apiVersion: v1 metadata: name: jaeger labels: app: jaeger spec: containers: - name: jaeger image: jaegertracing/all-in-one imagePullPolicy: IfNotPresent ports: - containerPort: 16686 <markup lang=\"bash\" title=\"Create the Jaeger pod and ClusterIP service:\" >kubectl apply -f ./jaeger.yaml <markup lang=\"bash\" title=\"Create a Jaeger external server and expose it on port 9142:\" >kubectl expose pod jaeger --name=jaeger-external --port=16687 --target-port=16686 --type=LoadBalancer Create a service so that you can access the Jaeger UI. Navigate to http://localhost:16687/search to validate that you can access Jaeger running in Kubernetes. It may take a few seconds before it is ready. ",
            "title": "Deploy Jaeger into Kubernetes"
        },
        {
            "location": "/mp/tracing",
            "text": "<markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named tracing.yaml , with the following contents:\" >kind: Service apiVersion: v1 metadata: name: helidon-tracing labels: app: helidon-tracing spec: type: NodePort selector: app: helidon-tracing ports: - port: 8080 targetPort: 8080 name: http --- kind: Deployment apiVersion: apps/v1 metadata: name: helidon-tracing spec: replicas: 1 selector: matchLabels: app: helidon-tracing template: metadata: labels: app: helidon-tracing version: v1 spec: containers: - name: helidon-tracing image: helidon-tracing-mp imagePullPolicy: IfNotPresent ports: - containerPort: 8080 A service of type NodePort that serves the default routes on port 8080 . A deployment with one replica of a pod. <markup lang=\"bash\" title=\"Create and deploy the application into Kubernetes:\" >kubectl apply -f ./tracing.yaml ",
            "title": "Deploy Your Helidon Application into Kubernetes"
        },
        {
            "location": "/mp/tracing",
            "text": "<markup lang=\"bash\" title=\"Get the application service information:\" >kubectl get service/helidon-tracing <markup lang=\"bash\" >NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE helidon-tracing NodePort 10.99.159.2 &lt;none&gt; 8080:31143/TCP 8s A service of type NodePort that serves the default routes on port 31143 . <markup lang=\"bash\" title=\"Verify the tracing endpoint using port 31143 , your port will likely be different:\" >curl http://localhost:31143/greet <markup lang=\"json\" >{ \"message\": \"Hello World!\" } Access the Jaeger UI at http://localhost:16687/search and click on the refresh icon to see the trace that was just created. ",
            "title": "Access Your Application and the Jaeger Trace"
        },
        {
            "location": "/mp/tracing",
            "text": " You can now delete the Kubernetes resources that were just created during this example. <markup lang=\"bash\" title=\"Delete the Kubernetes resources:\" >kubectl delete -f ./jaeger.yaml kubectl delete -f ./tracing.yaml kubectl delete service jaeger-external docker rm -f jaeger ",
            "title": "Cleanup"
        },
        {
            "location": "/mp/tracing",
            "text": " The following example demonstrates how to use Jaeger from a Helidon application running in Kubernetes. <markup lang=\"bash\" title=\"Update application.yaml :\" >tracing: host: \"jaeger\" <markup lang=\"bash\" title=\"Stop the application and build the docker image for your application:\" >docker build -t helidon-tracing-mp . Deploy Jaeger into Kubernetes <markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named jaeger.yaml , with the following contents:\" >apiVersion: v1 kind: Service metadata: name: jaeger spec: ports: - port: 16686 protocol: TCP selector: app: jaeger --- kind: Pod apiVersion: v1 metadata: name: jaeger labels: app: jaeger spec: containers: - name: jaeger image: jaegertracing/all-in-one imagePullPolicy: IfNotPresent ports: - containerPort: 16686 <markup lang=\"bash\" title=\"Create the Jaeger pod and ClusterIP service:\" >kubectl apply -f ./jaeger.yaml <markup lang=\"bash\" title=\"Create a Jaeger external server and expose it on port 9142:\" >kubectl expose pod jaeger --name=jaeger-external --port=16687 --target-port=16686 --type=LoadBalancer Create a service so that you can access the Jaeger UI. Navigate to http://localhost:16687/search to validate that you can access Jaeger running in Kubernetes. It may take a few seconds before it is ready. Deploy Your Helidon Application into Kubernetes <markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named tracing.yaml , with the following contents:\" >kind: Service apiVersion: v1 metadata: name: helidon-tracing labels: app: helidon-tracing spec: type: NodePort selector: app: helidon-tracing ports: - port: 8080 targetPort: 8080 name: http --- kind: Deployment apiVersion: apps/v1 metadata: name: helidon-tracing spec: replicas: 1 selector: matchLabels: app: helidon-tracing template: metadata: labels: app: helidon-tracing version: v1 spec: containers: - name: helidon-tracing image: helidon-tracing-mp imagePullPolicy: IfNotPresent ports: - containerPort: 8080 A service of type NodePort that serves the default routes on port 8080 . A deployment with one replica of a pod. <markup lang=\"bash\" title=\"Create and deploy the application into Kubernetes:\" >kubectl apply -f ./tracing.yaml Access Your Application and the Jaeger Trace <markup lang=\"bash\" title=\"Get the application service information:\" >kubectl get service/helidon-tracing <markup lang=\"bash\" >NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE helidon-tracing NodePort 10.99.159.2 &lt;none&gt; 8080:31143/TCP 8s A service of type NodePort that serves the default routes on port 31143 . <markup lang=\"bash\" title=\"Verify the tracing endpoint using port 31143 , your port will likely be different:\" >curl http://localhost:31143/greet <markup lang=\"json\" >{ \"message\": \"Hello World!\" } Access the Jaeger UI at http://localhost:16687/search and click on the refresh icon to see the trace that was just created. Cleanup You can now delete the Kubernetes resources that were just created during this example. <markup lang=\"bash\" title=\"Delete the Kubernetes resources:\" >kubectl delete -f ./jaeger.yaml kubectl delete -f ./tracing.yaml kubectl delete service jaeger-external docker rm -f jaeger ",
            "title": "Integration with Kubernetes"
        },
        {
            "location": "/mp/tracing",
            "text": " Helidon MP fully supports MicroProfile OpenTracing. You can add custom spans using @Traced annotation on methods of CDI beans. Note for invoking methods on same class: If you invoke a method on the same class, @Traced annotation would be ignored, as it is not invoked through a CDI proxy and as such cannot be intercepted. To make sure @Traced is honored, use it on JAX-RS resource methods and on CDI bean methods used from other beans. ",
            "title": "Creating custom spans"
        },
        {
            "location": "/mp/tracing",
            "text": " There is an option to provide SpanContext programmatically (such as when writing a command line application that starts the span manually). You can either configure the span context as the active span, or explicitly define it as client property. <markup lang=\"java\" title=\"Tracing propagation with Jersey client\" >import static io.helidon.tracing.jersey.client.ClientTracingFilter.CURRENT_SPAN_CONTEXT_PROPERTY_NAME; import static io.helidon.tracing.jersey.client.ClientTracingFilter.TRACER_PROPERTY_NAME; Response response = client.target(serviceEndpoint) .request() // tracer should be provided unless available as GlobalTracer .property(TRACER_PROPERTY_NAME, tracer) .property(CURRENT_SPAN_CONTEXT_PROPERTY_NAME, spanContext) .get(); ",
            "title": "Manual handling of traces in Jersey Client"
        },
        {
            "location": "/mp/tracing",
            "text": " Automated trace propagation is supported currently only with Jersey client. Tracing propagation works automatically as long as you run within the scope of Helidon MP and use Helidon components to invoke external services. Manual handling of traces in Jersey Client There is an option to provide SpanContext programmatically (such as when writing a command line application that starts the span manually). You can either configure the span context as the active span, or explicitly define it as client property. <markup lang=\"java\" title=\"Tracing propagation with Jersey client\" >import static io.helidon.tracing.jersey.client.ClientTracingFilter.CURRENT_SPAN_CONTEXT_PROPERTY_NAME; import static io.helidon.tracing.jersey.client.ClientTracingFilter.TRACER_PROPERTY_NAME; Response response = client.target(serviceEndpoint) .request() // tracer should be provided unless available as GlobalTracer .property(TRACER_PROPERTY_NAME, tracer) .property(CURRENT_SPAN_CONTEXT_PROPERTY_NAME, spanContext) .get(); ",
            "title": "Trace propagation across services"
        },
        {
            "location": "/mp/tracing",
            "text": "<markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-providers-jaeger&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Jaeger Tracing"
        },
        {
            "location": "/mp/tracing",
            "text": " Jaeger Tracing <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-providers-jaeger&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Additional Information"
        },
        {
            "location": "/mp/tracing",
            "text": " Jaeger tracer configuration. Type: io.helidon.tracing.Tracer This is a standalone configuration type, prefix from configuration root: tracing ",
            "title": "Configuring Jaeger"
        },
        {
            "location": "/mp/tracing",
            "text": " As the Jaeger Tracing section describes, you can use Jaeger tracing in your Helidon application. ",
            "title": "Jaeger Tracing Metrics"
        },
        {
            "location": "/mp/tracing",
            "text": "<markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-providers-zipkin&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Zipkin Tracing"
        },
        {
            "location": "/mp/tracing",
            "text": " Optional configuration options key type default value description client-cert-pem Resource &#160; Certificate of client in PEM format. exporter-timeout Duration PT10S Timeout of exporter requests. max-export-batch-size int 512 Maximum Export Batch Size of exporter requests. max-queue-size int 2048 Maximum Queue Size of exporter requests. private-key-pem Resource &#160; Private key in PEM format. propagation PropagationFormat[&#93; (B3, B3_SINGLE, JAEGER, W3C) JAEGER Add propagation format to use. sampler-param Number 1 The sampler parameter (number). sampler-type SamplerType (CONSTANT, RATIO) CONSTANT Sampler type. See &lt;a href=\"https://www.jaegertracing.io/docs/latest/sampling/#client-sampling-configuration\"&gt;Sampler types&lt;/a&gt;. schedule-delay Duration PT5S Schedule Delay of exporter requests. span-processor-type SpanProcessorType (SIMPLE, BATCH) batch Span Processor type used. trusted-cert-pem Resource &#160; Trusted certificates in PEM format. The following is an example of a Jaeger configuration, specified in the YAML format. <markup lang=\"yaml\" >tracing: service: \"helidon-full-http\" protocol: \"https\" host: \"jaeger\" port: 14240 Jaeger Tracing Metrics As the Jaeger Tracing section describes, you can use Jaeger tracing in your Helidon application. Zipkin Tracing <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-providers-zipkin&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Configuration options"
        },
        {
            "location": "/mp/tracing",
            "text": " Zipkin tracer configuration Type: io.opentracing.Tracer This is a standalone configuration type, prefix from configuration root: tracing ",
            "title": "Configuring Zipkin"
        },
        {
            "location": "/mp/tracing",
            "text": " Optional configuration options key type default value description api-version Version (V1, V2) V2 Version of Zipkin API to use. Defaults to Version#V2. The following is an example of a Zipkin configuration, specified in the YAML format. <markup lang=\"yaml\" >tracing: zipkin: service: \"helidon-service\" protocol: \"https\" host: \"zipkin\" port: 9987 api-version: 1 # this is the default path for API version 2 path: \"/api/v2/spans\" tags: tag1: \"tag1-value\" tag2: \"tag2-value\" boolean-tags: tag3: true tag4: false int-tags: tag5: 145 tag6: 741 Example of Zipkin trace: ",
            "title": "Configuration options"
        },
        {
            "location": "/mp/tracing",
            "text": " MicroProfile Opentracing Specification Opentracing Project ",
            "title": "Reference"
        },
        {
            "location": "/mp/websocket",
            "text": " Overview Maven Coordinates Usage API Examples Reference ",
            "title": "Contents"
        },
        {
            "location": "/mp/websocket",
            "text": " Helidon integrates with Tyrus to provide support for the Jakarta WebSocket API . ",
            "title": "Overview"
        },
        {
            "location": "/mp/websocket",
            "text": " To enable Jakarta Websocket add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.websocket&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-websocket&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/websocket",
            "text": " The WebSocket API enables Java applications to participate in WebSocket interactions as both servers and clients. The server API supports two flavors: annotated and programmatic endpoints. Annotated endpoints, as suggested by their name, use Java annotations to provide the necessary meta-data to define WebSocket handlers; programmatic endpoints implement API interfaces and are annotation free. Annotated endpoints tend to be more flexible since they allow different method signatures depending on the application needs, whereas programmatic endpoints must implement an interface and are, therefore, bounded to its definition. Helidon MP support is centered around annotations and bean discovery using CDI. Developers can choose between annotated and programmatic endpoints or use any combination of them. Using annotated endpoints is recommended in MP as they usually result in more succinct and easier-to-read code. ",
            "title": "Usage"
        },
        {
            "location": "/mp/websocket",
            "text": " <div class=\"table__overflow elevation-1 flex sm10 \"> Annotation Description @ServerEndpoint This class level annotation declares that the class it decorates is a web socket endpoint that will be deployed and made available in the URI-space of a web socket server. The annotation allows the developer to define the URL (or URI template) which this endpoint will be published, and other important properties of the endpoint to the websocket runtime, such as the encoders it uses to send messages. @ClientEndpoint The ClientEndpoint annotation, a class level annotation, is used to denote that a POJO is a web socket client and can be deployed as such. Similar to @ServerEndpoint , POJOs that are annotated with this annotation can have methods that, using the web socket method level annotations, are web socket lifecycle methods. @OnOpen This method level annotation can be used to decorate a Java method that will be called when a new web socket session is open. @OnMessage This method level annotation can be used to make a Java method receive incoming web socket messages. Each websocket endpoint may only have one message handling method for each of the native websocket message formats: text, binary and pong. @OnError This method level annotation can be used to decorate a Java method that will be called in order to handle errors. @OnClose This method level annotation can be used to decorate a Java method that will be called when a web socket session is closing. ",
            "title": "API"
        },
        {
            "location": "/mp/websocket",
            "text": " The Helidon WebServer can listen on multiple ports or sockets. This can be useful when APIs for different type of users need to be exposed (such as admin vs. non-admin users). Just like for REST resources, it is possible to expose WebSocket applications on different ports provided that the routing paths are different --this is due to a constraint in Tyrus, given that it is simply unaware that the endpoints are bound to different ports in the Helidon WebServer. In practice, this implies that the value of @RoutingPath , or the equivalent entry in config, must be different across sockets to satisfy the restriction in Tyrus. An attempt to register two or more endpoints on the same path, even if they belong to applications registered on different ports, shall result in a jakarta.websocket.DeploymentException being thrown. We can modify the MessageBoardApplication above and bind it to a non-default socket as follows: <markup lang=\"java\" >@ApplicationScoped @RoutingPath(\"/web\") @RoutingName(value = \"admin\", required = true) public class MessageBoardApplication implements ServerApplicationConfig { @Override public Set&lt;ServerEndpointConfig&gt; getEndpointConfigs( Set&lt;Class&lt;? extends Endpoint&gt;&gt; endpoints) { assert endpoints.isEmpty(); return Collections.emptySet(); // No programmatic endpoints } @Override public Set&lt;Class&lt;?&gt;&gt; getAnnotatedEndpointClasses(Set&lt;Class&lt;?&gt;&gt; endpoints) { return endpoints; // Returned scanned endpoints } } The value of the @RoutingName annotation must match that of a configured application socket as shown in the following application.yaml file: <markup >server: port: 8080 host: 0.0.0.0 sockets: - name: admin port: 8888 This example assumes that port 8888 is reserved for admin users and binds the MessageBoardApplication to it. ",
            "title": "WebSocket Endpoints on Different Ports"
        },
        {
            "location": "/mp/websocket",
            "text": " This section describes the implementation of a simple application that uses a REST resource to push messages into a shared queue and a WebSocket endpoint to download messages from the queue, one at a time, over a connection. The example will show how REST and WebSocket connections can be seamlessly combined into a Helidon application. The Helidon MP application shown here takes full advantage of CDI and class scanning and does not require any additional code given that the necessary information is available from the code annotations. The REST endpoint is implemented as a JAX-RS resource, and the shared queue (in application scope) is directly injected: <markup lang=\"java\" >@Path(\"rest\") public class MessageQueueResource { @Inject private MessageQueue messageQueue; @POST @Consumes(\"text/plain\") public void push(String s) { messageQueue.push(s); } } Here we opt for the use of an annotated WebSocket endpoint decorated by @ServerEndpoint that provides all the meta-data necessary for Helidon to create the endpoint. <markup lang=\"java\" >@ServerEndpoint( value = \"/websocket\", encoders = { UppercaseEncoder.class }) public class MessageBoardEndpoint { @Inject private MessageQueue messageQueue; @OnMessage public void onMessage(Session session, String message) { if (message.equals(\"SEND\")) { while (!messageQueue.isEmpty()) { session.getBasicRemote().sendObject(messageQueue.pop()); } } } } Since MessageBoardEndpoint is just a POJO, it uses additional annotations for event handlers such as @OnMessage . One advantage of this approach, much like in the JAX-RS API, is that method signatures are not fixed. In the snipped above, the parameters (which could be specified in any order!) include the WebSocket session and the message received that triggered the call. So what else is needed to run this Helidon MP app? Nothing else other than the supporting classes MessageQueue and UppercaseEncoder . Helidon MP declares both @Path and @ServerEndpoint as bean defining annotation, so all that is needed is for CDI discovery to be enabled --typically in your beans.xml file. By default, both JAX-RS resources and WebSocket endpoints will be available under the root path \"/\" . This default value can be overridden by providing subclasses/implementations for jakarta.ws.rs.Application and jakarta.websocket.server.ServerApplicationConfig , respectively. JAX-RS uses @ApplicationPath on application subclasses to provide this root path, but since there is no equivalent in the WebSocket API, Helidon MP uses its own annotation @RoutingPath on jakarta.websocket.server.ServerApplicationConfig implementations. For instance, if in our example we include the following class: <markup lang=\"java\" >@ApplicationScoped @RoutingPath(\"/web\") public class MessageBoardApplication implements ServerApplicationConfig { @Override public Set&lt;ServerEndpointConfig&gt; getEndpointConfigs( Set&lt;Class&lt;? extends Endpoint&gt;&gt; endpoints) { assert endpoints.isEmpty(); return Collections.emptySet(); // No programmatic endpoints } @Override public Set&lt;Class&lt;?&gt;&gt; getAnnotatedEndpointClasses(Set&lt;Class&lt;?&gt;&gt; endpoints) { return endpoints; // Returned scanned endpoints } } the root path for WebSocket endpoints will be \"/web\" instead of the default \"/\" . Note that @RoutingPath is not a bean defining annotation, thus the need to use @ApplicationScoped --which, as before, requires CDI bean discovery mode to be annotated . In addition to @RoutingPath , these classes can be annotated with @RoutingName to associate an endpoint with a Helidon named socket. Please refer to the Javadoc of that annotation for additional information. All endpoint methods in Helidon MP are executed in a separate thread pool, independently of Netty. Therefore, there is no need to create additional threads for blocking or long-running operations as these will not affect Netty&#8217;s ability to process networking data. For more information see the example . WebSocket Endpoints on Different Ports The Helidon WebServer can listen on multiple ports or sockets. This can be useful when APIs for different type of users need to be exposed (such as admin vs. non-admin users). Just like for REST resources, it is possible to expose WebSocket applications on different ports provided that the routing paths are different --this is due to a constraint in Tyrus, given that it is simply unaware that the endpoints are bound to different ports in the Helidon WebServer. In practice, this implies that the value of @RoutingPath , or the equivalent entry in config, must be different across sockets to satisfy the restriction in Tyrus. An attempt to register two or more endpoints on the same path, even if they belong to applications registered on different ports, shall result in a jakarta.websocket.DeploymentException being thrown. We can modify the MessageBoardApplication above and bind it to a non-default socket as follows: <markup lang=\"java\" >@ApplicationScoped @RoutingPath(\"/web\") @RoutingName(value = \"admin\", required = true) public class MessageBoardApplication implements ServerApplicationConfig { @Override public Set&lt;ServerEndpointConfig&gt; getEndpointConfigs( Set&lt;Class&lt;? extends Endpoint&gt;&gt; endpoints) { assert endpoints.isEmpty(); return Collections.emptySet(); // No programmatic endpoints } @Override public Set&lt;Class&lt;?&gt;&gt; getAnnotatedEndpointClasses(Set&lt;Class&lt;?&gt;&gt; endpoints) { return endpoints; // Returned scanned endpoints } } The value of the @RoutingName annotation must match that of a configured application socket as shown in the following application.yaml file: <markup >server: port: 8080 host: 0.0.0.0 sockets: - name: admin port: 8888 This example assumes that port 8888 is reserved for admin users and binds the MessageBoardApplication to it. ",
            "title": "Examples"
        },
        {
            "location": "/mp/websocket",
            "text": " Eclipse Tyrus WebSocket RFC 6455 Helidon MicroProfile Tyrus Javadoc ",
            "title": "Reference"
        },
        {
            "location": "/se/config/advanced-configuration",
            "text": " Overview Advanced Config Sources Advanced Config Parsers Config Keys with . in name Filters, Overrides and Token Substitution Executors for Asynchronous Config Activity ",
            "title": "Contents"
        },
        {
            "location": "/se/config/advanced-configuration",
            "text": " This section discusses several advanced topics related to Helidon configuration. ",
            "title": "Overview"
        },
        {
            "location": "/se/config/advanced-configuration",
            "text": " The config system supports using environment variables as a config source, and is enabled by default. Since environment variable names are normally restricted to alphanumeric characters and underscore, this config source adds aliases that enable setting or overriding config entries with dotted and/or hyphenated keys. The mapping makes it possible to set or override a config entry with a key of \"foo.bar\" using an environment variable named \"FOO_BAR\" and \"foo.bar-baz\" using \"FOO_BAR_dash_BAZ\" . One use case for this mapping is config overrides in containers, where passing environment variables directly or via Kubernetes Secrets/ConfigMaps is common. Scripts that solve the mapping problem by explicitly converting variables to system properties can also be simplified. Aliases are produced for any environment variable name that matches all of the following: does not begin or end with a '_' character does not contain \"__\" contains one or more '_' characters For each such name, two aliases are added with the names mapped as follows: Replace any \"_dash_\" or \"_DASH_\" substrings with \"-\" , e.g. \"APP_PAGE_dash_SIZE\" becomes \"APP_PAGE-SIZE\" . Replace '_' with '.' and add as an alias, e.g. \"APP_GREETING\" is added as \"APP.GREETING\" and \"APP_PAGE-SIZE\" is added as \"APP.PAGE-SIZE\" . This mapping is added primarily to support mixed case config keys such as \"app.someCamelCaseKey\" . Convert the result of step 2 to lowercase and add as an alias, e.g. \"APP.GREETING\" is added as \"app.greeting\" and \"APP.PAGE-SIZE\" is added as \"app.page-size\" . ",
            "title": "Environment Variables Config Source"
        },
        {
            "location": "/se/config/advanced-configuration",
            "text": " The config system supports using a file system directory as a config source. Each non-directory file in the directory becomes a config entry: the file name is the key and the contents of that file are used as the corresponding config String value. The following example shows, for example, one way to load Kubernetes secrets mounted on the pod&#8217;s filesystem. If the directory conf/secrets contains these two files <markup title=\"File secrets/username \" >jose <markup title=\"File secrets/password \" >^ery$ecretP&amp;ssword your application can load this as configuration as follows: <markup lang=\"java\" title=\"Using directory config source\" >Config secrets = Config.builder( ConfigSources.directory(\"conf/secrets\")) .disableEnvironmentVariablesSource() .disableSystemPropertiesSource() .build(); assert secrets.get(\"username\") .asString() .get() .equals(\"jose\"); assert secrets.get(\"password\") .asString() .get() .equals(\"^ery$ecretP&amp;ssword\"); Loads all files from the conf/secrets directory. No need to use environment variables or system properties as sources in building the Config . The loaded config maps the key username to the value jose &#8230;&#8203; &#8230;&#8203;and the key password to ^ery$ecretP&amp;ssword . Remember that your application can process the contents of a given file as configuration. See the config sources section and the ConfigSources.file JavaDoc. ",
            "title": "Directory Config Source"
        },
        {
            "location": "/se/config/advanced-configuration",
            "text": "<markup lang=\"java\" >Config anotherConfig = Config.create(classpath(\"application.conf\")); Config config = Config.create( ConfigSources.create(anotherConfig.get(\"data\"))); ",
            "title": "Subtree of Another Config "
        },
        {
            "location": "/se/config/advanced-configuration",
            "text": "<markup lang=\"java\" >Config config = Config.create( ConfigSources.create(System.getProperties()).build()); ",
            "title": " Properties Object"
        },
        {
            "location": "/se/config/advanced-configuration",
            "text": "<markup lang=\"java\" >Config config = Config.create( ConfigSources.create(\"app.greeting = Hi\", MediaTypes.create(\"text/x-java-properties\"))); ",
            "title": " String of a Given Media Type"
        },
        {
            "location": "/se/config/advanced-configuration",
            "text": "<markup lang=\"java\" >Config config = Config.crate( ConfigSources.create(Map.of(\"app.page-size\", \"20\")) .build()); ",
            "title": " Map "
        },
        {
            "location": "/se/config/advanced-configuration",
            "text": "<markup lang=\"java\" >Config config = Config.create( ConfigSources.create(ObjectNode.builder() .addList(\"app.basic-range\", ListNode.builder() .addValue(\"-20\") .addValue(\"20\") .build()) .build())); ConfigSources.create variants for Properties or Map arguments return a MapConfigSource.Builder instance. ",
            "title": " ad hoc Config Nodes"
        },
        {
            "location": "/se/config/advanced-configuration",
            "text": " The config system provides several ways to create a Config tree from data already in memory. See the ConfigSources javadoc for further details. The numerous variants of the from method construct ConfigSource or Builder&lt;ConfigSource&gt; instances. Subtree of Another Config <markup lang=\"java\" >Config anotherConfig = Config.create(classpath(\"application.conf\")); Config config = Config.create( ConfigSources.create(anotherConfig.get(\"data\"))); Properties Object <markup lang=\"java\" >Config config = Config.create( ConfigSources.create(System.getProperties()).build()); String of a Given Media Type <markup lang=\"java\" >Config config = Config.create( ConfigSources.create(\"app.greeting = Hi\", MediaTypes.create(\"text/x-java-properties\"))); Map <markup lang=\"java\" >Config config = Config.crate( ConfigSources.create(Map.of(\"app.page-size\", \"20\")) .build()); ad hoc Config Nodes <markup lang=\"java\" >Config config = Config.create( ConfigSources.create(ObjectNode.builder() .addList(\"app.basic-range\", ListNode.builder() .addValue(\"-20\") .addValue(\"20\") .build()) .build())); ConfigSources.create variants for Properties or Map arguments return a MapConfigSource.Builder instance. ",
            "title": "In-memory Config Sources"
        },
        {
            "location": "/se/config/advanced-configuration",
            "text": " Sometimes you might want to create a single config tree from multiple sources but in a way that keeps the config from different sources in different subtrees. The config system lets you assign a prefix to all keys from a given source using the ConfigSources.prefixed method. The following example shows two YAML files as config sources and the code to load each with a different prefix into a single Config tree: <markup lang=\"hocon\" title=\"File app.conf \" >greeting = \"Hello\" page-size = 20 basic-range = [ -20, 20 ] <markup lang=\"hocon\" title=\"File data.conf \" >providers: [ { name = \"Provider1\" class = \"this.is.my.Provider1\" }, { name = \"Provider2\" class = \"this.is.my.Provider2\" } ] <markup lang=\"java\" title=\"Using prefixed config source\" >Config config = Config.create( ConfigSources.prefixed(\"app\", classpath(\"app.conf\")), ConfigSources.prefixed(\"data\", classpath(\"data.conf\"))); assert config.get(\"app.greeting\") .asString() .get() .equals(\"Hello\"); assert config.get(\"data.providers.0.name\") .asString() .get() .equals(\"Provider1\"); Specifies the prefix app for the associated source. Supplier&lt;ConfigSource&gt; for the file app.conf loaded from the current classpath . Specifies the prefix data for the associated source. Supplier&lt;ConfigSource&gt; for the file app.conf loaded from the current classpath . Key app.greeting combines the app prefix and the original key greeting from the app.conf source. Key data.providers.0.name combines the data prefix and the original key providers.0.name property from data.conf source. This technique can be useful, for example, if multiple sources contain keys that might overlap; assigning different prefixes to the keys from different sources gives your application a way to access all config elements distinctly even if their keys would otherwise conflict. ",
            "title": "Prefixed Config Sources"
        },
        {
            "location": "/se/config/advanced-configuration",
            "text": " When creating config from multiple sources, it is possible that the same key comes from multiple sources. By default, earlier sources in the list have higher priority than later ones. This means that if the same key appears in two or more sources, then the source earlier in the list prevails. The config system provides the FallbackMergingStrategy which implements the default, \"first wins\" algorithm. You can write your own implementation of MergingStrategy interface and use it instead to provide a different algorithm. <markup lang=\"java\" title=\"Composite config source example\" >Config config = Config.builder() .addSource(file(\"config-file.properties\")) .addSource(classpath(\"application.yaml\")) .mergingStrategy(MergingStrategy.fallback()) .build(); Specifies the merging strategy. This example uses the default fallback merging strategy. ",
            "title": "Merging Strategies"
        },
        {
            "location": "/se/config/advanced-configuration",
            "text": " Prefixed Config Sources Sometimes you might want to create a single config tree from multiple sources but in a way that keeps the config from different sources in different subtrees. The config system lets you assign a prefix to all keys from a given source using the ConfigSources.prefixed method. The following example shows two YAML files as config sources and the code to load each with a different prefix into a single Config tree: <markup lang=\"hocon\" title=\"File app.conf \" >greeting = \"Hello\" page-size = 20 basic-range = [ -20, 20 ] <markup lang=\"hocon\" title=\"File data.conf \" >providers: [ { name = \"Provider1\" class = \"this.is.my.Provider1\" }, { name = \"Provider2\" class = \"this.is.my.Provider2\" } ] <markup lang=\"java\" title=\"Using prefixed config source\" >Config config = Config.create( ConfigSources.prefixed(\"app\", classpath(\"app.conf\")), ConfigSources.prefixed(\"data\", classpath(\"data.conf\"))); assert config.get(\"app.greeting\") .asString() .get() .equals(\"Hello\"); assert config.get(\"data.providers.0.name\") .asString() .get() .equals(\"Provider1\"); Specifies the prefix app for the associated source. Supplier&lt;ConfigSource&gt; for the file app.conf loaded from the current classpath . Specifies the prefix data for the associated source. Supplier&lt;ConfigSource&gt; for the file app.conf loaded from the current classpath . Key app.greeting combines the app prefix and the original key greeting from the app.conf source. Key data.providers.0.name combines the data prefix and the original key providers.0.name property from data.conf source. This technique can be useful, for example, if multiple sources contain keys that might overlap; assigning different prefixes to the keys from different sources gives your application a way to access all config elements distinctly even if their keys would otherwise conflict. Merging Strategies When creating config from multiple sources, it is possible that the same key comes from multiple sources. By default, earlier sources in the list have higher priority than later ones. This means that if the same key appears in two or more sources, then the source earlier in the list prevails. The config system provides the FallbackMergingStrategy which implements the default, \"first wins\" algorithm. You can write your own implementation of MergingStrategy interface and use it instead to provide a different algorithm. <markup lang=\"java\" title=\"Composite config source example\" >Config config = Config.builder() .addSource(file(\"config-file.properties\")) .addSource(classpath(\"application.yaml\")) .mergingStrategy(MergingStrategy.fallback()) .build(); Specifies the merging strategy. This example uses the default fallback merging strategy. ",
            "title": "Handling Key Collisions"
        },
        {
            "location": "/se/config/advanced-configuration",
            "text": " Although the examples above use a single source, you can build a single Config from multiple sources. Handling Key Collisions Prefixed Config Sources Sometimes you might want to create a single config tree from multiple sources but in a way that keeps the config from different sources in different subtrees. The config system lets you assign a prefix to all keys from a given source using the ConfigSources.prefixed method. The following example shows two YAML files as config sources and the code to load each with a different prefix into a single Config tree: <markup lang=\"hocon\" title=\"File app.conf \" >greeting = \"Hello\" page-size = 20 basic-range = [ -20, 20 ] <markup lang=\"hocon\" title=\"File data.conf \" >providers: [ { name = \"Provider1\" class = \"this.is.my.Provider1\" }, { name = \"Provider2\" class = \"this.is.my.Provider2\" } ] <markup lang=\"java\" title=\"Using prefixed config source\" >Config config = Config.create( ConfigSources.prefixed(\"app\", classpath(\"app.conf\")), ConfigSources.prefixed(\"data\", classpath(\"data.conf\"))); assert config.get(\"app.greeting\") .asString() .get() .equals(\"Hello\"); assert config.get(\"data.providers.0.name\") .asString() .get() .equals(\"Provider1\"); Specifies the prefix app for the associated source. Supplier&lt;ConfigSource&gt; for the file app.conf loaded from the current classpath . Specifies the prefix data for the associated source. Supplier&lt;ConfigSource&gt; for the file app.conf loaded from the current classpath . Key app.greeting combines the app prefix and the original key greeting from the app.conf source. Key data.providers.0.name combines the data prefix and the original key providers.0.name property from data.conf source. This technique can be useful, for example, if multiple sources contain keys that might overlap; assigning different prefixes to the keys from different sources gives your application a way to access all config elements distinctly even if their keys would otherwise conflict. Merging Strategies When creating config from multiple sources, it is possible that the same key comes from multiple sources. By default, earlier sources in the list have higher priority than later ones. This means that if the same key appears in two or more sources, then the source earlier in the list prevails. The config system provides the FallbackMergingStrategy which implements the default, \"first wins\" algorithm. You can write your own implementation of MergingStrategy interface and use it instead to provide a different algorithm. <markup lang=\"java\" title=\"Composite config source example\" >Config config = Config.builder() .addSource(file(\"config-file.properties\")) .addSource(classpath(\"application.yaml\")) .mergingStrategy(MergingStrategy.fallback()) .build(); Specifies the merging strategy. This example uses the default fallback merging strategy. ",
            "title": "Multi-Source Configs and Composite Config Sources"
        },
        {
            "location": "/se/config/advanced-configuration",
            "text": " Environment Variables Config Source The config system supports using environment variables as a config source, and is enabled by default. Since environment variable names are normally restricted to alphanumeric characters and underscore, this config source adds aliases that enable setting or overriding config entries with dotted and/or hyphenated keys. The mapping makes it possible to set or override a config entry with a key of \"foo.bar\" using an environment variable named \"FOO_BAR\" and \"foo.bar-baz\" using \"FOO_BAR_dash_BAZ\" . One use case for this mapping is config overrides in containers, where passing environment variables directly or via Kubernetes Secrets/ConfigMaps is common. Scripts that solve the mapping problem by explicitly converting variables to system properties can also be simplified. Aliases are produced for any environment variable name that matches all of the following: does not begin or end with a '_' character does not contain \"__\" contains one or more '_' characters For each such name, two aliases are added with the names mapped as follows: Replace any \"_dash_\" or \"_DASH_\" substrings with \"-\" , e.g. \"APP_PAGE_dash_SIZE\" becomes \"APP_PAGE-SIZE\" . Replace '_' with '.' and add as an alias, e.g. \"APP_GREETING\" is added as \"APP.GREETING\" and \"APP_PAGE-SIZE\" is added as \"APP.PAGE-SIZE\" . This mapping is added primarily to support mixed case config keys such as \"app.someCamelCaseKey\" . Convert the result of step 2 to lowercase and add as an alias, e.g. \"APP.GREETING\" is added as \"app.greeting\" and \"APP.PAGE-SIZE\" is added as \"app.page-size\" . Directory Config Source The config system supports using a file system directory as a config source. Each non-directory file in the directory becomes a config entry: the file name is the key and the contents of that file are used as the corresponding config String value. The following example shows, for example, one way to load Kubernetes secrets mounted on the pod&#8217;s filesystem. If the directory conf/secrets contains these two files <markup title=\"File secrets/username \" >jose <markup title=\"File secrets/password \" >^ery$ecretP&amp;ssword your application can load this as configuration as follows: <markup lang=\"java\" title=\"Using directory config source\" >Config secrets = Config.builder( ConfigSources.directory(\"conf/secrets\")) .disableEnvironmentVariablesSource() .disableSystemPropertiesSource() .build(); assert secrets.get(\"username\") .asString() .get() .equals(\"jose\"); assert secrets.get(\"password\") .asString() .get() .equals(\"^ery$ecretP&amp;ssword\"); Loads all files from the conf/secrets directory. No need to use environment variables or system properties as sources in building the Config . The loaded config maps the key username to the value jose &#8230;&#8203; &#8230;&#8203;and the key password to ^ery$ecretP&amp;ssword . Remember that your application can process the contents of a given file as configuration. See the config sources section and the ConfigSources.file JavaDoc. In-memory Config Sources The config system provides several ways to create a Config tree from data already in memory. See the ConfigSources javadoc for further details. The numerous variants of the from method construct ConfigSource or Builder&lt;ConfigSource&gt; instances. Subtree of Another Config <markup lang=\"java\" >Config anotherConfig = Config.create(classpath(\"application.conf\")); Config config = Config.create( ConfigSources.create(anotherConfig.get(\"data\"))); Properties Object <markup lang=\"java\" >Config config = Config.create( ConfigSources.create(System.getProperties()).build()); String of a Given Media Type <markup lang=\"java\" >Config config = Config.create( ConfigSources.create(\"app.greeting = Hi\", MediaTypes.create(\"text/x-java-properties\"))); Map <markup lang=\"java\" >Config config = Config.crate( ConfigSources.create(Map.of(\"app.page-size\", \"20\")) .build()); ad hoc Config Nodes <markup lang=\"java\" >Config config = Config.create( ConfigSources.create(ObjectNode.builder() .addList(\"app.basic-range\", ListNode.builder() .addValue(\"-20\") .addValue(\"20\") .build()) .build())); ConfigSources.create variants for Properties or Map arguments return a MapConfigSource.Builder instance. Multi-Source Configs and Composite Config Sources Although the examples above use a single source, you can build a single Config from multiple sources. Handling Key Collisions Prefixed Config Sources Sometimes you might want to create a single config tree from multiple sources but in a way that keeps the config from different sources in different subtrees. The config system lets you assign a prefix to all keys from a given source using the ConfigSources.prefixed method. The following example shows two YAML files as config sources and the code to load each with a different prefix into a single Config tree: <markup lang=\"hocon\" title=\"File app.conf \" >greeting = \"Hello\" page-size = 20 basic-range = [ -20, 20 ] <markup lang=\"hocon\" title=\"File data.conf \" >providers: [ { name = \"Provider1\" class = \"this.is.my.Provider1\" }, { name = \"Provider2\" class = \"this.is.my.Provider2\" } ] <markup lang=\"java\" title=\"Using prefixed config source\" >Config config = Config.create( ConfigSources.prefixed(\"app\", classpath(\"app.conf\")), ConfigSources.prefixed(\"data\", classpath(\"data.conf\"))); assert config.get(\"app.greeting\") .asString() .get() .equals(\"Hello\"); assert config.get(\"data.providers.0.name\") .asString() .get() .equals(\"Provider1\"); Specifies the prefix app for the associated source. Supplier&lt;ConfigSource&gt; for the file app.conf loaded from the current classpath . Specifies the prefix data for the associated source. Supplier&lt;ConfigSource&gt; for the file app.conf loaded from the current classpath . Key app.greeting combines the app prefix and the original key greeting from the app.conf source. Key data.providers.0.name combines the data prefix and the original key providers.0.name property from data.conf source. This technique can be useful, for example, if multiple sources contain keys that might overlap; assigning different prefixes to the keys from different sources gives your application a way to access all config elements distinctly even if their keys would otherwise conflict. Merging Strategies When creating config from multiple sources, it is possible that the same key comes from multiple sources. By default, earlier sources in the list have higher priority than later ones. This means that if the same key appears in two or more sources, then the source earlier in the list prevails. The config system provides the FallbackMergingStrategy which implements the default, \"first wins\" algorithm. You can write your own implementation of MergingStrategy interface and use it instead to provide a different algorithm. <markup lang=\"java\" title=\"Composite config source example\" >Config config = Config.builder() .addSource(file(\"config-file.properties\")) .addSource(classpath(\"application.yaml\")) .mergingStrategy(MergingStrategy.fallback()) .build(); Specifies the merging strategy. This example uses the default fallback merging strategy. ",
            "title": "Advanced Config Sources"
        },
        {
            "location": "/se/config/advanced-configuration",
            "text": " Most applications let the config system try to infer the media type of the config source. By default, config source implementations use the io.helidon.common.media.type.MediaTypes API to infer the source media type from the source, typically (but not always) based on the file type portion of the file path. Helidon media type module has a predefined set of mappings as configured in common/media-type/src/main/resources/io/helidon/common/media/type/default-media-types.properties , including the Config supported formats: .properties , .yaml , .json and .conf . To handle other formats you can implement and register your own io.helidon.common.media.type.spi.MediaTypeDetector Java Service implementations. (Typically, you would also write and register a config parser to translate that format; see Locating a Parser below.) ",
            "title": "By Inference"
        },
        {
            "location": "/se/config/advanced-configuration",
            "text": " Your application can specify what media type to use in interpreting a config source. Use this if your application knows the media type but the system might not be able to infer it correctly, either because no type detector would recognize it or because there might be more than one inferred media type. <markup lang=\"java\" title=\"Specify mediaType for config source\" >Config config = Config.create(classpath(\"props\") .mediaType(MediaTypes.create(\"text/x-java-properties\"))); The config system cannot infer the media type because there is no file type in the path props . The developer knows the file is in Java Properties format so specifies the media type explicitly. Note that a file type detector could be written to also inspect the contents of the file to infer the media type. The detectors provided by Helidon only inspect the suffix in the name of the file. ",
            "title": "By Application Directive"
        },
        {
            "location": "/se/config/advanced-configuration",
            "text": " By Inference Most applications let the config system try to infer the media type of the config source. By default, config source implementations use the io.helidon.common.media.type.MediaTypes API to infer the source media type from the source, typically (but not always) based on the file type portion of the file path. Helidon media type module has a predefined set of mappings as configured in common/media-type/src/main/resources/io/helidon/common/media/type/default-media-types.properties , including the Config supported formats: .properties , .yaml , .json and .conf . To handle other formats you can implement and register your own io.helidon.common.media.type.spi.MediaTypeDetector Java Service implementations. (Typically, you would also write and register a config parser to translate that format; see Locating a Parser below.) By Application Directive Your application can specify what media type to use in interpreting a config source. Use this if your application knows the media type but the system might not be able to infer it correctly, either because no type detector would recognize it or because there might be more than one inferred media type. <markup lang=\"java\" title=\"Specify mediaType for config source\" >Config config = Config.create(classpath(\"props\") .mediaType(MediaTypes.create(\"text/x-java-properties\"))); The config system cannot infer the media type because there is no file type in the path props . The developer knows the file is in Java Properties format so specifies the media type explicitly. Note that a file type detector could be written to also inspect the contents of the file to infer the media type. The detectors provided by Helidon only inspect the suffix in the name of the file. ",
            "title": "Identifying the Media Type"
        },
        {
            "location": "/se/config/advanced-configuration",
            "text": " Each config parser reports which media types it handles. Once the config system has determined a source&#8217;s media type, it searches the config parsers associated with the config builder for one that recognizes that media type. It then uses that parser to translate the config in the source into the in-memory config tree. The application can add one or more parsers to a Config.Builder using the addParser method. This makes the parser available for use by the config sources associated with that builder, but does not directly tie a given parser to a given source. The builder uses media-type matching to select one of the parsers registered with the builder for each source. If the config system cannot locate a parser that matches the media type of a source, it throws a ConfigException when trying to prepare the configuration. ",
            "title": "By Inference from media-type "
        },
        {
            "location": "/se/config/advanced-configuration",
            "text": " Your application can specify which parser to use for a config source. The AbstractConfigSourceBuilder class exposes the parser method, which accepts the ConfigParser to be used for that source. Several methods on ConfigSources such as classpath , directory , and file return this builder class. Generally try to rely on media-type matching rather than specifying a given parser for a given source in the application. This keeps your application more flexible, both by insulating it from implementation classes and by letting it easily take advantage of improvements in or alternatives to the parsers available for a given media type. <markup lang=\"java\" title=\"Specify parser for config source\" >Config config = Config.create(classpath(\"props\") .parser(ConfigParsers.properties())); The config system cannot infer the media type because there is no file type in the path props . The developer knows the file is in Java Properties format so specifies the properties parser explicitly. ",
            "title": "By Application Directive"
        },
        {
            "location": "/se/config/advanced-configuration",
            "text": " By Inference from media-type Each config parser reports which media types it handles. Once the config system has determined a source&#8217;s media type, it searches the config parsers associated with the config builder for one that recognizes that media type. It then uses that parser to translate the config in the source into the in-memory config tree. The application can add one or more parsers to a Config.Builder using the addParser method. This makes the parser available for use by the config sources associated with that builder, but does not directly tie a given parser to a given source. The builder uses media-type matching to select one of the parsers registered with the builder for each source. If the config system cannot locate a parser that matches the media type of a source, it throws a ConfigException when trying to prepare the configuration. By Application Directive Your application can specify which parser to use for a config source. The AbstractConfigSourceBuilder class exposes the parser method, which accepts the ConfigParser to be used for that source. Several methods on ConfigSources such as classpath , directory , and file return this builder class. Generally try to rely on media-type matching rather than specifying a given parser for a given source in the application. This keeps your application more flexible, both by insulating it from implementation classes and by letting it easily take advantage of improvements in or alternatives to the parsers available for a given media type. <markup lang=\"java\" title=\"Specify parser for config source\" >Config config = Config.create(classpath(\"props\") .parser(ConfigParsers.properties())); The config system cannot infer the media type because there is no file type in the path props . The developer knows the file is in Java Properties format so specifies the properties parser explicitly. ",
            "title": "Locating a Parser"
        },
        {
            "location": "/se/config/advanced-configuration",
            "text": " Although most applications are explicit about the config sources they use in building a Config , the config system often has to figure out what parser to use. It does so by: determining, the best that it can, the media type of the source, and locating a parser that can translate that media type. Identifying the Media Type By Inference Most applications let the config system try to infer the media type of the config source. By default, config source implementations use the io.helidon.common.media.type.MediaTypes API to infer the source media type from the source, typically (but not always) based on the file type portion of the file path. Helidon media type module has a predefined set of mappings as configured in common/media-type/src/main/resources/io/helidon/common/media/type/default-media-types.properties , including the Config supported formats: .properties , .yaml , .json and .conf . To handle other formats you can implement and register your own io.helidon.common.media.type.spi.MediaTypeDetector Java Service implementations. (Typically, you would also write and register a config parser to translate that format; see Locating a Parser below.) By Application Directive Your application can specify what media type to use in interpreting a config source. Use this if your application knows the media type but the system might not be able to infer it correctly, either because no type detector would recognize it or because there might be more than one inferred media type. <markup lang=\"java\" title=\"Specify mediaType for config source\" >Config config = Config.create(classpath(\"props\") .mediaType(MediaTypes.create(\"text/x-java-properties\"))); The config system cannot infer the media type because there is no file type in the path props . The developer knows the file is in Java Properties format so specifies the media type explicitly. Note that a file type detector could be written to also inspect the contents of the file to infer the media type. The detectors provided by Helidon only inspect the suffix in the name of the file. Locating a Parser By Inference from media-type Each config parser reports which media types it handles. Once the config system has determined a source&#8217;s media type, it searches the config parsers associated with the config builder for one that recognizes that media type. It then uses that parser to translate the config in the source into the in-memory config tree. The application can add one or more parsers to a Config.Builder using the addParser method. This makes the parser available for use by the config sources associated with that builder, but does not directly tie a given parser to a given source. The builder uses media-type matching to select one of the parsers registered with the builder for each source. If the config system cannot locate a parser that matches the media type of a source, it throws a ConfigException when trying to prepare the configuration. By Application Directive Your application can specify which parser to use for a config source. The AbstractConfigSourceBuilder class exposes the parser method, which accepts the ConfigParser to be used for that source. Several methods on ConfigSources such as classpath , directory , and file return this builder class. Generally try to rely on media-type matching rather than specifying a given parser for a given source in the application. This keeps your application more flexible, both by insulating it from implementation classes and by letting it easily take advantage of improvements in or alternatives to the parsers available for a given media type. <markup lang=\"java\" title=\"Specify parser for config source\" >Config config = Config.create(classpath(\"props\") .parser(ConfigParsers.properties())); The config system cannot infer the media type because there is no file type in the path props . The developer knows the file is in Java Properties format so specifies the properties parser explicitly. ",
            "title": "How Config Chooses Parsers"
        },
        {
            "location": "/se/config/advanced-configuration",
            "text": "<markup lang=\"java\" title=\"Specify JSON as media type for node\" >Config config = Config.create( classpath(\"application.yaml\") .mediaTypeMapping( key -&gt; \"app\".equals(key.toString()) ? Optional.of(MediaTypes.APPLICATION_JSON) : Optional.empty())); assert config.get(\"secrets.username\").asString() .get().equals(\"jose\"); assert config.get(\"secrets.password\").asString() .get().equals(\"^ery$ecretP&amp;ssword\"); assert config.get(\"app\").type() == Config.Type.OBJECT; assert config.get(\"app.greeting\") .asString().get().equals(\"Hello\"); assert config.get(\"app.page-size\") .asInt().get() == 20; assert config.get(\"app.basic-range.0\") .asInt().get() == -20; assert config.get(\"app.basic-range.1\") .asInt().get() == 20; The source builder&#8217;s mediaTypeMapping method accepts a function which returns the appropriate media types (if any) for config keys. The function says to treat the app property value as a JSON document and leave other nodes unchanged. Other properties are loaded as expected. Property app is now a structured object node. Because the function passed to mediaTypeMapping identifies the app node as a JSON document, the config system selects the config parser that is registered with the builder which also handles the JSON media type. Also, note that the config system replaces the original String value node with an object node resulting from parsing that String value as JSON. ",
            "title": "Specify Key-to-media-type Mapping"
        },
        {
            "location": "/se/config/advanced-configuration",
            "text": " Alternatively, your application could map config keys to the specific parsers you want to use for parsing those keys' values. <markup lang=\"java\" title=\"Specify JSON formatted property' parser instance\" >Config config = Config.create( classpath(\"application.yaml\") .parserMapping( key -&gt; \"app\".equals(key.toString()) ? Optional.of(HoconConfigParser.create()) : Optional.empty())); Uses the parserMapping method to map keys to parser instances. Tells the config system to use the HOCON parser for translating the String value of the app key. (HOCON is a superset of JSON.) As before, the config system replaces the value node in the containing config tree with the config tree resulting from the additional parse. ",
            "title": "Specify Key-to-parser Mapping"
        },
        {
            "location": "/se/config/advanced-configuration",
            "text": " A config value node might contain an entire config document in String form, but in a format different from the containing document. Your application can tell the config system to parse such a node as config in a different format and replace the String value node in the original tree with the config tree that results from parsing that String . In this example, a YAML document contains a JSON document as a leaf. <markup lang=\"yaml\" title=\"YAML file with included JSON formatted property\" >secrets: username: \"jose\" password: \"^ery$ecretP&amp;ssword\" app: &gt; { \"greeting\": \"Hello\", \"page-size\": 20, \"basic-range\": [ -20, 20 ] } The property app is itself formatted as a JSON document. Specify Key-to-media-type Mapping <markup lang=\"java\" title=\"Specify JSON as media type for node\" >Config config = Config.create( classpath(\"application.yaml\") .mediaTypeMapping( key -&gt; \"app\".equals(key.toString()) ? Optional.of(MediaTypes.APPLICATION_JSON) : Optional.empty())); assert config.get(\"secrets.username\").asString() .get().equals(\"jose\"); assert config.get(\"secrets.password\").asString() .get().equals(\"^ery$ecretP&amp;ssword\"); assert config.get(\"app\").type() == Config.Type.OBJECT; assert config.get(\"app.greeting\") .asString().get().equals(\"Hello\"); assert config.get(\"app.page-size\") .asInt().get() == 20; assert config.get(\"app.basic-range.0\") .asInt().get() == -20; assert config.get(\"app.basic-range.1\") .asInt().get() == 20; The source builder&#8217;s mediaTypeMapping method accepts a function which returns the appropriate media types (if any) for config keys. The function says to treat the app property value as a JSON document and leave other nodes unchanged. Other properties are loaded as expected. Property app is now a structured object node. Because the function passed to mediaTypeMapping identifies the app node as a JSON document, the config system selects the config parser that is registered with the builder which also handles the JSON media type. Also, note that the config system replaces the original String value node with an object node resulting from parsing that String value as JSON. Specify Key-to-parser Mapping Alternatively, your application could map config keys to the specific parsers you want to use for parsing those keys' values. <markup lang=\"java\" title=\"Specify JSON formatted property' parser instance\" >Config config = Config.create( classpath(\"application.yaml\") .parserMapping( key -&gt; \"app\".equals(key.toString()) ? Optional.of(HoconConfigParser.create()) : Optional.empty())); Uses the parserMapping method to map keys to parser instances. Tells the config system to use the HOCON parser for translating the String value of the app key. (HOCON is a superset of JSON.) As before, the config system replaces the value node in the containing config tree with the config tree resulting from the additional parse. ",
            "title": "Parsing a Config Value as Config"
        },
        {
            "location": "/se/config/advanced-configuration",
            "text": " Config sources and parsers work together to read and translate configuration data from some external form into the corresponding in-memory config tree. How Config Chooses Parsers Although most applications are explicit about the config sources they use in building a Config , the config system often has to figure out what parser to use. It does so by: determining, the best that it can, the media type of the source, and locating a parser that can translate that media type. Identifying the Media Type By Inference Most applications let the config system try to infer the media type of the config source. By default, config source implementations use the io.helidon.common.media.type.MediaTypes API to infer the source media type from the source, typically (but not always) based on the file type portion of the file path. Helidon media type module has a predefined set of mappings as configured in common/media-type/src/main/resources/io/helidon/common/media/type/default-media-types.properties , including the Config supported formats: .properties , .yaml , .json and .conf . To handle other formats you can implement and register your own io.helidon.common.media.type.spi.MediaTypeDetector Java Service implementations. (Typically, you would also write and register a config parser to translate that format; see Locating a Parser below.) By Application Directive Your application can specify what media type to use in interpreting a config source. Use this if your application knows the media type but the system might not be able to infer it correctly, either because no type detector would recognize it or because there might be more than one inferred media type. <markup lang=\"java\" title=\"Specify mediaType for config source\" >Config config = Config.create(classpath(\"props\") .mediaType(MediaTypes.create(\"text/x-java-properties\"))); The config system cannot infer the media type because there is no file type in the path props . The developer knows the file is in Java Properties format so specifies the media type explicitly. Note that a file type detector could be written to also inspect the contents of the file to infer the media type. The detectors provided by Helidon only inspect the suffix in the name of the file. Locating a Parser By Inference from media-type Each config parser reports which media types it handles. Once the config system has determined a source&#8217;s media type, it searches the config parsers associated with the config builder for one that recognizes that media type. It then uses that parser to translate the config in the source into the in-memory config tree. The application can add one or more parsers to a Config.Builder using the addParser method. This makes the parser available for use by the config sources associated with that builder, but does not directly tie a given parser to a given source. The builder uses media-type matching to select one of the parsers registered with the builder for each source. If the config system cannot locate a parser that matches the media type of a source, it throws a ConfigException when trying to prepare the configuration. By Application Directive Your application can specify which parser to use for a config source. The AbstractConfigSourceBuilder class exposes the parser method, which accepts the ConfigParser to be used for that source. Several methods on ConfigSources such as classpath , directory , and file return this builder class. Generally try to rely on media-type matching rather than specifying a given parser for a given source in the application. This keeps your application more flexible, both by insulating it from implementation classes and by letting it easily take advantage of improvements in or alternatives to the parsers available for a given media type. <markup lang=\"java\" title=\"Specify parser for config source\" >Config config = Config.create(classpath(\"props\") .parser(ConfigParsers.properties())); The config system cannot infer the media type because there is no file type in the path props . The developer knows the file is in Java Properties format so specifies the properties parser explicitly. Parsing a Config Value as Config A config value node might contain an entire config document in String form, but in a format different from the containing document. Your application can tell the config system to parse such a node as config in a different format and replace the String value node in the original tree with the config tree that results from parsing that String . In this example, a YAML document contains a JSON document as a leaf. <markup lang=\"yaml\" title=\"YAML file with included JSON formatted property\" >secrets: username: \"jose\" password: \"^ery$ecretP&amp;ssword\" app: &gt; { \"greeting\": \"Hello\", \"page-size\": 20, \"basic-range\": [ -20, 20 ] } The property app is itself formatted as a JSON document. Specify Key-to-media-type Mapping <markup lang=\"java\" title=\"Specify JSON as media type for node\" >Config config = Config.create( classpath(\"application.yaml\") .mediaTypeMapping( key -&gt; \"app\".equals(key.toString()) ? Optional.of(MediaTypes.APPLICATION_JSON) : Optional.empty())); assert config.get(\"secrets.username\").asString() .get().equals(\"jose\"); assert config.get(\"secrets.password\").asString() .get().equals(\"^ery$ecretP&amp;ssword\"); assert config.get(\"app\").type() == Config.Type.OBJECT; assert config.get(\"app.greeting\") .asString().get().equals(\"Hello\"); assert config.get(\"app.page-size\") .asInt().get() == 20; assert config.get(\"app.basic-range.0\") .asInt().get() == -20; assert config.get(\"app.basic-range.1\") .asInt().get() == 20; The source builder&#8217;s mediaTypeMapping method accepts a function which returns the appropriate media types (if any) for config keys. The function says to treat the app property value as a JSON document and leave other nodes unchanged. Other properties are loaded as expected. Property app is now a structured object node. Because the function passed to mediaTypeMapping identifies the app node as a JSON document, the config system selects the config parser that is registered with the builder which also handles the JSON media type. Also, note that the config system replaces the original String value node with an object node resulting from parsing that String value as JSON. Specify Key-to-parser Mapping Alternatively, your application could map config keys to the specific parsers you want to use for parsing those keys' values. <markup lang=\"java\" title=\"Specify JSON formatted property' parser instance\" >Config config = Config.create( classpath(\"application.yaml\") .parserMapping( key -&gt; \"app\".equals(key.toString()) ? Optional.of(HoconConfigParser.create()) : Optional.empty())); Uses the parserMapping method to map keys to parser instances. Tells the config system to use the HOCON parser for translating the String value of the app key. (HOCON is a superset of JSON.) As before, the config system replaces the value node in the containing config tree with the config tree resulting from the additional parse. ",
            "title": "Advanced Config Parsers"
        },
        {
            "location": "/se/config/advanced-configuration",
            "text": " As described in the hierarchical features section each config node (except the root) has a non-null key. Important To emphasize, the dot character (&#8220;.&#8221;) has special meaning as a name separator in keys. To include a dot as a character in a key escape it as &#8220;~1&#8221;. For example, the following configuration file contains two object nodes with names oracle and oracle.com . <markup lang=\"json\" title=\"Example application.json with dot character in key\" >{ \"oracle\" : { \"com\" : true, \"cz\" : false }, \"oracle.com\" : { \"secured\" : true } } <markup lang=\"java\" title=\"Working with configuration with dot character in node name\" >Config config = Config.create(classpath(\"application.json\")); // node `oracle` assert config.get(\"oracle.com\").asBoolean().get() == true; assert config.get(\"oracle\").get(\"com\").asBoolean().get() == true; assert config.get(\"oracle.com\").type() == Type.VALUE; assert config.get(\"oracle.com\").name().equals(\"com\"); // node `oracle.com` assert config.get(\"oracle~1com.secured\").asBoolean().get() == true; assert config.get(Key.escapeName(\"oracle.com\")) .get(\"secured\").asBoolean().get() == true; assert config.get(Key.escapeName(\"oracle.com\")).type() == Type.OBJECT; assert config.get(Key.escapeName(\"oracle.com\")).name().equals(\"oracle.com\"); Work with the first oracle object as usual. As always you can use the fully-qualified key oracle.com or chain get(key) calls to access the com property value. Config node \"oracle\" / \"com\" is a leaf node (has type VALUE )&#8230;&#8203; &#8230;&#8203; and has the name com (the last token in its key). The second object has name oracle.com . The code must escape the dot in the node&#8217;s name using oracle~1com . Or, use the utility method Config.Key.escapeName(name) to escape dots or tildes that might be in the node&#8217;s name, in this example in oracle.com . The config node \"oracle.com\" has type OBJECT &#8230;&#8203; &#8230;&#8203;and name \"oracle.com\" . ",
            "title": "Config Keys with . in name"
        },
        {
            "location": "/se/config/advanced-configuration",
            "text": " Each filter accepts a key and the value as defined in the source, and returns the value to be used. The filter can leave the value unchanged or alter it, as it sees fit. The built-in value-resolving filter enables the token substitution described below. See the ConfigFilter JavaDoc for more information. ",
            "title": "Filters"
        },
        {
            "location": "/se/config/advanced-configuration",
            "text": " The overrides feature allows you to create an external document containing key/value pairs which replace the value otherwise returned for the name, and then add that document as an override source to a config builder. There are some key differences between overrides and filters. Because overrides are loaded from sources those sources can change while your application runs and so the overrides they that prescribe can change. The override document can use wildcards in key expressions. Overrides can affect only keys that already exist in the original source; filters can supply values even if the key is absent from the config source. Each override entry consists of a Java properties-format definition. The key is an expression (which can use wildcards) to match config keys read from the current config sources, and the override value is the new value for any key matching the key expression from that entry. Order is important. The config system tests every key expression/value pair one by one in the order they appear in the overrides sources. Once the config system finds an override entry in which the key expression matches the configuration key, the system returns that entry&#8217;s value for the key being processed. See the OverrideSource JavaDoc for more detail. ",
            "title": "Overrides"
        },
        {
            "location": "/se/config/advanced-configuration",
            "text": " A token reference is a key token starting with $ , optionally enclosed between { and } , i.e. $ref , ${ref} . Even a key composed of more than one token can be referenced in another key, i.e. ${env.ref} . As an example use case, you can use token references to declare the default values (see resolving-tokens.yaml below), while the references may be resolved in another config source, which identifies a current environment (see env.yaml examples below). You can then use the same overrides for different environments, say test and prod . The configuration in each environment is then overridden with a different values using wildcards (see overrides.properties below). <markup lang=\"java\" title=\"Initialize Config with Override Definition from overrides.properties file\" >Config config = Config.builder() .overrides(OverrideSources.file(\"conf/overrides.properties\")) .sources(file(\"conf/env.yaml\"), classpath(\"resolving-tokens.yaml\")) .build(); Loads overrides from the specified file. A deployment-specific environment configuration file. A default configuration containing token references that are resolved using the environment-specific override. You can disable key and value token replacement separately as the following example shows. <markup lang=\"java\" title=\"Disabling Key and Value Token Replacement\" >Config config = Config.builder() .disableKeyResolving() .disableValueResolving() // other Config builder settings .build(); ",
            "title": "Tokens"
        },
        {
            "location": "/se/config/advanced-configuration",
            "text": " When your application retrieves a config value, the config system can transform it before returning the value, according to filters , overrides , and tokens . The config system provides some built-in instances of these you can use, and you can add your own as described in the sections which describe filters and overrides . Your application can add filters and overrides explicitly to a config builder and the config system by default uses the Java service loader mechanism to locate all available filters and overrides and add them automatically to all config builders (unless your code disables that behavior for a given builder). Filters Each filter accepts a key and the value as defined in the source, and returns the value to be used. The filter can leave the value unchanged or alter it, as it sees fit. The built-in value-resolving filter enables the token substitution described below. See the ConfigFilter JavaDoc for more information. Overrides The overrides feature allows you to create an external document containing key/value pairs which replace the value otherwise returned for the name, and then add that document as an override source to a config builder. There are some key differences between overrides and filters. Because overrides are loaded from sources those sources can change while your application runs and so the overrides they that prescribe can change. The override document can use wildcards in key expressions. Overrides can affect only keys that already exist in the original source; filters can supply values even if the key is absent from the config source. Each override entry consists of a Java properties-format definition. The key is an expression (which can use wildcards) to match config keys read from the current config sources, and the override value is the new value for any key matching the key expression from that entry. Order is important. The config system tests every key expression/value pair one by one in the order they appear in the overrides sources. Once the config system finds an override entry in which the key expression matches the configuration key, the system returns that entry&#8217;s value for the key being processed. See the OverrideSource JavaDoc for more detail. Tokens A token reference is a key token starting with $ , optionally enclosed between { and } , i.e. $ref , ${ref} . Even a key composed of more than one token can be referenced in another key, i.e. ${env.ref} . As an example use case, you can use token references to declare the default values (see resolving-tokens.yaml below), while the references may be resolved in another config source, which identifies a current environment (see env.yaml examples below). You can then use the same overrides for different environments, say test and prod . The configuration in each environment is then overridden with a different values using wildcards (see overrides.properties below). <markup lang=\"java\" title=\"Initialize Config with Override Definition from overrides.properties file\" >Config config = Config.builder() .overrides(OverrideSources.file(\"conf/overrides.properties\")) .sources(file(\"conf/env.yaml\"), classpath(\"resolving-tokens.yaml\")) .build(); Loads overrides from the specified file. A deployment-specific environment configuration file. A default configuration containing token references that are resolved using the environment-specific override. You can disable key and value token replacement separately as the following example shows. <markup lang=\"java\" title=\"Disabling Key and Value Token Replacement\" >Config config = Config.builder() .disableKeyResolving() .disableValueResolving() // other Config builder settings .build(); ",
            "title": "Filters, Overrides, and Token Substitution"
        },
        {
            "location": "/se/config/advanced-configuration",
            "text": " The method PollingStrategies.regular(Duration) returns builder for polling strategy. This builder provides executor method which your application can invoke, passing a java.util.concurrent.ScheduledExecutorService instance it requires for the polling work. By default, each polling strategy instance uses a separate thread pool executor. The following example shares the same executor for two different polling strategy instances. <markup lang=\"java\" title=\"Customize polling strategy executors\" >ScheduledExecutorService executor = Executors.newScheduledThreadPool(2); Config config = Config.create( ConfigSources.file(\"conf/dev.properties\") .pollingStrategy( PollingStrategies.regular(Duration.ofSeconds(2)) .executor(executor)), ConfigSources.file(\"conf/config.properties\") .pollingStrategy( PollingStrategies.regular(Duration.ofSeconds(5)) .executor(executor))); Prepares a thread pool executor with core pool size set 2 . Selects the built-in periodic polling strategy. Tells the config system to use the specific executor to poll the dev.properties config source. Tells the config system to use the specific executor to poll the config.properties config source. ",
            "title": "Executors for Polling Strategy"
        },
        {
            "location": "/se/config/advanced-configuration",
            "text": " Recall that when a change watcher detects a change in a source, it informs interested parties of the changes. By default, each Config.Builder arranges for the resulting Config tree to use a shared executor that reuses available threads from a pool, creating new threads as needed. The same executor is used for actually reloading the source. Your application can invoke the system watcher builder&#8217;s executor method to tell the builder to use a different Executor . <markup lang=\"java\" title=\"Customize config and override sources' executors\" >ScheduledExecutorService executor = Executors.newScheduledThreadPool(2); Config config = Config.builder() .overrides( OverrideSources.file(\"conf/overrides.properties\") .changeWatcher(FileSystemWatcher.builder() .executor(executor) .build())) .sources( ConfigSources.file(\"conf/env.yaml\") .changeWatcher(FileSystemWatcher.builder() .executor(executor) .build())) .build(); Prepares a thread pool executor to be shared by selected sources. Tells the builder that the resulting overrides source should use the specified Executor for notifying interested parties of changes and for reloading the override source. Uses the same Executor and event buffer size for the config source as for the override source above. ",
            "title": "Executors for Source Change Events"
        },
        {
            "location": "/se/config/advanced-configuration",
            "text": " You can control which executor a retry policy should use for its work. The RetryPolicies.repeat(int retries) method returns a RetryPolicies.Builder . Your application can invoke the retry policy builder&#8217;s executor method to specify which ScheduledExecutorService instance it should use to schedule and execute delayed retries. By default, the config system uses a separate thread pool executor for each retry policy instance. <markup lang=\"java\" title=\"Customize retry policy executors\" >ScheduledExecutorService executor = Executors.newScheduledThreadPool(2, myThreadFactory); Config config = Config.create( ConfigSources.file(\"conf/dev.properties\") .optional() .retryPolicy(RetryPolicies.repeat(2) .executor(executor))); Prepares a thread pool executor with core pool size set to 2 and a custom java.util.concurrent.ThreadFactory . When the source is flagged as optional() , the loading attempt will be repeated as the retry policy defines, but an overall failure will not lead to failing the initial load or preventing the source from being polled if so configured. Uses the built-in repeating implementation of RetryPolicy that can be used with any config source, but typically for ones that might suffer brief, intermittent outages. Specifies the executor to use for loading and retries. ",
            "title": "Retry Policy Custom Executor"
        },
        {
            "location": "/se/config/advanced-configuration",
            "text": " Various parts of the config system work asynchronously: polling strategies to detect changes to config sources, publishers to notify your application when such changes occur, Config instances which subscribe to and respond to change notifications for their underlying sources, and retry policies (which might wait between retries). Each of these uses an executor to perform its work. The config system provides default executors, but your application can specify different ones if necessary. Executors for Polling Strategy The method PollingStrategies.regular(Duration) returns builder for polling strategy. This builder provides executor method which your application can invoke, passing a java.util.concurrent.ScheduledExecutorService instance it requires for the polling work. By default, each polling strategy instance uses a separate thread pool executor. The following example shares the same executor for two different polling strategy instances. <markup lang=\"java\" title=\"Customize polling strategy executors\" >ScheduledExecutorService executor = Executors.newScheduledThreadPool(2); Config config = Config.create( ConfigSources.file(\"conf/dev.properties\") .pollingStrategy( PollingStrategies.regular(Duration.ofSeconds(2)) .executor(executor)), ConfigSources.file(\"conf/config.properties\") .pollingStrategy( PollingStrategies.regular(Duration.ofSeconds(5)) .executor(executor))); Prepares a thread pool executor with core pool size set 2 . Selects the built-in periodic polling strategy. Tells the config system to use the specific executor to poll the dev.properties config source. Tells the config system to use the specific executor to poll the config.properties config source. Executors for Source Change Events Recall that when a change watcher detects a change in a source, it informs interested parties of the changes. By default, each Config.Builder arranges for the resulting Config tree to use a shared executor that reuses available threads from a pool, creating new threads as needed. The same executor is used for actually reloading the source. Your application can invoke the system watcher builder&#8217;s executor method to tell the builder to use a different Executor . <markup lang=\"java\" title=\"Customize config and override sources' executors\" >ScheduledExecutorService executor = Executors.newScheduledThreadPool(2); Config config = Config.builder() .overrides( OverrideSources.file(\"conf/overrides.properties\") .changeWatcher(FileSystemWatcher.builder() .executor(executor) .build())) .sources( ConfigSources.file(\"conf/env.yaml\") .changeWatcher(FileSystemWatcher.builder() .executor(executor) .build())) .build(); Prepares a thread pool executor to be shared by selected sources. Tells the builder that the resulting overrides source should use the specified Executor for notifying interested parties of changes and for reloading the override source. Uses the same Executor and event buffer size for the config source as for the override source above. Retry Policy Custom Executor You can control which executor a retry policy should use for its work. The RetryPolicies.repeat(int retries) method returns a RetryPolicies.Builder . Your application can invoke the retry policy builder&#8217;s executor method to specify which ScheduledExecutorService instance it should use to schedule and execute delayed retries. By default, the config system uses a separate thread pool executor for each retry policy instance. <markup lang=\"java\" title=\"Customize retry policy executors\" >ScheduledExecutorService executor = Executors.newScheduledThreadPool(2, myThreadFactory); Config config = Config.create( ConfigSources.file(\"conf/dev.properties\") .optional() .retryPolicy(RetryPolicies.repeat(2) .executor(executor))); Prepares a thread pool executor with core pool size set to 2 and a custom java.util.concurrent.ThreadFactory . When the source is flagged as optional() , the loading attempt will be repeated as the retry policy defines, but an overall failure will not lead to failing the initial load or preventing the source from being polled if so configured. Uses the built-in repeating implementation of RetryPolicy that can be used with any config source, but typically for ones that might suffer brief, intermittent outages. Specifies the executor to use for loading and retries. ",
            "title": "Executors for Asynchronous Config Activity"
        },
        {
            "location": "/se/config/config-profiles",
            "text": " Overview Profile Options Profile Config Source Profile Files ",
            "title": "Contents"
        },
        {
            "location": "/se/config/config-profiles",
            "text": " Configuration profiles provide a capability to prepare structure of configuration for each environment in advance, and then simply switch between these structures using a system property or an environment variable. ",
            "title": "Overview"
        },
        {
            "location": "/se/config/config-profiles",
            "text": " To choose a configuration profile to use at runtime, you can use: A system property config.profile An environment variable HELIDON_CONFIG_PROFILE There are two ways to define a profile configuration: Use a config source with a profile specific name Use a profile file defining all configuration sources Configuration profiles can only be used when config is created using the Config.create() method without parameters. If you explicitly configure sources, profiles are ignored. ",
            "title": "Profile Options"
        },
        {
            "location": "/se/config/config-profiles",
            "text": " If a profile is specified, config will load the profile-specific default configuration source before the \"main\" source. Let&#8217;s consider the selected profile is dev , and we have yaml configuration support on classpath; config will look for the following sources (in this order): application-dev.yaml on file system application-dev.properties on file system application-dev.yaml on classpath application-dev.properties on classpath application.yaml on file system application.properties on file system application.yaml on classpath application.properties on classpath ",
            "title": "Profile Config Sources"
        },
        {
            "location": "/se/config/config-profiles",
            "text": " The config system supports these built-in types: Built-in Types Type Use Related ConfigSources Method Required Properties system-properties System properties are a config source ConfigSources.systemProperties() n/a environment-variables Environment variables are a config source ConfigSources.environmentVariables() n/a classpath Specified resource is used as a config source ConfigSources.classpath(String) resource - path to the resource to load file Specified file is used as a config source ConfigSources.file(Path) path - path to the file to load directory Each file in directory used as config entry, with key = file name and value = file contents ConfigSources.directory(String) path - path to the directory to use url Specified URL is read as a config source ConfigSources.url(URL) url - URL from which to load the config inlined The whole configuration tree under properties is added as a configuration source (excluding the properties node) n/a n/a prefixed Associated config source is loaded with the specified prefix ConfigSources.prefixed(String,Supplier) key - key of config element in associated source to load type - associated config source specification properties - as needed to further qualify the associated config source Except for the system-properties and environment-variables types, the profile properties section for a source can also specify any optional settings for the corresponding config source type. The JavaDoc for the related config source type builders lists the supported properties for each type. (For example, FileConfigSource.FileBuilder .) Here is an example profile in YAML format. Note how the properties sections are at the same level as the type or class within a sources array entry. <markup lang=\"yaml\" title=\"Profile config-profile.yaml illustrating all built-in sources available on the classpath\" >caching.enabled: false sources: - type: \"system-properties\" - type: \"environment-variables\" - type: \"directory\" properties: path: \"conf/secrets\" media-type-mapping: yaml: \"application/x-yaml\" password: \"application/base64\" polling-strategy: type: \"regular\" properties: interval: \"PT15S\" - type: \"url\" properties: url: \"http://config-service/my-config\" media-type: \"application/hocon\" optional: true retry-policy: type: \"repeat\" properties: retries: 3 - type: \"file\" properties: optional: true path: \"conf/env.yaml\" change-watcher: type: \"file\" properties: delay-millis: 5000 - type: \"prefixed\" properties: key: \"app\" type: \"classpath\" properties: resource: \"app.conf\" - type: \"classpath\" properties: resource: \"application.conf\" Note that the example shows how your profile can configure optional features such as polling strategies and retry policies for config sources. ",
            "title": "Built-in Types"
        },
        {
            "location": "/se/config/config-profiles",
            "text": " Profiles can be used to set up custom config sources as well as the built-in ones described above. Implement the ConfigSourceProvider <markup lang=\"java\" >public class MyConfigSourceProvider implements ConfigSourceProvider { private static final String TYPE = \"my-type\"; @Override public boolean supports(String type) { return TYPE.equals(type); } @Override public ConfigSource create(String type, Config metaConfig) { // as we only support one in this implementation, we can just return it return MyConfigSource.create(metaConfig); } @Override public Set&lt;String&gt; supported() { return Collections.singleton(TYPE); } } Register it as a java service loader service <markup title=\"File META-INF/services/io.helidon.config.spi.ConfigSourceProvider \" >io.helidon.examples.MyConfigSourceProvider And in module-info.java if using JPMS: <markup lang=\"java\" title=\"File module-info.java \" >provides io.helidon.config.spi.ConfigSourceProvider with io.helidon.examples.MyConfigSourceProvider Now you can use the following profile: <markup lang=\"yaml\" >sources: - type: \"system-properties\" - type: \"environment-variables\" - type: \"my-type\" properties: my-property: \"some-value\" Note that it is the io.helidon.config.AbstractConfigSource class that provides support for polling strategies, change watchers, and retry policies. If you create custom config sources that should also offer this support be sure they extend AbstractConfigSource and implement appropriate SPI interfaces (such as io.helidon.config.spi.WatchableSource ) to support such features. ",
            "title": "Support for Custom Sources"
        },
        {
            "location": "/se/config/config-profiles",
            "text": " Your config profile can include the set-up for polling strategies, change watchers, and retry policies if the config source supports them. Declare them in a way similar to how you declare the config sources themselves: by type and with accompanying properties . Config Profile Support for Built-in Polling Strategies Strategy Type Usage Properties regular Periodic polling - See PollingStrategies.regular method interval ( Duration ) - indicating how often to poll; e.g., PT15S represents 15 seconds Config Profile Support for Built-in Change Watchers Type Usage Properties file Filesystem monitoring - See FileSystemWatcher class initial-delay-millis - delay between the start of the watcher and first check for changes delay-millis - how often do we check the watcher service for changes Config Profile Support for Built-in Retry Policies Policy Type Usage Properties repeat Regularly-scheduled - see RetryPolicies.repeat . retries ( int ) - number of retries to perform Optional: delay ( Duration ) - initial delay between retries delay-factor ( double ) - delay is repeatedly multiplied by this each retry to compute the delay for each successive retry call-timeout ( Duration ) - timeout for a single invocation to load the source overall-timeout ( Duration ) - total timeout for all retry calls and delays To specify a custom polling strategy or custom retry policy, implement the interface ( io.helidon.config.spi.PollingStrategy , io.helidon.config.spi.ChangeWatcher , or io.helidon.config.spi.RetryPolicy ), and then implement the provider interface ( io.helidon.config.spi.PollingStrategyProvider , io.helidon.config.spi.ChangeWatcherProvider , or io.helidon.config.spi.RetryPolicyProvider ) to enable your custom implementations for profiles. You can then use any custom properties - these are provided as a Config instance to the create method of the Provider implementation. See RetryPolicy , ChangeWatcher , and PollingStrategy JavaDoc sections. ",
            "title": "Support for Custom Polling Strategies, Change Watchers, and Retry Policies"
        },
        {
            "location": "/se/config/config-profiles",
            "text": " Configuration profile provides similar options to the configuration builder. The profile file must contain at least the list of sources from which configuration can be loaded. The root sources property contains an array (ordered) of objects defining each config source to be used. Each element of the array must contain at least the type property, determining the config source type (such as system-properties , file ). It may also contain a properties property with additional configuration of the config source. An example development profile using \"inlined\" configuration: <markup lang=\"yaml\" title=\"Config profile config-profile-dev.yaml \" >sources: - type: \"inlined\" properties: app.greeting: \"Hello World\" An example of a profile using environment variables, system properties, classpath, and file configuration: <markup lang=\"yaml\" title=\"Config profile config-profile-prod.yaml \" >sources: - type: \"environment-variables\" - type: \"system-properties\" - type: \"file\" properties: path: \"config/config-prod.yaml\" - type: \"classpath\" properties: resource: \"application.yaml\" Built-in Types The config system supports these built-in types: Built-in Types Type Use Related ConfigSources Method Required Properties system-properties System properties are a config source ConfigSources.systemProperties() n/a environment-variables Environment variables are a config source ConfigSources.environmentVariables() n/a classpath Specified resource is used as a config source ConfigSources.classpath(String) resource - path to the resource to load file Specified file is used as a config source ConfigSources.file(Path) path - path to the file to load directory Each file in directory used as config entry, with key = file name and value = file contents ConfigSources.directory(String) path - path to the directory to use url Specified URL is read as a config source ConfigSources.url(URL) url - URL from which to load the config inlined The whole configuration tree under properties is added as a configuration source (excluding the properties node) n/a n/a prefixed Associated config source is loaded with the specified prefix ConfigSources.prefixed(String,Supplier) key - key of config element in associated source to load type - associated config source specification properties - as needed to further qualify the associated config source Except for the system-properties and environment-variables types, the profile properties section for a source can also specify any optional settings for the corresponding config source type. The JavaDoc for the related config source type builders lists the supported properties for each type. (For example, FileConfigSource.FileBuilder .) Here is an example profile in YAML format. Note how the properties sections are at the same level as the type or class within a sources array entry. <markup lang=\"yaml\" title=\"Profile config-profile.yaml illustrating all built-in sources available on the classpath\" >caching.enabled: false sources: - type: \"system-properties\" - type: \"environment-variables\" - type: \"directory\" properties: path: \"conf/secrets\" media-type-mapping: yaml: \"application/x-yaml\" password: \"application/base64\" polling-strategy: type: \"regular\" properties: interval: \"PT15S\" - type: \"url\" properties: url: \"http://config-service/my-config\" media-type: \"application/hocon\" optional: true retry-policy: type: \"repeat\" properties: retries: 3 - type: \"file\" properties: optional: true path: \"conf/env.yaml\" change-watcher: type: \"file\" properties: delay-millis: 5000 - type: \"prefixed\" properties: key: \"app\" type: \"classpath\" properties: resource: \"app.conf\" - type: \"classpath\" properties: resource: \"application.conf\" Note that the example shows how your profile can configure optional features such as polling strategies and retry policies for config sources. Support for Custom Sources Profiles can be used to set up custom config sources as well as the built-in ones described above. Implement the ConfigSourceProvider <markup lang=\"java\" >public class MyConfigSourceProvider implements ConfigSourceProvider { private static final String TYPE = \"my-type\"; @Override public boolean supports(String type) { return TYPE.equals(type); } @Override public ConfigSource create(String type, Config metaConfig) { // as we only support one in this implementation, we can just return it return MyConfigSource.create(metaConfig); } @Override public Set&lt;String&gt; supported() { return Collections.singleton(TYPE); } } Register it as a java service loader service <markup title=\"File META-INF/services/io.helidon.config.spi.ConfigSourceProvider \" >io.helidon.examples.MyConfigSourceProvider And in module-info.java if using JPMS: <markup lang=\"java\" title=\"File module-info.java \" >provides io.helidon.config.spi.ConfigSourceProvider with io.helidon.examples.MyConfigSourceProvider Now you can use the following profile: <markup lang=\"yaml\" >sources: - type: \"system-properties\" - type: \"environment-variables\" - type: \"my-type\" properties: my-property: \"some-value\" Note that it is the io.helidon.config.AbstractConfigSource class that provides support for polling strategies, change watchers, and retry policies. If you create custom config sources that should also offer this support be sure they extend AbstractConfigSource and implement appropriate SPI interfaces (such as io.helidon.config.spi.WatchableSource ) to support such features. Support for Custom Polling Strategies, Change Watchers, and Retry Policies Your config profile can include the set-up for polling strategies, change watchers, and retry policies if the config source supports them. Declare them in a way similar to how you declare the config sources themselves: by type and with accompanying properties . Config Profile Support for Built-in Polling Strategies Strategy Type Usage Properties regular Periodic polling - See PollingStrategies.regular method interval ( Duration ) - indicating how often to poll; e.g., PT15S represents 15 seconds Config Profile Support for Built-in Change Watchers Type Usage Properties file Filesystem monitoring - See FileSystemWatcher class initial-delay-millis - delay between the start of the watcher and first check for changes delay-millis - how often do we check the watcher service for changes Config Profile Support for Built-in Retry Policies Policy Type Usage Properties repeat Regularly-scheduled - see RetryPolicies.repeat . retries ( int ) - number of retries to perform Optional: delay ( Duration ) - initial delay between retries delay-factor ( double ) - delay is repeatedly multiplied by this each retry to compute the delay for each successive retry call-timeout ( Duration ) - timeout for a single invocation to load the source overall-timeout ( Duration ) - total timeout for all retry calls and delays To specify a custom polling strategy or custom retry policy, implement the interface ( io.helidon.config.spi.PollingStrategy , io.helidon.config.spi.ChangeWatcher , or io.helidon.config.spi.RetryPolicy ), and then implement the provider interface ( io.helidon.config.spi.PollingStrategyProvider , io.helidon.config.spi.ChangeWatcherProvider , or io.helidon.config.spi.RetryPolicyProvider ) to enable your custom implementations for profiles. You can then use any custom properties - these are provided as a Config instance to the create method of the Provider implementation. See RetryPolicy , ChangeWatcher , and PollingStrategy JavaDoc sections. ",
            "title": "Profile File Format"
        },
        {
            "location": "/se/config/config-profiles",
            "text": " If a profile is specified, config will look for a profile-specific \"meta configuration\". Let&#8217;s consider the selected profile is dev , and we have yaml configuration support on classpath; config will look for the following profiles (in this order): config-profile-dev.yaml on file system config-profile-dev.properties on file system config-profile-dev.yaml on classpath config-profile-dev.properties on classpath If any of these files is discovered, it would be used to set up the configuration. In case none is found, the config falls back to profile specific config sources . The structure of the file is described below in profile file format . In case you need to customize the location of the profile file, you can use the system property io.helidon.config.meta-config . For example if it is configured to config/profile.yaml , config looks for file config/profile-dev.yaml when dev profile is configured. Profile File Format Configuration profile provides similar options to the configuration builder. The profile file must contain at least the list of sources from which configuration can be loaded. The root sources property contains an array (ordered) of objects defining each config source to be used. Each element of the array must contain at least the type property, determining the config source type (such as system-properties , file ). It may also contain a properties property with additional configuration of the config source. An example development profile using \"inlined\" configuration: <markup lang=\"yaml\" title=\"Config profile config-profile-dev.yaml \" >sources: - type: \"inlined\" properties: app.greeting: \"Hello World\" An example of a profile using environment variables, system properties, classpath, and file configuration: <markup lang=\"yaml\" title=\"Config profile config-profile-prod.yaml \" >sources: - type: \"environment-variables\" - type: \"system-properties\" - type: \"file\" properties: path: \"config/config-prod.yaml\" - type: \"classpath\" properties: resource: \"application.yaml\" Built-in Types The config system supports these built-in types: Built-in Types Type Use Related ConfigSources Method Required Properties system-properties System properties are a config source ConfigSources.systemProperties() n/a environment-variables Environment variables are a config source ConfigSources.environmentVariables() n/a classpath Specified resource is used as a config source ConfigSources.classpath(String) resource - path to the resource to load file Specified file is used as a config source ConfigSources.file(Path) path - path to the file to load directory Each file in directory used as config entry, with key = file name and value = file contents ConfigSources.directory(String) path - path to the directory to use url Specified URL is read as a config source ConfigSources.url(URL) url - URL from which to load the config inlined The whole configuration tree under properties is added as a configuration source (excluding the properties node) n/a n/a prefixed Associated config source is loaded with the specified prefix ConfigSources.prefixed(String,Supplier) key - key of config element in associated source to load type - associated config source specification properties - as needed to further qualify the associated config source Except for the system-properties and environment-variables types, the profile properties section for a source can also specify any optional settings for the corresponding config source type. The JavaDoc for the related config source type builders lists the supported properties for each type. (For example, FileConfigSource.FileBuilder .) Here is an example profile in YAML format. Note how the properties sections are at the same level as the type or class within a sources array entry. <markup lang=\"yaml\" title=\"Profile config-profile.yaml illustrating all built-in sources available on the classpath\" >caching.enabled: false sources: - type: \"system-properties\" - type: \"environment-variables\" - type: \"directory\" properties: path: \"conf/secrets\" media-type-mapping: yaml: \"application/x-yaml\" password: \"application/base64\" polling-strategy: type: \"regular\" properties: interval: \"PT15S\" - type: \"url\" properties: url: \"http://config-service/my-config\" media-type: \"application/hocon\" optional: true retry-policy: type: \"repeat\" properties: retries: 3 - type: \"file\" properties: optional: true path: \"conf/env.yaml\" change-watcher: type: \"file\" properties: delay-millis: 5000 - type: \"prefixed\" properties: key: \"app\" type: \"classpath\" properties: resource: \"app.conf\" - type: \"classpath\" properties: resource: \"application.conf\" Note that the example shows how your profile can configure optional features such as polling strategies and retry policies for config sources. Support for Custom Sources Profiles can be used to set up custom config sources as well as the built-in ones described above. Implement the ConfigSourceProvider <markup lang=\"java\" >public class MyConfigSourceProvider implements ConfigSourceProvider { private static final String TYPE = \"my-type\"; @Override public boolean supports(String type) { return TYPE.equals(type); } @Override public ConfigSource create(String type, Config metaConfig) { // as we only support one in this implementation, we can just return it return MyConfigSource.create(metaConfig); } @Override public Set&lt;String&gt; supported() { return Collections.singleton(TYPE); } } Register it as a java service loader service <markup title=\"File META-INF/services/io.helidon.config.spi.ConfigSourceProvider \" >io.helidon.examples.MyConfigSourceProvider And in module-info.java if using JPMS: <markup lang=\"java\" title=\"File module-info.java \" >provides io.helidon.config.spi.ConfigSourceProvider with io.helidon.examples.MyConfigSourceProvider Now you can use the following profile: <markup lang=\"yaml\" >sources: - type: \"system-properties\" - type: \"environment-variables\" - type: \"my-type\" properties: my-property: \"some-value\" Note that it is the io.helidon.config.AbstractConfigSource class that provides support for polling strategies, change watchers, and retry policies. If you create custom config sources that should also offer this support be sure they extend AbstractConfigSource and implement appropriate SPI interfaces (such as io.helidon.config.spi.WatchableSource ) to support such features. Support for Custom Polling Strategies, Change Watchers, and Retry Policies Your config profile can include the set-up for polling strategies, change watchers, and retry policies if the config source supports them. Declare them in a way similar to how you declare the config sources themselves: by type and with accompanying properties . Config Profile Support for Built-in Polling Strategies Strategy Type Usage Properties regular Periodic polling - See PollingStrategies.regular method interval ( Duration ) - indicating how often to poll; e.g., PT15S represents 15 seconds Config Profile Support for Built-in Change Watchers Type Usage Properties file Filesystem monitoring - See FileSystemWatcher class initial-delay-millis - delay between the start of the watcher and first check for changes delay-millis - how often do we check the watcher service for changes Config Profile Support for Built-in Retry Policies Policy Type Usage Properties repeat Regularly-scheduled - see RetryPolicies.repeat . retries ( int ) - number of retries to perform Optional: delay ( Duration ) - initial delay between retries delay-factor ( double ) - delay is repeatedly multiplied by this each retry to compute the delay for each successive retry call-timeout ( Duration ) - timeout for a single invocation to load the source overall-timeout ( Duration ) - total timeout for all retry calls and delays To specify a custom polling strategy or custom retry policy, implement the interface ( io.helidon.config.spi.PollingStrategy , io.helidon.config.spi.ChangeWatcher , or io.helidon.config.spi.RetryPolicy ), and then implement the provider interface ( io.helidon.config.spi.PollingStrategyProvider , io.helidon.config.spi.ChangeWatcherProvider , or io.helidon.config.spi.RetryPolicyProvider ) to enable your custom implementations for profiles. You can then use any custom properties - these are provided as a Config instance to the create method of the Provider implementation. See RetryPolicy , ChangeWatcher , and PollingStrategy JavaDoc sections. ",
            "title": "Profile Files"
        },
        {
            "location": "/se/config/extensions",
            "text": " Overview Configuring an Extension Config-SPI-ConfigSource Config-SPI-ConfigParser Config-SPI-OverrideSource Config-SPI-ConfigFilter Config-SPI-ConfigMapperProvider Change Support SPI Config-SPI-RetryPolicy ",
            "title": "Contents"
        },
        {
            "location": "/se/config/extensions",
            "text": " Developer-provided extensions influence how the config system behaves. The getting_started'}\">config system introduction explains the design of the config system and how its parts work together to read and parse config data, convert it to Java types, fine-tune the look-up of config data, and reload and reprocess data when it changes. _Config extensions provided by the application modify and expand the way the config system performs these steps. Each config extension implements one of the interfaces defined in the Configuration SPI: ConfigSource - Loads raw configuration data from a given type of source and delegates to a ConfigParser , producing the in-memory data structure which represents the loaded and parsed configuration. ConfigParser - Translates configuration content in a given format into the corresponding internal config data structures. OverrideSource - Provides key/value pairs which override config values loaded from any ConfigSource , given the key and ignoring the original value. ConfigFilter - Transforms config String values returned from any value-type Config node, given the key and the original value. ConfigMapperProvider - Provides one or more ConfigMapper s each of which converts a Config object tree to a Java type specific to the application. PollingStrategy - Implements a custom technique to trigger polling of underlying sources for changes ChangeWatcher - Implements a custom technique to watch underlying sources for changes and notifying the config system of such a change The extension mechanism of Config can also use Java ServiceLoader . For this purpose, you implement providers that serve as factories for your implementation of an extension. This is to support config profiles even for custom extensions. Service providers: ConfigMapperProvider - support for config mappers, automatically discovered by the config system ConfigFilter - support for config filters, automatically discovered by the config system ConfigParser - support for config parsers, automatically discovered by the config system ConfigSourceProvider - support for named config sources, configurable through profiles ChangeWatcherProvider - support for named change watchers, configurable through profiles OverrideSourceProvider - support for named override sources, configurable through profiles PollingStrategyProvider - support for named polling strategies, configurable through profiles RetryPolicyProvider - support for retry policies, configurable through profiles The config system itself implements several of these SPIs, as noted in the sections below. ",
            "title": "Overview"
        },
        {
            "location": "/se/config/extensions",
            "text": " The following example shows configuration of all possible extensions with Config (all custom extension have a name prefix My ): <markup lang=\"java\" >Config config = Config.builder() .addSource(FileConfigSource.builder() .changeWatcher(MyChangeWatcher.create()) .pollingStrategy(MyPollingStrategy.create()) .parser(MyConfigParser.create()) .retryPolicy(MyRetryPolicy.create())) .addSource(MySource.create()) .addFilter(MyFilter.create()) .overrides(MyOverrides.create()) .build() ",
            "title": "Manual Configuration with Builder"
        },
        {
            "location": "/se/config/extensions",
            "text": " The following extensions are loaded using a service loader for any configuration instance, and do not require an explicit setup: ConfigParser - each config parser on the classpath that implements ConfigParserProvider as a Java service loader service ConfigFilter - each filter on the classpath that implements ConfigFilter as a Java service loader service Other extensions are only used from Java service loader when you use config profiles. Mapping is done through the type configured in config profile, and the type defined by the extension provider interface. For example for config sources, the interface defines the following methods (only subset shown): <markup lang=\"java\" >boolean supports(String type); ConfigSource create(String type, Config metaConfig); Considering the following meta configuration (or config profile): <markup lang=\"yaml\" >sources: - type: \"my-type\" properties: my-config: \"configuration\" The config system would iterate through all ConfigSourceProvider implementations found through Java ServiceLoader based on their weight . First provider that returns true when supports(\"my-type\") is called would be used, and an instance of a ConfigSource created using create(\"my-type\", config) , where config is located on the node of properties from config profile. ",
            "title": "Automatic Configuration Using a Service Loader"
        },
        {
            "location": "/se/config/extensions",
            "text": " The config system invokes extensions of a given type in priority order. Developers can express the relative importance of an extension by annotating the service implementation class with @Weight . The default value is 100. The higher the weight, the more important the extension is. ",
            "title": "About Priority"
        },
        {
            "location": "/se/config/extensions",
            "text": " You can configure a custom extension in two ways: Manual configuration with builder Automatic configuration using a Java service loader Manual Configuration with Builder The following example shows configuration of all possible extensions with Config (all custom extension have a name prefix My ): <markup lang=\"java\" >Config config = Config.builder() .addSource(FileConfigSource.builder() .changeWatcher(MyChangeWatcher.create()) .pollingStrategy(MyPollingStrategy.create()) .parser(MyConfigParser.create()) .retryPolicy(MyRetryPolicy.create())) .addSource(MySource.create()) .addFilter(MyFilter.create()) .overrides(MyOverrides.create()) .build() Automatic Configuration Using a Service Loader The following extensions are loaded using a service loader for any configuration instance, and do not require an explicit setup: ConfigParser - each config parser on the classpath that implements ConfigParserProvider as a Java service loader service ConfigFilter - each filter on the classpath that implements ConfigFilter as a Java service loader service Other extensions are only used from Java service loader when you use config profiles. Mapping is done through the type configured in config profile, and the type defined by the extension provider interface. For example for config sources, the interface defines the following methods (only subset shown): <markup lang=\"java\" >boolean supports(String type); ConfigSource create(String type, Config metaConfig); Considering the following meta configuration (or config profile): <markup lang=\"yaml\" >sources: - type: \"my-type\" properties: my-config: \"configuration\" The config system would iterate through all ConfigSourceProvider implementations found through Java ServiceLoader based on their weight . First provider that returns true when supports(\"my-type\") is called would be used, and an instance of a ConfigSource created using create(\"my-type\", config) , where config is located on the node of properties from config profile. About Priority The config system invokes extensions of a given type in priority order. Developers can express the relative importance of an extension by annotating the service implementation class with @Weight . The default value is 100. The higher the weight, the more important the extension is. ",
            "title": "Configuring an Extension"
        },
        {
            "location": "/se/config/extensions",
            "text": " The config system includes built-in support for several types of sources (for example, Java String , Readable , Properties , and Map objects - see ConfigSources ). Implement a ConfigSource to load raw configuration data from a type of source that the config system does not already support. ConfigSource SPI For config sources that work directly with config nodes, the following API is available. These interfaces have an implementation provided by Helidon. The interfaces ConfigNode , ObjectNode , ValueNode and ListNode represent the in-memory data structure for loaded and parsed configuration data. ConfigNode SPI For config sources that work return data ( NodeConfigSource and ParsableConfigSource ) a Content must be returned that describes the loaded data. The following diagram depicts the Content API. Content SPI Some methods provided are not always mandatory, yet they are part of the APIs to simplify the overall class structure: ConfigContent.stamp() - this method is used by PollingStrategy to determine if content has been changed. This can be always empty for sources, that do not implement PollableSource ConfigParser.Content.charset() - this can return any Charset for media types that are binary ConfigParser.Content.mediaType() - this can be used to override media type (that would otherwise be \"guessed\" from the underlying source) ParsableSource.parser() - this can be used to override parser (that would otherwise be based on mediaType ) ParsableSource.mediaType() - return the configured or \"guessed\" media type of this source, see io.helidon.common.media.type.MediaTypes , if not returned, media type must be present on Content , or provided through media type mapping ",
            "title": "ConfigSource SPI"
        },
        {
            "location": "/se/config/extensions",
            "text": " The parsing step converts config data in some format into the corresponding in-memory representation of config ObjectNode s. The config system can already parse several data formats (for example Java Properties , YAML, and HOCON). Implement the ConfigParser SPI to allow the config system to handle additional formats. ConfigParser SPI The ConfigParser.Content interface defines operations on the content that is to be parsed by a ConfigParser implementation: mediaType() - Reports the media type of the content (if it is to override media type defined on the config source) data() - Provides the InputStream with config source data charset() - Defines the charset to use to parse the stream in case this is a text based media type, ignored by parsers of binary content The application can register parsers for a builder by invoking Config.Builder#addParser(ConfigParser) . The config system also uses the Java service loader mechanism to load automatically, for all builders, any parsers listed in the META-INF/services/io.helidon.config.spi.ConfigParser resource on the runtime classpath. Prevent autoloading of parsers for a given builder by invoking Config.Builder#disableParserServices() . ConfigParser accepts @Weight . See About Priority . <markup lang=\"listing\" title=\"Example custom parser implementation listed in META-INF/services/io.helidon.config.spi.ConfigParser \" >my.module.MyConfigParser <markup lang=\"java\" title=\"Example custom parser definition in module-info.java \" >module my.module { requires transitive io.helidon.config; provides io.helidon.config.spi.ConfigParser with myModule.MyConfigParser; } ",
            "title": "ConfigParser SPI"
        },
        {
            "location": "/se/config/extensions",
            "text": " When the application retrieves a configuration value the config system first uses the relevant config sources and filters. It then applies any overrides the application has provided. Each override has: a Predicate&lt;Config.Key&gt; (a boolean-valued function that operates on the config key), and a replacement, overriding , String value the config system should use if the predicate evaluates to true. To furnish overrides to the config system, implement the OverrideSource SPI one or more times and pass instances of those implementations to the config builder&#8217;s overrides method. The config system will apply the overrides returned from each OverrideSource to each config key requested from a Config that is based on that Config.Builder . To support custom override sources in config profiles, also implement the OverrideSourceProvider service loader SPI OverrideSource SPI Note that override sources can also implement PollableSource , and WatchableSource to add change support. ",
            "title": "OverrideSource SPI"
        },
        {
            "location": "/se/config/extensions",
            "text": " The ConfigFilter JavaDoc describes multiple methods for adding filters to a Config.Builder . Some accept a ConfigFilter directly and some accept a provider function which, when passed a Config instance, returns a ConfigFilter . Neither a ConfigFilter nor a provider function which furnishes one should access the Config instance passed to the provider function. Instead, implement the ConfigFilter.init(Config) method on the filter. The config system invokes the filters' init methods according to the filters priority . Recall that whenever any code invokes Config.get , the Config instance invokes the apply method of all registered filters. By the time the application retrieves config this way the config system will have run the init method on all the filters. But note that when a filter&#8217;s init method invokes Config.get , the init methods of lower-priority filters will not yet have run. ConfigFilter SPI ",
            "title": "Initializing Filters"
        },
        {
            "location": "/se/config/extensions",
            "text": " Before returning a String from Config.value() the config system applies any filters set up on the Config.Builder used to create the config tree that contains the config node of interest. The application provides filters as implementations of the ConfigFilter interface. Each filter is a function which accepts a Config.Key and an input String value and returns a String value the config system should use for that key going forward. The filter can return the original value or return some other value. The application registers filters and filter providers by passing ConfigFilter implementations to one of the config builder addFilter methods . The config system also uses the Java service loader mechanism to load additional filters automatically, for all builders, using the service interface described in the following table. Prevent a given builder from using the autoloaded filters by invoking the disableFilterServices method. Config SPI Interfaces for Filtering Interface Method Usage ConfigFilter Accepts @Weight . See About Priority . String apply(Config.Key key, String stringValue); Accepts a key and the corresponding String value and returns the String which the config system should use for that key. Initializing Filters The ConfigFilter JavaDoc describes multiple methods for adding filters to a Config.Builder . Some accept a ConfigFilter directly and some accept a provider function which, when passed a Config instance, returns a ConfigFilter . Neither a ConfigFilter nor a provider function which furnishes one should access the Config instance passed to the provider function. Instead, implement the ConfigFilter.init(Config) method on the filter. The config system invokes the filters' init methods according to the filters priority . Recall that whenever any code invokes Config.get , the Config instance invokes the apply method of all registered filters. By the time the application retrieves config this way the config system will have run the init method on all the filters. But note that when a filter&#8217;s init method invokes Config.get , the init methods of lower-priority filters will not yet have run. ConfigFilter SPI ",
            "title": "ConfigFilter SPI"
        },
        {
            "location": "/se/config/extensions",
            "text": " The config system provides built-in mappings from String values to various Java types. (See ConfigMappers .) To handle mappings to other types the application can register custom mappers with the config system by implementing the ConfigMapperProvider SPI. Such providers return a map, with entries in which: the key is the Java type (a Class object) the mapper produces, and the value is a ConfigMapper that converts the config in-memory data structure into the type in the key. The provider may also implement other methods for finer tuned conversion mechanisms: genericTypeMappers() returns a map with entries for specific GenericType conversions, for example when the provider supports only mapping for GenericType&lt;Map&lt;String, Integer&gt;&gt; mapper(Class) returns a conversion function (optional) that converts a config node to the typed instance (if supported by this provider) mapper(GenericType) returns a conversion function (optional) that coverts a config node to the GenericType (if supported by this provider) - for example in case this provider supports any Map&lt;String, ?&gt; type, such as Map&lt;String, Integer&gt; and Map&lt;String, Double&gt; The config conversion system works as follows: For Config.as(Class) : Check whether a conversion function exists for the class requested (from method mappers() ). Check whether a conversion function is provided by any ConfigMapperProvider with method mapper(Class) . Check whether a conversion function exists for a generic type for the class requested (from method genericTypeMappers ). Check whether a conversion function is provided by any ConfigMapperProvider with method mapper(GenericType) for a generic type for the class requested. For Config.as(GenericType) - the first two steps are skipped. The config system also uses the Java ServiceLoader mechanism to load automatically, for all builders, any mappers returned by the providers listed in the META-INF/services/io.helidon.config.spi.ConfigMapperProvider resource on the runtime classpath. The application can prevent autoloading of mappers for a given builder by invoking Config.Builder#disableMapperServices() . Note that the built-in mappers described in ConfigMappers still operate. Mapper providers accept @Weight . See About Priority . ConfigMapperProvider SPI A mapper provider can specify @Weight . If no weight is explicitly assigned, the value of 100 is assumed. <markup lang=\"java\" title=\"Reference custom mapper provider implementation in META-INF/services/io.helidon.config.spi.ConfigMapperProvider \" >my.module.MyConfigMapperProvider <markup lang=\"java\" title=\"Reference custom mapper provider implementation in module-info.java \" >module my.module { requires transitive io.helidon.config; provides io.helidon.config.spi.ConfigMapperProvider with my.module.MyConfigMapperProvider; } ",
            "title": "ConfigMapperProvider SPI"
        },
        {
            "location": "/se/config/extensions",
            "text": " An implementation of PollingStrategy gets an instance to poll, and triggers its poll method. The result of poll method may be used to update the polling strategy schedule. The approach of checking for changes is part of the config system, and the PollingStrategy does not need to be concerned with it. This is based on the source stamp as defined in ConfigContent and used in PollableSource.isModified(Object) methods. If a more sophisticated solution is needed, you may need to implement a ChangeWatcher instead. The config system offers polling strategy for periodic time-based checks. Often an application can create a config source simply by using one of the methods on ConfigSources (for example, ConfigSources#file(path) to get a builder and then invoke pollingStrategy passing a polling strategy. But the application can implement its own PollingStrategy and set it on the config source builder instead. PollingStrategy SPI To support polling strategies that can be configured in config profile, also implement the PollingStrategyProvider Java service loader SPI. ",
            "title": "PollingStrategy SPI"
        },
        {
            "location": "/se/config/extensions",
            "text": " An implementation of ChangeWatcher gets the underlying source information and a change listener. The \"watcher\" then watches for changes of the source and notifies the listener when a change occurs. This is designed to support sources that can react on changes (such as file system). When a polling mechanism is needed, please check PollingStrategy above. The config system offers a change watcher for any Path based config source (such as FileConfigSource ) and for the etcd config source. To use a change watcher, simply create a config source using its builder and register the change watcher on the builder (the config source must support appropriate type of change watchers). ChangeWatcher SPI To support change watchers that can be configured in config profile, also implement the ChangeWatcherProvider Java service loader SPI. ",
            "title": "ChangeWatcher SPI"
        },
        {
            "location": "/se/config/extensions",
            "text": " Once it loads a Config tree from ConfigSource , the config system does not itself change the in-memory Config tree. Even so, the underlying data available via the tree&#8217;s ConfigSource s can change. Implementations of PollingStrategy may trigger regular check whether a source has new data. Implementation of ChangeWatcher may watch the underlying source for changes and trigger an update. PollingStrategy SPI An implementation of PollingStrategy gets an instance to poll, and triggers its poll method. The result of poll method may be used to update the polling strategy schedule. The approach of checking for changes is part of the config system, and the PollingStrategy does not need to be concerned with it. This is based on the source stamp as defined in ConfigContent and used in PollableSource.isModified(Object) methods. If a more sophisticated solution is needed, you may need to implement a ChangeWatcher instead. The config system offers polling strategy for periodic time-based checks. Often an application can create a config source simply by using one of the methods on ConfigSources (for example, ConfigSources#file(path) to get a builder and then invoke pollingStrategy passing a polling strategy. But the application can implement its own PollingStrategy and set it on the config source builder instead. PollingStrategy SPI To support polling strategies that can be configured in config profile, also implement the PollingStrategyProvider Java service loader SPI. ChangeWatcher SPI An implementation of ChangeWatcher gets the underlying source information and a change listener. The \"watcher\" then watches for changes of the source and notifies the listener when a change occurs. This is designed to support sources that can react on changes (such as file system). When a polling mechanism is needed, please check PollingStrategy above. The config system offers a change watcher for any Path based config source (such as FileConfigSource ) and for the etcd config source. To use a change watcher, simply create a config source using its builder and register the change watcher on the builder (the config source must support appropriate type of change watchers). ChangeWatcher SPI To support change watchers that can be configured in config profile, also implement the ChangeWatcherProvider Java service loader SPI. ",
            "title": "Change Support SPI"
        },
        {
            "location": "/se/config/extensions",
            "text": " The builder for each ConfigSource and OverrideSource accepts a RetryPolicy governing if and how the source should deal with failures loading the underlying data. A retry policy accepts a function, the invocation of which the policy will govern according to its own implementation. Applications can use the predefined policies in RetryPolicies , such as RetryPolicies.justCall which simply invokes the function without any retry. That class also exposes a builder for constructing a time-based retry policy, with several parameters: Parameters Controlling Built-in RetryPolicy Parameter Usage Default delay Initial delay between calls to the function 200 ms delayFactor Multiplier applied to delay on each successive call 2 callTimeout Time limit for each individual call of the function 500 ms overallTimeout Limit for the total elapsed time attempting to call the function successfully, including delays between calls 2 s The actual delay between function call starts as delay and changes by the factor delayFactor on each successive attempt. Note that the job of each retry policy is to call the provided function successfully. As such, the policy must perform the first attempt as well as any retries. RetryPolicy SPI The application can try to cancel the overall execution of a RetryPolicy by invoking the RetryPolicy#cancel(boolean mayInterruptIfRunning) method. Ideally the retry policy implementation should be able to abort the execution of the retry policy, even while a function call is in progress, but the policy must respond to cancel between function calls. In either case cancel returns true if the retry was aborted without a successful call to the function, and false otherwise, including if the function call had already completed successfully or had previously been successfully canceled. To support retry policies in config profiles, also implement the Java service loader SPI RetryPolicyProvider . ",
            "title": "RetryPolicy SPI"
        },
        {
            "location": "/se/config/hierarchical-features",
            "text": " Overview Configuration Node Types Configuration Key In-memory Representation of Configuration Access by Key Access by General Navigation Detaching a Config Subtree ",
            "title": "Contents"
        },
        {
            "location": "/se/config/hierarchical-features",
            "text": " The config system represents configuration as a tree in memory. Many developers will choose to work directly with config values&#8201;&#8212;&#8201;values from the leaves in the tree&#8201;&#8212;&#8201;accessing them by their keys. You can also navigate explicitly among the nodes of the tree without using keys. This section describes what the tree looks like and how you can traverse it. ",
            "title": "Overview"
        },
        {
            "location": "/se/config/hierarchical-features",
            "text": " The config system represents configuration in memory using three types of nodes, each a different interface defined within the ConfigNode interface. ConfigNode Types Type Java Interface Usage object ConfigNode.ObjectNode Represents complex structure (a subtree). Its child nodes can be of any type. list ConfigNode.ListNode Represents a list of nodes. Its components can be of any type. value ConfigNode.ValueNode Represents a leaf node. A node of any type can have a String value. Each config tree in memory will have an object node as its root with child nodes as dictated by the source config data from which the config system built the tree. Missing Config Nodes If your application attempts to access a non-existent node, for example using <markup lang=\"java\" >config.get(\"key.does.not.exist\") the config system returns a Config node object with type MISSING . The in-memory config tree contains nodes only of types OBJECT , LIST , and VALUE . ",
            "title": "Configuration Node Types"
        },
        {
            "location": "/se/config/hierarchical-features",
            "text": " Each config node (except the root) has a non-null key. Here is the formal definition of what keys can be: <markup lang=\"abnf\" title=\"The ABNF syntax of config key\" >config-key = *1( key-token *( \".\" key-token ) ) key-token = *( unescaped / escaped ) unescaped = %x00-2D / %x2F-7D / %x7F-10FFFF ; %x2E ('.') and %x7E ('~') are excluded from 'unescaped' escaped = \"~\" ( \"0\" / \"1\" ) ; representing '~' and '.', respectively Important To emphasize, the dot character (&#8220;.&#8221;) has special meaning as a name separator in keys. To include a dot as a character in a key escape it as &#8220;~1&#8221;. To include a tilda escape it as &#8220;~0&#8221;. ",
            "title": "Configuration Key"
        },
        {
            "location": "/se/config/hierarchical-features",
            "text": " The following example is in HOCON (human-optimized config object notation) format. The config system supports HOCON as an extension module . <markup lang=\"hocon\" title=\"HOCON application.conf file\" >app { greeting = \"Hello\" page-size = 20 basic-range = [ -20, 20 ] } data { providers: [ { name = \"Provider1\" class = \"this.is.my.Provider1\" }, { name = \"Provider2\" class = \"this.is.my.Provider2\" } ] } The diagram below illustrates the in-memory tree for that configuration. Config Nodes structure of application.conf file Notes Each non-root node has a name which distinguishes it from other nodes with the same parent. The interpretation of the name depends on the node type. Node Type Name object value member name of the node within its parent list element index of the node within the containing list Each node&#8217;s key is the fully-qualified path using dotted names from the root to that node. The root has an empty key, empty name, and no value. The Config object exposes methods to return the name , key , and type of the node. ",
            "title": "In-memory Representation of Configuration"
        },
        {
            "location": "/se/config/hierarchical-features",
            "text": " For many applications, accessing configuration values by key will be the simplest approach. If you write the code with a specific configuration structure in mind, your code can retrieve the value from a specific configuration node very easily. Your application can specify the entire navigation path as the key to a single get invocation, using dotted notation to separate the names of the nodes along the path. The code can navigate one level at a time using chained get invocations, each specifying one level of the path to the expected node. Or, you can mix the two styles. All the following lines retrieve the same Config node. <markup lang=\"java\" title=\"Equivalent Config Retrievals\" >assert config.get(\"\") == config; Config provName1 = config.get(\"data.providers.0.name\"); Config provName2 = config.get(\"data.providers.0\").get(\"name\"); Config provName3 = config.get(\"data.providers\").get(\"0.name\"); Config provName4 = config.get(\"data\").get(\"providers.0\").get(\"name\"); Config provName5 = config.get(\"data\").get(\"providers\").get(\"0\").get(\"name\"); using a single key mixed style (composite key and single key) navigating one level with each get invocation The Config.get(key) method always returns a Config object without throwing an exception. If the specified key does not exist the method returns a Config node of type MISSING . There are several ways your application can tell whether a given config value exists. Method Usage exists Returns true or false ifExists Execute functional operations for present nodes type Returns enum value for the Config.Type ; Config.Type.MISSING if the node represents a config value that does not exist as Returns the ConfigValue with the correct type that has all methods of Optional and a few additional ones - see ConfigValue interface. The config system throws a MissingValueException if the application tries to access the value of a missing node by invoking the ConfigValue.get() method. ",
            "title": "Access by Key"
        },
        {
            "location": "/se/config/hierarchical-features",
            "text": " Some applications might need to work with configuration without knowing its structure or key names ahead of time, and such applications can use various methods on the Config class to do this. General Config Node Methods Method Usage asNodeList() Returns a ConfigValue&lt;List&lt;Config&gt;&gt;. For nodes of type OBJECT contains child nodes as a List . hasValue() For any node reports if the node has a value. This can be true for any node type except MISSING . isLeaf() Reports whether the node has no child nodes. Leaf nodes have no children and has a single value. key() Returns the fully-qualified path of the node using dotted notation. name() Returns the name of the node (the last part of the key). asNode() Returns a ConfigValue&lt;Config&gt; wrapped around the node traverse() traverse(Predicate&lt;Config&gt;) Returns a Stream&lt;Config&gt; as an iterative deepening depth-first traversal of the subtree type() Returns the Type enum value for the node: OBJECT , LIST , VALUE , or MISSING <markup lang=\"java\" title=\"List names of child nodes of an object node\" >List&lt;String&gt; appNodeNames = config.get(\"app\") .asNodeList() .map(nodes -&gt; { return nodes .stream() .map(Config::name) .sorted() .collect(Collectors.toList()); }) .orElse(Collections.emptyList()); assert appNodeNames.get(0).equals(\"basic-range\"); assert appNodeNames.get(1).equals(\"greeting\"); assert appNodeNames.get(2).equals(\"page-size\"); Get the ConfigValue with child Config instances. Map the node list to names using the Java Stream API (if present) Use an empty list if the \"app\" node does not exist Check that the list contains the expected child names: basic-range , greeting and page-size . <markup lang=\"java\" title=\"List child nodes of a list node\" >List&lt;Config&gt; providers = config.get(\"data.providers\") .asNodeList().orElse(Collections.emptyList()); assert providers.get(0).key().toString().equals(\"data.providers.0\"); assert providers.get(1).key().toString().equals(\"data.providers.1\"); Get child nodes of the data.providers list node as a List of Config instances. Check that the list contains the expected child nodes with keys data.providers.0 and data.providers.1 . The traverse() method returns a stream of the nodes in the subtree that is rooted at the current configuration node. Depending on the structure of the loaded configuration the stream contains a mix of object, list or leaf value nodes. <markup lang=\"java\" title=\"Traverse subtree below a list node\" >config.get(\"data.providers\") .traverse() .forEach(node -&gt; System.out.println(node.type() + \" \\t\" + node.key())); Visit the subtree rooted at the data.providers list node. Prints out following list of nodes (type and key): OBJECT data.providers.0 VALUE data.providers.0.name VALUE data.providers.0.class OBJECT data.providers.1 VALUE data.providers.1.name VALUE data.providers.1.class The optional Predicate&lt;Config&gt; argument to the traverse methods allows the application to prune the traversal of a subtree at any point. <markup lang=\"java\" title=\"Traverse root ( object ) node, skipping the entire data subtree\" >config.traverse(node -&gt; !node.name().equals(\"data\")) .forEach(node -&gt; System.out.println(node.type() + \" \\t\" + node.key())); Visit all root sub-nodes, excluding whole data tree structure but including others. Prints out following list of nodes (type and key): OBJECT app VALUE app.page-size VALUE app.greeting LIST app.basic-range VALUE app.basic-range.0 VALUE app.basic-range.1 ",
            "title": "Access by General Navigation"
        },
        {
            "location": "/se/config/hierarchical-features",
            "text": " Sometimes it can be convenient to write part of your application to deal with configuration without it knowing if or where the relevant configuration is plugged into a larger config tree. For example, the application.properties from the introduction section contains several settings prefixed with web such as web.page-size . Perhaps in another config source the same information might be stored as server.web.page-size : <markup lang=\"java\" title=\"Alternate Structure for Web Config\" >server.web.page-size: 40 server.web.debug = true server.web.ratio = 1.4 You might want to write the web portion of your app to work with a config subtree with keys that are independent of the subtree&#8217;s position in a larger tree. This would allow you to reuse the web portion of your application without change, regardless of which structure a config source used. One easy way to do this is to detach a subtree from a larger config tree. When your application invokes the Config.detach method it gets back a copy of the config node but with no parent. The copy and the original node both point to the same objects for their child nodes (if any). The original node is unchanged. <markup lang=\"java\" title=\"Detaching a Subtree\" >Config originalRoot = // from the original example `.conf` file Config alternateRoot = // from the alternate structure above Config detachedFromOriginal = originalRoot.get(\"web\").detach(); Config detachedFromAlternate = alternateRoot.get(\"server.web\").detach(); assert originalRoot.get(\"web.debug\").equals(\"true\"); assert alternateRoot.get(\"server.web.debug\").equals(\"true\"); assert detachedFromOriginal.get(\"debug\").equals(\"true\"); assert detachedFromAlternate.get(\"debug\").equals(\"true\"); Navigation depends on knowing the full structure of the config and so is different for the two cases. Detaching so the web node is the root can use the same key regardless of where the config subtree came from. ",
            "title": "Detaching a Config Subtree"
        },
        {
            "location": "/se/config/introduction",
            "text": " Overview Maven Coordinates Usage Configuration Reference Additional Information ",
            "title": "Contents"
        },
        {
            "location": "/se/config/introduction",
            "text": " Helidon provides a very flexible and comprehensive configuration system, offering you many application configuration choices. The Config component provides a Java API to load and process configuration data from various sources into a Config object which the application can then use. ",
            "title": "Overview"
        },
        {
            "location": "/se/config/introduction",
            "text": " To enable Config add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.config&lt;/groupId&gt; &lt;artifactId&gt;helidon-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/config/introduction",
            "text": " Configuration can be loaded from different types of locations and expressed in different formats. The config system includes support for several types of config sources, for example: Environment variables - the property is a name/value pair. Java system properties - the property is a name/value pair. Resources in the classpath - the contents of the resource is parsed according to its inferred format. File - the contents of the file is parsed according to its inferred format. Directory - each non-directory file in the directory becomes a config entry: the file name is the key. and the contents of that file are used as the corresponding config String value. A URL resource - contents is parsed according to its inferred format. A variety of in-memory data structures ( String , Map , Properties ) See the JavaDoc for the ConfigSources class for a complete list of the built-in config source types and how to use them. See the advanced topics' page for further information on some more involved aspects of config sources. ",
            "title": "Config Sources"
        },
        {
            "location": "/se/config/introduction",
            "text": " When it reads configuration text from sources, the config system uses config parsers to translate that text into the in-memory data structures representing that configuration. The config system includes several built-in parsers, such as for the Java properties, YAML, JSON, and HOCON formats. See this section for how to change your pom.xml to make parsers for those formats available to your application. Then your application can invoke the config builder&#8217;s addParser method so that builder will use the parsers you choose. You can extend the system with custom parsers of your own. Implement the ConfigParser interface, then construct a Config.Builder using the addParser method, passing an instance of your customer parser. Invoke one of the sources methods to include a source that uses the custom format and then build the Config object. See the advanced topics' page for further information on some more involved aspects of config parsers. ",
            "title": "Config Parsers"
        },
        {
            "location": "/se/config/introduction",
            "text": " A brief overview of the config system helps clarify its different parts and how they work together. Most applications will typically deal with more than one of these parts. These are the main parts of the configuration system: Config system - allows you to read configuration data in an application A config source - a location containing configuration data (File, Map, Properties etc.) A config parser - a component capable of transforming bytes into configuration data (such as JSON content, YAML etc.) Config Sources Configuration can be loaded from different types of locations and expressed in different formats. The config system includes support for several types of config sources, for example: Environment variables - the property is a name/value pair. Java system properties - the property is a name/value pair. Resources in the classpath - the contents of the resource is parsed according to its inferred format. File - the contents of the file is parsed according to its inferred format. Directory - each non-directory file in the directory becomes a config entry: the file name is the key. and the contents of that file are used as the corresponding config String value. A URL resource - contents is parsed according to its inferred format. A variety of in-memory data structures ( String , Map , Properties ) See the JavaDoc for the ConfigSources class for a complete list of the built-in config source types and how to use them. See the advanced topics' page for further information on some more involved aspects of config sources. Config Parsers When it reads configuration text from sources, the config system uses config parsers to translate that text into the in-memory data structures representing that configuration. The config system includes several built-in parsers, such as for the Java properties, YAML, JSON, and HOCON formats. See this section for how to change your pom.xml to make parsers for those formats available to your application. Then your application can invoke the config builder&#8217;s addParser method so that builder will use the parsers you choose. You can extend the system with custom parsers of your own. Implement the ConfigParser interface, then construct a Config.Builder using the addParser method, passing an instance of your customer parser. Invoke one of the sources methods to include a source that uses the custom format and then build the Config object. See the advanced topics' page for further information on some more involved aspects of config parsers. ",
            "title": "Usage"
        },
        {
            "location": "/se/config/introduction",
            "text": " Global configuration is a singleton instance of Config that is implicitly used by some components of Helidon, plus it provides a convenient mechanism for your application to retrieve configuration from anywhere in your code. By default global configuration is initialized to the default Config object (as returned by Config.create() ). But it is recommended that you initialize it explicitly. This is especially important if you define custom config sources. <markup >Config config = Config.create(); Config.global(config); Create configuration. This shows creating the default config, but it could be created from custom config sources. Assign it to the application&#8217;s global configuration You can use global configuration to conveniently retrieve the application&#8217;s configuration: <markup >Config config = Config.global(); ",
            "title": "Global Configuration"
        },
        {
            "location": "/se/config/introduction",
            "text": " Although the default configuration is very simple to use, your application can take full control of all configuration sources and precedence. You can do so by creating and invoking methods on a Config.Builder object to construct a Config instance. When your application prepares a Config.Builder it sets what ConfigSource s and ConfigParser s the builder should use in constructing the resulting Config object. The JavaDoc explains how to use the Config.Builder . See the Custom Configuration Sources and advanced config sources sections for detailed examples and further information. ",
            "title": "Custom Config Sources"
        },
        {
            "location": "/se/config/introduction",
            "text": " You have used Helidon to customize configuration behavior from your code using the Config and Config.Builder classes. As discussed previously, Config system reads configuration from a config source, which uses a config parser to translate the source into an in-memory tree which represents the configuration’s structure and values. This approach allows us to take any source data, be it a flat properties file or an object structure such as JSON, and transform it into a single tree that allows for overriding of values using heterogeneous config sources. We are using the . as a separator of tree structure. Example of two config sources that can be used by Config with the same data tree in different formats: A Properties source: <markup lang=\"properties\" >web.page-size=25 A YAML source: <markup lang=\"yaml\" >web: page-size: 25 The configuration has the same internal representation in Config . Once created, the Config object provides many methods the application can use to retrieve config data as various Java types. See the Config JavaDoc for complete details. <markup lang=\"java\" >int pageSize = config.get(\"web.page-size\") .asInt() .orElse(20); Or using the tree node approach: <markup lang=\"java\" >int pageSize = config .get(\"web\") .get(\"page-size\") .asInt() .orElse(20); For this first example we can see the basic features of Config : Configuration is a tree of Config nodes You can use . as a tree separator when requesting node values Each config value can be retrieved as a typed object, with shortcut methods for the most commonly used types, such as int , String , long and other You can immediately provide a default value for the cases the configuration option is not defined in any source ",
            "title": "Accessing Config Values"
        },
        {
            "location": "/se/config/introduction",
            "text": " The Config system treats config sources as a hierarchy, where the first source that has a specific configuration key \"wins\" and its value is used, other sources are not even queried for it. In order to properly configure your application using configuration sources, you need to understand the precedence rules that Helidon uses to merge your configuration data. If any of the Helidon required properties are not specified in one of these source, then Helidon will use a default value. For example the default configuration when you use Config.create() uses the following config sources in precedence order: System properties config source Environment variables config source A classpath config source called application.? where the ? depends on supported media types currently on the classpath.By default, it is properties , but if you have YAML support on classpath, it would be application.yaml (a ConfigParser may add additional supported suffixes for default file) Let&#8217;s consider the following keys: System property answer=42 Environment variable ANSWER=38 A key in a configuration file answer=36 When you request config.get(`answer ).asInt().orElse(25) , you would get `42 This allows you to configure environment specific configuration values through system properties, environment variables, or through files available on each environment (be it a physical machine, a Kubernetes pod, or a docker image) without changing your source code. ",
            "title": "Overriding Values"
        },
        {
            "location": "/se/config/introduction",
            "text": " Config system applies configured config filters on each value when it is requested for the first time. There is a built-in filter called ValueResolvingFilter (enabled by default, can be disabled through API) that resolves references to other keys in values in configuration. Example: Let&#8217;s consider the following example properties file <markup lang=\"properties\" >host=localhost first-service.host=${host}/firstservice second-service.host=${host}/secondservice The filter resolves the ${host} reference to the localhost value. This makes it easier to override values in testing and production, as you can just override the host key and leave the URIs same. See Filter, Overrides, and Token Substitution section for further information on some more involved aspects. ",
            "title": "Config Filters"
        },
        {
            "location": "/se/config/introduction",
            "text": " The Config object lets your application retrieve config data as a typed ConfigValue. You can retrieve a ConfigValue&lt;T&gt; using the following as methods in Config : * asString() - to get a string config value * asBoolean() and other accessors for primitive types * as(Class) - to get a value for a type that has a mapper configured * as(Generic) - to get a value for a type supporting generics (such as Set&lt;String&gt; ) * asMap() - to get a map of key to value pairs * asList(Class) - to get a list of typed values * as(Function&lt;Config,T&gt;) - to get a typed value providing a mapper function ConfigValue&lt;T&gt; can be used to obtain: * an Optional&lt;T&gt; value from a single node , * the T value from a single node interpreted as a basic Java type (primitive or simple object) already known to the config system (such as a boolean or a Double ), or * a complex Java type from a subtree of the config tree. + The config system automatically knows how to return List and Map complex types, and you can provide config mappers to convert a config subtree to whatever Java types your application needs. See Property Mapping page for details on how to use the built-in mappings and your own custom ones to convert to simple and complex types. ",
            "title": "Typed config values"
        },
        {
            "location": "/se/config/introduction",
            "text": " Config sources, especially those that depend on fallible mechanisms such as the network or a shared file system, might fail to load during momentary outages. The config system allows you to build resiliency into your application&#8217;s use of configuration that relies on such technologies. When your application builds a ConfigSource it can specify a retry policy . When the config system needs to load data from that source it delegates the load operation to that retry policy. That policy is responsible not only for loading the data but also for detecting errors during loading and implementing the algorithm for deciding when and how many times to retry a failed load before reporting a failure back to your application. The config system includes two predefined retry policies: Predefined Retry Policies Policy Summary \"just call\" (default) asks the config source to load the data with no retry \"repeat\" performs a settable number of time-based retries, reporting failure only after all available retries have failed See the RetryPolicies JavaDoc for complete details on these built-in retry policies. You can devise your own policy. Implement the RetryPolicy interface. Then pass an instance of your policy implementation to the config source builder&#8217;s retryPolicy method. ",
            "title": "Dealing with Loading Errors: Retry Policies"
        },
        {
            "location": "/se/config/introduction",
            "text": " Each Config object which the config system returns to your application is immutable; even if the information in one of the underlying config sources changes, an in-memory data structure built from the earlier content remains unchanged. Nevertheless, we know that configuration sometimes changes, and we may want to react to such changes. So the config system allows your application to learn when such underlying changes in the data occur and respond accordingly. In Config system, you can do this through change support provided by these components: Config.onChange() API - you can use to add your listener, to be notified of configuration changes PollingStrategy - a component providing regular events to check if a source has changed. This requires support in config sources themselves (see PollableSource ) ChangeWatcher - a component watching the underlying source for changes. This requires support in config sources themselves (see WatchableSource ) EventConfigSource - an event source that is capable of notifying about changes itself If you want to receive onChange events, you must configure your Config with at least one source that is capable of providing changes (having a PollingStrategy or ChangeWatcher configured, or implementing EventConfigSource ) The mutability documentation explains this in detail, and the PollingStrategies JavaDoc describes the built-in implementations. You can, of course, write your own by implementing the PollingStrategy interface. On a config source builder invoke pollingStrategy with an instance of your custom strategy and then invoke build to create the ConfigSource . ",
            "title": "Change Support"
        },
        {
            "location": "/se/config/introduction",
            "text": " If you add additional Helidon config maven artifacts to your dependencies, then the config system can read formats other than Java properties format and the default configuration will search for other application file types in the following order. Note that the default configuration stops once it finds one of the files below; it does not merge all such files it can find. Default Config Files (most to the least important) Source Helidon maven artifact ID (group ID: io.helidon.config ) Notes application.yaml helidon-config-yaml YAML format http://yaml.org application.conf helidon-config-hocon HOCON format https://github.com/lightbend/config#using-hocon-the-json-superset application.json helidon-config-hocon JSON format https://json.org/ application.properties helidon-config Java properties format You can also extend the config system to handle other types of sources by implementing the ConfigSource interface. See the extensions' documentation for complete information. ",
            "title": "Built-in Support for Config Formats"
        },
        {
            "location": "/se/config/introduction",
            "text": " Helidon has an internal configuration, so you are not required to provide any configuration data for your application, though in practice you most likely would. In your application code, when you create a default Config object, Helidon uses the default configuration . <markup lang=\"Java\" >Config config = Config.create(); The Config object is created with default settings. Global Configuration Global configuration is a singleton instance of Config that is implicitly used by some components of Helidon, plus it provides a convenient mechanism for your application to retrieve configuration from anywhere in your code. By default global configuration is initialized to the default Config object (as returned by Config.create() ). But it is recommended that you initialize it explicitly. This is especially important if you define custom config sources. <markup >Config config = Config.create(); Config.global(config); Create configuration. This shows creating the default config, but it could be created from custom config sources. Assign it to the application&#8217;s global configuration You can use global configuration to conveniently retrieve the application&#8217;s configuration: <markup >Config config = Config.global(); Custom Config Sources Although the default configuration is very simple to use, your application can take full control of all configuration sources and precedence. You can do so by creating and invoking methods on a Config.Builder object to construct a Config instance. When your application prepares a Config.Builder it sets what ConfigSource s and ConfigParser s the builder should use in constructing the resulting Config object. The JavaDoc explains how to use the Config.Builder . See the Custom Configuration Sources and advanced config sources sections for detailed examples and further information. Accessing Config Values You have used Helidon to customize configuration behavior from your code using the Config and Config.Builder classes. As discussed previously, Config system reads configuration from a config source, which uses a config parser to translate the source into an in-memory tree which represents the configuration’s structure and values. This approach allows us to take any source data, be it a flat properties file or an object structure such as JSON, and transform it into a single tree that allows for overriding of values using heterogeneous config sources. We are using the . as a separator of tree structure. Example of two config sources that can be used by Config with the same data tree in different formats: A Properties source: <markup lang=\"properties\" >web.page-size=25 A YAML source: <markup lang=\"yaml\" >web: page-size: 25 The configuration has the same internal representation in Config . Once created, the Config object provides many methods the application can use to retrieve config data as various Java types. See the Config JavaDoc for complete details. <markup lang=\"java\" >int pageSize = config.get(\"web.page-size\") .asInt() .orElse(20); Or using the tree node approach: <markup lang=\"java\" >int pageSize = config .get(\"web\") .get(\"page-size\") .asInt() .orElse(20); For this first example we can see the basic features of Config : Configuration is a tree of Config nodes You can use . as a tree separator when requesting node values Each config value can be retrieved as a typed object, with shortcut methods for the most commonly used types, such as int , String , long and other You can immediately provide a default value for the cases the configuration option is not defined in any source Overriding Values The Config system treats config sources as a hierarchy, where the first source that has a specific configuration key \"wins\" and its value is used, other sources are not even queried for it. In order to properly configure your application using configuration sources, you need to understand the precedence rules that Helidon uses to merge your configuration data. If any of the Helidon required properties are not specified in one of these source, then Helidon will use a default value. For example the default configuration when you use Config.create() uses the following config sources in precedence order: System properties config source Environment variables config source A classpath config source called application.? where the ? depends on supported media types currently on the classpath.By default, it is properties , but if you have YAML support on classpath, it would be application.yaml (a ConfigParser may add additional supported suffixes for default file) Let&#8217;s consider the following keys: System property answer=42 Environment variable ANSWER=38 A key in a configuration file answer=36 When you request config.get(`answer ).asInt().orElse(25) , you would get `42 This allows you to configure environment specific configuration values through system properties, environment variables, or through files available on each environment (be it a physical machine, a Kubernetes pod, or a docker image) without changing your source code. Config Filters Config system applies configured config filters on each value when it is requested for the first time. There is a built-in filter called ValueResolvingFilter (enabled by default, can be disabled through API) that resolves references to other keys in values in configuration. Example: Let&#8217;s consider the following example properties file <markup lang=\"properties\" >host=localhost first-service.host=${host}/firstservice second-service.host=${host}/secondservice The filter resolves the ${host} reference to the localhost value. This makes it easier to override values in testing and production, as you can just override the host key and leave the URIs same. See Filter, Overrides, and Token Substitution section for further information on some more involved aspects. Typed config values The Config object lets your application retrieve config data as a typed ConfigValue. You can retrieve a ConfigValue&lt;T&gt; using the following as methods in Config : * asString() - to get a string config value * asBoolean() and other accessors for primitive types * as(Class) - to get a value for a type that has a mapper configured * as(Generic) - to get a value for a type supporting generics (such as Set&lt;String&gt; ) * asMap() - to get a map of key to value pairs * asList(Class) - to get a list of typed values * as(Function&lt;Config,T&gt;) - to get a typed value providing a mapper function ConfigValue&lt;T&gt; can be used to obtain: * an Optional&lt;T&gt; value from a single node , * the T value from a single node interpreted as a basic Java type (primitive or simple object) already known to the config system (such as a boolean or a Double ), or * a complex Java type from a subtree of the config tree. + The config system automatically knows how to return List and Map complex types, and you can provide config mappers to convert a config subtree to whatever Java types your application needs. See Property Mapping page for details on how to use the built-in mappings and your own custom ones to convert to simple and complex types. Dealing with Loading Errors: Retry Policies Config sources, especially those that depend on fallible mechanisms such as the network or a shared file system, might fail to load during momentary outages. The config system allows you to build resiliency into your application&#8217;s use of configuration that relies on such technologies. When your application builds a ConfigSource it can specify a retry policy . When the config system needs to load data from that source it delegates the load operation to that retry policy. That policy is responsible not only for loading the data but also for detecting errors during loading and implementing the algorithm for deciding when and how many times to retry a failed load before reporting a failure back to your application. The config system includes two predefined retry policies: Predefined Retry Policies Policy Summary \"just call\" (default) asks the config source to load the data with no retry \"repeat\" performs a settable number of time-based retries, reporting failure only after all available retries have failed See the RetryPolicies JavaDoc for complete details on these built-in retry policies. You can devise your own policy. Implement the RetryPolicy interface. Then pass an instance of your policy implementation to the config source builder&#8217;s retryPolicy method. Change Support Each Config object which the config system returns to your application is immutable; even if the information in one of the underlying config sources changes, an in-memory data structure built from the earlier content remains unchanged. Nevertheless, we know that configuration sometimes changes, and we may want to react to such changes. So the config system allows your application to learn when such underlying changes in the data occur and respond accordingly. In Config system, you can do this through change support provided by these components: Config.onChange() API - you can use to add your listener, to be notified of configuration changes PollingStrategy - a component providing regular events to check if a source has changed. This requires support in config sources themselves (see PollableSource ) ChangeWatcher - a component watching the underlying source for changes. This requires support in config sources themselves (see WatchableSource ) EventConfigSource - an event source that is capable of notifying about changes itself If you want to receive onChange events, you must configure your Config with at least one source that is capable of providing changes (having a PollingStrategy or ChangeWatcher configured, or implementing EventConfigSource ) The mutability documentation explains this in detail, and the PollingStrategies JavaDoc describes the built-in implementations. You can, of course, write your own by implementing the PollingStrategy interface. On a config source builder invoke pollingStrategy with an instance of your custom strategy and then invoke build to create the ConfigSource . Built-in Support for Config Formats If you add additional Helidon config maven artifacts to your dependencies, then the config system can read formats other than Java properties format and the default configuration will search for other application file types in the following order. Note that the default configuration stops once it finds one of the files below; it does not merge all such files it can find. Default Config Files (most to the least important) Source Helidon maven artifact ID (group ID: io.helidon.config ) Notes application.yaml helidon-config-yaml YAML format http://yaml.org application.conf helidon-config-hocon HOCON format https://github.com/lightbend/config#using-hocon-the-json-superset application.json helidon-config-hocon JSON format https://json.org/ application.properties helidon-config Java properties format You can also extend the config system to handle other types of sources by implementing the ConfigSource interface. See the extensions' documentation for complete information. ",
            "title": "Configuration"
        },
        {
            "location": "/se/config/introduction",
            "text": " SE Config Guide Step-by-step guide about using Config in your Helidon SE application. ",
            "title": "Reference"
        },
        {
            "location": "/se/config/introduction",
            "text": " The links in the following tables lead you to more information about various other config topics. Controlling How Config is Loaded Topic Documentation Where config comes from Config sources , Config Profiles What format config data is expressed in Config parsers , supported formats How to filter, override, and dereference values Filters and overrides What happens when config data changes Mutability Support How to deal with loading errors Config retry policies Accessing Configuration Data Topic Documentation How config data is translated into Java types Config mappers How to navigate config trees Navigation Extending and Fine-tuning the Config System Topic Documentation Writing extensions Extensions ",
            "title": "Additional Information"
        },
        {
            "location": "/se/config/mutability-support",
            "text": " Overview Using Config Metadata Responding to Changes in Config Sources Accessing Always-current Values ",
            "title": "Contents"
        },
        {
            "location": "/se/config/mutability-support",
            "text": " An in-memory config tree, once loaded, is immutable, even though the data in the underlying config sources can change over time. The config system internally records which config sources it used to load each config tree and some metadata about the configuration. Your application can be aware of updates to the underlying config sources by: using the metadata the config system maintains, responding to change when the config sources are updated, or using Supplier s of particular config values to obtain the always-current value for a key. ",
            "title": "Overview"
        },
        {
            "location": "/se/config/mutability-support",
            "text": " The config system records when it loads each configuration into memory. Your application can retrieve it by invoking the timestamp method : <markup lang=\"java\" >java.time.Instance loadTime = myConfig.timestamp(); on any config node. ",
            "title": "Loading Time"
        },
        {
            "location": "/se/config/mutability-support",
            "text": " The config system maintains a Config.Context for each Config node. Your application can retrieve the context by invoking the Config.context() method and then use it for these operations: Uses of Config.Context Method Usage Instant timestamp() Returns the load time of the last loaded configuration that used the context. Config last() Returns the most recently loaded configuration that used the context. Config reload() Reloads the entire config tree from the current contents of the same config sources used to load the tree in which the current node resides. Note that the config context describes or replaces a currently-loaded config tree. It by itself does not help your application decide when reloading the config might be useful. ",
            "title": "Config Context"
        },
        {
            "location": "/se/config/mutability-support",
            "text": " Loading Time The config system records when it loads each configuration into memory. Your application can retrieve it by invoking the timestamp method : <markup lang=\"java\" >java.time.Instance loadTime = myConfig.timestamp(); on any config node. Config Context The config system maintains a Config.Context for each Config node. Your application can retrieve the context by invoking the Config.context() method and then use it for these operations: Uses of Config.Context Method Usage Instant timestamp() Returns the load time of the last loaded configuration that used the context. Config last() Returns the most recently loaded configuration that used the context. Config reload() Reloads the entire config tree from the current contents of the same config sources used to load the tree in which the current node resides. Note that the config context describes or replaces a currently-loaded config tree. It by itself does not help your application decide when reloading the config might be useful. ",
            "title": "Using Config Metadata"
        },
        {
            "location": "/se/config/mutability-support",
            "text": " When the application creates a config source, it can set up change detection for that source. This is called polling in the Helidon API but specific change detection algorithms might not use actual polling. You choose a specific PollingStrategy for each config source you want to monitor. See the section on polling strategies in the config extensions doc page for more information. The config system provides some built-in polling strategies, exposed as these methods on the PollingStrategies class: regular(Duration interval) - a general-purpose scheduled polling strategy with a specified, constant polling interval. watch(Path watchedPath) - a filesystem-specific strategy to watch specified path. You can use this strategy with the file built-in config sources. nop() - a no-op strategy This example builds a Config object from three sources, each set up with a different polling strategy: <markup lang=\"java\" title=\"Build a Config with a different PollingStrategy for each config source\" >Config config = Config.create( ConfigSources.file(\"conf/dev.properties\") .pollingStrategy(PollingStrategies.regular(Duration.ofSeconds(2))) .optional(), ConfigSources.file(\"conf/config.properties\") .changeWatcher(FileSystemWatcher.create()) .optional(), ConfigSources.file(\"my.properties\") .pollingStrategy(PollingStrategies::nop)); Optional file source conf/dev.properties will be checked for changes every 2 seconds. Optional file source conf/config.properties will be watched by the Java WatchService for changes on filesystem. The file resource my.properties will not be checked for changes. PollingStrategies.nop() polling strategy is default. The polling strategies internally inform the config system when they detect changes in the monitored config sources (except that the nop strategy does nothing). ",
            "title": "Setting up Config Source Change Detection"
        },
        {
            "location": "/se/config/mutability-support",
            "text": " You register a function that runs when when a change occurs by using the Config.onChange() method on the node of interest. <markup lang=\"java\" title=\"Subscribe on greeting property changes via onChange method\" >config.get(\"greeting\") .onChange((changedNode) -&gt; { System.out.println(\"Node \" + changedNode.key() + \" has changed!\"); return true; }); Navigate to the Config node on which you want to register. Invoke the onChange method, passing a function ( Function&lt;Config, Boolean&gt; ). The config system invokes that function each time the subtree rooted at the greeting node changes. The changedNode is a new instance of Config representing the updated subtree rooted at greeting . The function should return true to continue being run on subsequent changes, false to stop. ",
            "title": "Registering Actions"
        },
        {
            "location": "/se/config/mutability-support",
            "text": " To know when config sources have changed, your application must register its interest on the Config node of interest. The config system will then notify your application of any change within the subtree rooted at that node. In particular, if you register on the root node, then the config system notifies your code of changes anywhere in the config tree. Registering Actions You register a function that runs when when a change occurs by using the Config.onChange() method on the node of interest. <markup lang=\"java\" title=\"Subscribe on greeting property changes via onChange method\" >config.get(\"greeting\") .onChange((changedNode) -&gt; { System.out.println(\"Node \" + changedNode.key() + \" has changed!\"); return true; }); Navigate to the Config node on which you want to register. Invoke the onChange method, passing a function ( Function&lt;Config, Boolean&gt; ). The config system invokes that function each time the subtree rooted at the greeting node changes. The changedNode is a new instance of Config representing the updated subtree rooted at greeting . The function should return true to continue being run on subsequent changes, false to stop. ",
            "title": "Registering a Config Change Response"
        },
        {
            "location": "/se/config/mutability-support",
            "text": " Although in-memory config trees do not change once loaded, applications can respond to change in the underlying config sources by: setting up change detection for the config sources used to build a configuration, and registering a response to be run when a source changes. Your code&#8217;s response can react to the changes in whatever way makes sense for your application. The following sections describe these steps in detail. Setting up Config Source Change Detection When the application creates a config source, it can set up change detection for that source. This is called polling in the Helidon API but specific change detection algorithms might not use actual polling. You choose a specific PollingStrategy for each config source you want to monitor. See the section on polling strategies in the config extensions doc page for more information. The config system provides some built-in polling strategies, exposed as these methods on the PollingStrategies class: regular(Duration interval) - a general-purpose scheduled polling strategy with a specified, constant polling interval. watch(Path watchedPath) - a filesystem-specific strategy to watch specified path. You can use this strategy with the file built-in config sources. nop() - a no-op strategy This example builds a Config object from three sources, each set up with a different polling strategy: <markup lang=\"java\" title=\"Build a Config with a different PollingStrategy for each config source\" >Config config = Config.create( ConfigSources.file(\"conf/dev.properties\") .pollingStrategy(PollingStrategies.regular(Duration.ofSeconds(2))) .optional(), ConfigSources.file(\"conf/config.properties\") .changeWatcher(FileSystemWatcher.create()) .optional(), ConfigSources.file(\"my.properties\") .pollingStrategy(PollingStrategies::nop)); Optional file source conf/dev.properties will be checked for changes every 2 seconds. Optional file source conf/config.properties will be watched by the Java WatchService for changes on filesystem. The file resource my.properties will not be checked for changes. PollingStrategies.nop() polling strategy is default. The polling strategies internally inform the config system when they detect changes in the monitored config sources (except that the nop strategy does nothing). Registering a Config Change Response To know when config sources have changed, your application must register its interest on the Config node of interest. The config system will then notify your application of any change within the subtree rooted at that node. In particular, if you register on the root node, then the config system notifies your code of changes anywhere in the config tree. Registering Actions You register a function that runs when when a change occurs by using the Config.onChange() method on the node of interest. <markup lang=\"java\" title=\"Subscribe on greeting property changes via onChange method\" >config.get(\"greeting\") .onChange((changedNode) -&gt; { System.out.println(\"Node \" + changedNode.key() + \" has changed!\"); return true; }); Navigate to the Config node on which you want to register. Invoke the onChange method, passing a function ( Function&lt;Config, Boolean&gt; ). The config system invokes that function each time the subtree rooted at the greeting node changes. The changedNode is a new instance of Config representing the updated subtree rooted at greeting . The function should return true to continue being run on subsequent changes, false to stop. ",
            "title": "Responding to Changes in Config Sources"
        },
        {
            "location": "/se/config/mutability-support",
            "text": " Some applications do not need to respond to change as they happen. Instead, it&#8217;s sufficient that they simply have access to the current value for a particular key in the configuration. Each asXXX method on the Config class has a companion asXXXSupplier method. These supplier methods return Supplier&lt;XXX&gt; , and when your application invokes the supplier&#8217;s get method the config system returns the then-current value as stored in the config source. <markup lang=\"java\" title=\"Access greeting property as Supplier&lt;String&gt; \" >// Construct a Config with the appropriate PollingStrategy on each config source. Supplier&lt;String&gt; greetingSupplier = config.get(\"greeting\") .asString().supplier(); System.out.println(\"Always actual greeting value: \" + greetingSupplier.get()); Navigate to the Config node for which you want access to the always-current value. Retrieve and store the returned supplier for later use. Invoke the supplier&#8217;s get() method to retrieve the current value of the node. Important Supplier support requires that you create the Config object from config sources that have proper polling strategies set up. The supplier returns refreshed values only after changes have been detected by the polling strategy. ",
            "title": "Accessing Always-current Values"
        },
        {
            "location": "/se/config/property-mapping",
            "text": " Overview Converting Configuration to Simple Types Converting Configuration to enum Values Converting Configuration to Complex Types Advanced Conversions using Explicit Mapping Logic Conversions using JavaBean Deserialization ",
            "title": "Contents"
        },
        {
            "location": "/se/config/property-mapping",
            "text": " Although config values are originally text, you can use the config system&#8217;s built-in conversions or add your own to translate text into Java primitive types and simple objects (such as Double ), into enum values, and to express parts of the config tree as complex types ( List , Map , and custom types specific to your application). This section introduces how to use the built-in mappings and your own custom ones to convert to simple and complex types. ",
            "title": "Overview"
        },
        {
            "location": "/se/config/property-mapping",
            "text": " The Config class itself provides many conversions to Java types. See the JavaDoc for the complete list. The methods which support Java primitive types and their related classes follow a common pattern. The examples in the table below deal with conversion to a boolean but the same pattern applies to many data types listed in the JavaDoc. Assume a local variable has been assigned something like <markup lang=\"java\" >Config config = Config.get(\"someKey\"); // shortcut method ConfigValue&lt;Boolean&gt; value = config.asBoolean(); // generic method (for any type) ConfigValue&lt;Boolean&gt; value2 = config.as(Boolean.class); Built-in Conversions to Simple Types (e.g., boolean) Java type Example usage 1 boolean boolean b = value.get(); 2 boolean defaultedB = value.orElse(true); 3 Optional&lt;Boolean&gt; ConfigValue already has all methods of an Optional. If actual optional is needed: Optional&lt;Boolean&gt; b = value.asOptional(); 4 Supplier&lt;Boolean&gt; Boolean b = value.supplier().get(); boolean defaultedB = value.supplier(true).get(); Supplier&lt;Optional&lt;Boolean&gt;&gt; Boolean b = value.optionalSupplier().get().orElse(Boolean.TRUE); Notes on Built-in Conversions to Simple Types 1 All conversions can throw MissingValueException (if no value exists at the requested key and no default is provided) and ConfigMappingException (if some error occurred while performing the data mapping). 2 The Config.asXXX methods internally use the Java-provided XXX.parseXXX methods, so here a missing or un-parseable string gives false because that is how Boolean.parseBoolean behaves. 3 User code defaults the value to true . 4 User code defaults the value to Boolean.TRUE if absent; otherwise parses the value using Boolean.parseBoolean . The numerous conversions defined on the Config class for other types (integers, doubles, etc.) will satisfy many of your application&#8217;s needs. The ConfigMappers class includes other related mappings from String (rather than from Config ) to Java types (described in the JavaDoc). For additional type mapping, you can use these methods defined on Config : <markup lang=\"java\" >T as(Class&lt;? extends T&gt; type); T as(Function&lt;Config, T&gt; mapper); T as(GenericType&lt;T&gt; genericType); which maps the current node to a type. The next example, and later ones below showing complex type mapping, use the example application.properties configuration from the config introduction. Part of that example includes this line: <markup >bl.initial-id = 10000000000 Your application can use Config.as to interpret the value as a BigDecimal : <markup lang=\"java\" >BigDecimal initialId = config.get(\"bl.initial-id\").as(BigDecimal.class); ",
            "title": "Converting Configuration to Simple Types"
        },
        {
            "location": "/se/config/property-mapping",
            "text": " The conversion applies the following algorithm to match config values to enum names, stopping as soon as it finds a match: Select an exact match if one exists. Treat hyphens ( - ) in config strings as underscores ( _ ) and select an otherwise exact match if one exists. Select a case-insensitive match (with or without hyphen substitution) if there is exactly one such match. Finding no match or multiple case-insensitive matches, throw a ConfigMappingException . ",
            "title": "Matching enum Names"
        },
        {
            "location": "/se/config/property-mapping",
            "text": " The following example illustrates how to use the built-in enum conversion feature. The example code builds a simple Config tree itself which contains simple test data; normally your application would load the config from a file or some other location. <markup lang=\"java\" >class Example { enum Color {RED, YELLOW, BLUE_GREEN}; void convert() { Config config = Config.just(ConfigSources.create(Map.of(\"house.tint\", \"blue-green\", \"car.color\", \"Red\", \"warning\", \"YELLOW\"))); Color house = config.get(\"house.tint\") .as(Color.class) .get(); Color car = config.get(\"car.color\") .as(Color.class) .get(); Color warning = config.get(\"warning\") .as(Color.class) .get(); } } Retrieve the Config object corresponding to the key house.tint . Indicate that, when the value in that Config object is converted, Helidon should convert it to a Color enum value. Convert and retrieve the value. The config key car.color locates the mixed-case string Red which the converter matches to Color.RED . The config key warning locates YELLOW which the converter matches exactly to Color.YELLOW . ",
            "title": "Example"
        },
        {
            "location": "/se/config/property-mapping",
            "text": " Short answer: ease-of-use. Users composing config sources often adopt a style with hyphens within words to improve readability and lower-case keys and values. With that style in mind, users typing an enum value into a config source might accidentally enter a hyphen instead of an underscore or use lower case instead of upper case. Users might even prefer to make these changes so they can follow their preferred config style. With the heuristics, Helidon allows users to adopt a common config style and prevents unnecessary runtime exceptions&#8212;&#8203;and user frustration&#8212;&#8203;from inconsequential typos. Remember: Helidon always finds exact matches unambiguously, without relying on the heuristics. In our Color example the text BLUE_GREEN always maps to Color.BLUE_GREEN . Because hyphens cannot appear in a valid Java enum value name, interpreting them as underscores during enum conversion introduces no ambiguity. Only in the following unusual sitatuation are the heuristics unable to unambiguously match a string to an enum value: The enum has values which differ only in their case (such as Red and RED ), and The string in the config source is not an exact match with an enum value name (such as red ). If your application must deal with such cases, write your own function which maps a Config node to the correct enum value, resolving the ambiguities however makes sense in your use case. Your code tells config to use that function instead of the built-in enum conversion when it converts values. A later section describes this technique which works for all types, not only enum types. ",
            "title": "Why use heuristics in matching strings to enum values?"
        },
        {
            "location": "/se/config/property-mapping",
            "text": " Configuration can automatically map Config nodes to most enum types. Your application code simply passes the enum class type to config.as(Class&lt;? extends T&gt; type) . The built-in enum converter attempts to match the string value in the config node to the name of one of the values declared for that specific enum in the Java code. Matching enum Names The conversion applies the following algorithm to match config values to enum names, stopping as soon as it finds a match: Select an exact match if one exists. Treat hyphens ( - ) in config strings as underscores ( _ ) and select an otherwise exact match if one exists. Select a case-insensitive match (with or without hyphen substitution) if there is exactly one such match. Finding no match or multiple case-insensitive matches, throw a ConfigMappingException . Example The following example illustrates how to use the built-in enum conversion feature. The example code builds a simple Config tree itself which contains simple test data; normally your application would load the config from a file or some other location. <markup lang=\"java\" >class Example { enum Color {RED, YELLOW, BLUE_GREEN}; void convert() { Config config = Config.just(ConfigSources.create(Map.of(\"house.tint\", \"blue-green\", \"car.color\", \"Red\", \"warning\", \"YELLOW\"))); Color house = config.get(\"house.tint\") .as(Color.class) .get(); Color car = config.get(\"car.color\") .as(Color.class) .get(); Color warning = config.get(\"warning\") .as(Color.class) .get(); } } Retrieve the Config object corresponding to the key house.tint . Indicate that, when the value in that Config object is converted, Helidon should convert it to a Color enum value. Convert and retrieve the value. The config key car.color locates the mixed-case string Red which the converter matches to Color.RED . The config key warning locates YELLOW which the converter matches exactly to Color.YELLOW . Why use heuristics in matching strings to enum values? Short answer: ease-of-use. Users composing config sources often adopt a style with hyphens within words to improve readability and lower-case keys and values. With that style in mind, users typing an enum value into a config source might accidentally enter a hyphen instead of an underscore or use lower case instead of upper case. Users might even prefer to make these changes so they can follow their preferred config style. With the heuristics, Helidon allows users to adopt a common config style and prevents unnecessary runtime exceptions&#8212;&#8203;and user frustration&#8212;&#8203;from inconsequential typos. Remember: Helidon always finds exact matches unambiguously, without relying on the heuristics. In our Color example the text BLUE_GREEN always maps to Color.BLUE_GREEN . Because hyphens cannot appear in a valid Java enum value name, interpreting them as underscores during enum conversion introduces no ambiguity. Only in the following unusual sitatuation are the heuristics unable to unambiguously match a string to an enum value: The enum has values which differ only in their case (such as Red and RED ), and The string in the config source is not an exact match with an enum value name (such as red ). If your application must deal with such cases, write your own function which maps a Config node to the correct enum value, resolving the ambiguities however makes sense in your use case. Your code tells config to use that function instead of the built-in enum conversion when it converts values. A later section describes this technique which works for all types, not only enum types. ",
            "title": "Converting Configuration to enum Values"
        },
        {
            "location": "/se/config/property-mapping",
            "text": " The Config class exposes several methods for mapping a structured config node to a Java List or Map . The JavaDoc contains complete details, but briefly your application can convert a structured Config node into: a List&lt;T&gt; of a given type a Map&lt;String, String&gt; in which each key is the fully-qualified key String for a config entry and the value is its String value ",
            "title": "Built-in Conversions to List and Map "
        },
        {
            "location": "/se/config/property-mapping",
            "text": " Any time your application has a Config instance to map to the target class it invokes Config.as passing an instance of the corresponding conversion function: <markup lang=\"java\" >Config config = Config.get(\"web\"); ConfigValue&lt;WebConfig&gt; web = config.as(WebConfigMapper::map); You do not necessarily need a new instance of the mapper every time you want to use it. In this approach, everywhere your application needs to perform this conversion it specifies the mapper to use. If you decided to change which mapper to use you would need to update each of those places in your application. ",
            "title": "Use Custom Mapper Explicitly: Config.as method"
        },
        {
            "location": "/se/config/property-mapping",
            "text": " In this approach, your application: Tells each Config.Builder that needs to know about the custom mapper by either: registering an instance of your mapper by invoking Config.Builder.addMapper , or implementing ConfigMapperProvider so it returns an instance of your mapper (see the JavaDoc for complete information) and creating or editing the file io.helidon.config.spi.ConfigMapperProvider so it contains a line with the fully-qualified class name of your ConfigMapperProvider . The config system will use the Java service loader to find and invoke all ConfigMapperProvider classes listed and add the mappers they provide to each Config.Builder automatically. Converts using the mapper by invoking the Config.as method which accepts the target type to convert to, not the mapper itself that does the conversion. If your application converts to the same target type in several places in the code, this approach allows you to change which mapper it uses by changing only the registration of the mapper, not each use of it. ",
            "title": "Register Custom Mapper Once, Use Implicitly: Config.as method"
        },
        {
            "location": "/se/config/property-mapping",
            "text": " The following examples build on the example configuration from the application.properties example file in the introduction. <markup lang=\"java\" title=\"Java POJO to Hold web Properties Config\" >public class WebConfig { private boolean debug; private int pageSize; private double ratio; public WebConfig(boolean debug, int pageSize, double ratio) { this.debug = debug; this.pageSize = pageSize; this.ratio = ratio; } public boolean isDebug() { return debug; } public int getPageSize() { return pageSize; } public double getRatio() { return ratio; } } <markup lang=\"java\" title=\"Custom Mapper Class\" >public class WebConfigMapper implements Function&lt;Config, WebConfig&gt; { @Override public WebConfig apply(Config config) { return new WebConfig( config.get(\"debug\").asBoolean().orElse(false), config.get(\"page-size\").asInt().orElse(10), config.get(\"ratio\").asDouble().orElse(1.0) ); } } <markup lang=\"java\" title=\"Explicitly Using the Mapper\" >Config config = Config.create(classpath(\"application.properties\")); WebConfig web = config.get(\"web\") .as(new WebConfigMapper()) .get(); <markup lang=\"java\" title=\"Registering and Implicitly Using the Mapper\" >Config config = Config.builder(classpath(\"application.properties\")) .addMapper(WebConfig.class, new WebConfigMapper()) .build(); WebConfig web = config.get(\"web\") .as(WebConfig.class) .get(); Either of the two approaches just described will always work without requiring you to change the POJO class. ",
            "title": "Continuing the Web Example"
        },
        {
            "location": "/se/config/property-mapping",
            "text": " Often your code will be simpler if you can treat parts of the configuration as custom, application-specific Java objects, rather than as a group of String keys and values. You will need customized conversions to do so. The config system provides many ways to accomplish this, described in the io.helidon.config package JavaDoc . Some of those approaches require that the target class&#8201;&#8212;&#8201;the class to which you want to convert the configuration data&#8201;&#8212;&#8201;have certain characteristics or that you add a method to the class to help do the mapping. You might want to avoid changing the target class else you might not even be able to if you do not control its source. Here are two approaches that will always work without requiring changes to the target class. For both approaches, you write your own conversion function. The difference is in how your application triggers the use of that mapper. Use Custom Mapper Explicitly: Config.as method Any time your application has a Config instance to map to the target class it invokes Config.as passing an instance of the corresponding conversion function: <markup lang=\"java\" >Config config = Config.get(\"web\"); ConfigValue&lt;WebConfig&gt; web = config.as(WebConfigMapper::map); You do not necessarily need a new instance of the mapper every time you want to use it. In this approach, everywhere your application needs to perform this conversion it specifies the mapper to use. If you decided to change which mapper to use you would need to update each of those places in your application. Register Custom Mapper Once, Use Implicitly: Config.as method In this approach, your application: Tells each Config.Builder that needs to know about the custom mapper by either: registering an instance of your mapper by invoking Config.Builder.addMapper , or implementing ConfigMapperProvider so it returns an instance of your mapper (see the JavaDoc for complete information) and creating or editing the file io.helidon.config.spi.ConfigMapperProvider so it contains a line with the fully-qualified class name of your ConfigMapperProvider . The config system will use the Java service loader to find and invoke all ConfigMapperProvider classes listed and add the mappers they provide to each Config.Builder automatically. Converts using the mapper by invoking the Config.as method which accepts the target type to convert to, not the mapper itself that does the conversion. If your application converts to the same target type in several places in the code, this approach allows you to change which mapper it uses by changing only the registration of the mapper, not each use of it. Continuing the Web Example The following examples build on the example configuration from the application.properties example file in the introduction. <markup lang=\"java\" title=\"Java POJO to Hold web Properties Config\" >public class WebConfig { private boolean debug; private int pageSize; private double ratio; public WebConfig(boolean debug, int pageSize, double ratio) { this.debug = debug; this.pageSize = pageSize; this.ratio = ratio; } public boolean isDebug() { return debug; } public int getPageSize() { return pageSize; } public double getRatio() { return ratio; } } <markup lang=\"java\" title=\"Custom Mapper Class\" >public class WebConfigMapper implements Function&lt;Config, WebConfig&gt; { @Override public WebConfig apply(Config config) { return new WebConfig( config.get(\"debug\").asBoolean().orElse(false), config.get(\"page-size\").asInt().orElse(10), config.get(\"ratio\").asDouble().orElse(1.0) ); } } <markup lang=\"java\" title=\"Explicitly Using the Mapper\" >Config config = Config.create(classpath(\"application.properties\")); WebConfig web = config.get(\"web\") .as(new WebConfigMapper()) .get(); <markup lang=\"java\" title=\"Registering and Implicitly Using the Mapper\" >Config config = Config.builder(classpath(\"application.properties\")) .addMapper(WebConfig.class, new WebConfigMapper()) .build(); WebConfig web = config.get(\"web\") .as(WebConfig.class) .get(); Either of the two approaches just described will always work without requiring you to change the POJO class. ",
            "title": "Custom Conversions"
        },
        {
            "location": "/se/config/property-mapping",
            "text": " The hierarchical features section describes the tree structure used to represent config data. The config system can map subtrees of a config tree to complex Java types. Built-in Conversions to List and Map The Config class exposes several methods for mapping a structured config node to a Java List or Map . The JavaDoc contains complete details, but briefly your application can convert a structured Config node into: a List&lt;T&gt; of a given type a Map&lt;String, String&gt; in which each key is the fully-qualified key String for a config entry and the value is its String value Custom Conversions Often your code will be simpler if you can treat parts of the configuration as custom, application-specific Java objects, rather than as a group of String keys and values. You will need customized conversions to do so. The config system provides many ways to accomplish this, described in the io.helidon.config package JavaDoc . Some of those approaches require that the target class&#8201;&#8212;&#8201;the class to which you want to convert the configuration data&#8201;&#8212;&#8201;have certain characteristics or that you add a method to the class to help do the mapping. You might want to avoid changing the target class else you might not even be able to if you do not control its source. Here are two approaches that will always work without requiring changes to the target class. For both approaches, you write your own conversion function. The difference is in how your application triggers the use of that mapper. Use Custom Mapper Explicitly: Config.as method Any time your application has a Config instance to map to the target class it invokes Config.as passing an instance of the corresponding conversion function: <markup lang=\"java\" >Config config = Config.get(\"web\"); ConfigValue&lt;WebConfig&gt; web = config.as(WebConfigMapper::map); You do not necessarily need a new instance of the mapper every time you want to use it. In this approach, everywhere your application needs to perform this conversion it specifies the mapper to use. If you decided to change which mapper to use you would need to update each of those places in your application. Register Custom Mapper Once, Use Implicitly: Config.as method In this approach, your application: Tells each Config.Builder that needs to know about the custom mapper by either: registering an instance of your mapper by invoking Config.Builder.addMapper , or implementing ConfigMapperProvider so it returns an instance of your mapper (see the JavaDoc for complete information) and creating or editing the file io.helidon.config.spi.ConfigMapperProvider so it contains a line with the fully-qualified class name of your ConfigMapperProvider . The config system will use the Java service loader to find and invoke all ConfigMapperProvider classes listed and add the mappers they provide to each Config.Builder automatically. Converts using the mapper by invoking the Config.as method which accepts the target type to convert to, not the mapper itself that does the conversion. If your application converts to the same target type in several places in the code, this approach allows you to change which mapper it uses by changing only the registration of the mapper, not each use of it. Continuing the Web Example The following examples build on the example configuration from the application.properties example file in the introduction. <markup lang=\"java\" title=\"Java POJO to Hold web Properties Config\" >public class WebConfig { private boolean debug; private int pageSize; private double ratio; public WebConfig(boolean debug, int pageSize, double ratio) { this.debug = debug; this.pageSize = pageSize; this.ratio = ratio; } public boolean isDebug() { return debug; } public int getPageSize() { return pageSize; } public double getRatio() { return ratio; } } <markup lang=\"java\" title=\"Custom Mapper Class\" >public class WebConfigMapper implements Function&lt;Config, WebConfig&gt; { @Override public WebConfig apply(Config config) { return new WebConfig( config.get(\"debug\").asBoolean().orElse(false), config.get(\"page-size\").asInt().orElse(10), config.get(\"ratio\").asDouble().orElse(1.0) ); } } <markup lang=\"java\" title=\"Explicitly Using the Mapper\" >Config config = Config.create(classpath(\"application.properties\")); WebConfig web = config.get(\"web\") .as(new WebConfigMapper()) .get(); <markup lang=\"java\" title=\"Registering and Implicitly Using the Mapper\" >Config config = Config.builder(classpath(\"application.properties\")) .addMapper(WebConfig.class, new WebConfigMapper()) .build(); WebConfig web = config.get(\"web\") .as(WebConfig.class) .get(); Either of the two approaches just described will always work without requiring you to change the POJO class. ",
            "title": "Converting Configuration to Complex Types"
        },
        {
            "location": "/se/config/property-mapping",
            "text": " If you can change the target class you can add any one of the following methods or constructors to the POJO class which the config system will find and use for mapping. Continuing with the WebConfig example introduced earlier: Methods Supporting Auto-mapping static WebConfig create(Config); static WebConfig from(Config); static WebConfig from(String); static WebConfig of(Config); static WebConfig of(String); static WebConfig valueOf(Config); static WebConfig valueOf(String); static WebConfig fromConfig(Config); static WebConfig fromString(String); Constructors Supporting Auto-mapping WebConfig(Config); WebConfig(String); If the config system finds any of these methods or constructors when the application invokes <markup lang=\"java\" >WebConfig wc = config.as(WebConfig.class).get(); it will invoke the one it found to map the config data to a new instance of the target class. You do not need to write a separate class to do the mapping or register it with the Config.Builder for the config instance. ",
            "title": "Adding the Mapping to the POJO"
        },
        {
            "location": "/se/config/property-mapping",
            "text": " You can limit the changes to the POJO class by adding a single builder method to the POJO which returns a builder class for the POJO: <markup lang=\"java\" >public class WebConfig { static WebConfigBuilder builder() { return new WebConfigBuilder(); } } The builder class WebConfigBuilder is expected to be a Java Bean with bean properties named for the config properties of interest, and a method WebConfig build() which creates the mapped instance from the builder&#8217;s own bean properties. When your application invokes config.as(WebConfig.class) the config system finds and invokes the WebConfig.builder() method, assigns the bean properties on the returned builder from the config subtree rooted at config , and invokes the builder&#8217;s build() method yielding the resulting WebConfig instance. ",
            "title": "Writing a Builder Method and Class for the POJO"
        },
        {
            "location": "/se/config/property-mapping",
            "text": " If the target Java class you want to use meets certain conditions&#8201;&#8212;&#8201;or if you can change it to meet one of those conditions&#8201;&#8212;&#8201;you might not need to write a separate mapper class. Instead, you add the mapping logic to the POJO itself in one of several ways and the config system uses Java reflection to search for those ways to perform the mapping. Your application facilitates this implicit mapping either by adding to the POJO class or by providing a builder class for it. This feature is available in Object mapping module, and is added through Java ServiceLoader mechanism. This is no longer part of core Config module, as it depends on reflection and introduces a lot of magic (see the list of supported mapping methods below, also uses reflection to invoke the methods and to map configuration values to fields/methods etc.). <markup lang=\"xml\" title=\"Config object mapping Dependency in pom.xml \" >&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.config&lt;/groupId&gt; &lt;artifactId&gt;helidon-config-object-mapping&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; Adding the Mapping to the POJO If you can change the target class you can add any one of the following methods or constructors to the POJO class which the config system will find and use for mapping. Continuing with the WebConfig example introduced earlier: Methods Supporting Auto-mapping static WebConfig create(Config); static WebConfig from(Config); static WebConfig from(String); static WebConfig of(Config); static WebConfig of(String); static WebConfig valueOf(Config); static WebConfig valueOf(String); static WebConfig fromConfig(Config); static WebConfig fromString(String); Constructors Supporting Auto-mapping WebConfig(Config); WebConfig(String); If the config system finds any of these methods or constructors when the application invokes <markup lang=\"java\" >WebConfig wc = config.as(WebConfig.class).get(); it will invoke the one it found to map the config data to a new instance of the target class. You do not need to write a separate class to do the mapping or register it with the Config.Builder for the config instance. Writing a Builder Method and Class for the POJO You can limit the changes to the POJO class by adding a single builder method to the POJO which returns a builder class for the POJO: <markup lang=\"java\" >public class WebConfig { static WebConfigBuilder builder() { return new WebConfigBuilder(); } } The builder class WebConfigBuilder is expected to be a Java Bean with bean properties named for the config properties of interest, and a method WebConfig build() which creates the mapped instance from the builder&#8217;s own bean properties. When your application invokes config.as(WebConfig.class) the config system finds and invokes the WebConfig.builder() method, assigns the bean properties on the returned builder from the config subtree rooted at config , and invokes the builder&#8217;s build() method yielding the resulting WebConfig instance. ",
            "title": "Advanced Conversions using Explicit Mapping Logic"
        },
        {
            "location": "/se/config/property-mapping",
            "text": " If your POJO target class is already a JavaBean&#8201;&#8212;&#8201;or you can modify it to become one&#8201;&#8212;&#8201;you might be able to avoid writing any explicit mapping code yourself. The config system invokes the no-args constructor on the target class to create a new instance. It treats each public setter method and each public non-final field as a JavaBean property. The config system processes any non-primitive property recursively as a JavaBean. In this way the config system builds up the target object from the config data. By default, the system matches potential JavaBean property names with config keys in the configuration. Use the Value annotation to control some of JavaBean processing for a given property. Value Annotation Attribute Usage key Indicates which config key should match this JavaBean property withDefault String used for the bean property default value if none is set in the config withDefaultSupplier Supplier of the default bean property value if not is set in the config To exclude a bean property from the config system bean processing annotate it with Transient . Here is an example using the app portion of the example configuration from the introduction. <markup lang=\"java\" title=\"Java bean to load app properties into via setters\" >public class AppConfig { private Instant timestamp; private String greeting; private int pageSize; private List&lt;Integer&gt; basicRange; public AppConfig() { } public void setGreeting(String greeting) { this.greeting = greeting; } public String getGreeting() { return greeting; } @Value(key = \"page-size\", withDefault = \"10\") public void setPageSize(int pageSize) { this.pageSize = pageSize; } public int getPageSize() { return pageSize; } @Value(key = \"basic-range\", withDefaultSupplier = BasicRangeSupplier.class) public void setBasicRange(List&lt;Integer&gt; basicRange) { this.basicRange = basicRange; } public List&lt;Integer&gt; getBasicRange() { return basicRange; } @Transient public void setTimestamp(Instant timestamp) { this.timestamp = timestamp; } public Instant getTimestamp() { return timestamp; } public static class BasicRangeSupplier implements Supplier&lt;List&lt;Integer&gt;&gt; { @Override public List&lt;Integer&gt; get() { return List.of(-10, 10); } } } Public no-parameter constructor. Property greeting is not customized and will be set from the config node with the key greeting , if present in the config. Property pageSize is matched to the config key page-size . If the page-size config node does not exist, the pageSize bean property defaults to 10 . Property basicRange is matched to the config key basic-range . If the basic-range config node does not exist, a BasicRangeSupplier instance will provide the default value. The timestamp bean property is never set, even if the config contains a node with the key timestamp . BasicRangeSupplier is used to supply the List&lt;Integer&gt; default value. Here is an example of code loading config and mapping part of it to the AppConfig bean above. <markup lang=\"java\" title=\"Map app config node into AppConfig class\" >Config config = Config.create(classpath(\"application.conf\")); AppConfig app = config.get(\"app\") .as(AppConfig.class) .get(); //assert that all values are loaded from file assert app.getGreeting().equals(\"Hello\"); assert app.getPageSize() == 20; assert app.getBasicRange().size() == 2 &amp;&amp; app.getBasicRange().get(0) == -20 &amp;&amp; app.getBasicRange().get(1) == 20; //assert that Transient property is not set assert app.getTimestamp() == null; The config system finds no registered ConfigMapper for AppConfig and so applies the JavaBean pattern to convert the config to an AppConfig instance. Because the bean property timestamp was marked as transient, the config system did not set it. ",
            "title": "POJO as JavaBean"
        },
        {
            "location": "/se/config/property-mapping",
            "text": " If the target class includes the public static method builder() that returns any object, then the config system will make sure that the return type has a method build() which returns an instance of the target class. If so, the config system treats the builder as a JavaBean and invokes the builder() method to instantiate the builder class, treats the builder as a JavaBean and maps the Config subtree to it, invokes the builder&#8217;s build() method to create the new instance of the target class. You can augment the target class with the public static builder() method: <markup lang=\"java\" title=\"JavaBean for app properties, via a Builder \" >public class AppConfig { private String greeting; private int pageSize; private List&lt;Integer&gt; basicRange; private AppConfig(String greeting, int pageSize, List&lt;Integer&gt; basicRange) { this.greeting = greeting; this.pageSize = pageSize; this.basicRange = basicRange; } public String getGreeting() { return greeting; } public int getPageSize() { return pageSize; } public List&lt;Integer&gt; getBasicRange() { return basicRange; } public static Builder builder() { return new Builder(); } public static class Builder { private String greeting; private int pageSize; private List&lt;Integer&gt; basicRange; private Builder() { } public void setGreeting(String greeting) { this.greeting = greeting; } @Value(key = \"page-size\", withDefault = \"10\") public void setPageSize(int pageSize) { this.pageSize = pageSize; } @Value(key = \"basic-range\", withDefaultSupplier = BasicRangeSupplier.class) public void setBasicRange(List&lt;Integer&gt; basicRange) { this.basicRange = basicRange; } public AppConfig build() { return new AppConfig(greeting, pageSize, basicRange); } } } The target class&#8217;s constructor can be private in this case because new instances are created from the inner class Builder which has access to `AppConfig&#8217;s private members. The target class contains public static method builder() which returns an object that itself exposes the method AppConfig build() , so the config system recognizes it. The config system treats the AppConfig.Builder (not the enclosing target class) as a JavaBean. The builder&#8217;s property greeting is not customized and is set from config node with greeting key, if one exists. The builder&#8217;s property pageSize maps to the config key page-size and defaults to 10 if absent. The builder&#8217;s property basicRange maps to the config key basic-range and uses a BasicRangeSupplier instance to get a default value if needed. Finally, the config system invokes the builder&#8217;s public method build() , creating the new instance of AppConfig for use by the application. ",
            "title": "Builder as JavaBean"
        },
        {
            "location": "/se/config/property-mapping",
            "text": " Another option is to annotate the parameters to a factory method or to a constructor on the target class. You can add a factory method to the target class, a public static method from with parameters annotated to link them to the corresponding config keys. Or you can add or modify a constructor with parameters, similarly annotated to form the link from each parameter to the corresponding config key. Warning Be sure to annotate each parameter of the from method or constructor with @Value and specify the key to use for the mapping. The parameter names in the Java code are not always available at runtime to map to config keys. (They might be arg0 , arg1 , etc.) <markup lang=\"java\" title=\"Target Class with Factory Method from \" >public class AppConfig { private final String greeting; private final int pageSize; private final List&lt;Integer&gt; basicRange; private AppConfig(String greeting, int pageSize, List&lt;Integer&gt; basicRange) { this.greeting = greeting; this.pageSize = pageSize; this.basicRange = basicRange; } public String getGreeting() { return greeting; } public int getPageSize() { return pageSize; } public List&lt;Integer&gt; getBasicRange() { return basicRange; } public static AppConfig from( @Value(key = \"greeting\") String greeting, @Value(key = \"page-size\", withDefault = \"10\") int pageSize, @Value(key = \"basic-range\", withDefaultSupplier = BasicRangeSupplier.class) List&lt;Integer&gt; basicRange) { return new AppConfig(greeting, pageSize, basicRange); } } The target class constructor can be private because the factory method on the same class has access to it. The config system invokes the factory method from(&#8230;&#8203;) , passing arguments it has fetched from the correspondingly-named config subtrees. The factory method returns the new initialized AppConfig instance. Note the consistent use of @Value(key = \"&#8230;&#8203;\") on each parameter. Because the property greeting does not specify a default value the property is mandatory and must appear in the configuration source. Otherwise, the config system throws a ConfigMappingException . Alternatively, you can use an annotated constructor instead of a static factory method. Revising the example above, make the constructor public, annotate its parameters, and remove the now-unneeded from factory method. <markup lang=\"java\" title=\"Target Class with Annotated Public Constructor\" >public class AppConfig { public AppConfig( @Value(key = \"greeting\") String greeting, @Value(key = \"page-size\", withDefault = \"10\") int pageSize, @Value(key = \"basic-range\", withDefaultSupplier = BasicRangeSupplier.class) List&lt;Integer&gt; basicRange) { this.greeting = greeting; this.pageSize = pageSize; this.basicRange = basicRange; } } Constructor is public . Each parameter has the ConfigValue annotation to at least specify the config key name. When the application invokes config.as(AppConfig.class) , the config system locates the public annotated constructor and invokes it, passing as arguments the data it fetches from the configuration matching the annotation key names with the configuration keys. ",
            "title": "Target Class with Annotated Factory Method or Constructor"
        },
        {
            "location": "/se/config/property-mapping",
            "text": " The config system can also interpret your classes as JavaBeans and use the normal bean naming conventions to map configuration data to your POJO classes, using one of these patterns: POJO as JavaBean - The config system treats the target class itself as a JavaBean, assigning values from the config to the bean properties of the POJO class. builder as JavaBean - The config system invokes the POJO&#8217;s builder() method to obtain a builder for that POJO type and treats the builder class as a JavaBean, assigning values from the config to the builder&#8217;s bean properties and then invoking the builder&#8217;s build method to create an instance of the target POJO class. POJO with factory method or decorated constructor - The config system finds a from method or a constructor on the POJO class itself which accepts annotated arguments, then invokes that method or constructor passing the specified arguments based on the config. The from method returns an instance of the POJO class initialized with the values passed as arguments. The following sections describe these patterns in more detail. This feature is available in Object mapping module, and is added through Java ServiceLoader mechanism. This is no longer part of core Config module, as it depends on reflection. <markup lang=\"xml\" title=\"Config object mapping Dependency in pom.xml \" >&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.config&lt;/groupId&gt; &lt;artifactId&gt;helidon-config-object-mapping&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; POJO as JavaBean If your POJO target class is already a JavaBean&#8201;&#8212;&#8201;or you can modify it to become one&#8201;&#8212;&#8201;you might be able to avoid writing any explicit mapping code yourself. The config system invokes the no-args constructor on the target class to create a new instance. It treats each public setter method and each public non-final field as a JavaBean property. The config system processes any non-primitive property recursively as a JavaBean. In this way the config system builds up the target object from the config data. By default, the system matches potential JavaBean property names with config keys in the configuration. Use the Value annotation to control some of JavaBean processing for a given property. Value Annotation Attribute Usage key Indicates which config key should match this JavaBean property withDefault String used for the bean property default value if none is set in the config withDefaultSupplier Supplier of the default bean property value if not is set in the config To exclude a bean property from the config system bean processing annotate it with Transient . Here is an example using the app portion of the example configuration from the introduction. <markup lang=\"java\" title=\"Java bean to load app properties into via setters\" >public class AppConfig { private Instant timestamp; private String greeting; private int pageSize; private List&lt;Integer&gt; basicRange; public AppConfig() { } public void setGreeting(String greeting) { this.greeting = greeting; } public String getGreeting() { return greeting; } @Value(key = \"page-size\", withDefault = \"10\") public void setPageSize(int pageSize) { this.pageSize = pageSize; } public int getPageSize() { return pageSize; } @Value(key = \"basic-range\", withDefaultSupplier = BasicRangeSupplier.class) public void setBasicRange(List&lt;Integer&gt; basicRange) { this.basicRange = basicRange; } public List&lt;Integer&gt; getBasicRange() { return basicRange; } @Transient public void setTimestamp(Instant timestamp) { this.timestamp = timestamp; } public Instant getTimestamp() { return timestamp; } public static class BasicRangeSupplier implements Supplier&lt;List&lt;Integer&gt;&gt; { @Override public List&lt;Integer&gt; get() { return List.of(-10, 10); } } } Public no-parameter constructor. Property greeting is not customized and will be set from the config node with the key greeting , if present in the config. Property pageSize is matched to the config key page-size . If the page-size config node does not exist, the pageSize bean property defaults to 10 . Property basicRange is matched to the config key basic-range . If the basic-range config node does not exist, a BasicRangeSupplier instance will provide the default value. The timestamp bean property is never set, even if the config contains a node with the key timestamp . BasicRangeSupplier is used to supply the List&lt;Integer&gt; default value. Here is an example of code loading config and mapping part of it to the AppConfig bean above. <markup lang=\"java\" title=\"Map app config node into AppConfig class\" >Config config = Config.create(classpath(\"application.conf\")); AppConfig app = config.get(\"app\") .as(AppConfig.class) .get(); //assert that all values are loaded from file assert app.getGreeting().equals(\"Hello\"); assert app.getPageSize() == 20; assert app.getBasicRange().size() == 2 &amp;&amp; app.getBasicRange().get(0) == -20 &amp;&amp; app.getBasicRange().get(1) == 20; //assert that Transient property is not set assert app.getTimestamp() == null; The config system finds no registered ConfigMapper for AppConfig and so applies the JavaBean pattern to convert the config to an AppConfig instance. Because the bean property timestamp was marked as transient, the config system did not set it. Builder as JavaBean If the target class includes the public static method builder() that returns any object, then the config system will make sure that the return type has a method build() which returns an instance of the target class. If so, the config system treats the builder as a JavaBean and invokes the builder() method to instantiate the builder class, treats the builder as a JavaBean and maps the Config subtree to it, invokes the builder&#8217;s build() method to create the new instance of the target class. You can augment the target class with the public static builder() method: <markup lang=\"java\" title=\"JavaBean for app properties, via a Builder \" >public class AppConfig { private String greeting; private int pageSize; private List&lt;Integer&gt; basicRange; private AppConfig(String greeting, int pageSize, List&lt;Integer&gt; basicRange) { this.greeting = greeting; this.pageSize = pageSize; this.basicRange = basicRange; } public String getGreeting() { return greeting; } public int getPageSize() { return pageSize; } public List&lt;Integer&gt; getBasicRange() { return basicRange; } public static Builder builder() { return new Builder(); } public static class Builder { private String greeting; private int pageSize; private List&lt;Integer&gt; basicRange; private Builder() { } public void setGreeting(String greeting) { this.greeting = greeting; } @Value(key = \"page-size\", withDefault = \"10\") public void setPageSize(int pageSize) { this.pageSize = pageSize; } @Value(key = \"basic-range\", withDefaultSupplier = BasicRangeSupplier.class) public void setBasicRange(List&lt;Integer&gt; basicRange) { this.basicRange = basicRange; } public AppConfig build() { return new AppConfig(greeting, pageSize, basicRange); } } } The target class&#8217;s constructor can be private in this case because new instances are created from the inner class Builder which has access to `AppConfig&#8217;s private members. The target class contains public static method builder() which returns an object that itself exposes the method AppConfig build() , so the config system recognizes it. The config system treats the AppConfig.Builder (not the enclosing target class) as a JavaBean. The builder&#8217;s property greeting is not customized and is set from config node with greeting key, if one exists. The builder&#8217;s property pageSize maps to the config key page-size and defaults to 10 if absent. The builder&#8217;s property basicRange maps to the config key basic-range and uses a BasicRangeSupplier instance to get a default value if needed. Finally, the config system invokes the builder&#8217;s public method build() , creating the new instance of AppConfig for use by the application. Target Class with Annotated Factory Method or Constructor Another option is to annotate the parameters to a factory method or to a constructor on the target class. You can add a factory method to the target class, a public static method from with parameters annotated to link them to the corresponding config keys. Or you can add or modify a constructor with parameters, similarly annotated to form the link from each parameter to the corresponding config key. Warning Be sure to annotate each parameter of the from method or constructor with @Value and specify the key to use for the mapping. The parameter names in the Java code are not always available at runtime to map to config keys. (They might be arg0 , arg1 , etc.) <markup lang=\"java\" title=\"Target Class with Factory Method from \" >public class AppConfig { private final String greeting; private final int pageSize; private final List&lt;Integer&gt; basicRange; private AppConfig(String greeting, int pageSize, List&lt;Integer&gt; basicRange) { this.greeting = greeting; this.pageSize = pageSize; this.basicRange = basicRange; } public String getGreeting() { return greeting; } public int getPageSize() { return pageSize; } public List&lt;Integer&gt; getBasicRange() { return basicRange; } public static AppConfig from( @Value(key = \"greeting\") String greeting, @Value(key = \"page-size\", withDefault = \"10\") int pageSize, @Value(key = \"basic-range\", withDefaultSupplier = BasicRangeSupplier.class) List&lt;Integer&gt; basicRange) { return new AppConfig(greeting, pageSize, basicRange); } } The target class constructor can be private because the factory method on the same class has access to it. The config system invokes the factory method from(&#8230;&#8203;) , passing arguments it has fetched from the correspondingly-named config subtrees. The factory method returns the new initialized AppConfig instance. Note the consistent use of @Value(key = \"&#8230;&#8203;\") on each parameter. Because the property greeting does not specify a default value the property is mandatory and must appear in the configuration source. Otherwise, the config system throws a ConfigMappingException . Alternatively, you can use an annotated constructor instead of a static factory method. Revising the example above, make the constructor public, annotate its parameters, and remove the now-unneeded from factory method. <markup lang=\"java\" title=\"Target Class with Annotated Public Constructor\" >public class AppConfig { public AppConfig( @Value(key = \"greeting\") String greeting, @Value(key = \"page-size\", withDefault = \"10\") int pageSize, @Value(key = \"basic-range\", withDefaultSupplier = BasicRangeSupplier.class) List&lt;Integer&gt; basicRange) { this.greeting = greeting; this.pageSize = pageSize; this.basicRange = basicRange; } } Constructor is public . Each parameter has the ConfigValue annotation to at least specify the config key name. When the application invokes config.as(AppConfig.class) , the config system locates the public annotated constructor and invokes it, passing as arguments the data it fetches from the configuration matching the annotation key names with the configuration keys. ",
            "title": "Conversions using JavaBean Deserialization"
        },
        {
            "location": "/se/config/supported-formats",
            "text": " Overview Additional Config Formats and Parsers Additional Config Source Types ",
            "title": "Contents"
        },
        {
            "location": "/se/config/supported-formats",
            "text": " Helidon Config provides several extension modules that support other configuration formats (parsers) and sources. This document describes how to include them and use them in your project. In each case you need to add module dependencies to your project and, in some cases, write your application accordingly. ",
            "title": "Overview"
        },
        {
            "location": "/se/config/supported-formats",
            "text": " With each of the parsers described here, your application can either explicitly add a parser of the correct implementation to the Config.Builder , or rely on Java service loading and the config system&#8217;s matching of file types and media types to parsers. If your application creates a Config.Builder with parser services disabled (see disableParserServices then that builder will not find the Java services for the various parsers and so will be unable to match the file type or media type of sources with the corresponding parser automatically. So if you want to use automatic type matching with a given builder, do not invoke Config.Builder.disableParserServices() . ",
            "title": "Automatic Media Type and File Type Handling"
        },
        {
            "location": "/se/config/supported-formats",
            "text": " Add the following dependency in your project: <markup lang=\"xml\" title=\"Config YAML Dependency in pom.xml \" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.config&lt;/groupId&gt; &lt;artifactId&gt;helidon-config-yaml&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"java\" title=\"Config YAML Dependency in module-info.java \" >module myModule { requires io.helidon.config.yaml; } ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/config/supported-formats",
            "text": " The YAML parser handles the following media type: application/x-yaml - YAML format (file type .yaml ) <markup lang=\"java\" title=\"Automatic selection\" >Config config = Config.create(classpath(\"application.yaml\")); The config system automatically maps the file type .yaml to the media type application/x-yaml which the Helidon YAML parser matches. <markup lang=\"java\" title=\"YAML parser specified - no file type on source\" >Config config = Config.create(classpath(\"my-config\") .parser(YamlConfigParser.create())); The media type of the source my-config is unknown, so the config system cannot choose a parser automatically. The config system will parse the resource my-config on the runtime classpath using the YAML parser instance created by the YamlConfigParser . The create() method creates a config parser with default behavior. <markup lang=\"java\" title=\"Media type specified\" >Config config = Config.create(classpath(\"my-config\") .mediaType(MediaTypes.APPLICATION_X_YAML)); The media type of the source my-config is unknown, so the config system cannot choose a parser automatically. Specifying the media type for the config source allows the config system to use its matching algorithm with the available parsers to choose a parser for that type. <markup lang=\"java\" title=\"YAML parser specified because parser services disabled\" >Config config = Config.builder(classpath(\"application.yaml\")) .disableParserServices() .addParser(YamlConfigParser.create()) .build(); Disables automatic parser lookup and registration. Explicit registration of the YAML parser is therefore required. ",
            "title": "Using the YAML Parser"
        },
        {
            "location": "/se/config/supported-formats",
            "text": " Maven Coordinates Add the following dependency in your project: <markup lang=\"xml\" title=\"Config YAML Dependency in pom.xml \" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.config&lt;/groupId&gt; &lt;artifactId&gt;helidon-config-yaml&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"java\" title=\"Config YAML Dependency in module-info.java \" >module myModule { requires io.helidon.config.yaml; } Using the YAML Parser The YAML parser handles the following media type: application/x-yaml - YAML format (file type .yaml ) <markup lang=\"java\" title=\"Automatic selection\" >Config config = Config.create(classpath(\"application.yaml\")); The config system automatically maps the file type .yaml to the media type application/x-yaml which the Helidon YAML parser matches. <markup lang=\"java\" title=\"YAML parser specified - no file type on source\" >Config config = Config.create(classpath(\"my-config\") .parser(YamlConfigParser.create())); The media type of the source my-config is unknown, so the config system cannot choose a parser automatically. The config system will parse the resource my-config on the runtime classpath using the YAML parser instance created by the YamlConfigParser . The create() method creates a config parser with default behavior. <markup lang=\"java\" title=\"Media type specified\" >Config config = Config.create(classpath(\"my-config\") .mediaType(MediaTypes.APPLICATION_X_YAML)); The media type of the source my-config is unknown, so the config system cannot choose a parser automatically. Specifying the media type for the config source allows the config system to use its matching algorithm with the available parsers to choose a parser for that type. <markup lang=\"java\" title=\"YAML parser specified because parser services disabled\" >Config config = Config.builder(classpath(\"application.yaml\")) .disableParserServices() .addParser(YamlConfigParser.create()) .build(); Disables automatic parser lookup and registration. Explicit registration of the YAML parser is therefore required. ",
            "title": "YAML"
        },
        {
            "location": "/se/config/supported-formats",
            "text": " Add the following dependency in your project: <markup lang=\"xml\" title=\"Config HOCON Dependency in pom.xml \" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.config&lt;/groupId&gt; &lt;artifactId&gt;helidon-config-hocon&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"java\" title=\"Config HOCON Dependency in module-info.java \" >module myModule { requires io.helidon.config.hocon; } ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/config/supported-formats",
            "text": " The parser handles the following media types: application/hocon - HOCON format (file type .conf ) application/json - JSON format (file type .json ) <markup lang=\"java\" title=\"Automatic selection\" >Config config = Config.create(classpath(\"application.conf\")); The config system automatically maps the file type .conf to the media type `application/hocon which the Helidon HOCON parser matches. The same module and parser supports file type .json and the media type application/json . <markup lang=\"java\" title=\"HOCON parser specified - no file type on source\" >Config config = Config.create(classpath(\"my-config\") .parser(HoconConfigParser.create())); the media type of the source my-config is unknown, so the config system cannot choose a parser automatically. The config system will parse the resource my-config using the HOCON parser created by the HoconConfigParser . The create() method creates a config parser with default behavior. <markup lang=\"java\" title=\"Media type specified\" >Config config = Config.create(classpath(\"my-config\") .mediaType(MediaTypes.APPLICATION_HOCON)); The media type of the source my-config is unknown, so the config system cannot choose a parser automatically. Specifying the media type for the config source allows the config system to use its matching algorithm with the available parsers to choose a parser for that type. <markup lang=\"java\" title=\"HOCON parser specified because parser services disabled\" >Config config = Config.builder(classpath(\"application.conf\")) .disableParserServices() .addParser(HoconConfigParser.create()) .build(); Disables automatic parser lookup and registration. Explicit registration of the HOCON parser is therefore required. <markup lang=\"java\" title=\"Customized HOCON parser\" >Config config = Config.builder(classpath(\"application.conf\")) .disableParserServices() .addParser(HoconConfigParser.builder() .resolvingEnabled(false) .build()) .build(); Creates new instance of the parser builder. Disables resolution of substitutions. (See the HOCON documentation .) Builds a new instance of the HOCON config parser. You can also specify ConfigResolveOptions using the HoconConfigParser.builder().resolveOptions method. ",
            "title": "Using the HOCON/JSON Parser"
        },
        {
            "location": "/se/config/supported-formats",
            "text": " The Helidon HOCON config module handles sources in the HOCON and JSON formats. Maven Coordinates Add the following dependency in your project: <markup lang=\"xml\" title=\"Config HOCON Dependency in pom.xml \" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.config&lt;/groupId&gt; &lt;artifactId&gt;helidon-config-hocon&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"java\" title=\"Config HOCON Dependency in module-info.java \" >module myModule { requires io.helidon.config.hocon; } Using the HOCON/JSON Parser The parser handles the following media types: application/hocon - HOCON format (file type .conf ) application/json - JSON format (file type .json ) <markup lang=\"java\" title=\"Automatic selection\" >Config config = Config.create(classpath(\"application.conf\")); The config system automatically maps the file type .conf to the media type `application/hocon which the Helidon HOCON parser matches. The same module and parser supports file type .json and the media type application/json . <markup lang=\"java\" title=\"HOCON parser specified - no file type on source\" >Config config = Config.create(classpath(\"my-config\") .parser(HoconConfigParser.create())); the media type of the source my-config is unknown, so the config system cannot choose a parser automatically. The config system will parse the resource my-config using the HOCON parser created by the HoconConfigParser . The create() method creates a config parser with default behavior. <markup lang=\"java\" title=\"Media type specified\" >Config config = Config.create(classpath(\"my-config\") .mediaType(MediaTypes.APPLICATION_HOCON)); The media type of the source my-config is unknown, so the config system cannot choose a parser automatically. Specifying the media type for the config source allows the config system to use its matching algorithm with the available parsers to choose a parser for that type. <markup lang=\"java\" title=\"HOCON parser specified because parser services disabled\" >Config config = Config.builder(classpath(\"application.conf\")) .disableParserServices() .addParser(HoconConfigParser.create()) .build(); Disables automatic parser lookup and registration. Explicit registration of the HOCON parser is therefore required. <markup lang=\"java\" title=\"Customized HOCON parser\" >Config config = Config.builder(classpath(\"application.conf\")) .disableParserServices() .addParser(HoconConfigParser.builder() .resolvingEnabled(false) .build()) .build(); Creates new instance of the parser builder. Disables resolution of substitutions. (See the HOCON documentation .) Builds a new instance of the HOCON config parser. You can also specify ConfigResolveOptions using the HoconConfigParser.builder().resolveOptions method. ",
            "title": "HOCON/JSON"
        },
        {
            "location": "/se/config/supported-formats",
            "text": " Automatic Media Type and File Type Handling With each of the parsers described here, your application can either explicitly add a parser of the correct implementation to the Config.Builder , or rely on Java service loading and the config system&#8217;s matching of file types and media types to parsers. If your application creates a Config.Builder with parser services disabled (see disableParserServices then that builder will not find the Java services for the various parsers and so will be unable to match the file type or media type of sources with the corresponding parser automatically. So if you want to use automatic type matching with a given builder, do not invoke Config.Builder.disableParserServices() . YAML Maven Coordinates Add the following dependency in your project: <markup lang=\"xml\" title=\"Config YAML Dependency in pom.xml \" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.config&lt;/groupId&gt; &lt;artifactId&gt;helidon-config-yaml&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"java\" title=\"Config YAML Dependency in module-info.java \" >module myModule { requires io.helidon.config.yaml; } Using the YAML Parser The YAML parser handles the following media type: application/x-yaml - YAML format (file type .yaml ) <markup lang=\"java\" title=\"Automatic selection\" >Config config = Config.create(classpath(\"application.yaml\")); The config system automatically maps the file type .yaml to the media type application/x-yaml which the Helidon YAML parser matches. <markup lang=\"java\" title=\"YAML parser specified - no file type on source\" >Config config = Config.create(classpath(\"my-config\") .parser(YamlConfigParser.create())); The media type of the source my-config is unknown, so the config system cannot choose a parser automatically. The config system will parse the resource my-config on the runtime classpath using the YAML parser instance created by the YamlConfigParser . The create() method creates a config parser with default behavior. <markup lang=\"java\" title=\"Media type specified\" >Config config = Config.create(classpath(\"my-config\") .mediaType(MediaTypes.APPLICATION_X_YAML)); The media type of the source my-config is unknown, so the config system cannot choose a parser automatically. Specifying the media type for the config source allows the config system to use its matching algorithm with the available parsers to choose a parser for that type. <markup lang=\"java\" title=\"YAML parser specified because parser services disabled\" >Config config = Config.builder(classpath(\"application.yaml\")) .disableParserServices() .addParser(YamlConfigParser.create()) .build(); Disables automatic parser lookup and registration. Explicit registration of the YAML parser is therefore required. HOCON/JSON The Helidon HOCON config module handles sources in the HOCON and JSON formats. Maven Coordinates Add the following dependency in your project: <markup lang=\"xml\" title=\"Config HOCON Dependency in pom.xml \" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.config&lt;/groupId&gt; &lt;artifactId&gt;helidon-config-hocon&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"java\" title=\"Config HOCON Dependency in module-info.java \" >module myModule { requires io.helidon.config.hocon; } Using the HOCON/JSON Parser The parser handles the following media types: application/hocon - HOCON format (file type .conf ) application/json - JSON format (file type .json ) <markup lang=\"java\" title=\"Automatic selection\" >Config config = Config.create(classpath(\"application.conf\")); The config system automatically maps the file type .conf to the media type `application/hocon which the Helidon HOCON parser matches. The same module and parser supports file type .json and the media type application/json . <markup lang=\"java\" title=\"HOCON parser specified - no file type on source\" >Config config = Config.create(classpath(\"my-config\") .parser(HoconConfigParser.create())); the media type of the source my-config is unknown, so the config system cannot choose a parser automatically. The config system will parse the resource my-config using the HOCON parser created by the HoconConfigParser . The create() method creates a config parser with default behavior. <markup lang=\"java\" title=\"Media type specified\" >Config config = Config.create(classpath(\"my-config\") .mediaType(MediaTypes.APPLICATION_HOCON)); The media type of the source my-config is unknown, so the config system cannot choose a parser automatically. Specifying the media type for the config source allows the config system to use its matching algorithm with the available parsers to choose a parser for that type. <markup lang=\"java\" title=\"HOCON parser specified because parser services disabled\" >Config config = Config.builder(classpath(\"application.conf\")) .disableParserServices() .addParser(HoconConfigParser.create()) .build(); Disables automatic parser lookup and registration. Explicit registration of the HOCON parser is therefore required. <markup lang=\"java\" title=\"Customized HOCON parser\" >Config config = Config.builder(classpath(\"application.conf\")) .disableParserServices() .addParser(HoconConfigParser.builder() .resolvingEnabled(false) .build()) .build(); Creates new instance of the parser builder. Disables resolution of substitutions. (See the HOCON documentation .) Builds a new instance of the HOCON config parser. You can also specify ConfigResolveOptions using the HoconConfigParser.builder().resolveOptions method. ",
            "title": "Additional Config Formats and Parsers"
        },
        {
            "location": "/se/config/supported-formats",
            "text": " Add the following dependency to your project: <markup lang=\"xml\" title=\"Config Etcd Dependency in pom.xml \" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.config&lt;/groupId&gt; &lt;artifactId&gt;helidon-config-etcd&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"java\" title=\"Config Etcd Dependency in module-info.java \" >module myModule { requires io.helidon.config.etcd; } ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/config/supported-formats",
            "text": " To read configuration from an Etcd source, your application uses the EtcdConfigSourceBuilder . <markup lang=\"java\" title=\"Use Etcd config source\" >Config config = Config.create( EtcdConfigSource .create(URI.create(\"http://my-etcd:2379\"), \"/config.yaml\", EtcdConfigSourceBuilder.EtcdApi.v3)); Use the factory method EtcdConfigSource.create to create the EtcdConfigSource . Specify the Etcd endpoint address. Specify the Etcd key of the configuration document. Version of the Etcd API to use; v3 is supported. v2 is deprecated. The config system will use the YAML parser automatically in this example because the file type of the key is .yaml . The EtcdConfigSourceBuilder class extends AbstractConfigSourceBuilder and so supports the usual settings on config sources. ",
            "title": "Using the Etcd Config Source"
        },
        {
            "location": "/se/config/supported-formats",
            "text": " The Etcd support includes a change watcher strategy designed for an etcd config source. <markup lang=\"java\" title=\"Use Etcd config source\" >Config config = Config.create( EtcdConfigSource .builder() .uri(URI.create(\"http://my-etcd:2379\")) .key(\"/config.yaml\") .api(EtcdConfigSourceBuilder.EtcdApi.v3) .changeWatcher(EtcdWatcher.create())); Use the etcd-specific change watcher strategy. ",
            "title": "Monitoring for Source Changes"
        },
        {
            "location": "/se/config/supported-formats",
            "text": " To read meta-configuration from an Etcd source set the following required properties for the source: type to etcd , or class to io.helidon.config.etcd.EtcdConfigSourceBuilder uri (type URI ) - Etcd endpoint URI. key (type String ) - Etcd key that is associated with the configuration. api (type EtcdConfigSourceBuilder.EtcdApi , i.e. v2 or v3 ) - Etcd API version. v2 is deprecated. Other optional properties are inherited from AbstractConfigSourceBuilder . (see javadoc ) <markup lang=\"java\" title=\"Load Config from meta-configuration\" >Config config = Config.loadSourcesFrom(classpath(\"config-meta-etcd.yaml\")); <markup lang=\"YAML\" title=\"Meta-config config-meta-etcd.yaml for the etcd source\" >sources: - type: \"etcd\" properties: uri: \"http://my-etcd:2379\" key: \"/config.yaml\" api: \"v3\" change-watcher: type: \"etcd\" etcd config source type Etcd source-specific (mandatory) properties : uri , key and api . Watcher strategy EtcdWatcher is automatically initialized by specified mandatory properties . ",
            "title": "Loading Meta-configuration via Etcd"
        },
        {
            "location": "/se/config/supported-formats",
            "text": " The Helidon Etcd config module supports reading configuration from a specified Etcd key. Maven Coordinates Add the following dependency to your project: <markup lang=\"xml\" title=\"Config Etcd Dependency in pom.xml \" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.config&lt;/groupId&gt; &lt;artifactId&gt;helidon-config-etcd&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"java\" title=\"Config Etcd Dependency in module-info.java \" >module myModule { requires io.helidon.config.etcd; } Using the Etcd Config Source To read configuration from an Etcd source, your application uses the EtcdConfigSourceBuilder . <markup lang=\"java\" title=\"Use Etcd config source\" >Config config = Config.create( EtcdConfigSource .create(URI.create(\"http://my-etcd:2379\"), \"/config.yaml\", EtcdConfigSourceBuilder.EtcdApi.v3)); Use the factory method EtcdConfigSource.create to create the EtcdConfigSource . Specify the Etcd endpoint address. Specify the Etcd key of the configuration document. Version of the Etcd API to use; v3 is supported. v2 is deprecated. The config system will use the YAML parser automatically in this example because the file type of the key is .yaml . The EtcdConfigSourceBuilder class extends AbstractConfigSourceBuilder and so supports the usual settings on config sources. Monitoring for Source Changes The Etcd support includes a change watcher strategy designed for an etcd config source. <markup lang=\"java\" title=\"Use Etcd config source\" >Config config = Config.create( EtcdConfigSource .builder() .uri(URI.create(\"http://my-etcd:2379\")) .key(\"/config.yaml\") .api(EtcdConfigSourceBuilder.EtcdApi.v3) .changeWatcher(EtcdWatcher.create())); Use the etcd-specific change watcher strategy. Loading Meta-configuration via Etcd To read meta-configuration from an Etcd source set the following required properties for the source: type to etcd , or class to io.helidon.config.etcd.EtcdConfigSourceBuilder uri (type URI ) - Etcd endpoint URI. key (type String ) - Etcd key that is associated with the configuration. api (type EtcdConfigSourceBuilder.EtcdApi , i.e. v2 or v3 ) - Etcd API version. v2 is deprecated. Other optional properties are inherited from AbstractConfigSourceBuilder . (see javadoc ) <markup lang=\"java\" title=\"Load Config from meta-configuration\" >Config config = Config.loadSourcesFrom(classpath(\"config-meta-etcd.yaml\")); <markup lang=\"YAML\" title=\"Meta-config config-meta-etcd.yaml for the etcd source\" >sources: - type: \"etcd\" properties: uri: \"http://my-etcd:2379\" key: \"/config.yaml\" api: \"v3\" change-watcher: type: \"etcd\" etcd config source type Etcd source-specific (mandatory) properties : uri , key and api . Watcher strategy EtcdWatcher is automatically initialized by specified mandatory properties . ",
            "title": "Etcd"
        },
        {
            "location": "/se/config/supported-formats",
            "text": " Add the following dependency to your project: <markup lang=\"xml\" title=\"Config git Dependency in pom.xml \" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.config&lt;/groupId&gt; &lt;artifactId&gt;helidon-config-git&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"java\" title=\"Config git Dependency in module-info.java \" >module myModule { requires io.helidon.config.git; } ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/config/supported-formats",
            "text": " To read configuration from a git source, your application uses the GitConfigSourceBuilder . <markup lang=\"java\" title=\"Use git config source\" >Config config = Config.create( GitConfigSource .builder() .uri(URI.create(\"https://github.com/okosatka/test-config.git\")) .directory(Paths.get(\"/config\")) .branch(\"dev\")); Use the factory method GitConfigSource.builder to initialize the builder. Specify the git repository URI. Specify a directory where the git repository is already cloned or it will be cloned. Specify the git branch. Note that the config system will use the HOCON parser in this example because the file type is .conf . Recall that for this to work the HOCON config module must be on module-path or classpath. The GitConfigSourceBuilder supports the usual source builder properties because it extends AbstractConfigSourceBuilder . ",
            "title": "Using the git Config Source"
        },
        {
            "location": "/se/config/supported-formats",
            "text": " Your application can monitor changes to a configuration loaded from a git source associating the regular built-in polling strategy with the source. <markup lang=\"java\" title=\"Use of git config source with polling strategy\" >Config config = Config.create( GitConfigSourceBuilder .create(\"application.conf\") .uri(URI.create(\"https://github.com/okosatka/test-config.git\")) .pollingStrategy(PollingStrategies.regular(Duration.ofMinutes(5)))); Use PollingStrategies.regular(Duration duration) to monitor for config changes. You can also implement your own polling strategy by implementing PollingStrategy . See the mutability support and polling strategy discussions. ",
            "title": "Monitoring for Source Changes"
        },
        {
            "location": "/se/config/supported-formats",
            "text": " The config system can load information about config sources from meta-configuration rather than requiring your application to construct the builder. To read meta-configuration from a git config source set the following properties for the source: type to git or class to io.helidon.config.git.GitConfigSourceBuilder path (type String ) - Relative path to the configuration file in repository. uri (type URI ) - URI to the git repository. directory (type Path ) - Directory with a cloned repository, by default a temporary directory. branch (type String ) - git branch (default is master ). The meta-configuration must set the path and one of uri or directory . Other optional properties are inherited from AbstractParsableConfigSource.Builder (see javadoc ) <markup lang=\"java\" title=\"Load Config from meta-configuration\" >Config config = Config.loadSourcesFrom(classpath(\"config-meta-git.yaml\")); <markup lang=\"YAML\" title=\"Meta-config config-meta-git.yaml for the git source\" >sources: - type: \"git\" properties: path: \"application.conf\" uri: \"https://github.com/okosatka/test-config.git\" directory: \"/config\" branch: \"dev\" polling-strategy: type: \"regular\" properties: interval: \"PT5M\" git config source type git source-specific properties: path , uri , directory and branch . Polling strategy regular with an interval, in Duration format, of 5 minutes in this example. ",
            "title": "Loading Meta-configuration via git"
        },
        {
            "location": "/se/config/supported-formats",
            "text": " The Helidon git config module supports reading configuration from a git repository. Maven Coordinates Add the following dependency to your project: <markup lang=\"xml\" title=\"Config git Dependency in pom.xml \" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.config&lt;/groupId&gt; &lt;artifactId&gt;helidon-config-git&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"java\" title=\"Config git Dependency in module-info.java \" >module myModule { requires io.helidon.config.git; } Using the git Config Source To read configuration from a git source, your application uses the GitConfigSourceBuilder . <markup lang=\"java\" title=\"Use git config source\" >Config config = Config.create( GitConfigSource .builder() .uri(URI.create(\"https://github.com/okosatka/test-config.git\")) .directory(Paths.get(\"/config\")) .branch(\"dev\")); Use the factory method GitConfigSource.builder to initialize the builder. Specify the git repository URI. Specify a directory where the git repository is already cloned or it will be cloned. Specify the git branch. Note that the config system will use the HOCON parser in this example because the file type is .conf . Recall that for this to work the HOCON config module must be on module-path or classpath. The GitConfigSourceBuilder supports the usual source builder properties because it extends AbstractConfigSourceBuilder . Monitoring for Source Changes Your application can monitor changes to a configuration loaded from a git source associating the regular built-in polling strategy with the source. <markup lang=\"java\" title=\"Use of git config source with polling strategy\" >Config config = Config.create( GitConfigSourceBuilder .create(\"application.conf\") .uri(URI.create(\"https://github.com/okosatka/test-config.git\")) .pollingStrategy(PollingStrategies.regular(Duration.ofMinutes(5)))); Use PollingStrategies.regular(Duration duration) to monitor for config changes. You can also implement your own polling strategy by implementing PollingStrategy . See the mutability support and polling strategy discussions. Loading Meta-configuration via git The config system can load information about config sources from meta-configuration rather than requiring your application to construct the builder. To read meta-configuration from a git config source set the following properties for the source: type to git or class to io.helidon.config.git.GitConfigSourceBuilder path (type String ) - Relative path to the configuration file in repository. uri (type URI ) - URI to the git repository. directory (type Path ) - Directory with a cloned repository, by default a temporary directory. branch (type String ) - git branch (default is master ). The meta-configuration must set the path and one of uri or directory . Other optional properties are inherited from AbstractParsableConfigSource.Builder (see javadoc ) <markup lang=\"java\" title=\"Load Config from meta-configuration\" >Config config = Config.loadSourcesFrom(classpath(\"config-meta-git.yaml\")); <markup lang=\"YAML\" title=\"Meta-config config-meta-git.yaml for the git source\" >sources: - type: \"git\" properties: path: \"application.conf\" uri: \"https://github.com/okosatka/test-config.git\" directory: \"/config\" branch: \"dev\" polling-strategy: type: \"regular\" properties: interval: \"PT5M\" git config source type git source-specific properties: path , uri , directory and branch . Polling strategy regular with an interval, in Duration format, of 5 minutes in this example. ",
            "title": "git"
        },
        {
            "location": "/se/config/supported-formats",
            "text": " Etcd The Helidon Etcd config module supports reading configuration from a specified Etcd key. Maven Coordinates Add the following dependency to your project: <markup lang=\"xml\" title=\"Config Etcd Dependency in pom.xml \" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.config&lt;/groupId&gt; &lt;artifactId&gt;helidon-config-etcd&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"java\" title=\"Config Etcd Dependency in module-info.java \" >module myModule { requires io.helidon.config.etcd; } Using the Etcd Config Source To read configuration from an Etcd source, your application uses the EtcdConfigSourceBuilder . <markup lang=\"java\" title=\"Use Etcd config source\" >Config config = Config.create( EtcdConfigSource .create(URI.create(\"http://my-etcd:2379\"), \"/config.yaml\", EtcdConfigSourceBuilder.EtcdApi.v3)); Use the factory method EtcdConfigSource.create to create the EtcdConfigSource . Specify the Etcd endpoint address. Specify the Etcd key of the configuration document. Version of the Etcd API to use; v3 is supported. v2 is deprecated. The config system will use the YAML parser automatically in this example because the file type of the key is .yaml . The EtcdConfigSourceBuilder class extends AbstractConfigSourceBuilder and so supports the usual settings on config sources. Monitoring for Source Changes The Etcd support includes a change watcher strategy designed for an etcd config source. <markup lang=\"java\" title=\"Use Etcd config source\" >Config config = Config.create( EtcdConfigSource .builder() .uri(URI.create(\"http://my-etcd:2379\")) .key(\"/config.yaml\") .api(EtcdConfigSourceBuilder.EtcdApi.v3) .changeWatcher(EtcdWatcher.create())); Use the etcd-specific change watcher strategy. Loading Meta-configuration via Etcd To read meta-configuration from an Etcd source set the following required properties for the source: type to etcd , or class to io.helidon.config.etcd.EtcdConfigSourceBuilder uri (type URI ) - Etcd endpoint URI. key (type String ) - Etcd key that is associated with the configuration. api (type EtcdConfigSourceBuilder.EtcdApi , i.e. v2 or v3 ) - Etcd API version. v2 is deprecated. Other optional properties are inherited from AbstractConfigSourceBuilder . (see javadoc ) <markup lang=\"java\" title=\"Load Config from meta-configuration\" >Config config = Config.loadSourcesFrom(classpath(\"config-meta-etcd.yaml\")); <markup lang=\"YAML\" title=\"Meta-config config-meta-etcd.yaml for the etcd source\" >sources: - type: \"etcd\" properties: uri: \"http://my-etcd:2379\" key: \"/config.yaml\" api: \"v3\" change-watcher: type: \"etcd\" etcd config source type Etcd source-specific (mandatory) properties : uri , key and api . Watcher strategy EtcdWatcher is automatically initialized by specified mandatory properties . git The Helidon git config module supports reading configuration from a git repository. Maven Coordinates Add the following dependency to your project: <markup lang=\"xml\" title=\"Config git Dependency in pom.xml \" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.config&lt;/groupId&gt; &lt;artifactId&gt;helidon-config-git&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"java\" title=\"Config git Dependency in module-info.java \" >module myModule { requires io.helidon.config.git; } Using the git Config Source To read configuration from a git source, your application uses the GitConfigSourceBuilder . <markup lang=\"java\" title=\"Use git config source\" >Config config = Config.create( GitConfigSource .builder() .uri(URI.create(\"https://github.com/okosatka/test-config.git\")) .directory(Paths.get(\"/config\")) .branch(\"dev\")); Use the factory method GitConfigSource.builder to initialize the builder. Specify the git repository URI. Specify a directory where the git repository is already cloned or it will be cloned. Specify the git branch. Note that the config system will use the HOCON parser in this example because the file type is .conf . Recall that for this to work the HOCON config module must be on module-path or classpath. The GitConfigSourceBuilder supports the usual source builder properties because it extends AbstractConfigSourceBuilder . Monitoring for Source Changes Your application can monitor changes to a configuration loaded from a git source associating the regular built-in polling strategy with the source. <markup lang=\"java\" title=\"Use of git config source with polling strategy\" >Config config = Config.create( GitConfigSourceBuilder .create(\"application.conf\") .uri(URI.create(\"https://github.com/okosatka/test-config.git\")) .pollingStrategy(PollingStrategies.regular(Duration.ofMinutes(5)))); Use PollingStrategies.regular(Duration duration) to monitor for config changes. You can also implement your own polling strategy by implementing PollingStrategy . See the mutability support and polling strategy discussions. Loading Meta-configuration via git The config system can load information about config sources from meta-configuration rather than requiring your application to construct the builder. To read meta-configuration from a git config source set the following properties for the source: type to git or class to io.helidon.config.git.GitConfigSourceBuilder path (type String ) - Relative path to the configuration file in repository. uri (type URI ) - URI to the git repository. directory (type Path ) - Directory with a cloned repository, by default a temporary directory. branch (type String ) - git branch (default is master ). The meta-configuration must set the path and one of uri or directory . Other optional properties are inherited from AbstractParsableConfigSource.Builder (see javadoc ) <markup lang=\"java\" title=\"Load Config from meta-configuration\" >Config config = Config.loadSourcesFrom(classpath(\"config-meta-git.yaml\")); <markup lang=\"YAML\" title=\"Meta-config config-meta-git.yaml for the git source\" >sources: - type: \"git\" properties: path: \"application.conf\" uri: \"https://github.com/okosatka/test-config.git\" directory: \"/config\" branch: \"dev\" polling-strategy: type: \"regular\" properties: interval: \"PT5M\" git config source type git source-specific properties: path , uri , directory and branch . Polling strategy regular with an interval, in Duration format, of 5 minutes in this example. ",
            "title": "Additional Config Source Types"
        },
        {
            "location": "/se/cors",
            "text": " Overview Maven Coordinates API Configuration Examples Additional Information ",
            "title": "Contents"
        },
        {
            "location": "/se/cors",
            "text": " Before you revise your application to add CORS support, you need to decide what type of cross-origin sharing you want to allow for each resource your application exposes. For example, suppose for a given resource you want to allow unrestricted sharing for GET, HEAD, and POST requests (what CORS refers to as \"simple\" requests), but permit other types of requests only from the two origins foo.com and there.com . Your application would implement two types of CORS sharing: more relaxed for the simple requests and stricter for others. Once you know the type of sharing you want to allow for each of your resources&#8201;&#8212;&#8201;including any from built-in services&#8201;&#8212;&#8201;you can change your application accordingly. ",
            "title": "Before You Begin"
        },
        {
            "location": "/se/cors",
            "text": " The cross-origin resource sharing (CORS) protocol helps developers control if and how REST resources served by their applications can be shared across origins. Helidon SE includes an implementation of CORS that you can use to add CORS behavior to the services you develop. You can define your application&#8217;s CORS behavior programmatically using the Helidon CORS API alone, or together with configuration. Helidon also provides three built-in services that add their own endpoints to your application&#8201;&#8212;&#8201;health, metrics, and OpenAPI&#8201;&#8212;&#8201;that have integrated CORS support. By adding very little code to your application, you control how all the resources in your application&#8201;&#8212;&#8201;the ones you write and the ones provided by the Helidon built-in services&#8201;&#8212;&#8201;can be shared across origins. Before You Begin Before you revise your application to add CORS support, you need to decide what type of cross-origin sharing you want to allow for each resource your application exposes. For example, suppose for a given resource you want to allow unrestricted sharing for GET, HEAD, and POST requests (what CORS refers to as \"simple\" requests), but permit other types of requests only from the two origins foo.com and there.com . Your application would implement two types of CORS sharing: more relaxed for the simple requests and stricter for others. Once you know the type of sharing you want to allow for each of your resources&#8201;&#8212;&#8201;including any from built-in services&#8201;&#8212;&#8201;you can change your application accordingly. ",
            "title": "Overview"
        },
        {
            "location": "/se/cors",
            "text": " To enable CORS add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webserver&lt;/groupId&gt; &lt;artifactId&gt;helidon-webserver-cors&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/cors",
            "text": " The Helidon SE Quickstart application lets you change the greeting by sending a PUT request to the /greet/greeting resource. This example, based on the QuickStart greeting app, uses the low-level CrossOriginConfig API and the CorsSupport API to influence the routing , thereby determining how that resource is shared. (If desired, you can use configuration instead of the low-level API.) The following code shows one way to prepare your application&#8217;s routing to support CORS. <markup lang=\"java\" >static void routing(HttpRouting.Builder routing) { CorsSupport corsSupport = CorsSupport.builder() .addCrossOrigin(CrossOriginConfig.builder() .allowOrigins(\"http://foo.com\", \"http://there.com\") .allowMethods(\"PUT\", \"DELETE\") .build()) .addCrossOrigin(CrossOriginConfig.create()) .build(); routing.register(\"/greet\", corsSupport, new GreetService()); } Create a CorsSupport.Builder instance. Add a CrossOriginConfig instance (using its builder) to constrain resource sharing. List the origins (sites) allowed to share resources from this app. List the HTTP methods the constraint applies to. Build the CrossOriginConfig instance. Add a CrossOriginConfig instance that permits all sharing (the default). Build the CorsSupport instance. Register the new CorsSupport instance with&#8201;&#8212;&#8201;but in front of&#8201;&#8212;&#8201;the service which implements the business logic. The order of steps 2 and 6 above is important. When processing an incoming request, the Helidon CORS implementation scans the CrossOriginConfig instances in the order they were added to the CorsSupport object, stopping as soon as it finds a CrossOriginConfig instance for which allowMethods matches the HTTP method of the request. By adding the few additional lines described above you allow the greeting application to participate in CORS. ",
            "title": "Sample Routing Setup Using the CrossOriginConfig API"
        },
        {
            "location": "/se/cors",
            "text": " Every Helidon SE application explicitly creates routing rules that govern how Helidon delivers each incoming request to the code that needs to respond. To add CORS behavior to endpoints, you need to make only minimal changes to how you set up the routing for those endpoints. Using the Helidon SE CORS API, you define the CORS behavior that you want and then include that behavior as you build the routing rules for the services in your application. The Helidon SE CORS API provides two key classes that you use in your application: CorsSupport - Represents information about resource sharing for a single resource. Typically, you create one CorsSupport instance for each distinct resource in your application (such as the /greet resource in the QuickStart greeting application) that should participate in CORS. CrossOriginConfig - Represents the details for a particular type of sharing, such as which origins are allowed to have access using which HTTP methods, etc. Create one instance of CrossOriginConfig for each different type of sharing you need. You associate one or more CrossOriginConfig objects with each CorsSupport object. You use the CorsSupport object when you construct the routing rules for the service. When your application is running and requests arrive, the Helidon CORS implementation enforces the CORS behavior represented by the CorsSupport object before routing the request to your endpoint code for the resource. Because Helidon SE does not use annotation processing to identify endpoints, you need to provide the CORS information for your application another way&#8201;&#8212;&#8201;by including CORS into the routing you construct for your application. For each distinct resource or subresource your application exposes: Create a CorsSupport instance corresponding to the resource. For each different type of sharing you want to provide for that resource: Create a CrossOriginConfig instance. The CrossOriginConfig Java class represents the details for a particular type of sharing, such as which origins are allowed to share via which HTTP methods, etc. Add the CrossOriginConfig to the CorsSupport instance for this resource. Use the resource&#8217;s CorsSupport object in setting up the routing rules for that resource. Each of these classes has an associated builder that you use in constructing instances of the class. The table below describes the methods on the CrossOriginConfig.Builder class and the configuration keys that map to the headers defined in the CORS protocol. (A later section discusses configuration .) builder method config key type default description CORS header name allowCredentials allow-credentials boolean false Sets the allow credentials flag. Access-Control-Allow-Credentials allowHeaders allow-headers string[] * Sets the allowed headers. Access-Control-Allow-Headers allowMethods allow-methods string[] * Sets the allowed methods. Access-Control-Allow-Methods allowOrigins allow-origins string[] * Sets the allowed origins. Access-Control-Allow-Origins exposeHeaders expose-headers string[] &#160; Sets the expose headers. Access-Control-Expose-Headers maxAgeSeconds max-age-seconds long 3600 Sets the maximum age. Access-Control-Max-Age enabled enabled boolean true Sets whether this config should be enabled or not. n/a If the cross-origin configuration is disabled ( enabled = false), then the Helidon CORS implementation ignores the cross-origin configuration entry. Sample Routing Setup Using the CrossOriginConfig API The Helidon SE Quickstart application lets you change the greeting by sending a PUT request to the /greet/greeting resource. This example, based on the QuickStart greeting app, uses the low-level CrossOriginConfig API and the CorsSupport API to influence the routing , thereby determining how that resource is shared. (If desired, you can use configuration instead of the low-level API.) The following code shows one way to prepare your application&#8217;s routing to support CORS. <markup lang=\"java\" >static void routing(HttpRouting.Builder routing) { CorsSupport corsSupport = CorsSupport.builder() .addCrossOrigin(CrossOriginConfig.builder() .allowOrigins(\"http://foo.com\", \"http://there.com\") .allowMethods(\"PUT\", \"DELETE\") .build()) .addCrossOrigin(CrossOriginConfig.create()) .build(); routing.register(\"/greet\", corsSupport, new GreetService()); } Create a CorsSupport.Builder instance. Add a CrossOriginConfig instance (using its builder) to constrain resource sharing. List the origins (sites) allowed to share resources from this app. List the HTTP methods the constraint applies to. Build the CrossOriginConfig instance. Add a CrossOriginConfig instance that permits all sharing (the default). Build the CorsSupport instance. Register the new CorsSupport instance with&#8201;&#8212;&#8201;but in front of&#8201;&#8212;&#8201;the service which implements the business logic. The order of steps 2 and 6 above is important. When processing an incoming request, the Helidon CORS implementation scans the CrossOriginConfig instances in the order they were added to the CorsSupport object, stopping as soon as it finds a CrossOriginConfig instance for which allowMethods matches the HTTP method of the request. By adding the few additional lines described above you allow the greeting application to participate in CORS. ",
            "title": "API"
        },
        {
            "location": "/se/cors",
            "text": " Support in Helidon for CORS configuration uses two closely-related cross-origin configuration formats: basic and mapped. Each format corresponds to a class in the Helidon CORS library. The basic format corresponds to the CrossOriginConfig class, and the mapped format corresponds to the MappedCrossOriginConfig class. ",
            "title": "Understanding the CORS Configuration Formats"
        },
        {
            "location": "/se/cors",
            "text": " In configuration, Helidon represents basic CORS information as a section, identified by a configuration key of your choosing, that contains one or more key/value pairs. Each key-value pair assigns one characteristic of CORS behavior. The table below lists the configuration keys that identify the CORS characteristics. include::[tag=cors-config-table] The following example of basic cross-origin configuration, when loaded and used by the application, limits cross-origin resource sharing for PUT and DELETE operations to only foo.com and there.com : <markup lang=\"yaml\" >restrictive-cors: allow-origins: [\"http://foo.com\", \"http://there.com\"] allow-methods: [\"PUT\", \"DELETE\"] ",
            "title": "Basic Cross-Origin Configuration"
        },
        {
            "location": "/se/cors",
            "text": " In some cases, you or your users might want to configure CORS behavior based on URL path matching. Helidon represents mapped CORS information as a section, identified by a configuration key of your choosing, that contains: An optional enabled setting which defaults to true and applies to the whole mapped CORS config section, and An optional paths subsection containing zero or more entries, each of which contains: a basic CORS config section, and a path-pattern path pattern that maps that basic CORS config section to the resource(s) it affects. You can use mapped configuration to your advantage if you want to allow your users to override the CORS behavior set up in the application code. The following example illustrates the mapped cross-origin configuration format. <markup lang=\"hocon\" >my-cors: paths: - path-pattern: /greeting allow-origins: [\"http://foo.com\", \"http://there.com\", \"http://other.com\"] allow-methods: [\"PUT\", \"DELETE\"] - path-pattern: / allow-methods: [\"GET\", \"HEAD\", \"OPTIONS\", \"POST\"] Assigns a unique identifier for this mapped CORS config section. Collects the sequence of entries, each of which maps a basic CORS config to a path pattern. Marks the beginning of an entry (the - character) and maps the associated basic CORS config to the /greeting subresource (the path-pattern key and value). Begins the basic CORS config section for /greeting ; it restricts sharing via PUT and DELETE to the listed origins. Marks the beginning of the next entry (the - character) and maps the associated basic CORS config to the top-level resource in the app (the path-pattern key and value). Begins the basic CORS config section for / ; it permits sharing of resources at the top-level path with all origins for the indicated HTTP methods. Path patterns can be any expression accepted by the PathMatcher class. Be sure to arrange the entries in the order that you want Helidon to check them. Helidon CORS support searches the cross-origin entries in the order you define them until it finds an entry that matches an incoming request&#8217;s path pattern and HTTP method. ",
            "title": "Mapped Cross-Origin Configuration"
        },
        {
            "location": "/se/cors",
            "text": " You use configuration in combination with the Helidon CORS SE API to add CORS support to your resources. The example in Sample Routing Setup Using the CrossOriginConfig API uses the low-level Helidon CORS SE API to create a CrossOriginConfig instance that is then used as part of a CorsSupport instance to create the routing rules. As an alternative to using the low-level API, this example uses config to create the CrossOriginConfig instance instead. <markup lang=\"java\" >static void routing(HttpRouting.Builder routing) { CorsSupport.Builder builder = CorsSupport.builder(); Config config = Config.global(); config.get(\"my-cors\") .ifExists(builder::mappedConfig); config.get(\"restrictive-cors\") .ifExists(builder::config); builder.addCrossOrigin(CrossOriginConfig.create()); CorsSupport corsSupport = builder.build(); // Note: Add the CORS routing *before* registering the GreetService routing. return Routing.builder() .register(\"/greet\", corsSupport, new GreetService()) .build(); } If my-cors exists in the configuration, use it to add mapped CORS config to the CorsSupport builder. If restrictive-cors exists in the configuration, use it to add basic (not mapped) config to the builder. Provide default CORS handling for requests that do not match earlier entries. Obtain the finished CorsSupport instance. Use corsSupport in constructing the routing rules. As each request arrives, Helidon checks it against the cross-origin config instances in the order that your application added them to the CorsSupport.Builder . The my-cors mapped configuration acts as an override because the application added it to the builder first. If the my-cors config key does not appear in the configuration, then the code skips creating a CrossOriginConfig instance based on that configuration, and no overriding occurs. The CORS behavior that is established by the other CrossOriginConfig instance based on the restrictive-cors config (if present) prevails. Remember that if you set configuration in a file that you include as part of your application JAR file, then you need to rebuild and restart your application for any changes to take effect. ",
            "title": "Using CORS Configuration in the Application"
        },
        {
            "location": "/se/cors",
            "text": " You can use configuration in combination with the Helidon CORS SE API to add CORS support to your resources by replacing some Java code with declarative configuration. This also gives your users a way to override the CORS behavior of your services without requiring the code to change. Understanding the CORS Configuration Formats Support in Helidon for CORS configuration uses two closely-related cross-origin configuration formats: basic and mapped. Each format corresponds to a class in the Helidon CORS library. The basic format corresponds to the CrossOriginConfig class, and the mapped format corresponds to the MappedCrossOriginConfig class. Basic Cross-Origin Configuration In configuration, Helidon represents basic CORS information as a section, identified by a configuration key of your choosing, that contains one or more key/value pairs. Each key-value pair assigns one characteristic of CORS behavior. The table below lists the configuration keys that identify the CORS characteristics. include::[tag=cors-config-table] The following example of basic cross-origin configuration, when loaded and used by the application, limits cross-origin resource sharing for PUT and DELETE operations to only foo.com and there.com : <markup lang=\"yaml\" >restrictive-cors: allow-origins: [\"http://foo.com\", \"http://there.com\"] allow-methods: [\"PUT\", \"DELETE\"] Mapped Cross-Origin Configuration In some cases, you or your users might want to configure CORS behavior based on URL path matching. Helidon represents mapped CORS information as a section, identified by a configuration key of your choosing, that contains: An optional enabled setting which defaults to true and applies to the whole mapped CORS config section, and An optional paths subsection containing zero or more entries, each of which contains: a basic CORS config section, and a path-pattern path pattern that maps that basic CORS config section to the resource(s) it affects. You can use mapped configuration to your advantage if you want to allow your users to override the CORS behavior set up in the application code. The following example illustrates the mapped cross-origin configuration format. <markup lang=\"hocon\" >my-cors: paths: - path-pattern: /greeting allow-origins: [\"http://foo.com\", \"http://there.com\", \"http://other.com\"] allow-methods: [\"PUT\", \"DELETE\"] - path-pattern: / allow-methods: [\"GET\", \"HEAD\", \"OPTIONS\", \"POST\"] Assigns a unique identifier for this mapped CORS config section. Collects the sequence of entries, each of which maps a basic CORS config to a path pattern. Marks the beginning of an entry (the - character) and maps the associated basic CORS config to the /greeting subresource (the path-pattern key and value). Begins the basic CORS config section for /greeting ; it restricts sharing via PUT and DELETE to the listed origins. Marks the beginning of the next entry (the - character) and maps the associated basic CORS config to the top-level resource in the app (the path-pattern key and value). Begins the basic CORS config section for / ; it permits sharing of resources at the top-level path with all origins for the indicated HTTP methods. Path patterns can be any expression accepted by the PathMatcher class. Be sure to arrange the entries in the order that you want Helidon to check them. Helidon CORS support searches the cross-origin entries in the order you define them until it finds an entry that matches an incoming request&#8217;s path pattern and HTTP method. Using CORS Configuration in the Application You use configuration in combination with the Helidon CORS SE API to add CORS support to your resources. The example in Sample Routing Setup Using the CrossOriginConfig API uses the low-level Helidon CORS SE API to create a CrossOriginConfig instance that is then used as part of a CorsSupport instance to create the routing rules. As an alternative to using the low-level API, this example uses config to create the CrossOriginConfig instance instead. <markup lang=\"java\" >static void routing(HttpRouting.Builder routing) { CorsSupport.Builder builder = CorsSupport.builder(); Config config = Config.global(); config.get(\"my-cors\") .ifExists(builder::mappedConfig); config.get(\"restrictive-cors\") .ifExists(builder::config); builder.addCrossOrigin(CrossOriginConfig.create()); CorsSupport corsSupport = builder.build(); // Note: Add the CORS routing *before* registering the GreetService routing. return Routing.builder() .register(\"/greet\", corsSupport, new GreetService()) .build(); } If my-cors exists in the configuration, use it to add mapped CORS config to the CorsSupport builder. If restrictive-cors exists in the configuration, use it to add basic (not mapped) config to the builder. Provide default CORS handling for requests that do not match earlier entries. Obtain the finished CorsSupport instance. Use corsSupport in constructing the routing rules. As each request arrives, Helidon checks it against the cross-origin config instances in the order that your application added them to the CorsSupport.Builder . The my-cors mapped configuration acts as an override because the application added it to the builder first. If the my-cors config key does not appear in the configuration, then the code skips creating a CrossOriginConfig instance based on that configuration, and no overriding occurs. The CORS behavior that is established by the other CrossOriginConfig instance based on the restrictive-cors config (if present) prevails. Remember that if you set configuration in a file that you include as part of your application JAR file, then you need to rebuild and restart your application for any changes to take effect. ",
            "title": "Configuration"
        },
        {
            "location": "/se/cors",
            "text": " For a complete example, see Helidon SE CORS Example . ",
            "title": "Examples"
        },
        {
            "location": "/se/cors",
            "text": " The decisions the Helidon CORS feature makes depend on accurate information about each incoming request, particularly the host to which the request is sent. Conveyed as headers in the request, this information can be changed or overwritten by intermediate nodes&#8212;&#8203;such as load balancers&#8212;&#8203;between the origin of the request and your service. Well-behaved intermediate nodes preserve this important data in other headers, such as Forwarded . You can configure how the Helidon server handles these headers as described in the documentation for requested URI discovery . The CORS support in Helidon uses the requested URI feature to discover the correct information about each request, according to your configuration, so it can make accurate decisions about whether to permit cross-origin accesses. ",
            "title": "CORS and the Requested URI Feature"
        },
        {
            "location": "/se/cors",
            "text": " To use built-in services with CORS support and customize the CORS behavior: Add the built-in service or services to your application. The health, metrics, and OpenAPI services automatically include default CORS support. Add a dependency on the Helidon SE CORS artifact to your Maven pom.xml file. If you want the built-in services to support CORS, then you need to add the CORS dependency even if your own endpoints do not use CORS. Use the Helidon API or configuration to customize the CORS behavior as needed. The documentation for the individual built-in services describes how to add each service to your application, including adding a Maven dependency and including the service in your application&#8217;s routing rules. In your application&#8217;s configuration file, the configuration for each service appears under its own key. Helidon Service Documentation Configuration Key health health metrics metrics OpenAPI openapi The Helidon SE QuickStart example uses these services, so you can use that as a template for your own application, or use the example project itself to experiment with customizing the CORS behavior in the built-in services. ",
            "title": "Built-in Services with CORS"
        },
        {
            "location": "/se/cors",
            "text": " You can also use configuration to control whether and how each of the built-in services works with CORS. Your application can pass configuration to the builder for each built-in service. In the configuration for the health, metrics, and OpenAPI services, you can add a section for CORS. The following example restricts sharing of the /health resource, provided by the health built-in service, to only the origin http://there.com . <markup lang=\"hocon\" >health: cors: allow-origins: [http://there.com] Modify your application to load the health config node and use it to construct the HealthSupport service. The following code shows this change in the the QuickStart SE example. <markup lang=\"java\" >HealthSupport health = HealthSupport.builder() .config(config.get(\"health\")) .add(HealthChecks.healthChecks()) // Adds a convenient set of checks .build(); Use the health config section (if present) to configure the health service. You have full control over the CORS configuration for a built-in Helidon service. Use a CORS config section as described in Using Configuration for CORS . ",
            "title": "Configuring CORS for Built-in Services"
        },
        {
            "location": "/se/cors",
            "text": " Although services such as health, metrics, and OpenAPI are built into Helidon, to use them your application must create instances of the services and then use those instances in building your application&#8217;s routing rules. Recall that each service type has a Builder class. To control the CORS behavior of a built-in service using the API, follow these steps: Create a Builder for the type of service of interest. Build an instance of CrossOriginConfig with the settings you want. Invoke the builder.crossOriginConfig method, passing that CrossOriginConfig instance. Invoke the builder&#8217;s build method to initialize the service instance. Use the service instance in preparing the routing rules. The following excerpt shows changes to the Helidon SE QuickStart example which limit sharing of the /metrics endpoint to http://foo.com . <markup lang=\"java\" >private static Routing createRouting(Config config) { CrossOriginConfig.Builder metricsCrossOriginConfigBuilder = CrossOriginConfig.builder() .allowOrigins(\"http://foo.com\"); RestServiceSettings.Builder restServiceSettingsBuilder = RestServiceSettings.builder() .crossOriginConfig(metricsCrossOriginConfigBuilder); MetricsSupport metrics = MetricsSupport.builder() .restServiceSettings(restServiceSettingsBuilder) .build(); GreetService greetService = new GreetService(config); HealthSupport health = HealthSupport.builder() .addLiveness(HealthChecks.healthChecks()) // Adds a convenient set of checks .build(); return Routing.builder() .register(health) // Health at \"/health\" .register(metrics) // Metrics at \"/metrics\" .register(\"/greet\", greetService) .build(); } Create the CrossOriginConfig.Builder for metrics, limiting sharing to http://foo.com . Use the CrossOriginConfig.Builder instance in constructing the RestServiceSetting.Builder (which assigns common settings such as the CORS configuration and the web context for the service endpoint). Use the RestServiceSetting.Builder in preparing the MetricsSupport service. Use the MetricsSupport object in creating the routing rules. Configuring CORS for Built-in Services You can also use configuration to control whether and how each of the built-in services works with CORS. Your application can pass configuration to the builder for each built-in service. In the configuration for the health, metrics, and OpenAPI services, you can add a section for CORS. The following example restricts sharing of the /health resource, provided by the health built-in service, to only the origin http://there.com . <markup lang=\"hocon\" >health: cors: allow-origins: [http://there.com] Modify your application to load the health config node and use it to construct the HealthSupport service. The following code shows this change in the the QuickStart SE example. <markup lang=\"java\" >HealthSupport health = HealthSupport.builder() .config(config.get(\"health\")) .add(HealthChecks.healthChecks()) // Adds a convenient set of checks .build(); Use the health config section (if present) to configure the health service. You have full control over the CORS configuration for a built-in Helidon service. Use a CORS config section as described in Using Configuration for CORS . ",
            "title": "Using the API"
        },
        {
            "location": "/se/cors",
            "text": " Using the API Although services such as health, metrics, and OpenAPI are built into Helidon, to use them your application must create instances of the services and then use those instances in building your application&#8217;s routing rules. Recall that each service type has a Builder class. To control the CORS behavior of a built-in service using the API, follow these steps: Create a Builder for the type of service of interest. Build an instance of CrossOriginConfig with the settings you want. Invoke the builder.crossOriginConfig method, passing that CrossOriginConfig instance. Invoke the builder&#8217;s build method to initialize the service instance. Use the service instance in preparing the routing rules. The following excerpt shows changes to the Helidon SE QuickStart example which limit sharing of the /metrics endpoint to http://foo.com . <markup lang=\"java\" >private static Routing createRouting(Config config) { CrossOriginConfig.Builder metricsCrossOriginConfigBuilder = CrossOriginConfig.builder() .allowOrigins(\"http://foo.com\"); RestServiceSettings.Builder restServiceSettingsBuilder = RestServiceSettings.builder() .crossOriginConfig(metricsCrossOriginConfigBuilder); MetricsSupport metrics = MetricsSupport.builder() .restServiceSettings(restServiceSettingsBuilder) .build(); GreetService greetService = new GreetService(config); HealthSupport health = HealthSupport.builder() .addLiveness(HealthChecks.healthChecks()) // Adds a convenient set of checks .build(); return Routing.builder() .register(health) // Health at \"/health\" .register(metrics) // Metrics at \"/metrics\" .register(\"/greet\", greetService) .build(); } Create the CrossOriginConfig.Builder for metrics, limiting sharing to http://foo.com . Use the CrossOriginConfig.Builder instance in constructing the RestServiceSetting.Builder (which assigns common settings such as the CORS configuration and the web context for the service endpoint). Use the RestServiceSetting.Builder in preparing the MetricsSupport service. Use the MetricsSupport object in creating the routing rules. Configuring CORS for Built-in Services You can also use configuration to control whether and how each of the built-in services works with CORS. Your application can pass configuration to the builder for each built-in service. In the configuration for the health, metrics, and OpenAPI services, you can add a section for CORS. The following example restricts sharing of the /health resource, provided by the health built-in service, to only the origin http://there.com . <markup lang=\"hocon\" >health: cors: allow-origins: [http://there.com] Modify your application to load the health config node and use it to construct the HealthSupport service. The following code shows this change in the the QuickStart SE example. <markup lang=\"java\" >HealthSupport health = HealthSupport.builder() .config(config.get(\"health\")) .add(HealthChecks.healthChecks()) // Adds a convenient set of checks .build(); Use the health config section (if present) to configure the health service. You have full control over the CORS configuration for a built-in Helidon service. Use a CORS config section as described in Using Configuration for CORS . ",
            "title": "Controlling CORS for Built-in Services"
        },
        {
            "location": "/se/cors",
            "text": " Build and run the QuickStart application as usual. <markup lang=\"bash\" >mvn package java -jar target/helidon-quickstart-se.jar <markup lang=\"listing\" >WEB server is up! http://localhost:8080/greet ",
            "title": "Build and Run the Application"
        },
        {
            "location": "/se/cors",
            "text": " The metrics service rejects attempts to access metrics on behalf of a disallowed origin. <markup lang=\"bash\" >curl -i -H \"Origin: http://other.com\" http://localhost:8080/metrics <markup lang=\"listing\" >HTTP/1.1 403 Forbidden Date: Mon, 11 May 2020 11:08:09 -0500 transfer-encoding: chunked connection: keep-alive But accesses from foo.com succeed. <markup lang=\"bash\" >curl -i -H \"Origin: http://foo.com\" http://localhost:8080/metrics <markup lang=\"listing\" >HTTP/1.1 200 OK Access-Control-Allow-Origin: http://foo.com Content-Type: text/plain Date: Mon, 11 May 2020 11:08:16 -0500 Vary: Origin connection: keep-alive content-length: 6065 # TYPE base_classloader_loadedClasses_count gauge # HELP base_classloader_loadedClasses_count Displays the number of classes that are currently loaded in the Java virtual machine. base_classloader_loadedClasses_count 3568 ",
            "title": "Retrieve Metrics"
        },
        {
            "location": "/se/cors",
            "text": " The health service rejects requests from origins not specifically approved. <markup lang=\"bash\" >curl -i -H \"Origin: http://foo.com\" http://localhost:8080/health <markup lang=\"listing\" >HTTP/1.1 403 Forbidden Date: Mon, 11 May 2020 12:06:55 -0500 transfer-encoding: chunked connection: keep-alive And responds successfully only to cross-origin requests from http://there.com . <markup lang=\"bash\" >curl -i -H \"Origin: http://there.com\" http://localhost:8080/health <markup lang=\"listing\" >HTTP/1.1 200 OK Access-Control-Allow-Origin: http://there.com Content-Type: application/json Date: Mon, 11 May 2020 12:07:32 -0500 Vary: Origin connection: keep-alive content-length: 461 {\"outcome\":\"UP\",...} ",
            "title": "Retrieve Health"
        },
        {
            "location": "/se/cors",
            "text": " If you have edited the Helidon SE QuickStart application as described in the previous topics and saved your changes, you can build and run the application. Once you do so you can execute curl commands to demonstrate the behavior changes in the metric and health services with the addition of the CORS functionality. Note the addition of the Origin header value in the curl commands, and the Access-Control-Allow-Origin in the successful responses. Build and Run the Application Build and run the QuickStart application as usual. <markup lang=\"bash\" >mvn package java -jar target/helidon-quickstart-se.jar <markup lang=\"listing\" >WEB server is up! http://localhost:8080/greet Retrieve Metrics The metrics service rejects attempts to access metrics on behalf of a disallowed origin. <markup lang=\"bash\" >curl -i -H \"Origin: http://other.com\" http://localhost:8080/metrics <markup lang=\"listing\" >HTTP/1.1 403 Forbidden Date: Mon, 11 May 2020 11:08:09 -0500 transfer-encoding: chunked connection: keep-alive But accesses from foo.com succeed. <markup lang=\"bash\" >curl -i -H \"Origin: http://foo.com\" http://localhost:8080/metrics <markup lang=\"listing\" >HTTP/1.1 200 OK Access-Control-Allow-Origin: http://foo.com Content-Type: text/plain Date: Mon, 11 May 2020 11:08:16 -0500 Vary: Origin connection: keep-alive content-length: 6065 # TYPE base_classloader_loadedClasses_count gauge # HELP base_classloader_loadedClasses_count Displays the number of classes that are currently loaded in the Java virtual machine. base_classloader_loadedClasses_count 3568 Retrieve Health The health service rejects requests from origins not specifically approved. <markup lang=\"bash\" >curl -i -H \"Origin: http://foo.com\" http://localhost:8080/health <markup lang=\"listing\" >HTTP/1.1 403 Forbidden Date: Mon, 11 May 2020 12:06:55 -0500 transfer-encoding: chunked connection: keep-alive And responds successfully only to cross-origin requests from http://there.com . <markup lang=\"bash\" >curl -i -H \"Origin: http://there.com\" http://localhost:8080/health <markup lang=\"listing\" >HTTP/1.1 200 OK Access-Control-Allow-Origin: http://there.com Content-Type: application/json Date: Mon, 11 May 2020 12:07:32 -0500 Vary: Origin connection: keep-alive content-length: 461 {\"outcome\":\"UP\",...} ",
            "title": "Accessing the Shared Resources"
        },
        {
            "location": "/se/cors",
            "text": " Several built-in Helidon services&#8212;&#8203; health , metrics , and OpenAPI --have integrated CORS support. You can include these services in your application and control how those resources can be shared across origins. For example, several websites related to OpenAPI run a web application in your browser. You provide the URL for your application to the browser application. The browser application uses the URL to retrieve the OpenAPI document that describes the application&#8217;s endpoints directly from your application. The browser application then displays a user interface that you use to \"drive\" your application. That is, you provide input, have the web application send requests to your application endpoints, and then view the responses. This scenario is exactly the situation CORS addresses: an application in the browser from one origin&#8201;&#8212;&#8201;the user interface downloaded from the website&#8201;&#8212;&#8201;requests a resource from another origin&#8201;&#8212;&#8201;the /openapi endpoint which Helidon&#8217;s OpenAPI built-in service automatically adds to your application. Integrating CORS support into these built-in services allows such third-party web sites and their browser applications&#8201;&#8212;&#8201;or more generally, apps from any other origin&#8201;&#8212;&#8201;to work with your Helidon application. Because all three of these built-in Helidon services serve only GET endpoints, by default the integrated CORS support in all three services permits any origin to share their resources using GET , HEAD , and OPTIONS HTTP requests. You can customize the CORS set-up for these built-in services independently from each other using either the Helidon API, configuration, or both. You can use this override feature to control the CORS behavior of the built-in services even if you do not add CORS behavior to your own endpoints. Built-in Services with CORS To use built-in services with CORS support and customize the CORS behavior: Add the built-in service or services to your application. The health, metrics, and OpenAPI services automatically include default CORS support. Add a dependency on the Helidon SE CORS artifact to your Maven pom.xml file. If you want the built-in services to support CORS, then you need to add the CORS dependency even if your own endpoints do not use CORS. Use the Helidon API or configuration to customize the CORS behavior as needed. The documentation for the individual built-in services describes how to add each service to your application, including adding a Maven dependency and including the service in your application&#8217;s routing rules. In your application&#8217;s configuration file, the configuration for each service appears under its own key. Helidon Service Documentation Configuration Key health health metrics metrics OpenAPI openapi The Helidon SE QuickStart example uses these services, so you can use that as a template for your own application, or use the example project itself to experiment with customizing the CORS behavior in the built-in services. Controlling CORS for Built-in Services Using the API Although services such as health, metrics, and OpenAPI are built into Helidon, to use them your application must create instances of the services and then use those instances in building your application&#8217;s routing rules. Recall that each service type has a Builder class. To control the CORS behavior of a built-in service using the API, follow these steps: Create a Builder for the type of service of interest. Build an instance of CrossOriginConfig with the settings you want. Invoke the builder.crossOriginConfig method, passing that CrossOriginConfig instance. Invoke the builder&#8217;s build method to initialize the service instance. Use the service instance in preparing the routing rules. The following excerpt shows changes to the Helidon SE QuickStart example which limit sharing of the /metrics endpoint to http://foo.com . <markup lang=\"java\" >private static Routing createRouting(Config config) { CrossOriginConfig.Builder metricsCrossOriginConfigBuilder = CrossOriginConfig.builder() .allowOrigins(\"http://foo.com\"); RestServiceSettings.Builder restServiceSettingsBuilder = RestServiceSettings.builder() .crossOriginConfig(metricsCrossOriginConfigBuilder); MetricsSupport metrics = MetricsSupport.builder() .restServiceSettings(restServiceSettingsBuilder) .build(); GreetService greetService = new GreetService(config); HealthSupport health = HealthSupport.builder() .addLiveness(HealthChecks.healthChecks()) // Adds a convenient set of checks .build(); return Routing.builder() .register(health) // Health at \"/health\" .register(metrics) // Metrics at \"/metrics\" .register(\"/greet\", greetService) .build(); } Create the CrossOriginConfig.Builder for metrics, limiting sharing to http://foo.com . Use the CrossOriginConfig.Builder instance in constructing the RestServiceSetting.Builder (which assigns common settings such as the CORS configuration and the web context for the service endpoint). Use the RestServiceSetting.Builder in preparing the MetricsSupport service. Use the MetricsSupport object in creating the routing rules. Configuring CORS for Built-in Services You can also use configuration to control whether and how each of the built-in services works with CORS. Your application can pass configuration to the builder for each built-in service. In the configuration for the health, metrics, and OpenAPI services, you can add a section for CORS. The following example restricts sharing of the /health resource, provided by the health built-in service, to only the origin http://there.com . <markup lang=\"hocon\" >health: cors: allow-origins: [http://there.com] Modify your application to load the health config node and use it to construct the HealthSupport service. The following code shows this change in the the QuickStart SE example. <markup lang=\"java\" >HealthSupport health = HealthSupport.builder() .config(config.get(\"health\")) .add(HealthChecks.healthChecks()) // Adds a convenient set of checks .build(); Use the health config section (if present) to configure the health service. You have full control over the CORS configuration for a built-in Helidon service. Use a CORS config section as described in Using Configuration for CORS . Accessing the Shared Resources If you have edited the Helidon SE QuickStart application as described in the previous topics and saved your changes, you can build and run the application. Once you do so you can execute curl commands to demonstrate the behavior changes in the metric and health services with the addition of the CORS functionality. Note the addition of the Origin header value in the curl commands, and the Access-Control-Allow-Origin in the successful responses. Build and Run the Application Build and run the QuickStart application as usual. <markup lang=\"bash\" >mvn package java -jar target/helidon-quickstart-se.jar <markup lang=\"listing\" >WEB server is up! http://localhost:8080/greet Retrieve Metrics The metrics service rejects attempts to access metrics on behalf of a disallowed origin. <markup lang=\"bash\" >curl -i -H \"Origin: http://other.com\" http://localhost:8080/metrics <markup lang=\"listing\" >HTTP/1.1 403 Forbidden Date: Mon, 11 May 2020 11:08:09 -0500 transfer-encoding: chunked connection: keep-alive But accesses from foo.com succeed. <markup lang=\"bash\" >curl -i -H \"Origin: http://foo.com\" http://localhost:8080/metrics <markup lang=\"listing\" >HTTP/1.1 200 OK Access-Control-Allow-Origin: http://foo.com Content-Type: text/plain Date: Mon, 11 May 2020 11:08:16 -0500 Vary: Origin connection: keep-alive content-length: 6065 # TYPE base_classloader_loadedClasses_count gauge # HELP base_classloader_loadedClasses_count Displays the number of classes that are currently loaded in the Java virtual machine. base_classloader_loadedClasses_count 3568 Retrieve Health The health service rejects requests from origins not specifically approved. <markup lang=\"bash\" >curl -i -H \"Origin: http://foo.com\" http://localhost:8080/health <markup lang=\"listing\" >HTTP/1.1 403 Forbidden Date: Mon, 11 May 2020 12:06:55 -0500 transfer-encoding: chunked connection: keep-alive And responds successfully only to cross-origin requests from http://there.com . <markup lang=\"bash\" >curl -i -H \"Origin: http://there.com\" http://localhost:8080/health <markup lang=\"listing\" >HTTP/1.1 200 OK Access-Control-Allow-Origin: http://there.com Content-Type: application/json Date: Mon, 11 May 2020 12:07:32 -0500 Vary: Origin connection: keep-alive content-length: 461 {\"outcome\":\"UP\",...} ",
            "title": "Using CORS Support in Built-in Helidon Services"
        },
        {
            "location": "/se/cors",
            "text": " CORS and the Requested URI Feature The decisions the Helidon CORS feature makes depend on accurate information about each incoming request, particularly the host to which the request is sent. Conveyed as headers in the request, this information can be changed or overwritten by intermediate nodes&#8212;&#8203;such as load balancers&#8212;&#8203;between the origin of the request and your service. Well-behaved intermediate nodes preserve this important data in other headers, such as Forwarded . You can configure how the Helidon server handles these headers as described in the documentation for requested URI discovery . The CORS support in Helidon uses the requested URI feature to discover the correct information about each request, according to your configuration, so it can make accurate decisions about whether to permit cross-origin accesses. Using CORS Support in Built-in Helidon Services Several built-in Helidon services&#8212;&#8203; health , metrics , and OpenAPI --have integrated CORS support. You can include these services in your application and control how those resources can be shared across origins. For example, several websites related to OpenAPI run a web application in your browser. You provide the URL for your application to the browser application. The browser application uses the URL to retrieve the OpenAPI document that describes the application&#8217;s endpoints directly from your application. The browser application then displays a user interface that you use to \"drive\" your application. That is, you provide input, have the web application send requests to your application endpoints, and then view the responses. This scenario is exactly the situation CORS addresses: an application in the browser from one origin&#8201;&#8212;&#8201;the user interface downloaded from the website&#8201;&#8212;&#8201;requests a resource from another origin&#8201;&#8212;&#8201;the /openapi endpoint which Helidon&#8217;s OpenAPI built-in service automatically adds to your application. Integrating CORS support into these built-in services allows such third-party web sites and their browser applications&#8201;&#8212;&#8201;or more generally, apps from any other origin&#8201;&#8212;&#8201;to work with your Helidon application. Because all three of these built-in Helidon services serve only GET endpoints, by default the integrated CORS support in all three services permits any origin to share their resources using GET , HEAD , and OPTIONS HTTP requests. You can customize the CORS set-up for these built-in services independently from each other using either the Helidon API, configuration, or both. You can use this override feature to control the CORS behavior of the built-in services even if you do not add CORS behavior to your own endpoints. Built-in Services with CORS To use built-in services with CORS support and customize the CORS behavior: Add the built-in service or services to your application. The health, metrics, and OpenAPI services automatically include default CORS support. Add a dependency on the Helidon SE CORS artifact to your Maven pom.xml file. If you want the built-in services to support CORS, then you need to add the CORS dependency even if your own endpoints do not use CORS. Use the Helidon API or configuration to customize the CORS behavior as needed. The documentation for the individual built-in services describes how to add each service to your application, including adding a Maven dependency and including the service in your application&#8217;s routing rules. In your application&#8217;s configuration file, the configuration for each service appears under its own key. Helidon Service Documentation Configuration Key health health metrics metrics OpenAPI openapi The Helidon SE QuickStart example uses these services, so you can use that as a template for your own application, or use the example project itself to experiment with customizing the CORS behavior in the built-in services. Controlling CORS for Built-in Services Using the API Although services such as health, metrics, and OpenAPI are built into Helidon, to use them your application must create instances of the services and then use those instances in building your application&#8217;s routing rules. Recall that each service type has a Builder class. To control the CORS behavior of a built-in service using the API, follow these steps: Create a Builder for the type of service of interest. Build an instance of CrossOriginConfig with the settings you want. Invoke the builder.crossOriginConfig method, passing that CrossOriginConfig instance. Invoke the builder&#8217;s build method to initialize the service instance. Use the service instance in preparing the routing rules. The following excerpt shows changes to the Helidon SE QuickStart example which limit sharing of the /metrics endpoint to http://foo.com . <markup lang=\"java\" >private static Routing createRouting(Config config) { CrossOriginConfig.Builder metricsCrossOriginConfigBuilder = CrossOriginConfig.builder() .allowOrigins(\"http://foo.com\"); RestServiceSettings.Builder restServiceSettingsBuilder = RestServiceSettings.builder() .crossOriginConfig(metricsCrossOriginConfigBuilder); MetricsSupport metrics = MetricsSupport.builder() .restServiceSettings(restServiceSettingsBuilder) .build(); GreetService greetService = new GreetService(config); HealthSupport health = HealthSupport.builder() .addLiveness(HealthChecks.healthChecks()) // Adds a convenient set of checks .build(); return Routing.builder() .register(health) // Health at \"/health\" .register(metrics) // Metrics at \"/metrics\" .register(\"/greet\", greetService) .build(); } Create the CrossOriginConfig.Builder for metrics, limiting sharing to http://foo.com . Use the CrossOriginConfig.Builder instance in constructing the RestServiceSetting.Builder (which assigns common settings such as the CORS configuration and the web context for the service endpoint). Use the RestServiceSetting.Builder in preparing the MetricsSupport service. Use the MetricsSupport object in creating the routing rules. Configuring CORS for Built-in Services You can also use configuration to control whether and how each of the built-in services works with CORS. Your application can pass configuration to the builder for each built-in service. In the configuration for the health, metrics, and OpenAPI services, you can add a section for CORS. The following example restricts sharing of the /health resource, provided by the health built-in service, to only the origin http://there.com . <markup lang=\"hocon\" >health: cors: allow-origins: [http://there.com] Modify your application to load the health config node and use it to construct the HealthSupport service. The following code shows this change in the the QuickStart SE example. <markup lang=\"java\" >HealthSupport health = HealthSupport.builder() .config(config.get(\"health\")) .add(HealthChecks.healthChecks()) // Adds a convenient set of checks .build(); Use the health config section (if present) to configure the health service. You have full control over the CORS configuration for a built-in Helidon service. Use a CORS config section as described in Using Configuration for CORS . Accessing the Shared Resources If you have edited the Helidon SE QuickStart application as described in the previous topics and saved your changes, you can build and run the application. Once you do so you can execute curl commands to demonstrate the behavior changes in the metric and health services with the addition of the CORS functionality. Note the addition of the Origin header value in the curl commands, and the Access-Control-Allow-Origin in the successful responses. Build and Run the Application Build and run the QuickStart application as usual. <markup lang=\"bash\" >mvn package java -jar target/helidon-quickstart-se.jar <markup lang=\"listing\" >WEB server is up! http://localhost:8080/greet Retrieve Metrics The metrics service rejects attempts to access metrics on behalf of a disallowed origin. <markup lang=\"bash\" >curl -i -H \"Origin: http://other.com\" http://localhost:8080/metrics <markup lang=\"listing\" >HTTP/1.1 403 Forbidden Date: Mon, 11 May 2020 11:08:09 -0500 transfer-encoding: chunked connection: keep-alive But accesses from foo.com succeed. <markup lang=\"bash\" >curl -i -H \"Origin: http://foo.com\" http://localhost:8080/metrics <markup lang=\"listing\" >HTTP/1.1 200 OK Access-Control-Allow-Origin: http://foo.com Content-Type: text/plain Date: Mon, 11 May 2020 11:08:16 -0500 Vary: Origin connection: keep-alive content-length: 6065 # TYPE base_classloader_loadedClasses_count gauge # HELP base_classloader_loadedClasses_count Displays the number of classes that are currently loaded in the Java virtual machine. base_classloader_loadedClasses_count 3568 Retrieve Health The health service rejects requests from origins not specifically approved. <markup lang=\"bash\" >curl -i -H \"Origin: http://foo.com\" http://localhost:8080/health <markup lang=\"listing\" >HTTP/1.1 403 Forbidden Date: Mon, 11 May 2020 12:06:55 -0500 transfer-encoding: chunked connection: keep-alive And responds successfully only to cross-origin requests from http://there.com . <markup lang=\"bash\" >curl -i -H \"Origin: http://there.com\" http://localhost:8080/health <markup lang=\"listing\" >HTTP/1.1 200 OK Access-Control-Allow-Origin: http://there.com Content-Type: application/json Date: Mon, 11 May 2020 12:07:32 -0500 Vary: Origin connection: keep-alive content-length: 461 {\"outcome\":\"UP\",...} ",
            "title": "Additional Information"
        },
        {
            "location": "/se/dbclient",
            "text": " Overview Maven Coordinates Usage API Configuration Additional Information ",
            "title": "Contents"
        },
        {
            "location": "/se/dbclient",
            "text": " The Helidon SE DB Client provides a unified API for working with databases. ",
            "title": "Overview"
        },
        {
            "location": "/se/dbclient",
            "text": " To enable DB Client add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.dbclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-dbclient&lt;/artifactId&gt; &lt;/dependency&gt; To use with a JDBC client also add the following dependency: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.dbclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-dbclient-jdbc&lt;/artifactId&gt; &lt;/dependency&gt; Or to use with MongoDB client add the following dependency: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.dbclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-dbclient-mongodb&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/dbclient",
            "text": " The DB Client simplifies how you work with databases by abstracting the type of the database. The API can be used both for relational and non-relational databases. ",
            "title": "Usage"
        },
        {
            "location": "/se/dbclient",
            "text": " Database configuration abstraction Using Helidon configuration allows database implementation specific configuration options without the need to use database implementation specific APIs. This allows for seamless switching between databases based on configuration. Statement configuration abstraction Using Helidon configuration allows use of database specific statements. This allows usage of different databases on different environments without changing code. Unified API for data access and query Thanks to the statement configuration abstraction, we can invoke a statement against a relational or non-relations databases (such as MySQL and MongoDB) without modifying source code Observability The API offers support for health checks, metrics and tracing. ",
            "title": "API"
        },
        {
            "location": "/se/dbclient",
            "text": " For the DB Client using JDBC implementation and H2 database, you must include the following dependencies in your project: <markup lang=\"xml\" >&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.dbclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-dbclient&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.dbclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-dbclient-jdbc&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.h2database&lt;/groupId&gt; &lt;artifactId&gt;h2&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; Add the Helidon DB Client Specify JDBC or MongoDB Add the database JDBC driver (only for JDBC) ",
            "title": "Add the DB Client dependencies to the Maven pom.xml file."
        },
        {
            "location": "/se/dbclient",
            "text": " The DB Client must be configured before you begin. In the example below we&#8217;ll use Helidon Config to set up JDBC-based client: <markup lang=\"yaml\" >db: source: \"jdbc\" connection: url: \"jdbc:mysql://127.0.0.1:3306/pokemon?useSSL=false\" username: \"user\" password: \"password\" statements: ping: \"DO 0\" select-all-pokemons: \"SELECT id, name FROM Pokemons\" Source: jdbc or mongoDb Connection: database connection parameters Statements: named statements to be used in application A ping statement used by health check ",
            "title": "Use Helidon Config to configure the client."
        },
        {
            "location": "/se/dbclient",
            "text": " Before you begin you must add the DB Client dependencies and configure the client. Add the DB Client dependencies to the Maven pom.xml file. For the DB Client using JDBC implementation and H2 database, you must include the following dependencies in your project: <markup lang=\"xml\" >&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.dbclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-dbclient&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.dbclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-dbclient-jdbc&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.h2database&lt;/groupId&gt; &lt;artifactId&gt;h2&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; Add the Helidon DB Client Specify JDBC or MongoDB Add the database JDBC driver (only for JDBC) Use Helidon Config to configure the client. The DB Client must be configured before you begin. In the example below we&#8217;ll use Helidon Config to set up JDBC-based client: <markup lang=\"yaml\" >db: source: \"jdbc\" connection: url: \"jdbc:mysql://127.0.0.1:3306/pokemon?useSSL=false\" username: \"user\" password: \"password\" statements: ping: \"DO 0\" select-all-pokemons: \"SELECT id, name FROM Pokemons\" Source: jdbc or mongoDb Connection: database connection parameters Statements: named statements to be used in application A ping statement used by health check ",
            "title": "Configuration"
        },
        {
            "location": "/se/dbclient",
            "text": " DBClient class has two methods to select whether statements will be executed in transaction or not: execute() transaction() Both methods provide an executor: either DbExecute or DbTransaction . ",
            "title": "Executor Selection"
        },
        {
            "location": "/se/dbclient",
            "text": " DbExecute class offers many methods for various statements builders: DML statements: createDmlStatement , createNamedDmlStatement insert statements: createInsert , createNamedInsert update statements: createUpdate , createNamedUpdate delete statements: createDelete , createNamedDelete query statements: createQuery , createNamedQuery get statements: createGet , createNamedGet Methods with \"Named\" in their name ( create Named DmlStatement ) expect statement name from statements section of Config, or a named statement configured when the DbClient was created using a Builder . All statement builders offer methods to set statement parameters. Those parameters can be ordered parameters or named parameters. Ordered and named parameters can’t be mixed in a single statement. Note that get statements are query statements that allow zero to one results. ",
            "title": "Statement Building and Execution"
        },
        {
            "location": "/se/dbclient",
            "text": " Ordered parameters are written down as ? in the statement text: <markup lang=\"sql\" >SELECT name FROM Pokemons WHERE id = ? The ordered parameters are equivalent to JDBC PreparedStatement parameters. Methods to set ordered parameters are: params(List&lt;?&gt; parameters) with all parameters as List params(Object… parameters) with all parameters as array indexedParam(Object parameters) POJO used with registered mapper addParam(Object parameter) with single parameter, can be called repeatedly ",
            "title": "Ordered Parameters"
        },
        {
            "location": "/se/dbclient",
            "text": " Named parameters are written down as :&lt;name&gt; in the JDBC statements <markup lang=\"sql\" >SELECT name FROM Pokemons WHERE id = :id or as $&lt;name&gt; in the MongoDB statement: <markup lang=\"json\" >{ \"collection\": \"pokemons\", \"operation\": \"update\", \"value\": { \"$set\": { \"name\": \"$name\" } }, \"query\": { \"id\": \"$id\" } } Methods to set named parameters are: params(Map&lt;String, ?&gt; parameters) with all parameters as Map namedParam(Object parameters) POJO used with registered mapper addParam(String name, Object parameter) with single parameter, can be called repeatedly ",
            "title": "Named Parameters"
        },
        {
            "location": "/se/dbclient",
            "text": " Execution of DML statements will always return a long with the number of modified records in the database. In following example, the number of modified records is printed to standard output: <markup lang=\"java\" >long count = dbClient.execute() .insert(\"INSERT INTO Pokemons (id, name) VALUES(?, ?)\", 1, \"Pikachu\")); System.out.printf(\"Inserted %d records\", count) ",
            "title": "DML Statement Result"
        },
        {
            "location": "/se/dbclient",
            "text": " Execution of a query statement will always return Stream&lt;DbRow&gt;&gt; . The stream is populated lazily, result rows can be processed individually Use .map(…) to map returned result Use .toList() on the stream to collect all rows ",
            "title": "Query Statement Result"
        },
        {
            "location": "/se/dbclient",
            "text": " Statements are executed by calling execute() method after statement parameters are set. This method returns either a Single or Multi depending on statement type. The type returned also depends on statement type. JDBC query with ordered parameters and query that does not run in the transaction: <markup lang=\"java\" >dbClient.execute() .createQuery(\"SELECT name FROM Pokemons WHERE id = ?\") .params(1) .execute(); JDBC query with named parameters and the query runs in transaction: <markup lang=\"java\" >dbClient.transaction() .createQuery(\"SELECT name FROM Pokemons WHERE id = :id\") .addParam(\"id\", 1) .execute(); Both examples will return Multi&lt;DbRow&gt; with rows returned by the query. This example shows a MongoDB update statement with named parameters and the query does not run in transaction: <markup lang=\"java\" >dbClient.execute() .createUpdate(\"{\\\"collection\\\": \\\"pokemons\\\",\" + \"\\\"value\\\":{$set:{\\\"name\\\":$name}},\" + \"\\\"query\\\":{id:$id}}\") .addParam(\"id\", 1) .addParam(\"name\", \"Pikachu\") .execute(); This update statement will return a long with the number of modified records in the database. DML Statement Result Execution of DML statements will always return a long with the number of modified records in the database. In following example, the number of modified records is printed to standard output: <markup lang=\"java\" >long count = dbClient.execute() .insert(\"INSERT INTO Pokemons (id, name) VALUES(?, ?)\", 1, \"Pikachu\")); System.out.printf(\"Inserted %d records\", count) Query Statement Result Execution of a query statement will always return Stream&lt;DbRow&gt;&gt; . The stream is populated lazily, result rows can be processed individually Use .map(…) to map returned result Use .toList() on the stream to collect all rows ",
            "title": "Statement Execution"
        },
        {
            "location": "/se/dbclient",
            "text": " The Helidon DB Client API contains many methods to run various statements with parameters and to retrieve statement execution results. The following sections describe the options you can use to build and execute your statements. Executor Selection DBClient class has two methods to select whether statements will be executed in transaction or not: execute() transaction() Both methods provide an executor: either DbExecute or DbTransaction . Statement Building and Execution DbExecute class offers many methods for various statements builders: DML statements: createDmlStatement , createNamedDmlStatement insert statements: createInsert , createNamedInsert update statements: createUpdate , createNamedUpdate delete statements: createDelete , createNamedDelete query statements: createQuery , createNamedQuery get statements: createGet , createNamedGet Methods with \"Named\" in their name ( create Named DmlStatement ) expect statement name from statements section of Config, or a named statement configured when the DbClient was created using a Builder . All statement builders offer methods to set statement parameters. Those parameters can be ordered parameters or named parameters. Ordered and named parameters can’t be mixed in a single statement. Note that get statements are query statements that allow zero to one results. Ordered Parameters Ordered parameters are written down as ? in the statement text: <markup lang=\"sql\" >SELECT name FROM Pokemons WHERE id = ? The ordered parameters are equivalent to JDBC PreparedStatement parameters. Methods to set ordered parameters are: params(List&lt;?&gt; parameters) with all parameters as List params(Object… parameters) with all parameters as array indexedParam(Object parameters) POJO used with registered mapper addParam(Object parameter) with single parameter, can be called repeatedly Named Parameters Named parameters are written down as :&lt;name&gt; in the JDBC statements <markup lang=\"sql\" >SELECT name FROM Pokemons WHERE id = :id or as $&lt;name&gt; in the MongoDB statement: <markup lang=\"json\" >{ \"collection\": \"pokemons\", \"operation\": \"update\", \"value\": { \"$set\": { \"name\": \"$name\" } }, \"query\": { \"id\": \"$id\" } } Methods to set named parameters are: params(Map&lt;String, ?&gt; parameters) with all parameters as Map namedParam(Object parameters) POJO used with registered mapper addParam(String name, Object parameter) with single parameter, can be called repeatedly Statement Execution Statements are executed by calling execute() method after statement parameters are set. This method returns either a Single or Multi depending on statement type. The type returned also depends on statement type. JDBC query with ordered parameters and query that does not run in the transaction: <markup lang=\"java\" >dbClient.execute() .createQuery(\"SELECT name FROM Pokemons WHERE id = ?\") .params(1) .execute(); JDBC query with named parameters and the query runs in transaction: <markup lang=\"java\" >dbClient.transaction() .createQuery(\"SELECT name FROM Pokemons WHERE id = :id\") .addParam(\"id\", 1) .execute(); Both examples will return Multi&lt;DbRow&gt; with rows returned by the query. This example shows a MongoDB update statement with named parameters and the query does not run in transaction: <markup lang=\"java\" >dbClient.execute() .createUpdate(\"{\\\"collection\\\": \\\"pokemons\\\",\" + \"\\\"value\\\":{$set:{\\\"name\\\":$name}},\" + \"\\\"query\\\":{id:$id}}\") .addParam(\"id\", 1) .addParam(\"name\", \"Pikachu\") .execute(); This update statement will return a long with the number of modified records in the database. DML Statement Result Execution of DML statements will always return a long with the number of modified records in the database. In following example, the number of modified records is printed to standard output: <markup lang=\"java\" >long count = dbClient.execute() .insert(\"INSERT INTO Pokemons (id, name) VALUES(?, ?)\", 1, \"Pikachu\")); System.out.printf(\"Inserted %d records\", count) Query Statement Result Execution of a query statement will always return Stream&lt;DbRow&gt;&gt; . The stream is populated lazily, result rows can be processed individually Use .map(…) to map returned result Use .toList() on the stream to collect all rows ",
            "title": "Using DB Client API Methods"
        },
        {
            "location": "/se/dbclient",
            "text": " Now that you understand how to build and execute statements, try it for yourself. DB Client Examples . ",
            "title": "Additional Information"
        },
        {
            "location": "/se/fault-tolerance",
            "text": " Overview Maven Coordinates API Examples Additional Information ",
            "title": "Contents"
        },
        {
            "location": "/se/fault-tolerance",
            "text": " Helidon Fault Tolerance support is inspired by MicroProfile Fault Tolerance . The API defines the notion of a fault handler that can be combined with other handlers to improve application robustness. Handlers are created to manage error conditions (faults) that may occur in real-world application environments. Examples include service restarts, network delays, temporal infrastructure instabilities, etc. The interaction of multiple microservices bring some new challenges from distributed systems that require careful planning. Faults in distributed systems should be compartmentalized to avoid unnecessary service interruptions. For example, if comparable information can be obtained from multiples sources, a user request should not be denied when a subset of these sources is unreachable or offline. Similarly, if a non-essential source has been flagged as unreachable, an application should avoid continuous access to that source as that would result in much higher response times. In order to tackle the most common types of application faults, the Helidon Fault Tolerance API provides support for circuit breakers, retries, timeouts, bulkheads and fallbacks. In addition, the API makes it very easy to create and monitor asynchronous tasks that do not require explicit creation and management of threads or executors. For more information, see Fault Tolerance API Javadocs . ",
            "title": "Overview"
        },
        {
            "location": "/se/fault-tolerance",
            "text": " To enable Fault Tolerance add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.fault-tolerance&lt;/groupId&gt; &lt;artifactId&gt;helidon-fault-tolerance&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/fault-tolerance",
            "text": " Temporal networking problems can sometimes be mitigated by simply retrying a certain task. A Retry handler is created using a RetryPolicy that indicates the number of retries, delay between retries, etc. <markup lang=\"java\" >Retry retry = Retry.builder() .retryPolicy(Retry.JitterRetryPolicy.builder() .calls(3) .delay(Duration.ofMillis(100)) .build()) .build(); T result = retry.invoke(this::retryOnFailure); The sample code above will retry calls to the supplier this::retryOnFailure for up to 3 times with a 100 millisecond delay between them. The return type of method retryOnFailure in the example above must be some T and the parameter to the retry handler&#8217;s invoke method Supplier&lt;? extends T&gt; . If the call to the supplier provided completes exceptionally, it will be treated as a failure and retried until the maximum number of attempts is reached; finer control is possible by creating a retry policy and using methods such as applyOn(Class&lt;? extends Throwable&gt;&#8230;&#8203; classes) and skipOn(Class&lt;? extends Throwable&gt;&#8230;&#8203; classes) to control the exceptions that must be retried and those that must be ignored. ",
            "title": "Retries"
        },
        {
            "location": "/se/fault-tolerance",
            "text": " A request to a service that is inaccessible or simply unavailable should be bounded to ensure a certain quality of service and response time. Timeouts can be configured to avoid excessive waiting times. In addition, a fallback action can be defined if a timeout expires as we shall cover in the next section. The following is an example of using Timeout : <markup lang=\"java\" >T result = Timeout.create(Duration.ofMillis(10)) .invoke(this::mayTakeVeryLong); Using a handler&#8217;s create method is an alternative to using a builder that is more convenient when default settings are acceptable. The example above monitors the call to method mayTakeVeryLong and reports a TimeoutException if the execution takes more than 10 milliseconds to complete. ",
            "title": "Timeouts"
        },
        {
            "location": "/se/fault-tolerance",
            "text": " A fallback to a known result can sometimes be an alternative to reporting an error. For example, if we are unable to access a service we may fall back to the last result obtained from that service at an earlier time. A Fallback instance is created by providing a function that takes a Throwable and produces some T to be used when the intended method failed to return a value: <markup lang=\"java\" >T result = Fallback.create(throwable -&gt; lastKnownValue) .invoke(this::mayFail); This example calls the method mayFail and if it produces a Throwable , it maps it to the last known value using the fallback handler. ",
            "title": "Fallbacks"
        },
        {
            "location": "/se/fault-tolerance",
            "text": " Failing to execute a certain task or to call another service repeatedly can have a direct impact on application performance. It is often preferred to avoid calls to non-essential services by simply preventing that logic to execute altogether. A circuit breaker can be configured to monitor such calls and block attempts that are likely to fail, thus improving overall performance. Circuit breakers start in a closed state, letting calls to proceed normally; after detecting a certain number of errors during a pre-defined processing window, they can open to prevent additional failures. After a circuit has been opened, it can transition first to a half-open state before finally transitioning back to a closed state. The use of an intermediate state (half-open) makes transitions from open to close more progressive, and prevents a circuit breaker from eagerly transitioning to states without considering sufficient observations. Any failure while a circuit breaker is in half-open state will immediately cause it to transition back to an open state. Consider the following example in which this::mayFail is monitored by a circuit breaker: <markup lang=\"java\" >CircuitBreaker breaker = CircuitBreaker.builder() .volume(10) .errorRatio(30) .delay(Duration.ofMillis(200)) .successThreshold(2) .build(); T result = breaker.invoke(this::mayFail); The circuit breaker in this example defines a processing window of size 10, an error ratio of 30%, a duration to transition to half-open state of 200 milliseconds, and a success threshold to transition from half-open to closed state of 2 observations. It follows that, After completing the processing window, if at least 3 errors are detected, the circuit breaker will transition to the open state, thus blocking the execution of any subsequent calls. After 200 millis, the circuit breaker will transition back to half-open and allow calls to proceed again. If the next two calls after transitioning to half-open are successful, the circuit breaker will transition to closed state; otherwise, it will transition back to open state, waiting for another 200 milliseconds before attempting to transition to half-open again. A circuit breaker will throw a io.helidon.faulttolerance.CircuitBreakerOpenException if an attempt to make an invocation takes place while it is in open state. ",
            "title": "Circuit Breakers"
        },
        {
            "location": "/se/fault-tolerance",
            "text": " Concurrent access to certain components may need to be limited to avoid excessive use of resources. For example, if an invocation that opens a network connection is allowed to execute concurrently without any restriction, and if the service on the other end is slow responding, it is possible for the rate at which network connections are opened to exceed the maximum number of connections allowed. Faults of this type can be prevented by guarding these invocations using a bulkhead. The origin of the name bulkhead comes from the partitions that comprise a ship&#8217;s hull. If some partition is somehow compromised (e.g., filled with water) it can be isolated in a manner not to affect the rest of the hull. A waiting queue can be associated with a bulkhead to handle tasks that are submitted when the bulkhead is already at full capacity. <markup lang=\"java\" >Bulkhead bulkhead = Bulkhead.builder() .limit(3) .queueLength(5) .build(); T result = bulkhead.invoke(this::usesResources); This example creates a bulkhead that limits concurrent execution to this:usesResources to at most 3, and with a queue of size 5. The bulkhead will report a io.helidon.faulttolerance.BulkheadException if unable to proceed with the call: either due to the limit being reached or the queue being at maximum capacity. ",
            "title": "Bulkheads"
        },
        {
            "location": "/se/fault-tolerance",
            "text": " Asynchronous tasks can be created or forked by using an Async instance. A supplier of type T is provided as the argument when invoking this handler. For example: <markup lang=\"java\" >CompletableFuture&lt;Thread&gt; cf = Async.create().invoke(Thread::currentThread)); cf.thenAccept(t -&gt; System.out.println(\"Async task executed in thread \" + t)); The supplier () &#8594; Thread.currentThread() is executed in a new thread and the value it produces printed by the consumer and passed to thenAccept . By default, asynchronous tasks are executed using a new virtual thread per task based on the ExecutorService defined in io.helidon.faulttolerance.FaultTolerance and configurable by an application. Alternatively, an ExecutorService can be specified when building a non-standard Async instance. ",
            "title": "Asynchronous"
        },
        {
            "location": "/se/fault-tolerance",
            "text": " Method invocations can be guarded by any combination of the handlers presented above. For example, an invocation that times out can be retried a few times before resorting to a fallback value &mdash;assuming it never succeeds. The easiest way to achieve handler composition is by using a builder in the FaultTolerance class as shown in the following example: <markup lang=\"java\" >FaultTolerance.TypedBuilder&lt;T&gt; builder = FaultTolerance.typedBuilder(); Timeout timeout = Timeout.create(Duration.ofMillis(10)); builder.addTimeout(timeout); Retry retry = Retry.builder() .retryPolicy(Retry.JitterRetryPolicy.builder() .calls(3) .delay(Duration.ofMillis(100)) .build()) .build(); builder.addRetry(retry); Fallback&lt;T&gt; fallback = Fallback.create(throwable -&gt;lastKnownValue); builder.addFallback(fallback); T result = builder.build().invoke(this::mayTakeVeryLong); The exact order in which handlers are added to a builder depends on the use case, but generally the order starting from innermost to outermost should be: bulkhead, timeout, circuit breaker, retry and fallback. That is, fallback is the first handler in the chain (the last to executed once a value is returned) and bulkhead is the last one (the first to be executed once a value is returned). This is the ordering used by the MicroProfile Fault Tolerance implementation in Helidon when a method is decorated with multiple annotations. ",
            "title": "Handler Composition"
        },
        {
            "location": "/se/fault-tolerance",
            "text": " The Fault Tolerance API is blocking and based on the JDK&#8217;s virtual thread model. As a result, methods return direct values instead of promises in the form of Single&lt;T&gt; or Multi&lt;T&gt; . In the sections that follow, we shall briefly explore each of the constructs provided by this API. Retries Temporal networking problems can sometimes be mitigated by simply retrying a certain task. A Retry handler is created using a RetryPolicy that indicates the number of retries, delay between retries, etc. <markup lang=\"java\" >Retry retry = Retry.builder() .retryPolicy(Retry.JitterRetryPolicy.builder() .calls(3) .delay(Duration.ofMillis(100)) .build()) .build(); T result = retry.invoke(this::retryOnFailure); The sample code above will retry calls to the supplier this::retryOnFailure for up to 3 times with a 100 millisecond delay between them. The return type of method retryOnFailure in the example above must be some T and the parameter to the retry handler&#8217;s invoke method Supplier&lt;? extends T&gt; . If the call to the supplier provided completes exceptionally, it will be treated as a failure and retried until the maximum number of attempts is reached; finer control is possible by creating a retry policy and using methods such as applyOn(Class&lt;? extends Throwable&gt;&#8230;&#8203; classes) and skipOn(Class&lt;? extends Throwable&gt;&#8230;&#8203; classes) to control the exceptions that must be retried and those that must be ignored. Timeouts A request to a service that is inaccessible or simply unavailable should be bounded to ensure a certain quality of service and response time. Timeouts can be configured to avoid excessive waiting times. In addition, a fallback action can be defined if a timeout expires as we shall cover in the next section. The following is an example of using Timeout : <markup lang=\"java\" >T result = Timeout.create(Duration.ofMillis(10)) .invoke(this::mayTakeVeryLong); Using a handler&#8217;s create method is an alternative to using a builder that is more convenient when default settings are acceptable. The example above monitors the call to method mayTakeVeryLong and reports a TimeoutException if the execution takes more than 10 milliseconds to complete. Fallbacks A fallback to a known result can sometimes be an alternative to reporting an error. For example, if we are unable to access a service we may fall back to the last result obtained from that service at an earlier time. A Fallback instance is created by providing a function that takes a Throwable and produces some T to be used when the intended method failed to return a value: <markup lang=\"java\" >T result = Fallback.create(throwable -&gt; lastKnownValue) .invoke(this::mayFail); This example calls the method mayFail and if it produces a Throwable , it maps it to the last known value using the fallback handler. Circuit Breakers Failing to execute a certain task or to call another service repeatedly can have a direct impact on application performance. It is often preferred to avoid calls to non-essential services by simply preventing that logic to execute altogether. A circuit breaker can be configured to monitor such calls and block attempts that are likely to fail, thus improving overall performance. Circuit breakers start in a closed state, letting calls to proceed normally; after detecting a certain number of errors during a pre-defined processing window, they can open to prevent additional failures. After a circuit has been opened, it can transition first to a half-open state before finally transitioning back to a closed state. The use of an intermediate state (half-open) makes transitions from open to close more progressive, and prevents a circuit breaker from eagerly transitioning to states without considering sufficient observations. Any failure while a circuit breaker is in half-open state will immediately cause it to transition back to an open state. Consider the following example in which this::mayFail is monitored by a circuit breaker: <markup lang=\"java\" >CircuitBreaker breaker = CircuitBreaker.builder() .volume(10) .errorRatio(30) .delay(Duration.ofMillis(200)) .successThreshold(2) .build(); T result = breaker.invoke(this::mayFail); The circuit breaker in this example defines a processing window of size 10, an error ratio of 30%, a duration to transition to half-open state of 200 milliseconds, and a success threshold to transition from half-open to closed state of 2 observations. It follows that, After completing the processing window, if at least 3 errors are detected, the circuit breaker will transition to the open state, thus blocking the execution of any subsequent calls. After 200 millis, the circuit breaker will transition back to half-open and allow calls to proceed again. If the next two calls after transitioning to half-open are successful, the circuit breaker will transition to closed state; otherwise, it will transition back to open state, waiting for another 200 milliseconds before attempting to transition to half-open again. A circuit breaker will throw a io.helidon.faulttolerance.CircuitBreakerOpenException if an attempt to make an invocation takes place while it is in open state. Bulkheads Concurrent access to certain components may need to be limited to avoid excessive use of resources. For example, if an invocation that opens a network connection is allowed to execute concurrently without any restriction, and if the service on the other end is slow responding, it is possible for the rate at which network connections are opened to exceed the maximum number of connections allowed. Faults of this type can be prevented by guarding these invocations using a bulkhead. The origin of the name bulkhead comes from the partitions that comprise a ship&#8217;s hull. If some partition is somehow compromised (e.g., filled with water) it can be isolated in a manner not to affect the rest of the hull. A waiting queue can be associated with a bulkhead to handle tasks that are submitted when the bulkhead is already at full capacity. <markup lang=\"java\" >Bulkhead bulkhead = Bulkhead.builder() .limit(3) .queueLength(5) .build(); T result = bulkhead.invoke(this::usesResources); This example creates a bulkhead that limits concurrent execution to this:usesResources to at most 3, and with a queue of size 5. The bulkhead will report a io.helidon.faulttolerance.BulkheadException if unable to proceed with the call: either due to the limit being reached or the queue being at maximum capacity. Asynchronous Asynchronous tasks can be created or forked by using an Async instance. A supplier of type T is provided as the argument when invoking this handler. For example: <markup lang=\"java\" >CompletableFuture&lt;Thread&gt; cf = Async.create().invoke(Thread::currentThread)); cf.thenAccept(t -&gt; System.out.println(\"Async task executed in thread \" + t)); The supplier () &#8594; Thread.currentThread() is executed in a new thread and the value it produces printed by the consumer and passed to thenAccept . By default, asynchronous tasks are executed using a new virtual thread per task based on the ExecutorService defined in io.helidon.faulttolerance.FaultTolerance and configurable by an application. Alternatively, an ExecutorService can be specified when building a non-standard Async instance. Handler Composition Method invocations can be guarded by any combination of the handlers presented above. For example, an invocation that times out can be retried a few times before resorting to a fallback value &mdash;assuming it never succeeds. The easiest way to achieve handler composition is by using a builder in the FaultTolerance class as shown in the following example: <markup lang=\"java\" >FaultTolerance.TypedBuilder&lt;T&gt; builder = FaultTolerance.typedBuilder(); Timeout timeout = Timeout.create(Duration.ofMillis(10)); builder.addTimeout(timeout); Retry retry = Retry.builder() .retryPolicy(Retry.JitterRetryPolicy.builder() .calls(3) .delay(Duration.ofMillis(100)) .build()) .build(); builder.addRetry(retry); Fallback&lt;T&gt; fallback = Fallback.create(throwable -&gt;lastKnownValue); builder.addFallback(fallback); T result = builder.build().invoke(this::mayTakeVeryLong); The exact order in which handlers are added to a builder depends on the use case, but generally the order starting from innermost to outermost should be: bulkhead, timeout, circuit breaker, retry and fallback. That is, fallback is the first handler in the chain (the last to executed once a value is returned) and bulkhead is the last one (the first to be executed once a value is returned). This is the ordering used by the MicroProfile Fault Tolerance implementation in Helidon when a method is decorated with multiple annotations. ",
            "title": "API"
        },
        {
            "location": "/se/fault-tolerance",
            "text": " See section for examples. ",
            "title": "Examples"
        },
        {
            "location": "/se/fault-tolerance",
            "text": " For additional information, see the Fault Tolerance API Javadocs . ",
            "title": "Additional Information"
        },
        {
            "location": "/se/graphql",
            "text": " Overview Maven Coordinates API Configuration Examples Additional Information ",
            "title": "Contents"
        },
        {
            "location": "/se/graphql",
            "text": " The Helidon GraphQL Server provides a framework for creating GraphQL applications that integrate with the Helidon WebServer. GraphQL is a query language to access server data. The Helidon GraphQL integration enables HTTP clients to issue queries over the network and retrieve data; it is an alternative to other protocols such as REST or GRPC. ",
            "title": "Overview"
        },
        {
            "location": "/se/graphql",
            "text": " To enable GraphQL add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.graphql&lt;/groupId&gt; &lt;artifactId&gt;helidon-graphql-server&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/graphql",
            "text": " An instance of GraphQlSupport must be registered in the Helidon WebServer routes to enable GraphQL support in your application. In addition, a GraphQL schema needs to be specified to verify and execute queries. The following code fragment creates an instance of GraphQlSupport and registers it in the Helidon WebServer. <markup lang=\"java\" > WebServer server = WebServer.builder() .routing(Routing.builder() .register(GraphQlSupport.create(buildSchema())) .build()) .build(); By default, GraphQlSupport will reserve /graphql as the URI path to process queries. The buildSchema method creates the schema and defines 2 types of queries for this application: <markup lang=\"java\" >private static GraphQLSchema buildSchema() { String schema = \"type Query{\" + \"hello: String \" + \"helloInDifferentLanguages: [String] \" + \"}\"; SchemaParser schemaParser = new SchemaParser(); TypeDefinitionRegistry typeDefinitionRegistry = schemaParser.parse(schema); // DataFetcher to return various hellos in difference languages DataFetcher&lt;List&lt;String&gt;&gt; hellosDataFetcher = (DataFetcher&lt;List&lt;String&gt;&gt;) environment -&gt; List.of(\"Bonjour\", \"Hola\", \"Zdravstvuyte\", \"Nǐn hǎo\", \"Salve\", \"Gudday\", \"Konnichiwa\", \"Guten Tag\"); RuntimeWiring runtimeWiring = RuntimeWiring.newRuntimeWiring() .type(\"Query\", builder -&gt; builder.dataFetcher(\"hello\", new StaticDataFetcher(\"world\"))) .type(\"Query\", builder -&gt; builder.dataFetcher(\"helloInDifferentLanguages\", hellosDataFetcher)) .build(); SchemaGenerator schemaGenerator = new SchemaGenerator(); return schemaGenerator.makeExecutableSchema(typeDefinitionRegistry, runtimeWiring); } The following is a description of each of these steps: Define the GraphQL schema. Create a DataFetcher to return a list of hellos in different languages. Wire up the DataFetcher s. Generate the GraphQL schema. ",
            "title": "API"
        },
        {
            "location": "/se/graphql",
            "text": " The following configuration keys can be used to set up integration with WebServer: key default value description graphql.web-context /graphql Context that serves the GraphQL endpoint. graphql.schema-uri /schema.graphql URI that serves the schema (under web context) graphql.cors &#160; CORS configuration for this service graphql.executor-service &#160; Configuration of ServerThreadPoolSupplier used to set up executor service The following configuration keys can be used to set up GraphQL invocation: key default value description graphql.default-error-message Server Error Error message to send to caller in case of error graphql.exception-white-list &#160; Array of checked exception classes that should return default error message graphql.exception-black-list &#160; Array of unchecked exception classes that should return message to caller (instead of default error message) ",
            "title": "Configuration"
        },
        {
            "location": "/se/graphql",
            "text": " Using the schema defined in Section , you can probe the following endpoints: Hello world endpoint <markup lang=\"bash\" >curl -X POST http://127.0.0.1:PORT/graphql -d '{\"query\":\"query { hello }\"}' \"data\":{\"hello\":\"world\"}} Hello in different languages <markup lang=\"bash\" >curl -X POST http://127.0.0.1:PORT/graphql -d '{\"query\":\"query { helloInDifferentLanguages }\"}' {\"data\":{\"helloInDifferentLanguages\":[\"Bonjour\",\"Hola\",\"Zdravstvuyte\",\"Nǐn hǎo\",\"Salve\",\"Gudday\",\"Konnichiwa\",\"Guten Tag\"]}} ",
            "title": "Examples"
        },
        {
            "location": "/se/graphql",
            "text": " GraphQL Javadocs ",
            "title": "Additional Information"
        },
        {
            "location": "/se/grpc/client",
            "text": " Overview ",
            "title": "Contents"
        },
        {
            "location": "/se/grpc/client",
            "text": " gRPC client is temporarily removed from Helidon, please follow issue https://github.com/helidon-io/helidon/issues/5418 If you require gRPC client, either stay with a previous version of Helidon, or allow us to finish fixing the issue above. ",
            "title": "Overview"
        },
        {
            "location": "/se/grpc/server",
            "text": " Overview Maven Coordinates Usage gRPC Server Routing Service Implementation Configuration Configuring the gRPC Server in the Code Examples ",
            "title": "Contents"
        },
        {
            "location": "/se/grpc/server",
            "text": " gRPC scope is temporarily smaller in Helidon, please follow issue https://github.com/helidon-io/helidon/issues/5418 As this is still work in progress, the WebServer gRPC module is release in preview mode, as we may introduce backward incompatible changes to our APIs, so we can re-introduce features. The Helidon gRPC server provides a framework for creating gRPC applications. While it allows you to deploy any standard gRPC service that implements io.grpc.BindableService interface, including services generated from the Protobuf IDL files (and even allows you to customize them to a certain extent), using Helidon gRPC framework to implement your services has a number of benefits: It allows you to define both HTTP and gRPC services using a similar programming model, simplifying the learning curve for developers. It provides a number of helper methods that make service implementation significantly simpler. It allows you to run gRPC and HTTP endpoints on the same WebServer, and even on the same port. ",
            "title": "Overview"
        },
        {
            "location": "/se/grpc/server",
            "text": " To enable gRPC Server add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webserver&lt;/groupId&gt; &lt;artifactId&gt;helidon-webserver-grpc&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/grpc/server",
            "text": " When registering a service, regardless of its type, you can customize its descriptor by providing an instance of ServerServiceDefinition to service method. ",
            "title": "Customizing Service Definitions"
        },
        {
            "location": "/se/grpc/server",
            "text": " Customizing Service Definitions Unlike the HTTP server, which allows you to route requests based on path expression and the HTTP verb, the gRPC server always routes requests based on the service and method name. This makes routing configuration somewhat simpler&#8201;&#8212;&#8201;all you need to do is register your services: <markup lang=\"java\" >private static GrpcRouting.Builder createRouting(Config config) { return GrpcRouting.builder() .service(new GreetService(config)) .service(new EchoService()) .service(new MathService()) .unary(Strings.getDescriptor(), \"StringService\", \"Upper\", Main::grpcUpper); } Register GreetService instance. Register EchoService instance. Register MathService instance. Register a custom unary gRPC route Both \"standard\" gRPC services that implement io.grpc.BindableService interface (typically implemented by extending the generated server-side stub and overriding its methods), and Helidon gRPC services that implement io.helidon.grpc.server.GrpcService interface can be registered. The difference is that Helidon gRPC services allow you to customize behavior down to the method level, and provide a number of useful helper methods that make service implementation easier, as we&#8217;ll see in a moment. Customizing Service Definitions When registering a service, regardless of its type, you can customize its descriptor by providing an instance of ServerServiceDefinition to service method. ",
            "title": "gRPC Server Routing"
        },
        {
            "location": "/se/grpc/server",
            "text": " For this example, we will re-implement the EchoService above as a Protobuf service in echo.proto file. <markup lang=\"proto\" >syntax = \"proto3\"; option java_package = \"org.example.services.echo\"; service EchoService { rpc Echo (EchoRequest) returns (EchoResponse) {} } message EchoRequest { string message = 1; } message EchoResponse { string message = 1; } Based on this IDL, the gRPC compiler will generate message classes ( EchoRequest and EchoResponse ), client stubs that can be used to make RPC calls to the server, as well as the base class for the server-side service implementation. We can ignore the last one, and implement the service using Helidon gRPC framework instead. ",
            "title": "Define the Service IDL"
        },
        {
            "location": "/se/grpc/server",
            "text": " The service implementation will be very similar to our original implementation: <markup lang=\"java\" >class EchoService implements GrpcService { @Override public Descriptors.FileDescriptor proto() { return Echo.getDescriptor(); } @Override public void update(ServiceDescriptor.Rules rules) { rules.unary(\"Echo\", this::echo); } /** * Echo the message back to the caller. * * @param request the echo request containing the message to echo * @param observer the response observer */ public void echo(Echo.EchoRequest request, StreamObserver&lt;Echo.EchoResponse&gt; observer) { String message = request.getMessage(); Echo.EchoResponse response = Echo.EchoResponse.newBuilder().setMessage(message).build(); complete(observer, response); } } Specify the proto descriptor in order to provide necessary type information and enable Protobuf marshalling. Define unary method Echo and map it to the this::echo handler. Create a handler for the Echo method, using Protobuf message types for request and response. Extract message string from the request. Create the response containing extracted message. Send the response back to the client by completing response observer. The complete method shown in the example above is just one of many helper methods available in the ResponseHelper class. See the full list here . ",
            "title": "Implement the Service"
        },
        {
            "location": "/se/grpc/server",
            "text": " In order to implement Protobuf-based service, you would follow the official instructions on the gRPC web site, which boil down to the following: Define the Service IDL For this example, we will re-implement the EchoService above as a Protobuf service in echo.proto file. <markup lang=\"proto\" >syntax = \"proto3\"; option java_package = \"org.example.services.echo\"; service EchoService { rpc Echo (EchoRequest) returns (EchoResponse) {} } message EchoRequest { string message = 1; } message EchoResponse { string message = 1; } Based on this IDL, the gRPC compiler will generate message classes ( EchoRequest and EchoResponse ), client stubs that can be used to make RPC calls to the server, as well as the base class for the server-side service implementation. We can ignore the last one, and implement the service using Helidon gRPC framework instead. Implement the Service The service implementation will be very similar to our original implementation: <markup lang=\"java\" >class EchoService implements GrpcService { @Override public Descriptors.FileDescriptor proto() { return Echo.getDescriptor(); } @Override public void update(ServiceDescriptor.Rules rules) { rules.unary(\"Echo\", this::echo); } /** * Echo the message back to the caller. * * @param request the echo request containing the message to echo * @param observer the response observer */ public void echo(Echo.EchoRequest request, StreamObserver&lt;Echo.EchoResponse&gt; observer) { String message = request.getMessage(); Echo.EchoResponse response = Echo.EchoResponse.newBuilder().setMessage(message).build(); complete(observer, response); } } Specify the proto descriptor in order to provide necessary type information and enable Protobuf marshalling. Define unary method Echo and map it to the this::echo handler. Create a handler for the Echo method, using Protobuf message types for request and response. Extract message string from the request. Create the response containing extracted message. Send the response back to the client by completing response observer. The complete method shown in the example above is just one of many helper methods available in the ResponseHelper class. See the full list here . ",
            "title": "Implementing Protobuf Services"
        },
        {
            "location": "/se/grpc/server",
            "text": " Implementing Protobuf Services In order to implement Protobuf-based service, you would follow the official instructions on the gRPC web site, which boil down to the following: Define the Service IDL For this example, we will re-implement the EchoService above as a Protobuf service in echo.proto file. <markup lang=\"proto\" >syntax = \"proto3\"; option java_package = \"org.example.services.echo\"; service EchoService { rpc Echo (EchoRequest) returns (EchoResponse) {} } message EchoRequest { string message = 1; } message EchoResponse { string message = 1; } Based on this IDL, the gRPC compiler will generate message classes ( EchoRequest and EchoResponse ), client stubs that can be used to make RPC calls to the server, as well as the base class for the server-side service implementation. We can ignore the last one, and implement the service using Helidon gRPC framework instead. Implement the Service The service implementation will be very similar to our original implementation: <markup lang=\"java\" >class EchoService implements GrpcService { @Override public Descriptors.FileDescriptor proto() { return Echo.getDescriptor(); } @Override public void update(ServiceDescriptor.Rules rules) { rules.unary(\"Echo\", this::echo); } /** * Echo the message back to the caller. * * @param request the echo request containing the message to echo * @param observer the response observer */ public void echo(Echo.EchoRequest request, StreamObserver&lt;Echo.EchoResponse&gt; observer) { String message = request.getMessage(); Echo.EchoResponse response = Echo.EchoResponse.newBuilder().setMessage(message).build(); complete(observer, response); } } Specify the proto descriptor in order to provide necessary type information and enable Protobuf marshalling. Define unary method Echo and map it to the this::echo handler. Create a handler for the Echo method, using Protobuf message types for request and response. Extract message string from the request. Create the response containing extracted message. Send the response back to the client by completing response observer. The complete method shown in the example above is just one of many helper methods available in the ResponseHelper class. See the full list here . ",
            "title": "Service Implementation"
        },
        {
            "location": "/se/grpc/server",
            "text": " gRPC Server Routing Customizing Service Definitions Unlike the HTTP server, which allows you to route requests based on path expression and the HTTP verb, the gRPC server always routes requests based on the service and method name. This makes routing configuration somewhat simpler&#8201;&#8212;&#8201;all you need to do is register your services: <markup lang=\"java\" >private static GrpcRouting.Builder createRouting(Config config) { return GrpcRouting.builder() .service(new GreetService(config)) .service(new EchoService()) .service(new MathService()) .unary(Strings.getDescriptor(), \"StringService\", \"Upper\", Main::grpcUpper); } Register GreetService instance. Register EchoService instance. Register MathService instance. Register a custom unary gRPC route Both \"standard\" gRPC services that implement io.grpc.BindableService interface (typically implemented by extending the generated server-side stub and overriding its methods), and Helidon gRPC services that implement io.helidon.grpc.server.GrpcService interface can be registered. The difference is that Helidon gRPC services allow you to customize behavior down to the method level, and provide a number of useful helper methods that make service implementation easier, as we&#8217;ll see in a moment. Customizing Service Definitions When registering a service, regardless of its type, you can customize its descriptor by providing an instance of ServerServiceDefinition to service method. Service Implementation Implementing Protobuf Services In order to implement Protobuf-based service, you would follow the official instructions on the gRPC web site, which boil down to the following: Define the Service IDL For this example, we will re-implement the EchoService above as a Protobuf service in echo.proto file. <markup lang=\"proto\" >syntax = \"proto3\"; option java_package = \"org.example.services.echo\"; service EchoService { rpc Echo (EchoRequest) returns (EchoResponse) {} } message EchoRequest { string message = 1; } message EchoResponse { string message = 1; } Based on this IDL, the gRPC compiler will generate message classes ( EchoRequest and EchoResponse ), client stubs that can be used to make RPC calls to the server, as well as the base class for the server-side service implementation. We can ignore the last one, and implement the service using Helidon gRPC framework instead. Implement the Service The service implementation will be very similar to our original implementation: <markup lang=\"java\" >class EchoService implements GrpcService { @Override public Descriptors.FileDescriptor proto() { return Echo.getDescriptor(); } @Override public void update(ServiceDescriptor.Rules rules) { rules.unary(\"Echo\", this::echo); } /** * Echo the message back to the caller. * * @param request the echo request containing the message to echo * @param observer the response observer */ public void echo(Echo.EchoRequest request, StreamObserver&lt;Echo.EchoResponse&gt; observer) { String message = request.getMessage(); Echo.EchoResponse response = Echo.EchoResponse.newBuilder().setMessage(message).build(); complete(observer, response); } } Specify the proto descriptor in order to provide necessary type information and enable Protobuf marshalling. Define unary method Echo and map it to the this::echo handler. Create a handler for the Echo method, using Protobuf message types for request and response. Extract message string from the request. Create the response containing extracted message. Send the response back to the client by completing response observer. The complete method shown in the example above is just one of many helper methods available in the ResponseHelper class. See the full list here . ",
            "title": "Usage"
        },
        {
            "location": "/se/grpc/server",
            "text": " Currently we do not have any custom configuration options for gRPC protocol. To register a routing with Helidon WebServer, simply add the routing to the listener (WebServer configuration is itself the default listener configuration) <markup lang=\"java\" >WebServer.builder() .port(8080) .routing(httpRouting -&gt; httpRouting.get(\"/greet\", (req, res) -&gt; res.send(\"Hi!\"))) .addRouting(GrpcRouting.builder() .unary(String.getDescriptor(), \"StringService\", \"Upper\", Main::grpcUpper)) .build() .start(); Configure HTTP routing of the server Configure gRPC routing of the server ",
            "title": "Configuring the gRPC Server in the Code"
        },
        {
            "location": "/se/grpc/server",
            "text": " Configure the gRPC server using the Helidon configuration framework, either programmatically or via a configuration file. Configuring the gRPC Server in the Code Currently we do not have any custom configuration options for gRPC protocol. To register a routing with Helidon WebServer, simply add the routing to the listener (WebServer configuration is itself the default listener configuration) <markup lang=\"java\" >WebServer.builder() .port(8080) .routing(httpRouting -&gt; httpRouting.get(\"/greet\", (req, res) -&gt; res.send(\"Hi!\"))) .addRouting(GrpcRouting.builder() .unary(String.getDescriptor(), \"StringService\", \"Upper\", Main::grpcUpper)) .build() .start(); Configure HTTP routing of the server Configure gRPC routing of the server ",
            "title": "Configuration"
        },
        {
            "location": "/se/grpc/server",
            "text": " The following gRPC examples for Helidon SE are available: Multiple protocols on a single WebServer ",
            "title": "Examples"
        },
        {
            "location": "/se/guides/config",
            "text": " This guide describes how to create a sample Helidon SE project that can be used to run some basic examples using both default and custom configuration. ",
            "title": "preambule"
        },
        {
            "location": "/se/guides/config",
            "text": " For this 20 minute tutorial, you will need the following: <div class=\"table__overflow elevation-1 flex sm7 \"> A Helidon SE Application You can use your own application or use the Helidon SE Quickstart to create a sample application. Java&#160;SE&#160;21 ( Open&#160;JDK&#160;21 ) Helidon requires Java 21+. Maven 3.8+ Helidon requires Maven 3.8+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop . <markup lang=\"bash\" title=\"Verify Prerequisites\" >java -version mvn --version docker --version kubectl version --short <markup lang=\"bash\" title=\"Setting JAVA_HOME\" ># On Mac export JAVA_HOME=`/usr/libexec/java_home -v 21` # On Linux # Use the appropriate path to your JDK export JAVA_HOME=/usr/lib/jvm/jdk-21 ",
            "title": "What you need"
        },
        {
            "location": "/se/guides/config",
            "text": " Use the Helidon SE Maven archetype to create a simple project that can be used for the examples in this guide. <markup lang=\"bash\" title=\"Run the Maven archetype:\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-se \\ -DarchetypeVersion=4.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-se \\ -Dpackage=io.helidon.examples.quickstart.se <markup lang=\"bash\" title=\"The project will be built and run from the helidon-quickstart-se directory:\" >cd helidon-quickstart-se ",
            "title": "Create a Sample Helidon SE Project"
        },
        {
            "location": "/se/guides/config",
            "text": " Helidon configuration sources can use different formats for the configuration data. You can specify the format on a per-source bases, mixing and matching formats as required. Here are the supported formats, each with the extension name you should use. By default, Helidon will determine the media type based on the extension name. Java Property (.properties) JSON (.json) YAML (.yaml) HOCON (.conf) The remainder of this document will use these formats in examples and show you how to configure Helidon to parse them. ",
            "title": "Configuration Formats"
        },
        {
            "location": "/se/guides/config",
            "text": " Helidon has an internal configuration, so you are not required to provide any configuration data for your application, though in practice you most likely would. By default, that configuration can be overridden from three sources: system properties, environment variables, and the contents of application.yaml in the classpath. For example, if you specify a custom server port in application.yaml then your server will listen on that port. In your application code, Helidon uses the default configuration when you create a default Config object. See the following code from the project you created. <markup lang=\"Java\" title=\"View Main.main :\" >Config config = Config.create(); The Config object is created with default settings. ",
            "title": "Default Configuration"
        },
        {
            "location": "/se/guides/config",
            "text": " An environment property has a higher precedence than application.yaml . <markup lang=\"bash\" title=\"Set the environment variable and restart the application:\" >export APP_GREETING=HelloFromEnvironment java -jar target/helidon-quickstart-se.jar <markup lang=\"bash\" title=\"Invoke the endpoint below and check the response:\" >curl http://localhost:8080/greet <markup lang=\"json\" >{ \"message\": \"HelloFromEnvironment World!\" } The environment property took precedence over application.yaml . ",
            "title": "Environment Variable Override"
        },
        {
            "location": "/se/guides/config",
            "text": " A system variable has a higher precedence than the environment property. <markup lang=\"bash\" title=\"Restart the application with a system property. The APP_GREETING environment variable is still set:\" >export APP_GREETING=HelloFromEnvironment java -Dapp.greeting=\"HelloFromSystemProperty\" -jar target/helidon-quickstart-se.jar <markup lang=\"bash\" title=\"Invoke the endpoint below and check the response:\" >curl http://localhost:8080/greet <markup lang=\"json\" >{ \"message\": \"HelloFromSystemProperty World!\" } The system variable app.greeting took precedence over the environment property and the value in application.yaml . ",
            "title": "System Property Override"
        },
        {
            "location": "/se/guides/config",
            "text": " Change a configuration parameter in the default configuration resource file, application.yaml . There are no environment variable or system property overrides defined. <markup lang=\"bash\" title=\"Change app.greeting in resources/application.yaml as follows:\" >app: greeting: HelloFrom-application.yaml <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-se.jar <markup lang=\"bash\" title=\"Run the curl command in a new terminal window and check the response:\" >curl http://localhost:8080/greet <markup lang=\"json\" >{ \"message\": \"HelloFrom-application.yaml World!\" } The new app.greeting value in application.yaml is used. Environment Variable Override An environment property has a higher precedence than application.yaml . <markup lang=\"bash\" title=\"Set the environment variable and restart the application:\" >export APP_GREETING=HelloFromEnvironment java -jar target/helidon-quickstart-se.jar <markup lang=\"bash\" title=\"Invoke the endpoint below and check the response:\" >curl http://localhost:8080/greet <markup lang=\"json\" >{ \"message\": \"HelloFromEnvironment World!\" } The environment property took precedence over application.yaml . System Property Override A system variable has a higher precedence than the environment property. <markup lang=\"bash\" title=\"Restart the application with a system property. The APP_GREETING environment variable is still set:\" >export APP_GREETING=HelloFromEnvironment java -Dapp.greeting=\"HelloFromSystemProperty\" -jar target/helidon-quickstart-se.jar <markup lang=\"bash\" title=\"Invoke the endpoint below and check the response:\" >curl http://localhost:8080/greet <markup lang=\"json\" >{ \"message\": \"HelloFromSystemProperty World!\" } The system variable app.greeting took precedence over the environment property and the value in application.yaml . ",
            "title": "Default Configuration Resource"
        },
        {
            "location": "/se/guides/config",
            "text": " In order to properly configure your application using configuration sources, you need to understand the precedence rules that Helidon uses to merge your configuration data. By default, Helidon will use the following sources in precedence order: Java system properties Environment variables Configuration specified in application.yaml If any of the Helidon required properties are not specified in one of these source, like server.port , then Helidon will use a default value. Because environment variable names are restricted to alphanumeric characters and underscore, Helidon adds aliases to the environment configuration source, allowing entries with dotted and/or hyphenated keys to be overridden. For example, this mapping allows an environment variable named \"APP_GREETING\" to override an entry key named \"app.greeting\". In the same way, an environment variable named \"APP_dash_GREETING\" will map to \"app-greeting\". See Advanced Config for more information. The following examples will demonstrate the default precedence order. Default Configuration Resource Change a configuration parameter in the default configuration resource file, application.yaml . There are no environment variable or system property overrides defined. <markup lang=\"bash\" title=\"Change app.greeting in resources/application.yaml as follows:\" >app: greeting: HelloFrom-application.yaml <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-se.jar <markup lang=\"bash\" title=\"Run the curl command in a new terminal window and check the response:\" >curl http://localhost:8080/greet <markup lang=\"json\" >{ \"message\": \"HelloFrom-application.yaml World!\" } The new app.greeting value in application.yaml is used. Environment Variable Override An environment property has a higher precedence than application.yaml . <markup lang=\"bash\" title=\"Set the environment variable and restart the application:\" >export APP_GREETING=HelloFromEnvironment java -jar target/helidon-quickstart-se.jar <markup lang=\"bash\" title=\"Invoke the endpoint below and check the response:\" >curl http://localhost:8080/greet <markup lang=\"json\" >{ \"message\": \"HelloFromEnvironment World!\" } The environment property took precedence over application.yaml . System Property Override A system variable has a higher precedence than the environment property. <markup lang=\"bash\" title=\"Restart the application with a system property. The APP_GREETING environment variable is still set:\" >export APP_GREETING=HelloFromEnvironment java -Dapp.greeting=\"HelloFromSystemProperty\" -jar target/helidon-quickstart-se.jar <markup lang=\"bash\" title=\"Invoke the endpoint below and check the response:\" >curl http://localhost:8080/greet <markup lang=\"json\" >{ \"message\": \"HelloFromSystemProperty World!\" } The system variable app.greeting took precedence over the environment property and the value in application.yaml . ",
            "title": "Source Precedence for Default Configuration"
        },
        {
            "location": "/se/guides/config",
            "text": " Helidon provides a very flexible and comprehensive configuration system, offering you many application configuration choices. You can include configuration data from a variety of sources using different formats, like JSON and YAML. Furthermore, you can customize the precedence of sources and make them optional or mandatory. This guide introduces Helidon SE configuration and demonstrates the fundamental concepts using several examples. Refer to Helidon Config for the full configuration concepts documentation. Create a Sample Helidon SE Project Use the Helidon SE Maven archetype to create a simple project that can be used for the examples in this guide. <markup lang=\"bash\" title=\"Run the Maven archetype:\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-se \\ -DarchetypeVersion=4.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-se \\ -Dpackage=io.helidon.examples.quickstart.se <markup lang=\"bash\" title=\"The project will be built and run from the helidon-quickstart-se directory:\" >cd helidon-quickstart-se Configuration Formats Helidon configuration sources can use different formats for the configuration data. You can specify the format on a per-source bases, mixing and matching formats as required. Here are the supported formats, each with the extension name you should use. By default, Helidon will determine the media type based on the extension name. Java Property (.properties) JSON (.json) YAML (.yaml) HOCON (.conf) The remainder of this document will use these formats in examples and show you how to configure Helidon to parse them. Default Configuration Helidon has an internal configuration, so you are not required to provide any configuration data for your application, though in practice you most likely would. By default, that configuration can be overridden from three sources: system properties, environment variables, and the contents of application.yaml in the classpath. For example, if you specify a custom server port in application.yaml then your server will listen on that port. In your application code, Helidon uses the default configuration when you create a default Config object. See the following code from the project you created. <markup lang=\"Java\" title=\"View Main.main :\" >Config config = Config.create(); The Config object is created with default settings. Source Precedence for Default Configuration In order to properly configure your application using configuration sources, you need to understand the precedence rules that Helidon uses to merge your configuration data. By default, Helidon will use the following sources in precedence order: Java system properties Environment variables Configuration specified in application.yaml If any of the Helidon required properties are not specified in one of these source, like server.port , then Helidon will use a default value. Because environment variable names are restricted to alphanumeric characters and underscore, Helidon adds aliases to the environment configuration source, allowing entries with dotted and/or hyphenated keys to be overridden. For example, this mapping allows an environment variable named \"APP_GREETING\" to override an entry key named \"app.greeting\". In the same way, an environment variable named \"APP_dash_GREETING\" will map to \"app-greeting\". See Advanced Config for more information. The following examples will demonstrate the default precedence order. Default Configuration Resource Change a configuration parameter in the default configuration resource file, application.yaml . There are no environment variable or system property overrides defined. <markup lang=\"bash\" title=\"Change app.greeting in resources/application.yaml as follows:\" >app: greeting: HelloFrom-application.yaml <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-se.jar <markup lang=\"bash\" title=\"Run the curl command in a new terminal window and check the response:\" >curl http://localhost:8080/greet <markup lang=\"json\" >{ \"message\": \"HelloFrom-application.yaml World!\" } The new app.greeting value in application.yaml is used. Environment Variable Override An environment property has a higher precedence than application.yaml . <markup lang=\"bash\" title=\"Set the environment variable and restart the application:\" >export APP_GREETING=HelloFromEnvironment java -jar target/helidon-quickstart-se.jar <markup lang=\"bash\" title=\"Invoke the endpoint below and check the response:\" >curl http://localhost:8080/greet <markup lang=\"json\" >{ \"message\": \"HelloFromEnvironment World!\" } The environment property took precedence over application.yaml . System Property Override A system variable has a higher precedence than the environment property. <markup lang=\"bash\" title=\"Restart the application with a system property. The APP_GREETING environment variable is still set:\" >export APP_GREETING=HelloFromEnvironment java -Dapp.greeting=\"HelloFromSystemProperty\" -jar target/helidon-quickstart-se.jar <markup lang=\"bash\" title=\"Invoke the endpoint below and check the response:\" >curl http://localhost:8080/greet <markup lang=\"json\" >{ \"message\": \"HelloFromSystemProperty World!\" } The system variable app.greeting took precedence over the environment property and the value in application.yaml . ",
            "title": "Getting Started with Configuration"
        },
        {
            "location": "/se/guides/config",
            "text": " Here is the full list of external config sources that you can use programmatically. Environment variables - the property is a name/value pair. Java system properties - the property is a name/value pair. Resources in the classpath - the contents of the resource is parsed according to its inferred format. File - the contents of the file is parsed according to its inferred format. Directory - each non-directory file in the directory becomes a config entry: the file name is the key. and the contents of that file are used as the corresponding config String value. A URL resource - contents is parsed according to its inferred format. You can also define custom sources, such as Git, and use them in your Helidon application. See Advanced Config for more information. ",
            "title": "Full List of Configuration Sources"
        },
        {
            "location": "/se/guides/config",
            "text": " The first custom resource example demonstrates how to add a second internal configuration resource that is discovered in the classpath . The code needs to build a Config object, which in turn is used to build the Server object. The Config object can be built using a Config.Builder , which lets you inject any number of sources into the builder. Furthermore, you can set precedence for the sources. The first source has highest precedence, then the next has second highest, and so forth. <markup lang=\"text\" title=\"Add a resource file, named config.properties to the resources directory with the following contents:\" >app.greeting=HelloFrom-config.properties <markup lang=\"java\" title=\"Update the Main class; 1) Add new imports, 2) Replace the Config.create() call with buildConfig() , and 3) Add buildConfig method:\" >import static io.helidon.config.ConfigSources.classpath; //... public static void main(final String[] args) { //... Config config = buildConfig(); private static Config buildConfig() { return Config.builder() .disableEnvironmentVariablesSource() .sources( classpath(\"config.properties\"), classpath(\"application.yaml\")) .build(); } Add new import statement. Call the new buildConfig method to build a Config object. Disable the environment variables as a source. Specify the new config.properties resource that is in the classpath . You must specify the existing application.yaml or Helidon will not use it as a configuration source even though it is considered a default source. <markup lang=\"bash\" title=\"Build and run the application (without the system property). Invoke the endpoint and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFrom-config.properties World!\" } The greeting was picked up from config.properties , overriding the value in application.yaml . It is important to remember that configuration from all sources is merged internally. If you have the same configuration property in multiple sources, then only the one with highest precedence will be used at runtime. This is true even the same property comes from sources with different formats. Swap the source order and run the test again. <markup lang=\"java\" title=\"Update the Main class and replace the buildConfig method:\" > private static Config buildConfig() { return Config.builder() .disableEnvironmentVariablesSource() .sources( classpath(\"application.yaml\"), classpath(\"config.properties\")) .build(); } Swap the source order, putting application.yaml first. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFrom-application.yaml World!\" } The file application.yaml was used to get the greeting since it now has precedence over config.properties . ",
            "title": "Classpath Sources"
        },
        {
            "location": "/se/guides/config",
            "text": " You can move all or part of your configuration to external files, making them optional or mandatory. The obvious advantage to this approach is that you do not need to rebuild your application to change configuration. In the following example, the app.greeting configuration property will be added to config-file.properties . <markup lang=\"bash\" title=\"Unset the environment variable so that disableEnvironmentVariablesSource doesn&#8217;t need to be called:\" >unset APP_GREETING <markup lang=\"bash\" title=\"Create a file named config-file.properties in the helidon-quickstart-se directory with the following contents:\" >app.greeting=HelloFrom-config-file.properties <markup lang=\"java\" title=\"Update the Main class; 1) Add new import and 2) Replace the buildConfig method:\" >import static io.helidon.config.ConfigSources.file; ... private static Config buildConfig() { return Config.builder() .sources( file(\"config-file.properties\"), classpath(\"application.yaml\")) .build(); } Add a mandatory configuration file. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFrom-config-file.properties World!\" } The configuration property from the file config-file.properties takes precedence. If you want the configuration file to be optional, you must use the optional method with sources , otherwise Helidon will generate an error during startup as shown below. This is true for both file and classpath sources. By default, these sources are mandatory. <markup lang=\"java\" title=\"Update the Main class and replace the buildConfig method:\" > private static Config buildConfig() { return Config.builder() .sources( file(\"missing-file\"), classpath(\"application.yaml\")) .build(); } Specify a file that doesn&#8217;t exist. <markup lang=\"bash\" title=\"Build then start the application and you will see the following output:\" >Exception in thread \"main\" io.helidon.config.ConfigException: Cannot load data from mandatory source FileConfig[missing-file]. File `missing-file` not found. To fix this, use the optional method as shown below, then rerun the test. ... file(\"missing-file\").optional(), The missing-file configuration file is now optional. ",
            "title": "External File Sources"
        },
        {
            "location": "/se/guides/config",
            "text": " If you have more than three sources, you can use the addSource method as shown below. <markup lang=\"java\" title=\"Update the Main class and replace the buildConfig method:\" > private static Config buildConfig() { return Config.builder() .addSource(directory(\"conf\")) .addSource(file(\"config-file.properties\")) .addSource(classpath(\"config.properties\").optional()) .addSource(classpath(\"application.yaml\")) .build(); } Add each config source using the addSource method. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFromFileInDirectoryConf World!\" } ",
            "title": "Exceeding Three Sources"
        },
        {
            "location": "/se/guides/config",
            "text": " A directory source treats every file in the directory as a key, and the file contents as the value. The following example includes a directory source as highest precedence. <markup lang=\"bash\" title=\"Create a new directory helidon-quickstart-se/conf then create a file named app.greeting in that directory with the following contents:\" >HelloFromFileInDirectoryConf <markup lang=\"java\" title=\"Update the Main class; 1) Add new import and 2) Replace the buildConfig method:\" >import static io.helidon.config.ConfigSources.directory; ... private static Config buildConfig() { return Config.builder() .sources( directory(\"conf\"), classpath(\"config.properties\").optional(), classpath(\"application.yaml\")) .build(); } Add a mandatory configuration directory. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFromFileInDirectoryConf World!\" } The greeting was fetched from the file named app.greeting . Exceeding Three Sources If you have more than three sources, you can use the addSource method as shown below. <markup lang=\"java\" title=\"Update the Main class and replace the buildConfig method:\" > private static Config buildConfig() { return Config.builder() .addSource(directory(\"conf\")) .addSource(file(\"config-file.properties\")) .addSource(classpath(\"config.properties\").optional()) .addSource(classpath(\"application.yaml\")) .build(); } Add each config source using the addSource method. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFromFileInDirectoryConf World!\" } ",
            "title": "Directory Source"
        },
        {
            "location": "/se/guides/config",
            "text": " Instead of directly specifying the configuration sources in your code, you can use a profile file that declares the configuration sources and their attributes. Simplest way to use a profile is to define a config-profile.yaml (and possible other files, such as config-profile-dev.yaml for dev profile) on classpath or on file system, and create config using Config.create() . The profile can be changed by a system property config.profile , or using an environment variable HELIDON_CONFIG_PROFILE . Profile file can use any supported format, following example is using YAML . <markup lang=\"yaml\" title=\"Create a file named config-profile.yaml in the helidon-quickstart-se directory with the following contents:\" >sources: - type: \"classpath\" properties: resource: \"application.yaml\" The source type. The name of the mandatory configuration resource. <markup lang=\"java\" title=\"Update the Main class and replace the buildConfig method:\" > private static Config buildConfig() { return Config.create(); } Will use config-profile.yaml by default <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFrom-application.yaml World!\" } The application.yaml resource file was used to get the greeting. The source precedence order in a profile file is the order of appearance in the file. This is demonstrated below where the config-file.properties has highest precedence. <markup lang=\"yaml\" title=\"Replace the contents of the config-profile.yaml file:\" >sources: - type: \"file\" properties: path: \"./config-file.properties\" - type: \"classpath\" properties: resource: \"application.yaml\" - type: \"file\" properties: path: \"optional-config-file\" optional: true The source type specifies a file. The name of the mandatory configuration file. Specify that the optional-config-file file is optional. <markup lang=\"bash\" title=\"Restart the application, then invoke the endpoint below and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFrom-config-file.properties World!\" } The config-file.properties source now takes precedence. When using a profile file, you need to explicitly include both environment variables and system properties as a source if you want to use them. <markup lang=\"bash\" title=\"Replace the contents of the config-profile.yaml file:\" >sources: - type: \"environment-variables\" - type: \"system-properties\" - type: \"classpath\" properties: resource: \"application.yaml\" - type: \"file\" properties: path: \"./config-file.properties\" Environment variables are now used as a source. System properties are now used as a source. You can re-run the previous tests that exercised environment variables and system properties. Swap the two types to see the precedence change. Be sure to unset APP_GREETING after you finish testing. ",
            "title": "Configuration Profiles"
        },
        {
            "location": "/se/guides/config",
            "text": " To use custom configuration sources, your application needs to specify the sources when it creates Config object. By doing this, you are in full control of all configuration sources and precedence. By default, the environment variable and system property sources are enabled, but you can disable them using the disableEnvironmentVariablesSource and disableSystemPropertiesSource methods. This section will show you how to use a custom configuration with various sources, formats, and precedence rules. Full List of Configuration Sources Here is the full list of external config sources that you can use programmatically. Environment variables - the property is a name/value pair. Java system properties - the property is a name/value pair. Resources in the classpath - the contents of the resource is parsed according to its inferred format. File - the contents of the file is parsed according to its inferred format. Directory - each non-directory file in the directory becomes a config entry: the file name is the key. and the contents of that file are used as the corresponding config String value. A URL resource - contents is parsed according to its inferred format. You can also define custom sources, such as Git, and use them in your Helidon application. See Advanced Config for more information. Classpath Sources The first custom resource example demonstrates how to add a second internal configuration resource that is discovered in the classpath . The code needs to build a Config object, which in turn is used to build the Server object. The Config object can be built using a Config.Builder , which lets you inject any number of sources into the builder. Furthermore, you can set precedence for the sources. The first source has highest precedence, then the next has second highest, and so forth. <markup lang=\"text\" title=\"Add a resource file, named config.properties to the resources directory with the following contents:\" >app.greeting=HelloFrom-config.properties <markup lang=\"java\" title=\"Update the Main class; 1) Add new imports, 2) Replace the Config.create() call with buildConfig() , and 3) Add buildConfig method:\" >import static io.helidon.config.ConfigSources.classpath; //... public static void main(final String[] args) { //... Config config = buildConfig(); private static Config buildConfig() { return Config.builder() .disableEnvironmentVariablesSource() .sources( classpath(\"config.properties\"), classpath(\"application.yaml\")) .build(); } Add new import statement. Call the new buildConfig method to build a Config object. Disable the environment variables as a source. Specify the new config.properties resource that is in the classpath . You must specify the existing application.yaml or Helidon will not use it as a configuration source even though it is considered a default source. <markup lang=\"bash\" title=\"Build and run the application (without the system property). Invoke the endpoint and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFrom-config.properties World!\" } The greeting was picked up from config.properties , overriding the value in application.yaml . It is important to remember that configuration from all sources is merged internally. If you have the same configuration property in multiple sources, then only the one with highest precedence will be used at runtime. This is true even the same property comes from sources with different formats. Swap the source order and run the test again. <markup lang=\"java\" title=\"Update the Main class and replace the buildConfig method:\" > private static Config buildConfig() { return Config.builder() .disableEnvironmentVariablesSource() .sources( classpath(\"application.yaml\"), classpath(\"config.properties\")) .build(); } Swap the source order, putting application.yaml first. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFrom-application.yaml World!\" } The file application.yaml was used to get the greeting since it now has precedence over config.properties . External File Sources You can move all or part of your configuration to external files, making them optional or mandatory. The obvious advantage to this approach is that you do not need to rebuild your application to change configuration. In the following example, the app.greeting configuration property will be added to config-file.properties . <markup lang=\"bash\" title=\"Unset the environment variable so that disableEnvironmentVariablesSource doesn&#8217;t need to be called:\" >unset APP_GREETING <markup lang=\"bash\" title=\"Create a file named config-file.properties in the helidon-quickstart-se directory with the following contents:\" >app.greeting=HelloFrom-config-file.properties <markup lang=\"java\" title=\"Update the Main class; 1) Add new import and 2) Replace the buildConfig method:\" >import static io.helidon.config.ConfigSources.file; ... private static Config buildConfig() { return Config.builder() .sources( file(\"config-file.properties\"), classpath(\"application.yaml\")) .build(); } Add a mandatory configuration file. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFrom-config-file.properties World!\" } The configuration property from the file config-file.properties takes precedence. If you want the configuration file to be optional, you must use the optional method with sources , otherwise Helidon will generate an error during startup as shown below. This is true for both file and classpath sources. By default, these sources are mandatory. <markup lang=\"java\" title=\"Update the Main class and replace the buildConfig method:\" > private static Config buildConfig() { return Config.builder() .sources( file(\"missing-file\"), classpath(\"application.yaml\")) .build(); } Specify a file that doesn&#8217;t exist. <markup lang=\"bash\" title=\"Build then start the application and you will see the following output:\" >Exception in thread \"main\" io.helidon.config.ConfigException: Cannot load data from mandatory source FileConfig[missing-file]. File `missing-file` not found. To fix this, use the optional method as shown below, then rerun the test. ... file(\"missing-file\").optional(), The missing-file configuration file is now optional. Directory Source A directory source treats every file in the directory as a key, and the file contents as the value. The following example includes a directory source as highest precedence. <markup lang=\"bash\" title=\"Create a new directory helidon-quickstart-se/conf then create a file named app.greeting in that directory with the following contents:\" >HelloFromFileInDirectoryConf <markup lang=\"java\" title=\"Update the Main class; 1) Add new import and 2) Replace the buildConfig method:\" >import static io.helidon.config.ConfigSources.directory; ... private static Config buildConfig() { return Config.builder() .sources( directory(\"conf\"), classpath(\"config.properties\").optional(), classpath(\"application.yaml\")) .build(); } Add a mandatory configuration directory. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFromFileInDirectoryConf World!\" } The greeting was fetched from the file named app.greeting . Exceeding Three Sources If you have more than three sources, you can use the addSource method as shown below. <markup lang=\"java\" title=\"Update the Main class and replace the buildConfig method:\" > private static Config buildConfig() { return Config.builder() .addSource(directory(\"conf\")) .addSource(file(\"config-file.properties\")) .addSource(classpath(\"config.properties\").optional()) .addSource(classpath(\"application.yaml\")) .build(); } Add each config source using the addSource method. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFromFileInDirectoryConf World!\" } Configuration Profiles Instead of directly specifying the configuration sources in your code, you can use a profile file that declares the configuration sources and their attributes. Simplest way to use a profile is to define a config-profile.yaml (and possible other files, such as config-profile-dev.yaml for dev profile) on classpath or on file system, and create config using Config.create() . The profile can be changed by a system property config.profile , or using an environment variable HELIDON_CONFIG_PROFILE . Profile file can use any supported format, following example is using YAML . <markup lang=\"yaml\" title=\"Create a file named config-profile.yaml in the helidon-quickstart-se directory with the following contents:\" >sources: - type: \"classpath\" properties: resource: \"application.yaml\" The source type. The name of the mandatory configuration resource. <markup lang=\"java\" title=\"Update the Main class and replace the buildConfig method:\" > private static Config buildConfig() { return Config.create(); } Will use config-profile.yaml by default <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFrom-application.yaml World!\" } The application.yaml resource file was used to get the greeting. The source precedence order in a profile file is the order of appearance in the file. This is demonstrated below where the config-file.properties has highest precedence. <markup lang=\"yaml\" title=\"Replace the contents of the config-profile.yaml file:\" >sources: - type: \"file\" properties: path: \"./config-file.properties\" - type: \"classpath\" properties: resource: \"application.yaml\" - type: \"file\" properties: path: \"optional-config-file\" optional: true The source type specifies a file. The name of the mandatory configuration file. Specify that the optional-config-file file is optional. <markup lang=\"bash\" title=\"Restart the application, then invoke the endpoint below and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFrom-config-file.properties World!\" } The config-file.properties source now takes precedence. When using a profile file, you need to explicitly include both environment variables and system properties as a source if you want to use them. <markup lang=\"bash\" title=\"Replace the contents of the config-profile.yaml file:\" >sources: - type: \"environment-variables\" - type: \"system-properties\" - type: \"classpath\" properties: resource: \"application.yaml\" - type: \"file\" properties: path: \"./config-file.properties\" Environment variables are now used as a source. System properties are now used as a source. You can re-run the previous tests that exercised environment variables and system properties. Swap the two types to see the precedence change. Be sure to unset APP_GREETING after you finish testing. ",
            "title": "Custom Configuration Sources"
        },
        {
            "location": "/se/guides/config",
            "text": " The simplest way to access configuration data is using a key, as shown below in the GreetService class. The key can be composite as shown below: <markup lang=\"java\" title=\"View the GreetService constructor:\" > GreetService() { greeting.set(Config.global().get(\"app.greeting\").asString().orElse(\"Ciao\")); } Get the app.greeting node using a composite key. You can also access the same greeting by navigating the nodes. <markup lang=\"java\" title=\"Replace the GreetService constructor with the following code:\" > GreetService() { greeting.set(Config.global().get(\"app\").get(\"greeting\").asString().orElse(\"Ciao\")); } Get the app node, then get the child node, greeting . <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFrom-application.yaml World!\" } ",
            "title": "Accessing Config Using Keys or Navigation"
        },
        {
            "location": "/se/guides/config",
            "text": " The Helidon Config class provides several methods that allow you to filter and customize the traversal of the configuration tree. The example below shows how to get the greeting node when you only know it is somewhere in the app subtree. <markup lang=\"bash\" title=\"Replace the contents of the config-profile.yaml file:\" >sources: - type: \"classpath\" properties: resource: \"application.yaml\" <markup lang=\"bash\" title=\"Replace the app section of the application.yaml resource file:\" >app: child1: child1-node child2: child2a: greeting: HelloFrom-application.yaml under child2a child3: child3-node <markup lang=\"java\" title=\"Update the GreetService.java file; 1) Add new imports and 2) Replace the GreetService constructor with the following:\" > import java.util.List; import java.util.stream.Collectors; GreetService() { List&lt;Config&gt; appGreetings = Config.global() .get(\"app\") .traverse() .filter(node -&gt; node.name().equals(\"greeting\")) .toList(); greeting.set(appGreetings.get(0).asString().get()); } Add new imports. Traverse the entire subtree of the app node. Include only nodes that have the name greeting . Add the greeting node to the collection. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFrom-application.yaml under child2a World!\" } ",
            "title": "Using Filters and Collections"
        },
        {
            "location": "/se/guides/config",
            "text": " Even though in-memory config trees are immutable, the config system internally records configuration source metadata that allows it to watch sources for changes. Your application listens for updates to the underlying config sources and reacts to the changes. See Config Mutability Support for a full discussion on this topic. The following example demonstrates how to listen and react to configuration changes. <markup lang=\"yaml\" title=\"Replace the contents of the config-profile.yaml file:\" >sources: - type: \"file\" properties: path: \"./config-file.properties\" change-watcher: type: \"file\" - type: \"classpath\" properties: resource: \"application.yaml\" <markup lang=\"java\" title=\"Update the GreetService class; 1) Add new import and 2) Replace the GreetService constructor:\" >import java.util.function.Consumer; ... GreetService() { Config greetingConfig = Config.global().get(\"app.greeting\"); greeting.set(greetingConfig.asString().orElse(\"Ciao\")); greetingConfig.onChange(cfg -&gt; greeting.set(cfg.asString().orElse(\"Ciao\"))); } Get the greeting Config node. Register a listener that will get called by Helidon when the configuration changes. The listener will update the greeting with the new value. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFrom-config-file.properties World!\" } <markup lang=\"bash\" title=\"Update config-file.properties with the following contents:\" >app.greeting=Updated HelloFrom-config-file.properties <markup lang=\"bash\" title=\"After a few seconds, check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"Updated HelloFrom-config-file.properties World!\" } The application reacted to the change and updated the greeting. ",
            "title": "Reacting to Configuration Updates"
        },
        {
            "location": "/se/guides/config",
            "text": " You have used Helidon to customize configuration behavior from your code using the Config and Config.Builder classes. As discussed previously, Helidon reads configuration from a config source, which uses a config parser to translate the source into an in-memory tree which represents the configuration’s structure and values. Helidon offers a variety of methods to access in-memory configuration. These can be categorized as key access or tree navigation . You have been using key access for all of the examples to this point. For example app.greeting is accessing the greeting child node of the app parent node. There are many options for access this data using navigation methods as described in Hierarchical Config and Advanced Config&gt; . Accessing Config Using Keys or Navigation The simplest way to access configuration data is using a key, as shown below in the GreetService class. The key can be composite as shown below: <markup lang=\"java\" title=\"View the GreetService constructor:\" > GreetService() { greeting.set(Config.global().get(\"app.greeting\").asString().orElse(\"Ciao\")); } Get the app.greeting node using a composite key. You can also access the same greeting by navigating the nodes. <markup lang=\"java\" title=\"Replace the GreetService constructor with the following code:\" > GreetService() { greeting.set(Config.global().get(\"app\").get(\"greeting\").asString().orElse(\"Ciao\")); } Get the app node, then get the child node, greeting . <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFrom-application.yaml World!\" } Using Filters and Collections The Helidon Config class provides several methods that allow you to filter and customize the traversal of the configuration tree. The example below shows how to get the greeting node when you only know it is somewhere in the app subtree. <markup lang=\"bash\" title=\"Replace the contents of the config-profile.yaml file:\" >sources: - type: \"classpath\" properties: resource: \"application.yaml\" <markup lang=\"bash\" title=\"Replace the app section of the application.yaml resource file:\" >app: child1: child1-node child2: child2a: greeting: HelloFrom-application.yaml under child2a child3: child3-node <markup lang=\"java\" title=\"Update the GreetService.java file; 1) Add new imports and 2) Replace the GreetService constructor with the following:\" > import java.util.List; import java.util.stream.Collectors; GreetService() { List&lt;Config&gt; appGreetings = Config.global() .get(\"app\") .traverse() .filter(node -&gt; node.name().equals(\"greeting\")) .toList(); greeting.set(appGreetings.get(0).asString().get()); } Add new imports. Traverse the entire subtree of the app node. Include only nodes that have the name greeting . Add the greeting node to the collection. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFrom-application.yaml under child2a World!\" } Reacting to Configuration Updates Even though in-memory config trees are immutable, the config system internally records configuration source metadata that allows it to watch sources for changes. Your application listens for updates to the underlying config sources and reacts to the changes. See Config Mutability Support for a full discussion on this topic. The following example demonstrates how to listen and react to configuration changes. <markup lang=\"yaml\" title=\"Replace the contents of the config-profile.yaml file:\" >sources: - type: \"file\" properties: path: \"./config-file.properties\" change-watcher: type: \"file\" - type: \"classpath\" properties: resource: \"application.yaml\" <markup lang=\"java\" title=\"Update the GreetService class; 1) Add new import and 2) Replace the GreetService constructor:\" >import java.util.function.Consumer; ... GreetService() { Config greetingConfig = Config.global().get(\"app.greeting\"); greeting.set(greetingConfig.asString().orElse(\"Ciao\")); greetingConfig.onChange(cfg -&gt; greeting.set(cfg.asString().orElse(\"Ciao\"))); } Get the greeting Config node. Register a listener that will get called by Helidon when the configuration changes. The listener will update the greeting with the new value. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFrom-config-file.properties World!\" } <markup lang=\"bash\" title=\"Update config-file.properties with the following contents:\" >app.greeting=Updated HelloFrom-config-file.properties <markup lang=\"bash\" title=\"After a few seconds, check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"Updated HelloFrom-config-file.properties World!\" } The application reacted to the change and updated the greeting. ",
            "title": "Accessing Config within an Application"
        },
        {
            "location": "/se/guides/config",
            "text": " The following example uses a Kubernetes ConfigMap to pass the configuration data to your Helidon application deployed to Kubernetes. When the pod is created, Kubernetes will automatically create a local file within the container that has the contents of the configuration file used for the ConfigMap. This example will create the file at /etc/config/config-file.properties . <markup lang=\"bash\" title=\"Replace the app section of the application.yaml resource file:\" >app: greeting: \"Hello\" <markup lang=\"java\" title=\"Update the Main class and replace the buildConfig method:\" > private static Config buildConfig() { return Config.builder() .sources( file(\"/etc/config/config-file.properties\").optional(), classpath(\"application.yaml\")) .build(); } The app.greeting value will be fetched from /etc/config/config-file.properties within the container. The server port is specified in application.yaml within the helidon-quickstart-se.jar . <markup lang=\"java\" title=\"Replace the GreetService constructor with the following code:\" > GreetService() { greeting.set(Config.global().get(\"app.greeting\").asString().orElse(\"Ciao\")); } <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"Hello World!\" } The greeting came from application.yaml since /etc/config/config-file.properties doesn&#8217;t exist. <markup lang=\"bash\" title=\"Stop the application and build the docker image:\" >docker build -t helidon-config-se . <markup lang=\"bash\" title=\"Generate a ConfigMap from config-file.properties :\" >kubectl create configmap helidon-configmap --from-file config-file.properties <markup lang=\"bash\" title=\"View the contents of the ConfigMap:\" >kubectl get configmap helidon-configmap -o yaml ... apiVersion: v1 data: config-file.properties: | app.greeting=Updated HelloFrom-config-file.properties kind: ConfigMap ... The file config-file.properties will be created within the Kubernetes container. The config-file.properties file will have this single property defined. <markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named k8s-config.yaml , with the following contents:\" >kind: Service apiVersion: v1 metadata: name: helidon-config labels: app: helidon-config spec: type: NodePort selector: app: helidon-config ports: - port: 8080 targetPort: 8080 name: http --- kind: Deployment apiVersion: apps/v1 metadata: name: helidon-config spec: replicas: 1 selector: matchLabels: app: helidon-config template: metadata: labels: app: helidon-config version: v1 spec: containers: - name: helidon-config image: helidon-config-se imagePullPolicy: IfNotPresent ports: - containerPort: 8080 volumeMounts: - name: config-volume mountPath: /etc/config volumes: - name: config-volume configMap: # Provide the name of the ConfigMap containing the files you want # to add to the container name: helidon-configmap A service of type NodePort that serves the default routes on port 8080 . A deployment with one replica of a pod. Mount the ConfigMap as a volume at /etc/config . This is where Kubernetes will create config-file.properties . Specify the ConfigMap which contains the configuration data. <markup lang=\"bash\" title=\"Create and deploy the application into Kubernetes:\" >kubectl apply -f ./k8s-config.yaml <markup lang=\"bash\" title=\"Get the service information:\" >kubectl get service/helidon-config <markup lang=\"bash\" >NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE helidon-config NodePort 10.99.159.2 &lt;none&gt; 8080:31143/TCP 8s A service of type NodePort that serves the default routes on port 31143 . <markup lang=\"bash\" title=\"Verify the configuration endpoint using port 31143 , your port will likely be different:\" >curl http://localhost:31143/greet ... { \"message\": \"Updated HelloFrom-config-file.properties World!\" } The greeting value from /etc/config/config-file.properties within the container was used. You can now delete the Kubernetes resources that were just created during this example. <markup lang=\"bash\" title=\"Delete the Kubernetes resources:\" >kubectl delete -f ./k8s-config.yaml kubectl delete configmap helidon-configmap ",
            "title": "Integration with Kubernetes"
        },
        {
            "location": "/se/guides/config",
            "text": " This guide has demonstrated how to use basic Helidon configuration features. The full configuration documentation, starting with the introduction section at Helidon Config has much more information including the following: Architecture Parsers Extensions Filters Hierarchical Access Property Mapping Mutability Support and more&#8230;&#8203; Refer to the following references for additional information: Helidon Javadoc ",
            "title": "Summary"
        },
        {
            "location": "/se/guides/dbclient",
            "text": " This guide describes the features of Helidon&#8217;s DB Client and how to create a sample Helidon SE project that can be used to run some basic examples using the Helidon DB Client. ",
            "title": "preambule"
        },
        {
            "location": "/se/guides/dbclient",
            "text": " For this 15 minute tutorial, you will need the following: <div class=\"table__overflow elevation-1 flex sm7 \"> A Helidon SE Application You can use your own application or use the Helidon SE Quickstart to create a sample application. Java&#160;SE&#160;21 ( Open&#160;JDK&#160;21 ) Helidon requires Java 21+. Maven 3.8+ Helidon requires Maven 3.8+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop . <markup lang=\"bash\" title=\"Verify Prerequisites\" >java -version mvn --version docker --version kubectl version --short <markup lang=\"bash\" title=\"Setting JAVA_HOME\" ># On Mac export JAVA_HOME=`/usr/libexec/java_home -v 21` # On Linux # Use the appropriate path to your JDK export JAVA_HOME=/usr/lib/jvm/jdk-21 ",
            "title": "What You Need"
        },
        {
            "location": "/se/guides/dbclient",
            "text": " The main features of Helidon DB Client are: Unified API for data access and query : The API was implemented as a layer above JDBC or MongoDB Java Driver, so any relational databases with JDBC driver or MongoDB are supported. Observability : Support for health checks, metrics and tracing. Portability between relational database drivers : Works with native database statements that can be used inline in the code or defined as named statements in database configuration. By moving the native query code to configuration files, the Helidon DB Client allows you to switch to another database by changing the configuration files, not the code. ",
            "title": "Main Features"
        },
        {
            "location": "/se/guides/dbclient",
            "text": " The Helidon DB Client provides a unified API for working with databases. Main Features The main features of Helidon DB Client are: Unified API for data access and query : The API was implemented as a layer above JDBC or MongoDB Java Driver, so any relational databases with JDBC driver or MongoDB are supported. Observability : Support for health checks, metrics and tracing. Portability between relational database drivers : Works with native database statements that can be used inline in the code or defined as named statements in database configuration. By moving the native query code to configuration files, the Helidon DB Client allows you to switch to another database by changing the configuration files, not the code. ",
            "title": "Introduction"
        },
        {
            "location": "/se/guides/dbclient",
            "text": " Create a new file in helidon-quickstart-se named Dockerfile.h2 . It will be used to create the H2 docker image to run H2 in a container. <markup lang=\"dockerfile\" title=\"Write the following content into the new file created\" >FROM openjdk:11-jre-slim ENV H2_VERSION \"1.4.199\" ADD \"https://repo1.maven.org/maven2/com/h2database/h2/${H2_VERSION}/h2-${H2_VERSION}.jar\" /opt/h2.jar COPY h2.server.properties /root/.h2.server.properties EXPOSE 8082 EXPOSE 9092 CMD java \\ -cp /opt/h2.jar \\ org.h2.tools.Server \\ -web -webDaemon -webAllowOthers -webPort 8082 \\ -tcp -tcpAllowOthers -tcpPort 9092 \\ -ifNotExists Create a new file h2.server.properties in the current directory. <markup lang=\"properties\" title=\"Copy the properties into the properties file.\" >webSSL=false webAllowOthers=true webPort=8082 0=Generic H2 (Server)|org.h2.Driver|jdbc\\:h2\\:tcp\\://localhost\\:9092/~/test|sa <markup lang=\"bash\" title=\"Build the H2 docker image\" >docker build -f Dockerfile.h2 . -t h2db <markup lang=\"bash\" title=\"Run the H2 docker image\" >docker run --rm -p 8082:8082 -p 9092:9092 --name=h2 -it h2db ",
            "title": "From Docker"
        },
        {
            "location": "/se/guides/dbclient",
            "text": " A database stores the books from the library. H2 is a java SQL database that is easy to use and lightweight. If H2 is not installed on your machine, here are few steps to quickly download and set it up: Download the latest H2 version from the official website: https://www.h2database.com/html/main.html Note: Windows operating system users can download the Windows Installer. Unzip the downloaded file into your directory. Only the h2-{latest-version}.jar, located in the h2/bin folder, will be needed. Open a terminal window and run the following command to start H2:. <markup lang=\"bash\" title=\"Replace {latest-version} with your current H2 version:\" >java -cp h2-{latest-version}.jar org.h2.tools.Shell -url dbc:h2:~/test -user sa -password \"\" -sql \"\" java -jar h2-{latest-version}.jar -webAllowOthers -tcpAllowOthers -web -tcp Pre-create the database (optional if the file ~/test already exists) Start the database ",
            "title": "From the Command Line"
        },
        {
            "location": "/se/guides/dbclient",
            "text": " From Docker Create a new file in helidon-quickstart-se named Dockerfile.h2 . It will be used to create the H2 docker image to run H2 in a container. <markup lang=\"dockerfile\" title=\"Write the following content into the new file created\" >FROM openjdk:11-jre-slim ENV H2_VERSION \"1.4.199\" ADD \"https://repo1.maven.org/maven2/com/h2database/h2/${H2_VERSION}/h2-${H2_VERSION}.jar\" /opt/h2.jar COPY h2.server.properties /root/.h2.server.properties EXPOSE 8082 EXPOSE 9092 CMD java \\ -cp /opt/h2.jar \\ org.h2.tools.Server \\ -web -webDaemon -webAllowOthers -webPort 8082 \\ -tcp -tcpAllowOthers -tcpPort 9092 \\ -ifNotExists Create a new file h2.server.properties in the current directory. <markup lang=\"properties\" title=\"Copy the properties into the properties file.\" >webSSL=false webAllowOthers=true webPort=8082 0=Generic H2 (Server)|org.h2.Driver|jdbc\\:h2\\:tcp\\://localhost\\:9092/~/test|sa <markup lang=\"bash\" title=\"Build the H2 docker image\" >docker build -f Dockerfile.h2 . -t h2db <markup lang=\"bash\" title=\"Run the H2 docker image\" >docker run --rm -p 8082:8082 -p 9092:9092 --name=h2 -it h2db From the Command Line A database stores the books from the library. H2 is a java SQL database that is easy to use and lightweight. If H2 is not installed on your machine, here are few steps to quickly download and set it up: Download the latest H2 version from the official website: https://www.h2database.com/html/main.html Note: Windows operating system users can download the Windows Installer. Unzip the downloaded file into your directory. Only the h2-{latest-version}.jar, located in the h2/bin folder, will be needed. Open a terminal window and run the following command to start H2:. <markup lang=\"bash\" title=\"Replace {latest-version} with your current H2 version:\" >java -cp h2-{latest-version}.jar org.h2.tools.Shell -url dbc:h2:~/test -user sa -password \"\" -sql \"\" java -jar h2-{latest-version}.jar -webAllowOthers -tcpAllowOthers -web -tcp Pre-create the database (optional if the file ~/test already exists) Start the database ",
            "title": "Set Up the H2 Database"
        },
        {
            "location": "/se/guides/dbclient",
            "text": " Open the console at http://127.0.0.1:8082 in your favorite browser. It displays a login window. Select Generic H2 from Saved Settings . The following settings should be set by default: Driver Class: org.h2.Driver JDBC URL: jdbc:h2:tcp://localhost:9092/~/test User Name: sa Password: Password must stay empty. Click Connect , the browser displays a web page. The database is correctly set and running. ",
            "title": "Connect to the Database"
        },
        {
            "location": "/se/guides/dbclient",
            "text": " Generate the project sources using the Helidon SE Maven archetype. The result is a simple project that can be used for the examples in this guide. <markup lang=\"bash\" title=\"Run the Maven archetype:\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-se \\ -DarchetypeVersion=4.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-se \\ -Dpackage=io.helidon.examples.quickstart.se A new directory named helidon-quickstart-se is created. <markup lang=\"bash\" title=\"Enter into this directory:\" >cd helidon-quickstart-se ",
            "title": "Create a Sample SE Project Using Maven Archetype"
        },
        {
            "location": "/se/guides/dbclient",
            "text": " Navigate to the helidon-quickstart-se directory and open the pom.xml file to add the following Helidon dependencies required to use the DB Client: <markup lang=\"xml\" title=\"Copy these dependencies to pom.xml:\" >&lt;dependencies&gt; &lt;!-- ... --&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.dbclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-dbclient&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.dbclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-dbclient-jdbc&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.dbclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-dbclient-hikari&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.db&lt;/groupId&gt; &lt;artifactId&gt;h2&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-jdk14&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.dbclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-dbclient-health&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.dbclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-dbclient-metrics&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.dbclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-dbclient-metrics-hikari&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.dbclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-dbclient-jsonp&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- ... --&gt; &lt;/dependencies&gt; DB Client API dependency. Using JDBC driver for this example. Using HikariCP as a connection pool. H2 driver dependency. Support for health check. Support for metrics. Support for Jsonp. ",
            "title": "Add Dependencies"
        },
        {
            "location": "/se/guides/dbclient",
            "text": " To configure the application, Helidon uses the application.yaml . The DB Client configuration can be joined in the same file and is located here: src/main/resources . <markup lang=\"yaml\" title=\"Copy these properties into application.yaml\" >db: source: jdbc connection: url: \"jdbc:h2:tcp://localhost:9092/~/test\" username: \"sa\" password: statements: health-check: \"SELECT 0\" create-table: \"CREATE TABLE IF NOT EXISTS LIBRARY (NAME VARCHAR NOT NULL, INFO VARCHAR NOT NULL)\" insert-book: \"INSERT INTO LIBRARY (NAME, INFO) VALUES (:name, :info)\" select-book: \"SELECT INFO FROM LIBRARY WHERE NAME = ?\" delete-book: \"DELETE FROM LIBRARY WHERE NAME = ?\" health-check: type: \"query\" statementName: \"health-check\" services: metrics: - type: COUNTER statement-names: [ \"select-book\" ] Source property support two values: jdbc and mongo. Connection detail we used to set up H2. SQL statements to manage the database. Add a counter for metrics only for the select-book statement. <markup lang=\"yaml\" title=\"Copy these properties into application-test.yaml\" >db: connection: url: \"jdbc:h2:mem:test\" Override the JDBC URL to use an in-memory database for the tests ",
            "title": "Configure the DB Client"
        },
        {
            "location": "/se/guides/dbclient",
            "text": "<markup lang=\"java\" title=\"Update the main method in Main.java \" >public static void main(String[] args) { // load logging configuration LogConfig.configureRuntime(); // initialize global config from default configuration Config config = Config.create(); Config.global(config); DbClient dbClient = DbClient.create(config.get(\"db\")); Contexts.globalContext().register(dbClient); ObserveFeature observe = ObserveFeature.builder() .config(config.get(\"server.features.observe\")) .addObserver(HealthObserver.builder() .useSystemServices(false) .details(true) .addCheck(DbClientHealthCheck.create(dbClient, config.get(\"db.health-check\"))) .build()) .build(); WebServer server = WebServer.builder() .config(config.get(\"server\")) .addFeature(observe) .routing(Main::routing) .build() .start(); System.out.println(\"WEB server is up! http://localhost:\" + server.port() + \"/simple-greet\"); } Create the DbClient instance Register it in the global context Create an instance of ObserveFeature to register a DbClientHealthCheck Register the ObserveFeature on the server ",
            "title": "Set Up Helidon DB Client"
        },
        {
            "location": "/se/guides/dbclient",
            "text": " Create LibraryService class into io.helidon.examples.quickstart.se package. <markup lang=\"java\" title=\"LibraryService class looks like this:\" >package io.helidon.examples.quickstart.se; import io.helidon.common.context.Contexts; import io.helidon.config.Config; import io.helidon.dbclient.DbClient; import io.helidon.http.NotFoundException; import io.helidon.http.Status; import io.helidon.webserver.http.HttpRules; import io.helidon.webserver.http.HttpService; import io.helidon.webserver.http.ServerRequest; import io.helidon.webserver.http.ServerResponse; import jakarta.json.JsonObject; public class LibraryService implements HttpService { private final DbClient dbClient; LibraryService() { this.dbClient = Contexts.globalContext() .get(DbClient.class) .orElseGet(() -&gt; DbClient.create(Config.global().get(\"db\"))); dbClient.execute().namedDml(\"create-table\"); } } Add new import statement Declare the DB Client instance Initialize the DB Client instance using global config Initialize the database schema As the LibraryService implements io.helidon.webserver.HttpService , the routing(HttpRules) method has to be implemented. It defines application endpoints and Http request which can be reached by clients. <markup lang=\"java\" title=\"Add update method to LibraryService\" >@Override public void routing(HttpRules rules) { rules .get(\"/{name}\", this::getBook) .put(\"/{name}\", this::addBook) .delete(\"/{name}\", this::deleteBook) .get(\"/json/{name}\", this::getJsonBook); } Return information about the required book from the database. Add a book to the library. Remove a book from the library. Return the book information in Json format. To summarize, there is one endpoint that can manipulate books. The number of endpoints and application features can be changed from these rules by creating or modifying methods. {name} is a path parameter for the book name. The architecture of the application is defined, so the next step is to create these features. <markup lang=\"java\" title=\"Add getBook to the LibraryService:\" >private void getBook(ServerRequest serverRequest, ServerResponse serverResponse) { String bookName = serverRequest.path().pathParameters().get(\"name\"); String bookInfo = dbClient.execute().namedGet(\"select-book\", bookName) .map(row -&gt; row.column(\"INFO\").asString().get()) .orElseThrow(() -&gt; new NotFoundException(\"Book not found: \" + bookName)); serverResponse.send(bookInfo); } Get the book name from the path in the URL. Helidon DB Client executes the select-book SQL script from application.yaml. Sends 404 HTTP status if no book was found for the given name. Sends book information to the client. The getBook method reach the book from the database and send the information to the client. The name of the book is located into the url path. If the book is not present in the database, an HTTP 404 is sent back. The execute() method is called on the dbClient instance to execute one statement. Nevertheless, it is possible to execute a set of tasks into a single execution unit by using the transaction() method. DbExecute class provides many builders to create statements such as, DML, insert, update, delete, query and get statements. For each statement there are two builders which can be regrouped in 2 categories. Builders with methods containing Named keyword, they use a statement defined in the configuration file. And builders without Named keyword, they use a statement passed as an argument. More information on the Helidon DB Client here . <markup lang=\"java\" title=\"Add getJsonBook to the LibraryService:\" >private void getJsonBook(ServerRequest serverRequest, ServerResponse serverResponse) { String bookName = serverRequest.path().pathParameters().get(\"name\"); JsonObject bookJson = dbClient.execute().namedGet(\"select-book\", bookName) .map(row -&gt; row.as(JsonObject.class)) .orElseThrow(() -&gt; new NotFoundException(\"Book not found: \" + bookName)); serverResponse.send(bookJson); } Instead of sending the INFO content of the targeted book, the getJsonBook method send the whole row of the database as a JsonObject . <markup lang=\"java\" title=\"Add addBook to the LibraryService:\" >private void addBook(ServerRequest serverRequest, ServerResponse serverResponse) { String bookName = serverRequest.path().pathParameters().get(\"name\"); String newValue = serverRequest.content().as(String.class); dbClient.execute().createNamedInsert(\"insert-book\") .addParam(\"name\", bookName) .addParam(\"info\", newValue) .execute(); serverResponse.status(Status.CREATED_201).send(); } The SQL statement requires the book name and its information. They are provided with addParam method. A new book was added to library, so a HTTP 201 code is returned. When a user adds a new book, it uses HTTP PUT method where the book name is in the URL and the information in the request content. To catch this content, the information is retrieved as a string and then the DB Client execute the insert-book script to add the book to the library. It requires two parameters, the book name and information which are passed to the dbClient thanks to addParam method. A HTTP 201 is sent back as a confirmation. <markup lang=\"java\" title=\"Add deleteBook to LibraryService:\" >private void deleteBook(ServerRequest serverRequest, ServerResponse serverResponse) { String bookName = serverRequest.path().pathParameters().get(\"name\"); dbClient.execute().namedDelete(\"delete-book\", bookName); serverResponse.status(Status.NO_CONTENT_204).send(); } Execute SQL script from application.yaml to remove a book from the library by its name. The required book was removed, so a HTTP 204 is sent. To remove a book from the library, use the \"delete-book\" script in the way than previously. If the book is removed successfully, a HTTP 204 is sent back. ",
            "title": "Create the Library service"
        },
        {
            "location": "/se/guides/dbclient",
            "text": "<markup lang=\"java\" title=\"Modify the routing method in Main.java :\" >static void routing(HttpRouting.Builder routing) { routing .register(\"/greet\", new GreetService()) .register(\"/library\", new LibraryService()) .get(\"/simple-greet\", (req, res) -&gt; res.send(\"Hello World!\")); } Register the LibraryService to the Routing. The library service does not yet exist, but you&#8217;ll create it in the next step of the guide. ",
            "title": "Set Up Routing"
        },
        {
            "location": "/se/guides/dbclient",
            "text": " This section describes how to configure and use the key features of the Helidon DB Client. Set Up the H2 Database From Docker Create a new file in helidon-quickstart-se named Dockerfile.h2 . It will be used to create the H2 docker image to run H2 in a container. <markup lang=\"dockerfile\" title=\"Write the following content into the new file created\" >FROM openjdk:11-jre-slim ENV H2_VERSION \"1.4.199\" ADD \"https://repo1.maven.org/maven2/com/h2database/h2/${H2_VERSION}/h2-${H2_VERSION}.jar\" /opt/h2.jar COPY h2.server.properties /root/.h2.server.properties EXPOSE 8082 EXPOSE 9092 CMD java \\ -cp /opt/h2.jar \\ org.h2.tools.Server \\ -web -webDaemon -webAllowOthers -webPort 8082 \\ -tcp -tcpAllowOthers -tcpPort 9092 \\ -ifNotExists Create a new file h2.server.properties in the current directory. <markup lang=\"properties\" title=\"Copy the properties into the properties file.\" >webSSL=false webAllowOthers=true webPort=8082 0=Generic H2 (Server)|org.h2.Driver|jdbc\\:h2\\:tcp\\://localhost\\:9092/~/test|sa <markup lang=\"bash\" title=\"Build the H2 docker image\" >docker build -f Dockerfile.h2 . -t h2db <markup lang=\"bash\" title=\"Run the H2 docker image\" >docker run --rm -p 8082:8082 -p 9092:9092 --name=h2 -it h2db From the Command Line A database stores the books from the library. H2 is a java SQL database that is easy to use and lightweight. If H2 is not installed on your machine, here are few steps to quickly download and set it up: Download the latest H2 version from the official website: https://www.h2database.com/html/main.html Note: Windows operating system users can download the Windows Installer. Unzip the downloaded file into your directory. Only the h2-{latest-version}.jar, located in the h2/bin folder, will be needed. Open a terminal window and run the following command to start H2:. <markup lang=\"bash\" title=\"Replace {latest-version} with your current H2 version:\" >java -cp h2-{latest-version}.jar org.h2.tools.Shell -url dbc:h2:~/test -user sa -password \"\" -sql \"\" java -jar h2-{latest-version}.jar -webAllowOthers -tcpAllowOthers -web -tcp Pre-create the database (optional if the file ~/test already exists) Start the database Connect to the Database Open the console at http://127.0.0.1:8082 in your favorite browser. It displays a login window. Select Generic H2 from Saved Settings . The following settings should be set by default: Driver Class: org.h2.Driver JDBC URL: jdbc:h2:tcp://localhost:9092/~/test User Name: sa Password: Password must stay empty. Click Connect , the browser displays a web page. The database is correctly set and running. Create a Sample SE Project Using Maven Archetype Generate the project sources using the Helidon SE Maven archetype. The result is a simple project that can be used for the examples in this guide. <markup lang=\"bash\" title=\"Run the Maven archetype:\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-se \\ -DarchetypeVersion=4.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-se \\ -Dpackage=io.helidon.examples.quickstart.se A new directory named helidon-quickstart-se is created. <markup lang=\"bash\" title=\"Enter into this directory:\" >cd helidon-quickstart-se Add Dependencies Navigate to the helidon-quickstart-se directory and open the pom.xml file to add the following Helidon dependencies required to use the DB Client: <markup lang=\"xml\" title=\"Copy these dependencies to pom.xml:\" >&lt;dependencies&gt; &lt;!-- ... --&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.dbclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-dbclient&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.dbclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-dbclient-jdbc&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.dbclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-dbclient-hikari&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.db&lt;/groupId&gt; &lt;artifactId&gt;h2&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-jdk14&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.dbclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-dbclient-health&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.dbclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-dbclient-metrics&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.dbclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-dbclient-metrics-hikari&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.dbclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-dbclient-jsonp&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- ... --&gt; &lt;/dependencies&gt; DB Client API dependency. Using JDBC driver for this example. Using HikariCP as a connection pool. H2 driver dependency. Support for health check. Support for metrics. Support for Jsonp. Configure the DB Client To configure the application, Helidon uses the application.yaml . The DB Client configuration can be joined in the same file and is located here: src/main/resources . <markup lang=\"yaml\" title=\"Copy these properties into application.yaml\" >db: source: jdbc connection: url: \"jdbc:h2:tcp://localhost:9092/~/test\" username: \"sa\" password: statements: health-check: \"SELECT 0\" create-table: \"CREATE TABLE IF NOT EXISTS LIBRARY (NAME VARCHAR NOT NULL, INFO VARCHAR NOT NULL)\" insert-book: \"INSERT INTO LIBRARY (NAME, INFO) VALUES (:name, :info)\" select-book: \"SELECT INFO FROM LIBRARY WHERE NAME = ?\" delete-book: \"DELETE FROM LIBRARY WHERE NAME = ?\" health-check: type: \"query\" statementName: \"health-check\" services: metrics: - type: COUNTER statement-names: [ \"select-book\" ] Source property support two values: jdbc and mongo. Connection detail we used to set up H2. SQL statements to manage the database. Add a counter for metrics only for the select-book statement. <markup lang=\"yaml\" title=\"Copy these properties into application-test.yaml\" >db: connection: url: \"jdbc:h2:mem:test\" Override the JDBC URL to use an in-memory database for the tests Set Up Helidon DB Client <markup lang=\"java\" title=\"Update the main method in Main.java \" >public static void main(String[] args) { // load logging configuration LogConfig.configureRuntime(); // initialize global config from default configuration Config config = Config.create(); Config.global(config); DbClient dbClient = DbClient.create(config.get(\"db\")); Contexts.globalContext().register(dbClient); ObserveFeature observe = ObserveFeature.builder() .config(config.get(\"server.features.observe\")) .addObserver(HealthObserver.builder() .useSystemServices(false) .details(true) .addCheck(DbClientHealthCheck.create(dbClient, config.get(\"db.health-check\"))) .build()) .build(); WebServer server = WebServer.builder() .config(config.get(\"server\")) .addFeature(observe) .routing(Main::routing) .build() .start(); System.out.println(\"WEB server is up! http://localhost:\" + server.port() + \"/simple-greet\"); } Create the DbClient instance Register it in the global context Create an instance of ObserveFeature to register a DbClientHealthCheck Register the ObserveFeature on the server Create the Library service Create LibraryService class into io.helidon.examples.quickstart.se package. <markup lang=\"java\" title=\"LibraryService class looks like this:\" >package io.helidon.examples.quickstart.se; import io.helidon.common.context.Contexts; import io.helidon.config.Config; import io.helidon.dbclient.DbClient; import io.helidon.http.NotFoundException; import io.helidon.http.Status; import io.helidon.webserver.http.HttpRules; import io.helidon.webserver.http.HttpService; import io.helidon.webserver.http.ServerRequest; import io.helidon.webserver.http.ServerResponse; import jakarta.json.JsonObject; public class LibraryService implements HttpService { private final DbClient dbClient; LibraryService() { this.dbClient = Contexts.globalContext() .get(DbClient.class) .orElseGet(() -&gt; DbClient.create(Config.global().get(\"db\"))); dbClient.execute().namedDml(\"create-table\"); } } Add new import statement Declare the DB Client instance Initialize the DB Client instance using global config Initialize the database schema As the LibraryService implements io.helidon.webserver.HttpService , the routing(HttpRules) method has to be implemented. It defines application endpoints and Http request which can be reached by clients. <markup lang=\"java\" title=\"Add update method to LibraryService\" >@Override public void routing(HttpRules rules) { rules .get(\"/{name}\", this::getBook) .put(\"/{name}\", this::addBook) .delete(\"/{name}\", this::deleteBook) .get(\"/json/{name}\", this::getJsonBook); } Return information about the required book from the database. Add a book to the library. Remove a book from the library. Return the book information in Json format. To summarize, there is one endpoint that can manipulate books. The number of endpoints and application features can be changed from these rules by creating or modifying methods. {name} is a path parameter for the book name. The architecture of the application is defined, so the next step is to create these features. <markup lang=\"java\" title=\"Add getBook to the LibraryService:\" >private void getBook(ServerRequest serverRequest, ServerResponse serverResponse) { String bookName = serverRequest.path().pathParameters().get(\"name\"); String bookInfo = dbClient.execute().namedGet(\"select-book\", bookName) .map(row -&gt; row.column(\"INFO\").asString().get()) .orElseThrow(() -&gt; new NotFoundException(\"Book not found: \" + bookName)); serverResponse.send(bookInfo); } Get the book name from the path in the URL. Helidon DB Client executes the select-book SQL script from application.yaml. Sends 404 HTTP status if no book was found for the given name. Sends book information to the client. The getBook method reach the book from the database and send the information to the client. The name of the book is located into the url path. If the book is not present in the database, an HTTP 404 is sent back. The execute() method is called on the dbClient instance to execute one statement. Nevertheless, it is possible to execute a set of tasks into a single execution unit by using the transaction() method. DbExecute class provides many builders to create statements such as, DML, insert, update, delete, query and get statements. For each statement there are two builders which can be regrouped in 2 categories. Builders with methods containing Named keyword, they use a statement defined in the configuration file. And builders without Named keyword, they use a statement passed as an argument. More information on the Helidon DB Client here . <markup lang=\"java\" title=\"Add getJsonBook to the LibraryService:\" >private void getJsonBook(ServerRequest serverRequest, ServerResponse serverResponse) { String bookName = serverRequest.path().pathParameters().get(\"name\"); JsonObject bookJson = dbClient.execute().namedGet(\"select-book\", bookName) .map(row -&gt; row.as(JsonObject.class)) .orElseThrow(() -&gt; new NotFoundException(\"Book not found: \" + bookName)); serverResponse.send(bookJson); } Instead of sending the INFO content of the targeted book, the getJsonBook method send the whole row of the database as a JsonObject . <markup lang=\"java\" title=\"Add addBook to the LibraryService:\" >private void addBook(ServerRequest serverRequest, ServerResponse serverResponse) { String bookName = serverRequest.path().pathParameters().get(\"name\"); String newValue = serverRequest.content().as(String.class); dbClient.execute().createNamedInsert(\"insert-book\") .addParam(\"name\", bookName) .addParam(\"info\", newValue) .execute(); serverResponse.status(Status.CREATED_201).send(); } The SQL statement requires the book name and its information. They are provided with addParam method. A new book was added to library, so a HTTP 201 code is returned. When a user adds a new book, it uses HTTP PUT method where the book name is in the URL and the information in the request content. To catch this content, the information is retrieved as a string and then the DB Client execute the insert-book script to add the book to the library. It requires two parameters, the book name and information which are passed to the dbClient thanks to addParam method. A HTTP 201 is sent back as a confirmation. <markup lang=\"java\" title=\"Add deleteBook to LibraryService:\" >private void deleteBook(ServerRequest serverRequest, ServerResponse serverResponse) { String bookName = serverRequest.path().pathParameters().get(\"name\"); dbClient.execute().namedDelete(\"delete-book\", bookName); serverResponse.status(Status.NO_CONTENT_204).send(); } Execute SQL script from application.yaml to remove a book from the library by its name. The required book was removed, so a HTTP 204 is sent. To remove a book from the library, use the \"delete-book\" script in the way than previously. If the book is removed successfully, a HTTP 204 is sent back. Set Up Routing <markup lang=\"java\" title=\"Modify the routing method in Main.java :\" >static void routing(HttpRouting.Builder routing) { routing .register(\"/greet\", new GreetService()) .register(\"/library\", new LibraryService()) .get(\"/simple-greet\", (req, res) -&gt; res.send(\"Hello World!\")); } Register the LibraryService to the Routing. The library service does not yet exist, but you&#8217;ll create it in the next step of the guide. ",
            "title": "Getting Started with Helidon DB Client"
        },
        {
            "location": "/se/guides/dbclient",
            "text": " This guide provided an introduction to the Helidon DB Client&#8217;s key features. If you want to learn more, see the Helidon DB Client samples in GitHub . ",
            "title": "Summary"
        },
        {
            "location": "/se/guides/dbclient",
            "text": " The application is ready to be built and run. <markup lang=\"bash\" title=\"Run the following to build the application:\" >mvn package Note that the tests are passing as the GreetService process was not modified. For the purposes of this demonstration, we only added independent new content to the existing application. Make sure H2 is running and start the Helidon quickstart with this command: <markup lang=\"bash\" title=\"Run the application\" >java -jar target/helidon-quickstart-se.jar Once the application starts, check the table LIBRARY is created in the H2 database. To do so, go to the H2 Server console and LIBRARY table should be present in the left column under jdbc:h2:tcp://localhost:9092/~/test . If it is not, try to refresh the page, and it should appear. Use curl to send request to the application: <markup lang=\"bash\" title=\"Get a book from the library\" >curl -i http://localhost:8080/library/SomeBook <markup lang=\"listing\" title=\"HTTP response\" >HTTP/1.1 404 Not Found Date: Tue, 12 Jan 2021 14:00:48 +0100 transfer-encoding: chunked connection: keep-alive There is currently no book inside the library, so the application returns a 404. Yet the application created an empty library table. Try to add a new book. <markup lang=\"bash\" title=\"Add a book from the library\" >curl -i -X PUT -d \"Fantasy\" http://localhost:8080/library/HarryPotter <markup lang=\"listing\" title=\"HTTP response\" >HTTP/1.1 201 Created Date: Tue, 12 Jan 2021 14:01:08 +0100 transfer-encoding: chunked connection: keep-alive This command creates an HTTP PUT request with the genre Fantasy content at the address http://localhost:8080/library/{book-name} . The 201 code means that Harry Potter book was successfully added to the library. You can now try to get it ! <markup lang=\"bash\" title=\"Get Harry Potter from the library\" >curl -i http://localhost:8080/library/HarryPotter <markup lang=\"listing\" title=\"HTTP response\" >HTTP/1.1 200 OK Content-Type: text/plain Date: Tue, 12 Jan 2021 14:01:14 +0100 connection: keep-alive content-length: 6 Fantasy The application accepted the request and returned an HTTP 200 OK with the book genre that was added earlier. <markup lang=\"bash\" title=\"Get Harry Potter from the library in Json\" >curl -i http://localhost:8080/library/json/HarryPotter <markup lang=\"listing\" title=\"HTTP response\" >HTTP/1.1 200 OK Content-Type: text/plain Date: Tue, 12 Jan 2021 14:01:14 +0100 connection: keep-alive content-length: 6 {\"INFO\":\"Fantasy\"} It returns the database row in a Json format for the Harry Potter book. Harry Potter can be removed from the library with the following: <markup lang=\"bash\" title=\"Remove Harry Potter from the library\" >curl -i -X DELETE http://localhost:8080/library/HarryPotter <markup lang=\"listing\" title=\"HTTP response\" >HTTP/1.1 204 No Content Date: Tue, 12 Jan 2021 14:01:22 +0100 connection: keep-alive The book had been removed from the library and confirmed by the 204 HTTP status. To check that the book was correctly deleted, try to get it again. <markup lang=\"bash\" title=\"Get Harry Potter from the library\" >curl -i http://localhost:8080/library/HarryPotter <markup lang=\"listing\" title=\"HTTP response\" >HTTP/1.1 404 Not Found Date: Tue, 12 Jan 2021 14:00:48 +0100 transfer-encoding: chunked connection: keep-alive The book is not found. We quickly checked, thanks to this suite of command, the application behavior. <markup lang=\"bash\" title=\"Check the health of your application:\" >curl http://localhost:8080/observe/health <markup lang=\"json\" title=\"Response body\" >{ \"status\": \"UP\", \"checks\": [ { \"name\": \"jdbc:h2\", \"status\": \"UP\" } ] } It confirms that the database is UP. <markup lang=\"bash\" title=\"Check the metrics of your application:\" >curl -H \"Accept: application/json\" http://localhost:8080/observe/metrics/application <markup lang=\"json\" title=\"Response body\" >{ \"db.counter.select-book\" : 4 } The select-book statement was invoked four times. Summary This guide provided an introduction to the Helidon DB Client&#8217;s key features. If you want to learn more, see the Helidon DB Client samples in GitHub . ",
            "title": "Build and Run the Library Application"
        },
        {
            "location": "/se/guides/graalnative",
            "text": " This guide describes how to build a GraalVM native image for a Helidon SE application. ",
            "title": "preambule"
        },
        {
            "location": "/se/guides/graalnative",
            "text": " Native images are ahead-of-time compiled Java code that result in a self contained native executable. When used appropriately native images have dramatically faster startup and lower runtime memory overhead compared to a Java VM. In this guide you will learn how to build a native image locally on your machine, as well as using Docker. ",
            "title": "Introduction"
        },
        {
            "location": "/se/guides/graalnative",
            "text": " For this 10 minute tutorial, you will need the following: <div class=\"table__overflow elevation-1 flex sm7 \"> A Helidon SE Application You can use your own application or use the Helidon SE Quickstart to create a sample application. Java&#160;SE&#160;21 ( Open&#160;JDK&#160;21 ) Helidon requires Java 21+. Maven 3.8+ Helidon requires Maven 3.8+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop . GraalVM for JDK 21 <markup lang=\"bash\" title=\"Verify Prerequisites\" >java -version mvn --version docker --version kubectl version --short <markup lang=\"bash\" title=\"Setting JAVA_HOME\" ># On Mac export JAVA_HOME=`/usr/libexec/java_home -v 21` # On Linux # Use the appropriate path to your JDK export JAVA_HOME=/usr/lib/jvm/jdk-21 ",
            "title": "What You Need"
        },
        {
            "location": "/se/guides/graalnative",
            "text": " After downloading and installing GraalVM, set the GRAALVM_HOME environment variable to point at your GraalVM installation, or use the GraalVM installation as your Java home. <markup lang=\"bash\" ># Your path might be different export GRAALVM_HOME=/usr/local/graalvm-jdk-21+35.1/Contents/Home/ Then verify: <markup lang=\"bash\" >$GRAALVM_HOME/bin/java -version $GRAALVM_HOME/bin/native-image --version ",
            "title": "Install GraalVM and the Native Image Command"
        },
        {
            "location": "/se/guides/graalnative",
            "text": " Generate the project using the Helidon SE Quickstart Maven archetype. <markup lang=\"bash\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-se \\ -DarchetypeVersion=4.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-se \\ -Dpackage=io.helidon.examples.quickstart.se The archetype generates a Maven project in your current directory (for example, helidon-quickstart-se ). Change into this directory and build. <markup lang=\"bash\" >cd helidon-quickstart-se mvn package At this point you can run the application using the JVM: <markup lang=\"bash\" >java -jar target/helidon-quickstart-se.jar In another shell test an endpoint: <markup lang=\"bash\" >curl -X GET http://localhost:8080/greet The application should respond with {\"message\":\"Hello World!\"} Now stop the running application (by pressing Ctrl+C). For more information about the Quickstart application and other endpoints it supports see the Helidon SE Quickstart Guide . ",
            "title": "Generate the Project"
        },
        {
            "location": "/se/guides/graalnative",
            "text": " Make sure you have GraalVM locally installed: <markup lang=\"bash\" >$GRAALVM_HOME/bin/native-image --version Build the native image using the native image profile: <markup lang=\"bash\" >mvn package -Pnative-image Tip This uses the org.graalvm.buildtools:native-maven-plugin to perform the native compilation using your installed copy of GraalVM. It might take a while to complete. Once it completes start the application using the native executable (no JVM!): <markup lang=\"bash\" >./target/helidon-quickstart-se Yep, it starts fast. You can exercise the application&#8217;s endpoints as before. ",
            "title": "Local build"
        },
        {
            "location": "/se/guides/graalnative",
            "text": " Build the \"native\" Docker image <markup lang=\"bash\" >docker build -t helidon-quickstart-se-native -f Dockerfile.native . Tip This does a full build inside the Docker container. The first time you run it, it will take a while because it is downloading all of the Maven dependencies and caching them in a Docker layer. Subsequent builds will be much faster as long as you don&#8217;t change the pom.xml file. If the pom is modified then the dependencies will be re-downloaded. Start the application: <markup lang=\"bash\" >docker run --rm -p 8080:8080 helidon-quickstart-se-native:latest Again, it starts fast. You can exercise the application&#8217;s endpoints as before. ",
            "title": "Multi-stage Docker build"
        },
        {
            "location": "/se/guides/graalnative",
            "text": " You can build a native executable in 2 different ways: With a local installation of GraalVM Using Docker Local build Make sure you have GraalVM locally installed: <markup lang=\"bash\" >$GRAALVM_HOME/bin/native-image --version Build the native image using the native image profile: <markup lang=\"bash\" >mvn package -Pnative-image Tip This uses the org.graalvm.buildtools:native-maven-plugin to perform the native compilation using your installed copy of GraalVM. It might take a while to complete. Once it completes start the application using the native executable (no JVM!): <markup lang=\"bash\" >./target/helidon-quickstart-se Yep, it starts fast. You can exercise the application&#8217;s endpoints as before. Multi-stage Docker build Build the \"native\" Docker image <markup lang=\"bash\" >docker build -t helidon-quickstart-se-native -f Dockerfile.native . Tip This does a full build inside the Docker container. The first time you run it, it will take a while because it is downloading all of the Maven dependencies and caching them in a Docker layer. Subsequent builds will be much faster as long as you don&#8217;t change the pom.xml file. If the pom is modified then the dependencies will be re-downloaded. Start the application: <markup lang=\"bash\" >docker run --rm -p 8080:8080 helidon-quickstart-se-native:latest Again, it starts fast. You can exercise the application&#8217;s endpoints as before. ",
            "title": "Building a Native Image"
        },
        {
            "location": "/se/guides/graalnative",
            "text": " Native images are ideal for applications with high horizontal scalability requirements where the ability to rapidly scale out to numerous instances is important. That said, native images do have some limitations , and for long running applications where startup and footprint are less of a priority, the Java SE HotSpot VM might be more appropriate. For information about creating custom Java runtime images see Custom Runtime Images with jlink . When building Helidon using native-image, we check features on classpath, and warn if there is a problem or restriction of support ",
            "title": "When should I use Native Images?"
        },
        {
            "location": "/se/guides/gradle-build",
            "text": " This guide describes Helidon&#8217;s support for Gradle projects. ",
            "title": "preambule"
        },
        {
            "location": "/se/guides/gradle-build",
            "text": " While most of Helidon&#8217;s examples use Maven, you can also use Helidon with a Gradle project. Gradle 8.4+ is required to build Helidon 4 projects. ",
            "title": "Introduction"
        },
        {
            "location": "/se/guides/gradle-build",
            "text": " The Helidon Quickstart Example contains a build.gradle file that you can use as an example for building your Helidon application using Gradle. ",
            "title": "Gradle Example"
        },
        {
            "location": "/se/guides/gradle-build",
            "text": " Gradle supports using a Maven POM to perform dependency management. You can use the Helidon Dependencies POM for this purpose. Once you import the Helidon dependency management POM you can specify dependencies without providing a version. <markup lang=\"xml\" title=\"Using the Helidon Dependencies POM\" >dependencies { // import Helidon dependency management implementation enforcedPlatform(\"io.helidon:helidon-dependencies:${project.helidonversion}\") implementation 'io.helidon.microprofile.bundles:helidon-microprofile' implementation 'org.glassfish.jersey.media:jersey-media-json-binding' runtimeOnly 'io.smallrye:jandex' runtimeOnly 'jakarta.activation:jakarta.activation-api' testCompileOnly 'org.junit.jupiter:junit-jupiter-api:' } ",
            "title": "Dependency Management"
        },
        {
            "location": "/se/guides/health",
            "text": " This guide describes how to create a sample Helidon SE project that can be used to run some basic examples using both built-in and custom health checks. ",
            "title": "preambule"
        },
        {
            "location": "/se/guides/health",
            "text": " Generate the project sources using the Helidon SE Maven archetype. The result is a simple project that can be used for the examples in this guide. <markup lang=\"bash\" title=\"Run the Maven archetype:\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-se \\ -DarchetypeVersion=4.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-se \\ -Dpackage=io.helidon.examples.quickstart.se ",
            "title": "Create a Sample SE Project"
        },
        {
            "location": "/se/guides/health",
            "text": " Helidon has a set of built-in health checks: deadlock detection available disk space available heap memory The following example shows how to use the built-in health checks. These examples are all executed from the root directory of your project (helidon-quickstart-se). Notice that the pom.xml file in the generated project already contains dependencies for Helidon&#8217;s health component and for the built-in health checks. <markup lang=\"xml\" title=\"Generated dependencies related to health\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webserver.observe&lt;/groupId&gt; &lt;artifactId&gt;helidon-webserver-observe-health&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.health&lt;/groupId&gt; &lt;artifactId&gt;helidon-health-checks&lt;/artifactId&gt; &lt;/dependency&gt; Handling health checks is part of Helidon&#8217;s observability support. By default, when you add the dependency for the built-in health checks, Helidon automatically registers the built-in checks. <markup lang=\"bash\" title=\"Build and run the project\" >mvn clean package java -jar target/helidon-quickstart-se.jar In another window, access the application&#8217;s health endpoint. <markup lang=\"bash\" title=\"Access the health endpoint\" >curl -v http://localhost:8080/observe/health The verbose curl output reports the HTTP status: &lt; HTTP/1.1 204 No Content The successful status means all health checks reported UP . To see the details about each health check, add the following features configuration fragment in the server section of the application.yaml . Make sure the features key is at the same level as port and host that are already in the file. <markup lang=\"yaml\" title=\"Configuration fragment to include details in the health output (nested under server )\" >server: port: 8080 host: 0.0.0.0 features: observe: observers: health: details: true Added features config section. Press ^C to stop the running server, rebuild it, and rerun it. <markup lang=\"bash\" title=\"Stop, rebuild, and rerun the server\" >^C mvn clean package java -jar target/helidon-quickstart-se.jar In the other window access the health endpoint again. <markup lang=\"bash\" title=\"Access the health endpoint\" >curl -v http://localhost:8080/observe/health This time the curl output shows not only the HTTP status&#8212;&#8203;as 200 instead of 204 because the response now contains data&#8212;&#8203;but also the detailed output for all health checks. <markup lang=\"json\" title=\"Health check details\" >{ \"status\": \"UP\", \"checks\": [ { \"name\": \"diskSpace\", \"status\": \"UP\", \"data\": { \"total\": \"465.63 GB\", \"percentFree\": \"14.10%\", \"totalBytes\": 499963174912, \"free\": \"65.67 GB\", \"freeBytes\": 70513274880 } }, { \"name\": \"heapMemory\", \"status\": \"UP\", \"data\": { \"total\": \"516.00 MB\", \"percentFree\": \"99.82%\", \"max\": \"8.00 GB\", \"totalBytes\": 541065216, \"maxBytes\": 8589934592, \"free\": \"500.87 MB\", \"freeBytes\": 525201320 } }, { \"name\": \"deadlock\", \"status\": \"UP\" } ] } Overall application health status List of individual health checks. ",
            "title": "Using the Built-In Health Checks"
        },
        {
            "location": "/se/guides/health",
            "text": " You can add your own custom health checks. These typically assess the conditions in and around your application and report whether the service should be considered started, live, and/or ready. The following trivial but illustrative example adds a custom start-up check that reports DOWN until the server has been running for eight seconds and reports UP thereafter. Note the two main steps in the example code: Create an explicit instance of ObserveFeature which contains a custom HealthObserver with the custom check. Add that ObserveFeature instance to the WebServer.Builder as a feature. <markup lang=\"java\" title=\"Updated Main.main , augmenting the creation of WebServer instance with a custom health check\" >AtomicLong serverStartTime = new AtomicLong(); ObserveFeature o = ObserveFeature.builder() .config(config.get(\"server.features.observe\")) .addObserver(HealthObserver.builder() .details(true) .addCheck(() -&gt; HealthCheckResponse.builder() .status(System.currentTimeMillis() - serverStartTime.get() &gt;= 8000) .detail(\"time\", System.currentTimeMillis()) .build(), HealthCheckType.STARTUP, \"warmedUp\") .build()) .build(); WebServer server = WebServer.builder() .config(config.get(\"server\")) .addFeature(observe) .routing(Main::routing) .build() .start(); serverStartTime.set(System.currentTimeMillis()); Declare a variable for holding the server start-up time. (This is set later in the code.) Find and apply configuration for observability observers other than health (because we are about to create our own custom HealthObserver ). Begin preparing the custom HealthObserver according to this app&#8217;s specific needs. Turn on detailed output in HTTP responses to the health endpoint. Add a custom start-up health check: Build the HealthObserver for addition to the ObserveFeature . Add the ObserveFeature instance as a feature to the webserver. Record when the server has actually started. Note that the health check type and name are fixed, whereas the health check recomputes the value of the response every time Helidon queries it. For the next step, be ready to access the health endpoint very quickly after you restart the server! <markup lang=\"bash\" title=\"Stop, rebuild, and rerun the application\" >^C mvn package java -jar target/helidon-quickstart-se.jar <markup lang=\"bash\" title=\"Access the health endpoint quickly \" >curl -v http://localhost:8080/observe/health If you access the health endpoint before the server has been up for eight seconds, curl reports the response status as 503 Service Unavailable and displays output similar to the following: <markup lang=\"json\" title=\"Health response shortly after server restart (partial)\" >{ \"status\": \"DOWN\", \"checks\": [ { \"name\": \"warmedUp\", \"status\": \"DOWN\", \"data\": { \"time\": 1702068978353 } }, ... The built-in health checks (not shown in the example output) all report UP but the new custom start-up health check reports DOWN because the server has been up only a short time. Access the health endpoint again, after the server has been up at least eight seconds. <markup lang=\"bash\" title=\"Access the health endpoint again after 8 seconds \" >curl -v http://localhost:8080/observe/health This time, curl reports 200 OK for the response status and displays different output for the custom health check. <markup lang=\"json\" title=\"Health response after the server has been running a while (partial)\" >{ \"status\": \"UP\", \"checks\": [ { \"name\": \"warmedUp\", \"status\": \"UP\", \"data\": { \"time\": 1702069379717 } }, The example code includes the built-in health checks in Helidon&#8217;s overall health assessment of the application. To exclude them invoke the HealthObserver.Builder useSystemServices method (for example, just after invoking details on the builder). <markup lang=\"java\" title=\"Disable all built-in health checks\" > .useSystemServices(false) Alternatively, you could instead remove the dependency on the helidon-health-checks component from the pom.xml file. ",
            "title": "Adding Custom Health Checks"
        },
        {
            "location": "/se/guides/health",
            "text": " You can choose which category of health check to retrieve when you access the health endpoint by adding the health check type as an additional part of the resource path: liveness only - http://localhost:8080/observe/health/live readiness only - http://localhost:8080/observe/health/ready startup only - http://localhost:8080/observe/health/started all - http://localhost:8080/observe/health <markup lang=\"bash\" title=\"Get only start-up health checks\" >curl http://localhost:8080/observe/started <markup lang=\"json\" title=\"JSON response:\" >{ \"status\": \"UP\", \"checks\": [ { \"name\": \"warmedUp\", \"status\": \"UP\", \"data\": { \"time\": 1702069835172 } } ] } ",
            "title": "Accessing Specific Health Check Types"
        },
        {
            "location": "/se/guides/health",
            "text": " Customize the URL path for health checks by invoking the endpoint method on the HealthObserver.Builder . <markup lang=\"java\" title=\"Set a custom endpoint path\" >ObserveFeature observe = ObserveFeature.builder() .config(config.get(\"server.features.observe\")) .addObserver(HealthObserver.builder() .endpoint(\"/myhealth\") .details(true) ... .build() ... ... Changes the health endpoint path to /myhealth . <markup lang=\"bash\" title=\"Build and run the application, then verify that the health check endpoint responds at /myhealth :\" >curl http://localhost:8080/myhealth Earlier you added health config to the application.yaml config file to turn on detailed output. If you want to run an experiment, change that details setting in the config file to false and stop, rebuild, and rerun the application. Now access the health endpoint (at /myhealth , remember). The output remains detailed because your code&#8212;&#8203;which has full responsibility for determining the custom health observer&#8217;s behavior&#8212;&#8203;does not apply configuration to the custom observer&#8217;s builder. ",
            "title": "Customizing the endpoint path in the code"
        },
        {
            "location": "/se/guides/health",
            "text": " In addition to preparing the health observer builder with hard-coded settings, your code can also apply configuration for health. This allows someone who deploys your application to control the behavior of the health subsystem using configuration without requiring source code changes to your application. The generated Main class in the application already creates a Config object for the top-level config node. Using the following code to create the observe feature also applies any health-related configuration settings to the custom health observer. Notice the added line just before the HealthObserver.Build build() invocation near the end of the example code. <markup title=\"Apply health configuration to your custom health observer\" >ObserveFeature observe = ObserveFeature.builder() .config(config.get(\"server.features.observe\")) .addObserver(HealthObserver.builder() .endpoint(\"/myhealth\") .details(true) .addCheck(() -&gt; HealthCheckResponse.builder() .status(System.currentTimeMillis() - serverStartTime.get() &gt;= 8000) .detail(\"time\", System.currentTimeMillis()) .build(), HealthCheckType.STARTUP, \"warmedUp\") .config(config.get(\"server.features.observe.observers.health\")) .build() ) .build(); Find and apply any health-related settings from configuration at the server.features.observe.observers.health config key. Your code decides what config key to use for retrieving the configuration. Recall earlier, before adding custom health checks, you added a config section for health&#8212;&#8203;to set details to true --at server.features.observe.observers.health . Helidon used that configuration to set up the health observer it created automatically. To be consistent for anyone preparing the configuration file, it&#8217;s a good idea for your application code&#8212;&#8203;as it prepares a custom HealthObserver --to look in the same place Helidon does for health config. Order is important. Here, the code first sets details to true explicitly and later applies configuration. If your end user sets details in the server.features.observe.observers.health config to false , that setting overrides the hard-coded true setting in the code because of where in the code you apply the configuration . Try changing the details value to false in the config file and then stop, rebuild, and rerun the application. Access the health endpoint and notice that the output is no longer detailed. In general, most applications should apply settings from config after assigning any settings in the code so users have the final say, but there might be exceptions in your particular case. ",
            "title": "Adding configuration to a custom observer"
        },
        {
            "location": "/se/guides/health",
            "text": " Earlier examples showed how to add custom health checks by building a custom HealthObserver in which the code set up the behavior of the health subsystem explicitly. Recall that the example code invoked the HealthObserver.Builder details method to turn on detailed output. Once it creates a custom health observer, your code has full responsibility for determining the observer&#8217;s behavior; Helidon does not automatically apply configuration to a custom observer. But your code can easily do so. The next example customizes the URL path for the health endpoint, first explicitly in the code and then via configuration. Customizing the endpoint path in the code Customize the URL path for health checks by invoking the endpoint method on the HealthObserver.Builder . <markup lang=\"java\" title=\"Set a custom endpoint path\" >ObserveFeature observe = ObserveFeature.builder() .config(config.get(\"server.features.observe\")) .addObserver(HealthObserver.builder() .endpoint(\"/myhealth\") .details(true) ... .build() ... ... Changes the health endpoint path to /myhealth . <markup lang=\"bash\" title=\"Build and run the application, then verify that the health check endpoint responds at /myhealth :\" >curl http://localhost:8080/myhealth Earlier you added health config to the application.yaml config file to turn on detailed output. If you want to run an experiment, change that details setting in the config file to false and stop, rebuild, and rerun the application. Now access the health endpoint (at /myhealth , remember). The output remains detailed because your code&#8212;&#8203;which has full responsibility for determining the custom health observer&#8217;s behavior&#8212;&#8203;does not apply configuration to the custom observer&#8217;s builder. Adding configuration to a custom observer In addition to preparing the health observer builder with hard-coded settings, your code can also apply configuration for health. This allows someone who deploys your application to control the behavior of the health subsystem using configuration without requiring source code changes to your application. The generated Main class in the application already creates a Config object for the top-level config node. Using the following code to create the observe feature also applies any health-related configuration settings to the custom health observer. Notice the added line just before the HealthObserver.Build build() invocation near the end of the example code. <markup title=\"Apply health configuration to your custom health observer\" >ObserveFeature observe = ObserveFeature.builder() .config(config.get(\"server.features.observe\")) .addObserver(HealthObserver.builder() .endpoint(\"/myhealth\") .details(true) .addCheck(() -&gt; HealthCheckResponse.builder() .status(System.currentTimeMillis() - serverStartTime.get() &gt;= 8000) .detail(\"time\", System.currentTimeMillis()) .build(), HealthCheckType.STARTUP, \"warmedUp\") .config(config.get(\"server.features.observe.observers.health\")) .build() ) .build(); Find and apply any health-related settings from configuration at the server.features.observe.observers.health config key. Your code decides what config key to use for retrieving the configuration. Recall earlier, before adding custom health checks, you added a config section for health&#8212;&#8203;to set details to true --at server.features.observe.observers.health . Helidon used that configuration to set up the health observer it created automatically. To be consistent for anyone preparing the configuration file, it&#8217;s a good idea for your application code&#8212;&#8203;as it prepares a custom HealthObserver --to look in the same place Helidon does for health config. Order is important. Here, the code first sets details to true explicitly and later applies configuration. If your end user sets details in the server.features.observe.observers.health config to false , that setting overrides the hard-coded true setting in the code because of where in the code you apply the configuration . Try changing the details value to false in the config file and then stop, rebuild, and rerun the application. Access the health endpoint and notice that the output is no longer detailed. In general, most applications should apply settings from config after assigning any settings in the code so users have the final say, but there might be exceptions in your particular case. ",
            "title": "Applying Configuration to a Custom Health Observer: Customizing the URL path"
        },
        {
            "location": "/se/guides/health",
            "text": " The following example shows how to integrate the Helidon health API in an application that implements health endpoints for the Kubernetes liveness, readiness, and startup probes. <markup lang=\"java\" title=\"Add a readyTime variable to the Main class:\" >private static AtomicLong readyTime = new AtomicLong(0); <markup lang=\"java\" title=\"Change the HealthObserver builder in the Main.main method to use new built-in liveness checks and custom liveness, readiness, and startup checks:\" >ObserveFeature observe = ObserveFeature.builder() .config(config.get(\"server.features.observe\")) .addObserver(HealthObserver.builder() .useSystemServices(true) .addCheck(() -&gt; HealthCheckResponse.builder() .status(readyTime.get() != 0) .detail(\"time\", readyTime.get()) .build(), HealthCheckType.READINESS) .addCheck(() -&gt; HealthCheckResponse.builder() .status(readyTime.get() != 0 &amp;&amp; Duration.ofMillis(System.currentTimeMillis() - readyTime.get()) .getSeconds() &gt;= 3) .detail(\"time\", readyTime.get()) .build(), HealthCheckType.STARTUP) .addCheck(() -&gt; HealthCheckResponse.builder() .status(HealthCheckResponse.Status.UP) .detail(\"time\", System.currentTimeMillis()) .build(), HealthCheckType.LIVENESS) .build()) .build(); Add built-in health checks. Add a custom readiness check. Add a custom start-up check. Add a custom liveness check. <markup lang=\"bash\" title=\"Build and run the application, then verify the liveness, readiness, and started endpoints:\" >curl http://localhost:8080/health/live curl http://localhost:8080/health/ready curl http://localhost:8080/health/started <markup lang=\"bash\" title=\"Stop the application and build the docker image:\" >docker build -t helidon-quickstart-se . <markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named health.yaml , with the following content:\" >kind: Service apiVersion: v1 metadata: name: helidon-health labels: app: helidon-health spec: type: NodePort selector: app: helidon-health ports: - port: 8080 targetPort: 8080 name: http --- kind: Deployment apiVersion: apps/v1 metadata: name: helidon-health spec: replicas: 1 selector: matchLabels: app: helidon-health template: metadata: labels: app: helidon-health version: v1 spec: containers: - name: helidon-health image: helidon-quickstart-se imagePullPolicy: IfNotPresent ports: - containerPort: 8080 livenessProbe: httpGet: path: /health/live port: 8080 initialDelaySeconds: 5 periodSeconds: 10 timeoutSeconds: 3 failureThreshold: 3 readinessProbe: httpGet: path: /health/ready port: 8080 initialDelaySeconds: 5 periodSeconds: 2 timeoutSeconds: 3 startupProbe: httpGet: path: /health/started port: 8080 initialDelaySeconds: 8 periodSeconds: 10 timeoutSeconds: 3 failureThreshold: 3 --- A service of type NodePort that serves the default routes on port 8080 . A deployment with one replica of a pod. The HTTP endpoint for the liveness probe. The liveness probe configuration. The HTTP endpoint for the readiness probe. The readiness probe configuration. The HTTP endpoint for the startup probe. The startup probe configuration. <markup lang=\"bash\" title=\"Create and deploy the application into Kubernetes:\" >kubectl apply -f ./health.yaml <markup lang=\"bash\" title=\"Get the service information:\" >kubectl get service/helidon-health <markup lang=\"bash\" >NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE helidon-health NodePort 10.107.226.62 &lt;none&gt; 8080:30116/TCP 4s A service of type NodePort that serves the default routes on port 30116 . <markup lang=\"bash\" title=\"Verify the health endpoints using port '30116', your port may be different:\" >curl http://localhost:30116/health <markup lang=\"bash\" title=\"Delete the application, cleaning up Kubernetes resources:\" >kubectl delete -f ./health.yaml ",
            "title": "Using Liveness, Readiness, and Startup Health Checks with Kubernetes"
        },
        {
            "location": "/se/guides/health",
            "text": " This guide demonstrates how to use health checks in a Helidon SE application as follows: Access the default health checks Create and use custom readiness, liveness, and startup checks Customize the health check root path Integrate Helidon health check with Kubernetes Refer to the following reference for additional information: Helidon Javadoc ",
            "title": "Summary"
        },
        {
            "location": "/se/guides/health",
            "text": " For this 15 minute tutorial, you will need the following: <div class=\"table__overflow elevation-1 flex sm7 \"> A Helidon SE Application You can use your own application or use the Helidon SE Quickstart to create a sample application. Java&#160;SE&#160;21 ( Open&#160;JDK&#160;21 ) Helidon requires Java 21+. Maven 3.8+ Helidon requires Maven 3.8+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop . <markup lang=\"bash\" title=\"Verify Prerequisites\" >java -version mvn --version docker --version kubectl version --short <markup lang=\"bash\" title=\"Setting JAVA_HOME\" ># On Mac export JAVA_HOME=`/usr/libexec/java_home -v 21` # On Linux # Use the appropriate path to your JDK export JAVA_HOME=/usr/lib/jvm/jdk-21 Create a Sample SE Project Generate the project sources using the Helidon SE Maven archetype. The result is a simple project that can be used for the examples in this guide. <markup lang=\"bash\" title=\"Run the Maven archetype:\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-se \\ -DarchetypeVersion=4.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-se \\ -Dpackage=io.helidon.examples.quickstart.se Using the Built-In Health Checks Helidon has a set of built-in health checks: deadlock detection available disk space available heap memory The following example shows how to use the built-in health checks. These examples are all executed from the root directory of your project (helidon-quickstart-se). Notice that the pom.xml file in the generated project already contains dependencies for Helidon&#8217;s health component and for the built-in health checks. <markup lang=\"xml\" title=\"Generated dependencies related to health\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webserver.observe&lt;/groupId&gt; &lt;artifactId&gt;helidon-webserver-observe-health&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.health&lt;/groupId&gt; &lt;artifactId&gt;helidon-health-checks&lt;/artifactId&gt; &lt;/dependency&gt; Handling health checks is part of Helidon&#8217;s observability support. By default, when you add the dependency for the built-in health checks, Helidon automatically registers the built-in checks. <markup lang=\"bash\" title=\"Build and run the project\" >mvn clean package java -jar target/helidon-quickstart-se.jar In another window, access the application&#8217;s health endpoint. <markup lang=\"bash\" title=\"Access the health endpoint\" >curl -v http://localhost:8080/observe/health The verbose curl output reports the HTTP status: &lt; HTTP/1.1 204 No Content The successful status means all health checks reported UP . To see the details about each health check, add the following features configuration fragment in the server section of the application.yaml . Make sure the features key is at the same level as port and host that are already in the file. <markup lang=\"yaml\" title=\"Configuration fragment to include details in the health output (nested under server )\" >server: port: 8080 host: 0.0.0.0 features: observe: observers: health: details: true Added features config section. Press ^C to stop the running server, rebuild it, and rerun it. <markup lang=\"bash\" title=\"Stop, rebuild, and rerun the server\" >^C mvn clean package java -jar target/helidon-quickstart-se.jar In the other window access the health endpoint again. <markup lang=\"bash\" title=\"Access the health endpoint\" >curl -v http://localhost:8080/observe/health This time the curl output shows not only the HTTP status&#8212;&#8203;as 200 instead of 204 because the response now contains data&#8212;&#8203;but also the detailed output for all health checks. <markup lang=\"json\" title=\"Health check details\" >{ \"status\": \"UP\", \"checks\": [ { \"name\": \"diskSpace\", \"status\": \"UP\", \"data\": { \"total\": \"465.63 GB\", \"percentFree\": \"14.10%\", \"totalBytes\": 499963174912, \"free\": \"65.67 GB\", \"freeBytes\": 70513274880 } }, { \"name\": \"heapMemory\", \"status\": \"UP\", \"data\": { \"total\": \"516.00 MB\", \"percentFree\": \"99.82%\", \"max\": \"8.00 GB\", \"totalBytes\": 541065216, \"maxBytes\": 8589934592, \"free\": \"500.87 MB\", \"freeBytes\": 525201320 } }, { \"name\": \"deadlock\", \"status\": \"UP\" } ] } Overall application health status List of individual health checks. Adding Custom Health Checks You can add your own custom health checks. These typically assess the conditions in and around your application and report whether the service should be considered started, live, and/or ready. The following trivial but illustrative example adds a custom start-up check that reports DOWN until the server has been running for eight seconds and reports UP thereafter. Note the two main steps in the example code: Create an explicit instance of ObserveFeature which contains a custom HealthObserver with the custom check. Add that ObserveFeature instance to the WebServer.Builder as a feature. <markup lang=\"java\" title=\"Updated Main.main , augmenting the creation of WebServer instance with a custom health check\" >AtomicLong serverStartTime = new AtomicLong(); ObserveFeature o = ObserveFeature.builder() .config(config.get(\"server.features.observe\")) .addObserver(HealthObserver.builder() .details(true) .addCheck(() -&gt; HealthCheckResponse.builder() .status(System.currentTimeMillis() - serverStartTime.get() &gt;= 8000) .detail(\"time\", System.currentTimeMillis()) .build(), HealthCheckType.STARTUP, \"warmedUp\") .build()) .build(); WebServer server = WebServer.builder() .config(config.get(\"server\")) .addFeature(observe) .routing(Main::routing) .build() .start(); serverStartTime.set(System.currentTimeMillis()); Declare a variable for holding the server start-up time. (This is set later in the code.) Find and apply configuration for observability observers other than health (because we are about to create our own custom HealthObserver ). Begin preparing the custom HealthObserver according to this app&#8217;s specific needs. Turn on detailed output in HTTP responses to the health endpoint. Add a custom start-up health check: Build the HealthObserver for addition to the ObserveFeature . Add the ObserveFeature instance as a feature to the webserver. Record when the server has actually started. Note that the health check type and name are fixed, whereas the health check recomputes the value of the response every time Helidon queries it. For the next step, be ready to access the health endpoint very quickly after you restart the server! <markup lang=\"bash\" title=\"Stop, rebuild, and rerun the application\" >^C mvn package java -jar target/helidon-quickstart-se.jar <markup lang=\"bash\" title=\"Access the health endpoint quickly \" >curl -v http://localhost:8080/observe/health If you access the health endpoint before the server has been up for eight seconds, curl reports the response status as 503 Service Unavailable and displays output similar to the following: <markup lang=\"json\" title=\"Health response shortly after server restart (partial)\" >{ \"status\": \"DOWN\", \"checks\": [ { \"name\": \"warmedUp\", \"status\": \"DOWN\", \"data\": { \"time\": 1702068978353 } }, ... The built-in health checks (not shown in the example output) all report UP but the new custom start-up health check reports DOWN because the server has been up only a short time. Access the health endpoint again, after the server has been up at least eight seconds. <markup lang=\"bash\" title=\"Access the health endpoint again after 8 seconds \" >curl -v http://localhost:8080/observe/health This time, curl reports 200 OK for the response status and displays different output for the custom health check. <markup lang=\"json\" title=\"Health response after the server has been running a while (partial)\" >{ \"status\": \"UP\", \"checks\": [ { \"name\": \"warmedUp\", \"status\": \"UP\", \"data\": { \"time\": 1702069379717 } }, The example code includes the built-in health checks in Helidon&#8217;s overall health assessment of the application. To exclude them invoke the HealthObserver.Builder useSystemServices method (for example, just after invoking details on the builder). <markup lang=\"java\" title=\"Disable all built-in health checks\" > .useSystemServices(false) Alternatively, you could instead remove the dependency on the helidon-health-checks component from the pom.xml file. Accessing Specific Health Check Types You can choose which category of health check to retrieve when you access the health endpoint by adding the health check type as an additional part of the resource path: liveness only - http://localhost:8080/observe/health/live readiness only - http://localhost:8080/observe/health/ready startup only - http://localhost:8080/observe/health/started all - http://localhost:8080/observe/health <markup lang=\"bash\" title=\"Get only start-up health checks\" >curl http://localhost:8080/observe/started <markup lang=\"json\" title=\"JSON response:\" >{ \"status\": \"UP\", \"checks\": [ { \"name\": \"warmedUp\", \"status\": \"UP\", \"data\": { \"time\": 1702069835172 } } ] } Applying Configuration to a Custom Health Observer: Customizing the URL path Earlier examples showed how to add custom health checks by building a custom HealthObserver in which the code set up the behavior of the health subsystem explicitly. Recall that the example code invoked the HealthObserver.Builder details method to turn on detailed output. Once it creates a custom health observer, your code has full responsibility for determining the observer&#8217;s behavior; Helidon does not automatically apply configuration to a custom observer. But your code can easily do so. The next example customizes the URL path for the health endpoint, first explicitly in the code and then via configuration. Customizing the endpoint path in the code Customize the URL path for health checks by invoking the endpoint method on the HealthObserver.Builder . <markup lang=\"java\" title=\"Set a custom endpoint path\" >ObserveFeature observe = ObserveFeature.builder() .config(config.get(\"server.features.observe\")) .addObserver(HealthObserver.builder() .endpoint(\"/myhealth\") .details(true) ... .build() ... ... Changes the health endpoint path to /myhealth . <markup lang=\"bash\" title=\"Build and run the application, then verify that the health check endpoint responds at /myhealth :\" >curl http://localhost:8080/myhealth Earlier you added health config to the application.yaml config file to turn on detailed output. If you want to run an experiment, change that details setting in the config file to false and stop, rebuild, and rerun the application. Now access the health endpoint (at /myhealth , remember). The output remains detailed because your code&#8212;&#8203;which has full responsibility for determining the custom health observer&#8217;s behavior&#8212;&#8203;does not apply configuration to the custom observer&#8217;s builder. Adding configuration to a custom observer In addition to preparing the health observer builder with hard-coded settings, your code can also apply configuration for health. This allows someone who deploys your application to control the behavior of the health subsystem using configuration without requiring source code changes to your application. The generated Main class in the application already creates a Config object for the top-level config node. Using the following code to create the observe feature also applies any health-related configuration settings to the custom health observer. Notice the added line just before the HealthObserver.Build build() invocation near the end of the example code. <markup title=\"Apply health configuration to your custom health observer\" >ObserveFeature observe = ObserveFeature.builder() .config(config.get(\"server.features.observe\")) .addObserver(HealthObserver.builder() .endpoint(\"/myhealth\") .details(true) .addCheck(() -&gt; HealthCheckResponse.builder() .status(System.currentTimeMillis() - serverStartTime.get() &gt;= 8000) .detail(\"time\", System.currentTimeMillis()) .build(), HealthCheckType.STARTUP, \"warmedUp\") .config(config.get(\"server.features.observe.observers.health\")) .build() ) .build(); Find and apply any health-related settings from configuration at the server.features.observe.observers.health config key. Your code decides what config key to use for retrieving the configuration. Recall earlier, before adding custom health checks, you added a config section for health&#8212;&#8203;to set details to true --at server.features.observe.observers.health . Helidon used that configuration to set up the health observer it created automatically. To be consistent for anyone preparing the configuration file, it&#8217;s a good idea for your application code&#8212;&#8203;as it prepares a custom HealthObserver --to look in the same place Helidon does for health config. Order is important. Here, the code first sets details to true explicitly and later applies configuration. If your end user sets details in the server.features.observe.observers.health config to false , that setting overrides the hard-coded true setting in the code because of where in the code you apply the configuration . Try changing the details value to false in the config file and then stop, rebuild, and rerun the application. Access the health endpoint and notice that the output is no longer detailed. In general, most applications should apply settings from config after assigning any settings in the code so users have the final say, but there might be exceptions in your particular case. Using Liveness, Readiness, and Startup Health Checks with Kubernetes The following example shows how to integrate the Helidon health API in an application that implements health endpoints for the Kubernetes liveness, readiness, and startup probes. <markup lang=\"java\" title=\"Add a readyTime variable to the Main class:\" >private static AtomicLong readyTime = new AtomicLong(0); <markup lang=\"java\" title=\"Change the HealthObserver builder in the Main.main method to use new built-in liveness checks and custom liveness, readiness, and startup checks:\" >ObserveFeature observe = ObserveFeature.builder() .config(config.get(\"server.features.observe\")) .addObserver(HealthObserver.builder() .useSystemServices(true) .addCheck(() -&gt; HealthCheckResponse.builder() .status(readyTime.get() != 0) .detail(\"time\", readyTime.get()) .build(), HealthCheckType.READINESS) .addCheck(() -&gt; HealthCheckResponse.builder() .status(readyTime.get() != 0 &amp;&amp; Duration.ofMillis(System.currentTimeMillis() - readyTime.get()) .getSeconds() &gt;= 3) .detail(\"time\", readyTime.get()) .build(), HealthCheckType.STARTUP) .addCheck(() -&gt; HealthCheckResponse.builder() .status(HealthCheckResponse.Status.UP) .detail(\"time\", System.currentTimeMillis()) .build(), HealthCheckType.LIVENESS) .build()) .build(); Add built-in health checks. Add a custom readiness check. Add a custom start-up check. Add a custom liveness check. <markup lang=\"bash\" title=\"Build and run the application, then verify the liveness, readiness, and started endpoints:\" >curl http://localhost:8080/health/live curl http://localhost:8080/health/ready curl http://localhost:8080/health/started <markup lang=\"bash\" title=\"Stop the application and build the docker image:\" >docker build -t helidon-quickstart-se . <markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named health.yaml , with the following content:\" >kind: Service apiVersion: v1 metadata: name: helidon-health labels: app: helidon-health spec: type: NodePort selector: app: helidon-health ports: - port: 8080 targetPort: 8080 name: http --- kind: Deployment apiVersion: apps/v1 metadata: name: helidon-health spec: replicas: 1 selector: matchLabels: app: helidon-health template: metadata: labels: app: helidon-health version: v1 spec: containers: - name: helidon-health image: helidon-quickstart-se imagePullPolicy: IfNotPresent ports: - containerPort: 8080 livenessProbe: httpGet: path: /health/live port: 8080 initialDelaySeconds: 5 periodSeconds: 10 timeoutSeconds: 3 failureThreshold: 3 readinessProbe: httpGet: path: /health/ready port: 8080 initialDelaySeconds: 5 periodSeconds: 2 timeoutSeconds: 3 startupProbe: httpGet: path: /health/started port: 8080 initialDelaySeconds: 8 periodSeconds: 10 timeoutSeconds: 3 failureThreshold: 3 --- A service of type NodePort that serves the default routes on port 8080 . A deployment with one replica of a pod. The HTTP endpoint for the liveness probe. The liveness probe configuration. The HTTP endpoint for the readiness probe. The readiness probe configuration. The HTTP endpoint for the startup probe. The startup probe configuration. <markup lang=\"bash\" title=\"Create and deploy the application into Kubernetes:\" >kubectl apply -f ./health.yaml <markup lang=\"bash\" title=\"Get the service information:\" >kubectl get service/helidon-health <markup lang=\"bash\" >NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE helidon-health NodePort 10.107.226.62 &lt;none&gt; 8080:30116/TCP 4s A service of type NodePort that serves the default routes on port 30116 . <markup lang=\"bash\" title=\"Verify the health endpoints using port '30116', your port may be different:\" >curl http://localhost:30116/health <markup lang=\"bash\" title=\"Delete the application, cleaning up Kubernetes resources:\" >kubectl delete -f ./health.yaml Summary This guide demonstrates how to use health checks in a Helidon SE application as follows: Access the default health checks Create and use custom readiness, liveness, and startup checks Customize the health check root path Integrate Helidon health check with Kubernetes Refer to the following reference for additional information: Helidon Javadoc ",
            "title": "What You Need"
        },
        {
            "location": "/se/guides/jlink-image",
            "text": " This guide describes how to build a custom runtime image for your Helidon application using Helidon&#8217;s support for the JDK&#8217;s jlink tool. ",
            "title": "preambule"
        },
        {
            "location": "/se/guides/jlink-image",
            "text": " JDK 9 introduced the jlink command that supports assembling a set of modules and their dependencies into a custom runtime image. The helidon-maven-plugin has support for easily creating a custom runtime image for your Helidon application resulting in a smaller, better performing runtime. In this guide you will learn how to build a custom runtime image locally on your machine, as well as how to build it in a Docker image. ",
            "title": "Introduction"
        },
        {
            "location": "/se/guides/jlink-image",
            "text": " For this 10 minute tutorial, you will need the following: <div class=\"table__overflow elevation-1 flex sm7 \"> A Helidon SE Application You can use your own application or use the Helidon SE Quickstart to create a sample application. Java&#160;SE&#160;21 ( Open&#160;JDK&#160;21 ) Helidon requires Java 21+. Maven 3.8+ Helidon requires Maven 3.8+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop . <markup lang=\"bash\" title=\"Verify Prerequisites\" >java -version mvn --version docker --version kubectl version --short <markup lang=\"bash\" title=\"Setting JAVA_HOME\" ># On Mac export JAVA_HOME=`/usr/libexec/java_home -v 21` # On Linux # Use the appropriate path to your JDK export JAVA_HOME=/usr/lib/jvm/jdk-21 ",
            "title": "What You Need"
        },
        {
            "location": "/se/guides/jlink-image",
            "text": " As noted in the prerequisites above, JDK 21 or newer is required. <markup lang=\"bash\" >$JAVA_HOME/bin/java --version Creating a custom runtime image requires that the JDK modules are present as *.jmod files, and some distributions do not provide them by default. Check the jmods directory to ensure they are present: <markup lang=\"bash\" >ls $JAVA_HOME/jmods OpenJDK on Linux RPM based distributions provide *.jmod files in separate java-*-openjdk-jmods packages. Debian based distributions provide *.jmod files only in the openjdk-*-jdk-headless packages. ",
            "title": "Verify JDK"
        },
        {
            "location": "/se/guides/jlink-image",
            "text": " Generate the project using the Helidon SE Quickstart Maven archetype. <markup lang=\"bash\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-se \\ -DarchetypeVersion=4.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-se \\ -Dpackage=io.helidon.examples.quickstart.se The archetype generates a Maven project in your current directory (for example, helidon-quickstart-se ). Change into this directory and build. <markup lang=\"bash\" >cd helidon-quickstart-se mvn package At this point you can run the application using the JVM: <markup lang=\"bash\" >java -jar target/helidon-quickstart-se.jar In another shell test an endpoint: <markup lang=\"bash\" >curl -X GET http://localhost:8080/greet The application should respond with {\"message\":\"Hello World!\"} Now stop the running application (by pressing Ctrl+C). For more information about the Quickstart application and other endpoints it supports see the Helidon SE quickstart Guide . ",
            "title": "Generate the Project"
        },
        {
            "location": "/se/guides/jlink-image",
            "text": " Build the custom runtime image using the jlink image profile: <markup lang=\"bash\" >mvn package -Pjlink-image Tip This uses the helidon-maven-plugin to perform the custom image generation. After the build completes it will report some statistics about the build including the reduction in image size. The target/helidon-quickstart-se-jri directory is a self contained custom image of your application. It contains your application, its runtime dependencies and the JDK modules it depends on. You can start your application using the provide start script: <markup lang=\"bash\" >./target/helidon-quickstart-se-jri/bin/start ",
            "title": "Local Build"
        },
        {
            "location": "/se/guides/jlink-image",
            "text": " Also included in the custom image is a Class Data Sharing (CDS) archive that improves your application&#8217;s startup performance and in-memory footprint. You can learn more about Class Data Sharing in the JDK documentation . The CDS archive increases your image size to get these performance optimizations. It can be of significant size (tens of MB). The size of the CDS archive is reported at the end of the build output. If you&#8217;d rather have a smaller image size (with a slightly increased startup time) you can skip the creation of the CDS archive by executing your build like this: <markup lang=\"bash\" >mvn package -Pjlink-image -Djlink.image.addClassDataSharingArchive=false For more information on available configuration options see the helidon-maven-plugin documentation . ",
            "title": "Class Data Sharing (CDS) Archive"
        },
        {
            "location": "/se/guides/jlink-image",
            "text": " To build a Docker image with a custom Java runtime image use the jlink Dockerfile included with the quickstart. <markup lang=\"bash\" >docker build -t helidon-quickstart-se-jri -f Dockerfile.jlink . Tip This does a full build inside the Docker container. The first time you run it, it will take a while because it is downloading all of the Maven dependencies and caching them in a Docker layer. Subsequent builds will be much faster as long as you don&#8217;t change the pom.xml file. If the pom is modified then the dependencies will be re-downloaded. Start the application: <markup lang=\"bash\" >docker run --rm -p 8080:8080 helidon-quickstart-se-jri:latest You can exercise the application&#8217;s endpoints as before. ",
            "title": "Multi-Stage Docker Build"
        },
        {
            "location": "/se/guides/jlink-image",
            "text": " You can build a custom runtime image in 2 different ways: Locally, on your desktop Using Docker Local Build Build the custom runtime image using the jlink image profile: <markup lang=\"bash\" >mvn package -Pjlink-image Tip This uses the helidon-maven-plugin to perform the custom image generation. After the build completes it will report some statistics about the build including the reduction in image size. The target/helidon-quickstart-se-jri directory is a self contained custom image of your application. It contains your application, its runtime dependencies and the JDK modules it depends on. You can start your application using the provide start script: <markup lang=\"bash\" >./target/helidon-quickstart-se-jri/bin/start Class Data Sharing (CDS) Archive Also included in the custom image is a Class Data Sharing (CDS) archive that improves your application&#8217;s startup performance and in-memory footprint. You can learn more about Class Data Sharing in the JDK documentation . The CDS archive increases your image size to get these performance optimizations. It can be of significant size (tens of MB). The size of the CDS archive is reported at the end of the build output. If you&#8217;d rather have a smaller image size (with a slightly increased startup time) you can skip the creation of the CDS archive by executing your build like this: <markup lang=\"bash\" >mvn package -Pjlink-image -Djlink.image.addClassDataSharingArchive=false For more information on available configuration options see the helidon-maven-plugin documentation . Multi-Stage Docker Build To build a Docker image with a custom Java runtime image use the jlink Dockerfile included with the quickstart. <markup lang=\"bash\" >docker build -t helidon-quickstart-se-jri -f Dockerfile.jlink . Tip This does a full build inside the Docker container. The first time you run it, it will take a while because it is downloading all of the Maven dependencies and caching them in a Docker layer. Subsequent builds will be much faster as long as you don&#8217;t change the pom.xml file. If the pom is modified then the dependencies will be re-downloaded. Start the application: <markup lang=\"bash\" >docker run --rm -p 8080:8080 helidon-quickstart-se-jri:latest You can exercise the application&#8217;s endpoints as before. ",
            "title": "Building a Custom Runtime Image"
        },
        {
            "location": "/se/guides/jlink-image",
            "text": " Custom runtime images are ideal for use when you want all of the runtime performance of the JDK JVM in a reasonably compact form. For cases where absolute minimal startup time and image size are required, then consider using GraalVM Native Images . ",
            "title": "Using Custom Runtime Images"
        },
        {
            "location": "/se/guides/maven-build",
            "text": " This guide describes Helidon&#8217;s support for Maven projects. ",
            "title": "preambule"
        },
        {
            "location": "/se/guides/maven-build",
            "text": " Helidon supports Maven by providing the following: The Helidon Application parent POM Dependency management via the Helidon BOM and Dependencies POMs The helidon-maven-plugin ",
            "title": "Introduction"
        },
        {
            "location": "/se/guides/maven-build",
            "text": " Helidon examples and projects generated using the Helidon Quickstart use a Helidon application POM as their parent. This parent POM provides the following: Helidon dependency management. Maven plugin configurations to help in the building and packaging of your Helidon application. If you want to use your own parent POM, then take a look at the standalone quickstart example . This example has a stand-alone POM that you can pattern your own application POM after. For more details on Helidon application POMs see the Helidon&#8217;s Application POMS ",
            "title": "The Helidon Application POM"
        },
        {
            "location": "/se/guides/maven-build",
            "text": " In Maven you use Dependency Management to manage the versions of the dependencies used by your project so that you do not need to specify versions when declaring project dependencies. Helidon provides two POMs that are used together for dependency management: The Helidon Bill of Materials (BOM) POM ( io.helidon:helidon-bom ): manages the version of Helidon artifacts (to align with the Helidon version). The Helidon Dependencies POM ( io.helidon:helidon-dependencies ): manages the versions of third party dependencies to ensure consistency across Helidon and your Helidon application. Inherits the Helidon BOM POM. When you use a Helidon Application POM as your project&#8217;s parent pom, you inherit Helidon&#8217;s dependency management. If you have your own parent, then you can import Helidon dependency management like this: <markup lang=\"xml\" title=\"Import Helidon Dependency Management\" >&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon&lt;/groupId&gt; &lt;artifactId&gt;helidon-dependencies&lt;/artifactId&gt; &lt;version&gt;4.0.2&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; You then declare dependencies on Helidon (and other) components without specifying a version. <markup lang=\"xml\" title=\"Component dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.config&lt;/groupId&gt; &lt;artifactId&gt;helidon-config-yaml&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Dependency Management"
        },
        {
            "location": "/se/guides/maven-build",
            "text": " You can override many of the plugin attributes by passing a system property to the mvn command: <markup lang=\"bash\" >mvn -Djlink.image.addClassDataSharingArchive=false package ",
            "title": "Pass Property on Command Line"
        },
        {
            "location": "/se/guides/maven-build",
            "text": " Or you can set the properties in your project&#8217;s pom.xml: <markup lang=\"xml\" >&lt;properties&gt; &lt;jlink.image.addClassDataSharingArchive&gt;false&lt;/jlink.image.addClassDataSharingArchive&gt; &lt;native.image.reportExceptionStackTraces&gt;true&lt;/native.image.reportExceptionStackTraces&gt; &lt;/properties&gt; ",
            "title": "Set Property in pom.xml"
        },
        {
            "location": "/se/guides/maven-build",
            "text": " For full control you can override the plugin&#8217;s configuration using pluginManagement : <markup lang=\"xml\" title=\"Turn off generation of the CDS Archive when generating a custom Java runtime image\" > &lt;build&gt; &lt;pluginManagement&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;io.helidon.build-tools&lt;/groupId&gt; &lt;artifactId&gt;helidon-maven-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;jlink-image&lt;/id&gt; &lt;configuration&gt; &lt;addClassDataSharingArchive&gt;false&lt;/addClassDataSharingArchive&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;/build&gt; ",
            "title": "Override Plugin Configuration using pluginManagement "
        },
        {
            "location": "/se/guides/maven-build",
            "text": " Helidon provides a Maven plugin that, among other things, provides the following goals: jlink-image: Build a custom runtime Java image . native-image: Build a GraalVM native image . Note: this capability is now provided via the Maven plugin for GraalVM Native Image For full documentation of the plugin please see the Helidon Maven Plugin README . If you use the Helidon application parent POM you will have this plugin configured for you. If you need to customize the helidon-maven-plugin you can do so in a few ways: Passing system properties to Maven on the command line. Setting system properties in your project&#8217;s pom.xml Overriding the plugin configuration by using pluginManagment Pass Property on Command Line You can override many of the plugin attributes by passing a system property to the mvn command: <markup lang=\"bash\" >mvn -Djlink.image.addClassDataSharingArchive=false package Set Property in pom.xml Or you can set the properties in your project&#8217;s pom.xml: <markup lang=\"xml\" >&lt;properties&gt; &lt;jlink.image.addClassDataSharingArchive&gt;false&lt;/jlink.image.addClassDataSharingArchive&gt; &lt;native.image.reportExceptionStackTraces&gt;true&lt;/native.image.reportExceptionStackTraces&gt; &lt;/properties&gt; Override Plugin Configuration using pluginManagement For full control you can override the plugin&#8217;s configuration using pluginManagement : <markup lang=\"xml\" title=\"Turn off generation of the CDS Archive when generating a custom Java runtime image\" > &lt;build&gt; &lt;pluginManagement&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;io.helidon.build-tools&lt;/groupId&gt; &lt;artifactId&gt;helidon-maven-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;jlink-image&lt;/id&gt; &lt;configuration&gt; &lt;addClassDataSharingArchive&gt;false&lt;/addClassDataSharingArchive&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;/build&gt; ",
            "title": "The helidon-maven-plugin "
        },
        {
            "location": "/se/guides/metrics",
            "text": " This guide describes how to create a sample Helidon {h1-prefix} project that can be used to run some basic examples using both built-in and custom meters with Helidon. ",
            "title": "preambule"
        },
        {
            "location": "/se/guides/metrics",
            "text": " Use the Helidon SE Maven archetype to create a simple project that can be used for the examples in this guide. <markup lang=\"bash\" title=\"Run the Maven archetype\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-se \\ -DarchetypeVersion=4.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-se \\ -Dpackage=io.helidon.examples.quickstart.se ",
            "title": "Create a Sample Helidon SE Project"
        },
        {
            "location": "/se/guides/metrics",
            "text": " Helidon provides three built-in scopes of metrics: base, vendor, and application. Here are the metric endpoints: /observe/metrics?scope=base - Base meters /observe/metrics?scope=vendor - Helidon-specific meters /observe/metrics?scope=application - Application-specific metrics data. Applications can add their own custom scopes as well simply by specifying a custom scope name when registering a meter. The /observe/metrics endpoint returns data for all scopes. The built-in meters fall into these categories: JVM behavior (in the base scope), and basic key performance indicators for request handling (in the vendor scope). A later section describes the key performance indicator meters in detail. The following example demonstrates how to use the other built-in meters. All examples are executed from the root directory of your project (helidon-quickstart-se). The generated source code is already configured for both metrics and health checks, but the following example removes health checks. <markup lang=\"xml\" title=\"Metrics dependencies in the generated pom.xml :\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webserver.observe&lt;/groupId&gt; &lt;artifactId&gt;helidon-webserver-observe-metrics&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics-system-meters&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; Includes the Helidon observability component for metrics and, as transitive dependencies, the Helidon neutral metrics API and a full-featured implementation of the API. Includes the built-in meters. With these dependencies in your project, Helidon&#8217;s auto-discovery of webserver features automatically finds and runs the metrics subsystem. You do not need to change any of the generated source code. <markup lang=\"bash\" title=\"Build the application and then run it:\" >mvn package java -jar target/helidon-quickstart-se.jar Metrics output can be returned in either text format (the default), or JSON. The text format uses OpenMetrics (Prometheus) Text Format, see https://prometheus.io/docs/instrumenting/exposition_formats/#text-format-details . <markup lang=\"bash\" title=\"Verify the metrics endpoint in a new terminal window:\" >curl http://localhost:8080/observe/metrics <markup lang=\"text\" title=\"Text response:\" ># TYPE base:classloader_current_loaded_class_count counter # HELP base:classloader_current_loaded_class_count Displays the number of classes that are currently loaded in the Java virtual machine. base:classloader_current_loaded_class_count 7511 # TYPE base:classloader_total_loaded_class_count counter # HELP base:classloader_total_loaded_class_count Displays the total number of classes that have been loaded since the Java virtual machine has started execution. base:classloader_total_loaded_class_count 7512 You can get the same data in JSON format. <markup lang=\"bash\" title=\"Verify the metrics endpoint with an HTTP accept header:\" >curl -H \"Accept: application/json\" http://localhost:8080/observe/metrics <markup lang=\"json\" title=\"JSON response:\" >{ \"base\": { \"gc.total;name=G1 Young Generation\": 1, \"cpu.systemLoadAverage\": 4.451171875, \"classloader.loadedClasses.count\": 3582, \"thread.count\": 18, \"classloader.unloadedClasses.total\": 0, \"jvm.uptime\": 36.9478, \"gc.time;name=G1 Young Generation\": 0, \"memory.committedHeap\": 541065216, \"thread.max.count\": 19, \"cpu.availableProcessors\": 8, \"classloader.loadedClasses.total\": 3582, \"thread.daemon.count\": 16, \"memory.maxHeap\": 8589934592, \"memory.usedHeap\": 20491248 }, \"vendor\": { \"requests.count\": 3 } } You can get a single metric by specifying the scope and name as query parameters in the URL. <markup lang=\"bash\" title=\"Get the Helidon requests.count meter:\" >curl -H \"Accept: application/json\" 'http://localhost:8080/observe/metrics?scope=vendor&amp;name=requests.count' <markup lang=\"json\" title=\"JSON response:\" >{ \"requests.count\": 6 } The base meters illustrated above provide some insight into the behavior of the JVM in which the server runs. The vendor meter shown above gives an idea of the request traffic the server is handling. See the later section for more information on the basic and extended key performance indicator meters. ",
            "title": "Using the Built-In Meters"
        },
        {
            "location": "/se/guides/metrics",
            "text": " You can disable the metrics subsystem entirely using configuration: <markup lang=\"yaml\" title=\"Configuration properties file disabling metrics\" >server: features: observe: observers: metrics: enabled: false A Helidon SE application can disable metrics processing programmatically. <markup lang=\"java\" title=\"Disable all metrics behavior\" > ObserveFeature observe = ObserveFeature.builder() .addObserver(metricsObserer.builder() .enabled(false) .build()) .build(); WebServer server = WebServer.builder() .config(Config.global().get(\"server\")) .addFeature(observe) .routing(Main::routing) .build() .start(); Begin preparing the ObserveFeature . Begin preparing the MetricsObserver . Disable metrics. Complete the MetricsObserver . Complete the ObserveFeature . Create and start the WebServer with the ObserveFeature (and other settings). These builders and interfaces also have methods which accept Config objects representing the metrics node from the application configuration. With metrics processing disabled, Helidon never updates any meters and the /observe/metrics endpoints respond with 404 . ",
            "title": "Disabling Metrics Subsystem Entirely"
        },
        {
            "location": "/se/guides/metrics",
            "text": " Any time you include the Helidon metrics module in your application, Helidon tracks a basic performance indicator meter: a Counter of all requests received ( requests.count ). Helidon SE also includes additional, extended KPI metrics which are disabled by default: current number of requests in-flight - a Gauge ( requests.inFlight ) of requests currently being processed long-running requests - a Counter ( requests.longRunning ) measuring the total number of requests which take at least a given amount of time to complete; configurable, defaults to 10000 milliseconds (10 seconds) load - a Counter ( requests.load ) measuring the number of requests worked on (as opposed to received) deferred - a Gauge ( requests.deferred ) measuring delayed request processing (work on a request was delayed after Helidon received the request) You can enable and control these meters using configuration: <markup lang=\"yaml\" >server: features: observe: observers: metrics: key-performance-indicators: extended: true long-running: threshold-ms: 2000 Your Helidon SE application can also control the KPI settings programmatically. <markup lang=\"java\" title=\"Assign KPI metrics behavior from code\" > KeyPerformanceIndicatorMetricsConfig kpiConfig = KeyPerformanceIndicatorMetricsConfig.builder() .extended(true) .longRunningRequestThreshold(Duration.ofSeconds(4)) .build(); MetricsObserver metrics = MetricsObserver.builder() .metricsConfig(MetricsConfig.builder() .keyPerformanceIndicatorMetricsConfig(kpiConfig)) .build(); ObserveFeature observe = ObserveFeature.builder() .config(config.get(\"server.features.observe\")) .addObserver(metrics) .build(); WebServer server = WebServer.builder() .config(Config.global().get(\"server\")) .addFeature(observe) .routing(Main::routing) .build() .start(); Create a KeyPerformanceIndicatorMetricsConfig instance (via its Builder ) with non-default values. Enabled extended KPI meters. Set the long-running request threshold. Prepare the metrics observer&#8217;s builder. Update the metrics observer&#8217;s builder using the just-prepared KPI metrics config. Add the metrics observer to the ObserveFeature . Add the ObserveFeature to the WebServer . ",
            "title": "Collecting Basic and Extended Key Performance Indicator (KPI) Metrics"
        },
        {
            "location": "/se/guides/metrics",
            "text": " By adding a metrics section to your application configuration you can control how the Helidon metrics subsystem behaves in any of several ways. Disable metrics subsystem entirely . Select whether to collect extended key performance indicator meters . Your Helidon SE application can also control metrics processing programmatically as described in the following sections. Disabling Metrics Subsystem Entirely You can disable the metrics subsystem entirely using configuration: <markup lang=\"yaml\" title=\"Configuration properties file disabling metrics\" >server: features: observe: observers: metrics: enabled: false A Helidon SE application can disable metrics processing programmatically. <markup lang=\"java\" title=\"Disable all metrics behavior\" > ObserveFeature observe = ObserveFeature.builder() .addObserver(metricsObserer.builder() .enabled(false) .build()) .build(); WebServer server = WebServer.builder() .config(Config.global().get(\"server\")) .addFeature(observe) .routing(Main::routing) .build() .start(); Begin preparing the ObserveFeature . Begin preparing the MetricsObserver . Disable metrics. Complete the MetricsObserver . Complete the ObserveFeature . Create and start the WebServer with the ObserveFeature (and other settings). These builders and interfaces also have methods which accept Config objects representing the metrics node from the application configuration. With metrics processing disabled, Helidon never updates any meters and the /observe/metrics endpoints respond with 404 . Collecting Basic and Extended Key Performance Indicator (KPI) Metrics Any time you include the Helidon metrics module in your application, Helidon tracks a basic performance indicator meter: a Counter of all requests received ( requests.count ). Helidon SE also includes additional, extended KPI metrics which are disabled by default: current number of requests in-flight - a Gauge ( requests.inFlight ) of requests currently being processed long-running requests - a Counter ( requests.longRunning ) measuring the total number of requests which take at least a given amount of time to complete; configurable, defaults to 10000 milliseconds (10 seconds) load - a Counter ( requests.load ) measuring the number of requests worked on (as opposed to received) deferred - a Gauge ( requests.deferred ) measuring delayed request processing (work on a request was delayed after Helidon received the request) You can enable and control these meters using configuration: <markup lang=\"yaml\" >server: features: observe: observers: metrics: key-performance-indicators: extended: true long-running: threshold-ms: 2000 Your Helidon SE application can also control the KPI settings programmatically. <markup lang=\"java\" title=\"Assign KPI metrics behavior from code\" > KeyPerformanceIndicatorMetricsConfig kpiConfig = KeyPerformanceIndicatorMetricsConfig.builder() .extended(true) .longRunningRequestThreshold(Duration.ofSeconds(4)) .build(); MetricsObserver metrics = MetricsObserver.builder() .metricsConfig(MetricsConfig.builder() .keyPerformanceIndicatorMetricsConfig(kpiConfig)) .build(); ObserveFeature observe = ObserveFeature.builder() .config(config.get(\"server.features.observe\")) .addObserver(metrics) .build(); WebServer server = WebServer.builder() .config(Config.global().get(\"server\")) .addFeature(observe) .routing(Main::routing) .build() .start(); Create a KeyPerformanceIndicatorMetricsConfig instance (via its Builder ) with non-default values. Enabled extended KPI meters. Set the long-running request threshold. Prepare the metrics observer&#8217;s builder. Update the metrics observer&#8217;s builder using the just-prepared KPI metrics config. Add the metrics observer to the ObserveFeature . Add the ObserveFeature to the WebServer . ",
            "title": "Controlling Metrics Behavior"
        },
        {
            "location": "/se/guides/metrics",
            "text": " Each meter has associated metadata that includes: name: The name of the meter. units: The unit of the meter such as time (seconds, milliseconds), size (bytes, megabytes), etc. a description of the meter. You can get the metadata for any scope, such as /observe/metrics?scope=base , as shown below: <markup lang=\"bash\" title=\"Get the metrics metadata using HTTP OPTIONS method:\" > curl -X OPTIONS -H \"Accept: application/json\" 'http://localhost:8080/observe/metrics?scope=base' <markup lang=\"json\" title=\"JSON response (truncated):\" >{ \"classloader.loadedClasses.count\": { \"type\": \"gauge\", \"description\": \"Displays the number of classes that are currently loaded in the Java virtual machine.\" }, \"jvm.uptime\": { \"type\": \"gauge\", \"unit\": \"seconds\", \"description\": \"Displays the start time of the Java virtual machine in milliseconds. This attribute displays the approximate time when the Java virtual machine started.\" }, \"memory.usedHeap\": { \"type\": \"gauge\", \"unit\": \"bytes\", \"description\": \"Displays the amount of used heap memory in bytes.\" } } ",
            "title": "Metrics Metadata"
        },
        {
            "location": "/se/guides/metrics",
            "text": " The Counter meter is a monotonically increasing number. The following example demonstrates how to use a Counter to track the number of times the /cards endpoint is called. <markup lang=\"java\" title=\"Create a new class named GreetingCards with the following code:\" >package io.helidon.examples.quickstart.se; import java.util.Collections; import io.helidon.metrics.api.Counter; import io.helidon.metrics.api.Metrics; import io.helidon.webserver.http.HttpRules; import io.helidon.webserver.http.HttpService; import io.helidon.webserver.http.ServerRequest; import io.helidon.webserver.http.ServerResponse; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; public class GreetingCards implements HttpService { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); private final Counter cardCounter; GreetingCards() { cardCounter = Metrics.globalRegistry() .getOrCreate(Counter.builder(\"cardCount\") .description(\"Counts card retrievals\")); } @Override public void routing(HttpRules rules) { rules.get(\"/\", this::getDefaultMessageHandler); } private void getDefaultMessageHandler(ServerRequest request, ServerResponse response) { cardCounter.increment(); sendResponse(response, \"Here are some cards ...\"); } private void sendResponse(ServerResponse response, String msg) { JsonObject returnObject = JSON.createObjectBuilder().add(\"message\", msg).build(); response.send(returnObject); } } Import metrics types. Declare a Counter member field. Create and register the Counter meter in the global meter registry`. This Counter will exist for the lifetime of the application. Increment the count. <markup lang=\"java\" title=\"Update the Main.routing method as follows:\" > static void routing(HttpRouting.Builder routing) { Config config = Config.global(); routing .register(\"/greet\", new GreetService()) .register(\"/cards\", new GreetingCards()) .get(\"/simple-greet\", (req, res) -&gt; res.send(\"Hello World!\")); } Add the GreetingCards service to the routing. Helidon routes any REST requests with the /cards root path to the GreetingCards service. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints below:\" >curl http://localhost:8080/cards curl -H \"Accept: application/json\" 'http://localhost:8080/observe/metrics?scope=application' <markup lang=\"json\" title=\"JSON response:\" >{ \"cardCount\": 1 } The count value is one since the method was called once. ",
            "title": "Counter Meter"
        },
        {
            "location": "/se/guides/metrics",
            "text": " The Timer meter aggregates durations. In the following example, a Timer meter measures the duration of a method&#8217;s execution. Whenever the REST /cards endpoint is called, the code updates the Timer with additional timing information. <markup lang=\"java\" title=\"Replace the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.se; import java.util.Collections; import io.helidon.metrics.api.Metrics; import io.helidon.metrics.api.Timer; import io.helidon.webserver.http.HttpRules; import io.helidon.webserver.http.HttpService; import io.helidon.webserver.http.ServerRequest; import io.helidon.webserver.http.ServerResponse; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; public class GreetingCards implements HttpService { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); private final Timer cardTimer; GreetingCards() { cardTimer = Metrics.globalRegistry() .getOrCreate(Timer.builder(\"cardTimer\") .description(\"Times card retrievals\")); } @Override public void routing(HttpRules rules) { rules.get(\"/\", this::getDefaultMessageHandler); } private void getDefaultMessageHandler(ServerRequest request, ServerResponse response) { Timer.Sample timerSample = Timer.start(); sendResponse(response, \"Here are some cards ...\"); response.whenSent(() -&gt; timerSample.stop(cardTimer)); } private void sendResponse(ServerResponse response, String msg) { JsonObject returnObject = JSON.createObjectBuilder().add(\"message\", msg).build(); response.send(returnObject); } } Import relevant metrics classes. Declare a Timer member field. Create and register the Timer metric in the global meter registry. Create a timer sample which, among other things, automatically records the starting time. Arrange for the timer sample to be stopped and applied to the cardTimer once Helidon sends the response to the client. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints below:\" >curl http://localhost:8080/cards curl http://localhost:8080/cards curl -H \"Accept: application/json\" 'http://localhost:8080/observe/metrics?scope=application' <markup lang=\"json\" title=\"JSON response:\" >{ \"cardTimer\": { \"count\": 2, \"max\": 0.01439681, \"mean\": 0.0073397075, \"elapsedTime\": 0.014679415, \"p0.5\": 0.000278528, \"p0.75\": 0.01466368, \"p0.95\": 0.01466368, \"p0.98\": 0.01466368, \"p0.99\": 0.01466368, \"p0.999\": 0.01466368 } } Helidon updated the timer statistics for each of the two accesses to the /cards endpoint. ",
            "title": "Timer Meter"
        },
        {
            "location": "/se/guides/metrics",
            "text": " The DistributionSummary meter calculates the distribution of a set of values within ranges. This meter does not relate to time at all. The following example records a set of random numbers in a DistributionSummary meter when the /cards endpoint is invoked. <markup lang=\"java\" title=\"Replace the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.se; import java.util.Collections; import java.util.Random; import io.helidon.metrics.api.DistributionSummary; import io.helidon.metrics.api.Metrics; import io.helidon.webserver.http.HttpRules; import io.helidon.webserver.http.HttpService; import io.helidon.webserver.http.ServerRequest; import io.helidon.webserver.http.ServerResponse; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; public class GreetingCards implements HttpService { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); private final DistributionSummary cardSummary; GreetingCards() { cardSummary = Metrics.globalRegistry() .getOrCreate(DistributionSummary.builder(\"cardDist\") .description(\"random card distribution\")); } @Override public void routing(HttpRules rules) { rules.get(\"/\", this::getDefaultMessageHandler); } private void getDefaultMessageHandler(ServerRequest request, ServerResponse response) { Random r = new Random(); for (int i = 0; i &lt; 1000; i++) { cardSummary.record(1 + r.nextDouble()); } sendResponse(response, \"Here are some cards ...\"); } private void sendResponse(ServerResponse response, String msg) { JsonObject returnObject = JSON.createObjectBuilder().add(\"message\", msg).build(); response.send(returnObject); } } Import relevant metrics classes. Declare a DistributionSummary member field. Create and register the DistributionSummary meter in the global meter registry Update the distribution summary with a random number multiple times for each request. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints below:\" >curl http://localhost:8080/cards curl -H \"Accept: application/json\" 'http://localhost:8080/observe/metrics?scope=application' <markup lang=\"json\" title=\"JSON response:\" >{ \"cardDist\": { \"count\": 1000, \"max\": 1.999805150914427, \"mean\": 1.4971440362723523, \"total\": 1497.1440362723522, \"p0.5\": 1.4375, \"p0.75\": 1.6875, \"p0.95\": 1.9375, \"p0.98\": 1.9375, \"p0.99\": 1.9375, \"p0.999\": 1.9375 } } The DistributionSummary.Builder allows your code to configure other aspects of the summary, such as bucket boundaries and percentiles to track. ",
            "title": "Distribution Summary Meters"
        },
        {
            "location": "/se/guides/metrics",
            "text": " The Gauge meter measures a value that is maintained by code outside the metrics subsystem. As with other meters, the application explicitly registers a gauge. When the /observe/metrics endpoint is invoked, Helidon retrieves the value of each registered Gauge . The following example demonstrates how a Gauge is used to get the current temperature. <markup lang=\"java\" title=\"Replace the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.se; import java.util.Collections; import java.util.Random; import io.helidon.metrics.api.Gauge; import io.helidon.metrics.api.Metrics; import io.helidon.webserver.http.HttpRules; import io.helidon.webserver.http.HttpService; import io.helidon.webserver.http.ServerRequest; import io.helidon.webserver.http.ServerResponse; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; public class GreetingCards implements HttpService { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); GreetingCards() { Random r = new Random(); Metrics.globalRegistry() .getOrCreate(Gauge.builder(\"temperature\", () -&gt; r.nextDouble(100.0)) .description(\"Ambient temperature\")); } @Override public void routing(HttpRules rules) { rules.get(\"/\", this::getDefaultMessageHandler); } private void getDefaultMessageHandler(ServerRequest request, ServerResponse response) { sendResponse(response, \"Here are some cards ...\"); } private void sendResponse(ServerResponse response, String msg) { JsonObject returnObject = JSON.createObjectBuilder().add(\"message\", msg).build(); response.send(returnObject); } } Register the Gauge , passing a Supplier&lt;Double&gt; which furnishes a random temperature from 0 to 100.0 each time the metrics system interrogates the gauge. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint below:\" >curl -H \"Accept: application/json\" 'http://localhost:8080/observe/metrics?scope=application <markup lang=\"json\" title=\"JSON response:\" >{ \"temperature\": 46.582132737739066 } The current (random) temperature. Accessing the endpoint again returns a different value. ",
            "title": "Gauge Metric"
        },
        {
            "location": "/se/guides/metrics",
            "text": " This section demonstrates how to use application-specific meters and integrate them with Helidon, starting from a Helidon SE QuickStart application. It is the application&#8217;s responsibility to create and update the meters at runtime. The application has complete control over when and how each meter is used. For example, an application may use the same counter for multiple methods, or one counter per method. Helidon maintains a single meter registry which holds all meters. In all of these examples, the code uses a meter builder specific to the type of meter needed to register a new meter or locate a previous-registered meter. Counter Meter The Counter meter is a monotonically increasing number. The following example demonstrates how to use a Counter to track the number of times the /cards endpoint is called. <markup lang=\"java\" title=\"Create a new class named GreetingCards with the following code:\" >package io.helidon.examples.quickstart.se; import java.util.Collections; import io.helidon.metrics.api.Counter; import io.helidon.metrics.api.Metrics; import io.helidon.webserver.http.HttpRules; import io.helidon.webserver.http.HttpService; import io.helidon.webserver.http.ServerRequest; import io.helidon.webserver.http.ServerResponse; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; public class GreetingCards implements HttpService { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); private final Counter cardCounter; GreetingCards() { cardCounter = Metrics.globalRegistry() .getOrCreate(Counter.builder(\"cardCount\") .description(\"Counts card retrievals\")); } @Override public void routing(HttpRules rules) { rules.get(\"/\", this::getDefaultMessageHandler); } private void getDefaultMessageHandler(ServerRequest request, ServerResponse response) { cardCounter.increment(); sendResponse(response, \"Here are some cards ...\"); } private void sendResponse(ServerResponse response, String msg) { JsonObject returnObject = JSON.createObjectBuilder().add(\"message\", msg).build(); response.send(returnObject); } } Import metrics types. Declare a Counter member field. Create and register the Counter meter in the global meter registry`. This Counter will exist for the lifetime of the application. Increment the count. <markup lang=\"java\" title=\"Update the Main.routing method as follows:\" > static void routing(HttpRouting.Builder routing) { Config config = Config.global(); routing .register(\"/greet\", new GreetService()) .register(\"/cards\", new GreetingCards()) .get(\"/simple-greet\", (req, res) -&gt; res.send(\"Hello World!\")); } Add the GreetingCards service to the routing. Helidon routes any REST requests with the /cards root path to the GreetingCards service. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints below:\" >curl http://localhost:8080/cards curl -H \"Accept: application/json\" 'http://localhost:8080/observe/metrics?scope=application' <markup lang=\"json\" title=\"JSON response:\" >{ \"cardCount\": 1 } The count value is one since the method was called once. Timer Meter The Timer meter aggregates durations. In the following example, a Timer meter measures the duration of a method&#8217;s execution. Whenever the REST /cards endpoint is called, the code updates the Timer with additional timing information. <markup lang=\"java\" title=\"Replace the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.se; import java.util.Collections; import io.helidon.metrics.api.Metrics; import io.helidon.metrics.api.Timer; import io.helidon.webserver.http.HttpRules; import io.helidon.webserver.http.HttpService; import io.helidon.webserver.http.ServerRequest; import io.helidon.webserver.http.ServerResponse; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; public class GreetingCards implements HttpService { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); private final Timer cardTimer; GreetingCards() { cardTimer = Metrics.globalRegistry() .getOrCreate(Timer.builder(\"cardTimer\") .description(\"Times card retrievals\")); } @Override public void routing(HttpRules rules) { rules.get(\"/\", this::getDefaultMessageHandler); } private void getDefaultMessageHandler(ServerRequest request, ServerResponse response) { Timer.Sample timerSample = Timer.start(); sendResponse(response, \"Here are some cards ...\"); response.whenSent(() -&gt; timerSample.stop(cardTimer)); } private void sendResponse(ServerResponse response, String msg) { JsonObject returnObject = JSON.createObjectBuilder().add(\"message\", msg).build(); response.send(returnObject); } } Import relevant metrics classes. Declare a Timer member field. Create and register the Timer metric in the global meter registry. Create a timer sample which, among other things, automatically records the starting time. Arrange for the timer sample to be stopped and applied to the cardTimer once Helidon sends the response to the client. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints below:\" >curl http://localhost:8080/cards curl http://localhost:8080/cards curl -H \"Accept: application/json\" 'http://localhost:8080/observe/metrics?scope=application' <markup lang=\"json\" title=\"JSON response:\" >{ \"cardTimer\": { \"count\": 2, \"max\": 0.01439681, \"mean\": 0.0073397075, \"elapsedTime\": 0.014679415, \"p0.5\": 0.000278528, \"p0.75\": 0.01466368, \"p0.95\": 0.01466368, \"p0.98\": 0.01466368, \"p0.99\": 0.01466368, \"p0.999\": 0.01466368 } } Helidon updated the timer statistics for each of the two accesses to the /cards endpoint. Distribution Summary Meters The DistributionSummary meter calculates the distribution of a set of values within ranges. This meter does not relate to time at all. The following example records a set of random numbers in a DistributionSummary meter when the /cards endpoint is invoked. <markup lang=\"java\" title=\"Replace the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.se; import java.util.Collections; import java.util.Random; import io.helidon.metrics.api.DistributionSummary; import io.helidon.metrics.api.Metrics; import io.helidon.webserver.http.HttpRules; import io.helidon.webserver.http.HttpService; import io.helidon.webserver.http.ServerRequest; import io.helidon.webserver.http.ServerResponse; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; public class GreetingCards implements HttpService { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); private final DistributionSummary cardSummary; GreetingCards() { cardSummary = Metrics.globalRegistry() .getOrCreate(DistributionSummary.builder(\"cardDist\") .description(\"random card distribution\")); } @Override public void routing(HttpRules rules) { rules.get(\"/\", this::getDefaultMessageHandler); } private void getDefaultMessageHandler(ServerRequest request, ServerResponse response) { Random r = new Random(); for (int i = 0; i &lt; 1000; i++) { cardSummary.record(1 + r.nextDouble()); } sendResponse(response, \"Here are some cards ...\"); } private void sendResponse(ServerResponse response, String msg) { JsonObject returnObject = JSON.createObjectBuilder().add(\"message\", msg).build(); response.send(returnObject); } } Import relevant metrics classes. Declare a DistributionSummary member field. Create and register the DistributionSummary meter in the global meter registry Update the distribution summary with a random number multiple times for each request. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints below:\" >curl http://localhost:8080/cards curl -H \"Accept: application/json\" 'http://localhost:8080/observe/metrics?scope=application' <markup lang=\"json\" title=\"JSON response:\" >{ \"cardDist\": { \"count\": 1000, \"max\": 1.999805150914427, \"mean\": 1.4971440362723523, \"total\": 1497.1440362723522, \"p0.5\": 1.4375, \"p0.75\": 1.6875, \"p0.95\": 1.9375, \"p0.98\": 1.9375, \"p0.99\": 1.9375, \"p0.999\": 1.9375 } } The DistributionSummary.Builder allows your code to configure other aspects of the summary, such as bucket boundaries and percentiles to track. Gauge Metric The Gauge meter measures a value that is maintained by code outside the metrics subsystem. As with other meters, the application explicitly registers a gauge. When the /observe/metrics endpoint is invoked, Helidon retrieves the value of each registered Gauge . The following example demonstrates how a Gauge is used to get the current temperature. <markup lang=\"java\" title=\"Replace the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.se; import java.util.Collections; import java.util.Random; import io.helidon.metrics.api.Gauge; import io.helidon.metrics.api.Metrics; import io.helidon.webserver.http.HttpRules; import io.helidon.webserver.http.HttpService; import io.helidon.webserver.http.ServerRequest; import io.helidon.webserver.http.ServerResponse; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; public class GreetingCards implements HttpService { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); GreetingCards() { Random r = new Random(); Metrics.globalRegistry() .getOrCreate(Gauge.builder(\"temperature\", () -&gt; r.nextDouble(100.0)) .description(\"Ambient temperature\")); } @Override public void routing(HttpRules rules) { rules.get(\"/\", this::getDefaultMessageHandler); } private void getDefaultMessageHandler(ServerRequest request, ServerResponse response) { sendResponse(response, \"Here are some cards ...\"); } private void sendResponse(ServerResponse response, String msg) { JsonObject returnObject = JSON.createObjectBuilder().add(\"message\", msg).build(); response.send(returnObject); } } Register the Gauge , passing a Supplier&lt;Double&gt; which furnishes a random temperature from 0 to 100.0 each time the metrics system interrogates the gauge. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint below:\" >curl -H \"Accept: application/json\" 'http://localhost:8080/observe/metrics?scope=application <markup lang=\"json\" title=\"JSON response:\" >{ \"temperature\": 46.582132737739066 } The current (random) temperature. Accessing the endpoint again returns a different value. ",
            "title": "Application-Specific Metrics Data"
        },
        {
            "location": "/se/guides/metrics",
            "text": " The following example shows how to integrate the Helidon SE application with Kubernetes. <markup lang=\"bash\" title=\"Stop the application and build the docker image:\" >docker build -t helidon-metrics-se . <markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named metrics.yaml , with the following content:\" >kind: Service apiVersion: v1 metadata: name: helidon-metrics labels: app: helidon-metrics annotations: prometheus.io/scrape: true spec: type: NodePort selector: app: helidon-metrics ports: - port: 8080 targetPort: 8080 name: http --- kind: Deployment apiVersion: apps/v1 metadata: name: helidon-metrics spec: replicas: 1 selector: matchLabels: app: helidon-metrics template: metadata: labels: app: helidon-metrics version: v1 spec: containers: - name: helidon-metrics image: helidon-metrics-se imagePullPolicy: IfNotPresent ports: - containerPort: 8080 A service of type NodePort that serves the default routes on port 8080 . An annotation that will allow Prometheus to discover and scrape the application pod. A deployment with one replica of a pod. <markup lang=\"bash\" title=\"Create and deploy the application into Kubernetes:\" >kubectl apply -f ./metrics.yaml <markup lang=\"bash\" title=\"Get the service information:\" >kubectl get service/helidon-metrics <markup lang=\"bash\" >NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE helidon-metrics NodePort 10.99.159.2 &lt;none&gt; 8080:31143/TCP 8s A service of type NodePort that serves the default routes on port 31143 . <markup lang=\"bash\" title=\"Verify the metrics endpoint using port 30116 , your port will likely be different:\" >curl http://localhost:31143/metrics Leave the application running in Kubernetes since it will be used for Prometheus integration. ",
            "title": "Kubernetes Integration"
        },
        {
            "location": "/se/guides/metrics",
            "text": " The metrics service that you just deployed into Kubernetes is already annotated with prometheus.io/scrape: . This will allow Prometheus to discover the service and scrape the metrics. This example shows how to install Prometheus into Kubernetes, then verify that it discovered the Helidon metrics in your application. <markup lang=\"bash\" title=\"Install Prometheus and wait until the pod is ready:\" >helm install stable/prometheus --name metrics export POD_NAME=$(kubectl get pods --namespace default -l \"app=prometheus,component=server\" -o jsonpath=\"{.items[0].metadata.name}\") kubectl get pod $POD_NAME You will see output similar to the following. Repeat the kubectl get pod command until you see 2/2 and Running . This may take up to one minute. <markup lang=\"bash\" >metrics-prometheus-server-5fc5dc86cb-79lk4 2/2 Running 0 46s <markup lang=\"bash\" title=\"Create a port-forward so you can access the server URL:\" >kubectl --namespace default port-forward $POD_NAME 7090:9090 Now open your browser and navigate to http://localhost:7090/targets . Search for helidon on the page and you will see your Helidon application as one of the Prometheus targets. ",
            "title": "Prometheus Integration"
        },
        {
            "location": "/se/guides/metrics",
            "text": " You can now delete the Kubernetes resources that were just created during this example. <markup lang=\"bash\" title=\"Delete the Prometheus Kubernetes resources:\" >helm delete --purge metrics <markup lang=\"bash\" title=\"Delete the application Kubernetes resources:\" >kubectl delete -f ./metrics.yaml ",
            "title": "Final Cleanup"
        },
        {
            "location": "/se/guides/metrics",
            "text": " Kubernetes Integration The following example shows how to integrate the Helidon SE application with Kubernetes. <markup lang=\"bash\" title=\"Stop the application and build the docker image:\" >docker build -t helidon-metrics-se . <markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named metrics.yaml , with the following content:\" >kind: Service apiVersion: v1 metadata: name: helidon-metrics labels: app: helidon-metrics annotations: prometheus.io/scrape: true spec: type: NodePort selector: app: helidon-metrics ports: - port: 8080 targetPort: 8080 name: http --- kind: Deployment apiVersion: apps/v1 metadata: name: helidon-metrics spec: replicas: 1 selector: matchLabels: app: helidon-metrics template: metadata: labels: app: helidon-metrics version: v1 spec: containers: - name: helidon-metrics image: helidon-metrics-se imagePullPolicy: IfNotPresent ports: - containerPort: 8080 A service of type NodePort that serves the default routes on port 8080 . An annotation that will allow Prometheus to discover and scrape the application pod. A deployment with one replica of a pod. <markup lang=\"bash\" title=\"Create and deploy the application into Kubernetes:\" >kubectl apply -f ./metrics.yaml <markup lang=\"bash\" title=\"Get the service information:\" >kubectl get service/helidon-metrics <markup lang=\"bash\" >NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE helidon-metrics NodePort 10.99.159.2 &lt;none&gt; 8080:31143/TCP 8s A service of type NodePort that serves the default routes on port 31143 . <markup lang=\"bash\" title=\"Verify the metrics endpoint using port 30116 , your port will likely be different:\" >curl http://localhost:31143/metrics Leave the application running in Kubernetes since it will be used for Prometheus integration. Prometheus Integration The metrics service that you just deployed into Kubernetes is already annotated with prometheus.io/scrape: . This will allow Prometheus to discover the service and scrape the metrics. This example shows how to install Prometheus into Kubernetes, then verify that it discovered the Helidon metrics in your application. <markup lang=\"bash\" title=\"Install Prometheus and wait until the pod is ready:\" >helm install stable/prometheus --name metrics export POD_NAME=$(kubectl get pods --namespace default -l \"app=prometheus,component=server\" -o jsonpath=\"{.items[0].metadata.name}\") kubectl get pod $POD_NAME You will see output similar to the following. Repeat the kubectl get pod command until you see 2/2 and Running . This may take up to one minute. <markup lang=\"bash\" >metrics-prometheus-server-5fc5dc86cb-79lk4 2/2 Running 0 46s <markup lang=\"bash\" title=\"Create a port-forward so you can access the server URL:\" >kubectl --namespace default port-forward $POD_NAME 7090:9090 Now open your browser and navigate to http://localhost:7090/targets . Search for helidon on the page and you will see your Helidon application as one of the Prometheus targets. Final Cleanup You can now delete the Kubernetes resources that were just created during this example. <markup lang=\"bash\" title=\"Delete the Prometheus Kubernetes resources:\" >helm delete --purge metrics <markup lang=\"bash\" title=\"Delete the application Kubernetes resources:\" >kubectl delete -f ./metrics.yaml ",
            "title": "Integration with Kubernetes and Prometheus"
        },
        {
            "location": "/se/guides/metrics",
            "text": " This guide demonstrated how to use metrics in a Helidon SE application using various combinations of meters and scopes. Access meters for all three built-in scopes: base, vendor, and application Configure meters that are updated by the application when an application REST endpoint is invoked Configure a Gauge meter Integrate Helidon metrics with Kubernetes and Prometheus Refer to the following references for additional information: Helidon Javadoc ",
            "title": "Summary"
        },
        {
            "location": "/se/guides/metrics",
            "text": " For this 30 minute tutorial, you will need the following: <div class=\"table__overflow elevation-1 flex sm7 \"> A Helidon SE Application You can use your own application or use the Helidon SE Quickstart to create a sample application. Java&#160;SE&#160;21 ( Open&#160;JDK&#160;21 ) Helidon requires Java 21+. Maven 3.8+ Helidon requires Maven 3.8+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop . Helm To manage Kubernetes applications. <markup lang=\"bash\" title=\"Verify Prerequisites\" >java -version mvn --version docker --version kubectl version --short <markup lang=\"bash\" title=\"Setting JAVA_HOME\" ># On Mac export JAVA_HOME=`/usr/libexec/java_home -v 21` # On Linux # Use the appropriate path to your JDK export JAVA_HOME=/usr/lib/jvm/jdk-21 Create a Sample Helidon SE Project Use the Helidon SE Maven archetype to create a simple project that can be used for the examples in this guide. <markup lang=\"bash\" title=\"Run the Maven archetype\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-se \\ -DarchetypeVersion=4.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-se \\ -Dpackage=io.helidon.examples.quickstart.se Using the Built-In Meters Helidon provides three built-in scopes of metrics: base, vendor, and application. Here are the metric endpoints: /observe/metrics?scope=base - Base meters /observe/metrics?scope=vendor - Helidon-specific meters /observe/metrics?scope=application - Application-specific metrics data. Applications can add their own custom scopes as well simply by specifying a custom scope name when registering a meter. The /observe/metrics endpoint returns data for all scopes. The built-in meters fall into these categories: JVM behavior (in the base scope), and basic key performance indicators for request handling (in the vendor scope). A later section describes the key performance indicator meters in detail. The following example demonstrates how to use the other built-in meters. All examples are executed from the root directory of your project (helidon-quickstart-se). The generated source code is already configured for both metrics and health checks, but the following example removes health checks. <markup lang=\"xml\" title=\"Metrics dependencies in the generated pom.xml :\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webserver.observe&lt;/groupId&gt; &lt;artifactId&gt;helidon-webserver-observe-metrics&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics-system-meters&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; Includes the Helidon observability component for metrics and, as transitive dependencies, the Helidon neutral metrics API and a full-featured implementation of the API. Includes the built-in meters. With these dependencies in your project, Helidon&#8217;s auto-discovery of webserver features automatically finds and runs the metrics subsystem. You do not need to change any of the generated source code. <markup lang=\"bash\" title=\"Build the application and then run it:\" >mvn package java -jar target/helidon-quickstart-se.jar Metrics output can be returned in either text format (the default), or JSON. The text format uses OpenMetrics (Prometheus) Text Format, see https://prometheus.io/docs/instrumenting/exposition_formats/#text-format-details . <markup lang=\"bash\" title=\"Verify the metrics endpoint in a new terminal window:\" >curl http://localhost:8080/observe/metrics <markup lang=\"text\" title=\"Text response:\" ># TYPE base:classloader_current_loaded_class_count counter # HELP base:classloader_current_loaded_class_count Displays the number of classes that are currently loaded in the Java virtual machine. base:classloader_current_loaded_class_count 7511 # TYPE base:classloader_total_loaded_class_count counter # HELP base:classloader_total_loaded_class_count Displays the total number of classes that have been loaded since the Java virtual machine has started execution. base:classloader_total_loaded_class_count 7512 You can get the same data in JSON format. <markup lang=\"bash\" title=\"Verify the metrics endpoint with an HTTP accept header:\" >curl -H \"Accept: application/json\" http://localhost:8080/observe/metrics <markup lang=\"json\" title=\"JSON response:\" >{ \"base\": { \"gc.total;name=G1 Young Generation\": 1, \"cpu.systemLoadAverage\": 4.451171875, \"classloader.loadedClasses.count\": 3582, \"thread.count\": 18, \"classloader.unloadedClasses.total\": 0, \"jvm.uptime\": 36.9478, \"gc.time;name=G1 Young Generation\": 0, \"memory.committedHeap\": 541065216, \"thread.max.count\": 19, \"cpu.availableProcessors\": 8, \"classloader.loadedClasses.total\": 3582, \"thread.daemon.count\": 16, \"memory.maxHeap\": 8589934592, \"memory.usedHeap\": 20491248 }, \"vendor\": { \"requests.count\": 3 } } You can get a single metric by specifying the scope and name as query parameters in the URL. <markup lang=\"bash\" title=\"Get the Helidon requests.count meter:\" >curl -H \"Accept: application/json\" 'http://localhost:8080/observe/metrics?scope=vendor&amp;name=requests.count' <markup lang=\"json\" title=\"JSON response:\" >{ \"requests.count\": 6 } The base meters illustrated above provide some insight into the behavior of the JVM in which the server runs. The vendor meter shown above gives an idea of the request traffic the server is handling. See the later section for more information on the basic and extended key performance indicator meters. Controlling Metrics Behavior By adding a metrics section to your application configuration you can control how the Helidon metrics subsystem behaves in any of several ways. Disable metrics subsystem entirely . Select whether to collect extended key performance indicator meters . Your Helidon SE application can also control metrics processing programmatically as described in the following sections. Disabling Metrics Subsystem Entirely You can disable the metrics subsystem entirely using configuration: <markup lang=\"yaml\" title=\"Configuration properties file disabling metrics\" >server: features: observe: observers: metrics: enabled: false A Helidon SE application can disable metrics processing programmatically. <markup lang=\"java\" title=\"Disable all metrics behavior\" > ObserveFeature observe = ObserveFeature.builder() .addObserver(metricsObserer.builder() .enabled(false) .build()) .build(); WebServer server = WebServer.builder() .config(Config.global().get(\"server\")) .addFeature(observe) .routing(Main::routing) .build() .start(); Begin preparing the ObserveFeature . Begin preparing the MetricsObserver . Disable metrics. Complete the MetricsObserver . Complete the ObserveFeature . Create and start the WebServer with the ObserveFeature (and other settings). These builders and interfaces also have methods which accept Config objects representing the metrics node from the application configuration. With metrics processing disabled, Helidon never updates any meters and the /observe/metrics endpoints respond with 404 . Collecting Basic and Extended Key Performance Indicator (KPI) Metrics Any time you include the Helidon metrics module in your application, Helidon tracks a basic performance indicator meter: a Counter of all requests received ( requests.count ). Helidon SE also includes additional, extended KPI metrics which are disabled by default: current number of requests in-flight - a Gauge ( requests.inFlight ) of requests currently being processed long-running requests - a Counter ( requests.longRunning ) measuring the total number of requests which take at least a given amount of time to complete; configurable, defaults to 10000 milliseconds (10 seconds) load - a Counter ( requests.load ) measuring the number of requests worked on (as opposed to received) deferred - a Gauge ( requests.deferred ) measuring delayed request processing (work on a request was delayed after Helidon received the request) You can enable and control these meters using configuration: <markup lang=\"yaml\" >server: features: observe: observers: metrics: key-performance-indicators: extended: true long-running: threshold-ms: 2000 Your Helidon SE application can also control the KPI settings programmatically. <markup lang=\"java\" title=\"Assign KPI metrics behavior from code\" > KeyPerformanceIndicatorMetricsConfig kpiConfig = KeyPerformanceIndicatorMetricsConfig.builder() .extended(true) .longRunningRequestThreshold(Duration.ofSeconds(4)) .build(); MetricsObserver metrics = MetricsObserver.builder() .metricsConfig(MetricsConfig.builder() .keyPerformanceIndicatorMetricsConfig(kpiConfig)) .build(); ObserveFeature observe = ObserveFeature.builder() .config(config.get(\"server.features.observe\")) .addObserver(metrics) .build(); WebServer server = WebServer.builder() .config(Config.global().get(\"server\")) .addFeature(observe) .routing(Main::routing) .build() .start(); Create a KeyPerformanceIndicatorMetricsConfig instance (via its Builder ) with non-default values. Enabled extended KPI meters. Set the long-running request threshold. Prepare the metrics observer&#8217;s builder. Update the metrics observer&#8217;s builder using the just-prepared KPI metrics config. Add the metrics observer to the ObserveFeature . Add the ObserveFeature to the WebServer . Metrics Metadata Each meter has associated metadata that includes: name: The name of the meter. units: The unit of the meter such as time (seconds, milliseconds), size (bytes, megabytes), etc. a description of the meter. You can get the metadata for any scope, such as /observe/metrics?scope=base , as shown below: <markup lang=\"bash\" title=\"Get the metrics metadata using HTTP OPTIONS method:\" > curl -X OPTIONS -H \"Accept: application/json\" 'http://localhost:8080/observe/metrics?scope=base' <markup lang=\"json\" title=\"JSON response (truncated):\" >{ \"classloader.loadedClasses.count\": { \"type\": \"gauge\", \"description\": \"Displays the number of classes that are currently loaded in the Java virtual machine.\" }, \"jvm.uptime\": { \"type\": \"gauge\", \"unit\": \"seconds\", \"description\": \"Displays the start time of the Java virtual machine in milliseconds. This attribute displays the approximate time when the Java virtual machine started.\" }, \"memory.usedHeap\": { \"type\": \"gauge\", \"unit\": \"bytes\", \"description\": \"Displays the amount of used heap memory in bytes.\" } } Application-Specific Metrics Data This section demonstrates how to use application-specific meters and integrate them with Helidon, starting from a Helidon SE QuickStart application. It is the application&#8217;s responsibility to create and update the meters at runtime. The application has complete control over when and how each meter is used. For example, an application may use the same counter for multiple methods, or one counter per method. Helidon maintains a single meter registry which holds all meters. In all of these examples, the code uses a meter builder specific to the type of meter needed to register a new meter or locate a previous-registered meter. Counter Meter The Counter meter is a monotonically increasing number. The following example demonstrates how to use a Counter to track the number of times the /cards endpoint is called. <markup lang=\"java\" title=\"Create a new class named GreetingCards with the following code:\" >package io.helidon.examples.quickstart.se; import java.util.Collections; import io.helidon.metrics.api.Counter; import io.helidon.metrics.api.Metrics; import io.helidon.webserver.http.HttpRules; import io.helidon.webserver.http.HttpService; import io.helidon.webserver.http.ServerRequest; import io.helidon.webserver.http.ServerResponse; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; public class GreetingCards implements HttpService { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); private final Counter cardCounter; GreetingCards() { cardCounter = Metrics.globalRegistry() .getOrCreate(Counter.builder(\"cardCount\") .description(\"Counts card retrievals\")); } @Override public void routing(HttpRules rules) { rules.get(\"/\", this::getDefaultMessageHandler); } private void getDefaultMessageHandler(ServerRequest request, ServerResponse response) { cardCounter.increment(); sendResponse(response, \"Here are some cards ...\"); } private void sendResponse(ServerResponse response, String msg) { JsonObject returnObject = JSON.createObjectBuilder().add(\"message\", msg).build(); response.send(returnObject); } } Import metrics types. Declare a Counter member field. Create and register the Counter meter in the global meter registry`. This Counter will exist for the lifetime of the application. Increment the count. <markup lang=\"java\" title=\"Update the Main.routing method as follows:\" > static void routing(HttpRouting.Builder routing) { Config config = Config.global(); routing .register(\"/greet\", new GreetService()) .register(\"/cards\", new GreetingCards()) .get(\"/simple-greet\", (req, res) -&gt; res.send(\"Hello World!\")); } Add the GreetingCards service to the routing. Helidon routes any REST requests with the /cards root path to the GreetingCards service. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints below:\" >curl http://localhost:8080/cards curl -H \"Accept: application/json\" 'http://localhost:8080/observe/metrics?scope=application' <markup lang=\"json\" title=\"JSON response:\" >{ \"cardCount\": 1 } The count value is one since the method was called once. Timer Meter The Timer meter aggregates durations. In the following example, a Timer meter measures the duration of a method&#8217;s execution. Whenever the REST /cards endpoint is called, the code updates the Timer with additional timing information. <markup lang=\"java\" title=\"Replace the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.se; import java.util.Collections; import io.helidon.metrics.api.Metrics; import io.helidon.metrics.api.Timer; import io.helidon.webserver.http.HttpRules; import io.helidon.webserver.http.HttpService; import io.helidon.webserver.http.ServerRequest; import io.helidon.webserver.http.ServerResponse; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; public class GreetingCards implements HttpService { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); private final Timer cardTimer; GreetingCards() { cardTimer = Metrics.globalRegistry() .getOrCreate(Timer.builder(\"cardTimer\") .description(\"Times card retrievals\")); } @Override public void routing(HttpRules rules) { rules.get(\"/\", this::getDefaultMessageHandler); } private void getDefaultMessageHandler(ServerRequest request, ServerResponse response) { Timer.Sample timerSample = Timer.start(); sendResponse(response, \"Here are some cards ...\"); response.whenSent(() -&gt; timerSample.stop(cardTimer)); } private void sendResponse(ServerResponse response, String msg) { JsonObject returnObject = JSON.createObjectBuilder().add(\"message\", msg).build(); response.send(returnObject); } } Import relevant metrics classes. Declare a Timer member field. Create and register the Timer metric in the global meter registry. Create a timer sample which, among other things, automatically records the starting time. Arrange for the timer sample to be stopped and applied to the cardTimer once Helidon sends the response to the client. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints below:\" >curl http://localhost:8080/cards curl http://localhost:8080/cards curl -H \"Accept: application/json\" 'http://localhost:8080/observe/metrics?scope=application' <markup lang=\"json\" title=\"JSON response:\" >{ \"cardTimer\": { \"count\": 2, \"max\": 0.01439681, \"mean\": 0.0073397075, \"elapsedTime\": 0.014679415, \"p0.5\": 0.000278528, \"p0.75\": 0.01466368, \"p0.95\": 0.01466368, \"p0.98\": 0.01466368, \"p0.99\": 0.01466368, \"p0.999\": 0.01466368 } } Helidon updated the timer statistics for each of the two accesses to the /cards endpoint. Distribution Summary Meters The DistributionSummary meter calculates the distribution of a set of values within ranges. This meter does not relate to time at all. The following example records a set of random numbers in a DistributionSummary meter when the /cards endpoint is invoked. <markup lang=\"java\" title=\"Replace the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.se; import java.util.Collections; import java.util.Random; import io.helidon.metrics.api.DistributionSummary; import io.helidon.metrics.api.Metrics; import io.helidon.webserver.http.HttpRules; import io.helidon.webserver.http.HttpService; import io.helidon.webserver.http.ServerRequest; import io.helidon.webserver.http.ServerResponse; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; public class GreetingCards implements HttpService { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); private final DistributionSummary cardSummary; GreetingCards() { cardSummary = Metrics.globalRegistry() .getOrCreate(DistributionSummary.builder(\"cardDist\") .description(\"random card distribution\")); } @Override public void routing(HttpRules rules) { rules.get(\"/\", this::getDefaultMessageHandler); } private void getDefaultMessageHandler(ServerRequest request, ServerResponse response) { Random r = new Random(); for (int i = 0; i &lt; 1000; i++) { cardSummary.record(1 + r.nextDouble()); } sendResponse(response, \"Here are some cards ...\"); } private void sendResponse(ServerResponse response, String msg) { JsonObject returnObject = JSON.createObjectBuilder().add(\"message\", msg).build(); response.send(returnObject); } } Import relevant metrics classes. Declare a DistributionSummary member field. Create and register the DistributionSummary meter in the global meter registry Update the distribution summary with a random number multiple times for each request. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints below:\" >curl http://localhost:8080/cards curl -H \"Accept: application/json\" 'http://localhost:8080/observe/metrics?scope=application' <markup lang=\"json\" title=\"JSON response:\" >{ \"cardDist\": { \"count\": 1000, \"max\": 1.999805150914427, \"mean\": 1.4971440362723523, \"total\": 1497.1440362723522, \"p0.5\": 1.4375, \"p0.75\": 1.6875, \"p0.95\": 1.9375, \"p0.98\": 1.9375, \"p0.99\": 1.9375, \"p0.999\": 1.9375 } } The DistributionSummary.Builder allows your code to configure other aspects of the summary, such as bucket boundaries and percentiles to track. Gauge Metric The Gauge meter measures a value that is maintained by code outside the metrics subsystem. As with other meters, the application explicitly registers a gauge. When the /observe/metrics endpoint is invoked, Helidon retrieves the value of each registered Gauge . The following example demonstrates how a Gauge is used to get the current temperature. <markup lang=\"java\" title=\"Replace the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.se; import java.util.Collections; import java.util.Random; import io.helidon.metrics.api.Gauge; import io.helidon.metrics.api.Metrics; import io.helidon.webserver.http.HttpRules; import io.helidon.webserver.http.HttpService; import io.helidon.webserver.http.ServerRequest; import io.helidon.webserver.http.ServerResponse; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; public class GreetingCards implements HttpService { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); GreetingCards() { Random r = new Random(); Metrics.globalRegistry() .getOrCreate(Gauge.builder(\"temperature\", () -&gt; r.nextDouble(100.0)) .description(\"Ambient temperature\")); } @Override public void routing(HttpRules rules) { rules.get(\"/\", this::getDefaultMessageHandler); } private void getDefaultMessageHandler(ServerRequest request, ServerResponse response) { sendResponse(response, \"Here are some cards ...\"); } private void sendResponse(ServerResponse response, String msg) { JsonObject returnObject = JSON.createObjectBuilder().add(\"message\", msg).build(); response.send(returnObject); } } Register the Gauge , passing a Supplier&lt;Double&gt; which furnishes a random temperature from 0 to 100.0 each time the metrics system interrogates the gauge. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint below:\" >curl -H \"Accept: application/json\" 'http://localhost:8080/observe/metrics?scope=application <markup lang=\"json\" title=\"JSON response:\" >{ \"temperature\": 46.582132737739066 } The current (random) temperature. Accessing the endpoint again returns a different value. Integration with Kubernetes and Prometheus Kubernetes Integration The following example shows how to integrate the Helidon SE application with Kubernetes. <markup lang=\"bash\" title=\"Stop the application and build the docker image:\" >docker build -t helidon-metrics-se . <markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named metrics.yaml , with the following content:\" >kind: Service apiVersion: v1 metadata: name: helidon-metrics labels: app: helidon-metrics annotations: prometheus.io/scrape: true spec: type: NodePort selector: app: helidon-metrics ports: - port: 8080 targetPort: 8080 name: http --- kind: Deployment apiVersion: apps/v1 metadata: name: helidon-metrics spec: replicas: 1 selector: matchLabels: app: helidon-metrics template: metadata: labels: app: helidon-metrics version: v1 spec: containers: - name: helidon-metrics image: helidon-metrics-se imagePullPolicy: IfNotPresent ports: - containerPort: 8080 A service of type NodePort that serves the default routes on port 8080 . An annotation that will allow Prometheus to discover and scrape the application pod. A deployment with one replica of a pod. <markup lang=\"bash\" title=\"Create and deploy the application into Kubernetes:\" >kubectl apply -f ./metrics.yaml <markup lang=\"bash\" title=\"Get the service information:\" >kubectl get service/helidon-metrics <markup lang=\"bash\" >NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE helidon-metrics NodePort 10.99.159.2 &lt;none&gt; 8080:31143/TCP 8s A service of type NodePort that serves the default routes on port 31143 . <markup lang=\"bash\" title=\"Verify the metrics endpoint using port 30116 , your port will likely be different:\" >curl http://localhost:31143/metrics Leave the application running in Kubernetes since it will be used for Prometheus integration. Prometheus Integration The metrics service that you just deployed into Kubernetes is already annotated with prometheus.io/scrape: . This will allow Prometheus to discover the service and scrape the metrics. This example shows how to install Prometheus into Kubernetes, then verify that it discovered the Helidon metrics in your application. <markup lang=\"bash\" title=\"Install Prometheus and wait until the pod is ready:\" >helm install stable/prometheus --name metrics export POD_NAME=$(kubectl get pods --namespace default -l \"app=prometheus,component=server\" -o jsonpath=\"{.items[0].metadata.name}\") kubectl get pod $POD_NAME You will see output similar to the following. Repeat the kubectl get pod command until you see 2/2 and Running . This may take up to one minute. <markup lang=\"bash\" >metrics-prometheus-server-5fc5dc86cb-79lk4 2/2 Running 0 46s <markup lang=\"bash\" title=\"Create a port-forward so you can access the server URL:\" >kubectl --namespace default port-forward $POD_NAME 7090:9090 Now open your browser and navigate to http://localhost:7090/targets . Search for helidon on the page and you will see your Helidon application as one of the Prometheus targets. Final Cleanup You can now delete the Kubernetes resources that were just created during this example. <markup lang=\"bash\" title=\"Delete the Prometheus Kubernetes resources:\" >helm delete --purge metrics <markup lang=\"bash\" title=\"Delete the application Kubernetes resources:\" >kubectl delete -f ./metrics.yaml Summary This guide demonstrated how to use metrics in a Helidon SE application using various combinations of meters and scopes. Access meters for all three built-in scopes: base, vendor, and application Configure meters that are updated by the application when an application REST endpoint is invoked Configure a Gauge meter Integrate Helidon metrics with Kubernetes and Prometheus Refer to the following references for additional information: Helidon Javadoc ",
            "title": "What You Need"
        },
        {
            "location": "/se/guides/overview",
            "text": " Quickstart SE Create your first Helidon SE application in under 5 minutes. ",
            "title": "Getting Started"
        },
        {
            "location": "/se/guides/overview",
            "text": " Config Guide Learn how to configure a Helidon SE application. Health Check Guide Learn how to use Helidon SE built-in and custom health checks. Metrics Guide Learn how to use Helidon SE built-in and application metrics. Tracing Guide Learn how to trace a Helidon SE application. OIDC Guide Learn how to set up an OIDC Helidon SE application Helidon SE Upgrade Guide Learn how to Upgrade your Helidon SE application Helidon SE WebClient Guide Learn how to use the Helidon SE WebClient Helidon SE DB Client Guide Learn how to use the Helidon SE DB Client Helidon SE Performance Tuning Guide Learn how to tune your Helidon SE application ",
            "title": "Helidon SE Guides"
        },
        {
            "location": "/se/guides/overview",
            "text": " Maven Guide Using Helidon in your Maven project. Gradle Guide Using Helidon in your Gradle project. GraalVM Native Images Learn how to build a GraalVM native image for your Helidon application both on your desktop and as part of a Docker image. Custom Runtime Images using jlink Learn how to build a custom runtime Java image for your Helidon application both on your desktop and as part of a Docker image. Building Container Images with Jib Learn how to use Jib to create a container image without Docker. Deploying to OKE Learn how to deploy your application to Oracle Cloud Infrastructure Container Engine for Kubernetes (OKE). ",
            "title": "Build and Deploy"
        },
        {
            "location": "/se/guides/performance-tuning",
            "text": " In this guide you fill find basic advice for performance tuning of your Helidon application. Most of this concerns tuning Helidon WebServer, but you should also consider configuring/tuning Java heap size as per any Java application. ",
            "title": "Introduction"
        },
        {
            "location": "/se/guides/performance-tuning",
            "text": " Helidon WebServer is in large part self tuning. It uses default values that will satisfy most use cases, and with the adoption of Java virtual threads there is no longer a need to tune pools of platform threads. Still, there might be cases where you wish to change configuration options from their default values. For details on the following options please see: WebServer Configuration WebServer Connection Configuration WebServer Socket Configuration ",
            "title": "WebServer Tuning"
        },
        {
            "location": "/se/guides/performance-tuning",
            "text": " The following application.yaml snippet shows some configuration options that can be used to tune your application. It is intended to show configuration options in context. Please make sure you understand these options before using them. See the documentation referenced above. <markup lang=\"yaml\" title=\"application.yaml snippet\" >server: # These are used to prevent unbounded resource consumption of the server idle-connection-period: PT2M # Check idle connections every 2 minutes idle-connection-timeout: PT5M # Close connections that have been idle for 5 minutes max-concurrent-requests: NNNN # Maximum number of concurrent requests. -1 is unlimited. max-tcp-connections: NNNN # Max number of concurrent tcp connections. -1 is unlimited. max-in-memory-entity: NNNNNN # Entities smaller than this are buffered in memory vs streamed (bytes) max-payload-size: NNNNNNN # Reject requests with payload sizes greater than this. -1 is unlimited (bytes) # Depends on the workload and kernel version backlog: NNNN receive-buffer-size: NNNNN write-buffer-size: NNNNN write-queue-length: NN # 0 means direct write connection-options: # 0 means indefinite (and less clutter on socket impl) read-timeout: PT0S connect-timeout: PT0S # Default (false: Nagle's algorithm enabled) is best for most cases. But for some OS and # workloads enabling TCP_NODELAY (disable Nagle's algorithm) can improve performance. tcp-no-delay: true|false # The default is TCP autotuning which is best for most cases. socket-send-buffer-size: NNNNN socket-receive-buffer-size: NNNNN # Protocol validation. # Careful with this! Can be dangerous if you turn these off. protocols: \"http_1_1\": validate-request-headers: true|false validate-response-headers: true|false validate-path: true|false recv-log: true|false send-log: true|false ",
            "title": "Summary of Tuning Options"
        },
        {
            "location": "/se/guides/quickstart",
            "text": " This guide describes a basic example of an Helidon SE application using Docker and Kubernetes. ",
            "title": "preambule"
        },
        {
            "location": "/se/guides/quickstart",
            "text": " For this 5 minute tutorial, you will need the following: <div class=\"table__overflow elevation-1 flex sm7 \"> A Helidon SE Application You can use your own application or use the Helidon SE Quickstart to create a sample application. Java&#160;SE&#160;21 ( Open&#160;JDK&#160;21 ) Helidon requires Java 21+. Maven 3.8+ Helidon requires Maven 3.8+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop . <markup lang=\"bash\" title=\"Verify Prerequisites\" >java -version mvn --version docker --version kubectl version --short <markup lang=\"bash\" title=\"Setting JAVA_HOME\" ># On Mac export JAVA_HOME=`/usr/libexec/java_home -v 21` # On Linux # Use the appropriate path to your JDK export JAVA_HOME=/usr/lib/jvm/jdk-21 ",
            "title": "What You Need"
        },
        {
            "location": "/se/guides/quickstart",
            "text": " Generate the project sources using one (or both) of the Helidon Maven archetypes. The result is a simple project that shows the basics of configuring the WebServer and implementing basic routing rules. <markup lang=\"bash\" title=\"Run the Maven archetype\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-se \\ -DarchetypeVersion=4.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-se \\ -Dpackage=io.helidon.examples.quickstart.se The archetype generates a Maven project in your current directory (for example, helidon-quickstart-se ). Change into this directory. <markup lang=\"bash\" >cd helidon-quickstart-se If you want to use the generated project as a starter for your own application, then you can replace groupId, artifactId and package with values appropriate for your application. <markup lang=\"bash\" title=\"Build the Application\" >mvn package The project builds an application jar for the example and saves all runtime dependencies in the target/libs directory. This means you can easily start the application by running the application jar file: <markup lang=\"bash\" title=\"Run the application\" >java -jar target/helidon-quickstart-se.jar The example is a very simple \"Hello World\" greeting service. It supports GET requests for generating a greeting message, and a PUT request for changing the greeting itself. The response is encoded using JSON. For example: <markup lang=\"bash\" title=\"Try the Application\" >curl -X GET http://localhost:8080/greet {\"message\":\"Hello World!\"} curl -X GET http://localhost:8080/greet/Joe {\"message\":\"Hello Joe!\"} curl -X PUT -H \"Content-Type: application/json\" -d '{\"greeting\" : \"Hola\"}' http://localhost:8080/greet/greeting curl -X GET http://localhost:8080/greet/Jose {\"message\":\"Hola Jose!\"} ",
            "title": "Generate The Project"
        },
        {
            "location": "/se/guides/quickstart",
            "text": " Helidon provides built-in support for health and metrics endpoints. <markup lang=\"bash\" title=\"Health\" >curl -sv -X GET http://localhost:8080/observe/health Notice we use the -v option to curl so that you can see that the health endpoint returns 204 (No Content) by default. <markup lang=\"bash\" title=\"Metrics in Prometheus Format\" >curl -s -X GET http://localhost:8080/observe/metrics <markup lang=\"bash\" title=\"Metrics in JSON Format\" >curl -H 'Accept: application/json' -X GET http://localhost:8080/observe/metrics ",
            "title": "Health and Metrics"
        },
        {
            "location": "/se/guides/quickstart",
            "text": " The project also contains a Dockerfile so that you can easily build and run a Docker image. To build the Docker image, you need to have Docker installed and running on your system. <markup lang=\"bash\" title=\"Docker build\" >docker build -t helidon-quickstart-se . <markup lang=\"bash\" title=\"Run Docker Image\" >docker run --rm -p 8080:8080 helidon-quickstart-se:latest Then you can try the application as you did before. ",
            "title": "Build a Docker Image"
        },
        {
            "location": "/se/guides/quickstart",
            "text": " If you don&#8217;t have access to a Kubernetes cluster, you can install one on your desktop . Then deploy the example: <markup lang=\"bash\" title=\"Verify connectivity to cluster\" >kubectl cluster-info kubectl get nodes <markup lang=\"bash\" title=\"Deploy the application to Kubernetes\" >kubectl create -f app.yaml kubectl get pods # Wait for quickstart pod to be RUNNING The step above created a service that is exposed into any node port. Lookup the service to find the port. <markup lang=\"bash\" title=\"Lookup the service\" >kubectl get service helidon-quickstart-se Note the PORTs. You can now exercise the application as you did before but use the second port number (the NodePort) instead of 8080. For example: <markup lang=\"bash\" >curl -X GET http://localhost:31431/greet After you&#8217;re done, cleanup. <markup lang=\"bash\" title=\"Remove the application from Kubernetes\" >kubectl delete -f app.yaml ",
            "title": "Deploy the application to Kubernetes"
        },
        {
            "location": "/se/guides/quickstart",
            "text": " Helidon also includes support for GraalVM Native Images and Java Custom Runtime Images. For more information see: GraalVM Native Images Custom Runtime Images using jlink ",
            "title": "Building Native and Custom Runtime Images"
        },
        {
            "location": "/se/guides/quickstart",
            "text": " With the Helidon CLI you can create additional types of Helidon applications and use the \"dev loop\" to do fast, iterative development. Try it now . ",
            "title": "The Helidon CLI"
        },
        {
            "location": "/se/guides/security-oidc",
            "text": " This guide describes how to setup Keycloak and Helidon to secure your application with OIDC security provider. ",
            "title": "preambule"
        },
        {
            "location": "/se/guides/security-oidc",
            "text": " For this 20 minute tutorial, you will need the following: <div class=\"table__overflow elevation-1 flex sm7 \"> A Helidon SE Application You can use your own application or use the Helidon SE Quickstart to create a sample application. Java&#160;SE&#160;21 ( Open&#160;JDK&#160;21 ) Helidon requires Java 21+. Maven 3.8+ Helidon requires Maven 3.8+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop . <markup lang=\"bash\" title=\"Verify Prerequisites\" >java -version mvn --version docker --version kubectl version --short <markup lang=\"bash\" title=\"Setting JAVA_HOME\" ># On Mac export JAVA_HOME=`/usr/libexec/java_home -v 21` # On Linux # Use the appropriate path to your JDK export JAVA_HOME=/usr/lib/jvm/jdk-21 In addition, you will need to install and configure the following: Introduction Keycloak Installation Setup Keycloak Setup Helidon Test Keycloak process with Postman Restrict access to a specific role ",
            "title": "What You Need"
        },
        {
            "location": "/se/guides/security-oidc",
            "text": " This guide describes the steps required to protect your whole application or a specific area with Open ID Connect (OIDC) security. OIDC is a secure mechanism for an application to contact an identity service. Its built on top of OAuth 2.0 and provides full-fledged authentication and authorization protocols. ",
            "title": "Introduction"
        },
        {
            "location": "/se/guides/security-oidc",
            "text": " To install Keycloak with Docker, open a terminal and make sure the port 8080 is free. <markup lang=\"bash\" title=\"Enter the following command\" >docker run -p 8080:8080 -e KEYCLOAK_USER=admin -e KEYCLOAK_PASSWORD=admin quay.io/keycloak/keycloak:11.0.2 This will start Keycloak on local port 8080. It will create the admin user with username admin and password admin Feel free to modify 11.0.2 by any keycloak version of your wish. If you are running docker behind a proxy server, make sure it is either configured into docker or disabled. Otherwise, you might face a connection timeout because docker cannot download the required data. To verify that Keycloak is running correctly, go to the admin console : http://localhost:8080/auth/admin Log in using the username and password mentioned above: admin . You should be logged in successfully, and it prompts the admin console. ",
            "title": "On Docker"
        },
        {
            "location": "/se/guides/security-oidc",
            "text": " Download the last version of Keycloak from Keycloak website : https://www.keycloak.org/downloads In the table Server choose Standalone server distribution. ZIP or Tar format are available, click on either to download Keycloak. After extracting the archive file, you should have a directory named keycloak followed by the version. For example, if you chose version 11.0.2, the folder must be named keycloak-11.0.2. Open keycloak folder to make it your current directory. <markup lang=\"bash\" title=\"Run this command from command prompt to open the directory:\" >cd keycloak-11.0.2 ",
            "title": "On JDK"
        },
        {
            "location": "/se/guides/security-oidc",
            "text": " On Docker To install Keycloak with Docker, open a terminal and make sure the port 8080 is free. <markup lang=\"bash\" title=\"Enter the following command\" >docker run -p 8080:8080 -e KEYCLOAK_USER=admin -e KEYCLOAK_PASSWORD=admin quay.io/keycloak/keycloak:11.0.2 This will start Keycloak on local port 8080. It will create the admin user with username admin and password admin Feel free to modify 11.0.2 by any keycloak version of your wish. If you are running docker behind a proxy server, make sure it is either configured into docker or disabled. Otherwise, you might face a connection timeout because docker cannot download the required data. To verify that Keycloak is running correctly, go to the admin console : http://localhost:8080/auth/admin Log in using the username and password mentioned above: admin . You should be logged in successfully, and it prompts the admin console. On JDK Download the last version of Keycloak from Keycloak website : https://www.keycloak.org/downloads In the table Server choose Standalone server distribution. ZIP or Tar format are available, click on either to download Keycloak. After extracting the archive file, you should have a directory named keycloak followed by the version. For example, if you chose version 11.0.2, the folder must be named keycloak-11.0.2. Open keycloak folder to make it your current directory. <markup lang=\"bash\" title=\"Run this command from command prompt to open the directory:\" >cd keycloak-11.0.2 ",
            "title": "Keycloak Installation"
        },
        {
            "location": "/se/guides/security-oidc",
            "text": " You need to create an admin user because it does not come by default when installing Keycloak. To do this, open http://localhost:8080/auth in your favorite browser. A window Welcome to Keycloak should be prompted. If not, check if any error appear in the terminal. Fill the form by adding Username and Password. Click on Create to create the admin user. Above Administration Console should be printed \"User created\" in a green rectangle. To check that the admin user was created correctly, click on Administration user which should redirect you to a Login form. Enter the Username and Password created earlier to log in. After successfully logged in, the admin console is prompted. ",
            "title": "Create an Admin User"
        },
        {
            "location": "/se/guides/security-oidc",
            "text": " To start keycloak and have it ready for further steps, run the following command. <markup lang=\"bash\" title=\"On Linux run:\" >bin/standalone.sh <markup lang=\"bash\" title=\"On Windows run:\" >bin/standalone.bat Keycloak runs on localhost:8080 by default. Create an Admin User You need to create an admin user because it does not come by default when installing Keycloak. To do this, open http://localhost:8080/auth in your favorite browser. A window Welcome to Keycloak should be prompted. If not, check if any error appear in the terminal. Fill the form by adding Username and Password. Click on Create to create the admin user. Above Administration Console should be printed \"User created\" in a green rectangle. To check that the admin user was created correctly, click on Administration user which should redirect you to a Login form. Enter the Username and Password created earlier to log in. After successfully logged in, the admin console is prompted. ",
            "title": "Start Keycloak"
        },
        {
            "location": "/se/guides/security-oidc",
            "text": " A realm is the place where groups of applications, and their environment, can be created. It gathers : One or several applications One or several users Sessions Events Clients and their scopes By default, there is a realm called Master . It is used to manage Keycloak. It is not recommended to associate your application with this realm as it could disturb Keycloak functioning. To create a new realm to manage your application: Open Keycloak admin console http://localhost:8080/auth/admin . Hover the mouse over the dropdown in the top-left corner where it says Master , and press Add realm . Fill the form by adding the realm name, myRealm for example. Click on Create to create the new realm. To verify that your realm is created, on the top-left corner where it said Master previously should be now your realm name or myRealm is you followed the example. To switch from a realm to another, hover the realm name, and the other realm created appear in the dropdown. Click on any realm name to change the current realm. Make sure all configuration or modification are saved before changing the current realm or be subject to lose your configuration. ",
            "title": "Create a Realm"
        },
        {
            "location": "/se/guides/security-oidc",
            "text": " Initially there are no users in a new realm. An unlimited number of user can be created per realm. A realm contains resources such as client which can be accessed by users. To create a new user: Open the Keycloak admin console: http://localhost:8080/auth/admin Click on Users in the left menu Press Add user Fill the form (Username is the only mandatory field) with this value Username: myUser Click Save A new user is just created but it needs a password to be able to login. To initialize it, do this: Click on Credentials at the top of the page, under Myuser . Fill Password and Password confirmation with the user password of your choice. If the Temporary field is set to ON , the user has to update password on next login. Click ON to make it OFF and prevent it. Press Set Password . A pop-up window is popping off. Click on Set Password to confirm the new password. To verify that the new user is created correctly: Open the Keycloak account console: http://localhost:8080/auth/realms/myRealm/account . Login with myUser and password chosen earlier. You should now be logged-in to the account console where users can manage their accounts. ",
            "title": "Create a User"
        },
        {
            "location": "/se/guides/security-oidc",
            "text": " To create your first client: Open the Keycloak admin console: http://localhost:8080/auth/admin . Make sure the current realm is myRealm and not Master . Navigate to the left menu, into configure section, click on Clients . This window displays a table with every client from the realm. Click on Create . Fill the following: Client ID : myClientID Client Protocol : openid-connect Press Save Modify Access type : confidential Update Valid Redirect URIs : http://localhost:7987/* Click on + to add the new URI. Click on Save . A new tab named Credentials is created. Click on it to access this new tab. Select Client Authenticator : Client ID and Secret Click on generate secret to generate client secret. Keycloak is now configured and ready. Keep keycloak running on your terminal and open a new tab to setup Helidon. ",
            "title": "Create a Client"
        },
        {
            "location": "/se/guides/security-oidc",
            "text": " To setup Keycloak properly, go to the admin console: http://localhost:8080/auth/admin If you are using Docker, use Username admin and password admin as it is the default admin user. Otherwise, use the username and password you used to create the admin user. Create a Realm A realm is the place where groups of applications, and their environment, can be created. It gathers : One or several applications One or several users Sessions Events Clients and their scopes By default, there is a realm called Master . It is used to manage Keycloak. It is not recommended to associate your application with this realm as it could disturb Keycloak functioning. To create a new realm to manage your application: Open Keycloak admin console http://localhost:8080/auth/admin . Hover the mouse over the dropdown in the top-left corner where it says Master , and press Add realm . Fill the form by adding the realm name, myRealm for example. Click on Create to create the new realm. To verify that your realm is created, on the top-left corner where it said Master previously should be now your realm name or myRealm is you followed the example. To switch from a realm to another, hover the realm name, and the other realm created appear in the dropdown. Click on any realm name to change the current realm. Make sure all configuration or modification are saved before changing the current realm or be subject to lose your configuration. Create a User Initially there are no users in a new realm. An unlimited number of user can be created per realm. A realm contains resources such as client which can be accessed by users. To create a new user: Open the Keycloak admin console: http://localhost:8080/auth/admin Click on Users in the left menu Press Add user Fill the form (Username is the only mandatory field) with this value Username: myUser Click Save A new user is just created but it needs a password to be able to login. To initialize it, do this: Click on Credentials at the top of the page, under Myuser . Fill Password and Password confirmation with the user password of your choice. If the Temporary field is set to ON , the user has to update password on next login. Click ON to make it OFF and prevent it. Press Set Password . A pop-up window is popping off. Click on Set Password to confirm the new password. To verify that the new user is created correctly: Open the Keycloak account console: http://localhost:8080/auth/realms/myRealm/account . Login with myUser and password chosen earlier. You should now be logged-in to the account console where users can manage their accounts. Create a Client To create your first client: Open the Keycloak admin console: http://localhost:8080/auth/admin . Make sure the current realm is myRealm and not Master . Navigate to the left menu, into configure section, click on Clients . This window displays a table with every client from the realm. Click on Create . Fill the following: Client ID : myClientID Client Protocol : openid-connect Press Save Modify Access type : confidential Update Valid Redirect URIs : http://localhost:7987/* Click on + to add the new URI. Click on Save . A new tab named Credentials is created. Click on it to access this new tab. Select Client Authenticator : Client ID and Secret Click on generate secret to generate client secret. Keycloak is now configured and ready. Keep keycloak running on your terminal and open a new tab to setup Helidon. ",
            "title": "Setup Keycloak"
        },
        {
            "location": "/se/guides/security-oidc",
            "text": " Update the pom.xml file and add the following Helidon dependency to the &lt;dependencies&gt; section. <markup lang=\"xml\" title=\"Add the following dependency to pom.xml :\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-oidc&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Update Project Dependencies"
        },
        {
            "location": "/se/guides/security-oidc",
            "text": " The OIDC security provider configuration can be joined to helidon configuration file. This file is located here: src/main/resources/application.yaml . It can be easily used to configure the web server without modifying application code. <markup lang=\"yaml\" title=\"Add the following line to application.yaml\" >security: providers: - abac: # Adds ABAC Provider - it does not require any configuration - oidc: client-id: \"myClientID\" client-secret: \"Client secret generated into Keycloak client credential\" identity-uri: \"http://localhost:8080/auth/realms/myRealm\" audience: \"account\" header-use: \"true\" # proxy-host should be defined if you operate behind a proxy, can be removed otherwise proxy-host: \"\" frontend-uri: \"http://localhost:7987\" server-type: \"oidc\" web-server: # protected paths on the web server paths: - path: \"/greet\" methods: [\"get\"] authenticate: true client-id must be the same as the one configure in keycloak. The client secret generate by Keycloak during Create a client section. identity-uri is used to redirect the user to keycloak. frontend-uri will direct you back to the application. paths section defines the protected application&#8217;s path. Make sure keycloak and the application are not running on the same port. The application port value can be changed into application.yaml. <markup lang=\"yaml\" title=\"Change these properties to configure the server host and port\" >server: port: 7987 host: localhost If the port 7987 is already used, check what port is free on your machine. <markup lang=\"yaml\" title=\"Replace the old port into application.yaml\" >server: port: \"{Your-new-port}\" frontend-uri: \"http://localhost:{Your-new-port}\" ",
            "title": "Add OIDC Security Properties"
        },
        {
            "location": "/se/guides/security-oidc",
            "text": " Once the properties are added, the web server must be setup. The Main.routing method gather all configuration properties. <markup lang=\"java\" title=\"Add the following to Main.routing method\" >import io.helidon.security.Security; import io.helidon.security.providers.oidc.OidcFeature; import io.helidon.webserver.context.ContextFeature; import io.helidon.webserver.security.SecurityFeature; Security security = Security.create(config.get(\"security\")); routing.addFeature(ContextFeature.create()) .addFeature(SecurityFeature.create(security, config.get(\"security\"))) .addFeature(OidcFeature.create(config)) Create the Helidon Security instance using configuration. Register Helidon SecurityFeature instance using security instance and configuration. Register Helidon OidcFeature instance. It is also needed to add the following lines to the module-info.java file: <markup lang=\"java\" title=\"Add security related module requirements\" >requires io.helidon.security; requires io.helidon.security.providers.oidc; requires io.helidon.webserver.security; requires io.helidon.webserver.context; That code is extracting security properties from application.yaml into two steps. First the Security instance is used to bootstrap security, so the SecurityFeature instance can integrate security into Web Server. Then, OidcFeature instance registers the endpoint to which OIDC redirects browser after a successful login. Helidon sample is now setup and ready. ",
            "title": "Configure Web Server"
        },
        {
            "location": "/se/guides/security-oidc",
            "text": " Use the Helidon SE Maven archetype to create a simple project. It will be used as an example to show how to setup Helidon. Replace 4.0.2 by the latest helidon version. It will download the quickstart project into the current directory. <markup lang=\"bash\" title=\"Run the Maven archetype\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-se \\ -DarchetypeVersion=4.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-se \\ -Dpackage=io.helidon.examples.quickstart.se <markup lang=\"bash\" title=\"The project will be built and run from the helidon-quickstart-se directory:\" >cd helidon-quickstart-se Update Project Dependencies Update the pom.xml file and add the following Helidon dependency to the &lt;dependencies&gt; section. <markup lang=\"xml\" title=\"Add the following dependency to pom.xml :\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-oidc&lt;/artifactId&gt; &lt;/dependency&gt; Add OIDC Security Properties The OIDC security provider configuration can be joined to helidon configuration file. This file is located here: src/main/resources/application.yaml . It can be easily used to configure the web server without modifying application code. <markup lang=\"yaml\" title=\"Add the following line to application.yaml\" >security: providers: - abac: # Adds ABAC Provider - it does not require any configuration - oidc: client-id: \"myClientID\" client-secret: \"Client secret generated into Keycloak client credential\" identity-uri: \"http://localhost:8080/auth/realms/myRealm\" audience: \"account\" header-use: \"true\" # proxy-host should be defined if you operate behind a proxy, can be removed otherwise proxy-host: \"\" frontend-uri: \"http://localhost:7987\" server-type: \"oidc\" web-server: # protected paths on the web server paths: - path: \"/greet\" methods: [\"get\"] authenticate: true client-id must be the same as the one configure in keycloak. The client secret generate by Keycloak during Create a client section. identity-uri is used to redirect the user to keycloak. frontend-uri will direct you back to the application. paths section defines the protected application&#8217;s path. Make sure keycloak and the application are not running on the same port. The application port value can be changed into application.yaml. <markup lang=\"yaml\" title=\"Change these properties to configure the server host and port\" >server: port: 7987 host: localhost If the port 7987 is already used, check what port is free on your machine. <markup lang=\"yaml\" title=\"Replace the old port into application.yaml\" >server: port: \"{Your-new-port}\" frontend-uri: \"http://localhost:{Your-new-port}\" Configure Web Server Once the properties are added, the web server must be setup. The Main.routing method gather all configuration properties. <markup lang=\"java\" title=\"Add the following to Main.routing method\" >import io.helidon.security.Security; import io.helidon.security.providers.oidc.OidcFeature; import io.helidon.webserver.context.ContextFeature; import io.helidon.webserver.security.SecurityFeature; Security security = Security.create(config.get(\"security\")); routing.addFeature(ContextFeature.create()) .addFeature(SecurityFeature.create(security, config.get(\"security\"))) .addFeature(OidcFeature.create(config)) Create the Helidon Security instance using configuration. Register Helidon SecurityFeature instance using security instance and configuration. Register Helidon OidcFeature instance. It is also needed to add the following lines to the module-info.java file: <markup lang=\"java\" title=\"Add security related module requirements\" >requires io.helidon.security; requires io.helidon.security.providers.oidc; requires io.helidon.webserver.security; requires io.helidon.webserver.context; That code is extracting security properties from application.yaml into two steps. First the Security instance is used to bootstrap security, so the SecurityFeature instance can integrate security into Web Server. Then, OidcFeature instance registers the endpoint to which OIDC redirects browser after a successful login. Helidon sample is now setup and ready. ",
            "title": "Setup Helidon"
        },
        {
            "location": "/se/guides/security-oidc",
            "text": " The Authorization Code flow is suitable for browser-based applications. It is composed of three main steps: The browser visits the application. The user is not logged in, so it redirects the browser to Keycloak which requires username and password for authentication. Keycloak authenticates the user and returns a temporary authorization code as a query parameter in the URL. The authorization code is used to get access and refresh token from Keycloak token endpoint. For the first step, paste the following URL into your browser: http://localhost:8080/auth/realms/myRealm/protocol/openid-connect/auth?client_id=myClientID&amp;response_type=code . The first part of the url http:/../auth is the Keycloak endpoint to request an authorization code. Two query parameters are provided, the client id and the response type. Press enter and Keycloak responds with different URL containing a query parameter code . You successfully received the authorization code. In order to achieve the third step, we can use Postman to exchange the authorization code for tokens. In Postman, select the Http POST method. Keycloak endpoint to get token is the following: http://localhost:8080/auth/realms/myRealm/protocol/openid-connect/token . In the body of the request, select x-www-form-urlencoded type. Add the following data: <markup lang=\"json\" title=\"Enter the key:value\" >[{\"key\":\"grant_type\",\"value\":\"authorization_code\"}, {\"key\":\"client_id\",\"value\":\"myClientID\"}, {\"key\":\"client_secret\",\"value\":\"client secret\"}, {\"key\":\"code\",\"value\":\"authorization code\"}] Do not forget to replace the client secret by its value (generated during Create a Client), and authorization code by the code value in the query parameter. Send the request by pressing Send . Keycloak returns an access token and a refresh token. ",
            "title": "Authorization Code Flow"
        },
        {
            "location": "/se/guides/security-oidc",
            "text": " The Direct Access Grants flow is used by REST clients that want to request tokens on behalf of a user. To use Postman to make this request on behalf of myuser , select the GET method and enter this URL: http://localhost:7987/greet/ . Under Authorization tab, select authorization type`OAuth 2.0`. Under it, complete the sentence Add authorization data to with Request Headers , and complete the required fields. Note: Make sure your Helidon application is running. If it is not, please start it. <markup lang=\"json\" title=\"Enter the following information:\" >[{\"key\":\"Header Prefix\",\"value\":\"bearer\"}, {\"key\":\"Grant type\",\"value\":\"Password Credentials\"}, {\"key\":\"Access Token URL\",\"value\":\"http://localhost:8080/auth/realms/myRealm/protocol/openid-connect/token\"}, {\"key\":\"Client ID\",\"value\":\"myClientID\"}, {\"key\":\"Client Secret\",\"value\":\"client secret\"}, {\"key\":\"Username\",\"value\":\"myuser\"}, {\"key\":\"Password\",\"value\":\"password\"}, {\"key\":\"Scope\",\"value\":\"openid\"}, {\"key\":\"Client Authentication\",\"value\":\"Send as Basic Auth Header\"}] Again, make sure to replace client secret by the actual client secret. Click on Get New Access Token . A popup window appears with Authentication complete, click on proceed to display access, refresh and identity token. Copy and paste the access token to Access Token field and press Send . Helidon greeting application sends back Hello World ! . ",
            "title": "Resource Owner Password Credentials Grant (Direct Access Grants)"
        },
        {
            "location": "/se/guides/security-oidc",
            "text": " At this stage of the application, tests cannot pass because of OIDC security. The only way to authenticate a user is through the front end of that server which can be accessed with the browser for example. In order to keep security and test the application locally, a new security provider must be setup. By adding specific configuration to the tests, it is possible to override the application configuration. The following explains how to set a basic authentication instead of oidc security provider only for the tests. Which means, at the end of this guide, the application will be secured by oidc security provider, and the tests will use basic authentication. <markup lang=\"xml\" title=\"Add the following dependency to pom.xml :\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-http-auth&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; In the test folder open the application.yaml file: helidon-quickstart-se/src/test/resources/application.yaml <markup lang=\"yaml\" title=\"Copy these properties into application.yaml\" >app: greeting: \"Hello\" server: port: 7987 host: localhost security: providers: - abac: # Adds ABAC Provider - it does not require any configuration - http-basic-auth: users: - login: \"jack\" password: \"jackIsGreat\" - oidc: client-id: \"myClientID\" client-secret: \"Your client secret\" identity-uri: \"http://localhost:8080/auth/realms/myRealm\" audience: \"account\" frontend-uri: \"http://localhost:7987\" server-type: \"oidc\" web-server: # protected paths on the web server - do not include paths served by Jersey, as those are protected directly paths: - path: \"/greet\" methods: [\"get\"] authenticate: true Replace this field by your Keycloak client ID. Replace this field by your Keycloak client Password. Add the http-basic-auth properties in the security &#8594; providers property section. This configuration will be used by the tests instead of the java/resources/application.yaml . In the AbstractMainTest.java file, tests need to be modified to check the application security when accessing /greet path with a GET method. <markup lang=\"java\" title=\"Import the following class:\" >import io.helidon.http.Status; <markup lang=\"java\" title=\"Replace the first webclient call by this one into testRootRoute method:\" >try (HttpClientResponse response = webClient.get() .path(\"/greet\") .request()) { assertThat(response.status(), is(Status.UNAUTHORIZED_401)); } This piece of code uses the webclient to access the application on /greet path with a GET method. The http basic authentication security protects this path, so the client should receive an HTTP 401 code for unauthorized. Only jack user has access to this part of the application. <markup lang=\"java\" title=\"Add new check to the testRootRoute method:\" >JsonObject jsonObject = webClient.get() .path(\"/greet\") .headers(headers -&gt; { String encoding = Base64.getEncoder().encodeToString(\"jack:jackIsGreat\".getBytes()); headers.add(HeaderNames.AUTHORIZATION, \"Basic \" + encoding); }) .requestEntity(JsonObject.class); assertThat(jsonObject.getString(\"message\"), is(\"Hello World!\")); The username and password are encoded and placed inside the header in order to authenticate as jack to access the application. If the authentication is successful, the application send the Hello World back as a JsonObject . Now, the project can be build without skipping test. <markup lang=\"bash\" title=\"Build the project\" >mvn clean install ",
            "title": "Update Tests to the Secure Environment"
        },
        {
            "location": "/se/guides/security-oidc",
            "text": " To give less access to an endpoint, it is possible to configure user role. So the application will only grant access to the user with the required role. Add a user and roles to the helidon-quickstart-se/src/test/resources/application.yaml . <markup lang=\"yaml\" title=\"Add jack role and create a new user named john:\" >- http-basic-auth: users: - login: \"jack\" password: \"jackIsGreat\" roles: [ \"admin\", \"user\" ] - login: \"john\" password: \"johnPassword\" roles: [ \"user\" ] Into the web-server section, the roles-allowed parameter defines which roles have access to the protected path and method. <markup lang=\"yaml\" title=\"Add admin role\" >web-server: # protected paths on the web server - do not include paths served by Jersey, as those are protected directly paths: - path: \"/greet\" methods: [\"get\"] roles-allowed: \"admin\" authenticate: true Now, only Jack has access to secure endpoint as he has an admin role. John, as a simple user, can not access it. Once it is done, go to the tests to check the application behavior. The test from previous section is still passing as jack has access. The user john has only the user role so when accessing protected endpoint, a 403 (Forbidden) http code is returned. <markup lang=\"java\" title=\"Check that john does not have access\" >HttpClientRequest request = webClient.get() .path(\"/greet\") .headers(headers -&gt; { String encoding = Base64.getEncoder().encodeToString(\"john:johnPassword\".getBytes()); headers.add(HeaderNames.AUTHORIZATION, \"Basic \" + encoding); }); try (HttpClientResponse response = request.request()) { assertThat(response.status(), is(Status.FORBIDDEN_403)); } <markup lang=\"bash\" title=\"Build the project\" >mvn clean install The tests pass, and your application is secured with specific roles in addition to user IDs. ",
            "title": "Restrict Access to a Specific Role"
        },
        {
            "location": "/se/guides/security-oidc",
            "text": " Keycloak supports many authentication and authorization flows, but only two of them will be shown. This section describes another way you can get an access token or refresh a token or identity token. The identity token contains information about the user. The access token contains access information that the application can use to determine what resources the user is allowed to access. Once expired, the refresh token allows the application to obtain a new access token. As these tokens contain sensitive information, they are valid for a very short period. It is possible to make them last longer in order to let you manipulate them with Postman. To do so: Open the Keycloak Console. Click on the Realm Setting in the left menu. Navigate to the Tokens tab. You can increase the access token lifespan. Authorization Code Flow The Authorization Code flow is suitable for browser-based applications. It is composed of three main steps: The browser visits the application. The user is not logged in, so it redirects the browser to Keycloak which requires username and password for authentication. Keycloak authenticates the user and returns a temporary authorization code as a query parameter in the URL. The authorization code is used to get access and refresh token from Keycloak token endpoint. For the first step, paste the following URL into your browser: http://localhost:8080/auth/realms/myRealm/protocol/openid-connect/auth?client_id=myClientID&amp;response_type=code . The first part of the url http:/../auth is the Keycloak endpoint to request an authorization code. Two query parameters are provided, the client id and the response type. Press enter and Keycloak responds with different URL containing a query parameter code . You successfully received the authorization code. In order to achieve the third step, we can use Postman to exchange the authorization code for tokens. In Postman, select the Http POST method. Keycloak endpoint to get token is the following: http://localhost:8080/auth/realms/myRealm/protocol/openid-connect/token . In the body of the request, select x-www-form-urlencoded type. Add the following data: <markup lang=\"json\" title=\"Enter the key:value\" >[{\"key\":\"grant_type\",\"value\":\"authorization_code\"}, {\"key\":\"client_id\",\"value\":\"myClientID\"}, {\"key\":\"client_secret\",\"value\":\"client secret\"}, {\"key\":\"code\",\"value\":\"authorization code\"}] Do not forget to replace the client secret by its value (generated during Create a Client), and authorization code by the code value in the query parameter. Send the request by pressing Send . Keycloak returns an access token and a refresh token. Resource Owner Password Credentials Grant (Direct Access Grants) The Direct Access Grants flow is used by REST clients that want to request tokens on behalf of a user. To use Postman to make this request on behalf of myuser , select the GET method and enter this URL: http://localhost:7987/greet/ . Under Authorization tab, select authorization type`OAuth 2.0`. Under it, complete the sentence Add authorization data to with Request Headers , and complete the required fields. Note: Make sure your Helidon application is running. If it is not, please start it. <markup lang=\"json\" title=\"Enter the following information:\" >[{\"key\":\"Header Prefix\",\"value\":\"bearer\"}, {\"key\":\"Grant type\",\"value\":\"Password Credentials\"}, {\"key\":\"Access Token URL\",\"value\":\"http://localhost:8080/auth/realms/myRealm/protocol/openid-connect/token\"}, {\"key\":\"Client ID\",\"value\":\"myClientID\"}, {\"key\":\"Client Secret\",\"value\":\"client secret\"}, {\"key\":\"Username\",\"value\":\"myuser\"}, {\"key\":\"Password\",\"value\":\"password\"}, {\"key\":\"Scope\",\"value\":\"openid\"}, {\"key\":\"Client Authentication\",\"value\":\"Send as Basic Auth Header\"}] Again, make sure to replace client secret by the actual client secret. Click on Get New Access Token . A popup window appears with Authentication complete, click on proceed to display access, refresh and identity token. Copy and paste the access token to Access Token field and press Send . Helidon greeting application sends back Hello World ! . Update Tests to the Secure Environment At this stage of the application, tests cannot pass because of OIDC security. The only way to authenticate a user is through the front end of that server which can be accessed with the browser for example. In order to keep security and test the application locally, a new security provider must be setup. By adding specific configuration to the tests, it is possible to override the application configuration. The following explains how to set a basic authentication instead of oidc security provider only for the tests. Which means, at the end of this guide, the application will be secured by oidc security provider, and the tests will use basic authentication. <markup lang=\"xml\" title=\"Add the following dependency to pom.xml :\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-http-auth&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; In the test folder open the application.yaml file: helidon-quickstart-se/src/test/resources/application.yaml <markup lang=\"yaml\" title=\"Copy these properties into application.yaml\" >app: greeting: \"Hello\" server: port: 7987 host: localhost security: providers: - abac: # Adds ABAC Provider - it does not require any configuration - http-basic-auth: users: - login: \"jack\" password: \"jackIsGreat\" - oidc: client-id: \"myClientID\" client-secret: \"Your client secret\" identity-uri: \"http://localhost:8080/auth/realms/myRealm\" audience: \"account\" frontend-uri: \"http://localhost:7987\" server-type: \"oidc\" web-server: # protected paths on the web server - do not include paths served by Jersey, as those are protected directly paths: - path: \"/greet\" methods: [\"get\"] authenticate: true Replace this field by your Keycloak client ID. Replace this field by your Keycloak client Password. Add the http-basic-auth properties in the security &#8594; providers property section. This configuration will be used by the tests instead of the java/resources/application.yaml . In the AbstractMainTest.java file, tests need to be modified to check the application security when accessing /greet path with a GET method. <markup lang=\"java\" title=\"Import the following class:\" >import io.helidon.http.Status; <markup lang=\"java\" title=\"Replace the first webclient call by this one into testRootRoute method:\" >try (HttpClientResponse response = webClient.get() .path(\"/greet\") .request()) { assertThat(response.status(), is(Status.UNAUTHORIZED_401)); } This piece of code uses the webclient to access the application on /greet path with a GET method. The http basic authentication security protects this path, so the client should receive an HTTP 401 code for unauthorized. Only jack user has access to this part of the application. <markup lang=\"java\" title=\"Add new check to the testRootRoute method:\" >JsonObject jsonObject = webClient.get() .path(\"/greet\") .headers(headers -&gt; { String encoding = Base64.getEncoder().encodeToString(\"jack:jackIsGreat\".getBytes()); headers.add(HeaderNames.AUTHORIZATION, \"Basic \" + encoding); }) .requestEntity(JsonObject.class); assertThat(jsonObject.getString(\"message\"), is(\"Hello World!\")); The username and password are encoded and placed inside the header in order to authenticate as jack to access the application. If the authentication is successful, the application send the Hello World back as a JsonObject . Now, the project can be build without skipping test. <markup lang=\"bash\" title=\"Build the project\" >mvn clean install Restrict Access to a Specific Role To give less access to an endpoint, it is possible to configure user role. So the application will only grant access to the user with the required role. Add a user and roles to the helidon-quickstart-se/src/test/resources/application.yaml . <markup lang=\"yaml\" title=\"Add jack role and create a new user named john:\" >- http-basic-auth: users: - login: \"jack\" password: \"jackIsGreat\" roles: [ \"admin\", \"user\" ] - login: \"john\" password: \"johnPassword\" roles: [ \"user\" ] Into the web-server section, the roles-allowed parameter defines which roles have access to the protected path and method. <markup lang=\"yaml\" title=\"Add admin role\" >web-server: # protected paths on the web server - do not include paths served by Jersey, as those are protected directly paths: - path: \"/greet\" methods: [\"get\"] roles-allowed: \"admin\" authenticate: true Now, only Jack has access to secure endpoint as he has an admin role. John, as a simple user, can not access it. Once it is done, go to the tests to check the application behavior. The test from previous section is still passing as jack has access. The user john has only the user role so when accessing protected endpoint, a 403 (Forbidden) http code is returned. <markup lang=\"java\" title=\"Check that john does not have access\" >HttpClientRequest request = webClient.get() .path(\"/greet\") .headers(headers -&gt; { String encoding = Base64.getEncoder().encodeToString(\"john:johnPassword\".getBytes()); headers.add(HeaderNames.AUTHORIZATION, \"Basic \" + encoding); }); try (HttpClientResponse response = request.request()) { assertThat(response.status(), is(Status.FORBIDDEN_403)); } <markup lang=\"bash\" title=\"Build the project\" >mvn clean install The tests pass, and your application is secured with specific roles in addition to user IDs. ",
            "title": "Test Keycloak Process with Postman"
        },
        {
            "location": "/se/guides/security-oidc",
            "text": "<markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-se.jar The tests must be skipped, otherwise it produces test failure. As the /greet endpoint for GET request is now protected, its access is limited, and the tests are not built to take oidc security in account. Open your favourite browser and try to access http://localhost:7987/greet/Michael . You should not be redirected and receive greeting from the application. Enter the following into URL : http://localhost:7987/greet . Keycloak redirect you to its login page. Enter the username and associated password: Username : myUser Password : password After successful log in, keycloak redirect you to the http://localhost:7987/greet endpoint and print Hello word. Press Ctrl+C to stop the application. From the actual settings, the user needs to log in only once, then Keycloak saves all the connection data. Test Keycloak Process with Postman Keycloak supports many authentication and authorization flows, but only two of them will be shown. This section describes another way you can get an access token or refresh a token or identity token. The identity token contains information about the user. The access token contains access information that the application can use to determine what resources the user is allowed to access. Once expired, the refresh token allows the application to obtain a new access token. As these tokens contain sensitive information, they are valid for a very short period. It is possible to make them last longer in order to let you manipulate them with Postman. To do so: Open the Keycloak Console. Click on the Realm Setting in the left menu. Navigate to the Tokens tab. You can increase the access token lifespan. Authorization Code Flow The Authorization Code flow is suitable for browser-based applications. It is composed of three main steps: The browser visits the application. The user is not logged in, so it redirects the browser to Keycloak which requires username and password for authentication. Keycloak authenticates the user and returns a temporary authorization code as a query parameter in the URL. The authorization code is used to get access and refresh token from Keycloak token endpoint. For the first step, paste the following URL into your browser: http://localhost:8080/auth/realms/myRealm/protocol/openid-connect/auth?client_id=myClientID&amp;response_type=code . The first part of the url http:/../auth is the Keycloak endpoint to request an authorization code. Two query parameters are provided, the client id and the response type. Press enter and Keycloak responds with different URL containing a query parameter code . You successfully received the authorization code. In order to achieve the third step, we can use Postman to exchange the authorization code for tokens. In Postman, select the Http POST method. Keycloak endpoint to get token is the following: http://localhost:8080/auth/realms/myRealm/protocol/openid-connect/token . In the body of the request, select x-www-form-urlencoded type. Add the following data: <markup lang=\"json\" title=\"Enter the key:value\" >[{\"key\":\"grant_type\",\"value\":\"authorization_code\"}, {\"key\":\"client_id\",\"value\":\"myClientID\"}, {\"key\":\"client_secret\",\"value\":\"client secret\"}, {\"key\":\"code\",\"value\":\"authorization code\"}] Do not forget to replace the client secret by its value (generated during Create a Client), and authorization code by the code value in the query parameter. Send the request by pressing Send . Keycloak returns an access token and a refresh token. Resource Owner Password Credentials Grant (Direct Access Grants) The Direct Access Grants flow is used by REST clients that want to request tokens on behalf of a user. To use Postman to make this request on behalf of myuser , select the GET method and enter this URL: http://localhost:7987/greet/ . Under Authorization tab, select authorization type`OAuth 2.0`. Under it, complete the sentence Add authorization data to with Request Headers , and complete the required fields. Note: Make sure your Helidon application is running. If it is not, please start it. <markup lang=\"json\" title=\"Enter the following information:\" >[{\"key\":\"Header Prefix\",\"value\":\"bearer\"}, {\"key\":\"Grant type\",\"value\":\"Password Credentials\"}, {\"key\":\"Access Token URL\",\"value\":\"http://localhost:8080/auth/realms/myRealm/protocol/openid-connect/token\"}, {\"key\":\"Client ID\",\"value\":\"myClientID\"}, {\"key\":\"Client Secret\",\"value\":\"client secret\"}, {\"key\":\"Username\",\"value\":\"myuser\"}, {\"key\":\"Password\",\"value\":\"password\"}, {\"key\":\"Scope\",\"value\":\"openid\"}, {\"key\":\"Client Authentication\",\"value\":\"Send as Basic Auth Header\"}] Again, make sure to replace client secret by the actual client secret. Click on Get New Access Token . A popup window appears with Authentication complete, click on proceed to display access, refresh and identity token. Copy and paste the access token to Access Token field and press Send . Helidon greeting application sends back Hello World ! . Update Tests to the Secure Environment At this stage of the application, tests cannot pass because of OIDC security. The only way to authenticate a user is through the front end of that server which can be accessed with the browser for example. In order to keep security and test the application locally, a new security provider must be setup. By adding specific configuration to the tests, it is possible to override the application configuration. The following explains how to set a basic authentication instead of oidc security provider only for the tests. Which means, at the end of this guide, the application will be secured by oidc security provider, and the tests will use basic authentication. <markup lang=\"xml\" title=\"Add the following dependency to pom.xml :\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-http-auth&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; In the test folder open the application.yaml file: helidon-quickstart-se/src/test/resources/application.yaml <markup lang=\"yaml\" title=\"Copy these properties into application.yaml\" >app: greeting: \"Hello\" server: port: 7987 host: localhost security: providers: - abac: # Adds ABAC Provider - it does not require any configuration - http-basic-auth: users: - login: \"jack\" password: \"jackIsGreat\" - oidc: client-id: \"myClientID\" client-secret: \"Your client secret\" identity-uri: \"http://localhost:8080/auth/realms/myRealm\" audience: \"account\" frontend-uri: \"http://localhost:7987\" server-type: \"oidc\" web-server: # protected paths on the web server - do not include paths served by Jersey, as those are protected directly paths: - path: \"/greet\" methods: [\"get\"] authenticate: true Replace this field by your Keycloak client ID. Replace this field by your Keycloak client Password. Add the http-basic-auth properties in the security &#8594; providers property section. This configuration will be used by the tests instead of the java/resources/application.yaml . In the AbstractMainTest.java file, tests need to be modified to check the application security when accessing /greet path with a GET method. <markup lang=\"java\" title=\"Import the following class:\" >import io.helidon.http.Status; <markup lang=\"java\" title=\"Replace the first webclient call by this one into testRootRoute method:\" >try (HttpClientResponse response = webClient.get() .path(\"/greet\") .request()) { assertThat(response.status(), is(Status.UNAUTHORIZED_401)); } This piece of code uses the webclient to access the application on /greet path with a GET method. The http basic authentication security protects this path, so the client should receive an HTTP 401 code for unauthorized. Only jack user has access to this part of the application. <markup lang=\"java\" title=\"Add new check to the testRootRoute method:\" >JsonObject jsonObject = webClient.get() .path(\"/greet\") .headers(headers -&gt; { String encoding = Base64.getEncoder().encodeToString(\"jack:jackIsGreat\".getBytes()); headers.add(HeaderNames.AUTHORIZATION, \"Basic \" + encoding); }) .requestEntity(JsonObject.class); assertThat(jsonObject.getString(\"message\"), is(\"Hello World!\")); The username and password are encoded and placed inside the header in order to authenticate as jack to access the application. If the authentication is successful, the application send the Hello World back as a JsonObject . Now, the project can be build without skipping test. <markup lang=\"bash\" title=\"Build the project\" >mvn clean install Restrict Access to a Specific Role To give less access to an endpoint, it is possible to configure user role. So the application will only grant access to the user with the required role. Add a user and roles to the helidon-quickstart-se/src/test/resources/application.yaml . <markup lang=\"yaml\" title=\"Add jack role and create a new user named john:\" >- http-basic-auth: users: - login: \"jack\" password: \"jackIsGreat\" roles: [ \"admin\", \"user\" ] - login: \"john\" password: \"johnPassword\" roles: [ \"user\" ] Into the web-server section, the roles-allowed parameter defines which roles have access to the protected path and method. <markup lang=\"yaml\" title=\"Add admin role\" >web-server: # protected paths on the web server - do not include paths served by Jersey, as those are protected directly paths: - path: \"/greet\" methods: [\"get\"] roles-allowed: \"admin\" authenticate: true Now, only Jack has access to secure endpoint as he has an admin role. John, as a simple user, can not access it. Once it is done, go to the tests to check the application behavior. The test from previous section is still passing as jack has access. The user john has only the user role so when accessing protected endpoint, a 403 (Forbidden) http code is returned. <markup lang=\"java\" title=\"Check that john does not have access\" >HttpClientRequest request = webClient.get() .path(\"/greet\") .headers(headers -&gt; { String encoding = Base64.getEncoder().encodeToString(\"john:johnPassword\".getBytes()); headers.add(HeaderNames.AUTHORIZATION, \"Basic \" + encoding); }); try (HttpClientResponse response = request.request()) { assertThat(response.status(), is(Status.FORBIDDEN_403)); } <markup lang=\"bash\" title=\"Build the project\" >mvn clean install The tests pass, and your application is secured with specific roles in addition to user IDs. ",
            "title": "Build the Application"
        },
        {
            "location": "/se/guides/tracing",
            "text": " This guide describes how to create a sample Helidon SE project that can be used to run some basic examples using tracing with a Helidon SE application. ",
            "title": "preambule"
        },
        {
            "location": "/se/guides/tracing",
            "text": " For this 30 minute tutorial, you will need the following: <div class=\"table__overflow elevation-1 flex sm7 \"> A Helidon SE Application You can use your own application or use the Helidon SE Quickstart to create a sample application. Java&#160;SE&#160;21 ( Open&#160;JDK&#160;21 ) Helidon requires Java 21+. Maven 3.8+ Helidon requires Maven 3.8+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop . <markup lang=\"bash\" title=\"Verify Prerequisites\" >java -version mvn --version docker --version kubectl version --short <markup lang=\"bash\" title=\"Setting JAVA_HOME\" ># On Mac export JAVA_HOME=`/usr/libexec/java_home -v 21` # On Linux # Use the appropriate path to your JDK export JAVA_HOME=/usr/lib/jvm/jdk-21 ",
            "title": "What You Need"
        },
        {
            "location": "/se/guides/tracing",
            "text": " This section explains a few concepts that you need to understand before you get started with tracing. In the context of this document, a service is synonymous with an application. A span is the basic unit of work done within a single service, on a single host. Every span has a name, starting timestamp, and duration. For example, the work done by a REST endpoint is a span. A span is associated to a single service, but its descendants can belong to different services and hosts. A trace contains a collection of spans from one or more services, running on one or more hosts. For example, if you trace a service endpoint that calls another service, then the trace would contain spans from both services. Within a trace, spans are organized as a directed acyclic graph (DAG) and can belong to multiple services, running on multiple hosts. Spans are automatically created by Helidon as needed during execution of the REST request. ",
            "title": "Tracing Concepts"
        },
        {
            "location": "/se/guides/tracing",
            "text": " Distributed tracing is a critical feature of microservice-based applications, since it traces workflow both within a service and across multiple services. This provides insight to sequence and timing data for specific blocks of work, which helps you identify performance and operational issues. Helidon includes support for distributed tracing through its own API, backed by either through the OpenTelemetry API , or by OpenTracing API . Tracing Concepts This section explains a few concepts that you need to understand before you get started with tracing. In the context of this document, a service is synonymous with an application. A span is the basic unit of work done within a single service, on a single host. Every span has a name, starting timestamp, and duration. For example, the work done by a REST endpoint is a span. A span is associated to a single service, but its descendants can belong to different services and hosts. A trace contains a collection of spans from one or more services, running on one or more hosts. For example, if you trace a service endpoint that calls another service, then the trace would contain spans from both services. Within a trace, spans are organized as a directed acyclic graph (DAG) and can belong to multiple services, running on multiple hosts. Spans are automatically created by Helidon as needed during execution of the REST request. ",
            "title": "Introduction"
        },
        {
            "location": "/se/guides/tracing",
            "text": " Use the Helidon SE Maven archetype to create a simple project that can be used for the examples in this guide. <markup lang=\"bash\" title=\"Run the Maven archetype:\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-se \\ -DarchetypeVersion=4.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-se \\ -Dpackage=io.helidon.examples.quickstart.se <markup lang=\"bash\" title=\"The project will be built and run from the helidon-quickstart-se directory:\" >cd helidon-quickstart-se ",
            "title": "Create a Sample Helidon SE Project"
        },
        {
            "location": "/se/guides/tracing",
            "text": " First, you need to run the Jaeger tracer. Helidon will communicate with this tracer at runtime. <markup lang=\"bash\" title=\"Run Jaeger within a docker container, then check the Jaeger server working:\" >docker run -d --name jaeger \\ -e COLLECTOR_OTLP_ENABLED=true \\ -p 6831:6831/udp \\ -p 6832:6832/udp \\ -p 5778:5778 \\ -p 16686:16686 \\ -p 4317:4317 \\ -p 4318:4318 \\ -p 14250:14250 \\ -p 14268:14268 \\ -p 14269:14269 \\ -p 9411:9411 \\ jaegertracing/all-in-one:1.50 Run the Jaeger docker image. ",
            "title": "Set up Jaeger"
        },
        {
            "location": "/se/guides/tracing",
            "text": " Update the pom.xml file and add the following Jaeger dependency to the &lt;dependencies&gt; section ( not &lt;dependencyManagement&gt; ). This will enable Helidon to use Jaeger at the default host and port, localhost:14250 . <markup lang=\"xml\" title=\"Add the following dependencies to pom.xml :\" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.webserver.observe&lt;/groupId&gt; &lt;artifactId&gt;helidon-webserver-observe-tracing&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-providers-jaeger&lt;/artifactId&gt; &lt;/dependency&gt; Helidon Tracing dependencies. Observability features for tracing. Jaeger tracing provider. All spans sent by Helidon to Jaeger need to be associated with a service. Specify the service name below. <markup lang=\"bash\" title=\"Add the following lines to resources/application.yaml :\" >tracing: service: helidon-se-1 protocol: http port: 14250 path: /api/traces tags: env: development enabled: true sampler-type: \"const\" sampler-param: 1 log-spans: true propagation: b3 <markup lang=\"java\" title=\"Update the Main class. Add Tracer to the WebServer builder\" >import io.helidon.tracing.TracerBuilder; ... Tracer tracer = TracerBuilder.create(\"helidon\") .build(); WebServer server = WebServer.builder(createRouting(config)) .config(config.get(\"server\")) .addFeature(ObserveFeature.builder() .addObserver(TracingObserver.create(tracer)) .build()) .addMediaSupport(JsonpSupport.create()) .build(); Create the Tracer object. Add an observability feature using the created Tracer . <markup lang=\"java\" title=\"Update the GreetService class: replace the getDefaultMessageHandler method:\" >private void getDefaultMessageHandler(ServerRequest request, ServerResponse response) { var spanBuilder = Tracer.global().spanBuilder(\"mychildSpan\"); request.context().get(SpanContext.class).ifPresent(sc -&gt; sc.asParent(spanBuilder)); var span = spanBuilder.start(); try { sendResponse(response, \"World\"); span.end(); } catch (Throwable t) { span.end(t); } } Create a new Span using the global tracer. Set the parent of the new span to the span from the Request if available. Start the span. End the span normally after the response is sent. End the span with an exception if one was thrown. <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-se.jar <markup lang=\"bash\" title=\"Run the curl command in a new terminal window and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"Hello World!\" } ",
            "title": "Enable Tracing in the Helidon Application"
        },
        {
            "location": "/se/guides/tracing",
            "text": " The tracing output data is verbose and can be challenging to interpret using the REST API, especially since it represents a structure of spans. Jaeger provides a web-based UI at http://localhost:16686/search , where you can see a visual representation of the same data and the relationship between spans within a trace. Click on the UI Find traces button (the search icon) as shown in the image below. Notice that you can change the look-back time to restrict the trace list. Jaeger UI The image below shows the trace summary, including start time and duration of each trace. There are two traces, each one generated in response to a curl http://localhost:8080/greet invocation. The oldest trace will have a much longer duration since there is one-time initialization that occurs. Tracing list view Click on a trace, and you will see the trace detail page where the spans are listed. You can clearly see the root span and the relationship among all the spans in the trace, along with timing information. Trace detail page For OpenTracing, a parent span might not depend on the result of the child. This is called a FollowsFrom reference, see Open Tracing Semantic Spec . You can examine span details by clicking on the span row. Refer to the image below, which shows the span details, including timing information. You can see times for each space relative to the root span. These rows are annotated with Server Start and Server Finish , as shown in the third column. Span detail page ",
            "title": "Viewing Tracing Using Jaeger UI"
        },
        {
            "location": "/se/guides/tracing",
            "text": " Helidon automatically traces across services if the services use the same tracer, for example, the same instance of Jaeger. This means a single trace can include spans from multiple services and hosts. Helidon uses a SpanContext to propagate tracing information across process boundaries. When you make client API calls, Helidon will internally call OpenTelemetry APIs or OpenTracing APIs to propagate the SpanContext . There is nothing you need to do in your application to make this work. To demonstrate distributed tracing, you will need to create a second project, where the server listens to on port 8081. Create a new root directory to hold this new project, then do the following steps, similar to what you did at the start of this guide: ",
            "title": "Tracing Across Services"
        },
        {
            "location": "/se/guides/tracing",
            "text": "<markup lang=\"bash\" title=\"Run the Maven archetype:\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-se \\ -DarchetypeVersion=4.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-se-2 \\ -Dpackage=io.helidon.examples.quickstart.se <markup lang=\"bash\" title=\"The project will be built and run from the helidon-quickstart-se directory:\" >cd helidon-quickstart-se-2 <markup lang=\"xml\" title=\"Add the following dependencies to pom.xml :\" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.webserver.observe&lt;/groupId&gt; &lt;artifactId&gt;helidon-webserver-observe-tracing&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-providers-jaeger&lt;/artifactId&gt; &lt;/dependency&gt; Helidon Tracing API. Observability features for tracing. Jaeger tracing provider. <markup lang=\"bash\" title=\"Replace resources/application.yaml with the following:\" >app: greeting: \"Hello From SE-2\" tracing: service: helidon-se-2 protocol: http port: 14250 path: /api/traces tags: env: development enabled: true sampler-type: \"const\" sampler-param: 1 log-spans: true propagation: b3 server: port: 8081 host: 0.0.0.0 The settings above are for development and experimental purposes only. For production environment, please see the Tracing documentation . <markup lang=\"java\" title=\"Update the Main class; Add Tracer to the WebServer builder\" >Tracer tracer = TracerBuilder.create(\"helidon\") .build(); WebServer server = WebServer.builder(createRouting(config)) .config(config.get(\"server\")) .addFeature(ObserveFeature.builder() .addObserver(TracingObserver.create(tracer)) .build()) .addMediaSupport(JsonpSupport.create()) .build(); Create the Tracer object. Add an observability feature using the created Tracer . <markup lang=\"java\" title=\"Update the GreetService class. Replace the getDefaultMessageHandler method:\" >private void getDefaultMessageHandler(ServerRequest request, ServerResponse response) { var spanBuilder = request.tracer() .buildSpan(\"getDefaultMessageHandler\"); request.spanContext().ifPresent(spanBuilder::asChildOf); Span span = spanBuilder.start(); try { sendResponse(response, \"World\"); } catch (Throwable t) { span.end(t); } } <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-se-2.jar <markup lang=\"bash\" title=\"Run the curl command in a new terminal window and check the response ( notice the port is 8081 ) :\" >curl http://localhost:8081/greet ... { \"message\": \"Hello From SE-2 World!\" } ",
            "title": "Create the Second Service"
        },
        {
            "location": "/se/guides/tracing",
            "text": " Once you have validated that the second service is running correctly, you need to modify the original application to call it. <markup lang=\"xml\" title=\"Add the following dependency to pom.xml :\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.integration&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-integration-jersey&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-jersey-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.glassfish.jersey.core&lt;/groupId&gt; &lt;artifactId&gt;jersey-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.glassfish.jersey.inject&lt;/groupId&gt; &lt;artifactId&gt;jersey-hk2&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"java\" title=\"Replace the GreetService class with the following code:\" >public class GreetService implements HttpService { private final AtomicReference&lt;String&gt; greeting = new AtomicReference&lt;&gt;(); private WebTarget webTarget; private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); GreetService(Config config) { greeting.set(config.get(\"app.greeting\").asString().orElse(\"Ciao\")); Client jaxRsClient = ClientBuilder.newBuilder().build(); webTarget = jaxRsClient.target(\"http://localhost:8081/greet\"); } @Override public void routing(HttpRules rules) { rules .get(\"/\", this::getDefaultMessageHandler) .get(\"/outbound\", this::outboundMessageHandler) .put(\"/greeting\", this::updateGreetingHandler); } private void getDefaultMessageHandler(ServerRequest request, ServerResponse response) { var spanBuilder = Tracer.global().spanBuilder(\"getDefaultMessageHandler\"); request.context().get(SpanContext.class).ifPresent(sc -&gt; sc.asParent(spanBuilder)); var span = spanBuilder.start(); try { sendResponse(response, \"World\"); span.end(); } catch (Throwable t) { span.end(t); } } private void sendResponse(ServerResponse response, String name) { String msg = String.format(\"%s %s!\", greeting.get(), name); JsonObject returnObject = JSON.createObjectBuilder().add(\"message\", msg).build(); response.send(returnObject); } private void updateGreetingFromJson(JsonObject jo, ServerResponse response) { if (!jo.containsKey(\"greeting\")) { JsonObject jsonErrorObject = JSON.createObjectBuilder().add(\"error\", \"No greeting provided\").build(); response.status(Http.Status.BAD_REQUEST_400).send(jsonErrorObject); return; } greeting.set(jo.getString(\"greeting\")); response.status(Http.Status.NO_CONTENT_204).send(); } private void outboundMessageHandler(ServerRequest request, ServerResponse response) { Invocation.Builder requestBuilder = webTarget.request(); var spanBuilder = Tracer.global().spanBuilder(\"outboundMessageHandler\"); request.context().get(SpanContext.class).ifPresent(sc -&gt; sc.asParent(spanBuilder)); var span = spanBuilder.start(); try { requestBuilder.property( ClientTracingFilter.CURRENT_SPAN_CONTEXT_PROPERTY_NAME, span.context()); String result = requestBuilder .get(String.class); response.send(result); span.end(); } catch (Throwable t) { span.end(t); } } } Add outboundMessageHandler to the routing rules. Create and start a span that is a child of the current span. Set a property with the SpanContext . Invoke the second service. Stop the span. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl -i http://localhost:8080/greet/outbound ... { \"message\": \"Hello From SE-2 World!\" } The request went to the service on 8080 , which then invoked the service at 8081 to get the greeting. Notice the greeting came from the second service. Refresh the Jaeger UI trace listing page and notice that there is a trace across two services. Tracing across multiple services detail view In the image above, you can see that the trace includes spans from two services. You will notice there is a gap before the sixth span, which is a get operation. This is a one-time client initialization delay. Run the /outbound curl command again and look at the new trace to see that the delay no longer exists. You can now stop your second service, it is no longer used in this guide. ",
            "title": "Modify the First Service"
        },
        {
            "location": "/se/guides/tracing",
            "text": " The examples in this guide demonstrate how to integrate tracing with Helidon, how to view traces, how to trace across multiple services, and how to integrate with tracing with Kubernetes. All examples use Jaeger and traces will be viewed using the Jaeger UI. Create a Sample Helidon SE Project Use the Helidon SE Maven archetype to create a simple project that can be used for the examples in this guide. <markup lang=\"bash\" title=\"Run the Maven archetype:\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-se \\ -DarchetypeVersion=4.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-se \\ -Dpackage=io.helidon.examples.quickstart.se <markup lang=\"bash\" title=\"The project will be built and run from the helidon-quickstart-se directory:\" >cd helidon-quickstart-se Set up Jaeger First, you need to run the Jaeger tracer. Helidon will communicate with this tracer at runtime. <markup lang=\"bash\" title=\"Run Jaeger within a docker container, then check the Jaeger server working:\" >docker run -d --name jaeger \\ -e COLLECTOR_OTLP_ENABLED=true \\ -p 6831:6831/udp \\ -p 6832:6832/udp \\ -p 5778:5778 \\ -p 16686:16686 \\ -p 4317:4317 \\ -p 4318:4318 \\ -p 14250:14250 \\ -p 14268:14268 \\ -p 14269:14269 \\ -p 9411:9411 \\ jaegertracing/all-in-one:1.50 Run the Jaeger docker image. Enable Tracing in the Helidon Application Update the pom.xml file and add the following Jaeger dependency to the &lt;dependencies&gt; section ( not &lt;dependencyManagement&gt; ). This will enable Helidon to use Jaeger at the default host and port, localhost:14250 . <markup lang=\"xml\" title=\"Add the following dependencies to pom.xml :\" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.webserver.observe&lt;/groupId&gt; &lt;artifactId&gt;helidon-webserver-observe-tracing&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-providers-jaeger&lt;/artifactId&gt; &lt;/dependency&gt; Helidon Tracing dependencies. Observability features for tracing. Jaeger tracing provider. All spans sent by Helidon to Jaeger need to be associated with a service. Specify the service name below. <markup lang=\"bash\" title=\"Add the following lines to resources/application.yaml :\" >tracing: service: helidon-se-1 protocol: http port: 14250 path: /api/traces tags: env: development enabled: true sampler-type: \"const\" sampler-param: 1 log-spans: true propagation: b3 <markup lang=\"java\" title=\"Update the Main class. Add Tracer to the WebServer builder\" >import io.helidon.tracing.TracerBuilder; ... Tracer tracer = TracerBuilder.create(\"helidon\") .build(); WebServer server = WebServer.builder(createRouting(config)) .config(config.get(\"server\")) .addFeature(ObserveFeature.builder() .addObserver(TracingObserver.create(tracer)) .build()) .addMediaSupport(JsonpSupport.create()) .build(); Create the Tracer object. Add an observability feature using the created Tracer . <markup lang=\"java\" title=\"Update the GreetService class: replace the getDefaultMessageHandler method:\" >private void getDefaultMessageHandler(ServerRequest request, ServerResponse response) { var spanBuilder = Tracer.global().spanBuilder(\"mychildSpan\"); request.context().get(SpanContext.class).ifPresent(sc -&gt; sc.asParent(spanBuilder)); var span = spanBuilder.start(); try { sendResponse(response, \"World\"); span.end(); } catch (Throwable t) { span.end(t); } } Create a new Span using the global tracer. Set the parent of the new span to the span from the Request if available. Start the span. End the span normally after the response is sent. End the span with an exception if one was thrown. <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-se.jar <markup lang=\"bash\" title=\"Run the curl command in a new terminal window and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"Hello World!\" } Viewing Tracing Using Jaeger UI The tracing output data is verbose and can be challenging to interpret using the REST API, especially since it represents a structure of spans. Jaeger provides a web-based UI at http://localhost:16686/search , where you can see a visual representation of the same data and the relationship between spans within a trace. Click on the UI Find traces button (the search icon) as shown in the image below. Notice that you can change the look-back time to restrict the trace list. Jaeger UI The image below shows the trace summary, including start time and duration of each trace. There are two traces, each one generated in response to a curl http://localhost:8080/greet invocation. The oldest trace will have a much longer duration since there is one-time initialization that occurs. Tracing list view Click on a trace, and you will see the trace detail page where the spans are listed. You can clearly see the root span and the relationship among all the spans in the trace, along with timing information. Trace detail page For OpenTracing, a parent span might not depend on the result of the child. This is called a FollowsFrom reference, see Open Tracing Semantic Spec . You can examine span details by clicking on the span row. Refer to the image below, which shows the span details, including timing information. You can see times for each space relative to the root span. These rows are annotated with Server Start and Server Finish , as shown in the third column. Span detail page Tracing Across Services Helidon automatically traces across services if the services use the same tracer, for example, the same instance of Jaeger. This means a single trace can include spans from multiple services and hosts. Helidon uses a SpanContext to propagate tracing information across process boundaries. When you make client API calls, Helidon will internally call OpenTelemetry APIs or OpenTracing APIs to propagate the SpanContext . There is nothing you need to do in your application to make this work. To demonstrate distributed tracing, you will need to create a second project, where the server listens to on port 8081. Create a new root directory to hold this new project, then do the following steps, similar to what you did at the start of this guide: Create the Second Service <markup lang=\"bash\" title=\"Run the Maven archetype:\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-se \\ -DarchetypeVersion=4.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-se-2 \\ -Dpackage=io.helidon.examples.quickstart.se <markup lang=\"bash\" title=\"The project will be built and run from the helidon-quickstart-se directory:\" >cd helidon-quickstart-se-2 <markup lang=\"xml\" title=\"Add the following dependencies to pom.xml :\" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.webserver.observe&lt;/groupId&gt; &lt;artifactId&gt;helidon-webserver-observe-tracing&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-providers-jaeger&lt;/artifactId&gt; &lt;/dependency&gt; Helidon Tracing API. Observability features for tracing. Jaeger tracing provider. <markup lang=\"bash\" title=\"Replace resources/application.yaml with the following:\" >app: greeting: \"Hello From SE-2\" tracing: service: helidon-se-2 protocol: http port: 14250 path: /api/traces tags: env: development enabled: true sampler-type: \"const\" sampler-param: 1 log-spans: true propagation: b3 server: port: 8081 host: 0.0.0.0 The settings above are for development and experimental purposes only. For production environment, please see the Tracing documentation . <markup lang=\"java\" title=\"Update the Main class; Add Tracer to the WebServer builder\" >Tracer tracer = TracerBuilder.create(\"helidon\") .build(); WebServer server = WebServer.builder(createRouting(config)) .config(config.get(\"server\")) .addFeature(ObserveFeature.builder() .addObserver(TracingObserver.create(tracer)) .build()) .addMediaSupport(JsonpSupport.create()) .build(); Create the Tracer object. Add an observability feature using the created Tracer . <markup lang=\"java\" title=\"Update the GreetService class. Replace the getDefaultMessageHandler method:\" >private void getDefaultMessageHandler(ServerRequest request, ServerResponse response) { var spanBuilder = request.tracer() .buildSpan(\"getDefaultMessageHandler\"); request.spanContext().ifPresent(spanBuilder::asChildOf); Span span = spanBuilder.start(); try { sendResponse(response, \"World\"); } catch (Throwable t) { span.end(t); } } <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-se-2.jar <markup lang=\"bash\" title=\"Run the curl command in a new terminal window and check the response ( notice the port is 8081 ) :\" >curl http://localhost:8081/greet ... { \"message\": \"Hello From SE-2 World!\" } Modify the First Service Once you have validated that the second service is running correctly, you need to modify the original application to call it. <markup lang=\"xml\" title=\"Add the following dependency to pom.xml :\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.integration&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-integration-jersey&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-jersey-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.glassfish.jersey.core&lt;/groupId&gt; &lt;artifactId&gt;jersey-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.glassfish.jersey.inject&lt;/groupId&gt; &lt;artifactId&gt;jersey-hk2&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"java\" title=\"Replace the GreetService class with the following code:\" >public class GreetService implements HttpService { private final AtomicReference&lt;String&gt; greeting = new AtomicReference&lt;&gt;(); private WebTarget webTarget; private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); GreetService(Config config) { greeting.set(config.get(\"app.greeting\").asString().orElse(\"Ciao\")); Client jaxRsClient = ClientBuilder.newBuilder().build(); webTarget = jaxRsClient.target(\"http://localhost:8081/greet\"); } @Override public void routing(HttpRules rules) { rules .get(\"/\", this::getDefaultMessageHandler) .get(\"/outbound\", this::outboundMessageHandler) .put(\"/greeting\", this::updateGreetingHandler); } private void getDefaultMessageHandler(ServerRequest request, ServerResponse response) { var spanBuilder = Tracer.global().spanBuilder(\"getDefaultMessageHandler\"); request.context().get(SpanContext.class).ifPresent(sc -&gt; sc.asParent(spanBuilder)); var span = spanBuilder.start(); try { sendResponse(response, \"World\"); span.end(); } catch (Throwable t) { span.end(t); } } private void sendResponse(ServerResponse response, String name) { String msg = String.format(\"%s %s!\", greeting.get(), name); JsonObject returnObject = JSON.createObjectBuilder().add(\"message\", msg).build(); response.send(returnObject); } private void updateGreetingFromJson(JsonObject jo, ServerResponse response) { if (!jo.containsKey(\"greeting\")) { JsonObject jsonErrorObject = JSON.createObjectBuilder().add(\"error\", \"No greeting provided\").build(); response.status(Http.Status.BAD_REQUEST_400).send(jsonErrorObject); return; } greeting.set(jo.getString(\"greeting\")); response.status(Http.Status.NO_CONTENT_204).send(); } private void outboundMessageHandler(ServerRequest request, ServerResponse response) { Invocation.Builder requestBuilder = webTarget.request(); var spanBuilder = Tracer.global().spanBuilder(\"outboundMessageHandler\"); request.context().get(SpanContext.class).ifPresent(sc -&gt; sc.asParent(spanBuilder)); var span = spanBuilder.start(); try { requestBuilder.property( ClientTracingFilter.CURRENT_SPAN_CONTEXT_PROPERTY_NAME, span.context()); String result = requestBuilder .get(String.class); response.send(result); span.end(); } catch (Throwable t) { span.end(t); } } } Add outboundMessageHandler to the routing rules. Create and start a span that is a child of the current span. Set a property with the SpanContext . Invoke the second service. Stop the span. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl -i http://localhost:8080/greet/outbound ... { \"message\": \"Hello From SE-2 World!\" } The request went to the service on 8080 , which then invoked the service at 8081 to get the greeting. Notice the greeting came from the second service. Refresh the Jaeger UI trace listing page and notice that there is a trace across two services. Tracing across multiple services detail view In the image above, you can see that the trace includes spans from two services. You will notice there is a gap before the sixth span, which is a get operation. This is a one-time client initialization delay. Run the /outbound curl command again and look at the new trace to see that the delay no longer exists. You can now stop your second service, it is no longer used in this guide. ",
            "title": "Getting Started with Tracing"
        },
        {
            "location": "/se/guides/tracing",
            "text": "<markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named jaeger.yaml , with the following contents:\" >apiVersion: v1 kind: Service metadata: name: jaeger spec: ports: - port: 16686 protocol: TCP selector: app: jaeger --- kind: Pod apiVersion: v1 metadata: name: jaeger labels: app: jaeger spec: containers: - name: jaeger image: jaegertracing/all-in-one imagePullPolicy: IfNotPresent ports: - containerPort: 16686 <markup lang=\"bash\" title=\"Create the Jaeger pod and ClusterIP service:\" >kubectl apply -f ./jaeger.yaml <markup lang=\"bash\" title=\"Create a Jaeger external server to view the UI and expose it on port 9142:\" >kubectl expose pod jaeger --name=jaeger-external --port=16687 --target-port=16686 --type=LoadBalancer Navigate to http://localhost:16687/jaeger to validate that you can access Jaeger running in Kubernetes. It may take a few seconds before it is ready. ",
            "title": "Deploy Jaeger into Kubernetes"
        },
        {
            "location": "/se/guides/tracing",
            "text": "<markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named tracing.yaml , with the following contents:\" >kind: Service apiVersion: v1 metadata: name: helidon-tracing labels: app: helidon-tracing spec: type: NodePort selector: app: helidon-tracing ports: - port: 8080 targetPort: 8080 name: http --- kind: Deployment apiVersion: apps/v1 metadata: name: helidon-tracing spec: replicas: 1 selector: matchLabels: app: helidon-tracing template: metadata: labels: app: helidon-tracing version: v1 spec: containers: - name: helidon-tracing image: helidon-tracing-se imagePullPolicy: IfNotPresent ports: - containerPort: 8080 A service of type NodePort that serves the default routes on port 8080 . A deployment with one replica of a pod. <markup lang=\"bash\" title=\"Create and deploy the application into Kubernetes:\" >kubectl apply -f ./tracing.yaml ",
            "title": "Deploy Your Helidon Application into Kubernetes"
        },
        {
            "location": "/se/guides/tracing",
            "text": "<markup lang=\"bash\" title=\"Get the application service information:\" >kubectl get service/helidon-tracing <markup lang=\"bash\" >NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE helidon-tracing NodePort 10.99.159.2 &lt;none&gt; 8080:31143/TCP 8s A service of type NodePort that serves the default routes on port 31143 . <markup lang=\"bash\" title=\"Verify the tracing endpoint using port 31143 , your port will likely be different:\" >curl http://localhost:31143/greet ... { \"message\": \"Hello World!\" } Access the Jaeger UI at http://localhost:9412/jaeger and click on the refresh icon to see the trace that was just created. ",
            "title": "Access Your Application and the Jaeger Trace"
        },
        {
            "location": "/se/guides/tracing",
            "text": " You can now delete the Kubernetes resources just created during this example. <markup lang=\"bash\" title=\"Delete the Kubernetes resources:\" >kubectl delete -f ./jaeger.yaml kubectl delete -f ./tracing.yaml kubectl delete service jaeger-external docker rm -f jaeger ",
            "title": "Cleanup"
        },
        {
            "location": "/se/guides/tracing",
            "text": " The following example demonstrates how to use Jaeger from a Helidon application running in Kubernetes. <markup lang=\"bash\" title=\"Replace the tracing configuration in resources/application.yaml with the following:\" > tracing: service: helidon-se-1 host: jaeger Helidon service helidon-se-1 will connect to the Jaeger server at host name jaeger . <markup lang=\"bash\" title=\"Stop the application and build the docker image for your application:\" >docker build -t helidon-tracing-se . Deploy Jaeger into Kubernetes <markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named jaeger.yaml , with the following contents:\" >apiVersion: v1 kind: Service metadata: name: jaeger spec: ports: - port: 16686 protocol: TCP selector: app: jaeger --- kind: Pod apiVersion: v1 metadata: name: jaeger labels: app: jaeger spec: containers: - name: jaeger image: jaegertracing/all-in-one imagePullPolicy: IfNotPresent ports: - containerPort: 16686 <markup lang=\"bash\" title=\"Create the Jaeger pod and ClusterIP service:\" >kubectl apply -f ./jaeger.yaml <markup lang=\"bash\" title=\"Create a Jaeger external server to view the UI and expose it on port 9142:\" >kubectl expose pod jaeger --name=jaeger-external --port=16687 --target-port=16686 --type=LoadBalancer Navigate to http://localhost:16687/jaeger to validate that you can access Jaeger running in Kubernetes. It may take a few seconds before it is ready. Deploy Your Helidon Application into Kubernetes <markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named tracing.yaml , with the following contents:\" >kind: Service apiVersion: v1 metadata: name: helidon-tracing labels: app: helidon-tracing spec: type: NodePort selector: app: helidon-tracing ports: - port: 8080 targetPort: 8080 name: http --- kind: Deployment apiVersion: apps/v1 metadata: name: helidon-tracing spec: replicas: 1 selector: matchLabels: app: helidon-tracing template: metadata: labels: app: helidon-tracing version: v1 spec: containers: - name: helidon-tracing image: helidon-tracing-se imagePullPolicy: IfNotPresent ports: - containerPort: 8080 A service of type NodePort that serves the default routes on port 8080 . A deployment with one replica of a pod. <markup lang=\"bash\" title=\"Create and deploy the application into Kubernetes:\" >kubectl apply -f ./tracing.yaml Access Your Application and the Jaeger Trace <markup lang=\"bash\" title=\"Get the application service information:\" >kubectl get service/helidon-tracing <markup lang=\"bash\" >NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE helidon-tracing NodePort 10.99.159.2 &lt;none&gt; 8080:31143/TCP 8s A service of type NodePort that serves the default routes on port 31143 . <markup lang=\"bash\" title=\"Verify the tracing endpoint using port 31143 , your port will likely be different:\" >curl http://localhost:31143/greet ... { \"message\": \"Hello World!\" } Access the Jaeger UI at http://localhost:9412/jaeger and click on the refresh icon to see the trace that was just created. Cleanup You can now delete the Kubernetes resources just created during this example. <markup lang=\"bash\" title=\"Delete the Kubernetes resources:\" >kubectl delete -f ./jaeger.yaml kubectl delete -f ./tracing.yaml kubectl delete service jaeger-external docker rm -f jaeger ",
            "title": "Integration with Kubernetes"
        },
        {
            "location": "/se/guides/tracing",
            "text": " This guide has demonstrated how to use the Helidon SE tracing feature with Jaeger. You have learned to do the following: Enable tracing within a service Use tracing with JAX-RS Use the Jaeger REST API and UI Use tracing across multiple services Integrate tracing with Kubernetes Refer to the following references for additional information: MicroProfile OpenTracing specification MicroProfile OpenTracing Javadoc OpenTelemetry API Helidon Javadoc ",
            "title": "Summary"
        },
        {
            "location": "/se/guides/upgrade",
            "text": " In Helidon 2 we have made some changes to APIs and runtime behavior. This guide will help you migrate a Helidon SE 1.x application to 2.x. ",
            "title": "preambule"
        },
        {
            "location": "/se/guides/upgrade",
            "text": " Java 8 is no longer supported in Helidon 2. Java 11 or newer is required. ",
            "title": "Java 11 Runtime"
        },
        {
            "location": "/se/guides/upgrade",
            "text": " We have upgraded to OpenTracing version 0.33.0 that is not backward compatible. OpenTracing introduced the following breaking changes: Removed Replacement ScopeManager.active() Tracer.activeSpan() ScopeManager.activate(Span, boolean) ScopeManager.activate(Span) - second parameter is now always false SpanBuilder.startActive() Tracer.activateSpan(Span) TextMapExtractAdapter and TextMapInjectAdapter TextMapAdapter Module name changed opentracing.api io.opentracing.api (same for noop and util ) If you use the TracerBuilder abstraction in Helidon and have no custom Spans, there is no change required ",
            "title": "Tracing"
        },
        {
            "location": "/se/guides/upgrade",
            "text": " When the OIDC provider is configured to use cookie (default configuration) to carry authentication information, the cookie Same-Site is now set to Lax (used to be Strict ). This is to prevent infinite redirects, as browsers would refuse to set the cookie on redirected requests (due to this setting). Only in the case of the frontend host and identity host match, we leave Strict as the default ",
            "title": "Security: OIDC"
        },
        {
            "location": "/se/guides/upgrade",
            "text": " Some methods that act as getters of type T have been modified to return Optional&lt;T&gt; . You will need to change your code to handle the Optional return type. For example ServerRequest.spanContext() in 1.x had a return type of SpanContext . In 2.x it has a return type of Optional&lt;SpanContext&gt; . So if you had code like: <markup lang=\"java\" title=\"Helidon 1.x Code\" >Span myNewSpan = GlobalTracer.get() .buildSpan(“my-operation”) .asChildOf(serverRequest.spanContext()) .start(); you will need to change it to something like: <markup lang=\"java\" title=\"Helidon 2.x Code\" >Tracer.SpanBuilder spanBuilder = serverRequest.tracer() .buildSpan(\"my-operation\"); serverRequest.spanContext().ifPresent(spanBuilder::asChildOf); Span myNewSpan = spanBuilder.start(); Note the use of ifPresent() on the returned Optional&lt;SpanContext&gt; . ",
            "title": "Getters"
        },
        {
            "location": "/se/guides/upgrade",
            "text": " File watching is now done through a ChangeWatcher - use of PollingStrategies.watch() needs to be refactored to FileSystemWatcher.create() and the method to configure it on config source builder has changed to changeWatcher(ChangeWatcher) . Methods on ConfigSources now return specific builders (they used to return AbstractParsableConfigSource.Builder with a complex type declaration). If you store such a builder in a variable, either change it to the correct type, or use var Some APIs were cleaned up to be aligned with the development guidelines of Helidon. When using Git config source, or etcd config source, the factory methods moved to the config source itself, and the builder now accepts all configuration options through methods The API of config source builders has been cleaned, so now only methods that are relevant to a specific config source type can be invoked on such a builder. Previously you could configure a polling strategy on a source that did not support polling There is a small change in behavior of Helidon Config vs. MicroProfile Config: The MP TCK require that system properties are fully mutable (e.g. as soon as the property is changed, it must be used), so MP Config methods work in this manner (with a certain performance overhead). Helidon Config treats System properties as a mutable config source, with a (optional) time based polling strategy. So the change is reflected as well, though not immediately (this is only relevant if you use change notifications). CompositeConfigSource has been removed from Config . If you need to configure MerginStrategy , you can do it now on Config Builder Example of advanced configuration of config: <markup lang=\"java\" >Config.builder() // system properties with a polling strategy of 10 seconds .addSource(ConfigSources.systemProperties() .pollingStrategy(PollingStrategies.regular(Duration.ofSeconds(10)))) // environment variables .addSource(ConfigSources.environmentVariables()) // optional file config source with change watcher .addSource(ConfigSources.file(Paths.get(\"/conf/app.yaml\")) .optional() .changeWatcher(FileSystemWatcher.create())) // classpath config source .addSource(ConfigSources.classpath(\"application.yaml\")) // map config source (also supports polling strategy) .addSource(ConfigSources.create(Map.of(\"key\", \"value\"))) .build(); ",
            "title": "Configuration"
        },
        {
            "location": "/se/guides/upgrade",
            "text": " The configuration approach to Resource class was using prefixes which was not aligned with our approach to configuration. All usages were refactored as follows: The Resource class expects a config node resource that will be used to read it The feature set remains unchanged - we support path, classpath, url, content as plain text, and content as base64 Classes using resources are changed as well, such as KeyConfig - see details below ",
            "title": "Resource Class When Loaded from Config"
        },
        {
            "location": "/se/guides/upgrade",
            "text": " In Helidon 1.x support for JSON and other media types was configured when constructing webserver.Routing using the register method. In Helidon 2 Media Support has been refactored so that it can be shared between the Helidon WebServer and WebClient . You now specify media support as part of the WebServer build: <markup lang=\"java\" >WebServer.builder() .addMediaSupport(JsonpSupport.create()) //registers reader and writer for Json-P .build() This replaces Routing.builder().register(JsonSupport.create())&#8230;&#8203; The new JSON MediaSupport classes are: io.helidon.http.media.jsonp.JsonpSupport in module io.helidon.http.media:helidon-media-jsonp io.helidon.http.media.jsonb.JsonbSupport in module io.helidon.http.media:helidon-media-jsonb io.helidon.http.media.jackson.JacksonSupport in module io.helidon.http.media:helidon-media-jackson ",
            "title": "Media Support"
        },
        {
            "location": "/se/guides/upgrade",
            "text": " Removed Replacement io.helidon.common.reactive.ReactiveStreamsAdapter org.reactivestreams.FlowAdapters ",
            "title": "Reactive"
        },
        {
            "location": "/se/guides/upgrade",
            "text": " Configuration has been updated to use the new Resource approach: oidc-metadata.resource is the new key for loading oidc-metadata from local resource sign-jwk.resource is the new key for loading signing JWK resource ",
            "title": "Security: OidcConfig"
        },
        {
            "location": "/se/guides/upgrade",
            "text": " Configuration has been updated to use the new Resource approach: jwk.resource is the new key for loading JWK for verifying signatures jwt.resource is also used for outbound as key for loading JWK for signing tokens ",
            "title": "Security: JwtProvider and JwtAuthProvider"
        },
        {
            "location": "/se/guides/upgrade",
            "text": " The configuration has been updated to have a nicer tree structure: Example of a public key from keystore: <markup lang=\"yaml\" >keystore: cert.alias: \"service_cert\" resource.path: \"/conf/keystore.p12\" type: \"PKCS12\" passphrase: \"password\" Example of a private key from keystore: <markup lang=\"yaml\" >keystore: key: alias: \"myPrivateKey\" passphrase: \"password\" resource.resource-path: \"keystore/keystore.p12\" passphrase: \"password\" Example of a pem resource with private key and certificate chain: <markup lang=\"yaml\" >pem: key: passphrase: \"password\" resource.resource-path: \"keystore/id_rsa.p8\" cert-chain: resource.resource-path: \"keystore/public_key_cert.pem\" ",
            "title": "PKI Key Configuration"
        },
        {
            "location": "/se/guides/upgrade",
            "text": " Configuration has been updated to use the new Resource approach: tls-cert.resource is the new key for certificate tls-key.resource is the new key for private key tl-ca-cert is the the new key for certificate ",
            "title": "GrpcTlsDescriptor"
        },
        {
            "location": "/se/guides/upgrade",
            "text": " There is a new class io.helidon.webserver.WebServerTls that can be used to configure TLS for a WebServer socket. Class io.helidon.webserver.SSLContextBuilder has been deprecated and will be removed. The class uses a Builder pattern: <markup lang=\"java\" >WebServerTls.builder() .privateKey(KeyConfig.keystoreBuilder() .keystore(Resource.create(\"certificate.p12\")) .keystorePassphrase(\"helidon\") The builder or built instance can be registered with a socket configuration builder including the WebServer.Builder itself: <markup lang=\"java\" >WebServer.builder(routing()) .tls(webServerTls) .build(); ",
            "title": "SSL/TLS"
        },
        {
            "location": "/se/guides/upgrade",
            "text": " Additional socket configuration has changed both in config and in API. The configuration now accepts following structure: <markup lang=\"yaml\" >server: port: 8000 sockets: - name: \"admin\" port: 8001 - name: \"static\" port: 8002 enabled: false Socket name is now a value of a property, allowing more freedom in naming. The default socket name is implicit (and set to @default ). We have added the enabled flag to support disabling sockets through configuration. To add socket using a builder, you can use: <markup lang=\"java\" >WebServer.builder() .addSocket(SocketConfigurationBuilder.builder() .port(8001) .name(\"admin\"))); There is also a specialized method to add a socket and routing together, to remove mapping through a name. ",
            "title": "Additional Sockets"
        },
        {
            "location": "/se/guides/upgrade",
            "text": " io.helidon.webserver.ServerConfiguration.Builder is no longer used to configure WebServer . Most methods from this class have been moved to WebServer.Builder or deprecated. Example of a simple WebServer setup: <markup lang=\"java\" >WebServer.builder() .port(8001) .host(\"localhost\") .routing(createRouting()) .build(); ",
            "title": "Deprecation of ServerConfiguration"
        },
        {
            "location": "/se/guides/upgrade",
            "text": " io.helidon.webserver.WebServer.Builder - all methods that accept ServerConfiguration or its builder are deprecated, please use methods on WebServer.Builder instead io.helidon.webserver.WebServer.Builder - all methods for socket configuration that accept a name and socket are deprecated, socket name is now part of socket configuration itself io.helidon.webserver.ResponseHeaders.whenSend() - please use whenSent() io.helidon.webserver.Routing.createServer(ServerConfiguration) - please use WebServer.builder() io.helidon.webserver.Routing.createServer() - please use WebServer.builder() io.helidon.webserver.SocketConfiguration.DEFAULT - use a builder to create a named configuration io.helidon.webserver.SocketConfiguration.Builder.ssl(SSLContext) - use `WebServerTls instead io.helidon.webserver.SocketConfiguration.Builder.enabledSSlProtocols(String&#8230;&#8203;) - use `WebServerTls instead ",
            "title": "Other Significant WebServer Deprecations"
        },
        {
            "location": "/se/guides/upgrade",
            "text": " SSL/TLS There is a new class io.helidon.webserver.WebServerTls that can be used to configure TLS for a WebServer socket. Class io.helidon.webserver.SSLContextBuilder has been deprecated and will be removed. The class uses a Builder pattern: <markup lang=\"java\" >WebServerTls.builder() .privateKey(KeyConfig.keystoreBuilder() .keystore(Resource.create(\"certificate.p12\")) .keystorePassphrase(\"helidon\") The builder or built instance can be registered with a socket configuration builder including the WebServer.Builder itself: <markup lang=\"java\" >WebServer.builder(routing()) .tls(webServerTls) .build(); Additional Sockets Additional socket configuration has changed both in config and in API. The configuration now accepts following structure: <markup lang=\"yaml\" >server: port: 8000 sockets: - name: \"admin\" port: 8001 - name: \"static\" port: 8002 enabled: false Socket name is now a value of a property, allowing more freedom in naming. The default socket name is implicit (and set to @default ). We have added the enabled flag to support disabling sockets through configuration. To add socket using a builder, you can use: <markup lang=\"java\" >WebServer.builder() .addSocket(SocketConfigurationBuilder.builder() .port(8001) .name(\"admin\"))); There is also a specialized method to add a socket and routing together, to remove mapping through a name. Deprecation of ServerConfiguration io.helidon.webserver.ServerConfiguration.Builder is no longer used to configure WebServer . Most methods from this class have been moved to WebServer.Builder or deprecated. Example of a simple WebServer setup: <markup lang=\"java\" >WebServer.builder() .port(8001) .host(\"localhost\") .routing(createRouting()) .build(); Other Significant WebServer Deprecations io.helidon.webserver.WebServer.Builder - all methods that accept ServerConfiguration or its builder are deprecated, please use methods on WebServer.Builder instead io.helidon.webserver.WebServer.Builder - all methods for socket configuration that accept a name and socket are deprecated, socket name is now part of socket configuration itself io.helidon.webserver.ResponseHeaders.whenSend() - please use whenSent() io.helidon.webserver.Routing.createServer(ServerConfiguration) - please use WebServer.builder() io.helidon.webserver.Routing.createServer() - please use WebServer.builder() io.helidon.webserver.SocketConfiguration.DEFAULT - use a builder to create a named configuration io.helidon.webserver.SocketConfiguration.Builder.ssl(SSLContext) - use `WebServerTls instead io.helidon.webserver.SocketConfiguration.Builder.enabledSSlProtocols(String&#8230;&#8203;) - use `WebServerTls instead ",
            "title": "WebServer Configuration"
        },
        {
            "location": "/se/guides/upgrade_3x",
            "text": " In Helidon 3 we have made some changes to APIs and runtime behavior. This guide will help you upgrade a Helidon SE 2.x application to 3.x. ",
            "title": "preambule"
        },
        {
            "location": "/se/guides/upgrade_3x",
            "text": " Java 11 is no longer supported in Helidon 3. Java 17 or newer is required. Please follow the instructions in Prerequisites for proper installation. ",
            "title": "Java 17 Runtime"
        },
        {
            "location": "/se/guides/upgrade_3x",
            "text": " Handling routes based on the protocol version is now possible by registering specific routes on routing builder. For further information check WebServer Documentation ",
            "title": "New Routing"
        },
        {
            "location": "/se/guides/upgrade_3x",
            "text": " Helidon support of Http/2 is no longer experimental. Http/2 needed to be explicitly enabled by configuration in Helidon 2: <markup lang=\"yaml\" title=\"Enabling Http/2 support in Helidon 2\" >server: port: 8080 host: 0.0.0.0 experimental: enable-http2: true http2-max-content-length: 16384 In Helidon 3 Http/2 is automatically enabled when artifact with Http/2 support is available on the classpath. <markup lang=\"xml\" title=\"Enabling Http/2 support in Helidon 3 by adding dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webserver&lt;/groupId&gt; &lt;artifactId&gt;helidon-reactive-webserver-http2&lt;/artifactId&gt; &lt;/dependency&gt; With above dependency Helidon 3 supports Http/2 upgrade from Http/1, cleartext Http/2 without prior knowledge and Http/2 with ALPN over TLS. In Helidon 2, max content length was configurable with server.experimental.http2-max-content-length , in Helidon 3 can be configured with server.max-upgrade-content-length globally or per socket with the same max-upgrade-content-length key. <markup lang=\"yaml\" title=\"Max upgrade content length in Helidon 3\" >server: port: 8080 host: 0.0.0.0 max-upgrade-content-length: 16384 For further information check WebServer Documentation ",
            "title": "Http/2 Support"
        },
        {
            "location": "/se/guides/upgrade_3x",
            "text": " Helidon SE support is now based on the WebSocketRouting class which enables Helidon application to configure routing for both annotated and programmatic WebSocket endpoints. TyrusSupport is now deprecated. Websocket support in now placed in different artifact. <markup lang=\"xml\" title=\"Helidon 2 WebSocket support dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webserver&lt;/groupId&gt; &lt;artifactId&gt;helidon-reactive-webserver-tyrus&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"xml\" title=\"Helidon 3 WebSocket support dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webserver&lt;/groupId&gt; &lt;artifactId&gt;helidon-reactive-webserver-websocket&lt;/artifactId&gt; &lt;/dependency&gt; In Helidon 2, WebSocket routing is defined by registering TyrusSupport as additional service: <markup lang=\"java\" title=\"Helidon 2 WebSocket route registering\" >WebServer.builder(Routing.builder() .register(\"/rest\", new SomeRestService()) .register(\"/websocket\",TyrusSupport.builder() .register(ServerEndpointConfig.Builder .create(MessageBoardEndpoint.class, \"/\") .encoders(encoders) .build()) .build() )) .port(8080) .build(); Traditional REST routing service registration WebSocket setup with Tyrus service In Helidon 3, WebSocket routing is defined by adding another routing: <markup lang=\"java\" title=\"Helidon 3 WebSocket route registering\" >WebServer.builder() .routing(r -&gt; r .register(\"/rest\", new SomeRestService()) ) .addRouting(WebSocketRouting.builder() .endpoint(\"/websocket\", ServerEndpointConfig.Builder .create(MessageBoardEndpoint.class, \"/board\") .encoders(encoders) .build()) .build()) .port(8080) Traditional REST routing service registration WebSocket routing setup ",
            "title": "WebSocket"
        },
        {
            "location": "/se/guides/upgrade_3x",
            "text": " Deprecations in the following classes: Resource - old configuration approach (since 2.0) ThreadPoolSupplier - Named thread pools (since 2.4.2) More information in the following Task . ",
            "title": "Helidon Common"
        },
        {
            "location": "/se/guides/upgrade_3x",
            "text": " Deprecations in the following classes: ContentReaders - Methods with alternatives (since 2.0) ContentTypeCharset - Class with alternative (since 2.0) ContentWriters - Methods with alternatives (since 2.0) MessageBodyReaderContext - Methods with alternatives (since 2.0) MessageBodyWriterContext - Methods with alternatives (since 2.0) ReadableByteChannelPublisher - Class with alternative (since 2.0) More information in the following Task . ",
            "title": "Media Common"
        },
        {
            "location": "/se/guides/upgrade_3x",
            "text": " Deprecations in the following classes: MetricsSupport - 3 methods, replacing Config with metrics settings KeyPerformanceIndicatorMetricsSettings - New class in metrics API, for backward compatibility only RegistryFactory - New class in metrics API, for backward compatibility only More information in the following Task . ",
            "title": "Metrics"
        },
        {
            "location": "/se/guides/upgrade_3x",
            "text": " Deprecations in the following class: DataPropagationProvider - clearData should use new method More information in the following Task . ",
            "title": "Common Context"
        },
        {
            "location": "/se/guides/upgrade_3x",
            "text": " Deprecations: JavaMarshaller - removed support for JavaMarshaller More information in the following Task . gRPC scope is temporarily smaller in Helidon, please follow issue https://github.com/helidon-io/helidon/issues/5418 ",
            "title": "GRPC core"
        },
        {
            "location": "/se/guides/upgrade_3x",
            "text": " Deprecations in the following class: CoordinatorClient - multiple methods Headers More information in the following Task . ",
            "title": "LRA"
        },
        {
            "location": "/se/guides/upgrade_3x",
            "text": " Deprecations in the following class: MessagingCdiExtension - Alternative methods used More information in the following Task . ",
            "title": "MP Messaging"
        },
        {
            "location": "/se/guides/upgrade_3x",
            "text": " Deprecations in the following class: Jwt - Audience can be a list (since 2.4.0) More information in the following Task . ",
            "title": "JWT"
        },
        {
            "location": "/se/guides/upgrade_3x",
            "text": " Deprecations in the following class: MetricUtil - multiple methods MetricsCdiExtension - multiple methods More information in the following Task . ",
            "title": "MP Metrics"
        },
        {
            "location": "/se/guides/upgrade_3x",
            "text": " backwardCompatibleEol - set to false More information in the following Task . ",
            "title": "HTTP Signature Security Provider"
        },
        {
            "location": "/se/guides/upgrade_3x",
            "text": " Deprecations in the following class: HelidonRestServiceSupport - method configureEndpoint(Rules) More information in the following Task . ",
            "title": "Service Common"
        },
        {
            "location": "/se/guides/upgrade_3x",
            "text": " Static content support in WebServer - moved to a separate module. Fully removed from WebServer module. More information in the following Task . ",
            "title": "WebServer"
        },
        {
            "location": "/se/guides/upgrade_3x",
            "text": " The custom Helidon OCI clients have been deprecated ( See PR ). Use the OCI Java SDK instead. If you use Helidon MP you can inject OCI SDK clients by adding the dependency io.helidon.integrations.oci.sdk:helidon-integrations-oci-sdk-cdi . See Resolving compatibility issue with OCI SDK for detailed information on how to work around this issue. The MultiPart buffered readers have been deprecated ( See PR ). Use the MultiPart stream readers instead. Helidon Common Deprecations in the following classes: Resource - old configuration approach (since 2.0) ThreadPoolSupplier - Named thread pools (since 2.4.2) More information in the following Task . Media Common Deprecations in the following classes: ContentReaders - Methods with alternatives (since 2.0) ContentTypeCharset - Class with alternative (since 2.0) ContentWriters - Methods with alternatives (since 2.0) MessageBodyReaderContext - Methods with alternatives (since 2.0) MessageBodyWriterContext - Methods with alternatives (since 2.0) ReadableByteChannelPublisher - Class with alternative (since 2.0) More information in the following Task . Metrics Deprecations in the following classes: MetricsSupport - 3 methods, replacing Config with metrics settings KeyPerformanceIndicatorMetricsSettings - New class in metrics API, for backward compatibility only RegistryFactory - New class in metrics API, for backward compatibility only More information in the following Task . Common Context Deprecations in the following class: DataPropagationProvider - clearData should use new method More information in the following Task . GRPC core Deprecations: JavaMarshaller - removed support for JavaMarshaller More information in the following Task . gRPC scope is temporarily smaller in Helidon, please follow issue https://github.com/helidon-io/helidon/issues/5418 LRA Deprecations in the following class: CoordinatorClient - multiple methods Headers More information in the following Task . MP Messaging Deprecations in the following class: MessagingCdiExtension - Alternative methods used More information in the following Task . JWT Deprecations in the following class: Jwt - Audience can be a list (since 2.4.0) More information in the following Task . MP Metrics Deprecations in the following class: MetricUtil - multiple methods MetricsCdiExtension - multiple methods More information in the following Task . HTTP Signature Security Provider backwardCompatibleEol - set to false More information in the following Task . Service Common Deprecations in the following class: HelidonRestServiceSupport - method configureEndpoint(Rules) More information in the following Task . WebServer Static content support in WebServer - moved to a separate module. Fully removed from WebServer module. More information in the following Task . ",
            "title": "Deprecations"
        },
        {
            "location": "/se/guides/upgrade_4x",
            "text": " In Helidon 4.x we have made some major changes to Helidon. Reactive engine has been removed. APIS and implementations are rewritten in \"blocking\" paradigm. This guide will help you upgrade a Helidon MP 3.x application to 4.x. ",
            "title": "preambule"
        },
        {
            "location": "/se/guides/upgrade_4x",
            "text": " Java 17 is no longer supported in Helidon 4. Java 21 or newer is required. Please follow the instructions in Prerequisites for proper installation. Helidon 4 no longer uses Netty. Helidon SE is now running on Helidon WebServer which is based on virtual threads technology, available in Java 21. ",
            "title": "Java 21 Runtime"
        },
        {
            "location": "/se/guides/upgrade_4x",
            "text": " Helidon SE has changed from an asynchronous style API to an imperative/blocking style API that is optimized for use with virtual threads. Currently, there is no compatibility API available ",
            "title": "Programming paradigm"
        },
        {
            "location": "/se/guides/upgrade_4x",
            "text": " In Helidon 1.x-3.x you started a server like this: <markup lang=\"java\" title=\"Start Helidon SE 3.x Server\" >static Single&lt;WebServer&gt; startServer() { Config config = Config.create(); WebServer server = WebServer.builder(createRouting(config)) .config(config.get(\"server\")) .addMediaSupport(JsonpSupport.create()) .build(); Single&lt;WebServer&gt; webserver = server.start(); webserver.thenAccept(ws -&gt; { System.out.println(\"WEB server is up! http://localhost:\" + ws.port() + \"/greet\"); ws.whenShutdown().thenRun(() -&gt; System.out.println(\"WEB server is DOWN. Good bye!\")); }) .exceptionallyAccept(t -&gt; { System.err.println(\"Startup failed: \" + t.getMessage()); t.printStackTrace(System.err); }); return webserver; } Server is started in an asynchronous way. A Single object is returned. Wait for the Server to start and print the message in an asynchronous way. Gracefully handle exceptions if they occur during the initialization process. Since Helidon SE in 3.x was reactive, during the start a Single object is returned, the server has been started in asynchronous way. We have to use reactive methods like thenAccept to wait for the server to start and then to perform the desired action. The exception handling should also be done in reactive way using the corresponding method. In Helidon 4.x asynchronous programming is no longer required so the server startup is much simpler: <markup lang=\"java\" title=\"Start Helidon SE 4.x Server\" >public static void main(String[] args) { Config config = Config.create(); Config.global(config); WebServer server = WebServer.builder() .config(config.get(\"server\")) .routing(Main::routing) .build() .start(); System.out.println(\"WEB server is up! http://localhost:\" + server.port() + \"/greet\"); } Configure the Server. Start the Server. No reactive objects returned. Print a message when the Server is started. Just create it, configure it, and wait for it to start. If any exceptions happen, they are handled the traditional way using available language constructions. ",
            "title": "Server Initialization and Start Up"
        },
        {
            "location": "/se/guides/upgrade_4x",
            "text": " In previous versions of Helidon you had to explicitly register WebServer features ( register(MetricsSupport.create()) ) and explicitly add media support ( addMediaSupport(JsonpSupport.create()) ). In Helidon 4 the default behavior is to automatically discover these components from the classpath. So all you need to do is add the dependencies to your pom.xml and optionally add configuration to customize them. If you want full control using the API, you still have that option. For more information see: Observability feature support Media types support ",
            "title": "Server Features and Media Support Discovery"
        },
        {
            "location": "/se/guides/upgrade_4x",
            "text": " In Helidon 1.x-3.x the routing config was done the following way: <markup lang=\"java\" title=\"Routing in Helidon SE 3.x Server\" >private static Routing createRouting(Config config) { MetricsSupport metrics = MetricsSupport.create(); HealthSupport health = HealthSupport.builder() .addLiveness(HealthChecks.healthChecks()) .build(); GreetService greetService = new GreetService(config); return Routing.builder() .register(health) .register(metrics) .register(\"/greet\", greetService) .build(); } Create and configure Metrics and Heath support. Create a regular Helidon Service. Register Metrics and Heath support as Helidon Services. Register the regular Greeting service. Services are created and assigned to the desired path. Observability and other features are being created as usual Helidon services , available as part of the framework. User-defined services are also registered the same way. In Helidon 4, the routing is configured the following way: <markup lang=\"java\" title=\"Start Helidon SE 4.x Server\" >static void routing(HttpRouting.Builder routing) { routing.register(\"/greet\", new GreetService()); } Register Greeting service as in previous versions of Helidon. As described previously, the Metrics and Health features will be discovered automatically as long as you have added the dependencies for them to your project. If you wanteded to add these features to the server programatically you would do so using WebServer.builder().addFeature() method. Feature encapsulates a set of endpoints, services and/or filters. It is similar to HttpService but gives more freedom in setup. Main difference is that a feature can add Filters and it cannot be registered on a path. Features are not registered immediately—each feature can define a Weight or implement Weighted to order features according to their weight. Higher-weighted features are registered first. This is to allow ordering of features in a meaningful way (e.g. Context should be first, Tracing second, Security third etc.). ",
            "title": "Routing Configuration"
        },
        {
            "location": "/se/guides/upgrade_4x",
            "text": " Media support has moved from the io.helidon.media Java package to io.helidon.http.media and has new dependency coordinates. For example: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.http.media&lt;/groupId&gt; &lt;artifactId&gt;helidon-http-media-jsonp&lt;/artifactId&gt; &lt;/dependency&gt; In Helidon 4 media support is discovered by default, so you simple need to add the dependency. You no longer need to explicitly add media support using the WebServer builder. Media support no long transitively brings the Jakarta API dependencies. So you might need to add these explicitly. For example: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;jakarta.json&lt;/groupId&gt; &lt;artifactId&gt;jakarta.json-api&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Media Support"
        },
        {
            "location": "/se/guides/upgrade_4x",
            "text": " There is a new testing framework for Helidon SE. <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.testing&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-testing-junit5&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; Find more information, see Helidon SE testing ",
            "title": "Testing"
        },
        {
            "location": "/se/guides/upgrade_4x",
            "text": " Observability features of Helidon have now moved to different package. For Health and Metrics please use: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webserver.observe&lt;/groupId&gt; &lt;artifactId&gt;helidon-webserver-observe-health&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.webserver.observe&lt;/groupId&gt; &lt;artifactId&gt;helidon-webserver-observe-metrics&lt;/artifactId&gt; &lt;/dependency&gt; Observability has new endpoints. See them here . For System Metrics, please use: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics-system-meters&lt;/artifactId&gt; &lt;/dependency&gt; By default Observability features are discovered automatically if you add the above dependencies. If you choose to add them programmatically (using addFeature ) you will need to add the following dependency: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webserver.observe&lt;/groupId&gt; &lt;artifactId&gt;helidon-webserver-observe&lt;/artifactId&gt; &lt;/dependency&gt; Metrics has changed significantly in Helidon 4. See Helidon SE Metrics for more information. ",
            "title": "Observability"
        },
        {
            "location": "/se/guides/upgrade_4x",
            "text": " Changed modules: helidon-security-integration-jersey moved to the module helidon-microprofile-security helidon-security-integration-jersey-client moved to the module helidon-microprofile-security helidon-security-integration-grpc was removed helidon-security-integration-webserver moved to the module helidon-webserver-security Significant class name changes: OidcSupport renamed to OidcFeature WebSecurity renamed to SecurityFeature Other: SynchronousProvider removed - SynchronousProvider usage is no longer needed, since all security providers are synchronous. ",
            "title": "Security"
        },
        {
            "location": "/se/guides/upgrade_4x",
            "text": " Media Support Media support has moved from the io.helidon.media Java package to io.helidon.http.media and has new dependency coordinates. For example: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.http.media&lt;/groupId&gt; &lt;artifactId&gt;helidon-http-media-jsonp&lt;/artifactId&gt; &lt;/dependency&gt; In Helidon 4 media support is discovered by default, so you simple need to add the dependency. You no longer need to explicitly add media support using the WebServer builder. Media support no long transitively brings the Jakarta API dependencies. So you might need to add these explicitly. For example: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;jakarta.json&lt;/groupId&gt; &lt;artifactId&gt;jakarta.json-api&lt;/artifactId&gt; &lt;/dependency&gt; Testing There is a new testing framework for Helidon SE. <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.testing&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-testing-junit5&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; Find more information, see Helidon SE testing Observability Observability features of Helidon have now moved to different package. For Health and Metrics please use: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webserver.observe&lt;/groupId&gt; &lt;artifactId&gt;helidon-webserver-observe-health&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.webserver.observe&lt;/groupId&gt; &lt;artifactId&gt;helidon-webserver-observe-metrics&lt;/artifactId&gt; &lt;/dependency&gt; Observability has new endpoints. See them here . For System Metrics, please use: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics-system-meters&lt;/artifactId&gt; &lt;/dependency&gt; By default Observability features are discovered automatically if you add the above dependencies. If you choose to add them programmatically (using addFeature ) you will need to add the following dependency: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webserver.observe&lt;/groupId&gt; &lt;artifactId&gt;helidon-webserver-observe&lt;/artifactId&gt; &lt;/dependency&gt; Metrics has changed significantly in Helidon 4. See Helidon SE Metrics for more information. Security Changed modules: helidon-security-integration-jersey moved to the module helidon-microprofile-security helidon-security-integration-jersey-client moved to the module helidon-microprofile-security helidon-security-integration-grpc was removed helidon-security-integration-webserver moved to the module helidon-webserver-security Significant class name changes: OidcSupport renamed to OidcFeature WebSecurity renamed to SecurityFeature Other: SynchronousProvider removed - SynchronousProvider usage is no longer needed, since all security providers are synchronous. ",
            "title": "Other Significant Changes"
        },
        {
            "location": "/se/guides/upgrade_4x",
            "text": " The global configuration represents a single instance of the Config class, which is implicitly employed by certain Helidon components. Furthermore, it offers a handy approach for your application to access configuration information from any part of your code. It is recommended that you explicitly initialize global configuration before using any Helidon components: <markup >Config config = Config.create(); // Uses default config sources Config.global(config); You can then utilize the global configuration for easy retrieval of your application&#8217;s configuration: <markup >Config config = Config.global(); More information at Helidon SE Config . ",
            "title": "Global Configuration"
        },
        {
            "location": "/se/guides/upgrade_4x",
            "text": " The class LogConfig has moved to the io.helidon.logging.common Java package. The Helidon console handler has changed from io.helidon.common.HelidonConsoleHandler to io.helidon.logging.jul.HelidonConsoleHandler . If you use this handler in your logging.properties you will need to update it and add the following dependency: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.logging&lt;/groupId&gt; &lt;artifactId&gt;helidon-logging-jul&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; ",
            "title": "Logging"
        },
        {
            "location": "/se/guides/upgrade_4x",
            "text": " There are also significant changes in Helidon Service . In prior versions, a service looks this way: <markup lang=\"java\" title=\"Helidon SE 3.x Service\" >public class GreetService implements Service { @Override public void update(Routing.Rules rules) { rules .get(\"/\", this::getDefaultMessageHandler) .get(\"/{name}\", this::getMessageHandler) .put(\"/greeting\", this::updateGreetingHandler); } private void getDefaultMessageHandler(ServerRequest request, ServerResponse response) { sendResponse(response, \"World\"); } // other methods omitted } Use update() method to set up routing. Handle a Request and return a Responce . In Helidon 4, the same service: <markup lang=\"java\" title=\"Helidon SE 4.x Service\" >public class GreetService implements HttpService { @Override public void routing(HttpRules rules) { rules.get(\"/\", this::getDefaultMessageHandler) .get(\"/{name}\", this::getMessageHandler) .put(\"/greeting\", this::updateGreetingHandler); } private void getDefaultMessageHandler(ServerRequest request, ServerResponse response) { sendResponse(response, \"World\"); } // other methods omitted } Implement HttpService for the GreetingService . Use routing(HttpRules rules) to set up routing. Handle a Request and return a Responce . Helidon 4 introduced HttpService that should be implemented in order to process HTTP requests. To set up routing, the method routing(HttpRules rules) should now be used. It receives HttpRules object with routes description. ServerRequest and ServerResponse are now in the io.helidon.webserver.http package; Http.Status is now io.helidon.http.Status These changes make Helidon 4 incompatible with previous versions. Learn more about HttpService and Routing at Helidon SE WebServer Other Significant Changes Media Support Media support has moved from the io.helidon.media Java package to io.helidon.http.media and has new dependency coordinates. For example: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.http.media&lt;/groupId&gt; &lt;artifactId&gt;helidon-http-media-jsonp&lt;/artifactId&gt; &lt;/dependency&gt; In Helidon 4 media support is discovered by default, so you simple need to add the dependency. You no longer need to explicitly add media support using the WebServer builder. Media support no long transitively brings the Jakarta API dependencies. So you might need to add these explicitly. For example: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;jakarta.json&lt;/groupId&gt; &lt;artifactId&gt;jakarta.json-api&lt;/artifactId&gt; &lt;/dependency&gt; Testing There is a new testing framework for Helidon SE. <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.testing&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-testing-junit5&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; Find more information, see Helidon SE testing Observability Observability features of Helidon have now moved to different package. For Health and Metrics please use: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webserver.observe&lt;/groupId&gt; &lt;artifactId&gt;helidon-webserver-observe-health&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.webserver.observe&lt;/groupId&gt; &lt;artifactId&gt;helidon-webserver-observe-metrics&lt;/artifactId&gt; &lt;/dependency&gt; Observability has new endpoints. See them here . For System Metrics, please use: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics-system-meters&lt;/artifactId&gt; &lt;/dependency&gt; By default Observability features are discovered automatically if you add the above dependencies. If you choose to add them programmatically (using addFeature ) you will need to add the following dependency: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webserver.observe&lt;/groupId&gt; &lt;artifactId&gt;helidon-webserver-observe&lt;/artifactId&gt; &lt;/dependency&gt; Metrics has changed significantly in Helidon 4. See Helidon SE Metrics for more information. Security Changed modules: helidon-security-integration-jersey moved to the module helidon-microprofile-security helidon-security-integration-jersey-client moved to the module helidon-microprofile-security helidon-security-integration-grpc was removed helidon-security-integration-webserver moved to the module helidon-webserver-security Significant class name changes: OidcSupport renamed to OidcFeature WebSecurity renamed to SecurityFeature Other: SynchronousProvider removed - SynchronousProvider usage is no longer needed, since all security providers are synchronous. Global Configuration The global configuration represents a single instance of the Config class, which is implicitly employed by certain Helidon components. Furthermore, it offers a handy approach for your application to access configuration information from any part of your code. It is recommended that you explicitly initialize global configuration before using any Helidon components: <markup >Config config = Config.create(); // Uses default config sources Config.global(config); You can then utilize the global configuration for easy retrieval of your application&#8217;s configuration: <markup >Config config = Config.global(); More information at Helidon SE Config . Logging The class LogConfig has moved to the io.helidon.logging.common Java package. The Helidon console handler has changed from io.helidon.common.HelidonConsoleHandler to io.helidon.logging.jul.HelidonConsoleHandler . If you use this handler in your logging.properties you will need to update it and add the following dependency: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.logging&lt;/groupId&gt; &lt;artifactId&gt;helidon-logging-jul&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; ",
            "title": "Services"
        },
        {
            "location": "/se/guides/upgrade_4x",
            "text": " Please proceed to Helidon SE Introduction to find more information and documentation about each module. Also, the Helidon examples are a good resource for seeing how things are done in Helidon 4. ",
            "title": "Conclusion"
        },
        {
            "location": "/se/guides/webclient",
            "text": " This guide describes how to create a sample Helidon SE project that can be used to run some basic examples using WebClient. ",
            "title": "preambule"
        },
        {
            "location": "/se/guides/webclient",
            "text": " Helidon&#8217;s WebClient is used to perform HTTP REST requests to target endpoints and handle their responses. Note : WebClient is still experimental and not intended for production use. APIs and features are not yet fully tested and are subject to change. WebClient provides the following features: User-friendly : Every client and request is created by a builder pattern, so it improves readability and code maintenance. Following redirects : The WebClient is able to follow the redirect chain and perform requests on the correct endpoint for you. You no longer have to point your client to the correct/final endpoint. Tracing, metrics and security propagation : When you configure the Helidon WebServer to use tracing, metrics and security, the settings are automatically propagated to the WebClient and used during request/response. For more information about the WebClient , please refer to the WebClient Introduction . ",
            "title": "WebClient Features"
        },
        {
            "location": "/se/guides/webclient",
            "text": " Generate the project sources using the Helidon SE Maven archetype. The result is a simple project that can be used for the examples in this guide. <markup lang=\"bash\" title=\"Run the Maven archetype:\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-se \\ -DarchetypeVersion=4.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-se \\ -Dpackage=io.helidon.examples.quickstart.se You should now have a directory called helidon-quickstart-se . <markup lang=\"bash\" title=\"Open this directory\" >cd helidon-quickstart-se The Helidon quickstart is a greeting application supporting several HTTP requests such as GET and PUT. Using it will be time-saving for this exercise as it will allow us to modify the project to demonstrate some of the Webclient features and usability, rather than start from scratch. ",
            "title": "Create a sample SE project"
        },
        {
            "location": "/se/guides/webclient",
            "text": " In io.helidon.examples.quickstart.se package, create a new class named ClientExample. This class will use the WebClient to send request to the greeting application. <markup lang=\"java\" title=\"Create ClientExample class:\" >package io.helidon.examples.quickstart.se; public class ClientExample { public static void main(String[] args) { } } Add the following code to create a WebClient instance. The builder approach allows you to create the WebClient with specific settings and improves the readability and simplicity of the code. <markup lang=\"java\" title=\"Add WebClient instance to the main method:\" >import io.helidon.http.media.jsonp.JsonpSupport; import io.helidon.webclient.WebClient; WebClient webClient = WebClient.builder() .baseUri(\"http://localhost:8080\") .build(); The base URI of the outbound requests. By default, the Helidon quickstart application runs on localhost:8080. If for some reason the host name or port number of the quickstart application is changed, make sure that the baseURI is also modified to reflect that change. Once built, the WebClient can be used to send a GET request to the greeting application. <markup lang=\"java\" title=\"Send a GET request to the target endpoint:\" >ClientResponseTyped&lt;String&gt; response = webClient.get() .path(\"/greet\") .request(String.class); String entityString = response.entity(); System.out.println(entityString); Create a HTTP GET request. Target endpoint path. Execute the request Return response entity handled as a String. The path method appends /greet to the WebClient base URI which results to the request URI becoming http://localhost:8080/greet . The received response entity will be a greeting message and will be automatically handled as a String. If no specific type is set in the method request(), HttpClientResponse will be returned by default. This HttpClientResponse object contains response code, headers and entity. ",
            "title": "Add ClientExample class"
        },
        {
            "location": "/se/guides/webclient",
            "text": "<markup lang=\"bash\" title=\"Build the quickstart:\" >mvn package This command will create helidon-quickstart-se.jar in the target folder. <markup lang=\"bash\" title=\"Run the greeting application:\" >java -cp target/helidon-quickstart-se.jar io.helidon.examples.quickstart.se.Main Open a new command prompt or terminal and run the ClientExample class you just created. <markup lang=\"bash\" title=\"Run the client application:\" >java -cp target/helidon-quickstart-se.jar io.helidon.examples.quickstart.se.ClientExample <markup lang=\"bash\" title=\"Output:\" >{\"message\":\"Hello World!\"} When the ClientExample finishes its execution, you can stop the Main class by pressing CTRL+C . ",
            "title": "Run the application"
        },
        {
            "location": "/se/guides/webclient",
            "text": " In practice, String is not the most useful return type, since it usually needs some more handling. In this case, it could be more interesting to return an object of another type like a JSON object. One way to process a JSON object is by enabling Helidon&#8217;s built-in JSON-P support and this can be simply achieved by adding its dependency in the project&#8217;s pom.xml: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.http.media&lt;/groupId&gt; &lt;artifactId&gt;helidon-http-media-jsonp&lt;/artifactId&gt; &lt;/dependency&gt; Once the dependency is added, the feature will be automatically loaded as a service allowing the response methods to easily parse the JSON object. <markup lang=\"java\" title=\"Replace String by JsonObject:\" >import javax.json.JsonObject; ClientResponseTyped&lt;JsonObject&gt; response = webClient.get() .path(\"/greet/David\") .request(JsonObject.class); String value = response.entity().getString(\"message\"); System.out.println(value); Request a JsonObject as return value. Extract the value of the JsonObject with name of message . In the URI, the String value following greet is a path parameter which allows the application to greet someone. <markup lang=\"bash\" title=\"Output:\" >Hello David! It is also possible to change the greeting word by using a PUT request to /greet/greeting path. The request also needs to include a body with JSON type and using a structure like {\"greeting\" : \"value\"} . <markup lang=\"java\" title=\"Modify the application greeting:\" >import javax.json.Json; JsonObject entity = Json.createObjectBuilder() .add(\"greeting\", \"Bonjour\") .build(); webClient.put() .path(\"/greet/greeting\") .submit(entity); ClientResponseTyped&lt;JsonObject&gt; response = webClient.get() .path(\"/greet/David\") .request(JsonObject.class); String entityString = response.entity().getString(\"message\"); System.out.println(entityString); Create a JsonObject with key greeting and value bonjour . Create a PUT request. Submit the JsonObject created earlier. Execute a GET call to verify that the greeting has been changed. Retrieve the greeting message from the JSON object Executing the above code will yield this output showing that the greeting word has been changed. <markup lang=\"bash\" title=\"Output:\" >Bonjour David! ",
            "title": "Discover other WebClient functionality"
        },
        {
            "location": "/se/guides/webclient",
            "text": " Create a sample SE project Generate the project sources using the Helidon SE Maven archetype. The result is a simple project that can be used for the examples in this guide. <markup lang=\"bash\" title=\"Run the Maven archetype:\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-se \\ -DarchetypeVersion=4.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-se \\ -Dpackage=io.helidon.examples.quickstart.se You should now have a directory called helidon-quickstart-se . <markup lang=\"bash\" title=\"Open this directory\" >cd helidon-quickstart-se The Helidon quickstart is a greeting application supporting several HTTP requests such as GET and PUT. Using it will be time-saving for this exercise as it will allow us to modify the project to demonstrate some of the Webclient features and usability, rather than start from scratch. Add ClientExample class In io.helidon.examples.quickstart.se package, create a new class named ClientExample. This class will use the WebClient to send request to the greeting application. <markup lang=\"java\" title=\"Create ClientExample class:\" >package io.helidon.examples.quickstart.se; public class ClientExample { public static void main(String[] args) { } } Add the following code to create a WebClient instance. The builder approach allows you to create the WebClient with specific settings and improves the readability and simplicity of the code. <markup lang=\"java\" title=\"Add WebClient instance to the main method:\" >import io.helidon.http.media.jsonp.JsonpSupport; import io.helidon.webclient.WebClient; WebClient webClient = WebClient.builder() .baseUri(\"http://localhost:8080\") .build(); The base URI of the outbound requests. By default, the Helidon quickstart application runs on localhost:8080. If for some reason the host name or port number of the quickstart application is changed, make sure that the baseURI is also modified to reflect that change. Once built, the WebClient can be used to send a GET request to the greeting application. <markup lang=\"java\" title=\"Send a GET request to the target endpoint:\" >ClientResponseTyped&lt;String&gt; response = webClient.get() .path(\"/greet\") .request(String.class); String entityString = response.entity(); System.out.println(entityString); Create a HTTP GET request. Target endpoint path. Execute the request Return response entity handled as a String. The path method appends /greet to the WebClient base URI which results to the request URI becoming http://localhost:8080/greet . The received response entity will be a greeting message and will be automatically handled as a String. If no specific type is set in the method request(), HttpClientResponse will be returned by default. This HttpClientResponse object contains response code, headers and entity. Run the application <markup lang=\"bash\" title=\"Build the quickstart:\" >mvn package This command will create helidon-quickstart-se.jar in the target folder. <markup lang=\"bash\" title=\"Run the greeting application:\" >java -cp target/helidon-quickstart-se.jar io.helidon.examples.quickstart.se.Main Open a new command prompt or terminal and run the ClientExample class you just created. <markup lang=\"bash\" title=\"Run the client application:\" >java -cp target/helidon-quickstart-se.jar io.helidon.examples.quickstart.se.ClientExample <markup lang=\"bash\" title=\"Output:\" >{\"message\":\"Hello World!\"} When the ClientExample finishes its execution, you can stop the Main class by pressing CTRL+C . Discover other WebClient functionality In practice, String is not the most useful return type, since it usually needs some more handling. In this case, it could be more interesting to return an object of another type like a JSON object. One way to process a JSON object is by enabling Helidon&#8217;s built-in JSON-P support and this can be simply achieved by adding its dependency in the project&#8217;s pom.xml: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.http.media&lt;/groupId&gt; &lt;artifactId&gt;helidon-http-media-jsonp&lt;/artifactId&gt; &lt;/dependency&gt; Once the dependency is added, the feature will be automatically loaded as a service allowing the response methods to easily parse the JSON object. <markup lang=\"java\" title=\"Replace String by JsonObject:\" >import javax.json.JsonObject; ClientResponseTyped&lt;JsonObject&gt; response = webClient.get() .path(\"/greet/David\") .request(JsonObject.class); String value = response.entity().getString(\"message\"); System.out.println(value); Request a JsonObject as return value. Extract the value of the JsonObject with name of message . In the URI, the String value following greet is a path parameter which allows the application to greet someone. <markup lang=\"bash\" title=\"Output:\" >Hello David! It is also possible to change the greeting word by using a PUT request to /greet/greeting path. The request also needs to include a body with JSON type and using a structure like {\"greeting\" : \"value\"} . <markup lang=\"java\" title=\"Modify the application greeting:\" >import javax.json.Json; JsonObject entity = Json.createObjectBuilder() .add(\"greeting\", \"Bonjour\") .build(); webClient.put() .path(\"/greet/greeting\") .submit(entity); ClientResponseTyped&lt;JsonObject&gt; response = webClient.get() .path(\"/greet/David\") .request(JsonObject.class); String entityString = response.entity().getString(\"message\"); System.out.println(entityString); Create a JsonObject with key greeting and value bonjour . Create a PUT request. Submit the JsonObject created earlier. Execute a GET call to verify that the greeting has been changed. Retrieve the greeting message from the JSON object Executing the above code will yield this output showing that the greeting word has been changed. <markup lang=\"bash\" title=\"Output:\" >Bonjour David! ",
            "title": "WebClient Usage"
        },
        {
            "location": "/se/guides/webclient",
            "text": " To enable support for this feature, the helidon-webclient-metrics dependency needs to be added . <markup lang=\"xml\" title=\"Add the following dependency to pom.xml:\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-webclient-metrics&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Add metrics dependency"
        },
        {
            "location": "/se/guides/webclient",
            "text": " Metrics can be registered on the WebClient directly. The following example shows how a Counter metric can be defined, created and monitored. <markup lang=\"java\" title=\"Example of metric creation:\" >import io.helidon.http.Method; import io.helidon.metrics.api.Counter; import io.helidon.metrics.api.MeterRegistry; import io.helidon.metrics.api.Metrics; import io.helidon.webclient.api.ClientResponseTyped; import io.helidon.webclient.api.WebClient; import io.helidon.webclient.metrics.WebClientMetrics; import io.helidon.webclient.spi.WebClientService; public class ClientExample { public static void main(String[] args) { final MeterRegistry METER_REGISTRY = Metrics.globalRegistry(); String metricName = \"counter.GET.localhost\"; Counter counter = METER_REGISTRY.getOrCreate(Counter.builder(metricName)); System.out.println(metricName + \": \" + counter.count()); WebClientService clientServiceMetric = WebClientMetrics.counter() .methods(Method.GET) // OPTIONAL .success(true) // OPTIONAL .errors(true) // OPTIONAL .description(\"Metric Description\") // OPTIONAL .nameFormat(\"counter.%1$s.%2$s\") .build(); Specify the metric name. From the MeterRegistry , create a Counter metric using the specified metric name. Specify how the name of the metric will be generated using the nameFormat . Build a WebClient Metric Service that can count number of GET requests made. In this example, the metric uses a Counter to measure the number of GET requests executed on the localhost . The format strings in the parameter value of nameFormat method will identify how the name of a metric will get generated: %1$s = Request method %2$s = Request host %3$s = Response status So for example, if the nameFormat value is metric.%1$s.%2$s.%3$s and a request uses a GET method, targeting a URL with localhost as the hostname, and got a response code of 200, that the final metric will get created with a name of metric.GET.localhost.200. To register the metric service, simply use the addService method and pass in the created WebClient Metric Service as a parameter. <markup lang=\"java\" title=\"Add the metric service to the WebClient:\" > WebClient webClient = WebClient.builder() .baseUri(\"http://localhost:8080\") .addService(clientServiceMetric) .build(); webClient.get().path(\"/greet\").request(); Register the metric service to the webclient. Send an HTTP GET request To verify that the metric is set up correctly, print the value of the Counter at the end of the main method. <markup lang=\"java\" title=\"Print the metric count\" > System.out.println(metricName + \": \" + counter.count()); This will result to an output showing that a metric with the name of counter.GET.localhost was created with a count value of 1 indicating that it correctly measured the request that was just made. <markup lang=\"bash\" title=\"Output:\" >counter.GET.localhost: 1 ",
            "title": "Set up metrics on WebClient instance"
        },
        {
            "location": "/se/guides/webclient",
            "text": " Using the configuration file can reduce the code complexity and make the metrics simpler to use. With this approach, it eliminates the need to modify the source code for scenarios where the metric settings have to be changed. The application.yaml file is the default configuration file for Helidon and can be used to set up metrics settings. <markup lang=\"yaml\" title=\"Example of metric configuration:\" >client: services: metrics: - type: COUNTER methods: [\"GET\"] description: \"Metric Description\" name-format: \"counter.%1$s.%2$s\" In the example configuration definition above, the metrics configuration are located under client.services.metrics . The metric setting can start either by its type or methods . The configuration file uses the same keywords as the programmatic way. For example, type defines the kind of metric and methods identifies the http methods that will be measured. <markup lang=\"java\" title=\"Add the metric service to the WebClient via the Configuration:\" >import io.helidon.http.Method; import io.helidon.metrics.api.Counter; import io.helidon.metrics.api.MeterRegistry; import io.helidon.metrics.api.Metrics; import io.helidon.webclient.api.WebClient; public class ClientExample { public static void main(String[] args) { final MeterRegistry METER_REGISTRY = Metrics.globalRegistry(); String counterName = \"counter.GET.localhost\"; Counter counter = METER_REGISTRY.getOrCreate(Counter.builder(counterName)); System.out.println(counterName + \": \" + counter.count()); Config config = Config.create(); WebClient webClient = WebClient.builder() .baseUri(\"http://localhost:8080\") .config(config.get(\"client\")) .build(); webClient.get().path(\"/greet\").request(); System.out.println(counterName + \": \" + counter.count()); Choose the metric name. Create counter metric from MeterRegistry . Create a Helidon Config instance from default config file application.yaml . Configure the WebClient using the client section from application.yaml . Send an HTTP GET request Print out the metric result As demonstrated, using the configuration file reduces the amount of code needed in the source code. For more information about metrics, see the Helidon Metrics Guide . ",
            "title": "Set up metrics with configuration files"
        },
        {
            "location": "/se/guides/webclient",
            "text": " WebClient, like other Helidon components, supports Metrics. The following example introduces a counter metric that can be used to measure WebClient request activity. There are two ways to set up metrics, programmatically on the WebClient instance or manually using the configuration file. Add metrics dependency To enable support for this feature, the helidon-webclient-metrics dependency needs to be added . <markup lang=\"xml\" title=\"Add the following dependency to pom.xml:\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-webclient-metrics&lt;/artifactId&gt; &lt;/dependency&gt; Set up metrics on WebClient instance Metrics can be registered on the WebClient directly. The following example shows how a Counter metric can be defined, created and monitored. <markup lang=\"java\" title=\"Example of metric creation:\" >import io.helidon.http.Method; import io.helidon.metrics.api.Counter; import io.helidon.metrics.api.MeterRegistry; import io.helidon.metrics.api.Metrics; import io.helidon.webclient.api.ClientResponseTyped; import io.helidon.webclient.api.WebClient; import io.helidon.webclient.metrics.WebClientMetrics; import io.helidon.webclient.spi.WebClientService; public class ClientExample { public static void main(String[] args) { final MeterRegistry METER_REGISTRY = Metrics.globalRegistry(); String metricName = \"counter.GET.localhost\"; Counter counter = METER_REGISTRY.getOrCreate(Counter.builder(metricName)); System.out.println(metricName + \": \" + counter.count()); WebClientService clientServiceMetric = WebClientMetrics.counter() .methods(Method.GET) // OPTIONAL .success(true) // OPTIONAL .errors(true) // OPTIONAL .description(\"Metric Description\") // OPTIONAL .nameFormat(\"counter.%1$s.%2$s\") .build(); Specify the metric name. From the MeterRegistry , create a Counter metric using the specified metric name. Specify how the name of the metric will be generated using the nameFormat . Build a WebClient Metric Service that can count number of GET requests made. In this example, the metric uses a Counter to measure the number of GET requests executed on the localhost . The format strings in the parameter value of nameFormat method will identify how the name of a metric will get generated: %1$s = Request method %2$s = Request host %3$s = Response status So for example, if the nameFormat value is metric.%1$s.%2$s.%3$s and a request uses a GET method, targeting a URL with localhost as the hostname, and got a response code of 200, that the final metric will get created with a name of metric.GET.localhost.200. To register the metric service, simply use the addService method and pass in the created WebClient Metric Service as a parameter. <markup lang=\"java\" title=\"Add the metric service to the WebClient:\" > WebClient webClient = WebClient.builder() .baseUri(\"http://localhost:8080\") .addService(clientServiceMetric) .build(); webClient.get().path(\"/greet\").request(); Register the metric service to the webclient. Send an HTTP GET request To verify that the metric is set up correctly, print the value of the Counter at the end of the main method. <markup lang=\"java\" title=\"Print the metric count\" > System.out.println(metricName + \": \" + counter.count()); This will result to an output showing that a metric with the name of counter.GET.localhost was created with a count value of 1 indicating that it correctly measured the request that was just made. <markup lang=\"bash\" title=\"Output:\" >counter.GET.localhost: 1 Set up metrics with configuration files Using the configuration file can reduce the code complexity and make the metrics simpler to use. With this approach, it eliminates the need to modify the source code for scenarios where the metric settings have to be changed. The application.yaml file is the default configuration file for Helidon and can be used to set up metrics settings. <markup lang=\"yaml\" title=\"Example of metric configuration:\" >client: services: metrics: - type: COUNTER methods: [\"GET\"] description: \"Metric Description\" name-format: \"counter.%1$s.%2$s\" In the example configuration definition above, the metrics configuration are located under client.services.metrics . The metric setting can start either by its type or methods . The configuration file uses the same keywords as the programmatic way. For example, type defines the kind of metric and methods identifies the http methods that will be measured. <markup lang=\"java\" title=\"Add the metric service to the WebClient via the Configuration:\" >import io.helidon.http.Method; import io.helidon.metrics.api.Counter; import io.helidon.metrics.api.MeterRegistry; import io.helidon.metrics.api.Metrics; import io.helidon.webclient.api.WebClient; public class ClientExample { public static void main(String[] args) { final MeterRegistry METER_REGISTRY = Metrics.globalRegistry(); String counterName = \"counter.GET.localhost\"; Counter counter = METER_REGISTRY.getOrCreate(Counter.builder(counterName)); System.out.println(counterName + \": \" + counter.count()); Config config = Config.create(); WebClient webClient = WebClient.builder() .baseUri(\"http://localhost:8080\") .config(config.get(\"client\")) .build(); webClient.get().path(\"/greet\").request(); System.out.println(counterName + \": \" + counter.count()); Choose the metric name. Create counter metric from MeterRegistry . Create a Helidon Config instance from default config file application.yaml . Configure the WebClient using the client section from application.yaml . Send an HTTP GET request Print out the metric result As demonstrated, using the configuration file reduces the amount of code needed in the source code. For more information about metrics, see the Helidon Metrics Guide . ",
            "title": "WebClient Metrics"
        },
        {
            "location": "/se/guides/webclient",
            "text": " For this 15 minute tutorial, you will need the following: <div class=\"table__overflow elevation-1 flex sm7 \"> A Helidon SE Application You can use your own application or use the Helidon SE Quickstart to create a sample application. Java&#160;SE&#160;21 ( Open&#160;JDK&#160;21 ) Helidon requires Java 21+. Maven 3.8+ Helidon requires Maven 3.8+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop . <markup lang=\"bash\" title=\"Verify Prerequisites\" >java -version mvn --version docker --version kubectl version --short <markup lang=\"bash\" title=\"Setting JAVA_HOME\" ># On Mac export JAVA_HOME=`/usr/libexec/java_home -v 21` # On Linux # Use the appropriate path to your JDK export JAVA_HOME=/usr/lib/jvm/jdk-21 WebClient features WebClient usage WebClient Metrics WebClient Features Helidon&#8217;s WebClient is used to perform HTTP REST requests to target endpoints and handle their responses. Note : WebClient is still experimental and not intended for production use. APIs and features are not yet fully tested and are subject to change. WebClient provides the following features: User-friendly : Every client and request is created by a builder pattern, so it improves readability and code maintenance. Following redirects : The WebClient is able to follow the redirect chain and perform requests on the correct endpoint for you. You no longer have to point your client to the correct/final endpoint. Tracing, metrics and security propagation : When you configure the Helidon WebServer to use tracing, metrics and security, the settings are automatically propagated to the WebClient and used during request/response. For more information about the WebClient , please refer to the WebClient Introduction . WebClient Usage Create a sample SE project Generate the project sources using the Helidon SE Maven archetype. The result is a simple project that can be used for the examples in this guide. <markup lang=\"bash\" title=\"Run the Maven archetype:\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-se \\ -DarchetypeVersion=4.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-se \\ -Dpackage=io.helidon.examples.quickstart.se You should now have a directory called helidon-quickstart-se . <markup lang=\"bash\" title=\"Open this directory\" >cd helidon-quickstart-se The Helidon quickstart is a greeting application supporting several HTTP requests such as GET and PUT. Using it will be time-saving for this exercise as it will allow us to modify the project to demonstrate some of the Webclient features and usability, rather than start from scratch. Add ClientExample class In io.helidon.examples.quickstart.se package, create a new class named ClientExample. This class will use the WebClient to send request to the greeting application. <markup lang=\"java\" title=\"Create ClientExample class:\" >package io.helidon.examples.quickstart.se; public class ClientExample { public static void main(String[] args) { } } Add the following code to create a WebClient instance. The builder approach allows you to create the WebClient with specific settings and improves the readability and simplicity of the code. <markup lang=\"java\" title=\"Add WebClient instance to the main method:\" >import io.helidon.http.media.jsonp.JsonpSupport; import io.helidon.webclient.WebClient; WebClient webClient = WebClient.builder() .baseUri(\"http://localhost:8080\") .build(); The base URI of the outbound requests. By default, the Helidon quickstart application runs on localhost:8080. If for some reason the host name or port number of the quickstart application is changed, make sure that the baseURI is also modified to reflect that change. Once built, the WebClient can be used to send a GET request to the greeting application. <markup lang=\"java\" title=\"Send a GET request to the target endpoint:\" >ClientResponseTyped&lt;String&gt; response = webClient.get() .path(\"/greet\") .request(String.class); String entityString = response.entity(); System.out.println(entityString); Create a HTTP GET request. Target endpoint path. Execute the request Return response entity handled as a String. The path method appends /greet to the WebClient base URI which results to the request URI becoming http://localhost:8080/greet . The received response entity will be a greeting message and will be automatically handled as a String. If no specific type is set in the method request(), HttpClientResponse will be returned by default. This HttpClientResponse object contains response code, headers and entity. Run the application <markup lang=\"bash\" title=\"Build the quickstart:\" >mvn package This command will create helidon-quickstart-se.jar in the target folder. <markup lang=\"bash\" title=\"Run the greeting application:\" >java -cp target/helidon-quickstart-se.jar io.helidon.examples.quickstart.se.Main Open a new command prompt or terminal and run the ClientExample class you just created. <markup lang=\"bash\" title=\"Run the client application:\" >java -cp target/helidon-quickstart-se.jar io.helidon.examples.quickstart.se.ClientExample <markup lang=\"bash\" title=\"Output:\" >{\"message\":\"Hello World!\"} When the ClientExample finishes its execution, you can stop the Main class by pressing CTRL+C . Discover other WebClient functionality In practice, String is not the most useful return type, since it usually needs some more handling. In this case, it could be more interesting to return an object of another type like a JSON object. One way to process a JSON object is by enabling Helidon&#8217;s built-in JSON-P support and this can be simply achieved by adding its dependency in the project&#8217;s pom.xml: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.http.media&lt;/groupId&gt; &lt;artifactId&gt;helidon-http-media-jsonp&lt;/artifactId&gt; &lt;/dependency&gt; Once the dependency is added, the feature will be automatically loaded as a service allowing the response methods to easily parse the JSON object. <markup lang=\"java\" title=\"Replace String by JsonObject:\" >import javax.json.JsonObject; ClientResponseTyped&lt;JsonObject&gt; response = webClient.get() .path(\"/greet/David\") .request(JsonObject.class); String value = response.entity().getString(\"message\"); System.out.println(value); Request a JsonObject as return value. Extract the value of the JsonObject with name of message . In the URI, the String value following greet is a path parameter which allows the application to greet someone. <markup lang=\"bash\" title=\"Output:\" >Hello David! It is also possible to change the greeting word by using a PUT request to /greet/greeting path. The request also needs to include a body with JSON type and using a structure like {\"greeting\" : \"value\"} . <markup lang=\"java\" title=\"Modify the application greeting:\" >import javax.json.Json; JsonObject entity = Json.createObjectBuilder() .add(\"greeting\", \"Bonjour\") .build(); webClient.put() .path(\"/greet/greeting\") .submit(entity); ClientResponseTyped&lt;JsonObject&gt; response = webClient.get() .path(\"/greet/David\") .request(JsonObject.class); String entityString = response.entity().getString(\"message\"); System.out.println(entityString); Create a JsonObject with key greeting and value bonjour . Create a PUT request. Submit the JsonObject created earlier. Execute a GET call to verify that the greeting has been changed. Retrieve the greeting message from the JSON object Executing the above code will yield this output showing that the greeting word has been changed. <markup lang=\"bash\" title=\"Output:\" >Bonjour David! WebClient Metrics WebClient, like other Helidon components, supports Metrics. The following example introduces a counter metric that can be used to measure WebClient request activity. There are two ways to set up metrics, programmatically on the WebClient instance or manually using the configuration file. Add metrics dependency To enable support for this feature, the helidon-webclient-metrics dependency needs to be added . <markup lang=\"xml\" title=\"Add the following dependency to pom.xml:\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-webclient-metrics&lt;/artifactId&gt; &lt;/dependency&gt; Set up metrics on WebClient instance Metrics can be registered on the WebClient directly. The following example shows how a Counter metric can be defined, created and monitored. <markup lang=\"java\" title=\"Example of metric creation:\" >import io.helidon.http.Method; import io.helidon.metrics.api.Counter; import io.helidon.metrics.api.MeterRegistry; import io.helidon.metrics.api.Metrics; import io.helidon.webclient.api.ClientResponseTyped; import io.helidon.webclient.api.WebClient; import io.helidon.webclient.metrics.WebClientMetrics; import io.helidon.webclient.spi.WebClientService; public class ClientExample { public static void main(String[] args) { final MeterRegistry METER_REGISTRY = Metrics.globalRegistry(); String metricName = \"counter.GET.localhost\"; Counter counter = METER_REGISTRY.getOrCreate(Counter.builder(metricName)); System.out.println(metricName + \": \" + counter.count()); WebClientService clientServiceMetric = WebClientMetrics.counter() .methods(Method.GET) // OPTIONAL .success(true) // OPTIONAL .errors(true) // OPTIONAL .description(\"Metric Description\") // OPTIONAL .nameFormat(\"counter.%1$s.%2$s\") .build(); Specify the metric name. From the MeterRegistry , create a Counter metric using the specified metric name. Specify how the name of the metric will be generated using the nameFormat . Build a WebClient Metric Service that can count number of GET requests made. In this example, the metric uses a Counter to measure the number of GET requests executed on the localhost . The format strings in the parameter value of nameFormat method will identify how the name of a metric will get generated: %1$s = Request method %2$s = Request host %3$s = Response status So for example, if the nameFormat value is metric.%1$s.%2$s.%3$s and a request uses a GET method, targeting a URL with localhost as the hostname, and got a response code of 200, that the final metric will get created with a name of metric.GET.localhost.200. To register the metric service, simply use the addService method and pass in the created WebClient Metric Service as a parameter. <markup lang=\"java\" title=\"Add the metric service to the WebClient:\" > WebClient webClient = WebClient.builder() .baseUri(\"http://localhost:8080\") .addService(clientServiceMetric) .build(); webClient.get().path(\"/greet\").request(); Register the metric service to the webclient. Send an HTTP GET request To verify that the metric is set up correctly, print the value of the Counter at the end of the main method. <markup lang=\"java\" title=\"Print the metric count\" > System.out.println(metricName + \": \" + counter.count()); This will result to an output showing that a metric with the name of counter.GET.localhost was created with a count value of 1 indicating that it correctly measured the request that was just made. <markup lang=\"bash\" title=\"Output:\" >counter.GET.localhost: 1 Set up metrics with configuration files Using the configuration file can reduce the code complexity and make the metrics simpler to use. With this approach, it eliminates the need to modify the source code for scenarios where the metric settings have to be changed. The application.yaml file is the default configuration file for Helidon and can be used to set up metrics settings. <markup lang=\"yaml\" title=\"Example of metric configuration:\" >client: services: metrics: - type: COUNTER methods: [\"GET\"] description: \"Metric Description\" name-format: \"counter.%1$s.%2$s\" In the example configuration definition above, the metrics configuration are located under client.services.metrics . The metric setting can start either by its type or methods . The configuration file uses the same keywords as the programmatic way. For example, type defines the kind of metric and methods identifies the http methods that will be measured. <markup lang=\"java\" title=\"Add the metric service to the WebClient via the Configuration:\" >import io.helidon.http.Method; import io.helidon.metrics.api.Counter; import io.helidon.metrics.api.MeterRegistry; import io.helidon.metrics.api.Metrics; import io.helidon.webclient.api.WebClient; public class ClientExample { public static void main(String[] args) { final MeterRegistry METER_REGISTRY = Metrics.globalRegistry(); String counterName = \"counter.GET.localhost\"; Counter counter = METER_REGISTRY.getOrCreate(Counter.builder(counterName)); System.out.println(counterName + \": \" + counter.count()); Config config = Config.create(); WebClient webClient = WebClient.builder() .baseUri(\"http://localhost:8080\") .config(config.get(\"client\")) .build(); webClient.get().path(\"/greet\").request(); System.out.println(counterName + \": \" + counter.count()); Choose the metric name. Create counter metric from MeterRegistry . Create a Helidon Config instance from default config file application.yaml . Configure the WebClient using the client section from application.yaml . Send an HTTP GET request Print out the metric result As demonstrated, using the configuration file reduces the amount of code needed in the source code. For more information about metrics, see the Helidon Metrics Guide . ",
            "title": "What you need"
        },
        {
            "location": "/se/health",
            "text": " Overview Maven Coordinates API Enabling Health Support Writing Custom Health Checks Kubernetes Probes Troubleshooting Probes Configuration Examples JSON Response Example Kubernetes Example Additional Information ",
            "title": "Contents"
        },
        {
            "location": "/se/health",
            "text": " It’s a good practice to monitor your microservice’s health to ensure that it is available and performs correctly. Applications implement health checks to expose health status that is collected at regular intervals by external tooling, such as orchestrators like Kubernetes. The orchestrator may then take action, such as restarting your application if the health check fails. A typical health check combines the statuses of all the dependencies that affect availability and the ability to perform correctly: Network Latency Storage Database Other Services (used by your application) ",
            "title": "Overview"
        },
        {
            "location": "/se/health",
            "text": " To enable Health Checks add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webserver.observe&lt;/groupId&gt; &lt;artifactId&gt;helidon-webserver-observe-health&lt;/artifactId&gt; &lt;/dependency&gt; Optional dependency to use built-in health checks: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.health&lt;/groupId&gt; &lt;artifactId&gt;helidon-health-checks&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/health",
            "text": " The health subsystem is part of Helidon&#8217;s observability support. As a result, your application includes health support by default provided your project meets several conditions: Your project depends on the helidon-webserver-observe-health component as described above. (Optional) Your project depends on the helidon-health-checks component (if you want Helidon&#8217;s built-in health checks). Your code allows the webserver&#8217;s automatic feature discovery (enabled by default). Your code allows the observe feature&#8217;s automatic observer discovery (also enabled by default). If you disable either type of automatic discovery you can add the observe feature to the webserver explicitly and you can add the health observer to the observe feature explicitly, customizing the behavior of each programmatically if you wish. You can also use configuration to tailor some of the behavior of the health component (such as changing the URI path from /observe/health to something else). ",
            "title": "Enabling Health Support (and Built-in Health Checks) in Your Application"
        },
        {
            "location": "/se/health",
            "text": " If you gather the logic for computing the health check response into a method, then you can use a method reference to register the health check. <markup lang=\"java\" title=\"Declaring a health check response supplier method\" >static HealthCheckResponse slowStartLivenessResponse() { long now = System.currentTimeMillis(); return HealthCheckResponse.builder() .detail(\"time\", now) .status(now - serverStartTime &gt;= 8000) .build(); } <markup lang=\"java\" title=\"Registering a health check using a method reference\" >ObserveFeature observe = ObserveFeature.builder() .config(config.get(\"server.features.observe\")) .addObserver(HealthObserver.builder() .useSystemServices(true) .addCheck(Main::slowStartLivenessResponse, HealthCheckType.LIVENESS, \"live-after-8-seconds\") .build()) .build(); Apply configuration to auto-discovered observers (e.g., health, metrics). Augment the web server by adding the ObserveFeature containing the HealthObserver . This replaces the auto-discovered health observer. Include the Helidon-supplied health checks. Add the custom health check, passing a reference to the method which returns the health check responses. Set the type of the custom health check. Set the name of the custom health check. ",
            "title": "Option 1: Using a HealthCheckResponse supplier method"
        },
        {
            "location": "/se/health",
            "text": " If the logic for computing the health check response is fairly simple, express it as an in-line lambda when you register the health check. <markup lang=\"java\" title=\"Registering a health check using an in-line lambda expression\" >ObserveFeature observe = ObserveFeature.builder() .config(config.get(\"server.features.observe\")) .addObserver(HealthObserver.builder() .useSystemServices(true) // Include Helidon-provided health checks. .addCheck(() -&gt; HealthCheckResponse.builder() .status(System.currentTimeMillis() - serverStartTime &gt;= 8000) .detail(\"time\", System.currentTimeMillis()) .build(), HealthCheckType.READINESS, \"live-after-8-seconds\") .build()) .build(); Augment the web server by adding the ObserveFeature containing the HealthObserver . Add the custom health check passing a lambda expression supplying the health check response. In the lambda, set the health check response status. Still in the lambda, set a detail associated with the health check response. Still in the lambda, build the health check response. Set the type of the custom health check. Set the name of the custom health check. Note that the logic in the lambda expression runs every time Helidon probes the added health check, so the values passed to status and detail are recomputed every time. ",
            "title": "Option 2: Using an in-line lambda expression"
        },
        {
            "location": "/se/health",
            "text": " If a custom health check requires a lot of information to compute its health check response, it might be clearest to implement it as a class that implements the HealthCheck interface. Your code instantiates the class with all the information, including references to other data, it might need to compute the response each time Helidon probes it. This example is not complicated in that way but it&#8217;s useful to illustrate this technique of writing a custom health check. <markup lang=\"java\" title=\"Declaring a concrete HealthCheck implementation\" >/** * A custom readiness health check that reports UP 8 seconds after server start-up. */ class SlowStartHealthCheck implements HealthCheck { @Override public HealthCheckType type() { return HealthCheckType.READINESS; } @Override public HealthCheckResponse call() { long now = System.currentTimeMillis(); return HealthCheckResponse.builder() .detail(\"time\", now) .status(now - serverStartTime &gt;= 8000) .build(); } } Implement the io.helidon.health.HealthCheck interface. The default health check name is the simple class name of the implementing class. Your code can override the name() method to return a different name. (Not shown in this example) The default health check type is LIVENESS so this implementation overrides type() to declare a READINESS check. Sets a detail value time associated with the response to the current time. Reports DOWN until at least eight seconds have passed since the server start-up, then reports UP thereafter. <markup lang=\"java\" title=\"Registering a HealthCheck instance\" >ObserveFeature observe = ObserveFeature.builder() .config(config.get(\"server.features.observe\")) .addObserver(HealthObserver.builder() .addCheck(new SlowStartHealthCheck()) .build()) .build(); Augment the web server by adding the ObserveFeature containing the HealthObserver . Instantiate the custom health check class and add the instance to the HealthObserver . ",
            "title": "Option 3: Using a HealthCheck Instance"
        },
        {
            "location": "/se/health",
            "text": " The code examples above prepare the observe feature instance using the built-in and custom health checks. To activate the health subsystem and other auto-discovered observability subsystems, add that observe instance as a feature to the webserver and start the server. <markup lang=\"java\" title=\"Register the observe feature with the server and start it\" >WebServer server = WebServer.builder() .featuresDiscoverServices(false) .addFeature(observe) .routing(Main::routing) .build() .start(); Add the previously-prepared health observer to the server as a feature ",
            "title": "Adding Observability (including the Custom Health Checks) to Helidon"
        },
        {
            "location": "/se/health",
            "text": " Health support in Helidon is part of Helidon&#8217;s observability feature. HealthObserver is a Helidon-provided observability implementation that contains a collection of registered HealthCheck instances and, when queried, invokes the registered health checks and returns a response with a status code representing the overall status of the application. Health status codes <div class=\"table__overflow elevation-1 flex sm7 \"> 200 The application is healthy (with health check details in the response). 204 The application is healthy (with no health check details in the response). 503 The application is not healthy. 500 An error occurred while reporting the health. You control, either using configuration or adding code to your application, whether the HTTP responses to GET requests contain detailed information about each health check. With details enabled, HTTP GET responses include JSON content showing the detailed results of all the health checks which the server executed after receiving the request. With details disabled, HTTP GET responses have no payload. HTTP HEAD requests always return only the status with no payload. If you add the Helidon health dependency to your pom.xml file, Helidon automatically registers the HelidonObserver service and responds to the default /observe/health endpoint. Further, if you add the built-in health checks dependency, Helidon automatically finds them and adds those checks to the HealthObserver . Below are parts of health responses which include the custom health check added in the earlier example code. This first response shows the health output within the first eight seconds after start-up. Recall that the custom health check will report DOWN during that time, so the overall health is DOWN and the HTTP response status is 503 Service Unavailable . <markup lang=\"json\" title=\"Response within 8 seconds: HTTP status 503 (not healthy)\" >{ \"status\": \"DOWN\", \"checks\": [ { \"name\": \"live-after-8-seconds\", \"status\": \"DOWN\", \"data\": { \"time\": 1701984253071 } }, ... } The next response shows the health output once the server has been running for at least eight seconds. The custom health check now reports UP so the overall health status is also UP now and the HTTP status is 200 . <markup lang=\"json\" title=\"Response after 8 seconds: HTTP status 200\" >{ \"status\": \"UP\", \"checks\": [ { \"name\": \"live-after-8-seconds\", \"status\": \"UP\", \"data\": { \"time\": 1701984258292 } }, Balance collecting a lot of information with the need to avoid overloading the application and overwhelming users. The following table provides a summary of the Health Check API classes. Health check API classes io.helidon.health.HealthCheck Java functional interface representing the logic of a single health check io.helidon.health.HealthCheckResponse Result of a health check invocation that contains a status io.helidon.webserver.observe.health.HealthObserver WebServer service that exposes /observe/health and invokes the registered health checks ",
            "title": "Triggering and Interpreting Health Check Output"
        },
        {
            "location": "/se/health",
            "text": " In many cases, the ability of your application to do its job depends on conditions known only to your application: for example, whether certain external resources such as databases are available. You can create custom health checks which reflect those conditions and add them to Helidon&#8217;s overall health assessment of your application. A health check is a Java functional interface that returns a new HealthCheckResponse instance each time Helidon queries the health check. Each health check also has a fixed name and a fixed health check type (start-up, liveness, or readiness). Your code registers a custom health check by invoking a method on Helidon-provided types in one of the following ways: Pass the name and type of the health check and a Supplier of a HealthCheckResponse such as a method reference or a lambda expression. Pass an instance of a class which implements the HealthCheck interface. Within an application different techniques might make sense for different custom health checks, depending on the complexity of the logic for computing the status for each check. The various styles are functionally equivalent; for a given custom health check choose the style which enhances the readability and clarity of your code. The examples below, in no particular order, implement the same custom health check functionality in different ways to illustrate. Option 1: Using a HealthCheckResponse supplier method If you gather the logic for computing the health check response into a method, then you can use a method reference to register the health check. <markup lang=\"java\" title=\"Declaring a health check response supplier method\" >static HealthCheckResponse slowStartLivenessResponse() { long now = System.currentTimeMillis(); return HealthCheckResponse.builder() .detail(\"time\", now) .status(now - serverStartTime &gt;= 8000) .build(); } <markup lang=\"java\" title=\"Registering a health check using a method reference\" >ObserveFeature observe = ObserveFeature.builder() .config(config.get(\"server.features.observe\")) .addObserver(HealthObserver.builder() .useSystemServices(true) .addCheck(Main::slowStartLivenessResponse, HealthCheckType.LIVENESS, \"live-after-8-seconds\") .build()) .build(); Apply configuration to auto-discovered observers (e.g., health, metrics). Augment the web server by adding the ObserveFeature containing the HealthObserver . This replaces the auto-discovered health observer. Include the Helidon-supplied health checks. Add the custom health check, passing a reference to the method which returns the health check responses. Set the type of the custom health check. Set the name of the custom health check. Option 2: Using an in-line lambda expression If the logic for computing the health check response is fairly simple, express it as an in-line lambda when you register the health check. <markup lang=\"java\" title=\"Registering a health check using an in-line lambda expression\" >ObserveFeature observe = ObserveFeature.builder() .config(config.get(\"server.features.observe\")) .addObserver(HealthObserver.builder() .useSystemServices(true) // Include Helidon-provided health checks. .addCheck(() -&gt; HealthCheckResponse.builder() .status(System.currentTimeMillis() - serverStartTime &gt;= 8000) .detail(\"time\", System.currentTimeMillis()) .build(), HealthCheckType.READINESS, \"live-after-8-seconds\") .build()) .build(); Augment the web server by adding the ObserveFeature containing the HealthObserver . Add the custom health check passing a lambda expression supplying the health check response. In the lambda, set the health check response status. Still in the lambda, set a detail associated with the health check response. Still in the lambda, build the health check response. Set the type of the custom health check. Set the name of the custom health check. Note that the logic in the lambda expression runs every time Helidon probes the added health check, so the values passed to status and detail are recomputed every time. Option 3: Using a HealthCheck Instance If a custom health check requires a lot of information to compute its health check response, it might be clearest to implement it as a class that implements the HealthCheck interface. Your code instantiates the class with all the information, including references to other data, it might need to compute the response each time Helidon probes it. This example is not complicated in that way but it&#8217;s useful to illustrate this technique of writing a custom health check. <markup lang=\"java\" title=\"Declaring a concrete HealthCheck implementation\" >/** * A custom readiness health check that reports UP 8 seconds after server start-up. */ class SlowStartHealthCheck implements HealthCheck { @Override public HealthCheckType type() { return HealthCheckType.READINESS; } @Override public HealthCheckResponse call() { long now = System.currentTimeMillis(); return HealthCheckResponse.builder() .detail(\"time\", now) .status(now - serverStartTime &gt;= 8000) .build(); } } Implement the io.helidon.health.HealthCheck interface. The default health check name is the simple class name of the implementing class. Your code can override the name() method to return a different name. (Not shown in this example) The default health check type is LIVENESS so this implementation overrides type() to declare a READINESS check. Sets a detail value time associated with the response to the current time. Reports DOWN until at least eight seconds have passed since the server start-up, then reports UP thereafter. <markup lang=\"java\" title=\"Registering a HealthCheck instance\" >ObserveFeature observe = ObserveFeature.builder() .config(config.get(\"server.features.observe\")) .addObserver(HealthObserver.builder() .addCheck(new SlowStartHealthCheck()) .build()) .build(); Augment the web server by adding the ObserveFeature containing the HealthObserver . Instantiate the custom health check class and add the instance to the HealthObserver . Adding Observability (including the Custom Health Checks) to Helidon The code examples above prepare the observe feature instance using the built-in and custom health checks. To activate the health subsystem and other auto-discovered observability subsystems, add that observe instance as a feature to the webserver and start the server. <markup lang=\"java\" title=\"Register the observe feature with the server and start it\" >WebServer server = WebServer.builder() .featuresDiscoverServices(false) .addFeature(observe) .routing(Main::routing) .build() .start(); Add the previously-prepared health observer to the server as a feature Triggering and Interpreting Health Check Output Health support in Helidon is part of Helidon&#8217;s observability feature. HealthObserver is a Helidon-provided observability implementation that contains a collection of registered HealthCheck instances and, when queried, invokes the registered health checks and returns a response with a status code representing the overall status of the application. Health status codes <div class=\"table__overflow elevation-1 flex sm7 \"> 200 The application is healthy (with health check details in the response). 204 The application is healthy (with no health check details in the response). 503 The application is not healthy. 500 An error occurred while reporting the health. You control, either using configuration or adding code to your application, whether the HTTP responses to GET requests contain detailed information about each health check. With details enabled, HTTP GET responses include JSON content showing the detailed results of all the health checks which the server executed after receiving the request. With details disabled, HTTP GET responses have no payload. HTTP HEAD requests always return only the status with no payload. If you add the Helidon health dependency to your pom.xml file, Helidon automatically registers the HelidonObserver service and responds to the default /observe/health endpoint. Further, if you add the built-in health checks dependency, Helidon automatically finds them and adds those checks to the HealthObserver . Below are parts of health responses which include the custom health check added in the earlier example code. This first response shows the health output within the first eight seconds after start-up. Recall that the custom health check will report DOWN during that time, so the overall health is DOWN and the HTTP response status is 503 Service Unavailable . <markup lang=\"json\" title=\"Response within 8 seconds: HTTP status 503 (not healthy)\" >{ \"status\": \"DOWN\", \"checks\": [ { \"name\": \"live-after-8-seconds\", \"status\": \"DOWN\", \"data\": { \"time\": 1701984253071 } }, ... } The next response shows the health output once the server has been running for at least eight seconds. The custom health check now reports UP so the overall health status is also UP now and the HTTP status is 200 . <markup lang=\"json\" title=\"Response after 8 seconds: HTTP status 200\" >{ \"status\": \"UP\", \"checks\": [ { \"name\": \"live-after-8-seconds\", \"status\": \"UP\", \"data\": { \"time\": 1701984258292 } }, Balance collecting a lot of information with the need to avoid overloading the application and overwhelming users. The following table provides a summary of the Health Check API classes. Health check API classes io.helidon.health.HealthCheck Java functional interface representing the logic of a single health check io.helidon.health.HealthCheckResponse Result of a health check invocation that contains a status io.helidon.webserver.observe.health.HealthObserver WebServer service that exposes /observe/health and invokes the registered health checks ",
            "title": "Writing Custom Health Checks"
        },
        {
            "location": "/se/health",
            "text": " You can use Helidon-provided health checks to report various common health check statuses: Built-in health check Health check name JavaDoc Config properties (within server.features.observe.observers.health ) Default config value deadlock detection deadlock DeadlockHealthCheck n/a n/a available disk space diskSpace DiskSpaceHealthCheck helidon.health.diskSpace.thresholdPercent + helidon.health.diskSpace.path 99.999 + / available heap memory heapMemory HeapMemoryHealthCheck helidon.health.heapMemory.thresholdPercent 98 Simply adding the built-in health check dependency is sufficient to register all the built-in health checks automatically. If you want to use only some of the built-in checks in your application, you can disable automatic discovery of the built-in health checks and register only the ones you want. The following code adds only selected built-in health checks to your application: <markup lang=\"java\" title=\"Adding selected built-in health checks\" >WebServer server = WebServer.builder() .config(config.get(\"server\")) .addFeature(ObserveFeature.create(HealthObserver.builder() .useSystemServices(false) .addCheck(HealthChecks.deadlockCheck()) .addCheck(hc) .details(true) .build())) .routing(Main::routing) .build() .start(); Disables automatic registration of the built-in health checks. Adds the specific built-in check(s) you want. Adds a custom check (in a previously-prepared variable hc ). You can control the thresholds for built-in health checks in either of two ways: Create the health checks individually using their builders instead of using the HealthChecks convenience class. Follow the JavaDoc links in the table above. Using configuration as explained in Configuration . ",
            "title": "Built-In Health Checks"
        },
        {
            "location": "/se/health",
            "text": " The liveness probe is used to verify the container has become unresponsive. For example, it can be used to detect deadlocks or analyze heap usage. When Kubernetes gives up on a liveness probe, the corresponding pod is restarted. The liveness probe can result in repeated restarts in certain cases. For example, if the probe is implemented to check all the dependencies strictly, then it can fail repeatedly for temporary issues. Repeated restarts can also occur if timeoutSeconds or periodSeconds is too low. We recommend the following: Avoid checking dependencies in a liveness probe. Set timeoutSeconds to avoid excessive probe failures. Acknowledge startup times with initialDelaySeconds . ",
            "title": "Liveness Probe"
        },
        {
            "location": "/se/health",
            "text": " The readiness probe is used to avoid routing requests to the pod until it is ready to accept traffic. When Kubernetes gives up on a readiness probe, the pod is not restarted, traffic is not routed to the pod anymore. In certain cases, the readiness probe can cause all the pods to be removed from service routing. For example, if the probe is implemented to check all the dependencies strictly, then it can fail repeatedly for temporary issues. This issue can also occur if timeoutSeconds or periodSeconds is too low. We recommend the following: Be conservative when checking shared dependencies. Be aggressive when checking local dependencies. Set failureThreshold according to periodSeconds in order to accommodate temporary errors. ",
            "title": "Readiness Probe"
        },
        {
            "location": "/se/health",
            "text": " The startup probe prevents Kubernetes from prematurely checking the other probes if the application takes a long time to start. Otherwise, Kubernetes might misinterpret a failed liveness or readiness probe and shut down the container when, in fact, the application is still coming up. ",
            "title": "Startup Probe"
        },
        {
            "location": "/se/health",
            "text": " Liveness Probe Readiness Probe Startup Probe Probes is the term used by Kubernetes to describe health checks for containers ( Kubernetes documentation ). There are three types of probes: liveness : Indicates whether the container is running readiness : Indicates whether the container is ready to service requests startup : Indicates whether the application in the container has started You can implement probes using the following mechanisms: Running a command inside a container Sending an HTTP request to a container Opening a TCP socket to a container A microservice exposed to HTTP traffic will typically implement both the liveness probe and the readiness probe using HTTP requests. If the microservice takes a significant time to initialize itself, you can also define a startup probe, in which case Kubernetes does not check liveness or readiness probes until the startup probe returns success. You can configure several parameters for probes. The following are the most relevant parameters: <div class=\"table__overflow elevation-1 flex sm7 \"> initialDelaySeconds Number of seconds after the container has started before liveness or readiness probes are initiated. periodSeconds Probe interval. Default to 10 seconds. Minimum value is 1. timeoutSeconds Number of seconds after which the probe times out. Defaults to 1 second. Minimum value is 1 failureThreshold Number of consecutive failures after which the probe should stop. Default: 3. Minimum: 1. Liveness Probe The liveness probe is used to verify the container has become unresponsive. For example, it can be used to detect deadlocks or analyze heap usage. When Kubernetes gives up on a liveness probe, the corresponding pod is restarted. The liveness probe can result in repeated restarts in certain cases. For example, if the probe is implemented to check all the dependencies strictly, then it can fail repeatedly for temporary issues. Repeated restarts can also occur if timeoutSeconds or periodSeconds is too low. We recommend the following: Avoid checking dependencies in a liveness probe. Set timeoutSeconds to avoid excessive probe failures. Acknowledge startup times with initialDelaySeconds . Readiness Probe The readiness probe is used to avoid routing requests to the pod until it is ready to accept traffic. When Kubernetes gives up on a readiness probe, the pod is not restarted, traffic is not routed to the pod anymore. In certain cases, the readiness probe can cause all the pods to be removed from service routing. For example, if the probe is implemented to check all the dependencies strictly, then it can fail repeatedly for temporary issues. This issue can also occur if timeoutSeconds or periodSeconds is too low. We recommend the following: Be conservative when checking shared dependencies. Be aggressive when checking local dependencies. Set failureThreshold according to periodSeconds in order to accommodate temporary errors. Startup Probe The startup probe prevents Kubernetes from prematurely checking the other probes if the application takes a long time to start. Otherwise, Kubernetes might misinterpret a failed liveness or readiness probe and shut down the container when, in fact, the application is still coming up. ",
            "title": "Kubernetes Probes"
        },
        {
            "location": "/se/health",
            "text": " Failed probes are recorded as events associated with their corresponding pods. The event message contains only the status code. <markup lang=\"bash\" title=\"Get the events of a single pod:\" >POD_NAME=$(kubectl get pod -l app=acme -o jsonpath='{.items[0].metadata.name}') kubectl get event --field-selector involvedObject.name=${POD_NAME} Get the effective pod name by filtering pods with the label app=acme . Filter the events for the pod. Create log messages in your health check implementation when setting a DOWN status. This will allow you to correlate the cause of a failed probe. ",
            "title": "Troubleshooting Probes"
        },
        {
            "location": "/se/health",
            "text": " Enabling Health Support (and Built-in Health Checks) in Your Application The health subsystem is part of Helidon&#8217;s observability support. As a result, your application includes health support by default provided your project meets several conditions: Your project depends on the helidon-webserver-observe-health component as described above. (Optional) Your project depends on the helidon-health-checks component (if you want Helidon&#8217;s built-in health checks). Your code allows the webserver&#8217;s automatic feature discovery (enabled by default). Your code allows the observe feature&#8217;s automatic observer discovery (also enabled by default). If you disable either type of automatic discovery you can add the observe feature to the webserver explicitly and you can add the health observer to the observe feature explicitly, customizing the behavior of each programmatically if you wish. You can also use configuration to tailor some of the behavior of the health component (such as changing the URI path from /observe/health to something else). Writing Custom Health Checks In many cases, the ability of your application to do its job depends on conditions known only to your application: for example, whether certain external resources such as databases are available. You can create custom health checks which reflect those conditions and add them to Helidon&#8217;s overall health assessment of your application. A health check is a Java functional interface that returns a new HealthCheckResponse instance each time Helidon queries the health check. Each health check also has a fixed name and a fixed health check type (start-up, liveness, or readiness). Your code registers a custom health check by invoking a method on Helidon-provided types in one of the following ways: Pass the name and type of the health check and a Supplier of a HealthCheckResponse such as a method reference or a lambda expression. Pass an instance of a class which implements the HealthCheck interface. Within an application different techniques might make sense for different custom health checks, depending on the complexity of the logic for computing the status for each check. The various styles are functionally equivalent; for a given custom health check choose the style which enhances the readability and clarity of your code. The examples below, in no particular order, implement the same custom health check functionality in different ways to illustrate. Option 1: Using a HealthCheckResponse supplier method If you gather the logic for computing the health check response into a method, then you can use a method reference to register the health check. <markup lang=\"java\" title=\"Declaring a health check response supplier method\" >static HealthCheckResponse slowStartLivenessResponse() { long now = System.currentTimeMillis(); return HealthCheckResponse.builder() .detail(\"time\", now) .status(now - serverStartTime &gt;= 8000) .build(); } <markup lang=\"java\" title=\"Registering a health check using a method reference\" >ObserveFeature observe = ObserveFeature.builder() .config(config.get(\"server.features.observe\")) .addObserver(HealthObserver.builder() .useSystemServices(true) .addCheck(Main::slowStartLivenessResponse, HealthCheckType.LIVENESS, \"live-after-8-seconds\") .build()) .build(); Apply configuration to auto-discovered observers (e.g., health, metrics). Augment the web server by adding the ObserveFeature containing the HealthObserver . This replaces the auto-discovered health observer. Include the Helidon-supplied health checks. Add the custom health check, passing a reference to the method which returns the health check responses. Set the type of the custom health check. Set the name of the custom health check. Option 2: Using an in-line lambda expression If the logic for computing the health check response is fairly simple, express it as an in-line lambda when you register the health check. <markup lang=\"java\" title=\"Registering a health check using an in-line lambda expression\" >ObserveFeature observe = ObserveFeature.builder() .config(config.get(\"server.features.observe\")) .addObserver(HealthObserver.builder() .useSystemServices(true) // Include Helidon-provided health checks. .addCheck(() -&gt; HealthCheckResponse.builder() .status(System.currentTimeMillis() - serverStartTime &gt;= 8000) .detail(\"time\", System.currentTimeMillis()) .build(), HealthCheckType.READINESS, \"live-after-8-seconds\") .build()) .build(); Augment the web server by adding the ObserveFeature containing the HealthObserver . Add the custom health check passing a lambda expression supplying the health check response. In the lambda, set the health check response status. Still in the lambda, set a detail associated with the health check response. Still in the lambda, build the health check response. Set the type of the custom health check. Set the name of the custom health check. Note that the logic in the lambda expression runs every time Helidon probes the added health check, so the values passed to status and detail are recomputed every time. Option 3: Using a HealthCheck Instance If a custom health check requires a lot of information to compute its health check response, it might be clearest to implement it as a class that implements the HealthCheck interface. Your code instantiates the class with all the information, including references to other data, it might need to compute the response each time Helidon probes it. This example is not complicated in that way but it&#8217;s useful to illustrate this technique of writing a custom health check. <markup lang=\"java\" title=\"Declaring a concrete HealthCheck implementation\" >/** * A custom readiness health check that reports UP 8 seconds after server start-up. */ class SlowStartHealthCheck implements HealthCheck { @Override public HealthCheckType type() { return HealthCheckType.READINESS; } @Override public HealthCheckResponse call() { long now = System.currentTimeMillis(); return HealthCheckResponse.builder() .detail(\"time\", now) .status(now - serverStartTime &gt;= 8000) .build(); } } Implement the io.helidon.health.HealthCheck interface. The default health check name is the simple class name of the implementing class. Your code can override the name() method to return a different name. (Not shown in this example) The default health check type is LIVENESS so this implementation overrides type() to declare a READINESS check. Sets a detail value time associated with the response to the current time. Reports DOWN until at least eight seconds have passed since the server start-up, then reports UP thereafter. <markup lang=\"java\" title=\"Registering a HealthCheck instance\" >ObserveFeature observe = ObserveFeature.builder() .config(config.get(\"server.features.observe\")) .addObserver(HealthObserver.builder() .addCheck(new SlowStartHealthCheck()) .build()) .build(); Augment the web server by adding the ObserveFeature containing the HealthObserver . Instantiate the custom health check class and add the instance to the HealthObserver . Adding Observability (including the Custom Health Checks) to Helidon The code examples above prepare the observe feature instance using the built-in and custom health checks. To activate the health subsystem and other auto-discovered observability subsystems, add that observe instance as a feature to the webserver and start the server. <markup lang=\"java\" title=\"Register the observe feature with the server and start it\" >WebServer server = WebServer.builder() .featuresDiscoverServices(false) .addFeature(observe) .routing(Main::routing) .build() .start(); Add the previously-prepared health observer to the server as a feature Triggering and Interpreting Health Check Output Health support in Helidon is part of Helidon&#8217;s observability feature. HealthObserver is a Helidon-provided observability implementation that contains a collection of registered HealthCheck instances and, when queried, invokes the registered health checks and returns a response with a status code representing the overall status of the application. Health status codes <div class=\"table__overflow elevation-1 flex sm7 \"> 200 The application is healthy (with health check details in the response). 204 The application is healthy (with no health check details in the response). 503 The application is not healthy. 500 An error occurred while reporting the health. You control, either using configuration or adding code to your application, whether the HTTP responses to GET requests contain detailed information about each health check. With details enabled, HTTP GET responses include JSON content showing the detailed results of all the health checks which the server executed after receiving the request. With details disabled, HTTP GET responses have no payload. HTTP HEAD requests always return only the status with no payload. If you add the Helidon health dependency to your pom.xml file, Helidon automatically registers the HelidonObserver service and responds to the default /observe/health endpoint. Further, if you add the built-in health checks dependency, Helidon automatically finds them and adds those checks to the HealthObserver . Below are parts of health responses which include the custom health check added in the earlier example code. This first response shows the health output within the first eight seconds after start-up. Recall that the custom health check will report DOWN during that time, so the overall health is DOWN and the HTTP response status is 503 Service Unavailable . <markup lang=\"json\" title=\"Response within 8 seconds: HTTP status 503 (not healthy)\" >{ \"status\": \"DOWN\", \"checks\": [ { \"name\": \"live-after-8-seconds\", \"status\": \"DOWN\", \"data\": { \"time\": 1701984253071 } }, ... } The next response shows the health output once the server has been running for at least eight seconds. The custom health check now reports UP so the overall health status is also UP now and the HTTP status is 200 . <markup lang=\"json\" title=\"Response after 8 seconds: HTTP status 200\" >{ \"status\": \"UP\", \"checks\": [ { \"name\": \"live-after-8-seconds\", \"status\": \"UP\", \"data\": { \"time\": 1701984258292 } }, Balance collecting a lot of information with the need to avoid overloading the application and overwhelming users. The following table provides a summary of the Health Check API classes. Health check API classes io.helidon.health.HealthCheck Java functional interface representing the logic of a single health check io.helidon.health.HealthCheckResponse Result of a health check invocation that contains a status io.helidon.webserver.observe.health.HealthObserver WebServer service that exposes /observe/health and invokes the registered health checks Built-In Health Checks You can use Helidon-provided health checks to report various common health check statuses: Built-in health check Health check name JavaDoc Config properties (within server.features.observe.observers.health ) Default config value deadlock detection deadlock DeadlockHealthCheck n/a n/a available disk space diskSpace DiskSpaceHealthCheck helidon.health.diskSpace.thresholdPercent + helidon.health.diskSpace.path 99.999 + / available heap memory heapMemory HeapMemoryHealthCheck helidon.health.heapMemory.thresholdPercent 98 Simply adding the built-in health check dependency is sufficient to register all the built-in health checks automatically. If you want to use only some of the built-in checks in your application, you can disable automatic discovery of the built-in health checks and register only the ones you want. The following code adds only selected built-in health checks to your application: <markup lang=\"java\" title=\"Adding selected built-in health checks\" >WebServer server = WebServer.builder() .config(config.get(\"server\")) .addFeature(ObserveFeature.create(HealthObserver.builder() .useSystemServices(false) .addCheck(HealthChecks.deadlockCheck()) .addCheck(hc) .details(true) .build())) .routing(Main::routing) .build() .start(); Disables automatic registration of the built-in health checks. Adds the specific built-in check(s) you want. Adds a custom check (in a previously-prepared variable hc ). You can control the thresholds for built-in health checks in either of two ways: Create the health checks individually using their builders instead of using the HealthChecks convenience class. Follow the JavaDoc links in the table above. Using configuration as explained in Configuration . Kubernetes Probes Liveness Probe Readiness Probe Startup Probe Probes is the term used by Kubernetes to describe health checks for containers ( Kubernetes documentation ). There are three types of probes: liveness : Indicates whether the container is running readiness : Indicates whether the container is ready to service requests startup : Indicates whether the application in the container has started You can implement probes using the following mechanisms: Running a command inside a container Sending an HTTP request to a container Opening a TCP socket to a container A microservice exposed to HTTP traffic will typically implement both the liveness probe and the readiness probe using HTTP requests. If the microservice takes a significant time to initialize itself, you can also define a startup probe, in which case Kubernetes does not check liveness or readiness probes until the startup probe returns success. You can configure several parameters for probes. The following are the most relevant parameters: <div class=\"table__overflow elevation-1 flex sm7 \"> initialDelaySeconds Number of seconds after the container has started before liveness or readiness probes are initiated. periodSeconds Probe interval. Default to 10 seconds. Minimum value is 1. timeoutSeconds Number of seconds after which the probe times out. Defaults to 1 second. Minimum value is 1 failureThreshold Number of consecutive failures after which the probe should stop. Default: 3. Minimum: 1. Liveness Probe The liveness probe is used to verify the container has become unresponsive. For example, it can be used to detect deadlocks or analyze heap usage. When Kubernetes gives up on a liveness probe, the corresponding pod is restarted. The liveness probe can result in repeated restarts in certain cases. For example, if the probe is implemented to check all the dependencies strictly, then it can fail repeatedly for temporary issues. Repeated restarts can also occur if timeoutSeconds or periodSeconds is too low. We recommend the following: Avoid checking dependencies in a liveness probe. Set timeoutSeconds to avoid excessive probe failures. Acknowledge startup times with initialDelaySeconds . Readiness Probe The readiness probe is used to avoid routing requests to the pod until it is ready to accept traffic. When Kubernetes gives up on a readiness probe, the pod is not restarted, traffic is not routed to the pod anymore. In certain cases, the readiness probe can cause all the pods to be removed from service routing. For example, if the probe is implemented to check all the dependencies strictly, then it can fail repeatedly for temporary issues. This issue can also occur if timeoutSeconds or periodSeconds is too low. We recommend the following: Be conservative when checking shared dependencies. Be aggressive when checking local dependencies. Set failureThreshold according to periodSeconds in order to accommodate temporary errors. Startup Probe The startup probe prevents Kubernetes from prematurely checking the other probes if the application takes a long time to start. Otherwise, Kubernetes might misinterpret a failed liveness or readiness probe and shut down the container when, in fact, the application is still coming up. Troubleshooting Probes Failed probes are recorded as events associated with their corresponding pods. The event message contains only the status code. <markup lang=\"bash\" title=\"Get the events of a single pod:\" >POD_NAME=$(kubectl get pod -l app=acme -o jsonpath='{.items[0].metadata.name}') kubectl get event --field-selector involvedObject.name=${POD_NAME} Get the effective pod name by filtering pods with the label app=acme . Filter the events for the pod. Create log messages in your health check implementation when setting a DOWN status. This will allow you to correlate the cause of a failed probe. ",
            "title": "API"
        },
        {
            "location": "/se/health",
            "text": " Built-in health checks can be configured using the config property keys described in this table . Further, you can suppress one or more of the built-in health checks by setting the configuration item helidon.health.exclude to a comma-separated list of the health check names (from this table ) you want to exclude. ",
            "title": "Configuration"
        },
        {
            "location": "/se/health",
            "text": " Accessing the Helidon-provided /observe/health endpoint reports the health of your application as shown below: <markup lang=\"json\" title=\"JSON response.\" >{ \"status\": \"UP\", \"checks\": [ { \"name\": \"deadlock\", \"status\": \"UP\" }, { \"name\": \"diskSpace\", \"status\": \"UP\", \"data\": { \"free\": \"211.00 GB\", \"freeBytes\": 226563444736, \"percentFree\": \"45.31%\", \"total\": \"465.72 GB\", \"totalBytes\": 500068036608 } }, { \"name\": \"heapMemory\", \"status\": \"UP\", \"data\": { \"free\": \"215.15 MB\", \"freeBytes\": 225600496, \"max\": \"3.56 GB\", \"maxBytes\": 3817865216, \"percentFree\": \"99.17%\", \"total\": \"245.50 MB\", \"totalBytes\": 257425408 } } ] } ",
            "title": "JSON Response Example"
        },
        {
            "location": "/se/health",
            "text": " This example shows the usage of the Helidon health API in an application that implements health endpoints for the liveness and readiness probes. Note that the application code dissociates the health endpoints from the default routes, so that the health endpoints are not exposed by the service. An example YAML specification is also provided for the Kubernetes service and deployment. <markup lang=\"java\" title=\"Application code:\" >ObserveFeature observeFeature = ObserveFeature.builder() .addObserver(HealthObserver.builder() .useSystemServices(false) .endpoint(\"/health/live\") .addChecks(HealthChecks.healthChecks()) .build()) .addObserver(HealthObserver.builder() .useSystemServices(false) .endpoint(\"/health/ready\") .addCheck(() -&gt; HealthCheckResponse.builder() .status(true) .build(), HealthCheckType.READINESS, \"database\") .build()) .build(); WebServer server = WebServer.builder() .putSocket(\"@default\", socket -&gt; socket .port(8080) .routing(r -&gt; r.any((req, res) -&gt; res.send(\"It works!\")))) .putSocket(\"observe\", socket -&gt; socket .port(8081) .routing(r -&gt; r.addFeature(observeFeature))) .build() .start(); The health service for the liveness probe is exposed at /observe/health/live . Using the built-in health checks for the liveness probe. The health service for the readiness probe is exposed at /observe/health/ready . Using a custom health check for a pseudo database that is always UP . The default socket uses port 8080 for the default routes. The default route: returns It works! for any request. The observe socket uses port 8081 for the \"/observe\" routes. Route the observe feature exclusively on the observe socket. <markup lang=\"yaml\" title=\"Kubernetes descriptor:\" >kind: Service apiVersion: v1 metadata: name: acme labels: app: acme spec: type: NodePort selector: app: acme ports: - port: 8080 targetPort: 8080 name: http --- kind: Deployment apiVersion: apps/v1 metadata: name: acme spec: replicas: 1 selector: matchLabels: app: acme template: metadata: name: acme labels: name: acme spec: containers: - name: acme image: acme imagePullPolicy: IfNotPresent ports: - containerPort: 8080 livenessProbe: httpGet: path: /observe/health/live port: 8081 initialDelaySeconds: 3 periodSeconds: 10 timeoutSeconds: 3 failureThreshold: 3 readinessProbe: httpGet: path: /observe/health/ready port: 8081 initialDelaySeconds: 10 periodSeconds: 30 timeoutSeconds: 10 --- A service of type NodePort that serves the default routes on port 8080 . A deployment with one replica of a pod. The HTTP endpoint for the liveness probe. The liveness probe configuration. The HTTP endpoint for the readiness probe. The readiness probe configuration. ",
            "title": "Kubernetes Example"
        },
        {
            "location": "/se/health",
            "text": " JSON Response Example Accessing the Helidon-provided /observe/health endpoint reports the health of your application as shown below: <markup lang=\"json\" title=\"JSON response.\" >{ \"status\": \"UP\", \"checks\": [ { \"name\": \"deadlock\", \"status\": \"UP\" }, { \"name\": \"diskSpace\", \"status\": \"UP\", \"data\": { \"free\": \"211.00 GB\", \"freeBytes\": 226563444736, \"percentFree\": \"45.31%\", \"total\": \"465.72 GB\", \"totalBytes\": 500068036608 } }, { \"name\": \"heapMemory\", \"status\": \"UP\", \"data\": { \"free\": \"215.15 MB\", \"freeBytes\": 225600496, \"max\": \"3.56 GB\", \"maxBytes\": 3817865216, \"percentFree\": \"99.17%\", \"total\": \"245.50 MB\", \"totalBytes\": 257425408 } } ] } Kubernetes Example This example shows the usage of the Helidon health API in an application that implements health endpoints for the liveness and readiness probes. Note that the application code dissociates the health endpoints from the default routes, so that the health endpoints are not exposed by the service. An example YAML specification is also provided for the Kubernetes service and deployment. <markup lang=\"java\" title=\"Application code:\" >ObserveFeature observeFeature = ObserveFeature.builder() .addObserver(HealthObserver.builder() .useSystemServices(false) .endpoint(\"/health/live\") .addChecks(HealthChecks.healthChecks()) .build()) .addObserver(HealthObserver.builder() .useSystemServices(false) .endpoint(\"/health/ready\") .addCheck(() -&gt; HealthCheckResponse.builder() .status(true) .build(), HealthCheckType.READINESS, \"database\") .build()) .build(); WebServer server = WebServer.builder() .putSocket(\"@default\", socket -&gt; socket .port(8080) .routing(r -&gt; r.any((req, res) -&gt; res.send(\"It works!\")))) .putSocket(\"observe\", socket -&gt; socket .port(8081) .routing(r -&gt; r.addFeature(observeFeature))) .build() .start(); The health service for the liveness probe is exposed at /observe/health/live . Using the built-in health checks for the liveness probe. The health service for the readiness probe is exposed at /observe/health/ready . Using a custom health check for a pseudo database that is always UP . The default socket uses port 8080 for the default routes. The default route: returns It works! for any request. The observe socket uses port 8081 for the \"/observe\" routes. Route the observe feature exclusively on the observe socket. <markup lang=\"yaml\" title=\"Kubernetes descriptor:\" >kind: Service apiVersion: v1 metadata: name: acme labels: app: acme spec: type: NodePort selector: app: acme ports: - port: 8080 targetPort: 8080 name: http --- kind: Deployment apiVersion: apps/v1 metadata: name: acme spec: replicas: 1 selector: matchLabels: app: acme template: metadata: name: acme labels: name: acme spec: containers: - name: acme image: acme imagePullPolicy: IfNotPresent ports: - containerPort: 8080 livenessProbe: httpGet: path: /observe/health/live port: 8081 initialDelaySeconds: 3 periodSeconds: 10 timeoutSeconds: 3 failureThreshold: 3 readinessProbe: httpGet: path: /observe/health/ready port: 8081 initialDelaySeconds: 10 periodSeconds: 30 timeoutSeconds: 10 --- A service of type NodePort that serves the default routes on port 8080 . A deployment with one replica of a pod. The HTTP endpoint for the liveness probe. The liveness probe configuration. The HTTP endpoint for the readiness probe. The readiness probe configuration. ",
            "title": "Examples"
        },
        {
            "location": "/se/health",
            "text": " Health Checks SE API JavaDocs . ",
            "title": "Additional Information"
        },
        {
            "location": "/se/inject/injection_intro",
            "text": " Overview Maven Coordinates Usage API Configuration Examples Additional Information ",
            "title": "Contents"
        },
        {
            "location": "/se/inject/injection_intro",
            "text": " Helidon Injection is an optional feature in Helidon that provides service registry, a lifecycle engine and extensibility for customized code generation. Helidon Injection provides a way to develop non Helidon-specific declarative code using standard Javax/Jakarta annotation types. The Helidon Injection Framework provides a mix of declarative and programmatic ways to build your application. Helidon Injection&#8217;s minimalist, compile-time generated dependency injection (DI) framework and compile-time source code generation has a number of advantages, including: enables declarative, Inversion of Control-style programming offers visibility into your application by providing \"less magic\" - understandability and debug-ability of your application provides deterministic behavior (instead of depending on reflection and classpath ordering, etc.) optimizes performance improvements since binding the model at compile-time is more efficient than computing it at runtime. ",
            "title": "Overview"
        },
        {
            "location": "/se/inject/injection_intro",
            "text": "<markup lang=\"java\" title=\"Injection dependencies\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.inject&lt;/groupId&gt; &lt;artifactId&gt;helidon-inject-api&lt;/artifactId&gt; &lt;version&gt;${helidon.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.inject&lt;/groupId&gt; &lt;artifactId&gt;helidon-inject-types&lt;/artifactId&gt; &lt;version&gt;${helidon.version}&lt;/version&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/inject/injection_intro",
            "text": " Once you have planned how each of your resources should support Injection, you specify the behavior in one of two ways: ",
            "title": "Usage"
        },
        {
            "location": "/se/inject/injection_intro",
            "text": "<markup lang=\"java\" title=\"Injection API pom.xml\" > &lt;artifactId&gt;helidon-inject-inject&lt;/artifactId&gt; &lt;name&gt;Helidon Injection API&lt;/name&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/inject/injection_intro",
            "text": " The Injection API provides types that are generally useful at compile time to assign special meaning to the type. In this way it also helps with readability and intentions of the code itself. <markup lang=\"java\" title=\"Injection types pom.xml\" > &lt;artifactId&gt;helidon-inject-types&lt;/artifactId&gt; &lt;name&gt;Helidon Injection Types&lt;/name&gt; {@link io.helidon.inject.api.Contract} - signifies that the type can be used for lookup in the service registry. {@link io.helidon.inject.api.ExternalContracts} - same as Contract, but applied to the implementation class instead. {@link io.helidon.inject.api.RunLevel} - ascribes meaning for when the service should start. ",
            "title": "Types"
        },
        {
            "location": "/se/inject/injection_intro",
            "text": " Adding Injection behavior to your Helidon WebServer application involves just a few simple steps. Maven Coordinates <markup lang=\"java\" title=\"Injection API pom.xml\" > &lt;artifactId&gt;helidon-inject-inject&lt;/artifactId&gt; &lt;name&gt;Helidon Injection API&lt;/name&gt; Types The Injection API provides types that are generally useful at compile time to assign special meaning to the type. In this way it also helps with readability and intentions of the code itself. <markup lang=\"java\" title=\"Injection types pom.xml\" > &lt;artifactId&gt;helidon-inject-types&lt;/artifactId&gt; &lt;name&gt;Helidon Injection Types&lt;/name&gt; {@link io.helidon.inject.api.Contract} - signifies that the type can be used for lookup in the service registry. {@link io.helidon.inject.api.ExternalContracts} - same as Contract, but applied to the implementation class instead. {@link io.helidon.inject.api.RunLevel} - ascribes meaning for when the service should start. ",
            "title": "API"
        },
        {
            "location": "/se/inject/injection_intro",
            "text": " Injection Config builder ",
            "title": "Configuration"
        },
        {
            "location": "/se/inject/injection_intro",
            "text": "",
            "title": "Examples"
        },
        {
            "location": "/se/inject/injection_intro",
            "text": "",
            "title": "Additional Information"
        },
        {
            "location": "/se/integrations/hcv",
            "text": " Overview Maven Coordinates Usage Examples Local Testing References ",
            "title": "Contents"
        },
        {
            "location": "/se/integrations/hcv",
            "text": " HashiCorp Vault is a commonly used Vault in many microservices. The APIs are REST-based and Helidon implements them using WebClient . ",
            "title": "Overview"
        },
        {
            "location": "/se/integrations/hcv",
            "text": " To enable HashiCorp Vault add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.vault&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-vault&lt;/artifactId&gt; &lt;/dependency&gt; The following is a list of maven coordinates of all Vault modules available: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.vault.auths&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-vault-auths-token&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.vault.auths&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-vault-auths-approle&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.vault.auths&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-vault-auths-k8s&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.vault.secrets&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-vault-secrets-kv1&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.vault.secrets&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-vault-secrets-kv2&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.vault.secrets&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-vault-secrets-cubbyhole&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.vault.secrets&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-vault-secrets-transit&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.vault.secrets&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-vault-secrets-database&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.vault.sys&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-vault-sys&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/integrations/hcv",
            "text": " New secret engines and authentication methods can be implemented quite easily, as the integration is based on service providers (using ServiceLoader). This gives us (or you, as the users) the option to add new secret engines and/or authentication methods without adding a plethora of methods to the Vault class. See the following SPIs: <markup lang=\"properties\" >io.helidon.integrations.vault.spi.AuthMethodProvider io.helidon.integrations.vault.spi.SecretsEngineProvider io.helidon.integrations.vault.spi.SysProvider io.helidon.integrations.vault.spi.VaultAuth io.helidon.integrations.vault.spi.InjectionProvider ",
            "title": "Extensibility"
        },
        {
            "location": "/se/integrations/hcv",
            "text": " Vault integration supports the following: Secret Engines : Key/Value version 2, Key/Value version 1, Cubbyhole, PKI, Transit, Database Authentication Methods : Token, Kubernetes (k8s), AppRole Other Sys Operations and Configurations Each of these features is implemented as a separate module, with the Vault class binding them together. Code to set up Vault and obtain a specific secret engine: <markup lang=\"java\" >Vault vault = Vault.builder() .config(config.get(\"vault\")) .build(); Kv2SecretsRx secrets = vault.secrets(Kv2SecretsRx.ENGINE); Similar code can be used for any secret engine available: Kv2SecretsRx - Key/Value Version 2 Secrets (versioned secrets, default) Kv1SecretsRx - Key/Value Version 1 Secrets (unversioned secrets, legacy) CubbyholeSecretsRx - Cubbyhole secrets (token bound secrets) DbSecretsRx - Database secrets (for generating temporary DB credentials) PkiSecretsRx - PKI secrets (for generating keys and X.509 certificates) TransitSecretsRx - Transit operations (encryption, signatures, HMAC) In addition to these features, Vault itself can be authenticated as follows: Token authentication - token is configured when connecting to Vault vault: address: \"http://localhost:8200\" token: \"my-token\" AppRole authentication - AppRole ID and secret ID are configured, integration exchanges these for a temporary token that is used to connect to Vault vault: auth: app-role: role-id: \"app-role-id\" secret-id: app-role-secret-id K8s authentication - the k8s JWT token is discovered on current node and used to obtain a temporary token that is used to connect to Vault vault: auth: k8s: token-role: \"my-role\" The token role must be configured in Vault Minimal configuration to connect to Vault: Code to get the Sys operations of Vault: <markup lang=\"java\" >SysRx sys = vault.sys(SysRx.API); Extensibility New secret engines and authentication methods can be implemented quite easily, as the integration is based on service providers (using ServiceLoader). This gives us (or you, as the users) the option to add new secret engines and/or authentication methods without adding a plethora of methods to the Vault class. See the following SPIs: <markup lang=\"properties\" >io.helidon.integrations.vault.spi.AuthMethodProvider io.helidon.integrations.vault.spi.SecretsEngineProvider io.helidon.integrations.vault.spi.SysProvider io.helidon.integrations.vault.spi.VaultAuth io.helidon.integrations.vault.spi.InjectionProvider ",
            "title": "Usage"
        },
        {
            "location": "/se/integrations/hcv",
            "text": " Configure the Vault object using token base configuration: <markup lang=\"java\" >Config config = buildConfig(); Vault tokenVault = Vault.builder() .config(config.get(\"vault.token\")) .updateWebClient(it -&gt; it.connectTimeout(5, TimeUnit.SECONDS) .readTimeout(5, TimeUnit.SECONDS)) .build(); Then WebService has to be configured with endpoints routing registered: <markup lang=\"java\" >Sys sys = tokenVault.sys(Sys.API); WebServer webServer = WebServer.builder() .config(config.get(\"server\")) .routing(routing -&gt; routing .register(\"/cubbyhole\", new CubbyholeService(sys, tokenVault.secrets(CubbyholeSecrets.ENGINE))) .register(\"/kv1\", new Kv1Service(sys, tokenVault.secrets(Kv1Secrets.ENGINE))) .register(\"/kv2\", new Kv2Service(sys, tokenVault.secrets(Kv2Secrets.ENGINE))) .register(\"/transit\", new TransitService(sys, tokenVault.secrets(TransitSecrets.ENGINE)))) .build() .start(); AppRole-based and Kubernetes authentications are available. ",
            "title": "Usage with WebServer"
        },
        {
            "location": "/se/integrations/hcv",
            "text": " Cubbyhole secrets engine operations: <markup lang=\"java\" >@Override public void routing(HttpRules rules) { rules.get(\"/create\", this::createSecrets) .get(\"/secrets/{path:.*}\", this::getSecret); } private void createSecrets(ServerRequest req, ServerResponse res) { secrets.create(\"first/secret\", Map.of(\"key\", \"secretValue\")); res.send(\"Created secret on path /first/secret\"); } private void getSecret(ServerRequest req, ServerResponse res) { String path = req.path().pathParameters().get(\"path\"); Optional&lt;Secret&gt; secret = secrets.get(path); if (secret.isPresent()) { // using toString so we do not need to depend on JSON-B res.send(secret.get().values().toString()); } else { res.status(Status.NOT_FOUND_404); res.send(); } } Create a secret from request entity. Get the secret on a specified path. ",
            "title": "Cubbyhole secrets"
        },
        {
            "location": "/se/integrations/hcv",
            "text": " Key/Value version 1 secrets engine operations: <markup lang=\"java\" >@Override public void routing(HttpRules rules) { rules.get(\"/enable\", this::enableEngine) .get(\"/create\", this::createSecrets) .get(\"/secrets/{path:.*}\", this::getSecret) .delete(\"/secrets/{path:.*}\", this::deleteSecret) .get(\"/disable\", this::disableEngine); } private void disableEngine(ServerRequest req, ServerResponse res) { sys.disableEngine(Kv1Secrets.ENGINE); res.send(\"KV1 Secret engine disabled\"); } private void enableEngine(ServerRequest req, ServerResponse res) { sys.enableEngine(Kv1Secrets.ENGINE); res.send(\"KV1 Secret engine enabled\"); } private void createSecrets(ServerRequest req, ServerResponse res) { secrets.create(\"first/secret\", Map.of(\"key\", \"secretValue\")); res.send(\"Created secret on path /first/secret\"); } private void deleteSecret(ServerRequest req, ServerResponse res) { String path = req.path().pathParameters().get(\"path\"); secrets.delete(path); res.send(\"Deleted secret on path \" + path); } private void getSecret(ServerRequest req, ServerResponse res) { String path = req.path().pathParameters().get(\"path\"); Optional&lt;Secret&gt; secret = secrets.get(path); if (secret.isPresent()) { // using toString so we do not need to depend on JSON-B res.send(secret.get().values().toString()); } else { res.status(Status.NOT_FOUND_404); res.send(); } } Disable the secrets engine on the default path. Enable the secrets engine on the default path. Create a secret from request entity. Delete the secret on a specified path. Get the secret on a specified path. ",
            "title": "KV1 Secrets"
        },
        {
            "location": "/se/integrations/hcv",
            "text": " Key/Value version 2 secrets engine operations: <markup lang=\"java\" >@Override public void routing(HttpRules rules) { rules.get(\"/create\", this::createSecrets) .get(\"/secrets/{path:.*}\", this::getSecret) .delete(\"/secrets/{path:.*}\", this::deleteSecret); } private void createSecrets(ServerRequest req, ServerResponse res) { secrets.create(\"first/secret\", Map.of(\"key\", \"secretValue\")); res.send(\"Created secret on path /first/secret\"); } private void deleteSecret(ServerRequest req, ServerResponse res) { String path = req.path().pathParameters().get(\"path\"); secrets.deleteAll(path); res.send(\"Deleted secret on path \" + path); } private void getSecret(ServerRequest req, ServerResponse res) { String path = req.path().pathParameters().get(\"path\"); Optional&lt;Kv2Secret&gt; secret = secrets.get(path); if (secret.isPresent()) { // using toString so we do not need to depend on JSON-B Kv2Secret kv2Secret = secret.get(); res.send(\"Version \" + kv2Secret.metadata().version() + \", secret: \" + kv2Secret.values().toString()); } else { res.status(Status.NOT_FOUND_404); res.send(); } } Create a secret from request entity. Delete the secret on a specified path. Get the secret on a specified path. ",
            "title": "KV2 Secrets"
        },
        {
            "location": "/se/integrations/hcv",
            "text": " Transit secrets engine operations: <markup lang=\"java\" >@Override public void routing(HttpRules rules) { rules.get(\"/enable\", this::enableEngine) .get(\"/keys\", this::createKeys) .delete(\"/keys\", this::deleteKeys) .get(\"/batch\", this::batch) .get(\"/encrypt/{text:.*}\", this::encryptSecret) .get(\"/decrypt/{text:.*}\", this::decryptSecret) .get(\"/sign\", this::sign) .get(\"/hmac\", this::hmac) .get(\"/verify/sign/{text:.*}\", this::verify) .get(\"/verify/hmac/{text:.*}\", this::verifyHmac) .get(\"/disable\", this::disableEngine); } private void enableEngine(ServerRequest req, ServerResponse res) { sys.enableEngine(TransitSecrets.ENGINE); res.send(\"Transit Secret engine enabled\"); } private void disableEngine(ServerRequest req, ServerResponse res) { sys.disableEngine(TransitSecrets.ENGINE); res.send(\"Transit Secret engine disabled\"); } private void createKeys(ServerRequest req, ServerResponse res) { CreateKey.Request request = CreateKey.Request.builder() .name(ENCRYPTION_KEY); secrets.createKey(request); secrets.createKey(CreateKey.Request.builder() .name(SIGNATURE_KEY) .type(\"rsa-2048\")); res.send(\"Created keys\"); } private void deleteKeys(ServerRequest req, ServerResponse res) { secrets.updateKeyConfig(UpdateKeyConfig.Request.builder() .name(ENCRYPTION_KEY) .allowDeletion(true)); System.out.println(\"Updated key config\"); secrets.deleteKey(DeleteKey.Request.create(ENCRYPTION_KEY)); res.send(\"Deleted key.\"); } private void encryptSecret(ServerRequest req, ServerResponse res) { String secret = req.path().pathParameters().get(\"text\"); Encrypt.Response encryptResponse = secrets.encrypt(Encrypt.Request.builder() .encryptionKeyName(ENCRYPTION_KEY) .data(Base64Value.create(secret))); res.send(encryptResponse.encrypted().cipherText()); } private void decryptSecret(ServerRequest req, ServerResponse res) { String encrypted = req.path().pathParameters().get(\"text\"); Decrypt.Response decryptResponse = secrets.decrypt(Decrypt.Request.builder() .encryptionKeyName(ENCRYPTION_KEY) .cipherText(encrypted)); res.send(String.valueOf(decryptResponse.decrypted().toDecodedString())); } private void hmac(ServerRequest req, ServerResponse res) { Hmac.Response hmacResponse = secrets.hmac(Hmac.Request.builder() .hmacKeyName(ENCRYPTION_KEY) .data(SECRET_STRING)); res.send(hmacResponse.hmac()); } private void sign(ServerRequest req, ServerResponse res) { Sign.Response signResponse = secrets.sign(Sign.Request.builder() .signatureKeyName(SIGNATURE_KEY) .data(SECRET_STRING)); res.send(signResponse.signature()); } private void verifyHmac(ServerRequest req, ServerResponse res) { String hmac = req.path().pathParameters().get(\"text\"); Verify.Response verifyResponse = secrets.verify(Verify.Request.builder() .digestKeyName(ENCRYPTION_KEY) .data(SECRET_STRING) .hmac(hmac)); res.send(\"Valid: \" + verifyResponse.isValid()); } private void verify(ServerRequest req, ServerResponse res) { String signature = req.path().pathParameters().get(\"text\"); Verify.Response verifyResponse = secrets.verify(Verify.Request.builder() .digestKeyName(SIGNATURE_KEY) .data(SECRET_STRING) .signature(signature)); res.send(\"Valid: \" + verifyResponse.isValid()); } Enable the secrets engine on the default path. Disable the secrets engine on the default path. Create the encryption and signature keys. Delete the encryption and signature keys. Encrypt a secret. Decrypt a secret. Create an HMAC for text. Create a signature for text. Verify HMAC. Verify signature. ",
            "title": "Transit secrets"
        },
        {
            "location": "/se/integrations/hcv",
            "text": " In order to use Kubernetes authentication: <markup lang=\"java\" >class K8sExample { private static final String SECRET_PATH = \"k8s/example/secret\"; private static final String POLICY_NAME = \"k8s_policy\"; private final Vault tokenVault; private final String k8sAddress; private final Config config; private final Sys sys; private Vault k8sVault; K8sExample(Vault tokenVault, Config config) { this.tokenVault = tokenVault; this.sys = tokenVault.sys(Sys.API); this.k8sAddress = config.get(\"cluster-address\").asString().get(); this.config = config; } public String run() { /* The following tasks must be run before we authenticate */ enableK8sAuth(); // Now we can login using k8s - must run within a k8s cluster (or you need the k8s configuration files locally) workWithSecrets(); // Now back to token based Vault, as we will clean up disableK8sAuth(); return \"k8s example finished successfully.\"; } private void workWithSecrets() { Kv2Secrets secrets = k8sVault.secrets(Kv2Secrets.ENGINE); secrets.create(SECRET_PATH, Map.of(\"secret-key\", \"secretValue\", \"secret-user\", \"username\")); Optional&lt;Kv2Secret&gt; secret = secrets.get(SECRET_PATH); if (secret.isPresent()) { Kv2Secret kv2Secret = secret.get(); System.out.println(\"k8s first secret: \" + kv2Secret.value(\"secret-key\")); System.out.println(\"k8s second secret: \" + kv2Secret.value(\"secret-user\")); } else { System.out.println(\"k8s secret not found\"); } secrets.deleteAll(SECRET_PATH); } private void disableK8sAuth() { sys.deletePolicy(POLICY_NAME); sys.disableAuth(K8sAuth.AUTH_METHOD.defaultPath()); } private void enableK8sAuth() { // enable the method sys.enableAuth(K8sAuth.AUTH_METHOD); sys.createPolicy(POLICY_NAME, VaultPolicy.POLICY); tokenVault.auth(K8sAuth.AUTH_METHOD) .configure(ConfigureK8s.Request.builder() .address(k8sAddress)); tokenVault.auth(K8sAuth.AUTH_METHOD) // this must be the same role name as is defined in application.yaml .createRole(CreateRole.Request.builder() .roleName(\"my-role\") .addBoundServiceAccountName(\"*\") .addBoundServiceAccountNamespace(\"default\") .addTokenPolicy(POLICY_NAME)); k8sVault = Vault.create(config); } } Run the Kubernetes Authentication by enabling it. Create Kubernetes secrets. Disable Kubernetes authentication if needed. Function used to enable Kubernetes authentication. ",
            "title": "Authentication with Kubernetes"
        },
        {
            "location": "/se/integrations/hcv",
            "text": " The following example shows usage of Vault to encrypt a secret. Usage with WebServer Configure the Vault object using token base configuration: <markup lang=\"java\" >Config config = buildConfig(); Vault tokenVault = Vault.builder() .config(config.get(\"vault.token\")) .updateWebClient(it -&gt; it.connectTimeout(5, TimeUnit.SECONDS) .readTimeout(5, TimeUnit.SECONDS)) .build(); Then WebService has to be configured with endpoints routing registered: <markup lang=\"java\" >Sys sys = tokenVault.sys(Sys.API); WebServer webServer = WebServer.builder() .config(config.get(\"server\")) .routing(routing -&gt; routing .register(\"/cubbyhole\", new CubbyholeService(sys, tokenVault.secrets(CubbyholeSecrets.ENGINE))) .register(\"/kv1\", new Kv1Service(sys, tokenVault.secrets(Kv1Secrets.ENGINE))) .register(\"/kv2\", new Kv2Service(sys, tokenVault.secrets(Kv2Secrets.ENGINE))) .register(\"/transit\", new TransitService(sys, tokenVault.secrets(TransitSecrets.ENGINE)))) .build() .start(); AppRole-based and Kubernetes authentications are available. Cubbyhole secrets Cubbyhole secrets engine operations: <markup lang=\"java\" >@Override public void routing(HttpRules rules) { rules.get(\"/create\", this::createSecrets) .get(\"/secrets/{path:.*}\", this::getSecret); } private void createSecrets(ServerRequest req, ServerResponse res) { secrets.create(\"first/secret\", Map.of(\"key\", \"secretValue\")); res.send(\"Created secret on path /first/secret\"); } private void getSecret(ServerRequest req, ServerResponse res) { String path = req.path().pathParameters().get(\"path\"); Optional&lt;Secret&gt; secret = secrets.get(path); if (secret.isPresent()) { // using toString so we do not need to depend on JSON-B res.send(secret.get().values().toString()); } else { res.status(Status.NOT_FOUND_404); res.send(); } } Create a secret from request entity. Get the secret on a specified path. KV1 Secrets Key/Value version 1 secrets engine operations: <markup lang=\"java\" >@Override public void routing(HttpRules rules) { rules.get(\"/enable\", this::enableEngine) .get(\"/create\", this::createSecrets) .get(\"/secrets/{path:.*}\", this::getSecret) .delete(\"/secrets/{path:.*}\", this::deleteSecret) .get(\"/disable\", this::disableEngine); } private void disableEngine(ServerRequest req, ServerResponse res) { sys.disableEngine(Kv1Secrets.ENGINE); res.send(\"KV1 Secret engine disabled\"); } private void enableEngine(ServerRequest req, ServerResponse res) { sys.enableEngine(Kv1Secrets.ENGINE); res.send(\"KV1 Secret engine enabled\"); } private void createSecrets(ServerRequest req, ServerResponse res) { secrets.create(\"first/secret\", Map.of(\"key\", \"secretValue\")); res.send(\"Created secret on path /first/secret\"); } private void deleteSecret(ServerRequest req, ServerResponse res) { String path = req.path().pathParameters().get(\"path\"); secrets.delete(path); res.send(\"Deleted secret on path \" + path); } private void getSecret(ServerRequest req, ServerResponse res) { String path = req.path().pathParameters().get(\"path\"); Optional&lt;Secret&gt; secret = secrets.get(path); if (secret.isPresent()) { // using toString so we do not need to depend on JSON-B res.send(secret.get().values().toString()); } else { res.status(Status.NOT_FOUND_404); res.send(); } } Disable the secrets engine on the default path. Enable the secrets engine on the default path. Create a secret from request entity. Delete the secret on a specified path. Get the secret on a specified path. KV2 Secrets Key/Value version 2 secrets engine operations: <markup lang=\"java\" >@Override public void routing(HttpRules rules) { rules.get(\"/create\", this::createSecrets) .get(\"/secrets/{path:.*}\", this::getSecret) .delete(\"/secrets/{path:.*}\", this::deleteSecret); } private void createSecrets(ServerRequest req, ServerResponse res) { secrets.create(\"first/secret\", Map.of(\"key\", \"secretValue\")); res.send(\"Created secret on path /first/secret\"); } private void deleteSecret(ServerRequest req, ServerResponse res) { String path = req.path().pathParameters().get(\"path\"); secrets.deleteAll(path); res.send(\"Deleted secret on path \" + path); } private void getSecret(ServerRequest req, ServerResponse res) { String path = req.path().pathParameters().get(\"path\"); Optional&lt;Kv2Secret&gt; secret = secrets.get(path); if (secret.isPresent()) { // using toString so we do not need to depend on JSON-B Kv2Secret kv2Secret = secret.get(); res.send(\"Version \" + kv2Secret.metadata().version() + \", secret: \" + kv2Secret.values().toString()); } else { res.status(Status.NOT_FOUND_404); res.send(); } } Create a secret from request entity. Delete the secret on a specified path. Get the secret on a specified path. Transit secrets Transit secrets engine operations: <markup lang=\"java\" >@Override public void routing(HttpRules rules) { rules.get(\"/enable\", this::enableEngine) .get(\"/keys\", this::createKeys) .delete(\"/keys\", this::deleteKeys) .get(\"/batch\", this::batch) .get(\"/encrypt/{text:.*}\", this::encryptSecret) .get(\"/decrypt/{text:.*}\", this::decryptSecret) .get(\"/sign\", this::sign) .get(\"/hmac\", this::hmac) .get(\"/verify/sign/{text:.*}\", this::verify) .get(\"/verify/hmac/{text:.*}\", this::verifyHmac) .get(\"/disable\", this::disableEngine); } private void enableEngine(ServerRequest req, ServerResponse res) { sys.enableEngine(TransitSecrets.ENGINE); res.send(\"Transit Secret engine enabled\"); } private void disableEngine(ServerRequest req, ServerResponse res) { sys.disableEngine(TransitSecrets.ENGINE); res.send(\"Transit Secret engine disabled\"); } private void createKeys(ServerRequest req, ServerResponse res) { CreateKey.Request request = CreateKey.Request.builder() .name(ENCRYPTION_KEY); secrets.createKey(request); secrets.createKey(CreateKey.Request.builder() .name(SIGNATURE_KEY) .type(\"rsa-2048\")); res.send(\"Created keys\"); } private void deleteKeys(ServerRequest req, ServerResponse res) { secrets.updateKeyConfig(UpdateKeyConfig.Request.builder() .name(ENCRYPTION_KEY) .allowDeletion(true)); System.out.println(\"Updated key config\"); secrets.deleteKey(DeleteKey.Request.create(ENCRYPTION_KEY)); res.send(\"Deleted key.\"); } private void encryptSecret(ServerRequest req, ServerResponse res) { String secret = req.path().pathParameters().get(\"text\"); Encrypt.Response encryptResponse = secrets.encrypt(Encrypt.Request.builder() .encryptionKeyName(ENCRYPTION_KEY) .data(Base64Value.create(secret))); res.send(encryptResponse.encrypted().cipherText()); } private void decryptSecret(ServerRequest req, ServerResponse res) { String encrypted = req.path().pathParameters().get(\"text\"); Decrypt.Response decryptResponse = secrets.decrypt(Decrypt.Request.builder() .encryptionKeyName(ENCRYPTION_KEY) .cipherText(encrypted)); res.send(String.valueOf(decryptResponse.decrypted().toDecodedString())); } private void hmac(ServerRequest req, ServerResponse res) { Hmac.Response hmacResponse = secrets.hmac(Hmac.Request.builder() .hmacKeyName(ENCRYPTION_KEY) .data(SECRET_STRING)); res.send(hmacResponse.hmac()); } private void sign(ServerRequest req, ServerResponse res) { Sign.Response signResponse = secrets.sign(Sign.Request.builder() .signatureKeyName(SIGNATURE_KEY) .data(SECRET_STRING)); res.send(signResponse.signature()); } private void verifyHmac(ServerRequest req, ServerResponse res) { String hmac = req.path().pathParameters().get(\"text\"); Verify.Response verifyResponse = secrets.verify(Verify.Request.builder() .digestKeyName(ENCRYPTION_KEY) .data(SECRET_STRING) .hmac(hmac)); res.send(\"Valid: \" + verifyResponse.isValid()); } private void verify(ServerRequest req, ServerResponse res) { String signature = req.path().pathParameters().get(\"text\"); Verify.Response verifyResponse = secrets.verify(Verify.Request.builder() .digestKeyName(SIGNATURE_KEY) .data(SECRET_STRING) .signature(signature)); res.send(\"Valid: \" + verifyResponse.isValid()); } Enable the secrets engine on the default path. Disable the secrets engine on the default path. Create the encryption and signature keys. Delete the encryption and signature keys. Encrypt a secret. Decrypt a secret. Create an HMAC for text. Create a signature for text. Verify HMAC. Verify signature. Authentication with Kubernetes In order to use Kubernetes authentication: <markup lang=\"java\" >class K8sExample { private static final String SECRET_PATH = \"k8s/example/secret\"; private static final String POLICY_NAME = \"k8s_policy\"; private final Vault tokenVault; private final String k8sAddress; private final Config config; private final Sys sys; private Vault k8sVault; K8sExample(Vault tokenVault, Config config) { this.tokenVault = tokenVault; this.sys = tokenVault.sys(Sys.API); this.k8sAddress = config.get(\"cluster-address\").asString().get(); this.config = config; } public String run() { /* The following tasks must be run before we authenticate */ enableK8sAuth(); // Now we can login using k8s - must run within a k8s cluster (or you need the k8s configuration files locally) workWithSecrets(); // Now back to token based Vault, as we will clean up disableK8sAuth(); return \"k8s example finished successfully.\"; } private void workWithSecrets() { Kv2Secrets secrets = k8sVault.secrets(Kv2Secrets.ENGINE); secrets.create(SECRET_PATH, Map.of(\"secret-key\", \"secretValue\", \"secret-user\", \"username\")); Optional&lt;Kv2Secret&gt; secret = secrets.get(SECRET_PATH); if (secret.isPresent()) { Kv2Secret kv2Secret = secret.get(); System.out.println(\"k8s first secret: \" + kv2Secret.value(\"secret-key\")); System.out.println(\"k8s second secret: \" + kv2Secret.value(\"secret-user\")); } else { System.out.println(\"k8s secret not found\"); } secrets.deleteAll(SECRET_PATH); } private void disableK8sAuth() { sys.deletePolicy(POLICY_NAME); sys.disableAuth(K8sAuth.AUTH_METHOD.defaultPath()); } private void enableK8sAuth() { // enable the method sys.enableAuth(K8sAuth.AUTH_METHOD); sys.createPolicy(POLICY_NAME, VaultPolicy.POLICY); tokenVault.auth(K8sAuth.AUTH_METHOD) .configure(ConfigureK8s.Request.builder() .address(k8sAddress)); tokenVault.auth(K8sAuth.AUTH_METHOD) // this must be the same role name as is defined in application.yaml .createRole(CreateRole.Request.builder() .roleName(\"my-role\") .addBoundServiceAccountName(\"*\") .addBoundServiceAccountNamespace(\"default\") .addTokenPolicy(POLICY_NAME)); k8sVault = Vault.create(config); } } Run the Kubernetes Authentication by enabling it. Create Kubernetes secrets. Disable Kubernetes authentication if needed. Function used to enable Kubernetes authentication. ",
            "title": "Examples"
        },
        {
            "location": "/se/integrations/hcv",
            "text": " Vault is available as a docker image, so to test locally, you can simply: <markup lang=\"bash\" >docker run -e VAULT_DEV_ROOT_TOKEN_ID=my-token -d --name=vault -p8200:8200 vault This will create a Vault docker image, run it in background and open it on localhost:8200 with a custom root token my-token, using name vault. This is of course only suitable for local testing, as the root token has too many rights, but it can be easily used with the examples below. ",
            "title": "Local testing"
        },
        {
            "location": "/se/integrations/hcv",
            "text": " Hashicorp Vault Usage Examples ",
            "title": "References"
        },
        {
            "location": "/se/integrations/neo4j",
            "text": " Overview Maven Coordinates Usage Configuration Examples Additional Information References ",
            "title": "Contents"
        },
        {
            "location": "/se/integrations/neo4j",
            "text": " Neo4j is a graph database management system developed by Neo4j, Inc. It is an ACID-compliant transactional database with native graph storage and processing. Neo4j is available in a GPL3-licensed open-source “community edition”. ",
            "title": "Overview"
        },
        {
            "location": "/se/integrations/neo4j",
            "text": " To enable Neo4j add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.neo4j&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-neo4j&lt;/artifactId&gt; &lt;/dependency&gt; Check Neo4j Metrics propagation and Neo4j Health Checks for additional dependencies for Neo4j Metrics and Health Checks integration. ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/integrations/neo4j",
            "text": " The support for Neo4j is implemented in Neo4j driver level. Just add the dependency, add configuration in application.yaml file and Neo4j driver will be configured by Helidon and can be used with Neo4j support object. First describe Neo4j connection properties: <markup lang=\"properties\" >neo4j: uri: bolt://localhost:7687 authentication: username: neo4j password: secret pool: metricsEnabled: true Then just get the driver: <markup lang=\"java\" >Neo4j neo4j = Neo4j.create(config.get(\"neo4j\")); Driver neo4jDriver = neo4j.driver(); The driver can be used according to the Neo4j documentation . ",
            "title": "Usage"
        },
        {
            "location": "/se/integrations/neo4j",
            "text": " Optional configuration options key type default value description authentication-enabled boolean true Enable authentication. certificate Path &#160; Set certificate path. connection-acquisition-timeout Duration PT1MS Set connection acquisition timeout. encrypted boolean &#160; Enable encrypted field. hostname-verification-enabled boolean &#160; Enable hostname verification. idle-time-before-connection-test Duration PT-1MS Set idle time. log-leaked-sessions boolean &#160; Enable log leaked sessions. max-connection-lifetime Duration PT5H Set max life time. max-connection-pool-size int 100 Set pool size. metrics-enabled boolean &#160; Enable metrics. password string &#160; Create password. trust-strategy TrustStrategy (TRUST_ALL_CERTIFICATES, TRUST_CUSTOM_CA_SIGNED_CERTIFICATES, TRUST_SYSTEM_CA_SIGNED_CERTIFICATES) &#160; Set trust strategy. uri string &#160; Create uri. username string &#160; Create username. ",
            "title": "Configuration options"
        },
        {
            "location": "/se/integrations/neo4j",
            "text": " Type: io.helidon.integrations.neo4j.Neo4j Configuration options Optional configuration options key type default value description authentication-enabled boolean true Enable authentication. certificate Path &#160; Set certificate path. connection-acquisition-timeout Duration PT1MS Set connection acquisition timeout. encrypted boolean &#160; Enable encrypted field. hostname-verification-enabled boolean &#160; Enable hostname verification. idle-time-before-connection-test Duration PT-1MS Set idle time. log-leaked-sessions boolean &#160; Enable log leaked sessions. max-connection-lifetime Duration PT5H Set max life time. max-connection-pool-size int 100 Set pool size. metrics-enabled boolean &#160; Enable metrics. password string &#160; Create password. trust-strategy TrustStrategy (TRUST_ALL_CERTIFICATES, TRUST_CUSTOM_CA_SIGNED_CERTIFICATES, TRUST_SYSTEM_CA_SIGNED_CERTIFICATES) &#160; Set trust strategy. uri string &#160; Create uri. username string &#160; Create username. ",
            "title": "Configuration"
        },
        {
            "location": "/se/integrations/neo4j",
            "text": " This example implements a simple Neo4j REST service using MicroProfile. For this example a working Neo4j database is required. The Neo4j Movie database is used for this example. Bring up a Neo4j instance via Docker <markup lang=\"bash\" >docker run --publish=7474:7474 --publish=7687:7687 -e 'NEO4J_AUTH=neo4j/secret' neo4j:latest Go to the Neo4j browser and play the first step of the movies graph: :play movies Now go to the pom.xml and add the following dependencies: <markup lang=\"xml\" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.neo4j&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-neo4j&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.neo4j&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-neo4j-metrics&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.neo4j&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-neo4j-health&lt;/artifactId&gt; &lt;/dependency&gt; Next add the connection configuration properties for Neo4j: <markup lang=\"properties\" >neo4j: uri: bolt://localhost:7687 authentication: username: neo4j password: secret pool: metricsEnabled: true This includes both connection information and enables Neo4j metrics propagation. Finally, we are able to use the Neo4j driver. <markup lang=\"java\" >@ApplicationScoped public class MovieRepository { private final Driver driver; public MovieRepository(Driver driver) { this.driver = driver; } public List&lt;Movie&gt; findAll() { try (var session = driver.session()) { var query = \"\" + \"match (m:Movie) \" + \"match (m) &lt;- [:DIRECTED] - (d:Person) \" + \"match (m) &lt;- [r:ACTED_IN] - (a:Person) \" + \"return m, collect(d) as directors, collect({name:a.name, roles: r.roles}) as actors\"; return session.readTransaction(tx -&gt; tx.run(query).list(r -&gt; { var movieNode = r.get(\"m\").asNode(); var directors = r.get(\"directors\").asList(v -&gt; { var personNode = v.asNode(); return new Person(personNode.get(\"born\").asInt(), personNode.get(\"name\").asString()); }); var actors = r.get(\"actors\").asList(v -&gt; { return new Actor(v.get(\"name\").asString(), v.get(\"roles\").asList(Value::asString)); }); var m = new Movie(movieNode.get(\"title\").asString(), movieNode.get(\"tagline\").asString()); m.setReleased(movieNode.get(\"released\").asInt()); m.setDirectorss(directors); m.setActors(actors); return m; })); } } } Constructor with Neo4j driver parameter Use Neo4j driver to extract all Movies Movies can now be returned as JSON objects: <markup lang=\"java\" >public class MovieService implements HttpService { private final MovieRepository movieRepository; public MovieService(MovieRepository movieRepository) { this.movieRepository = movieRepository; } @Override public void routing(HttpRules rules) { rules.get(\"/api/movies\", this::findMoviesHandler); } private void findMoviesHandler(ServerRequest request, ServerResponse response) { response.send(this.movieRepository.findAll()); } } To use the service, as well as to add metrics and health support the following routing should be created: <markup lang=\"java\" >private static Routing createRouting(Config config) { MetricsSupport metrics = MetricsSupport.create(); Neo4j neo4j = Neo4j.create(config.get(\"neo4j\")); // registers all metrics Neo4jMetricsSupport.builder() .driver(neo4j.driver()) .build() .initialize(); Neo4jHealthCheck healthCheck = Neo4jHealthCheck.create(neo4j.driver()); Driver neo4jDriver = neo4j.driver(); MovieService movieService = new MovieService(new MovieRepository(neo4jDriver)); HealthSupport health = HealthSupport.builder() .add(HealthChecks.healthChecks()) // Adds a convenient set of checks .add(healthCheck) .build(); return Routing.builder() .register(health) // Health at \"/health\" .register(metrics) // Metrics at \"/metrics\" .register(movieService) .build(); } Use of Neo4j support object to initialise and configure the driver. Use of Neo4jMetricsSupport to add Neo4j metrics to /metrics output. Use of Neo4jHealthCheck to add Neo4j health support. Initialize MovieService with Neo4j driver. Register the services in Routing . Now build and run with JDK17+ <markup lang=\"bash\" >mvn package java -jar target/helidon-examples-integration-neo4j-mp.jar Exercise the application: <markup lang=\"bash\" >curl -X GET http://localhost:8080/movies {. . .} # Try health and metrics curl -s -X GET http://localhost:8080/health {\"outcome\":\"UP\",... . . . # Prometheus Format curl -s -X GET http://localhost:8080/metrics # TYPE base:gc_g1_young_generation_count gauge . . . # JSON Format curl -H 'Accept: application/json' -X GET http://localhost:8080/metrics {\"base\":... . . . Full example code is available in Helidon GitHub Repository . ",
            "title": "Examples"
        },
        {
            "location": "/se/integrations/neo4j",
            "text": " Neo4j metrics can be propagated to the user as MicroProfile metrics. This is implemented in a separate Maven module. Just add: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.neo4j&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-neo4j-metrics&lt;/artifactId&gt; &lt;/dependency&gt; Works with Neo4j Integration main dependency described in Maven Coordinates . To enable metrics in Neo4j, add the following property to application.yaml : <markup lang=\"yaml\" >pool: metricsEnabled: true Finally, to initialize metrics run: <markup lang=\"java\" >Neo4jMetricsSupport.builder() .driver(neo4j.driver()) .build() .initialize(); Neo4j metrics will be automatically added to the output of the /metrics endpoint. ",
            "title": "Neo4j Metrics propagation"
        },
        {
            "location": "/se/integrations/neo4j",
            "text": " If your application is highly dependent on Neo4j database, health and liveness checks are essential for this application to work correctly. MicroProfile Health checks for Neo4j are implemented in a separate Maven module: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.neo4j&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-neo4j-health&lt;/artifactId&gt; &lt;/dependency&gt; Works with Neo4j Integration main dependency described in Maven Coordinates . To enable health checks run the following code: <markup lang=\"java\" >Neo4jHealthCheck healthCheck = Neo4jHealthCheck.create(neo4j.driver()); HealthSupport health = HealthSupport.builder() .add(healthCheck) .build(); Health checks for Neo4j will be included in /health endpoint output. ",
            "title": "Neo4j Health Checks"
        },
        {
            "location": "/se/integrations/neo4j",
            "text": " Neo4j Metrics propagation Neo4j metrics can be propagated to the user as MicroProfile metrics. This is implemented in a separate Maven module. Just add: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.neo4j&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-neo4j-metrics&lt;/artifactId&gt; &lt;/dependency&gt; Works with Neo4j Integration main dependency described in Maven Coordinates . To enable metrics in Neo4j, add the following property to application.yaml : <markup lang=\"yaml\" >pool: metricsEnabled: true Finally, to initialize metrics run: <markup lang=\"java\" >Neo4jMetricsSupport.builder() .driver(neo4j.driver()) .build() .initialize(); Neo4j metrics will be automatically added to the output of the /metrics endpoint. Neo4j Health Checks If your application is highly dependent on Neo4j database, health and liveness checks are essential for this application to work correctly. MicroProfile Health checks for Neo4j are implemented in a separate Maven module: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.neo4j&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-neo4j-health&lt;/artifactId&gt; &lt;/dependency&gt; Works with Neo4j Integration main dependency described in Maven Coordinates . To enable health checks run the following code: <markup lang=\"java\" >Neo4jHealthCheck healthCheck = Neo4jHealthCheck.create(neo4j.driver()); HealthSupport health = HealthSupport.builder() .add(healthCheck) .build(); Health checks for Neo4j will be included in /health endpoint output. ",
            "title": "Additional Information"
        },
        {
            "location": "/se/integrations/neo4j",
            "text": " Neo4j official website Neo4j Java developer guide ",
            "title": "References"
        },
        {
            "location": "/se/integrations/oci",
            "text": " Overview Usage Examples References ",
            "title": "Contents"
        },
        {
            "location": "/se/integrations/oci",
            "text": " Helidon SE OCI Integration provides easy access to Oracle Cloud Infrastructure using the OCI Java SDK. ",
            "title": "Overview"
        },
        {
            "location": "/se/integrations/oci",
            "text": " Authentication with OCI is abstracted through AuthenticationDetailsProvider . If your environment is already set up to work with the OCI SDK or the OCI command line, then it is very likely you do not need to do any additional configuration. It is recommended that you do this first, and verify your configuration by using the OCI CLI to access the service. <markup lang=\"java\" >ConfigFile config = ConfigFileReader.parse(\"~/.oci/config\", \"DEFAULT\"); AuthenticationDetailsProvider authProvider = new ConfigFileAuthenticationDetailsProvider(config); You also need to add the following dependency to your application for this <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;com.oracle.oci.sdk&lt;/groupId&gt; &lt;artifactId&gt;oci-java-sdk-common-httpclient-jersey3&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; ",
            "title": "Configuring the OCI SDK Client"
        },
        {
            "location": "/se/integrations/oci",
            "text": " Once you have authentication with OCI configured, you can use it to access any OCI service supported by the OCI SDK. You will need to add dependencies for the specific ODI SDK clients you will use. ",
            "title": "Accessing OCI Services"
        },
        {
            "location": "/se/integrations/oci",
            "text": " It is recommended that you use the OCI Java SDK directly, in particular the Async clients. All you need to do is configure and create an OCI SDK Client object. The configuration primarily consists of setting up authenticate with OCI. Configuring the OCI SDK Client Authentication with OCI is abstracted through AuthenticationDetailsProvider . If your environment is already set up to work with the OCI SDK or the OCI command line, then it is very likely you do not need to do any additional configuration. It is recommended that you do this first, and verify your configuration by using the OCI CLI to access the service. <markup lang=\"java\" >ConfigFile config = ConfigFileReader.parse(\"~/.oci/config\", \"DEFAULT\"); AuthenticationDetailsProvider authProvider = new ConfigFileAuthenticationDetailsProvider(config); You also need to add the following dependency to your application for this <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;com.oracle.oci.sdk&lt;/groupId&gt; &lt;artifactId&gt;oci-java-sdk-common-httpclient-jersey3&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; Accessing OCI Services Once you have authentication with OCI configured, you can use it to access any OCI service supported by the OCI SDK. You will need to add dependencies for the specific ODI SDK clients you will use. ",
            "title": "Usage"
        },
        {
            "location": "/se/integrations/oci",
            "text": " Now you can create OCI SDK Clients. <markup lang=\"java\" >ConfigFile config = ConfigFileReader.parse(\"~/.oci/config\", \"DEFAULT\"); AuthenticationDetailsProvider authProvider = new ConfigFileAuthenticationDetailsProvider(config); ObjectStorageAsync objectStorageAsyncClient = new ObjectStorageAsyncClient(authProvider); ",
            "title": "Creating an Object Storage Client"
        },
        {
            "location": "/se/integrations/oci",
            "text": " Once you have created an ObjectStorage client you can use it as described in: OCI SDK Object Storage Javadocs OCI Object Storage Overview ",
            "title": "Using the Object Storage client"
        },
        {
            "location": "/se/integrations/oci",
            "text": " This example describes how to access OCI Object Storage. As mentioned above in , you need to add a dependency on the OCI SDK Object Storage API: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;com.oracle.oci.sdk&lt;/groupId&gt; &lt;artifactId&gt;oci-java-sdk-objectstorage&lt;/artifactId&gt; &lt;/dependency&gt; Creating an Object Storage Client Now you can create OCI SDK Clients. <markup lang=\"java\" >ConfigFile config = ConfigFileReader.parse(\"~/.oci/config\", \"DEFAULT\"); AuthenticationDetailsProvider authProvider = new ConfigFileAuthenticationDetailsProvider(config); ObjectStorageAsync objectStorageAsyncClient = new ObjectStorageAsyncClient(authProvider); Using the Object Storage client Once you have created an ObjectStorage client you can use it as described in: OCI SDK Object Storage Javadocs OCI Object Storage Overview ",
            "title": "Examples"
        },
        {
            "location": "/se/integrations/oci",
            "text": " OCI SDK Usage Examples OCI Documentation ] ",
            "title": "References"
        },
        {
            "location": "/se/introduction",
            "text": " Helidon SE is Helidon&#8217;s foundational set of APIs and, as of Helidon 4, it uses virtual threads to enable these APIs to change from asynchronous to blocking. ",
            "title": "preambule"
        },
        {
            "location": "/se/introduction",
            "text": " The REST framework for Helidon SE is the Helidon WebServer. It was built from the ground up to take full advantage of Java 21&#8217;s virtual threads. Helidon SE supports a number of additional Helidon features: settings Config A flexible configuration framework with support for multiple sources and formats. share CORS Add support for CORS to your application using a Helidon module. storage DB Client Provides a unified, reactive API for working with databases in non-blocking way. graphic_eq GraphQL Build GraphQL servers. swap_horiz gRPC Build gRPC servers and clients. favorite_outline Health Checks Expose health statuses of your applications. av_timer Metrics Instrumentation to expose metrics of your applications. donut_large OpenAPI Support OpenAPI from your application. message Reactive Messaging Use prepared tools for repetitive use case scenarios. waves Reactive Streams APIs to work with reactive streams in Helidon. security Security A tool-chain to handle authentication, authorization and context propagation. timeline Tracing Profile and monitor your applications across multiple services. http WebClient HTTP client that handles responses to the HTTP requests. settings_ethernet WebServer A programmatic HTTP API that uses virtual threads to handle nearly unlimited concurrent requests without blocking a platform thread or starving other requests. sync_alt WebSocket Enables Java applications to participate in WebSocket interactions as both servers and clients. ",
            "title": "Components"
        },
        {
            "location": "/se/introduction",
            "text": " In case you need to upgrade the version of Helidon, follow the upgrade guides: upgrade Helidon SE 4x Upgrade Guide Follow this guide to migrate your application from Helidon 3.x to 4.x. upgrade Helidon SE 3x Upgrade Guide Follow this guide to migrate your application from Helidon 2.x to 3.x. upgrade Helidon SE 2.x Upgrade Guide Follow this guide to migrate your application from Helidon 1.x to 2.x. ",
            "title": "Upgrade"
        },
        {
            "location": "/se/introduction",
            "text": " Try the Helidon SE quickstart guides to get your first Helidon SE application up and running in minutes. explore Guides Follow step-by-step guides to build your applications using Helidon SE. library_books Javadocs Browse the Helidon Javadocs. ",
            "title": "Next Steps"
        },
        {
            "location": "/se/metrics/metrics-capable-components",
            "text": " Overview Usage Examples ",
            "title": "Contents"
        },
        {
            "location": "/se/metrics/metrics-capable-components",
            "text": " The Helidon metrics API This API allows your code to register, look-up, remove, and update metrics using the RegistryFactory , MetricRegistry , and individual metrics interfaces. The Helidon metrics REST service API This API allows your code to set up and respond to the /metrics endpoint so clients can retreive metrics information. ",
            "title": "APIs"
        },
        {
            "location": "/se/metrics/metrics-capable-components",
            "text": " Implementations of the Helidon metrics API. Helidon provides two&#8212;&#8203;minimal and full-featured&#8212;&#8203;and selects which one to use at runtime, based on what components are present on the runtime path and whether metrics is configured to be enabled or disabled. You control which implementation your Helidon SE service uses by which dependency you add to your project. Implementations of the Helidon metrics REST service API. Helidon provides two&#8212;&#8203;minimal and full-featured&#8212;&#8203;and selects which one to use at runtime. Your Helidon SE app provides this feature (if at all) by explicitly using the MetricsSupport interface. Most Helidon SE applications are web-based and their developers choose to expose the built-in metrics web service. But by separating the parts of metrics this way, Helidon allows non-web apps to work with metrics as well, just without the web service support. As you plan and write Helidon components and applications, you make some choices about exactly how your code will use metrics. This document gives some background information, describes each option and its effect, and provides some code examples. ",
            "title": "Implementations of the APIs"
        },
        {
            "location": "/se/metrics/metrics-capable-components",
            "text": " This document explains Helidon SE metrics-capable components and applications and describes how to create and control them. Think of Helidon metrics in several related but different parts: APIs The Helidon metrics API This API allows your code to register, look-up, remove, and update metrics using the RegistryFactory , MetricRegistry , and individual metrics interfaces. The Helidon metrics REST service API This API allows your code to set up and respond to the /metrics endpoint so clients can retreive metrics information. Implementations of the APIs Implementations of the Helidon metrics API. Helidon provides two&#8212;&#8203;minimal and full-featured&#8212;&#8203;and selects which one to use at runtime, based on what components are present on the runtime path and whether metrics is configured to be enabled or disabled. You control which implementation your Helidon SE service uses by which dependency you add to your project. Implementations of the Helidon metrics REST service API. Helidon provides two&#8212;&#8203;minimal and full-featured&#8212;&#8203;and selects which one to use at runtime. Your Helidon SE app provides this feature (if at all) by explicitly using the MetricsSupport interface. Most Helidon SE applications are web-based and their developers choose to expose the built-in metrics web service. But by separating the parts of metrics this way, Helidon allows non-web apps to work with metrics as well, just without the web service support. As you plan and write Helidon components and applications, you make some choices about exactly how your code will use metrics. This document gives some background information, describes each option and its effect, and provides some code examples. ",
            "title": "Overview"
        },
        {
            "location": "/se/metrics/metrics-capable-components",
            "text": " We can place each Helidon component and Helidon application into one of three categories based on how it relies on metrics. The type of module dictates the compile-time dependency you declare in the project pom.xml . Types of Metrics Usage Registers, updates, removes metrics? Refers to metrics values? Category times times metrics-independent check times metrics-capable check check metrics-dependent Whenever possible, if your component or application uses metrics, then write it as metrics-capable code. ",
            "title": "Categorizing Metrics Usage"
        },
        {
            "location": "/se/metrics/metrics-capable-components",
            "text": " Helidon provides two metrics implementations: Full-featured metrics allows registering, removing, and updating metrics and observing metrics' changing values. The helidon-metrics component contains full-featured metrics. Minimal metrics supports registering, removing, and updating metrics. The metrics objects provided by the minimal implementation are no-ops: their values never change. The minimal implementation is part of the helidon-metrics-api component. Any code compiled with helidon-metrics-api can assume that the runtime path will include the minimal implementation. Both implementations support all the operations of the RegistryFactory and the MetricRegistry . The full implementation provides fully-functional metrics instances (counters, timers, etc.). In the minimal implementations, metrics do not update their values. For Helidon to use the full implementation, two conditions must hold: The helidon-metrics component must be on the runtime path. Metrics must be enabled, using either a builder or configuration. (Enabled is the default.) Otherwise, provided that the runtime path includes helidon-metrics-api , Helidon activates the minimal implementation. ",
            "title": "Understanding the Two Metrics Implementations"
        },
        {
            "location": "/se/metrics/metrics-capable-components",
            "text": " Helidon includes two implementations of support for the metrics web service endpoint /metrics (or whatever context value is configured). The full-service implementation sends responses which describe the metadata and current values for the metrics registered in metric registries. The helidon-metrics component contains this implementation. The helidon-metrics-service-api component contains the API for the metrics web service support (the MetricsSupport interface) and also a minimal implementation. This implementation simply responds with 404 and an explanatory message that metrics are disabled. Any code compiled with helidon-metrics-service-api can assume that the runtime path will contain the minimal implementation. Helidon activates the full implementation if the runtime path includes the full implementation and metrics is configured as enabled; Helidon uses the minimal implementation otherwise. ",
            "title": "Understanding the Two Metrics Service Implementations"
        },
        {
            "location": "/se/metrics/metrics-capable-components",
            "text": " Using either builder-style settings or configuration, your component or Helidon SE application can let end users control at runtime whether Helidon should use full-featured metrics. If an end user sets metrics.enabled to false , then Helidon activates the minimal metrics and metrics service implementations provided they are in the runtime path. Further, users can set component-name.metrics.enabled to false which disables metrics for just that component so long as the component was written to check that setting and act on it accordingly. ",
            "title": "Enabling and Disabling Metrics"
        },
        {
            "location": "/se/metrics/metrics-capable-components",
            "text": " Include this dependency: <markup lang=\"xml\" title=\"Dependency for Helidon metrics API\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics-api&lt;/artifactId&gt; &lt;/dependency&gt; This module defines the metrics API: RegistryFactory , MetricRegistry , and the various metrics themselves. To permit the use of the built-in metrics web service support for the /metrics endpoint, add this dependency: <markup lang=\"xml\" title=\"Dependency for metrics web service support\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics-service-api&lt;/artifactId&gt; &lt;/dependency&gt; This module defines the metrics web service API: MetricsSupport . Use the MetricsSupport interface from helidon-metrics-service-api in your SE app initialization code to create a service you can register with the web server. (See the example below .) Declare an explicit runtime dependency on the full-featured metrics implementation: <markup lang=\"xml\" title=\"Dependency for full metrics and metrics service implementations\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; ",
            "title": "Declaring Dependencies"
        },
        {
            "location": "/se/metrics/metrics-capable-components",
            "text": " Whoever packages and deploys your application or component can control what code will be on the runtime path and whether metrics is enabled or not. As a result, wherever possible, construct your modules which use metrics so that they do not make decisions based on the values of metrics; that is, design them to be metrics-capable, not metrics-dependent. Doing so allows your code to operate regardless of whether the full-featured metrics implementation is active at runtime. Declaring Dependencies Include this dependency: <markup lang=\"xml\" title=\"Dependency for Helidon metrics API\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics-api&lt;/artifactId&gt; &lt;/dependency&gt; This module defines the metrics API: RegistryFactory , MetricRegistry , and the various metrics themselves. To permit the use of the built-in metrics web service support for the /metrics endpoint, add this dependency: <markup lang=\"xml\" title=\"Dependency for metrics web service support\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics-service-api&lt;/artifactId&gt; &lt;/dependency&gt; This module defines the metrics web service API: MetricsSupport . Use the MetricsSupport interface from helidon-metrics-service-api in your SE app initialization code to create a service you can register with the web server. (See the example below .) Declare an explicit runtime dependency on the full-featured metrics implementation: <markup lang=\"xml\" title=\"Dependency for full metrics and metrics service implementations\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; ",
            "title": "Designing and Writing Metrics-capable Applications and Components"
        },
        {
            "location": "/se/metrics/metrics-capable-components",
            "text": " Write your SE application similarly, but do not use the ComponentMetricsSettings . Instead, build a MetricsSettings object from the configuration. <markup lang=\"java\" title=\"Example code to support disabling metrics usage in a component\" >import io.helidon.config.Config; import io.helidon.metrics.api.MetricsSettings; import io.helidon.metrics.api.RegistryFactory; import io.helidon.webserver.WebServer; import org.eclipse.microprofile.metrics.MetricRegistry; public class MyApp { private static MetricsSettings metricsSettings; static MetricRegistry metricRegistry; public static void main(final String[] args) { startServer(); } static Single&lt;WebServer&gt; startServer() { Config config = Config.create(); metricsSettings = MetricsSettings.builder() .config(config) .build(); metricRegistry = RegistryFactory.getInstance(metricsSettings) .getRegistry(MetricRegistry.Type.APPLICATION); WebServer server = WebServer.builder(createRouting(config)) .config(config.get(\"server\")) .addMediaSupport(JsonpSupport.create()) .build(); return server.start(); } private static Routing createRouting(Config config) { RestServiceSettings restServiceSettings = RestServiceSettings.create(config); MetricsSupport metricsSupport = MetricsSupport.create(metricsSettings, restServiceSettings); GreetService greetService = new GreetService(config); return Routing.builder() .register(metricsSupport) .register(\"/greet\", greetService) .build(); } } Create and save MetricsSettings from config. Use MetricsSettings to get a suitable RegistryFactory , and use that to get the application registry. Pass config to createRouting which returns the Routing to initialize the web server. Use the config to create RestServiceSettings which controls the routing name, web context, and CORS set-up for the metrics endpoint. Create the MetricsSupport instance using the metrics and REST service settings. Add the properly initialized MetricsSupport instance as a service to the routing, along with the app&#8217;s own service. Helidon uses the enabled value from MetricsSettings in providing the correct implementations of both the RegistryFactory and the MetricsSupport . ",
            "title": "Writing and Packaging a Metrics-capable Helidon SE Application "
        },
        {
            "location": "/se/metrics/metrics-capable-components",
            "text": " The way you write a metrics-capable module depends on whether it is a component (that is, not an application) or an application . Writing and Packaging a Metrics-capable Helidon SE Application Write your SE application similarly, but do not use the ComponentMetricsSettings . Instead, build a MetricsSettings object from the configuration. <markup lang=\"java\" title=\"Example code to support disabling metrics usage in a component\" >import io.helidon.config.Config; import io.helidon.metrics.api.MetricsSettings; import io.helidon.metrics.api.RegistryFactory; import io.helidon.webserver.WebServer; import org.eclipse.microprofile.metrics.MetricRegistry; public class MyApp { private static MetricsSettings metricsSettings; static MetricRegistry metricRegistry; public static void main(final String[] args) { startServer(); } static Single&lt;WebServer&gt; startServer() { Config config = Config.create(); metricsSettings = MetricsSettings.builder() .config(config) .build(); metricRegistry = RegistryFactory.getInstance(metricsSettings) .getRegistry(MetricRegistry.Type.APPLICATION); WebServer server = WebServer.builder(createRouting(config)) .config(config.get(\"server\")) .addMediaSupport(JsonpSupport.create()) .build(); return server.start(); } private static Routing createRouting(Config config) { RestServiceSettings restServiceSettings = RestServiceSettings.create(config); MetricsSupport metricsSupport = MetricsSupport.create(metricsSettings, restServiceSettings); GreetService greetService = new GreetService(config); return Routing.builder() .register(metricsSupport) .register(\"/greet\", greetService) .build(); } } Create and save MetricsSettings from config. Use MetricsSettings to get a suitable RegistryFactory , and use that to get the application registry. Pass config to createRouting which returns the Routing to initialize the web server. Use the config to create RestServiceSettings which controls the routing name, web context, and CORS set-up for the metrics endpoint. Create the MetricsSupport instance using the metrics and REST service settings. Add the properly initialized MetricsSupport instance as a service to the routing, along with the app&#8217;s own service. Helidon uses the enabled value from MetricsSettings in providing the correct implementations of both the RegistryFactory and the MetricsSupport . ",
            "title": "Writing Metrics-capable Code"
        },
        {
            "location": "/se/metrics/metrics-capable-components",
            "text": " This section helps you decide how incorporate metrics into your software by describing the categories of metrics usage, explaining generally how Helidon implements metrics, and illustrating how to write the metrics-related code accordingly. Categorizing Metrics Usage We can place each Helidon component and Helidon application into one of three categories based on how it relies on metrics. The type of module dictates the compile-time dependency you declare in the project pom.xml . Types of Metrics Usage Registers, updates, removes metrics? Refers to metrics values? Category times times metrics-independent check times metrics-capable check check metrics-dependent Whenever possible, if your component or application uses metrics, then write it as metrics-capable code. Understanding the Two Metrics Implementations Helidon provides two metrics implementations: Full-featured metrics allows registering, removing, and updating metrics and observing metrics' changing values. The helidon-metrics component contains full-featured metrics. Minimal metrics supports registering, removing, and updating metrics. The metrics objects provided by the minimal implementation are no-ops: their values never change. The minimal implementation is part of the helidon-metrics-api component. Any code compiled with helidon-metrics-api can assume that the runtime path will include the minimal implementation. Both implementations support all the operations of the RegistryFactory and the MetricRegistry . The full implementation provides fully-functional metrics instances (counters, timers, etc.). In the minimal implementations, metrics do not update their values. For Helidon to use the full implementation, two conditions must hold: The helidon-metrics component must be on the runtime path. Metrics must be enabled, using either a builder or configuration. (Enabled is the default.) Otherwise, provided that the runtime path includes helidon-metrics-api , Helidon activates the minimal implementation. Understanding the Two Metrics Service Implementations Helidon includes two implementations of support for the metrics web service endpoint /metrics (or whatever context value is configured). The full-service implementation sends responses which describe the metadata and current values for the metrics registered in metric registries. The helidon-metrics component contains this implementation. The helidon-metrics-service-api component contains the API for the metrics web service support (the MetricsSupport interface) and also a minimal implementation. This implementation simply responds with 404 and an explanatory message that metrics are disabled. Any code compiled with helidon-metrics-service-api can assume that the runtime path will contain the minimal implementation. Helidon activates the full implementation if the runtime path includes the full implementation and metrics is configured as enabled; Helidon uses the minimal implementation otherwise. Enabling and Disabling Metrics Using either builder-style settings or configuration, your component or Helidon SE application can let end users control at runtime whether Helidon should use full-featured metrics. If an end user sets metrics.enabled to false , then Helidon activates the minimal metrics and metrics service implementations provided they are in the runtime path. Further, users can set component-name.metrics.enabled to false which disables metrics for just that component so long as the component was written to check that setting and act on it accordingly. Designing and Writing Metrics-capable Applications and Components Whoever packages and deploys your application or component can control what code will be on the runtime path and whether metrics is enabled or not. As a result, wherever possible, construct your modules which use metrics so that they do not make decisions based on the values of metrics; that is, design them to be metrics-capable, not metrics-dependent. Doing so allows your code to operate regardless of whether the full-featured metrics implementation is active at runtime. Declaring Dependencies Include this dependency: <markup lang=\"xml\" title=\"Dependency for Helidon metrics API\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics-api&lt;/artifactId&gt; &lt;/dependency&gt; This module defines the metrics API: RegistryFactory , MetricRegistry , and the various metrics themselves. To permit the use of the built-in metrics web service support for the /metrics endpoint, add this dependency: <markup lang=\"xml\" title=\"Dependency for metrics web service support\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics-service-api&lt;/artifactId&gt; &lt;/dependency&gt; This module defines the metrics web service API: MetricsSupport . Use the MetricsSupport interface from helidon-metrics-service-api in your SE app initialization code to create a service you can register with the web server. (See the example below .) Declare an explicit runtime dependency on the full-featured metrics implementation: <markup lang=\"xml\" title=\"Dependency for full metrics and metrics service implementations\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; Writing Metrics-capable Code The way you write a metrics-capable module depends on whether it is a component (that is, not an application) or an application . Writing and Packaging a Metrics-capable Helidon SE Application Write your SE application similarly, but do not use the ComponentMetricsSettings . Instead, build a MetricsSettings object from the configuration. <markup lang=\"java\" title=\"Example code to support disabling metrics usage in a component\" >import io.helidon.config.Config; import io.helidon.metrics.api.MetricsSettings; import io.helidon.metrics.api.RegistryFactory; import io.helidon.webserver.WebServer; import org.eclipse.microprofile.metrics.MetricRegistry; public class MyApp { private static MetricsSettings metricsSettings; static MetricRegistry metricRegistry; public static void main(final String[] args) { startServer(); } static Single&lt;WebServer&gt; startServer() { Config config = Config.create(); metricsSettings = MetricsSettings.builder() .config(config) .build(); metricRegistry = RegistryFactory.getInstance(metricsSettings) .getRegistry(MetricRegistry.Type.APPLICATION); WebServer server = WebServer.builder(createRouting(config)) .config(config.get(\"server\")) .addMediaSupport(JsonpSupport.create()) .build(); return server.start(); } private static Routing createRouting(Config config) { RestServiceSettings restServiceSettings = RestServiceSettings.create(config); MetricsSupport metricsSupport = MetricsSupport.create(metricsSettings, restServiceSettings); GreetService greetService = new GreetService(config); return Routing.builder() .register(metricsSupport) .register(\"/greet\", greetService) .build(); } } Create and save MetricsSettings from config. Use MetricsSettings to get a suitable RegistryFactory , and use that to get the application registry. Pass config to createRouting which returns the Routing to initialize the web server. Use the config to create RestServiceSettings which controls the routing name, web context, and CORS set-up for the metrics endpoint. Create the MetricsSupport instance using the metrics and REST service settings. Add the properly initialized MetricsSupport instance as a service to the routing, along with the app&#8217;s own service. Helidon uses the enabled value from MetricsSettings in providing the correct implementations of both the RegistryFactory and the MetricsSupport . ",
            "title": "Usage"
        },
        {
            "location": "/se/metrics/metrics-capable-components",
            "text": " The following example shows how useful metrics-capable code can be in the context of building Docker images. You (or others) could assemble a Docker image with your metrics-capable app as its top layer or your metrics-capable component in a middle layer, built on a lower layer containing several Helidon modules including the full metrics implementation. When that Docker image runs, your app will run with full-featured metrics support. Separately, someone could build a similar Docker image which does not include the Helidon metrics implementation. In this Docker image, your app or component will run successfully but will not incur the overhead of actually updating the metrics it uses. Users can create different Docker images, some with full metrics support and some without, which all use a single version of your metrics-capable app or component which runs properly in either environment without change. ",
            "title": "Examples"
        },
        {
            "location": "/se/metrics/metrics-capable-components",
            "text": " By writing a metrics-capable app or component, you give packagers and deployers of your code the flexibility to include or exclude the full metrics implementation at runtime as they see fit. Because your one module works correctly in either environment: The consumers of your app benefit by not needing to understand and choose between two different implementations of your module, or having to add both your main module and an optional add-on which adds metrics support to your module. You benefit by writing and maintaining a single module, not two: one that is metrics-independent and one that is metrics-dependent. ",
            "title": "Advantages of Writing Metrics-capable Modules"
        },
        {
            "location": "/se/metrics/metrics-capable-components",
            "text": " Advantages of Writing Metrics-capable Modules By writing a metrics-capable app or component, you give packagers and deployers of your code the flexibility to include or exclude the full metrics implementation at runtime as they see fit. Because your one module works correctly in either environment: The consumers of your app benefit by not needing to understand and choose between two different implementations of your module, or having to add both your main module and an optional add-on which adds metrics support to your module. You benefit by writing and maintaining a single module, not two: one that is metrics-independent and one that is metrics-dependent. ",
            "title": "Additional Information"
        },
        {
            "location": "/se/metrics/metrics",
            "text": " Overview Maven Coordinates Usage API Helidon Metrics API Configuration Examples Example Application Code Example Configuration Additional Information Support for the Prometheus Metrics API ",
            "title": "Contents"
        },
        {
            "location": "/se/metrics/metrics",
            "text": " Helidon SE uses the term \"metrics\" to refer to the subsystem in Helidon which manages the registration of, updates to, and reporting of aggregate statistical measurements about the service. The term \"meter\" refers to an entity which collects these measurements, such as a counter or a timer. ",
            "title": "A Word about Terminology"
        },
        {
            "location": "/se/metrics/metrics",
            "text": " Helidon SE metrics is a neutral metrics API which provides a unified way for Helidon servers to export monitoring data&#8212;&#8203;telemetry&#8212;&#8203;to management agents, and a unified Java API which all application programmers can use to register and update meters to expose telemetry data from their services. Metrics is one of the Helidon observability features. A Word about Terminology Helidon SE uses the term \"metrics\" to refer to the subsystem in Helidon which manages the registration of, updates to, and reporting of aggregate statistical measurements about the service. The term \"meter\" refers to an entity which collects these measurements, such as a counter or a timer. ",
            "title": "Overview"
        },
        {
            "location": "/se/metrics/metrics",
            "text": " To enable metrics add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" title=\"Packaging the metrics API\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics-api&lt;/artifactId&gt; &lt;/dependency&gt; This dependency adds the metrics API and a no-op implementation of that API to your project. The no-op implementation: does not register meters in a registry does not update meter values does not expose the metrics endpoint for reporting meter values. To include the full-featured metrics implementation, add the following dependency to your project: <markup lang=\"xml\" title=\"Packaging a full-featured metrics implementation\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webserver.observe&lt;/groupId&gt; &lt;artifactId&gt;helidon-webserver-observe-metrics&lt;/artifactId&gt; &lt;/dependency&gt; Adding this dependency packages the full-featured metrics implementation and support for the metrics endpoint with your service. You might notice the transitive dependency io.helidon.metrics.providers:helidon-metrics-providers-micrometer in your project. This component contains an implementation of the Helidon metrics API that uses Micrometer as the underlying metrics technology. Helidon provides several built-in meters in a separate artifact. To include the build-in meters, add the following dependency to your project: <markup lang=\"xml\" title=\"Packaging the built-in meters\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics-system-meters&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/metrics/metrics",
            "text": " You add meters to your service by writing code which explicitly invokes the metrics API to register meters, retrieve previously-registered meters, and update meter values. Later sections of this document describe how to do this. ",
            "title": "Instrumenting Your Service"
        },
        {
            "location": "/se/metrics/metrics",
            "text": " Helidon distinguishes among scopes , or types, of meters. Helidon includes meters in the built-in scopes described below. Applications often register their own meters in the application scope but can create their own scopes and register meters within them. Built-in meter scopes Built-in Scope Typical Usage base OS or Java runtime measurements (available heap, disk space, etc.). vendor Implemented by vendors, including the REST.request metrics and other key performance indicator measurements (described in later sections). application Declared via annotations or programmatically registered by your service code. When an application creates a new meter it can specify which scope the meter belongs to. If the application does not specify a scope for a new meter, the default scope is application . ",
            "title": "Categorizing Types of Meters"
        },
        {
            "location": "/se/metrics/metrics",
            "text": " Helidon stores all meters in a meter registry . Typically, applications use the global meter registry which is the registry where Helidon stores built-in meters. Application code refers to the global registry using Metrics.globalRegistry() . ",
            "title": "Meter Registry"
        },
        {
            "location": "/se/metrics/metrics",
            "text": " When you add the helidon-webserver-observe-metrics dependency to your project, Helidon automatically provides a built-in REST endpoint /observe/metrics which responds with a report of the registered meters and their values. Clients can request a particular output format. Formats for /observe/metrics output Format Requested by OpenMetrics (Prometheus) default ( text/plain ) JSON Header Accept: application/json Clients can also limit the report by specifying the scope as a query parameter in the request URL: /observe/metrics?scope=base /observe/metrics?scope=vendor /observe/metrics?scope=application Further, clients can narrow down to a specific metric name by adding the name as another query parameter, such as /observe/metrics?scope=application&amp;name=myCount . <markup lang=\"bash\" title=\"Example Reporting: Prometheus format\" >curl -s -H 'Accept: text/plain' -X GET http://localhost:8080/observe/metrics # TYPE base:classloader_total_loaded_class_count counter # HELP base:classloader_total_loaded_class_count Displays the total number of classes that have been loaded since the Java virtual machine has started execution. base:classloader_total_loaded_class_count 3157 <markup lang=\"bash\" title=\"Example Reporting: JSON format\" >curl -s -H 'Accept: application/json' -X GET http://localhost:8080/observe/metrics { \"base\" : { \"memory.maxHeap\" : 3817865216, \"memory.committedHeap\" : 335544320, } } In addition to your application meters, the reports contain other meters of interest such as system and VM information. ",
            "title": "Retrieving Metrics Reports from your Service"
        },
        {
            "location": "/se/metrics/metrics",
            "text": " If you add the dependencies described above, your service automatically supports the metrics REST endpoint as long as the WebServer is configured to discover features automatically. If you disable auto-discovery, you can add the metrics observer explicitly. Create an instance of MetricsObserver , either directly as shown below or using its builder. Include the MetricsObserver instance in your application&#8217;s ObserveFeature . Register your ObserveFeature with your WebServer . <markup lang=\"java\" >Config config = Config.create(); Config.global(config); ObserveFeature observe = ObserveFeature.builder() .config(config.get(\"server.features.observe\")) .addObserver(MetricsObserver.create()) .build(); WebServer server = WebServer.builder() .config(Config.global().get(\"server\")) .featuresDiscoverServices(false) .addFeature(observe) .routing(Main::routing) .build() .start(); ",
            "title": "Enabling the Metrics REST Service"
        },
        {
            "location": "/se/metrics/metrics",
            "text": " Instrumenting Your Service You add meters to your service by writing code which explicitly invokes the metrics API to register meters, retrieve previously-registered meters, and update meter values. Later sections of this document describe how to do this. Categorizing Types of Meters Helidon distinguishes among scopes , or types, of meters. Helidon includes meters in the built-in scopes described below. Applications often register their own meters in the application scope but can create their own scopes and register meters within them. Built-in meter scopes Built-in Scope Typical Usage base OS or Java runtime measurements (available heap, disk space, etc.). vendor Implemented by vendors, including the REST.request metrics and other key performance indicator measurements (described in later sections). application Declared via annotations or programmatically registered by your service code. When an application creates a new meter it can specify which scope the meter belongs to. If the application does not specify a scope for a new meter, the default scope is application . Meter Registry Helidon stores all meters in a meter registry . Typically, applications use the global meter registry which is the registry where Helidon stores built-in meters. Application code refers to the global registry using Metrics.globalRegistry() . Retrieving Metrics Reports from your Service When you add the helidon-webserver-observe-metrics dependency to your project, Helidon automatically provides a built-in REST endpoint /observe/metrics which responds with a report of the registered meters and their values. Clients can request a particular output format. Formats for /observe/metrics output Format Requested by OpenMetrics (Prometheus) default ( text/plain ) JSON Header Accept: application/json Clients can also limit the report by specifying the scope as a query parameter in the request URL: /observe/metrics?scope=base /observe/metrics?scope=vendor /observe/metrics?scope=application Further, clients can narrow down to a specific metric name by adding the name as another query parameter, such as /observe/metrics?scope=application&amp;name=myCount . <markup lang=\"bash\" title=\"Example Reporting: Prometheus format\" >curl -s -H 'Accept: text/plain' -X GET http://localhost:8080/observe/metrics # TYPE base:classloader_total_loaded_class_count counter # HELP base:classloader_total_loaded_class_count Displays the total number of classes that have been loaded since the Java virtual machine has started execution. base:classloader_total_loaded_class_count 3157 <markup lang=\"bash\" title=\"Example Reporting: JSON format\" >curl -s -H 'Accept: application/json' -X GET http://localhost:8080/observe/metrics { \"base\" : { \"memory.maxHeap\" : 3817865216, \"memory.committedHeap\" : 335544320, } } In addition to your application meters, the reports contain other meters of interest such as system and VM information. Enabling the Metrics REST Service If you add the dependencies described above, your service automatically supports the metrics REST endpoint as long as the WebServer is configured to discover features automatically. If you disable auto-discovery, you can add the metrics observer explicitly. Create an instance of MetricsObserver , either directly as shown below or using its builder. Include the MetricsObserver instance in your application&#8217;s ObserveFeature . Register your ObserveFeature with your WebServer . <markup lang=\"java\" >Config config = Config.create(); Config.global(config); ObserveFeature observe = ObserveFeature.builder() .config(config.get(\"server.features.observe\")) .addObserver(MetricsObserver.create()) .build(); WebServer server = WebServer.builder() .config(Config.global().get(\"server\")) .featuresDiscoverServices(false) .addFeature(observe) .routing(Main::routing) .build() .start(); ",
            "title": "Usage"
        },
        {
            "location": "/se/metrics/metrics",
            "text": " The Helidon Metrics API defines the classes and interfaces for meter types and other related items. The following table summarizes the meter types. Meter Types Meter Type Usage Counter Monotonically increasing count of events. Gauge Access to a value managed by other code in the service. DistributionSummary Calculates the distribution of a value. Timer Frequency of invocations and the distribution of how long the invocations take. Each meter type has its own set of methods for updating and retrieving the metric&#8217;s value. ",
            "title": "Helidon Metrics API"
        },
        {
            "location": "/se/metrics/metrics",
            "text": " To register or look up meters programmatically, your service code uses the global MeterRegistry . Simply invoke Metrics.globalRegistry() to get a reference to the global meter registry. To locate an existing meter or register a new one, your code: Creates a builder of the appropriate type of meter, setting the name and possibly other characteristics of the meter. Invokes the MeterRegistry.getOrCreate method, passing the builder. The meter registry returns a reference to a previously-registered meter with the specified name and tags or, if none exists, a newly-registered meter. Your code can then operate on the returned meter as needed to record new measurements or retrieve existing data. The example code in the Examples section below illustrates how to register, retrieve, and update meters. ",
            "title": "The MeterRegistry API"
        },
        {
            "location": "/se/metrics/metrics",
            "text": " To work with Helidon Metrics in your code, follow these steps: Use the static globalRegistry method on the Metrics interface to get a reference to the global MeterRegistry instance. Use the MeterRegistry instance to register new meters and look up previously-registered meters. Use the meter reference returned from the MeterRegistry to update the meter or get its value. You can also use the MeterRegistry to remove an existing meter. Helidon Metrics API The Helidon Metrics API defines the classes and interfaces for meter types and other related items. The following table summarizes the meter types. Meter Types Meter Type Usage Counter Monotonically increasing count of events. Gauge Access to a value managed by other code in the service. DistributionSummary Calculates the distribution of a value. Timer Frequency of invocations and the distribution of how long the invocations take. Each meter type has its own set of methods for updating and retrieving the metric&#8217;s value. The MeterRegistry API To register or look up meters programmatically, your service code uses the global MeterRegistry . Simply invoke Metrics.globalRegistry() to get a reference to the global meter registry. To locate an existing meter or register a new one, your code: Creates a builder of the appropriate type of meter, setting the name and possibly other characteristics of the meter. Invokes the MeterRegistry.getOrCreate method, passing the builder. The meter registry returns a reference to a previously-registered meter with the specified name and tags or, if none exists, a newly-registered meter. Your code can then operate on the returned meter as needed to record new measurements or retrieve existing data. The example code in the Examples section below illustrates how to register, retrieve, and update meters. ",
            "title": "API"
        },
        {
            "location": "/se/metrics/metrics",
            "text": " Optional configuration options key type default value description app-name string &#160; Value for the application tag to be added to each meter ID. @return application tag value app-tag-name string &#160; Name for the application tag to be added to each meter ID. @return application tag name enabled boolean true Whether metrics functionality is enabled. @return if metrics are configured to be enabled endpoint string metrics key-performance-indicators KeyPerformanceIndicatorMetricsConfig &#160; Key performance indicator metrics settings. @return key performance indicator metrics settings permit-all boolean &#160; Whether to allow anybody to access the endpoint. @return whether to permit access to metrics endpoint to anybody, defaults to `true` @see #roles() rest-request-enabled boolean &#160; Whether automatic REST request metrics should be measured. @return true/false roles string[&#93; &#160; Hints for role names the user is expected to be in. @return list of hints scoping ScopingConfig &#160; Settings related to scoping management. @return scoping settings tags Tag[&#93; &#160; Global tags. @return name/value pairs for global tags ",
            "title": "Configuration options"
        },
        {
            "location": "/se/metrics/metrics",
            "text": " To control how the Helidon metrics subsystem behaves, add a metrics section to your configuration file, such as application.yaml . Type: io.helidon.webserver.observe.metrics.MetricsObserver This is a standalone configuration type, prefix from configuration root: metrics This type provides the following service implementations: io.helidon.webserver.observe.spi.ObserveProvider Configuration options Optional configuration options key type default value description app-name string &#160; Value for the application tag to be added to each meter ID. @return application tag value app-tag-name string &#160; Name for the application tag to be added to each meter ID. @return application tag name enabled boolean true Whether metrics functionality is enabled. @return if metrics are configured to be enabled endpoint string metrics key-performance-indicators KeyPerformanceIndicatorMetricsConfig &#160; Key performance indicator metrics settings. @return key performance indicator metrics settings permit-all boolean &#160; Whether to allow anybody to access the endpoint. @return whether to permit access to metrics endpoint to anybody, defaults to `true` @see #roles() rest-request-enabled boolean &#160; Whether automatic REST request metrics should be measured. @return true/false roles string[&#93; &#160; Hints for role names the user is expected to be in. @return list of hints scoping ScopingConfig &#160; Settings related to scoping management. @return scoping settings tags Tag[&#93; &#160; Global tags. @return name/value pairs for global tags ",
            "title": "Configuration"
        },
        {
            "location": "/se/metrics/metrics",
            "text": " The following example, based on the Helidon SE QuickStart application, shows how to register and update a new Counter in application code. The counter tracks the number of times any of the service endpoints is accessed. <markup lang=\"java\" title=\"Define and use a Counter \" >import io.helidon.metrics.api.Counter; //... public class GreetService implements HttpService { private final Counter accessCtr = Metrics.globalRegistry() .getOrCreate(Counter.builder(\"accessctr\")); @Override public void routing(HttpRules rules) { rules .any(this::countAccess) .get(\"/\", this::getDefaultMessageHandler) .get(\"/{name}\", this::getMessageHandler) .put(\"/greeting\", this::updateGreetingHandler) } private void countAccess(ServerRequest request, ServerResponse response) { accessCtr.inc(); request.next(); } } Get the global meter registry. Create (or find) a counter named \"accessctr\" in the global registry. Route every request to the countAccess method. Increment the access counter for every request. Perform the following steps to see the new counter in action. <markup lang=\"bash\" title=\"Build and run the application\" >mvn package java -jar target/helidon-quickstart-se.jar <markup title=\"Retrieve application metrics\" >curl 'http://localhost:8080/observe/metrics?scope=application' # HELP accessctr_total # TYPE accessctr_total counter accessctr_total{scope=\"application\",} 0.0 Access the metrics endpoint, selecting only application meters. Note the counter is zero; we have not accessed a service endpoint yet. <markup lang=\"bash\" title=\"Access a service endpoint to retrieve a greeting\" >curl http://localhost:8080/greet {\"message\":\"Hello World\"} <markup lang=\"bash\" title=\"Retrieve application metrics again\" >curl 'http://localhost:8080/observe/metrics?scope=application' # HELP accessctr_total # TYPE accessctr_total counter accessctr_total{scope=\"application\",} 1.0 The counter now reports 1, reflecting our earlier access to the /greet endpoint. ",
            "title": "Example Application Code"
        },
        {
            "location": "/se/metrics/metrics",
            "text": "<markup lang=\"yaml\" title=\"Disabling metrics entirely\" >server: features: observe: observers: metrics: enabled: false Helidon does not update metrics, and the /observe/metrics endpoints respond with 404 .. ",
            "title": "Disable Metrics Subsystem"
        },
        {
            "location": "/se/metrics/metrics",
            "text": " Any time you include the Helidon metrics module in your application, Helidon tracks a basic performance indicator meter: a Counter of all requests received ( requests.count ) Helidon SE also includes additional, extended KPI meters which are disabled by default: current number of requests in-flight - a Gauge ( requests.inFlight ) of requests currently being processed long-running requests - a Counter ( requests.longRunning ) measuring the total number of requests which take at least a given amount of time to complete; configurable, defaults to 10000 milliseconds (10 seconds) load - a Counter ( requests.load ) measuring the number of requests worked on (as opposed to received) deferred - a Gauge ( requests.deferred ) measuring delayed request processing (work on a request was delayed after Helidon received the request) You can enable and control these meters using configuration: <markup lang=\"yaml\" title=\"Controlling extended KPI meters\" >server: features: observe: observers: metrics: key-performance-indicators: extended: true long-running: threshold-ms: 2000 ",
            "title": "Collecting Basic and Extended Key Performance Indicator (KPI) Meters"
        },
        {
            "location": "/se/metrics/metrics",
            "text": " Metrics configuration is quite extensive and powerful and, therefore, a bit complicated. The rest of this section illustrates some of the most common scenarios: Disable metrics entirely. Choose whether to collect extended key performance indicator metrics. Disable Metrics Subsystem <markup lang=\"yaml\" title=\"Disabling metrics entirely\" >server: features: observe: observers: metrics: enabled: false Helidon does not update metrics, and the /observe/metrics endpoints respond with 404 .. Collecting Basic and Extended Key Performance Indicator (KPI) Meters Any time you include the Helidon metrics module in your application, Helidon tracks a basic performance indicator meter: a Counter of all requests received ( requests.count ) Helidon SE also includes additional, extended KPI meters which are disabled by default: current number of requests in-flight - a Gauge ( requests.inFlight ) of requests currently being processed long-running requests - a Counter ( requests.longRunning ) measuring the total number of requests which take at least a given amount of time to complete; configurable, defaults to 10000 milliseconds (10 seconds) load - a Counter ( requests.load ) measuring the number of requests worked on (as opposed to received) deferred - a Gauge ( requests.deferred ) measuring delayed request processing (work on a request was delayed after Helidon received the request) You can enable and control these meters using configuration: <markup lang=\"yaml\" title=\"Controlling extended KPI meters\" >server: features: observe: observers: metrics: key-performance-indicators: extended: true long-running: threshold-ms: 2000 ",
            "title": "Example Configuration"
        },
        {
            "location": "/se/metrics/metrics",
            "text": " Helidon SE includes several prewritten example applications illustrating aspects of metrics: Enabling/disabling meters using MetricsObserver and MetricsConfig Controlling key performance indicator metrics using configuration and KeyPerformanceIndicatorMetricsSettings . The rest of this section shows how to add a custom meter to your code and how to configure the Helidon metrics subsystem. Example Application Code The following example, based on the Helidon SE QuickStart application, shows how to register and update a new Counter in application code. The counter tracks the number of times any of the service endpoints is accessed. <markup lang=\"java\" title=\"Define and use a Counter \" >import io.helidon.metrics.api.Counter; //... public class GreetService implements HttpService { private final Counter accessCtr = Metrics.globalRegistry() .getOrCreate(Counter.builder(\"accessctr\")); @Override public void routing(HttpRules rules) { rules .any(this::countAccess) .get(\"/\", this::getDefaultMessageHandler) .get(\"/{name}\", this::getMessageHandler) .put(\"/greeting\", this::updateGreetingHandler) } private void countAccess(ServerRequest request, ServerResponse response) { accessCtr.inc(); request.next(); } } Get the global meter registry. Create (or find) a counter named \"accessctr\" in the global registry. Route every request to the countAccess method. Increment the access counter for every request. Perform the following steps to see the new counter in action. <markup lang=\"bash\" title=\"Build and run the application\" >mvn package java -jar target/helidon-quickstart-se.jar <markup title=\"Retrieve application metrics\" >curl 'http://localhost:8080/observe/metrics?scope=application' # HELP accessctr_total # TYPE accessctr_total counter accessctr_total{scope=\"application\",} 0.0 Access the metrics endpoint, selecting only application meters. Note the counter is zero; we have not accessed a service endpoint yet. <markup lang=\"bash\" title=\"Access a service endpoint to retrieve a greeting\" >curl http://localhost:8080/greet {\"message\":\"Hello World\"} <markup lang=\"bash\" title=\"Retrieve application metrics again\" >curl 'http://localhost:8080/observe/metrics?scope=application' # HELP accessctr_total # TYPE accessctr_total counter accessctr_total{scope=\"application\",} 1.0 The counter now reports 1, reflecting our earlier access to the /greet endpoint. Example Configuration Metrics configuration is quite extensive and powerful and, therefore, a bit complicated. The rest of this section illustrates some of the most common scenarios: Disable metrics entirely. Choose whether to collect extended key performance indicator metrics. Disable Metrics Subsystem <markup lang=\"yaml\" title=\"Disabling metrics entirely\" >server: features: observe: observers: metrics: enabled: false Helidon does not update metrics, and the /observe/metrics endpoints respond with 404 .. Collecting Basic and Extended Key Performance Indicator (KPI) Meters Any time you include the Helidon metrics module in your application, Helidon tracks a basic performance indicator meter: a Counter of all requests received ( requests.count ) Helidon SE also includes additional, extended KPI meters which are disabled by default: current number of requests in-flight - a Gauge ( requests.inFlight ) of requests currently being processed long-running requests - a Counter ( requests.longRunning ) measuring the total number of requests which take at least a given amount of time to complete; configurable, defaults to 10000 milliseconds (10 seconds) load - a Counter ( requests.load ) measuring the number of requests worked on (as opposed to received) deferred - a Gauge ( requests.deferred ) measuring delayed request processing (work on a request was delayed after Helidon received the request) You can enable and control these meters using configuration: <markup lang=\"yaml\" title=\"Controlling extended KPI meters\" >server: features: observe: observers: metrics: key-performance-indicators: extended: true long-running: threshold-ms: 2000 ",
            "title": "Examples"
        },
        {
            "location": "/se/metrics/metrics",
            "text": "<markup lang=\"xml\" title=\"Dependency for Helidon Prometheus API support\" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics-prometheus&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/metrics/metrics",
            "text": " Your application code uses the Prometheus API to manage metrics. To expose those metrics to clients via a REST endpoint, your code uses the PrometheusSupport interface which Helidon provides. ",
            "title": "Usage"
        },
        {
            "location": "/se/metrics/metrics",
            "text": " Your code creates a PrometheusSupport object either using a static factory method (shown in the following example) or by using its Builder . <markup lang=\"java\" >import io.helidon.metrics.prometheus.PrometheusSupport; routing .register(PrometheusSupport.create()) .register(\"/myapp\", new MyService()); This example uses the default Prometheus CollectorRegistry . By default, the PrometheusSupport and exposes its REST endpoint at the path /metrics . Use the builder obtained by PrometheusSupport.builder() to configure a different CollectorRegistry or a different path. ",
            "title": "API"
        },
        {
            "location": "/se/metrics/metrics",
            "text": " Maven Coordinates Usage API Helidon provides optional support for the Prometheus metrics API. To use it, your service registers Prometheus support with your routing set-up. You can customize its configuration. For information about using Prometheus, see the Prometheus documentation: https://prometheus.io/docs/introduction/overview/ . Helidon&#8217;s fully-functional, built-in metrics implementation supports Prometheus (OpenMetrics) output. Use the optional support described in this section only if you want to use the Prometheus API from your application code. Maven Coordinates <markup lang=\"xml\" title=\"Dependency for Helidon Prometheus API support\" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics-prometheus&lt;/artifactId&gt; &lt;/dependency&gt; Usage Your application code uses the Prometheus API to manage metrics. To expose those metrics to clients via a REST endpoint, your code uses the PrometheusSupport interface which Helidon provides. API Your code creates a PrometheusSupport object either using a static factory method (shown in the following example) or by using its Builder . <markup lang=\"java\" >import io.helidon.metrics.prometheus.PrometheusSupport; routing .register(PrometheusSupport.create()) .register(\"/myapp\", new MyService()); This example uses the default Prometheus CollectorRegistry . By default, the PrometheusSupport and exposes its REST endpoint at the path /metrics . Use the builder obtained by PrometheusSupport.builder() to configure a different CollectorRegistry or a different path. ",
            "title": "Support for the Prometheus Metrics API"
        },
        {
            "location": "/se/metrics/metrics",
            "text": " Support for the Prometheus Metrics API Maven Coordinates Usage API Helidon provides optional support for the Prometheus metrics API. To use it, your service registers Prometheus support with your routing set-up. You can customize its configuration. For information about using Prometheus, see the Prometheus documentation: https://prometheus.io/docs/introduction/overview/ . Helidon&#8217;s fully-functional, built-in metrics implementation supports Prometheus (OpenMetrics) output. Use the optional support described in this section only if you want to use the Prometheus API from your application code. Maven Coordinates <markup lang=\"xml\" title=\"Dependency for Helidon Prometheus API support\" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics-prometheus&lt;/artifactId&gt; &lt;/dependency&gt; Usage Your application code uses the Prometheus API to manage metrics. To expose those metrics to clients via a REST endpoint, your code uses the PrometheusSupport interface which Helidon provides. API Your code creates a PrometheusSupport object either using a static factory method (shown in the following example) or by using its Builder . <markup lang=\"java\" >import io.helidon.metrics.prometheus.PrometheusSupport; routing .register(PrometheusSupport.create()) .register(\"/myapp\", new MyService()); This example uses the default Prometheus CollectorRegistry . By default, the PrometheusSupport and exposes its REST endpoint at the path /metrics . Use the builder obtained by PrometheusSupport.builder() to configure a different CollectorRegistry or a different path. ",
            "title": "Additional Information"
        },
        {
            "location": "/se/metrics/micrometer",
            "text": " Overview Maven Coordinates Usage Registering and Updating Meters Accessing the Helidon Micrometer Endpoint API The Helidon Micrometer API Configuration Examples Register an Instance of MicrometerSupport with the Web Server Create and Update Meters in Your Application Service Additional Information ",
            "title": "Contents"
        },
        {
            "location": "/se/metrics/micrometer",
            "text": " Helidon SE simplifies how you can use Micrometer for application-specific metrics: The endpoint /micrometer : A configurable endpoint that exposes metrics according to which Micrometer meter registry responds to the HTTP request. The MicrometerSupport class: A convenience class for enrolling Micrometer meter registries your application creates explicitly or for selecting which built-in Micrometer meter registries to use. Configuration to tailor the Prometheus and other Micrometer meter registries. In Helidon 4.0.2, Micrometer support is separate from the Helidon SE metrics API and the built-in Helidon metrics. ",
            "title": "Overview"
        },
        {
            "location": "/se/metrics/micrometer",
            "text": " To enable Micrometer support add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.micrometer&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-micrometer&lt;/artifactId&gt; &lt;/dependency&gt; Micrometer supports different types of meter registries which have different output styles and formats. Helidon provides built-in support for the Prometheus meter registry. To use other meter registry types, you will need to add dependencies for them to your pom.xml and, optionally, add code to your application or add configuration to set them up as you wish. ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/metrics/micrometer",
            "text": " Your code can create, look up, and update metrics programmatically using the Micrometer MeterRegistry API. The Micrometer concepts document provides a good starting point for learning how to use Micrometer&#8217;s interfaces and classes. ",
            "title": "Registering and Updating Meters"
        },
        {
            "location": "/se/metrics/micrometer",
            "text": " Your application can easily have Helidon create a REST endpoint which clients can access to retrieve Micrometer metrics, by default at the /micrometer endpoint. Within Helidon, each type of meter registry is paired with some code that examines the incoming HTTP request to /micrometer and decides whether the request matches up with the associated meter registry. The first pairing that accepts the request returns the response. You will need to take advantage of this if your application uses additional meter registries beyond what Helidon automatically provides and you want those meter registries reflected in the output from the /micrometer REST endpoint. ",
            "title": "Accessing the Helidon Micrometer Endpoint"
        },
        {
            "location": "/se/metrics/micrometer",
            "text": " Your application registers and updates Micrometer meters using annotations or direct use of the Micrometer API. Your users retrieve Micrometer meters using an endpoint which Helidon creates automatically. Registering and Updating Meters Your code can create, look up, and update metrics programmatically using the Micrometer MeterRegistry API. The Micrometer concepts document provides a good starting point for learning how to use Micrometer&#8217;s interfaces and classes. Accessing the Helidon Micrometer Endpoint Your application can easily have Helidon create a REST endpoint which clients can access to retrieve Micrometer metrics, by default at the /micrometer endpoint. Within Helidon, each type of meter registry is paired with some code that examines the incoming HTTP request to /micrometer and decides whether the request matches up with the associated meter registry. The first pairing that accepts the request returns the response. You will need to take advantage of this if your application uses additional meter registries beyond what Helidon automatically provides and you want those meter registries reflected in the output from the /micrometer REST endpoint. ",
            "title": "Usage"
        },
        {
            "location": "/se/metrics/micrometer",
            "text": " Helidon provides no special API for dealing with Micrometer meters and meter registries beyond what Micrometer offers itself. Helidon does give you an easy way to expose a REST endpoint to report the meters stored in the Micrometer meter registry. The MicrometerSupport interface exposes static methods to directly create an instance of MicrometerSupport and to return a Builder instance so your code can fine-tune how the REST service behaves. ",
            "title": "The Helidon Micrometer API"
        },
        {
            "location": "/se/metrics/micrometer",
            "text": " The Helidon Micrometer API Helidon provides no special API for dealing with Micrometer meters and meter registries beyond what Micrometer offers itself. Helidon does give you an easy way to expose a REST endpoint to report the meters stored in the Micrometer meter registry. The MicrometerSupport interface exposes static methods to directly create an instance of MicrometerSupport and to return a Builder instance so your code can fine-tune how the REST service behaves. ",
            "title": "API"
        },
        {
            "location": "/se/metrics/micrometer",
            "text": " Optional configuration options key type default value description cross-origin-config CrossOriginConfig &#160; Set the CORS config from the specified CrossOriginConfig object. web-context string &#160; Set the root context for the REST API of the service. By default, Helidon Micrometer integration exposes the /micrometer endpoint. You can override the path using the Builder or the micrometer.web-context configuration key. <markup lang=\"yaml\" title=\"Overriding the default Micrometer path\" >micrometer: web-context: my-micrometer ",
            "title": "Configuration options"
        },
        {
            "location": "/se/metrics/micrometer",
            "text": " You can configure the Helidon Micrometer REST service as you can other built-in Helidon services by adding configuration settings under the micrometer top-level key. Type: io.helidon.integrations.micrometer.MicrometerFeature <markup lang=\"text\" title=\"Config key\" >micrometer Configuration options Optional configuration options key type default value description cross-origin-config CrossOriginConfig &#160; Set the CORS config from the specified CrossOriginConfig object. web-context string &#160; Set the root context for the REST API of the service. By default, Helidon Micrometer integration exposes the /micrometer endpoint. You can override the path using the Builder or the micrometer.web-context configuration key. <markup lang=\"yaml\" title=\"Overriding the default Micrometer path\" >micrometer: web-context: my-micrometer ",
            "title": "Configuration"
        },
        {
            "location": "/se/metrics/micrometer",
            "text": "<markup lang=\"java\" title=\"Initialize Micrometer support\" >import io.helidon.integrations.micrometer.MicrometerSupport; MicrometerSupport micrometerSupport = MicrometerSupport.create(); Routing.builder() .register(micrometerSupport) .register(\"/myapp\", new MyService(micrometerSupport.registry())) .build(); Create the MicrometerSupport instance, using the default built-in Prometheus meter registry. Register the MicrometerSupport instance as a service; by default, MicrometerSupport exposes the endpoint as /micrometer . Pass the MicrometerSupport object&#8217;s meter registry to your service for use in creating and updating meters. ",
            "title": "Register an Instance of MicrometerSupport with the Web Server"
        },
        {
            "location": "/se/metrics/micrometer",
            "text": " Unless you specify otherwise, Helidon uses defaults for any built-in Micrometer meter registry. For example, Helidon configures the built-in Prometheus registry using PrometheusConfig.DEFAULT . You can override these defaults in either of two ways: Using the MicrometerSupport.Builder class Using configuration ",
            "title": "Overriding Defaults for Built-in Meter Registry Types"
        },
        {
            "location": "/se/metrics/micrometer",
            "text": " Use the MicrometerSupport.Builder class to set up Micrometer support however your application needs. The builder lets you: Provide your own Micrometer meter registry configuration that MicrometerSupport uses to create a built-in meter registry, or Instantiate a Micrometer meter registry yourself, configured however you want, and add it to the MicrometerSupport object&#8217;s collection of meter registries <markup lang=\"java\" title=\"Overriding defaults for built-in meter registries using MicrometerSupport.Builder \" >PrometheusConfig myPrometheusConfig = ...; MicrometerSupport support = MicrometerSupport.builder() .enrollBuiltInRegistry( MicrometerSupport.BuiltInRegistryType.PROMETHEUS, myPrometheusConfig) .build(); Create the meter registry configuration however you need. Enroll the PROMETHEUS built-in registry type with your custom configuration. ",
            "title": "Using MicrometerSupport.Builder"
        },
        {
            "location": "/se/metrics/micrometer",
            "text": " To use configuration to control the selection and behavior of Helidon&#8217;s built-in Micrometer meter registries, include in your configuration (such as application.yaml ) a micrometer.builtin-registries section. <markup lang=\"yaml\" title=\"Enroll Prometheus built-in meter registry using default configuration\" >micrometer: builtin-registries: - type: prometheus <markup lang=\"yaml\" title=\"Enroll Prometheus built-in meter registry with non-default configuration\" >micrometer: builtin-registries: - type: prometheus prefix: myPrefix Note that the first config example is equivalent to the default Helidon Micrometer behavior; Helidon by default supports the Prometheus meter registry. The configuration keys that are valid for the builtin-registries child entries depend on the type of Micrometer meter registry. For example, support in Helidon for the Prometheus meter registry respects the prefix configuration setting but other meter registries might not and might support other settings. Refer to the documentation for the meter registry you want to configure to find out what items apply to that registry type. Helidon does not validate the configuration keys you specify for meter registries. ",
            "title": "Using Configuration"
        },
        {
            "location": "/se/metrics/micrometer",
            "text": "<markup lang=\"java\" title=\"Define and use a Counter \" >import io.micrometer.core.instrument.Counter; public class MyService implements HttpService { private final Counter requestCounter; public MyService(MicrometerMeterRegistry registry) { requestCounter = registry.counter(\"allRequests\"); } @Override public void routing(HttpRules rules) { rules .any(this::countRequests) .get(\"/\", this::myGet); } private void countRequests(ServerRequest request, ServerResponse response) { requestCounter.increment(); request.next(); } } Use the Micrometer meter registry to create the request counter. Add routing for any request to invoke the method which counts requests by updating the counter. Update the counter and then delegate the rest of the request processing to the next handler in the chain. The example above enrolls the built-in Prometheus meter registry with the default Prometheus registry configuration. You can change the default setup for built-in registries, and you can enroll other meter registries your application creates itself. Overriding Defaults for Built-in Meter Registry Types Unless you specify otherwise, Helidon uses defaults for any built-in Micrometer meter registry. For example, Helidon configures the built-in Prometheus registry using PrometheusConfig.DEFAULT . You can override these defaults in either of two ways: Using the MicrometerSupport.Builder class Using configuration Using MicrometerSupport.Builder Use the MicrometerSupport.Builder class to set up Micrometer support however your application needs. The builder lets you: Provide your own Micrometer meter registry configuration that MicrometerSupport uses to create a built-in meter registry, or Instantiate a Micrometer meter registry yourself, configured however you want, and add it to the MicrometerSupport object&#8217;s collection of meter registries <markup lang=\"java\" title=\"Overriding defaults for built-in meter registries using MicrometerSupport.Builder \" >PrometheusConfig myPrometheusConfig = ...; MicrometerSupport support = MicrometerSupport.builder() .enrollBuiltInRegistry( MicrometerSupport.BuiltInRegistryType.PROMETHEUS, myPrometheusConfig) .build(); Create the meter registry configuration however you need. Enroll the PROMETHEUS built-in registry type with your custom configuration. Using Configuration To use configuration to control the selection and behavior of Helidon&#8217;s built-in Micrometer meter registries, include in your configuration (such as application.yaml ) a micrometer.builtin-registries section. <markup lang=\"yaml\" title=\"Enroll Prometheus built-in meter registry using default configuration\" >micrometer: builtin-registries: - type: prometheus <markup lang=\"yaml\" title=\"Enroll Prometheus built-in meter registry with non-default configuration\" >micrometer: builtin-registries: - type: prometheus prefix: myPrefix Note that the first config example is equivalent to the default Helidon Micrometer behavior; Helidon by default supports the Prometheus meter registry. The configuration keys that are valid for the builtin-registries child entries depend on the type of Micrometer meter registry. For example, support in Helidon for the Prometheus meter registry respects the prefix configuration setting but other meter registries might not and might support other settings. Refer to the documentation for the meter registry you want to configure to find out what items apply to that registry type. Helidon does not validate the configuration keys you specify for meter registries. ",
            "title": "Create and Update Meters in Your Application Service"
        },
        {
            "location": "/se/metrics/micrometer",
            "text": " To create additional types of registries and enroll them with MicrometerSupport , you need to: Write a Handler Each meter registry has its own way of producing output. Write your handler so that it has a reference to the meter registry it should use and so that its accept method sets the payload in the HTTP response using the registry&#8217;s mechanism for creating output. Write a Function which accepts a ServerRequest and returns an Optional&lt;Handler&gt; Typically, the function examines the request&#8212;&#8203;the Content-Type , query parameters, etc.--to decide whether the corresponding handler should respond to the request. If so, your function should instantiate your Handler and return an Optional.of(theHandlerInstance) ; otherwise, your function should return Optional.empty() . When MicrometerSupport receives a request, it invokes the functions of all the enrolled registries, stopping as soon as one function provides a handler. MicrometerSupport then delegates to that handler to create and send the response. Pass the Handler and Function to the MicrometerSupport.enrollRegistry method to enroll them <markup lang=\"java\" title=\"Creating and enrolling your own Micrometer meter registry\" >MeterRegistry myRegistry = new PrometheusMeterRegistry(myPrometheusConfig); MicrometerSupport support = MicrometerSupport.builder() .enrollRegistry(myRegistry, request -&gt; request .headers() .bestAccepted(MediaType.TEXT_PLAIN).isPresent() ? Optional.of((req, resp) -&gt; resp.send(myRegistry.scrape())) : Optional.empty()) .build(); Create the meter registry. This example uses a Prometheus registry but it can be any extension of MeterRegistry . Provide the function that checks if the ServerRequest accepts content that your meter registry can produce (e.g., either text/plain or unspecified is normally an indication for Prometheus-style output) and returns the appropriate Optional&lt; Handler &gt; . A very simple in-line Handler that sets the response entity from the Prometheus registry&#8217;s scrape() method. ",
            "title": "Enrolling Other Micrometer Meter Registries"
        },
        {
            "location": "/se/metrics/micrometer",
            "text": " Your application can easily have Helidon create a REST endpoint which clients can access to retrieve Micrometer metrics, by default at the /micrometer endpoint. Within Helidon, each type of meter registry is paired with some code that examines the incoming HTTP request to /micrometer and decides whether the request matches up with the associated meter registry. The first pairing that accepts the request returns the response. You will need to take advantage of this if your application uses additional meter registries beyond what Helidon automatically provides and you want those meter registries reflected in the output from the /micrometer REST endpoint. When MicrometerSupport receives a request at the endpoint, it looks for the first enrolled meter registry for which the corresponding Function&lt;ServerRequest, Optional&lt;Handler&gt;&gt; returns a non-empty Handler . Helidon invokes that Handler which must retrieve the metrics output from its meter registry and set and send the response. Note that the Handler which your function returns typically has a reference to the meter registry it will use in preparing the response. ",
            "title": "Accessing the Helidon Micrometer Endpoint"
        },
        {
            "location": "/se/metrics/micrometer",
            "text": " Helidon SE includes an example application which uses Micrometer support. The rest of this section takes you through the process of changing your application to use Helidon SE integration with Micrometer: Register an instance of MicrometerSupport with the web server. Create meters using the meter registry managed by Helidon&#8217;s MicrometerSupport and then update and query those meters. Register an Instance of MicrometerSupport with the Web Server <markup lang=\"java\" title=\"Initialize Micrometer support\" >import io.helidon.integrations.micrometer.MicrometerSupport; MicrometerSupport micrometerSupport = MicrometerSupport.create(); Routing.builder() .register(micrometerSupport) .register(\"/myapp\", new MyService(micrometerSupport.registry())) .build(); Create the MicrometerSupport instance, using the default built-in Prometheus meter registry. Register the MicrometerSupport instance as a service; by default, MicrometerSupport exposes the endpoint as /micrometer . Pass the MicrometerSupport object&#8217;s meter registry to your service for use in creating and updating meters. Create and Update Meters in Your Application Service <markup lang=\"java\" title=\"Define and use a Counter \" >import io.micrometer.core.instrument.Counter; public class MyService implements HttpService { private final Counter requestCounter; public MyService(MicrometerMeterRegistry registry) { requestCounter = registry.counter(\"allRequests\"); } @Override public void routing(HttpRules rules) { rules .any(this::countRequests) .get(\"/\", this::myGet); } private void countRequests(ServerRequest request, ServerResponse response) { requestCounter.increment(); request.next(); } } Use the Micrometer meter registry to create the request counter. Add routing for any request to invoke the method which counts requests by updating the counter. Update the counter and then delegate the rest of the request processing to the next handler in the chain. The example above enrolls the built-in Prometheus meter registry with the default Prometheus registry configuration. You can change the default setup for built-in registries, and you can enroll other meter registries your application creates itself. Overriding Defaults for Built-in Meter Registry Types Unless you specify otherwise, Helidon uses defaults for any built-in Micrometer meter registry. For example, Helidon configures the built-in Prometheus registry using PrometheusConfig.DEFAULT . You can override these defaults in either of two ways: Using the MicrometerSupport.Builder class Using configuration Using MicrometerSupport.Builder Use the MicrometerSupport.Builder class to set up Micrometer support however your application needs. The builder lets you: Provide your own Micrometer meter registry configuration that MicrometerSupport uses to create a built-in meter registry, or Instantiate a Micrometer meter registry yourself, configured however you want, and add it to the MicrometerSupport object&#8217;s collection of meter registries <markup lang=\"java\" title=\"Overriding defaults for built-in meter registries using MicrometerSupport.Builder \" >PrometheusConfig myPrometheusConfig = ...; MicrometerSupport support = MicrometerSupport.builder() .enrollBuiltInRegistry( MicrometerSupport.BuiltInRegistryType.PROMETHEUS, myPrometheusConfig) .build(); Create the meter registry configuration however you need. Enroll the PROMETHEUS built-in registry type with your custom configuration. Using Configuration To use configuration to control the selection and behavior of Helidon&#8217;s built-in Micrometer meter registries, include in your configuration (such as application.yaml ) a micrometer.builtin-registries section. <markup lang=\"yaml\" title=\"Enroll Prometheus built-in meter registry using default configuration\" >micrometer: builtin-registries: - type: prometheus <markup lang=\"yaml\" title=\"Enroll Prometheus built-in meter registry with non-default configuration\" >micrometer: builtin-registries: - type: prometheus prefix: myPrefix Note that the first config example is equivalent to the default Helidon Micrometer behavior; Helidon by default supports the Prometheus meter registry. The configuration keys that are valid for the builtin-registries child entries depend on the type of Micrometer meter registry. For example, support in Helidon for the Prometheus meter registry respects the prefix configuration setting but other meter registries might not and might support other settings. Refer to the documentation for the meter registry you want to configure to find out what items apply to that registry type. Helidon does not validate the configuration keys you specify for meter registries. Enrolling Other Micrometer Meter Registries To create additional types of registries and enroll them with MicrometerSupport , you need to: Write a Handler Each meter registry has its own way of producing output. Write your handler so that it has a reference to the meter registry it should use and so that its accept method sets the payload in the HTTP response using the registry&#8217;s mechanism for creating output. Write a Function which accepts a ServerRequest and returns an Optional&lt;Handler&gt; Typically, the function examines the request&#8212;&#8203;the Content-Type , query parameters, etc.--to decide whether the corresponding handler should respond to the request. If so, your function should instantiate your Handler and return an Optional.of(theHandlerInstance) ; otherwise, your function should return Optional.empty() . When MicrometerSupport receives a request, it invokes the functions of all the enrolled registries, stopping as soon as one function provides a handler. MicrometerSupport then delegates to that handler to create and send the response. Pass the Handler and Function to the MicrometerSupport.enrollRegistry method to enroll them <markup lang=\"java\" title=\"Creating and enrolling your own Micrometer meter registry\" >MeterRegistry myRegistry = new PrometheusMeterRegistry(myPrometheusConfig); MicrometerSupport support = MicrometerSupport.builder() .enrollRegistry(myRegistry, request -&gt; request .headers() .bestAccepted(MediaType.TEXT_PLAIN).isPresent() ? Optional.of((req, resp) -&gt; resp.send(myRegistry.scrape())) : Optional.empty()) .build(); Create the meter registry. This example uses a Prometheus registry but it can be any extension of MeterRegistry . Provide the function that checks if the ServerRequest accepts content that your meter registry can produce (e.g., either text/plain or unspecified is normally an indication for Prometheus-style output) and returns the appropriate Optional&lt; Handler &gt; . A very simple in-line Handler that sets the response entity from the Prometheus registry&#8217;s scrape() method. Accessing the Helidon Micrometer Endpoint Your application can easily have Helidon create a REST endpoint which clients can access to retrieve Micrometer metrics, by default at the /micrometer endpoint. Within Helidon, each type of meter registry is paired with some code that examines the incoming HTTP request to /micrometer and decides whether the request matches up with the associated meter registry. The first pairing that accepts the request returns the response. You will need to take advantage of this if your application uses additional meter registries beyond what Helidon automatically provides and you want those meter registries reflected in the output from the /micrometer REST endpoint. When MicrometerSupport receives a request at the endpoint, it looks for the first enrolled meter registry for which the corresponding Function&lt;ServerRequest, Optional&lt;Handler&gt;&gt; returns a non-empty Handler . Helidon invokes that Handler which must retrieve the metrics output from its meter registry and set and send the response. Note that the Handler which your function returns typically has a reference to the meter registry it will use in preparing the response. ",
            "title": "Examples"
        },
        {
            "location": "/se/metrics/micrometer",
            "text": " The Micrometer website describes the project as a whole and has links to more information. ",
            "title": "Additional Information"
        },
        {
            "location": "/se/metrics/prometheus-exemplar-support",
            "text": " Overview Maven Coordinates Usage Examples Additional Information ",
            "title": "Contents"
        },
        {
            "location": "/se/metrics/prometheus-exemplar-support",
            "text": " A meter typically reflects the usage of a single point in your service which processes multiple requests over time. A value such as the total time consumed by a given REST endpoint which can be invoked multiple times underscores the aggregate nature of meter values; Helidon accumulates the time from all requests in the total duration. Tracing, on the other hand, captures the usage of multiple parts of your code as your service responds to a single request. Metrics and tracing come together in Helidon&#8217;s support for exemplars. Note exemplar - one that serves as a model or example &#8201;&#8212;&#8201;Merriam-Webster Dictionary In the context of metrics, an exemplar for a given meter is a specific sample which, in some sense, made a typical contribution to the meter&#8217;s value. For example, an exemplar for a Counter might be the most recent sample which updated the counter. The metrics output identifies the exemplar sample using the span and trace IDs of the span and trace which triggered that sample. Exemplar support in Helidon relies on the exemplar support provided by the underlying metrics implementation. Currently, Helidon&#8217;s Micrometer implementation supports exemplars as recorded by Micrometer&#8217;s Prometheus meter registry and exposed by the OpenMetrics output (media type application/openmetrics-text ). ",
            "title": "Overview"
        },
        {
            "location": "/se/metrics/prometheus-exemplar-support",
            "text": " To enable OpenMetrics exemplar support add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics-trace-exemplar&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; Also, include the Helidon integration module for a tracing implementation (such as Helidon Zipkin ) <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-providers-zipkin&lt;/artifactId&gt; &lt;/dependency&gt; Add the Helidon tracing component itself: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.webserver.observe&lt;/groupId&gt; &lt;artifactId&gt;helidon-webserver-observe-tracing&lt;/artifactId&gt; &lt;/dependency&gt; Helidon tracing dependency. Observability dependencies for tracing. For further processing of the tracing data, different providers are used. For Jaeger: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-providers-jaeger&lt;/artifactId&gt; &lt;/dependency&gt; For Zipkin: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-providers-zipkin&lt;/artifactId&gt; &lt;/dependency&gt; For OpenTelemetry: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-providers-opentelemetry&lt;/artifactId&gt; &lt;/dependency&gt; For OpenTracing: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-providers-opentracing&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/metrics/prometheus-exemplar-support",
            "text": " Each exemplar reflects a sample described by a label, a value, and a timestamp. When a client accesses the /observe/metrics endpoint and specifies that it accepts the application/openmetrics-text media type, the label, value, and timestamp appear in the OpenMetrics response for meters that support exemplars. The exemplar information in the output describes a single, actual sample that is representative of the statistical value as recorded by the underlying Micrometer Prometheus meter registry. ",
            "title": "Interpreting Exemplars"
        },
        {
            "location": "/se/metrics/prometheus-exemplar-support",
            "text": " In the OpenMetrics output, an exemplar actually appears as a comment appended to the normal OpenMetrics output. <markup title=\"OpenMetrics format with exemplars\" > meter-identifier meter-value # exemplar-label sample-timestamp Even downstream consumers of OpenMetrics output that do not recognize the exemplar format should continue to work correctly (as long as they do recognize comments). But some consumers, such as trace collectors and their UIs, understand the exemplar format, and they allow you to browse meters and then navigate directly to the trace for the meter&#8217;s exemplar. ",
            "title": "Output Format"
        },
        {
            "location": "/se/metrics/prometheus-exemplar-support",
            "text": " Once you add the appropriate dependencies to your project, exemplar support runs automatically as part of the Helidon metrics implementation using Micrometer. You do not need to change your application or configuration. Interpreting Exemplars Each exemplar reflects a sample described by a label, a value, and a timestamp. When a client accesses the /observe/metrics endpoint and specifies that it accepts the application/openmetrics-text media type, the label, value, and timestamp appear in the OpenMetrics response for meters that support exemplars. The exemplar information in the output describes a single, actual sample that is representative of the statistical value as recorded by the underlying Micrometer Prometheus meter registry. Output Format In the OpenMetrics output, an exemplar actually appears as a comment appended to the normal OpenMetrics output. <markup title=\"OpenMetrics format with exemplars\" > meter-identifier meter-value # exemplar-label sample-timestamp Even downstream consumers of OpenMetrics output that do not recognize the exemplar format should continue to work correctly (as long as they do recognize comments). But some consumers, such as trace collectors and their UIs, understand the exemplar format, and they allow you to browse meters and then navigate directly to the trace for the meter&#8217;s exemplar. ",
            "title": "Usage"
        },
        {
            "location": "/se/metrics/prometheus-exemplar-support",
            "text": " Helidon includes an example application , based on the QuickStart application, which illustrates exemplar support. Once you enable exemplar support you can see the exemplars in the metrics output. # TYPE counterForPersonalizedGreetings counter # HELP counterForPersonalizedGreetings counterForPersonalizedGreetings_total{scope=\"application\"} 4.0 # {span_id=\"6b1fc9f9fd42fb0c\",trace_id=\"6b1fc9f9fd42fb0c\"} 1.0 1696889651.779 The exemplar (the portion following the # ) is a sample corresponding to an update to the counter, showing the span and trace identifiers, the amount by which the counter was updated ( 1.0 ), and the timestamp recording when the update occurred expressed as seconds in the UNIX epoch ( 1696889651.779 ). ",
            "title": "Examples"
        },
        {
            "location": "/se/metrics/prometheus-exemplar-support",
            "text": " Brief discussion of exemplars in the OpenMetrics spec ",
            "title": "Additional Information"
        },
        {
            "location": "/se/observability",
            "text": " Overview Maven Coordinates Usage Configuration Additional Information Reference ",
            "title": "Contents"
        },
        {
            "location": "/se/observability",
            "text": " In Helidon 4 all observability features were moved to one logical module: observe . The observability support groups all observe endpoints together under a single context root (the default behavior) /observe . ",
            "title": "Overview"
        },
        {
            "location": "/se/observability",
            "text": " To enable Helidon Observability add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webserver.observe&lt;/groupId&gt; &lt;artifactId&gt;helidon-webserver-observe&lt;/artifactId&gt; &lt;/dependency&gt; For Health Observability features: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webserver.observe&lt;/groupId&gt; &lt;artifactId&gt;helidon-webserver-observe-health&lt;/artifactId&gt; &lt;/dependency&gt; For Metrics Observability features: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webserver.observe&lt;/groupId&gt; &lt;artifactId&gt;helidon-webserver-observe-metrics&lt;/artifactId&gt; &lt;/dependency&gt; For Info Observability features: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webserver.observe&lt;/groupId&gt; &lt;artifactId&gt;helidon-webserver-observe-info&lt;/artifactId&gt; &lt;/dependency&gt; For Logging Observability features: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webserver.observe&lt;/groupId&gt; &lt;artifactId&gt;helidon-webserver-observe-log&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/observability",
            "text": " ObserveProvider instances are discovered using ServiceLoader . In case an explicit Observer is registered with the same type as a provider, the provider will not be used (so we do not duplicate services). ",
            "title": "Discovery"
        },
        {
            "location": "/se/observability",
            "text": " Configuration observability allows reading the current application configuration values. Configuration observability defines the following endpoints: Endpoint Method Action /config/profile GET Returns the current configuration profile /config/values GET Returns the current configuration values /config/values/{name} GET Returns specified by name configuration value All secrets and passwords are obfuscated with \"*\" characters. ",
            "title": "Configuration Observability"
        },
        {
            "location": "/se/observability",
            "text": " Health observability allows reading application readiness to serve requests, whether the services are alive. Health observability defines the following endpoints: Endpoint Method Action /health/ready GET Returns Service Readiness /health/live GET Returns whether the service is alive /health/started GET Returns whether the service is started /health/ready/{name} GET Returns Service name Readiness /health/live/{name} GET Returns whether the service name is alive /health/started/{name} GET Returns whether the service name is started /health/check/{name} GET Returns all checks for service name /health/ready HEAD Returns Service Readiness without details /health/live HEAD Returns whether the service is alive without details /health/started HEAD Returns whether the service is started without details /health/ready/{name} HEAD Returns Service name Readiness without details /health/live/{name} HEAD Returns whether the service name is alive without details /health/started/{name} HEAD Returns whether the service name is started without details /health/check/{name} HEAD Returns all checks for service name without details For more information, please, check Health documentation. ",
            "title": "Health Observability"
        },
        {
            "location": "/se/observability",
            "text": " Info observability allows configuration of custom properties to be available to users. Information observability defines the following endpoints: Endpoint Method Action /info GET Returns the Application information /info/{name} GET Returns the Application information for the specified name ",
            "title": "Information Observability"
        },
        {
            "location": "/se/observability",
            "text": " Log observability allows reading and configuring of log levels of various loggers and reading log messages. Logger Observability defines the following endpoints: Endpoint Method Action /log GET Stream logs (if enabled) /log/loggers GET Returns all logger handlers /log/log/loggers/{logger} GET Returns the Logger by name logger /log/loggers/{logger} POST Set Logger level by name logger /log/loggers/{logger} DELETE Unset the specified logger logger ",
            "title": "Logger Observability"
        },
        {
            "location": "/se/observability",
            "text": " Helidon distinguishes among three general types , or scopes, of metrics. Types (scopes) of metrics Type/scope Typical Usage base OS or Java runtime measurements (available heap, disk space, etc.). vendor Implemented by vendors, including the REST.request metrics and other key performance indicator measurements. application Declared via annotations or programmatically registered by your service code. When you add the metrics dependency to your project, Helidon automatically provides a built-in REST endpoint /observe/metrics which responds with a report of the registered metrics and their values. Clients can request a particular output format. Formats for /observe/metrics output Format Requested by OpenMetrics (Prometheus) default ( text/plain ) JSON Header Accept: application/json Clients can also limit the report by appending the metric type to the path: /observe/metrics/base /observe/metrics/vendor /observe/metrics/application For more information see Metrics documentation. ",
            "title": "Metrics Observability"
        },
        {
            "location": "/se/observability",
            "text": " The \"Observe\" service endpoint can be modified on the ObserveFeature that is registered with routing. The feature endpoint defaults to /observe , and all observers are prefixed with it (see further) Each observer has customizable endpoints as well, and the result is decided as follows: 1. If the custom endpoint is relative, the result would be under observe endpoint (e.g. for health &#8594; /observe/health ) 2. If the custom endpoint is absolute, the result would be absolute as well (e.g. for /health &#8594; /health ) Configuration Observability Configuration observability allows reading the current application configuration values. Configuration observability defines the following endpoints: Endpoint Method Action /config/profile GET Returns the current configuration profile /config/values GET Returns the current configuration values /config/values/{name} GET Returns specified by name configuration value All secrets and passwords are obfuscated with \"*\" characters. Health Observability Health observability allows reading application readiness to serve requests, whether the services are alive. Health observability defines the following endpoints: Endpoint Method Action /health/ready GET Returns Service Readiness /health/live GET Returns whether the service is alive /health/started GET Returns whether the service is started /health/ready/{name} GET Returns Service name Readiness /health/live/{name} GET Returns whether the service name is alive /health/started/{name} GET Returns whether the service name is started /health/check/{name} GET Returns all checks for service name /health/ready HEAD Returns Service Readiness without details /health/live HEAD Returns whether the service is alive without details /health/started HEAD Returns whether the service is started without details /health/ready/{name} HEAD Returns Service name Readiness without details /health/live/{name} HEAD Returns whether the service name is alive without details /health/started/{name} HEAD Returns whether the service name is started without details /health/check/{name} HEAD Returns all checks for service name without details For more information, please, check Health documentation. Information Observability Info observability allows configuration of custom properties to be available to users. Information observability defines the following endpoints: Endpoint Method Action /info GET Returns the Application information /info/{name} GET Returns the Application information for the specified name Logger Observability Log observability allows reading and configuring of log levels of various loggers and reading log messages. Logger Observability defines the following endpoints: Endpoint Method Action /log GET Stream logs (if enabled) /log/loggers GET Returns all logger handlers /log/log/loggers/{logger} GET Returns the Logger by name logger /log/loggers/{logger} POST Set Logger level by name logger /log/loggers/{logger} DELETE Unset the specified logger logger Metrics Observability Helidon distinguishes among three general types , or scopes, of metrics. Types (scopes) of metrics Type/scope Typical Usage base OS or Java runtime measurements (available heap, disk space, etc.). vendor Implemented by vendors, including the REST.request metrics and other key performance indicator measurements. application Declared via annotations or programmatically registered by your service code. When you add the metrics dependency to your project, Helidon automatically provides a built-in REST endpoint /observe/metrics which responds with a report of the registered metrics and their values. Clients can request a particular output format. Formats for /observe/metrics output Format Requested by OpenMetrics (Prometheus) default ( text/plain ) JSON Header Accept: application/json Clients can also limit the report by appending the metric type to the path: /observe/metrics/base /observe/metrics/vendor /observe/metrics/application For more information see Metrics documentation. ",
            "title": "Endpoints"
        },
        {
            "location": "/se/observability",
            "text": " Each provider usually adds a new endpoint (such as health , metrics ). This is to have a single easily configurable path for security, proxy etc. purposes, rather than expose multiple \"root\" endpoints that may collide with the business code. Discovery ObserveProvider instances are discovered using ServiceLoader . In case an explicit Observer is registered with the same type as a provider, the provider will not be used (so we do not duplicate services). Endpoints The \"Observe\" service endpoint can be modified on the ObserveFeature that is registered with routing. The feature endpoint defaults to /observe , and all observers are prefixed with it (see further) Each observer has customizable endpoints as well, and the result is decided as follows: 1. If the custom endpoint is relative, the result would be under observe endpoint (e.g. for health &#8594; /observe/health ) 2. If the custom endpoint is absolute, the result would be absolute as well (e.g. for /health &#8594; /health ) Configuration Observability Configuration observability allows reading the current application configuration values. Configuration observability defines the following endpoints: Endpoint Method Action /config/profile GET Returns the current configuration profile /config/values GET Returns the current configuration values /config/values/{name} GET Returns specified by name configuration value All secrets and passwords are obfuscated with \"*\" characters. Health Observability Health observability allows reading application readiness to serve requests, whether the services are alive. Health observability defines the following endpoints: Endpoint Method Action /health/ready GET Returns Service Readiness /health/live GET Returns whether the service is alive /health/started GET Returns whether the service is started /health/ready/{name} GET Returns Service name Readiness /health/live/{name} GET Returns whether the service name is alive /health/started/{name} GET Returns whether the service name is started /health/check/{name} GET Returns all checks for service name /health/ready HEAD Returns Service Readiness without details /health/live HEAD Returns whether the service is alive without details /health/started HEAD Returns whether the service is started without details /health/ready/{name} HEAD Returns Service name Readiness without details /health/live/{name} HEAD Returns whether the service name is alive without details /health/started/{name} HEAD Returns whether the service name is started without details /health/check/{name} HEAD Returns all checks for service name without details For more information, please, check Health documentation. Information Observability Info observability allows configuration of custom properties to be available to users. Information observability defines the following endpoints: Endpoint Method Action /info GET Returns the Application information /info/{name} GET Returns the Application information for the specified name Logger Observability Log observability allows reading and configuring of log levels of various loggers and reading log messages. Logger Observability defines the following endpoints: Endpoint Method Action /log GET Stream logs (if enabled) /log/loggers GET Returns all logger handlers /log/log/loggers/{logger} GET Returns the Logger by name logger /log/loggers/{logger} POST Set Logger level by name logger /log/loggers/{logger} DELETE Unset the specified logger logger Metrics Observability Helidon distinguishes among three general types , or scopes, of metrics. Types (scopes) of metrics Type/scope Typical Usage base OS or Java runtime measurements (available heap, disk space, etc.). vendor Implemented by vendors, including the REST.request metrics and other key performance indicator measurements. application Declared via annotations or programmatically registered by your service code. When you add the metrics dependency to your project, Helidon automatically provides a built-in REST endpoint /observe/metrics which responds with a report of the registered metrics and their values. Clients can request a particular output format. Formats for /observe/metrics output Format Requested by OpenMetrics (Prometheus) default ( text/plain ) JSON Header Accept: application/json Clients can also limit the report by appending the metric type to the path: /observe/metrics/base /observe/metrics/vendor /observe/metrics/application For more information see Metrics documentation. ",
            "title": "Usage"
        },
        {
            "location": "/se/observability",
            "text": " To customize the endpoint of an observer: Configure a custom endpoint through configuration to modify the ObserveProvider setup (such as observe.health.endpoint ) Configure a custom endpoint through a builder on the specific Observer ( HealthObserver.builder().endpoint(\"myhealth\") ) ",
            "title": "Configuration"
        },
        {
            "location": "/se/observability",
            "text": " The Observability features are now implemented with HttpFeature and can be registered with HttpRouting.Builder#addFeature(java.util.function.Supplier) . Such a feature encapsulates a set of endpoints, services and/or filters. Feature is similar to HttpService but gives more freedom in setup. Main difference is that a feature can add Filter filters and it cannot be registered on a path (that is left to the discretion of the feature developer). Features are not registered immediately - each feature can define a Weight or implement Weighted to order features according to their weight. Higher weighted features are registered first. This is to allow ordering of features in a meaningful way (e.g. Context should be first, Tracing second, Security third etc.). ",
            "title": "Additional Information"
        },
        {
            "location": "/se/observability",
            "text": " MicroProfile Metrics Specification Metrics documentation. Health documentation. ",
            "title": "Reference"
        },
        {
            "location": "/se/openapi/openapi-generator",
            "text": " Overview Maven Coordinates Configuration Usage References ",
            "title": "Contents"
        },
        {
            "location": "/se/openapi/openapi-generator",
            "text": " The OpenAPI specification provides a standard way to express RESTful APIs. Separately, the OpenAPI generator project has created a powerful code generator tool which accepts an OpenAPI document and generates client and server code for many languages and frameworks. The Helidon team contributes to this tool to ensure that it provides strong support for Helidon SE clients and servers. As a result, you can use the generator to create code that fits smoothly into your Helidon applications. The OpenAPI generator release 6.2.1 gained particularly strong support for Helidon. This document applies to that release and later ones. In the vocabulary of the tool, there are two generators for Helidon: java-helidon-client (hereafter the Helidon client generator) java-helidon-server (hereafter the Helidon server generator). Each of these generators supports two libraries : mp - for Helidon MP code generation se - for Helidon SE code generation Use the Helidon client generator and its se library to create a Helidon SE client based on Helidon WebClients . The resulting client library works with any server that implements the API declared in the OpenAPI document you specified when you ran the generator. The client library provides an abstraction similar to remote procedure calls (RPC). To access a remote service that implements the endpoints declared in the OpenAPI document, your code uses the generated client library first to establish a connection to the remote service and then to call remote service endpoints by invoking local methods passing POJO business objects or Java types as arguments. Use the tool&#8217;s Helidon server generator and its se library to create server endpoint stubs for a Helidon SE service. You build on these stubs by extending a generated class or implementing a generated interface, adding your specific business logic to finish the implementation of the endpoints. The combination of the generated server code plus Helidon SE underneath it allows you to focus on the business details instead of resource boilerplate. You can run the OpenAPI generators in three ways: using the OpenAPI generator CLI using the OpenAPI generator Maven plug-in using the online OpenAPI generator website The rest of this document walks you through how to use each technique and how to configure the generators to produce the code you want. ",
            "title": "Overview"
        },
        {
            "location": "/se/openapi/openapi-generator",
            "text": " Your project does not need any dependencies on the OpenAPI generator. To use the OpenAPI generator plug-in to generate or regenerate files during your project build, add the following to your project&#8217;s pom.xml file to declare the plug-in. Choose whichever version of the generator plug-in meets your needs as long as it is at least 6.2.1. <markup lang=\"xml\" title=\"Declaring the OpenAPI Generator Plug-in\" >&lt;properties&gt; &lt;openapi-generator-version&gt;6.2.1&lt;/openapi-generator-version&gt; &lt;/properties&gt; ... &lt;build&gt; ... &lt;plugin-management&gt; ... &lt;plugin&gt; &lt;groupId&gt;org.openapitools&lt;/groupId&gt; &lt;artifactId&gt;openapi-generator-maven-plugin&lt;/artifactId&gt; &lt;version&gt;${openapi-generator-version}&lt;/version&gt; &lt;/plugin&gt; ... &lt;/plugin-management&gt; ... &lt;/build&gt; A later section describes how to invoke the plug-in during your build. ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/openapi/openapi-generator",
            "text": " You must specify the following options: Required OpenAPI Generator Options Option Short Option Plug-in Setting Description Values --inputSpec -i &lt;inputSpec&gt; Path to the OpenAPI document defining the REST API --generatorName -g &lt;generatorName&gt; Generator you want to use ( java-helidon-server or java-helidon-client ) java-helidon-server java-helidon-client ",
            "title": "Required Settings"
        },
        {
            "location": "/se/openapi/openapi-generator",
            "text": " Your project might have different needs, but in general we advise developers to use the following settings when using the OpenAPI generator. Recommended OpenAPI Generator Additional Properties Property Description Default apiPackage Name of the package for generated API interfaces/classes org.openapitools.server.api or org.openapitools.client.api modelPackage Name of the package for generated model (POJO) classes org.openapitools.server.model or org.openapitools.client.model invokerPackage Name of the package for generated driver classes org.openapitools.server or org.openapitools.client groupId Group ID in the generated pom.xml org.openapitools artifactId Artifact ID in the generated pom.xml openapi-java-server or openapi-java-client artifactVersion Artifact version in the generated pom.xml 1.0.0 Note The next table contains recommendations only for using the OpenAPI generator plug-in (not for using the CLI). Recommended OpenAPI Generator Plug-in Options Plug-in Option Description Default &lt;output&gt; Directory where the generator should place files. + We strongly recommend &lt;output&gt;target/generated-sources&lt;/output&gt; or a subdirectory below there. . (current directory) &lt;addCompileSourceRoot&gt; Whether Maven should include the output directory as a source root (that is, include it automatically in the build). + We advise &lt;addCompileSourceRoot&gt;true&lt;/addCompileSourceRoot&gt; . false ",
            "title": "Recommended Settings for the OpenAPI Generator"
        },
        {
            "location": "/se/openapi/openapi-generator",
            "text": " Among the many configuration settings available to you, some you should particularly consider are summarized in the table below. Refer to the earlier links for complete lists. Common OpenAPI Generator Additional Properties Property Description Values Default Notes helidonVersion Version of Helidon for which to generate the files &#160; 2.5.2 Affects: Helidon version for the &lt;parent&gt; Dependencies ( javax vs. jakarta ) java import statements in generated code ( javax vs. jakarta ) fullProject Whether to generate all the normal files or only API files true / false false The \"API files\" include files developers do not normally modify after they are generated: the interfaces or classes for the declared API and the model classes. serializationLibrary which Java library to use for serializing JSON jsonb , jackson jackson ",
            "title": "Common Settings"
        },
        {
            "location": "/se/openapi/openapi-generator",
            "text": " The OpenAPI generators support a substantial, powerful, and sometimes bewildering group of configuration settings. For complete lists see these pages: generic options Helidon client generator options and Helidon server generator options The OpenAPI generator loosely divides its settings into three types: global properties These settings generally govern the overall behavior of the tool, regardless of which specific generator you use. For the CLI, use the common option style: -i petstore.yaml --input-spec petstore.yaml For the Maven plug-in, use elements within the &lt;configuration&gt; section of the plug-in: <markup lang=\"xml\" >&lt;configuration&gt; &lt;inputSpec&gt;petstore.yaml&lt;/inputSpec&gt; &lt;/configuration&gt; options These settings typically affect how particular generators operate. For the CLI, specify config options as additional properties: --additional-properties=groupId=com.mycompany.test,artifactId=my-example or <markup lang=\"bash\" >-p groupId=com.mycompany.test -p artifactId=my-example For the Maven plug-in, use the &lt;configOptions&gt; section within &lt;configuration&gt; : <markup lang=\"xml\" >&lt;configuration&gt; ... &lt;configOptions&gt; &lt;groupId&gt;com.mycompany.test&lt;/groupId&gt; &lt;artifactId&gt;my-example&lt;/artifactId&gt; &lt;/configOptions&gt; ... &lt;/configuration&gt; additional properties Settings in this category typically are passed to the templates used in generating the files, although generators can use additional properties in deciding how to generate the files. For the CLI: --additional-properties \"useAbstractClasses=false,returnResponse=true\" or <markup lang=\"bash\" >-p useAbstractClasses=false -p returnResponse=true For the Maven plug-in, use an &lt;additionalProperties&gt; section within the &lt;configuration&gt; section for the plug-in: <markup lang=\"xml\" >&lt;configuration&gt; .... &lt;additionalProperties&gt; &lt;additionalProperty&gt;useAbstractClasses=false&lt;/additionalProperty&gt; &lt;additionalProperty&gt;returnResponse=true&lt;/additionalProperty&gt; &lt;/additionalProperties&gt; &lt;/configuration&gt; Keep this distinction among global options, config options, and additional properties in mind so you know how to express the configuration you want. The earlier links to the lists of configuration options for the Helidon generators groups options and additional properties in separate tables. The next few sections describe, in turn, required settings, settings we recommend, and other common settings most developers will want to use. Required Settings You must specify the following options: Required OpenAPI Generator Options Option Short Option Plug-in Setting Description Values --inputSpec -i &lt;inputSpec&gt; Path to the OpenAPI document defining the REST API --generatorName -g &lt;generatorName&gt; Generator you want to use ( java-helidon-server or java-helidon-client ) java-helidon-server java-helidon-client Recommended Settings for the OpenAPI Generator Your project might have different needs, but in general we advise developers to use the following settings when using the OpenAPI generator. Recommended OpenAPI Generator Additional Properties Property Description Default apiPackage Name of the package for generated API interfaces/classes org.openapitools.server.api or org.openapitools.client.api modelPackage Name of the package for generated model (POJO) classes org.openapitools.server.model or org.openapitools.client.model invokerPackage Name of the package for generated driver classes org.openapitools.server or org.openapitools.client groupId Group ID in the generated pom.xml org.openapitools artifactId Artifact ID in the generated pom.xml openapi-java-server or openapi-java-client artifactVersion Artifact version in the generated pom.xml 1.0.0 Note The next table contains recommendations only for using the OpenAPI generator plug-in (not for using the CLI). Recommended OpenAPI Generator Plug-in Options Plug-in Option Description Default &lt;output&gt; Directory where the generator should place files. + We strongly recommend &lt;output&gt;target/generated-sources&lt;/output&gt; or a subdirectory below there. . (current directory) &lt;addCompileSourceRoot&gt; Whether Maven should include the output directory as a source root (that is, include it automatically in the build). + We advise &lt;addCompileSourceRoot&gt;true&lt;/addCompileSourceRoot&gt; . false Common Settings Among the many configuration settings available to you, some you should particularly consider are summarized in the table below. Refer to the earlier links for complete lists. Common OpenAPI Generator Additional Properties Property Description Values Default Notes helidonVersion Version of Helidon for which to generate the files &#160; 2.5.2 Affects: Helidon version for the &lt;parent&gt; Dependencies ( javax vs. jakarta ) java import statements in generated code ( javax vs. jakarta ) fullProject Whether to generate all the normal files or only API files true / false false The \"API files\" include files developers do not normally modify after they are generated: the interfaces or classes for the declared API and the model classes. serializationLibrary which Java library to use for serializing JSON jsonb , jackson jackson ",
            "title": "Configuration"
        },
        {
            "location": "/se/openapi/openapi-generator",
            "text": " You can use the OpenAPI generator to create a new project or to generate files into an existing project. Some developers do both, using the generator to create the project at first and then to update the project as they evolve the OpenAPI document or change the generation options they select. Others create the project in some other way&#8212;&#8203;for example, using the Helidon CLI . The OpenAPI generator CLI and plug-in both support each type of usage. If the OpenAPI generator finds a pre-existing API or model file, it overwrites it with the latest content. It does not overwrite a pom.xml file or test files. This is important because certain generation settings can influence the generated dependencies in the pom.xml file. For example, the serializationLibrary setting creates dependencies on either JSON-B or Jackson artifacts. As a result, changing the generation options can change the dependencies your project should have. If you rerun the generator, the old pom.xml remains and does not reflect the revised depencencies. As a practical matter, many developers use the OpenAPI generators in one of the following ways: Use the generator CLI once to create a new project. By default, the generator CLI creates files in the normal Maven project structure: src/main/java , etc. Then you add your own files to that same project structure. Because the generated files are in the standard places, the project build includes them by default. Note You can run the generator CLI again to update the generated files. Because this happens outside the project&#8217;s build lifecycle, you need to remember to rerun the CLI yourself when you change the OpenAPI document. You also need to identify and manually remove any previously-generated files that become obsolete. Similarly, you must understand how changes in the OpenAPI document or the generation options affect the project dependencies and update the project pom.xml accordingly. Use the generator plug-in to (re)generate files during each build. Specify in the plug-in configuration that the generated files should reside in target/generated-sources directory (the conventional location for generated sources) or a subdirectory below there. Each project build runs the OpenAPI generator which reads the then-current OpenAPI document file. With the generated files under target , you can use mvn clean to remove any obsolete generated files left over from previous builds. Note In particular, with mvn clean each build regenerates the candidate pom.xml under target/generated-sources . You can inspect the generated pom.xml file for changes in dependencies and make any necessary changes in the actual project pom.xml file. ",
            "title": "Generating a New Project and Generating Into an Existing Project"
        },
        {
            "location": "/se/openapi/openapi-generator",
            "text": " As you generate a Helidon SE server , you can choose whether you want Java interfaces or classes to represent the RESTful API endpoints. By default, the Helidon OpenAPI server generator creates classes. You write your own concrete subclasses which extend those generated classes, supplying the business logic for each REST endpoint. Do not modify the generated classes. If you set useAbstractClasses=false then the generator creates Java interfaces instead of classes. You then write classes which implement those generated interfaces. Either way, you can safely regenerate the code later so long as you have not edited the generated code. The generator replaces the generated classes or interfaces but does not touch other classes you wrote. The Helidon client generator always creates concrete classes. Typically, you do not need to customize the behavior in the generated client API classes. If you choose to do so, write your own subclass of the generated client API class; do not modify the generated files. ",
            "title": "Generating Interfaces or Classes"
        },
        {
            "location": "/se/openapi/openapi-generator",
            "text": " Each operation in an OpenAPI document can have a tags attribute. The generators group operations with the same tags value into the same API. When you generate a Helidon SE server, the generator creates a separate interface or class for each API your service exposes . You implement each interface or extend each class to add your business logic for that API. When you generate a Helidon SE client, the generated code contains a separate API class for each distinct API your code might invoke . ",
            "title": "Grouping Operations into \"APIs\""
        },
        {
            "location": "/se/openapi/openapi-generator",
            "text": " Beyond the settings listed above, there are several important choices you need to make when planning your project and when running the OpenAPI generators. This section addresses those choices. Generating a New Project and Generating Into an Existing Project You can use the OpenAPI generator to create a new project or to generate files into an existing project. Some developers do both, using the generator to create the project at first and then to update the project as they evolve the OpenAPI document or change the generation options they select. Others create the project in some other way&#8212;&#8203;for example, using the Helidon CLI . The OpenAPI generator CLI and plug-in both support each type of usage. If the OpenAPI generator finds a pre-existing API or model file, it overwrites it with the latest content. It does not overwrite a pom.xml file or test files. This is important because certain generation settings can influence the generated dependencies in the pom.xml file. For example, the serializationLibrary setting creates dependencies on either JSON-B or Jackson artifacts. As a result, changing the generation options can change the dependencies your project should have. If you rerun the generator, the old pom.xml remains and does not reflect the revised depencencies. As a practical matter, many developers use the OpenAPI generators in one of the following ways: Use the generator CLI once to create a new project. By default, the generator CLI creates files in the normal Maven project structure: src/main/java , etc. Then you add your own files to that same project structure. Because the generated files are in the standard places, the project build includes them by default. Note You can run the generator CLI again to update the generated files. Because this happens outside the project&#8217;s build lifecycle, you need to remember to rerun the CLI yourself when you change the OpenAPI document. You also need to identify and manually remove any previously-generated files that become obsolete. Similarly, you must understand how changes in the OpenAPI document or the generation options affect the project dependencies and update the project pom.xml accordingly. Use the generator plug-in to (re)generate files during each build. Specify in the plug-in configuration that the generated files should reside in target/generated-sources directory (the conventional location for generated sources) or a subdirectory below there. Each project build runs the OpenAPI generator which reads the then-current OpenAPI document file. With the generated files under target , you can use mvn clean to remove any obsolete generated files left over from previous builds. Note In particular, with mvn clean each build regenerates the candidate pom.xml under target/generated-sources . You can inspect the generated pom.xml file for changes in dependencies and make any necessary changes in the actual project pom.xml file. Generating Interfaces or Classes As you generate a Helidon SE server , you can choose whether you want Java interfaces or classes to represent the RESTful API endpoints. By default, the Helidon OpenAPI server generator creates classes. You write your own concrete subclasses which extend those generated classes, supplying the business logic for each REST endpoint. Do not modify the generated classes. If you set useAbstractClasses=false then the generator creates Java interfaces instead of classes. You then write classes which implement those generated interfaces. Either way, you can safely regenerate the code later so long as you have not edited the generated code. The generator replaces the generated classes or interfaces but does not touch other classes you wrote. The Helidon client generator always creates concrete classes. Typically, you do not need to customize the behavior in the generated client API classes. If you choose to do so, write your own subclass of the generated client API class; do not modify the generated files. Grouping Operations into \"APIs\" Each operation in an OpenAPI document can have a tags attribute. The generators group operations with the same tags value into the same API. When you generate a Helidon SE server, the generator creates a separate interface or class for each API your service exposes . You implement each interface or extend each class to add your business logic for that API. When you generate a Helidon SE client, the generated code contains a separate API class for each distinct API your code might invoke . ",
            "title": "Planning Your Use of the OpenAPI Generators"
        },
        {
            "location": "/se/openapi/openapi-generator",
            "text": " Downloading the OpenAPI Generator CLI You need to download the CLI .jar file before you can run the CLI. Follow these instructions and remember where you save the .jar file. The examples below use the placeholder path-to-generator to represent the directory where you store that downloaded file. The following example uses the Helidon server generator to create a project or regenerate files into an existing project. <markup lang=\"bash\" title=\"Creating or updating a server project using the OpenAPI generator CLI\" >java -jar ${path-to-generator}/openapi-generator-cli.jar \\ generate \\ -i src/main/resources/petstore.yaml \\ -g java-helidon-server \\ --library se \\ -p groupId=io.helidon.examples \\ -p artifactId=helidon-openapigen-se-server \\ -p artifactVersion=1.0.0-SNAPSHOT \\ -p apiPackage=io.helidon.examples.openapigen.se.server.api \\ -p modelPackage=io.helidon.examples.openapigen.se.server.model \\ -p invokerPackage=io.helidon.examples.openapigen.se.server The next example runs the Helidon client generator using the same input file. <markup lang=\"bash\" title=\"Creating or updating a client project using the OpenAPI generator CLI\" >java -jar ${path-to-generator}/openapi-generator-cli.jar \\ generate \\ -i src/main/resources/petstore.yaml \\ -g java-helidon-client \\ --library se \\ -p groupId=io.helidon.examples \\ -p artifactId=helidon-openapigen-se-client \\ -p artifactVersion=1.0.0-SNAPSHOT \\ -p apiPackage=io.helidon.examples.openapigen.se.client.api \\ -p modelPackage=io.helidon.examples.openapigen.se.client.model \\ -p invokerPackage=io.helidon.examples.openapigen.se.client The key differences between the commands are: the generator selected by the -g option ( client vs. server ), the artifact ID and package names ( client vs. server ). You could use these two commands together to generate a server submodule and a client submodule in a pre-existing multi-module Maven project. Remember that the resulting client project can access any server which implements the API described in the petstore.yaml OpenAPI document, whether it was generated using the OpenAPI generator tool or not. In both examples, the generator creates the entire project if it does not exist and recreates the generated API and model files if the project already exists. The generator does not overwrite an existing pom.xml file, previously-generated test files, or files you create yourself. ",
            "title": "Using the OpenAPI Generator CLI"
        },
        {
            "location": "/se/openapi/openapi-generator",
            "text": " You can run the OpenAPI generator plug-in as part of your project build to generate or regenerate files. First, declare the plug-in as explained in the earlier section on Maven coordinates . Then, in the &lt;build&gt; section of your pom.xml file, add an execution of the plug-in with the configuration you want. By default, the plug-in runs during the generate-sources phase of the Maven build. The plug-in execution in the following example is equivalent to the CLI example above for generating server files: <markup lang=\"xml\" title=\"Creating or updating a client project using the OpenAPI Maven plug-in\" >&lt;plugin&gt; &lt;groupId&gt;org.openapitools&lt;/groupId&gt; &lt;artifactId&gt;openapi-generator-maven-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;generate&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;inputSpec&gt;${project.basedir}/src/main/resources/petstore.yaml&lt;/inputSpec&gt; &lt;generatorName&gt;java-helidon-client&lt;/generatorName&gt; &lt;library&gt;se&lt;/library&gt; &lt;output&gt;${project.build.directory}/generated-sources/client&lt;/output&gt; &lt;addCompileSourceRoot&gt;true&lt;/addCompileSourceRoot&gt; &lt;configOptions&gt; &lt;groupId&gt;io.helidon.examples&lt;/groupId&gt; &lt;artifactId&gt;helidon-openapigen-se-client&lt;/artifactId&gt; &lt;artifactVersion&gt;1.0.0-SNAPSHOT&lt;/artifactVersion&gt; &lt;apiPackage&gt;io.helidon.examples.openapigen.se.client.api&lt;/apiPackage&gt; &lt;modelPackage&gt;io.helidon.examples.openapigen.se.client.model&lt;/modelPackage&gt; &lt;invokerPackage&gt;io.helidon.examples.openapigen.se.client&lt;/invokerPackage&gt; &lt;/configOptions&gt; &lt;additionalProperties&gt; &lt;additionalProperty&gt;returnResponse=true&lt;/additionalProperty&gt; &lt;/additionalProperties&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; Specifies that the generated files should reside in the target/generated-sources/client directory. ",
            "title": "Invoking the OpenAPI Generator Maven Plug-in"
        },
        {
            "location": "/se/openapi/openapi-generator",
            "text": " The OpenAPI tools project hosts and maintains the online OpenAPI generator at http://api.openapi-generator.tech . You can use the site&#8217;s API browser to explore the available generators and the settings each supports, expressed as JSON. To generate your project, you supply the options and additional properties as JSON. The online generator provides you with a file ID, and you refer to the file ID in a subsequent HTTP request to retrieve your project. Note The online generator stores your project on the server which you then retrieve using a separate HTTP request. Before you use the online generator, consider whether any of the input you provide&#8212;&#8203;the OpenAPI document, package or Maven coordinates&#8212;&#8203;and therefore the generated project will reveal any sensitive information. This document does not explore further the use of the online generator. ",
            "title": "Using the Online Generator"
        },
        {
            "location": "/se/openapi/openapi-generator",
            "text": " Earlier we listed the ways you can run the OpenAPI generator: using the OpenAPI generator CLI using the OpenAPI generator Maven plug-in using the online OpenAPI generator website The next sections describe each of these techniques in detail. Using the OpenAPI Generator CLI Downloading the OpenAPI Generator CLI You need to download the CLI .jar file before you can run the CLI. Follow these instructions and remember where you save the .jar file. The examples below use the placeholder path-to-generator to represent the directory where you store that downloaded file. The following example uses the Helidon server generator to create a project or regenerate files into an existing project. <markup lang=\"bash\" title=\"Creating or updating a server project using the OpenAPI generator CLI\" >java -jar ${path-to-generator}/openapi-generator-cli.jar \\ generate \\ -i src/main/resources/petstore.yaml \\ -g java-helidon-server \\ --library se \\ -p groupId=io.helidon.examples \\ -p artifactId=helidon-openapigen-se-server \\ -p artifactVersion=1.0.0-SNAPSHOT \\ -p apiPackage=io.helidon.examples.openapigen.se.server.api \\ -p modelPackage=io.helidon.examples.openapigen.se.server.model \\ -p invokerPackage=io.helidon.examples.openapigen.se.server The next example runs the Helidon client generator using the same input file. <markup lang=\"bash\" title=\"Creating or updating a client project using the OpenAPI generator CLI\" >java -jar ${path-to-generator}/openapi-generator-cli.jar \\ generate \\ -i src/main/resources/petstore.yaml \\ -g java-helidon-client \\ --library se \\ -p groupId=io.helidon.examples \\ -p artifactId=helidon-openapigen-se-client \\ -p artifactVersion=1.0.0-SNAPSHOT \\ -p apiPackage=io.helidon.examples.openapigen.se.client.api \\ -p modelPackage=io.helidon.examples.openapigen.se.client.model \\ -p invokerPackage=io.helidon.examples.openapigen.se.client The key differences between the commands are: the generator selected by the -g option ( client vs. server ), the artifact ID and package names ( client vs. server ). You could use these two commands together to generate a server submodule and a client submodule in a pre-existing multi-module Maven project. Remember that the resulting client project can access any server which implements the API described in the petstore.yaml OpenAPI document, whether it was generated using the OpenAPI generator tool or not. In both examples, the generator creates the entire project if it does not exist and recreates the generated API and model files if the project already exists. The generator does not overwrite an existing pom.xml file, previously-generated test files, or files you create yourself. Invoking the OpenAPI Generator Maven Plug-in You can run the OpenAPI generator plug-in as part of your project build to generate or regenerate files. First, declare the plug-in as explained in the earlier section on Maven coordinates . Then, in the &lt;build&gt; section of your pom.xml file, add an execution of the plug-in with the configuration you want. By default, the plug-in runs during the generate-sources phase of the Maven build. The plug-in execution in the following example is equivalent to the CLI example above for generating server files: <markup lang=\"xml\" title=\"Creating or updating a client project using the OpenAPI Maven plug-in\" >&lt;plugin&gt; &lt;groupId&gt;org.openapitools&lt;/groupId&gt; &lt;artifactId&gt;openapi-generator-maven-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;generate&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;inputSpec&gt;${project.basedir}/src/main/resources/petstore.yaml&lt;/inputSpec&gt; &lt;generatorName&gt;java-helidon-client&lt;/generatorName&gt; &lt;library&gt;se&lt;/library&gt; &lt;output&gt;${project.build.directory}/generated-sources/client&lt;/output&gt; &lt;addCompileSourceRoot&gt;true&lt;/addCompileSourceRoot&gt; &lt;configOptions&gt; &lt;groupId&gt;io.helidon.examples&lt;/groupId&gt; &lt;artifactId&gt;helidon-openapigen-se-client&lt;/artifactId&gt; &lt;artifactVersion&gt;1.0.0-SNAPSHOT&lt;/artifactVersion&gt; &lt;apiPackage&gt;io.helidon.examples.openapigen.se.client.api&lt;/apiPackage&gt; &lt;modelPackage&gt;io.helidon.examples.openapigen.se.client.model&lt;/modelPackage&gt; &lt;invokerPackage&gt;io.helidon.examples.openapigen.se.client&lt;/invokerPackage&gt; &lt;/configOptions&gt; &lt;additionalProperties&gt; &lt;additionalProperty&gt;returnResponse=true&lt;/additionalProperty&gt; &lt;/additionalProperties&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; Specifies that the generated files should reside in the target/generated-sources/client directory. Using the Online Generator The OpenAPI tools project hosts and maintains the online OpenAPI generator at http://api.openapi-generator.tech . You can use the site&#8217;s API browser to explore the available generators and the settings each supports, expressed as JSON. To generate your project, you supply the options and additional properties as JSON. The online generator provides you with a file ID, and you refer to the file ID in a subsequent HTTP request to retrieve your project. Note The online generator stores your project on the server which you then retrieve using a separate HTTP request. Before you use the online generator, consider whether any of the input you provide&#8212;&#8203;the OpenAPI document, package or Maven coordinates&#8212;&#8203;and therefore the generated project will reveal any sensitive information. This document does not explore further the use of the online generator. ",
            "title": "Running the OpenAPI Generators"
        },
        {
            "location": "/se/openapi/openapi-generator",
            "text": " This section covers two major topics: Planning your use of the OpenAPI generators Running the generators Planning Your Use of the OpenAPI Generators Beyond the settings listed above, there are several important choices you need to make when planning your project and when running the OpenAPI generators. This section addresses those choices. Generating a New Project and Generating Into an Existing Project You can use the OpenAPI generator to create a new project or to generate files into an existing project. Some developers do both, using the generator to create the project at first and then to update the project as they evolve the OpenAPI document or change the generation options they select. Others create the project in some other way&#8212;&#8203;for example, using the Helidon CLI . The OpenAPI generator CLI and plug-in both support each type of usage. If the OpenAPI generator finds a pre-existing API or model file, it overwrites it with the latest content. It does not overwrite a pom.xml file or test files. This is important because certain generation settings can influence the generated dependencies in the pom.xml file. For example, the serializationLibrary setting creates dependencies on either JSON-B or Jackson artifacts. As a result, changing the generation options can change the dependencies your project should have. If you rerun the generator, the old pom.xml remains and does not reflect the revised depencencies. As a practical matter, many developers use the OpenAPI generators in one of the following ways: Use the generator CLI once to create a new project. By default, the generator CLI creates files in the normal Maven project structure: src/main/java , etc. Then you add your own files to that same project structure. Because the generated files are in the standard places, the project build includes them by default. Note You can run the generator CLI again to update the generated files. Because this happens outside the project&#8217;s build lifecycle, you need to remember to rerun the CLI yourself when you change the OpenAPI document. You also need to identify and manually remove any previously-generated files that become obsolete. Similarly, you must understand how changes in the OpenAPI document or the generation options affect the project dependencies and update the project pom.xml accordingly. Use the generator plug-in to (re)generate files during each build. Specify in the plug-in configuration that the generated files should reside in target/generated-sources directory (the conventional location for generated sources) or a subdirectory below there. Each project build runs the OpenAPI generator which reads the then-current OpenAPI document file. With the generated files under target , you can use mvn clean to remove any obsolete generated files left over from previous builds. Note In particular, with mvn clean each build regenerates the candidate pom.xml under target/generated-sources . You can inspect the generated pom.xml file for changes in dependencies and make any necessary changes in the actual project pom.xml file. Generating Interfaces or Classes As you generate a Helidon SE server , you can choose whether you want Java interfaces or classes to represent the RESTful API endpoints. By default, the Helidon OpenAPI server generator creates classes. You write your own concrete subclasses which extend those generated classes, supplying the business logic for each REST endpoint. Do not modify the generated classes. If you set useAbstractClasses=false then the generator creates Java interfaces instead of classes. You then write classes which implement those generated interfaces. Either way, you can safely regenerate the code later so long as you have not edited the generated code. The generator replaces the generated classes or interfaces but does not touch other classes you wrote. The Helidon client generator always creates concrete classes. Typically, you do not need to customize the behavior in the generated client API classes. If you choose to do so, write your own subclass of the generated client API class; do not modify the generated files. Grouping Operations into \"APIs\" Each operation in an OpenAPI document can have a tags attribute. The generators group operations with the same tags value into the same API. When you generate a Helidon SE server, the generator creates a separate interface or class for each API your service exposes . You implement each interface or extend each class to add your business logic for that API. When you generate a Helidon SE client, the generated code contains a separate API class for each distinct API your code might invoke . Running the OpenAPI Generators Earlier we listed the ways you can run the OpenAPI generator: using the OpenAPI generator CLI using the OpenAPI generator Maven plug-in using the online OpenAPI generator website The next sections describe each of these techniques in detail. Using the OpenAPI Generator CLI Downloading the OpenAPI Generator CLI You need to download the CLI .jar file before you can run the CLI. Follow these instructions and remember where you save the .jar file. The examples below use the placeholder path-to-generator to represent the directory where you store that downloaded file. The following example uses the Helidon server generator to create a project or regenerate files into an existing project. <markup lang=\"bash\" title=\"Creating or updating a server project using the OpenAPI generator CLI\" >java -jar ${path-to-generator}/openapi-generator-cli.jar \\ generate \\ -i src/main/resources/petstore.yaml \\ -g java-helidon-server \\ --library se \\ -p groupId=io.helidon.examples \\ -p artifactId=helidon-openapigen-se-server \\ -p artifactVersion=1.0.0-SNAPSHOT \\ -p apiPackage=io.helidon.examples.openapigen.se.server.api \\ -p modelPackage=io.helidon.examples.openapigen.se.server.model \\ -p invokerPackage=io.helidon.examples.openapigen.se.server The next example runs the Helidon client generator using the same input file. <markup lang=\"bash\" title=\"Creating or updating a client project using the OpenAPI generator CLI\" >java -jar ${path-to-generator}/openapi-generator-cli.jar \\ generate \\ -i src/main/resources/petstore.yaml \\ -g java-helidon-client \\ --library se \\ -p groupId=io.helidon.examples \\ -p artifactId=helidon-openapigen-se-client \\ -p artifactVersion=1.0.0-SNAPSHOT \\ -p apiPackage=io.helidon.examples.openapigen.se.client.api \\ -p modelPackage=io.helidon.examples.openapigen.se.client.model \\ -p invokerPackage=io.helidon.examples.openapigen.se.client The key differences between the commands are: the generator selected by the -g option ( client vs. server ), the artifact ID and package names ( client vs. server ). You could use these two commands together to generate a server submodule and a client submodule in a pre-existing multi-module Maven project. Remember that the resulting client project can access any server which implements the API described in the petstore.yaml OpenAPI document, whether it was generated using the OpenAPI generator tool or not. In both examples, the generator creates the entire project if it does not exist and recreates the generated API and model files if the project already exists. The generator does not overwrite an existing pom.xml file, previously-generated test files, or files you create yourself. Invoking the OpenAPI Generator Maven Plug-in You can run the OpenAPI generator plug-in as part of your project build to generate or regenerate files. First, declare the plug-in as explained in the earlier section on Maven coordinates . Then, in the &lt;build&gt; section of your pom.xml file, add an execution of the plug-in with the configuration you want. By default, the plug-in runs during the generate-sources phase of the Maven build. The plug-in execution in the following example is equivalent to the CLI example above for generating server files: <markup lang=\"xml\" title=\"Creating or updating a client project using the OpenAPI Maven plug-in\" >&lt;plugin&gt; &lt;groupId&gt;org.openapitools&lt;/groupId&gt; &lt;artifactId&gt;openapi-generator-maven-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;generate&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;inputSpec&gt;${project.basedir}/src/main/resources/petstore.yaml&lt;/inputSpec&gt; &lt;generatorName&gt;java-helidon-client&lt;/generatorName&gt; &lt;library&gt;se&lt;/library&gt; &lt;output&gt;${project.build.directory}/generated-sources/client&lt;/output&gt; &lt;addCompileSourceRoot&gt;true&lt;/addCompileSourceRoot&gt; &lt;configOptions&gt; &lt;groupId&gt;io.helidon.examples&lt;/groupId&gt; &lt;artifactId&gt;helidon-openapigen-se-client&lt;/artifactId&gt; &lt;artifactVersion&gt;1.0.0-SNAPSHOT&lt;/artifactVersion&gt; &lt;apiPackage&gt;io.helidon.examples.openapigen.se.client.api&lt;/apiPackage&gt; &lt;modelPackage&gt;io.helidon.examples.openapigen.se.client.model&lt;/modelPackage&gt; &lt;invokerPackage&gt;io.helidon.examples.openapigen.se.client&lt;/invokerPackage&gt; &lt;/configOptions&gt; &lt;additionalProperties&gt; &lt;additionalProperty&gt;returnResponse=true&lt;/additionalProperty&gt; &lt;/additionalProperties&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; Specifies that the generated files should reside in the target/generated-sources/client directory. Using the Online Generator The OpenAPI tools project hosts and maintains the online OpenAPI generator at http://api.openapi-generator.tech . You can use the site&#8217;s API browser to explore the available generators and the settings each supports, expressed as JSON. To generate your project, you supply the options and additional properties as JSON. The online generator provides you with a file ID, and you refer to the file ID in a subsequent HTTP request to retrieve your project. Note The online generator stores your project on the server which you then retrieve using a separate HTTP request. Before you use the online generator, consider whether any of the input you provide&#8212;&#8203;the OpenAPI document, package or Maven coordinates&#8212;&#8203;and therefore the generated project will reveal any sensitive information. This document does not explore further the use of the online generator. ",
            "title": "Usage"
        },
        {
            "location": "/se/openapi/openapi-generator",
            "text": " Recall from earlier how the OpenAPI generator gathers operations into one or more \"APIs\" and generates either a class or an interface&#8212;&#8203;your choice&#8212;&#8203;for each API. You need to extend each generated API class or implement each generated API interface by writing your own classes. Any input parameters to the endpoints are expressed as POJO model objects or Java types, as declared in the OpenAPI document. Your server code uses each of the input parameters to accomplish whatever business purpose that endpoint is responsible for, possibly returning a result as a POJO or Java type as indicated for that operation in the OpenAPI document. The Helidon SE server generator also creates, for each API, a separate class containing handler methods for each endpoint. Along with the PetService interface or abstract class which has methods such as addPet and getPetById , the tool generates PetServiceImpl with methods such as handleAddPet and handleGetPetById . <markup lang=\"java\" title=\"Generated PetService abstract class\" >public abstract class PetService implements HttpService { void addPet(ServerRequest request, ServerResponse response, Pet pet) { // ... } abstract void handleAddPet(ServerRequest request, ServerResponse response, Pet pet); void getPetById(ServerRequest request, ServerResponse response) { // ... } abstract void handleGetPetById(ServerRequest request, ServerResponse response, Long petId); } <markup lang=\"java\" title=\"Generated skeleton PetServiceImpl class (which you extend)\" >public class PetServiceImpl extends PetService { public void handleAddPet(ServerRequest request, ServerResponse response, Pet pet) { response.status(HTTP_CODE_NOT_IMPLEMENTED.send()); } public void handleGetPetById(ServerRequest request, ServerResponse response, Long petId) { response.status(HTTP_CODE_NOT_IMPLEMENTED).send(); } } You write your own classes which extend PetServiceImpl and the other generated xxxImpl classes, overriding the handle&#8230;&#8203; methods. You have control over&#8212;&#8203;and therefore responsibility for&#8212;&#8203;preparing the response to be sent to the client, including the status, any response headers, and any returned entity. Your overriding implementation of handleGetPetById might look like the following example. <markup lang=\"java\" title=\"Example override of handleGetPetById \" >public void handleGetPetById(ServerRequest request, ServerResponse response, Long petId) { Pet pet = locatePetInDatabase(petId); if (pet == null) { response.status(404).send(); } response.send(pet); // Respnose status is 200 by default. } } ",
            "title": "Completing the Server"
        },
        {
            "location": "/se/openapi/openapi-generator",
            "text": " In the simplest case, your code can get an ApiClient instance directly. <markup lang=\"java\" title=\"Creating an ApiClient instance - simple case\" >ApiClient apiClient = ApiClient.builder().build(); Your code relies fully on the automatic WebClient.Builder . In many cases, this approach works very well, especially if the OpenAPI document correctly declares the servers and their URIs. ",
            "title": "Accepting the Automatic WebClient.Builder "
        },
        {
            "location": "/se/openapi/openapi-generator",
            "text": " Your code can use the ApiClient.Builder to fine-tune the settings for the internal WebClient.Builder . For instance, your code can set an object mapper to be used for Jackson processing or the JsonbConfig object to be used for JSON-B processing, depending on which serialization library you chose when you ran the generator. Your code does not need to know how the object mapper setting is conveyed to the internal WebClient.Builder . The ApiClient.Builder knows how to do that. <markup lang=\"java\" title=\"Creating an ApiClient instance - influencing the ApiClient.Builder \" >ApiClient apiClient = apiClient.builder() .objectMapper(yourCustomMapper) .build(); ",
            "title": "Influencing the Automatic WebClient.Builder "
        },
        {
            "location": "/se/openapi/openapi-generator",
            "text": " In more complicated situations, your code can adjust the settings of the WebClient.Builder the ApiClient.Builder creates. <markup lang=\"java\" title=\"Creating an ApiClient instance - adjusting the WebClient.Builder \" >ApiClient.Builder apiClientBuilder = ApiClient.builder(); apiClientBuilder.webClientBuilder() .connectTimeout(4, TimeUnit.SECONDS); ApiClient apiClient = apiClientBuilder.build(); Access the ApiClient.Builder&#8217;s automatic `WebClient.Builder instance. Adjust a setting of the WebClient.Builder directly. Build the ApiClient which implicitly builds the WebClient from the now-adjusted internal WebClient.Builder . The automatic WebClient.Builder retains information derived from the OpenAPI document unless your code overrides those specific settings. ",
            "title": "Adjusting the Automatic WebClient.Builder "
        },
        {
            "location": "/se/openapi/openapi-generator",
            "text": " Lastly, you can construct the WebClient.Builder entirely yourself and have the ApiClient.Builder use it instead of its own internal builder. <markup lang=\"java\" title=\"Creating an ApiClient instance - using a custom WebClient.Builder \" >WebClient.Builder customWebClientBuilder = WebClient.builder() .connectTimeout(3, TimeUnit.SECONDS) .baseUri(\"https://myservice.mycompany.com\"); ApiClient apiClient = ApiClient.builder() .webClientBuilder(customWebClientBuilder) .build(); Note that this approach entirely replaces the internal, automatically-prepared WebClient.Builder with yours; it does not merge the new builder with the internal one. In particular, any information from the OpenAPI document the generator used to prepare the internal WebClient.Builder is lost. ",
            "title": "Providing a Custom WebClient.Builder "
        },
        {
            "location": "/se/openapi/openapi-generator",
            "text": " The Helidon SE client generator gives you as much flexibility as you need in connecting to the remote service. Internally, the ApiClient uses a Helidon WebClient object to contact the remote system. The ApiClient.Builder automatically prepares a Helidon WebClient.Builder object using information from the OpenAPI document. The next sections describe, from simplest to most complicated, the ways your code can create an ApiClient instance, each involving increased involvement with the WebClient.Builder object. Accepting the Automatic WebClient.Builder In the simplest case, your code can get an ApiClient instance directly. <markup lang=\"java\" title=\"Creating an ApiClient instance - simple case\" >ApiClient apiClient = ApiClient.builder().build(); Your code relies fully on the automatic WebClient.Builder . In many cases, this approach works very well, especially if the OpenAPI document correctly declares the servers and their URIs. Influencing the Automatic WebClient.Builder Your code can use the ApiClient.Builder to fine-tune the settings for the internal WebClient.Builder . For instance, your code can set an object mapper to be used for Jackson processing or the JsonbConfig object to be used for JSON-B processing, depending on which serialization library you chose when you ran the generator. Your code does not need to know how the object mapper setting is conveyed to the internal WebClient.Builder . The ApiClient.Builder knows how to do that. <markup lang=\"java\" title=\"Creating an ApiClient instance - influencing the ApiClient.Builder \" >ApiClient apiClient = apiClient.builder() .objectMapper(yourCustomMapper) .build(); Adjusting the Automatic WebClient.Builder In more complicated situations, your code can adjust the settings of the WebClient.Builder the ApiClient.Builder creates. <markup lang=\"java\" title=\"Creating an ApiClient instance - adjusting the WebClient.Builder \" >ApiClient.Builder apiClientBuilder = ApiClient.builder(); apiClientBuilder.webClientBuilder() .connectTimeout(4, TimeUnit.SECONDS); ApiClient apiClient = apiClientBuilder.build(); Access the ApiClient.Builder&#8217;s automatic `WebClient.Builder instance. Adjust a setting of the WebClient.Builder directly. Build the ApiClient which implicitly builds the WebClient from the now-adjusted internal WebClient.Builder . The automatic WebClient.Builder retains information derived from the OpenAPI document unless your code overrides those specific settings. Providing a Custom WebClient.Builder Lastly, you can construct the WebClient.Builder entirely yourself and have the ApiClient.Builder use it instead of its own internal builder. <markup lang=\"java\" title=\"Creating an ApiClient instance - using a custom WebClient.Builder \" >WebClient.Builder customWebClientBuilder = WebClient.builder() .connectTimeout(3, TimeUnit.SECONDS) .baseUri(\"https://myservice.mycompany.com\"); ApiClient apiClient = ApiClient.builder() .webClientBuilder(customWebClientBuilder) .build(); Note that this approach entirely replaces the internal, automatically-prepared WebClient.Builder with yours; it does not merge the new builder with the internal one. In particular, any information from the OpenAPI document the generator used to prepare the internal WebClient.Builder is lost. ",
            "title": "Creating an ApiClient Instance"
        },
        {
            "location": "/se/openapi/openapi-generator",
            "text": " The ApiClient represents the connection to the remote server but not the individual RESTful operations. Each generated xxxApi interface exposes a method for each operation declared in the OpenAPI document associated with that API via its tags value. By example, the PetApi interface exposes a method for each operation in the OpenAPI document that pertains to pets. To invoke an operation defined on the PetApi interface, your code instantiates a PetApi using an ApiClient object: <markup lang=\"java\" title=\"Preparing the PetStore Client API\" >ApiClient apiClient = ApiClient.builder().build(); PetApi petApi = PetApiImpl.create(apiClient); ",
            "title": "Creating a PetApi Instance"
        },
        {
            "location": "/se/openapi/openapi-generator",
            "text": " The Helidon WebClient programming model includes a HTTPClientResponse interface which exposes all aspects of the HTTP response returned from the remote service. The next example shows how your code can use the HTTPClientResponse . <markup lang=\"java\" title=\"Access with status checking\" >ApiResponse&lt;List&lt;Pet&gt;&gt; apiResponse = petApi.findPetsByStatus(List.of(Pet.StatusEnum.AVAILABLE.value())); HTTPClientResponse webClientResponse = apiResponse.webClientResponse(); if (webClientResponse.status().code() != 200) { // Handle a non-successful status. } List&lt;Pet&gt;&gt; availablePets = apiResponse.result(); Start the remote service invocation. Wait for the HTTP response status and headers to arrive. Check the status in the HTTP response. Wait for the content to arrive subject to a four-second timeout. This code also blocks the current thread, first to wait for the initial response and then to wait for the result content. ",
            "title": "Access with status checking"
        },
        {
            "location": "/se/openapi/openapi-generator",
            "text": " With the petApi object, your code can invoke any of the methods on the PetApi interface to contact the remote service. The Helidon SE client generator creates an ApiResponse interface. Each generated PetApi method returns an ApiResponse&lt;returnType&gt; where the returnType is the return type declared in the OpenAPI document for the corresponding operation. The ApiResponse interface exposes two methods your code can use to work with the response from the remote service invocation: T result() Provides access to the value returned by the remote service in the response. This method lets your code fetch the return value directly. HTTPClientResponse webClientResponse() Provides access to the Helidon HTTPClientResponse object. Your code can find out the HTTP return status, read headers in the response, and process the content (if any) in the response however it needs to. In the Helidon WebClient model, the first part of the response message can arrive (the status and headers are available) before the entity in the body of the response is readable. So there are two events associated with an incoming HTTP response: when the response excluding the entity content has arrived, and when your code can begin consuming the entity content. You can adopt different styles of retrieving the results, depending on the specific needs of the code you are writing. Access with status checking The Helidon WebClient programming model includes a HTTPClientResponse interface which exposes all aspects of the HTTP response returned from the remote service. The next example shows how your code can use the HTTPClientResponse . <markup lang=\"java\" title=\"Access with status checking\" >ApiResponse&lt;List&lt;Pet&gt;&gt; apiResponse = petApi.findPetsByStatus(List.of(Pet.StatusEnum.AVAILABLE.value())); HTTPClientResponse webClientResponse = apiResponse.webClientResponse(); if (webClientResponse.status().code() != 200) { // Handle a non-successful status. } List&lt;Pet&gt;&gt; availablePets = apiResponse.result(); Start the remote service invocation. Wait for the HTTP response status and headers to arrive. Check the status in the HTTP response. Wait for the content to arrive subject to a four-second timeout. This code also blocks the current thread, first to wait for the initial response and then to wait for the result content. ",
            "title": "Invoking Remote Endpoints"
        },
        {
            "location": "/se/openapi/openapi-generator",
            "text": " The generated client code represents a true library. Typically, you do not need to customize the generated client code itself. You do need to write code to invoke the code in that library. The generated Helidon SE client includes the class ApiClient . This class corresponds to the Helidon WebClient and represents the connection between your code and the remote server. The generator also creates one or more Api interfaces and corresponding implementation classes. The examples below use the PetApi interface and the PetApiImpl class. To invoke the remote service your code must: Create an instance of ApiClient using an ApiClient.Builder . Use that ApiClient instance to instantiate a PetApi object. Invoke the methods on the PetApi object to access the remote services and then retrieve the returned result value. The following sections explain these steps. Creating an ApiClient Instance The Helidon SE client generator gives you as much flexibility as you need in connecting to the remote service. Internally, the ApiClient uses a Helidon WebClient object to contact the remote system. The ApiClient.Builder automatically prepares a Helidon WebClient.Builder object using information from the OpenAPI document. The next sections describe, from simplest to most complicated, the ways your code can create an ApiClient instance, each involving increased involvement with the WebClient.Builder object. Accepting the Automatic WebClient.Builder In the simplest case, your code can get an ApiClient instance directly. <markup lang=\"java\" title=\"Creating an ApiClient instance - simple case\" >ApiClient apiClient = ApiClient.builder().build(); Your code relies fully on the automatic WebClient.Builder . In many cases, this approach works very well, especially if the OpenAPI document correctly declares the servers and their URIs. Influencing the Automatic WebClient.Builder Your code can use the ApiClient.Builder to fine-tune the settings for the internal WebClient.Builder . For instance, your code can set an object mapper to be used for Jackson processing or the JsonbConfig object to be used for JSON-B processing, depending on which serialization library you chose when you ran the generator. Your code does not need to know how the object mapper setting is conveyed to the internal WebClient.Builder . The ApiClient.Builder knows how to do that. <markup lang=\"java\" title=\"Creating an ApiClient instance - influencing the ApiClient.Builder \" >ApiClient apiClient = apiClient.builder() .objectMapper(yourCustomMapper) .build(); Adjusting the Automatic WebClient.Builder In more complicated situations, your code can adjust the settings of the WebClient.Builder the ApiClient.Builder creates. <markup lang=\"java\" title=\"Creating an ApiClient instance - adjusting the WebClient.Builder \" >ApiClient.Builder apiClientBuilder = ApiClient.builder(); apiClientBuilder.webClientBuilder() .connectTimeout(4, TimeUnit.SECONDS); ApiClient apiClient = apiClientBuilder.build(); Access the ApiClient.Builder&#8217;s automatic `WebClient.Builder instance. Adjust a setting of the WebClient.Builder directly. Build the ApiClient which implicitly builds the WebClient from the now-adjusted internal WebClient.Builder . The automatic WebClient.Builder retains information derived from the OpenAPI document unless your code overrides those specific settings. Providing a Custom WebClient.Builder Lastly, you can construct the WebClient.Builder entirely yourself and have the ApiClient.Builder use it instead of its own internal builder. <markup lang=\"java\" title=\"Creating an ApiClient instance - using a custom WebClient.Builder \" >WebClient.Builder customWebClientBuilder = WebClient.builder() .connectTimeout(3, TimeUnit.SECONDS) .baseUri(\"https://myservice.mycompany.com\"); ApiClient apiClient = ApiClient.builder() .webClientBuilder(customWebClientBuilder) .build(); Note that this approach entirely replaces the internal, automatically-prepared WebClient.Builder with yours; it does not merge the new builder with the internal one. In particular, any information from the OpenAPI document the generator used to prepare the internal WebClient.Builder is lost. Creating a PetApi Instance The ApiClient represents the connection to the remote server but not the individual RESTful operations. Each generated xxxApi interface exposes a method for each operation declared in the OpenAPI document associated with that API via its tags value. By example, the PetApi interface exposes a method for each operation in the OpenAPI document that pertains to pets. To invoke an operation defined on the PetApi interface, your code instantiates a PetApi using an ApiClient object: <markup lang=\"java\" title=\"Preparing the PetStore Client API\" >ApiClient apiClient = ApiClient.builder().build(); PetApi petApi = PetApiImpl.create(apiClient); Invoking Remote Endpoints With the petApi object, your code can invoke any of the methods on the PetApi interface to contact the remote service. The Helidon SE client generator creates an ApiResponse interface. Each generated PetApi method returns an ApiResponse&lt;returnType&gt; where the returnType is the return type declared in the OpenAPI document for the corresponding operation. The ApiResponse interface exposes two methods your code can use to work with the response from the remote service invocation: T result() Provides access to the value returned by the remote service in the response. This method lets your code fetch the return value directly. HTTPClientResponse webClientResponse() Provides access to the Helidon HTTPClientResponse object. Your code can find out the HTTP return status, read headers in the response, and process the content (if any) in the response however it needs to. In the Helidon WebClient model, the first part of the response message can arrive (the status and headers are available) before the entity in the body of the response is readable. So there are two events associated with an incoming HTTP response: when the response excluding the entity content has arrived, and when your code can begin consuming the entity content. You can adopt different styles of retrieving the results, depending on the specific needs of the code you are writing. Access with status checking The Helidon WebClient programming model includes a HTTPClientResponse interface which exposes all aspects of the HTTP response returned from the remote service. The next example shows how your code can use the HTTPClientResponse . <markup lang=\"java\" title=\"Access with status checking\" >ApiResponse&lt;List&lt;Pet&gt;&gt; apiResponse = petApi.findPetsByStatus(List.of(Pet.StatusEnum.AVAILABLE.value())); HTTPClientResponse webClientResponse = apiResponse.webClientResponse(); if (webClientResponse.status().code() != 200) { // Handle a non-successful status. } List&lt;Pet&gt;&gt; availablePets = apiResponse.result(); Start the remote service invocation. Wait for the HTTP response status and headers to arrive. Check the status in the HTTP response. Wait for the content to arrive subject to a four-second timeout. This code also blocks the current thread, first to wait for the initial response and then to wait for the result content. ",
            "title": "Using the Client Library"
        },
        {
            "location": "/se/openapi/openapi-generator",
            "text": " The Helidon generators go a long way in helping you write your client or server. Even so, there are important parts of your project only you can provide. This section describes your next steps after you have run the generator. Completing the Server Recall from earlier how the OpenAPI generator gathers operations into one or more \"APIs\" and generates either a class or an interface&#8212;&#8203;your choice&#8212;&#8203;for each API. You need to extend each generated API class or implement each generated API interface by writing your own classes. Any input parameters to the endpoints are expressed as POJO model objects or Java types, as declared in the OpenAPI document. Your server code uses each of the input parameters to accomplish whatever business purpose that endpoint is responsible for, possibly returning a result as a POJO or Java type as indicated for that operation in the OpenAPI document. The Helidon SE server generator also creates, for each API, a separate class containing handler methods for each endpoint. Along with the PetService interface or abstract class which has methods such as addPet and getPetById , the tool generates PetServiceImpl with methods such as handleAddPet and handleGetPetById . <markup lang=\"java\" title=\"Generated PetService abstract class\" >public abstract class PetService implements HttpService { void addPet(ServerRequest request, ServerResponse response, Pet pet) { // ... } abstract void handleAddPet(ServerRequest request, ServerResponse response, Pet pet); void getPetById(ServerRequest request, ServerResponse response) { // ... } abstract void handleGetPetById(ServerRequest request, ServerResponse response, Long petId); } <markup lang=\"java\" title=\"Generated skeleton PetServiceImpl class (which you extend)\" >public class PetServiceImpl extends PetService { public void handleAddPet(ServerRequest request, ServerResponse response, Pet pet) { response.status(HTTP_CODE_NOT_IMPLEMENTED.send()); } public void handleGetPetById(ServerRequest request, ServerResponse response, Long petId) { response.status(HTTP_CODE_NOT_IMPLEMENTED).send(); } } You write your own classes which extend PetServiceImpl and the other generated xxxImpl classes, overriding the handle&#8230;&#8203; methods. You have control over&#8212;&#8203;and therefore responsibility for&#8212;&#8203;preparing the response to be sent to the client, including the status, any response headers, and any returned entity. Your overriding implementation of handleGetPetById might look like the following example. <markup lang=\"java\" title=\"Example override of handleGetPetById \" >public void handleGetPetById(ServerRequest request, ServerResponse response, Long petId) { Pet pet = locatePetInDatabase(petId); if (pet == null) { response.status(404).send(); } response.send(pet); // Respnose status is 200 by default. } } Using the Client Library The generated client code represents a true library. Typically, you do not need to customize the generated client code itself. You do need to write code to invoke the code in that library. The generated Helidon SE client includes the class ApiClient . This class corresponds to the Helidon WebClient and represents the connection between your code and the remote server. The generator also creates one or more Api interfaces and corresponding implementation classes. The examples below use the PetApi interface and the PetApiImpl class. To invoke the remote service your code must: Create an instance of ApiClient using an ApiClient.Builder . Use that ApiClient instance to instantiate a PetApi object. Invoke the methods on the PetApi object to access the remote services and then retrieve the returned result value. The following sections explain these steps. Creating an ApiClient Instance The Helidon SE client generator gives you as much flexibility as you need in connecting to the remote service. Internally, the ApiClient uses a Helidon WebClient object to contact the remote system. The ApiClient.Builder automatically prepares a Helidon WebClient.Builder object using information from the OpenAPI document. The next sections describe, from simplest to most complicated, the ways your code can create an ApiClient instance, each involving increased involvement with the WebClient.Builder object. Accepting the Automatic WebClient.Builder In the simplest case, your code can get an ApiClient instance directly. <markup lang=\"java\" title=\"Creating an ApiClient instance - simple case\" >ApiClient apiClient = ApiClient.builder().build(); Your code relies fully on the automatic WebClient.Builder . In many cases, this approach works very well, especially if the OpenAPI document correctly declares the servers and their URIs. Influencing the Automatic WebClient.Builder Your code can use the ApiClient.Builder to fine-tune the settings for the internal WebClient.Builder . For instance, your code can set an object mapper to be used for Jackson processing or the JsonbConfig object to be used for JSON-B processing, depending on which serialization library you chose when you ran the generator. Your code does not need to know how the object mapper setting is conveyed to the internal WebClient.Builder . The ApiClient.Builder knows how to do that. <markup lang=\"java\" title=\"Creating an ApiClient instance - influencing the ApiClient.Builder \" >ApiClient apiClient = apiClient.builder() .objectMapper(yourCustomMapper) .build(); Adjusting the Automatic WebClient.Builder In more complicated situations, your code can adjust the settings of the WebClient.Builder the ApiClient.Builder creates. <markup lang=\"java\" title=\"Creating an ApiClient instance - adjusting the WebClient.Builder \" >ApiClient.Builder apiClientBuilder = ApiClient.builder(); apiClientBuilder.webClientBuilder() .connectTimeout(4, TimeUnit.SECONDS); ApiClient apiClient = apiClientBuilder.build(); Access the ApiClient.Builder&#8217;s automatic `WebClient.Builder instance. Adjust a setting of the WebClient.Builder directly. Build the ApiClient which implicitly builds the WebClient from the now-adjusted internal WebClient.Builder . The automatic WebClient.Builder retains information derived from the OpenAPI document unless your code overrides those specific settings. Providing a Custom WebClient.Builder Lastly, you can construct the WebClient.Builder entirely yourself and have the ApiClient.Builder use it instead of its own internal builder. <markup lang=\"java\" title=\"Creating an ApiClient instance - using a custom WebClient.Builder \" >WebClient.Builder customWebClientBuilder = WebClient.builder() .connectTimeout(3, TimeUnit.SECONDS) .baseUri(\"https://myservice.mycompany.com\"); ApiClient apiClient = ApiClient.builder() .webClientBuilder(customWebClientBuilder) .build(); Note that this approach entirely replaces the internal, automatically-prepared WebClient.Builder with yours; it does not merge the new builder with the internal one. In particular, any information from the OpenAPI document the generator used to prepare the internal WebClient.Builder is lost. Creating a PetApi Instance The ApiClient represents the connection to the remote server but not the individual RESTful operations. Each generated xxxApi interface exposes a method for each operation declared in the OpenAPI document associated with that API via its tags value. By example, the PetApi interface exposes a method for each operation in the OpenAPI document that pertains to pets. To invoke an operation defined on the PetApi interface, your code instantiates a PetApi using an ApiClient object: <markup lang=\"java\" title=\"Preparing the PetStore Client API\" >ApiClient apiClient = ApiClient.builder().build(); PetApi petApi = PetApiImpl.create(apiClient); Invoking Remote Endpoints With the petApi object, your code can invoke any of the methods on the PetApi interface to contact the remote service. The Helidon SE client generator creates an ApiResponse interface. Each generated PetApi method returns an ApiResponse&lt;returnType&gt; where the returnType is the return type declared in the OpenAPI document for the corresponding operation. The ApiResponse interface exposes two methods your code can use to work with the response from the remote service invocation: T result() Provides access to the value returned by the remote service in the response. This method lets your code fetch the return value directly. HTTPClientResponse webClientResponse() Provides access to the Helidon HTTPClientResponse object. Your code can find out the HTTP return status, read headers in the response, and process the content (if any) in the response however it needs to. In the Helidon WebClient model, the first part of the response message can arrive (the status and headers are available) before the entity in the body of the response is readable. So there are two events associated with an incoming HTTP response: when the response excluding the entity content has arrived, and when your code can begin consuming the entity content. You can adopt different styles of retrieving the results, depending on the specific needs of the code you are writing. Access with status checking The Helidon WebClient programming model includes a HTTPClientResponse interface which exposes all aspects of the HTTP response returned from the remote service. The next example shows how your code can use the HTTPClientResponse . <markup lang=\"java\" title=\"Access with status checking\" >ApiResponse&lt;List&lt;Pet&gt;&gt; apiResponse = petApi.findPetsByStatus(List.of(Pet.StatusEnum.AVAILABLE.value())); HTTPClientResponse webClientResponse = apiResponse.webClientResponse(); if (webClientResponse.status().code() != 200) { // Handle a non-successful status. } List&lt;Pet&gt;&gt; availablePets = apiResponse.result(); Start the remote service invocation. Wait for the HTTP response status and headers to arrive. Check the status in the HTTP response. Wait for the content to arrive subject to a four-second timeout. This code also blocks the current thread, first to wait for the initial response and then to wait for the result content. ",
            "title": "Using the Generated Code"
        },
        {
            "location": "/se/openapi/openapi-generator",
            "text": " OpenAPI Generator Official Website OpenAPI Generator GitHub Repository OpenAPI specification Helidon WebClient documentation ",
            "title": "References"
        },
        {
            "location": "/se/openapi/openapi-ui",
            "text": " Overview Maven Coordinates Usage API Configuration Additional Information ",
            "title": "Contents"
        },
        {
            "location": "/se/openapi/openapi-ui",
            "text": " SmallRye offers an OpenAPI user interface component which displays a web page based on your application&#8217;s OpenAPI document. Through that UI, users can invoke the operations declared in the document. Note The Helidon team discourages including the OpenAPI UI in production applications. The OpenAPI UI can be useful for demonstrating and testing your service&#8217;s endpoints prior to deployment. The Helidon OpenAPI component allows you to integrate the SmallRye UI into your application, adding the UI web page to your application very simply. ",
            "title": "Overview"
        },
        {
            "location": "/se/openapi/openapi-ui",
            "text": " To enable Helidon OpenAPI UI support add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.openapi-ui&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-openapi-ui&lt;/artifactId&gt; &lt;/dependency&gt; And add a runtime dependency on the SmallRye UI. <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.smallrye&lt;/groupId&gt; &lt;artifactId&gt;smallrye-open-api-ui&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; Also, make sure your project has the following dependency. <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.openapi&lt;/groupId&gt; &lt;artifactId&gt;helidon-openapi&lt;/artifactId&gt; &lt;/dependency&gt; This dependency allows your application to create, configure, and register the OpenApiFeature service. ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/openapi/openapi-ui",
            "text": " Make sure your application incorporates Helidon OpenAPI support as described in detail in the Helidon OpenAPI documentation ). Helidon automatically prepares the OpenAPI UI with default settings if you also declare a dependency on the Helidon OpenAPI UI integration component as explained above. The API section below illustrates adding OpenAPI to your application and customizing the UI behavior. After you modify, build, and start your Helidon SE service, you can access the OpenAPI UI by default at http://your-host:your-port/openapi/ui . Helidon also uses conventional content negotiation at http://your-host:your-port/openapi returning the UI to browsers (or any client that accepts HTML) and the OpenAPI document otherwise. You can customize the path using either the API or configuration . The example below shows the UI if you modify the Helidon SE QuickStart greeting application to contain a static OpenAPI file which describes the service endpoints. Example OpenAPI UI Screen With the OpenAPI UI displayed, follow these steps to access one of your service&#8217;s operations. Find the operation you want to run and click on its row in the list. The UI expands the operation, showing any input parameters and the possible responses. Click the \"Try it out\" button in the operation&#8217;s row. The UI now allows you to type into the input parameter field(s) to the right of each parameter name. Enter any required parameter values (first highlighted rectangle) and any non-required values you wish, then click \"Execute\" (highlighted arrow). Just below the \"Execute\" button the UI shows several sections: the equivalent curl command for submitting the request with your inputs, the URL used for the request, and a new \"Server response\" section (second highlighted rectangle) containing several items from the response: HTTP status code body headers The next image shows the screen after you submit the \"Returns a personalized greeting\" operation. Note that the UI shows the actual response from invoking the operation in the \"Server response\" section. The \"Responses\" section farther below describes the possible responses from the operation as declared in the OpenAPI document for the application. Example OpenAPI UI Screen ",
            "title": "Usage"
        },
        {
            "location": "/se/openapi/openapi-ui",
            "text": " Some applications explicitly create the OpenApiFeature object to tailor its behavior before registering it with the server. If your pom.xml includes a dependency on the OpenAPI UI component, then any OpenApiFeature object your application builds prepares the default OpenAPI UI behavior, possibly modified as above by any UI settings you have in your configuration. <markup lang=\"java\" title=\"Create OpenApiFeature with automatic UI\" >Config config = Config.create(); Config.global(config); WebServer server = WebServer.builder() .config(config.get(\"server\")) .addFeature(OpenApiFeature.create(Config.global().get(\"openapi\"))) .routing(Main::routing) .build() .start(); Load and set the global configuration. Add the OpenAPI feature to the server, configured using the openapi section of the configuration. If your code invokes the OpenApiFeature.Builder config method, Helidon automatically applies the ui section of the openapi configuration to the UI. ",
            "title": "Creating OpenApiFeature with Automatic UI Behavior"
        },
        {
            "location": "/se/openapi/openapi-ui",
            "text": " You can control some of the behavior of the UI programmatically in two steps: Create an OpenApiUi.Builder and invoke methods on it to set the UI behavior, then invoke the builder&#8217;s build method to create the OpenApiUi object. Invoke the addService method on OpenApiFeature.Builder , passing the OpenApiUi object you prepared above. The following example illustrates these steps, combining configuration with explicit programmatic settings. <markup lang=\"java\" title=\"Create OpenApiUi and OpenAPISupport instances\" >Config config = Config.create(); Config.global(config); Config openApiConfig = Config.global().get(\"openapi\"); WebServer server = WebServer.builder() .config(config.get(\"server\")) .addFeature(OpenApiFeature.builder() .addService(OpenApiUi.builder() .webContext(\"my-ui\") .config(openApiConfig.get(\"ui\")) .build()) .config(openApiConfig) .build()) .routing(Main::routing) .build() .start(); Load and set global configuration. Extract the openapi config. Begin setting up the OpenApiFeature builder. Create the UI builder. Set UI behavior programmatically. Set additional UI behavior based on UI configuration. Build the OpenApiUi object. Build the OpenApiFeature object. The order in which your code invokes the methods on OpenApiUi.Builder and OpenApiFeature.Builder determines the outcome. For instance, the example above adds the UI service to the OpenApiFeature.Builder before applying configuration to the OpenApiFeature.Builder . If the configuration contains a setting for the UI&#8217;s web-context value, then the UI uses the configured value and not the programmatic value because your code applies the configuration later. Your code should typically apply configuration after setting any values programmatically. Doing so allows users or deployers of your service to set the behavior using configuration according to their particular needs which your code might not be able to anticipate. Note The webContext(String) method on OpenApiUi.Builder sets the web context where the UI should respond instead of the default /openapi/ui . Helidon uses the provided string to set the entire web context for the UI, not as a suffix appended to the web context for the OpenAPISupport service. ",
            "title": "Customizing the UI Behavior"
        },
        {
            "location": "/se/openapi/openapi-ui",
            "text": " With the Helidon OpenAPI UI dependency in your pom.xml file, Helidon&#8217;s OpenAPI support automatically includes the default UI behavior, possibly modified by any UI settings you have in your configuration. You do not have to do anything else to enable the UI. Creating OpenApiFeature with Automatic UI Behavior Some applications explicitly create the OpenApiFeature object to tailor its behavior before registering it with the server. If your pom.xml includes a dependency on the OpenAPI UI component, then any OpenApiFeature object your application builds prepares the default OpenAPI UI behavior, possibly modified as above by any UI settings you have in your configuration. <markup lang=\"java\" title=\"Create OpenApiFeature with automatic UI\" >Config config = Config.create(); Config.global(config); WebServer server = WebServer.builder() .config(config.get(\"server\")) .addFeature(OpenApiFeature.create(Config.global().get(\"openapi\"))) .routing(Main::routing) .build() .start(); Load and set the global configuration. Add the OpenAPI feature to the server, configured using the openapi section of the configuration. If your code invokes the OpenApiFeature.Builder config method, Helidon automatically applies the ui section of the openapi configuration to the UI. Customizing the UI Behavior You can control some of the behavior of the UI programmatically in two steps: Create an OpenApiUi.Builder and invoke methods on it to set the UI behavior, then invoke the builder&#8217;s build method to create the OpenApiUi object. Invoke the addService method on OpenApiFeature.Builder , passing the OpenApiUi object you prepared above. The following example illustrates these steps, combining configuration with explicit programmatic settings. <markup lang=\"java\" title=\"Create OpenApiUi and OpenAPISupport instances\" >Config config = Config.create(); Config.global(config); Config openApiConfig = Config.global().get(\"openapi\"); WebServer server = WebServer.builder() .config(config.get(\"server\")) .addFeature(OpenApiFeature.builder() .addService(OpenApiUi.builder() .webContext(\"my-ui\") .config(openApiConfig.get(\"ui\")) .build()) .config(openApiConfig) .build()) .routing(Main::routing) .build() .start(); Load and set global configuration. Extract the openapi config. Begin setting up the OpenApiFeature builder. Create the UI builder. Set UI behavior programmatically. Set additional UI behavior based on UI configuration. Build the OpenApiUi object. Build the OpenApiFeature object. The order in which your code invokes the methods on OpenApiUi.Builder and OpenApiFeature.Builder determines the outcome. For instance, the example above adds the UI service to the OpenApiFeature.Builder before applying configuration to the OpenApiFeature.Builder . If the configuration contains a setting for the UI&#8217;s web-context value, then the UI uses the configured value and not the programmatic value because your code applies the configuration later. Your code should typically apply configuration after setting any values programmatically. Doing so allows users or deployers of your service to set the behavior using configuration according to their particular needs which your code might not be able to anticipate. Note The webContext(String) method on OpenApiUi.Builder sets the web context where the UI should respond instead of the default /openapi/ui . Helidon uses the provided string to set the entire web context for the UI, not as a suffix appended to the web context for the OpenAPISupport service. ",
            "title": "API"
        },
        {
            "location": "/se/openapi/openapi-ui",
            "text": " Optional configuration options key type default value description enabled boolean true Sets whether the service should be enabled. @return `true` if enabled, `false` otherwise options Map&lt;string, string&gt; &#160; Merges implementation-specific UI options. @return options for the UI to merge web-context string &#160; Full web context (not just the suffix). @return full web context path The default UI web-context value is the web context for your OpenApiFeature service with the added suffix /ui . If you use the default web context for both OpenApiFeature and the UI, the UI responds at /openapi/ui . You can use configuration to affect the UI path in two ways: Configure the OpenAPI endpoint path (the /openapi part). Recall that you can configure the Helidon OpenAPI component to change where it serves the OpenAPI document. <markup lang=\"yaml\" title=\"Configuring the OpenAPI web context\" >openapi: web-context: /my-openapi In this case, the path for the UI component is your customized OpenAPI path with /ui as a suffix. With the example above, the UI responds at /my-openapi/ui and Helidon uses standard content negotiation at /my-openapi to return either the OpenAPI document or the UI. Separately, configure the entire web context path for the UI independently from the web context for OpenAPI. <markup lang=\"yaml\" title=\"Configuring the OpenAPI UI web context\" >openapi: services: ui: web-context: /my-ui Note The openapi.services.ui.web-context setting assigns the entire web-context for the UI, not the suffix appended to the OpenApiFeature endpoint. With this configuration, the UI responds at /my-ui regardless of the path for OpenAPI itself. The SmallRye OpenAPI UI component accepts several options, but they are of minimal use to application developers and they must be passed to the SmallRye UI code programmatically. Helidon allows you to specify these values using configuration in the openapi.services.ui.options section. Helidon then passes the corresponding options to SmallRye for you. To configure any of these settings, use the enum values&#8212;&#8203;they are all lower case&#8212;&#8203;declared in the SmallRye Option.java class as the keys in your Helidon configuration. Note Helidon prepares several of the SmallRye options automatically based on other settings. Any options you configure override the values Helidon assigns, possibly interfering with the proper operation of the UI. ",
            "title": "Configuration options"
        },
        {
            "location": "/se/openapi/openapi-ui",
            "text": " To use configuration to control how the Helidon OpenAPI UI service behaves, add an openapi.services.ui section to your configuration file, such as application.yaml . Type: io.helidon.integrations.openapi.ui.OpenApiUi Configuration options Optional configuration options key type default value description enabled boolean true Sets whether the service should be enabled. @return `true` if enabled, `false` otherwise options Map&lt;string, string&gt; &#160; Merges implementation-specific UI options. @return options for the UI to merge web-context string &#160; Full web context (not just the suffix). @return full web context path The default UI web-context value is the web context for your OpenApiFeature service with the added suffix /ui . If you use the default web context for both OpenApiFeature and the UI, the UI responds at /openapi/ui . You can use configuration to affect the UI path in two ways: Configure the OpenAPI endpoint path (the /openapi part). Recall that you can configure the Helidon OpenAPI component to change where it serves the OpenAPI document. <markup lang=\"yaml\" title=\"Configuring the OpenAPI web context\" >openapi: web-context: /my-openapi In this case, the path for the UI component is your customized OpenAPI path with /ui as a suffix. With the example above, the UI responds at /my-openapi/ui and Helidon uses standard content negotiation at /my-openapi to return either the OpenAPI document or the UI. Separately, configure the entire web context path for the UI independently from the web context for OpenAPI. <markup lang=\"yaml\" title=\"Configuring the OpenAPI UI web context\" >openapi: services: ui: web-context: /my-ui Note The openapi.services.ui.web-context setting assigns the entire web-context for the UI, not the suffix appended to the OpenApiFeature endpoint. With this configuration, the UI responds at /my-ui regardless of the path for OpenAPI itself. The SmallRye OpenAPI UI component accepts several options, but they are of minimal use to application developers and they must be passed to the SmallRye UI code programmatically. Helidon allows you to specify these values using configuration in the openapi.services.ui.options section. Helidon then passes the corresponding options to SmallRye for you. To configure any of these settings, use the enum values&#8212;&#8203;they are all lower case&#8212;&#8203;declared in the SmallRye Option.java class as the keys in your Helidon configuration. Note Helidon prepares several of the SmallRye options automatically based on other settings. Any options you configure override the values Helidon assigns, possibly interfering with the proper operation of the UI. ",
            "title": "Configuration"
        },
        {
            "location": "/se/openapi/openapi-ui",
            "text": " Helidon OpenAPI SE documentation SmallRye OpenAPI UI GitHub site ",
            "title": "Additional Information"
        },
        {
            "location": "/se/openapi/openapi",
            "text": " Overview Maven Coordinates Usage API Configuration Examples ",
            "title": "Contents"
        },
        {
            "location": "/se/openapi/openapi",
            "text": " The OpenAPI specification defines a standard way to express the interface exposed by a REST service. The MicroProfile OpenAPI spec explains how MicroProfile embraces OpenAPI, adding annotations, configuration, and a service provider interface (SPI). OpenAPI support in Helidon SE draws its inspiration from MicroProfile OpenAPI but does not implement the spec because Helidon SE does not support annotations. The OpenAPI support in Helidon SE performs two main tasks: Build an in-memory model of the REST API your service implements. Expose the model in text format (YAML or JSON) via the /openapi endpoint. To construct the model, Helidon gathers information about the service API from a static OpenAPI document file packaged as part of your service. ",
            "title": "Overview"
        },
        {
            "location": "/se/openapi/openapi",
            "text": " To enable OpenAPI add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.openapi&lt;/groupId&gt; &lt;artifactId&gt;helidon-openapi&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/openapi/openapi",
            "text": " Simply by adding the dependency described above you add support for OpenAPI to your Helidon SE application. Because Helidon automatically discovers the OpenAPI feature, you do not have to make any changes to your application code. ",
            "title": "Automatic Registration (default)"
        },
        {
            "location": "/se/openapi/openapi",
            "text": " Helidon SE provides the OpenApiFeature class which your application uses to assemble the in-memory model and expose the /openapi endpoint to clients. You can create an instance either using a static create method or by instantiating its Builder . The example below illustrates one way to do this. ",
            "title": "Create and Register OpenApiFeature in your application"
        },
        {
            "location": "/se/openapi/openapi",
            "text": " Add a static file at META-INF/openapi.yml , META-INF/openapi.yaml , or META-INF/openapi.json . Tools such as Swagger let you describe your app&#8217;s API and they then generate an OpenAPI document file which you can include in your application so OpenAPI can use it. ",
            "title": "Provide a static OpenAPI file"
        },
        {
            "location": "/se/openapi/openapi",
            "text": " Your application supplies data for the OpenAPI model using a static OpenAPI file. Provide a static OpenAPI file Add a static file at META-INF/openapi.yml , META-INF/openapi.yaml , or META-INF/openapi.json . Tools such as Swagger let you describe your app&#8217;s API and they then generate an OpenAPI document file which you can include in your application so OpenAPI can use it. ",
            "title": "Furnish OpenAPI information about your endpoints"
        },
        {
            "location": "/se/openapi/openapi",
            "text": " To control the behavior of the OpenAPI feature programmatically, you can add and configure the OpenAPI feature explicitly as explained below. Create and Register OpenApiFeature in your application Helidon SE provides the OpenApiFeature class which your application uses to assemble the in-memory model and expose the /openapi endpoint to clients. You can create an instance either using a static create method or by instantiating its Builder . The example below illustrates one way to do this. Furnish OpenAPI information about your endpoints Your application supplies data for the OpenAPI model using a static OpenAPI file. Provide a static OpenAPI file Add a static file at META-INF/openapi.yml , META-INF/openapi.yaml , or META-INF/openapi.json . Tools such as Swagger let you describe your app&#8217;s API and they then generate an OpenAPI document file which you can include in your application so OpenAPI can use it. ",
            "title": "Explicit Registration"
        },
        {
            "location": "/se/openapi/openapi",
            "text": " Once you have added the SE OpenAPI dependency to your project, if you are using auto-discovery&#8212;&#8203;or if you are not using auto-discovery and you have added code to register the OpenApiFeature object with your routing&#8212;&#8203;then your application responds to the built-in endpoint&#8201;&#8212;&#8201; /openapi &#8201;&#8212;&#8201;and returns the OpenAPI document describing the endpoints in your application. The default format of the OpenAPI document is YAML. There is not yet an adopted IANA YAML media type, but a proposed one specifically for OpenAPI documents that has some support is application/vnd.oai.openapi . That is what Helidon returns by default. In addition, a client can specify the HTTP header Accept as either application/vnd.oai.openapi+json or application/json to request JSON. Alternatively, the client can pass the query parameter format as either JSON or YAML to receive application/json or application/vnd.oai.openapi (YAML) output, respectively. ",
            "title": "Accessing the REST Endpoint"
        },
        {
            "location": "/se/openapi/openapi",
            "text": " Automatic Registration (default) Simply by adding the dependency described above you add support for OpenAPI to your Helidon SE application. Because Helidon automatically discovers the OpenAPI feature, you do not have to make any changes to your application code. Explicit Registration To control the behavior of the OpenAPI feature programmatically, you can add and configure the OpenAPI feature explicitly as explained below. Create and Register OpenApiFeature in your application Helidon SE provides the OpenApiFeature class which your application uses to assemble the in-memory model and expose the /openapi endpoint to clients. You can create an instance either using a static create method or by instantiating its Builder . The example below illustrates one way to do this. Furnish OpenAPI information about your endpoints Your application supplies data for the OpenAPI model using a static OpenAPI file. Provide a static OpenAPI file Add a static file at META-INF/openapi.yml , META-INF/openapi.yaml , or META-INF/openapi.json . Tools such as Swagger let you describe your app&#8217;s API and they then generate an OpenAPI document file which you can include in your application so OpenAPI can use it. Accessing the REST Endpoint Once you have added the SE OpenAPI dependency to your project, if you are using auto-discovery&#8212;&#8203;or if you are not using auto-discovery and you have added code to register the OpenApiFeature object with your routing&#8212;&#8203;then your application responds to the built-in endpoint&#8201;&#8212;&#8201; /openapi &#8201;&#8212;&#8201;and returns the OpenAPI document describing the endpoints in your application. The default format of the OpenAPI document is YAML. There is not yet an adopted IANA YAML media type, but a proposed one specifically for OpenAPI documents that has some support is application/vnd.oai.openapi . That is what Helidon returns by default. In addition, a client can specify the HTTP header Accept as either application/vnd.oai.openapi+json or application/json to request JSON. Alternatively, the client can pass the query parameter format as either JSON or YAML to receive application/json or application/vnd.oai.openapi (YAML) output, respectively. ",
            "title": "Usage"
        },
        {
            "location": "/se/openapi/openapi",
            "text": " Helidon SE provides an API for creating and setting up the REST endpoint which serves OpenAPI documents to clients at the /openapi path. Use either static methods on OpenApiFeature or use its Builder . Then add that instance or builder to your application&#8217;s routing. The example below shows how to do this. ",
            "title": "API"
        },
        {
            "location": "/se/openapi/openapi",
            "text": " Optional configuration options key type default value description cors CrossOriginConfig &#160; CORS config. @return CORS config enabled boolean true Sets whether the feature should be enabled. @return `true` if enabled, `false` otherwise manager io.helidon.openapi.OpenApiManager (service provider interface) &#160; OpenAPI manager. @return the OpenAPI manager permit-all boolean &#160; Whether to allow anybody to access the endpoint. @return whether to permit access to metrics endpoint to anybody, defaults to `true` @see #roles() roles string[&#93; &#160; Hints for role names the user is expected to be in. @return list of hints services io.helidon.openapi.OpenApiService[&#93; (service provider interface) &#160; OpenAPI services. @return the OpenAPI services static-file string &#160; Path of the static OpenAPI document file. Default types are json , yaml , and yml . @return location of the static OpenAPI document file web-context string /openapi Web context path for the OpenAPI endpoint. @return webContext to use ",
            "title": "Configuration options"
        },
        {
            "location": "/se/openapi/openapi",
            "text": " Helidon SE OpenAPI configuration supports the following settings: Type: io.helidon.openapi.OpenApiFeature This is a standalone configuration type, prefix from configuration root: openapi Configuration options Optional configuration options key type default value description cors CrossOriginConfig &#160; CORS config. @return CORS config enabled boolean true Sets whether the feature should be enabled. @return `true` if enabled, `false` otherwise manager io.helidon.openapi.OpenApiManager (service provider interface) &#160; OpenAPI manager. @return the OpenAPI manager permit-all boolean &#160; Whether to allow anybody to access the endpoint. @return whether to permit access to metrics endpoint to anybody, defaults to `true` @see #roles() roles string[&#93; &#160; Hints for role names the user is expected to be in. @return list of hints services io.helidon.openapi.OpenApiService[&#93; (service provider interface) &#160; OpenAPI services. @return the OpenAPI services static-file string &#160; Path of the static OpenAPI document file. Default types are json , yaml , and yml . @return location of the static OpenAPI document file web-context string /openapi Web context path for the OpenAPI endpoint. @return webContext to use ",
            "title": "Configuration"
        },
        {
            "location": "/se/openapi/openapi",
            "text": "<markup lang=\"java\" title=\"Java Code to Create and Register OpenAPISupport \" >Config config = Config.create(); Config.global(config); WebServer server = WebServer.builder() .config(config.get(\"server\")) .addFeature(OpenApiFeature.create(Config.global().get(\"openapi\"))) .routing(Main::routing) .build() .start(); Initializes the global Config instance from the default configuration. Adds the OpenApiFeature service to your server using the openapi section from configuration. If you need programmatic control over the OpenApiFeature instance, invoke OpenApiFeature.builder() to get an OpenApiFeature.Builder object and work with it, then invoke the builder&#8217;s build method and pass the resulting OpenApiFeature instance to the WebServer.Builder addFeature method. ",
            "title": "Register OpenApiFeature explicitly"
        },
        {
            "location": "/se/openapi/openapi",
            "text": " Helidon SE provides a complete OpenAPI example based on the SE QuickStart sample app. Most Helidon SE applications need only add the dependency as explained above; Helidon discovers and registers OpenAPI automatically. The example below shows how to create and register OpenApiFeature explicitly instead. Register OpenApiFeature explicitly <markup lang=\"java\" title=\"Java Code to Create and Register OpenAPISupport \" >Config config = Config.create(); Config.global(config); WebServer server = WebServer.builder() .config(config.get(\"server\")) .addFeature(OpenApiFeature.create(Config.global().get(\"openapi\"))) .routing(Main::routing) .build() .start(); Initializes the global Config instance from the default configuration. Adds the OpenApiFeature service to your server using the openapi section from configuration. If you need programmatic control over the OpenApiFeature instance, invoke OpenApiFeature.builder() to get an OpenApiFeature.Builder object and work with it, then invoke the builder&#8217;s build method and pass the resulting OpenApiFeature instance to the WebServer.Builder addFeature method. ",
            "title": "Examples"
        },
        {
            "location": "/se/reactive-messaging",
            "text": " Overview Maven Coordinates Usage Channel Processor Message Connectors Kafka Connector JMS Connector AQ Connector Configuration Reference ",
            "title": "Contents"
        },
        {
            "location": "/se/reactive-messaging",
            "text": " Asynchronous messaging is a commonly used form of communication in the world of microservices. While it is possible to start building your reactive streams directly by combining operators and connecting them to reactive APIs, with Helidon SE Reactive Messaging, you can now use prepared tools for repetitive use case scenarios . ",
            "title": "Overview"
        },
        {
            "location": "/se/reactive-messaging",
            "text": " To enable Reactive Messaging add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.messaging&lt;/groupId&gt; &lt;artifactId&gt;helidon-messaging&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/reactive-messaging",
            "text": " A channel is a named pair of Publisher and Subscriber . Channels can be connected together by processors . Registering a Publisher or Subscriber for a channel can be done by Messaging API, or configured implicitly using registered connectors to generate the Publisher or Subscriber . <markup lang=\"java\" title=\"Example of simple channel:\" >Channel&lt;String&gt; channel1 = Channel.create(\"channel1\"); Messaging.builder() .publisher(channel1, Multi.just(\"message 1\", \"message 2\") .map(Message::of)) .listener(channel1, s -&gt; System.out.println(\"Intecepted message \" + s)) .build() .start(); ",
            "title": "Channel"
        },
        {
            "location": "/se/reactive-messaging",
            "text": " Processor is a typical reactive processor acting as a Subscriber to upstream and as a Publisher to downstream. In terms of reactive messaging, it is able to connect two channels to one reactive stream. <markup lang=\"java\" title=\"Example of processor usage:\" >Channel&lt;String&gt; firstChannel = Channel.create(\"first-channel\"); Channel&lt;String&gt; secondChannel = Channel.create(\"second-channel\"); Messaging.builder() .publisher(secondChannel, ReactiveStreams.of(\"test1\", \"test2\", \"test3\") .map(Message::of)) .processor(secondChannel, firstChannel, ReactiveStreams.&lt;Message&lt;String&gt;&gt;builder() .map(Message::getPayload) .map(String::toUpperCase) .map(Message::of) ) .subscriber(firstChannel, ReactiveStreams.&lt;Message&lt;String&gt;&gt;builder() .peek(Message::ack) .map(Message::getPayload) .forEach(s -&gt; System.out.println(\"Consuming message \" + s))) .build() .start(); &gt;Consuming message TEST1 &gt;Consuming message TEST2 &gt;Consuming message TEST3 ",
            "title": "Processor"
        },
        {
            "location": "/se/reactive-messaging",
            "text": " Reactive Messaging in Helidon SE uses the same concept of message wrapping as MicroProfile messaging. The only notable difference is that SE Messaging does almost no implicit or automatic acknowledgement due to no magic philosophy of Helidon SE. The only exception to this are the variants of the methods Messaging.Builder#listener and Messaging.Builder#processor configured with consumer or function parameters which will conveniently unwrap the payload for you. Once the payload is automatically unwrapped, it is not possible to do a manual acknowledgement, therefore an implicit acknowledgement is executed before the callback. ",
            "title": "Message"
        },
        {
            "location": "/se/reactive-messaging",
            "text": " An explicit config for channel&#8217;s publisher is possible with Channel.Builder#publisherConfig(Config config) and for a subscriber with the Channel.Builder#subscriberConfig(Config config) . The supplied Helidon Config is merged with the mandatory attributes and any implicit configuration found. The resulting configuration is then served to the Connector. <markup lang=\"java\" title=\"Example consuming from Kafka connector with explicit config:\" >String kafkaServer = config.get(\"app.kafka.bootstrap.servers\").asString().get(); String topic = config.get(\"app.kafka.topic\").asString().get(); Channel&lt;String&gt; fromKafka = Channel.&lt;String&gt;builder() .name(\"from-kafka\") .publisherConfig(KafkaConnector.configBuilder() .bootstrapServers(kafkaServer) .groupId(\"example-group-\" + session.getId()) .topic(topic) .autoOffsetReset(KafkaConfigBuilder.AutoOffsetReset.LATEST) .enableAutoCommit(true) .keyDeserializer(StringDeserializer.class) .valueDeserializer(StringDeserializer.class) .build() ) .build(); KafkaConnector kafkaConnector = KafkaConnector.create(); Messaging messaging = Messaging.builder() .connector(kafkaConnector) .listener(fromKafka, payload -&gt; { System.out.println(\"Kafka says: \" + payload); }) .build() .start(); Prepare channel for connecting kafka connector with specific publisher configuration &#8594; listener, Channel &#8594; connector mapping is automatic when using KafkaConnector.configBuilder() Prepare Kafka connector, can be used by any channel ",
            "title": "Explicit Config for Messaging Connector"
        },
        {
            "location": "/se/reactive-messaging",
            "text": " Implicit config without any hard-coding is possible with Helidon Config following notation of MicroProfile Reactive Messaging . <markup lang=\"yaml\" title=\"Example of channel to connector mapping config with custom properties:\" >mp.messaging.incoming.from-connector-channel.connector: example-connector mp.messaging.incoming.from-connector-channel.first-test-prop: foo mp.messaging.connector.example-connector.second-test-prop: bar Channel &#8594; Connector mapping Channel configuration properties Connector configuration properties <markup lang=\"java\" title=\"Example consuming from connector:\" >Config config = Config.create(); Messaging.builder() .config(config) .connector(new ExampleConnector()) .listener(Channel.create(\"from-connector-channel\"), s -&gt; System.out.println(\"Consuming: \" + s)) .build() .start(); &gt; Consuming: foo &gt; Consuming: bar ",
            "title": "Implicit Config for Messaging Connector"
        },
        {
            "location": "/se/reactive-messaging",
            "text": " A messaging connector in Helidon SE can be configured explicitly by API or implicitly by config following the notation of MicroProfile Reactive Messaging . Configuration that is supplied to connector by the Messaging implementation must include two mandatory attributes: channel-name which is the name of the channel that has the connector configured as Publisher or Subscriber, or Channel.create('name-of-channel') in case of explicit configuration or mp.messaging.incoming.name-of-channel.connector: connector-name in case of implicit config connector name of the connector @Connector(\"connector-name\") <markup lang=\"java\" title=\"Example connector accessing configuration:\" >@Connector(\"example-connector\") public class ExampleConnector implements IncomingConnectorFactory { @Override public PublisherBuilder&lt;? extends Message&lt;?&gt;&gt; getPublisherBuilder(final Config config) { String firstPropValue = config.getValue(\"first-test-prop\", String.class); String secondPropValue = config.getValue(\"second-test-prop\", String.class); return ReactiveStreams.of(firstPropValue, secondPropValue) .map(Message::of); } } Config context is merged from channel and connector contexts Explicit Config for Messaging Connector An explicit config for channel&#8217;s publisher is possible with Channel.Builder#publisherConfig(Config config) and for a subscriber with the Channel.Builder#subscriberConfig(Config config) . The supplied Helidon Config is merged with the mandatory attributes and any implicit configuration found. The resulting configuration is then served to the Connector. <markup lang=\"java\" title=\"Example consuming from Kafka connector with explicit config:\" >String kafkaServer = config.get(\"app.kafka.bootstrap.servers\").asString().get(); String topic = config.get(\"app.kafka.topic\").asString().get(); Channel&lt;String&gt; fromKafka = Channel.&lt;String&gt;builder() .name(\"from-kafka\") .publisherConfig(KafkaConnector.configBuilder() .bootstrapServers(kafkaServer) .groupId(\"example-group-\" + session.getId()) .topic(topic) .autoOffsetReset(KafkaConfigBuilder.AutoOffsetReset.LATEST) .enableAutoCommit(true) .keyDeserializer(StringDeserializer.class) .valueDeserializer(StringDeserializer.class) .build() ) .build(); KafkaConnector kafkaConnector = KafkaConnector.create(); Messaging messaging = Messaging.builder() .connector(kafkaConnector) .listener(fromKafka, payload -&gt; { System.out.println(\"Kafka says: \" + payload); }) .build() .start(); Prepare channel for connecting kafka connector with specific publisher configuration &#8594; listener, Channel &#8594; connector mapping is automatic when using KafkaConnector.configBuilder() Prepare Kafka connector, can be used by any channel Implicit Config for Messaging Connector Implicit config without any hard-coding is possible with Helidon Config following notation of MicroProfile Reactive Messaging . <markup lang=\"yaml\" title=\"Example of channel to connector mapping config with custom properties:\" >mp.messaging.incoming.from-connector-channel.connector: example-connector mp.messaging.incoming.from-connector-channel.first-test-prop: foo mp.messaging.connector.example-connector.second-test-prop: bar Channel &#8594; Connector mapping Channel configuration properties Connector configuration properties <markup lang=\"java\" title=\"Example consuming from connector:\" >Config config = Config.create(); Messaging.builder() .config(config) .connector(new ExampleConnector()) .listener(Channel.create(\"from-connector-channel\"), s -&gt; System.out.println(\"Consuming: \" + s)) .build() .start(); &gt; Consuming: foo &gt; Consuming: bar ",
            "title": "Configuration for Messaging Connector"
        },
        {
            "location": "/se/reactive-messaging",
            "text": " A connector for Reactive Messaging is a factory that produces Publishers and Subscribers for Channels in Reactive Messaging. Messaging connector is just an implementation of IncomingConnectorFactory , OutgoingConnectorFactory or both. <markup lang=\"java\" title=\"Example connector example-connector :\" >@Connector(\"example-connector\") public class ExampleConnector implements IncomingConnectorFactory, OutgoingConnectorFactory { @Override public PublisherBuilder&lt;? extends Message&lt;?&gt;&gt; getPublisherBuilder(Config config) { return ReactiveStreams.of(\"foo\", \"bar\") .map(Message::of); } @Override public SubscriberBuilder&lt;? extends Message&lt;?&gt;, Void&gt; getSubscriberBuilder(Config config) { return ReactiveStreams.&lt;Message&lt;?&gt;&gt;builder() .map(Message::getPayload) .forEach(o -&gt; System.out.println(\"Connector says: \" + o)); } } <markup lang=\"yaml\" title=\"Example of channel to connector mapping config:\" >mp.messaging.outgoing.to-connector-channel.connector: example-connector mp.messaging.incoming.from-connector-channel.connector: example-connector <markup lang=\"java\" title=\"Example producing to connector:\" >Config config = Config.create(); Messaging.builder() .config(config) .connector(new ExampleConnector()) .publisher(Channel.create(\"to-connector-channel\"), ReactiveStreams.of(\"fee\", \"fie\") .map(Message::of) ) .build() .start(); &gt; Connector says: fee &gt; Connector says: fie <markup lang=\"java\" title=\"Example consuming from connector:\" >Messaging.builder() .connector(new ExampleConnector()) .subscriber(Channel.create(\"from-connector-channel\"), ReactiveStreams.&lt;Message&lt;String&gt;&gt;builder() .peek(Message::ack) .map(Message::getPayload) .forEach(s -&gt; System.out.println(\"Consuming: \" + s)) ) .build() .start(); &gt; Consuming: foo &gt; Consuming: bar Configuration for Messaging Connector A messaging connector in Helidon SE can be configured explicitly by API or implicitly by config following the notation of MicroProfile Reactive Messaging . Configuration that is supplied to connector by the Messaging implementation must include two mandatory attributes: channel-name which is the name of the channel that has the connector configured as Publisher or Subscriber, or Channel.create('name-of-channel') in case of explicit configuration or mp.messaging.incoming.name-of-channel.connector: connector-name in case of implicit config connector name of the connector @Connector(\"connector-name\") <markup lang=\"java\" title=\"Example connector accessing configuration:\" >@Connector(\"example-connector\") public class ExampleConnector implements IncomingConnectorFactory { @Override public PublisherBuilder&lt;? extends Message&lt;?&gt;&gt; getPublisherBuilder(final Config config) { String firstPropValue = config.getValue(\"first-test-prop\", String.class); String secondPropValue = config.getValue(\"second-test-prop\", String.class); return ReactiveStreams.of(firstPropValue, secondPropValue) .map(Message::of); } } Config context is merged from channel and connector contexts Explicit Config for Messaging Connector An explicit config for channel&#8217;s publisher is possible with Channel.Builder#publisherConfig(Config config) and for a subscriber with the Channel.Builder#subscriberConfig(Config config) . The supplied Helidon Config is merged with the mandatory attributes and any implicit configuration found. The resulting configuration is then served to the Connector. <markup lang=\"java\" title=\"Example consuming from Kafka connector with explicit config:\" >String kafkaServer = config.get(\"app.kafka.bootstrap.servers\").asString().get(); String topic = config.get(\"app.kafka.topic\").asString().get(); Channel&lt;String&gt; fromKafka = Channel.&lt;String&gt;builder() .name(\"from-kafka\") .publisherConfig(KafkaConnector.configBuilder() .bootstrapServers(kafkaServer) .groupId(\"example-group-\" + session.getId()) .topic(topic) .autoOffsetReset(KafkaConfigBuilder.AutoOffsetReset.LATEST) .enableAutoCommit(true) .keyDeserializer(StringDeserializer.class) .valueDeserializer(StringDeserializer.class) .build() ) .build(); KafkaConnector kafkaConnector = KafkaConnector.create(); Messaging messaging = Messaging.builder() .connector(kafkaConnector) .listener(fromKafka, payload -&gt; { System.out.println(\"Kafka says: \" + payload); }) .build() .start(); Prepare channel for connecting kafka connector with specific publisher configuration &#8594; listener, Channel &#8594; connector mapping is automatic when using KafkaConnector.configBuilder() Prepare Kafka connector, can be used by any channel Implicit Config for Messaging Connector Implicit config without any hard-coding is possible with Helidon Config following notation of MicroProfile Reactive Messaging . <markup lang=\"yaml\" title=\"Example of channel to connector mapping config with custom properties:\" >mp.messaging.incoming.from-connector-channel.connector: example-connector mp.messaging.incoming.from-connector-channel.first-test-prop: foo mp.messaging.connector.example-connector.second-test-prop: bar Channel &#8594; Connector mapping Channel configuration properties Connector configuration properties <markup lang=\"java\" title=\"Example consuming from connector:\" >Config config = Config.create(); Messaging.builder() .config(config) .connector(new ExampleConnector()) .listener(Channel.create(\"from-connector-channel\"), s -&gt; System.out.println(\"Consuming: \" + s)) .build() .start(); &gt; Consuming: foo &gt; Consuming: bar ",
            "title": "Messaging Connector"
        },
        {
            "location": "/se/reactive-messaging",
            "text": " As the API is the same for MicroProfile Reactive Messaging connectors, all that is needed to make connector work in both ways is annotating it with @ApplicationScoped . Such connector is treated as a bean in Helidon MP. For specific information about creating messaging connectors for Helidon MP visit MicroProfile Reactive Messaging . ",
            "title": "Reusability in MP Messaging"
        },
        {
            "location": "/se/reactive-messaging",
            "text": " Connecting streams to Kafka with Reactive Messaging couldn&#8217;t be easier. ",
            "title": "Reactive Kafka Connector"
        },
        {
            "location": "/se/reactive-messaging",
            "text": "<markup lang=\"java\" title=\"Example of consuming from Kafka:\" >String kafkaServer = config.get(\"app.kafka.bootstrap.servers\").asString().get(); String topic = config.get(\"app.kafka.topic\").asString().get(); Channel&lt;String&gt; fromKafka = Channel.&lt;String&gt;builder() .name(\"from-kafka\") .publisherConfig(KafkaConnector.configBuilder() .bootstrapServers(kafkaServer) .groupId(\"example-group-\" + session.getId()) .topic(topic) .autoOffsetReset(KafkaConfigBuilder.AutoOffsetReset.LATEST) .enableAutoCommit(true) .keyDeserializer(StringDeserializer.class) .valueDeserializer(StringDeserializer.class) .build() ) .build(); KafkaConnector kafkaConnector = KafkaConnector.create(); Messaging messaging = Messaging.builder() .connector(kafkaConnector) .listener(fromKafka, payload -&gt; { System.out.println(\"Kafka says: \" + payload); }) .build() .start(); Prepare a channel for connecting kafka connector with specific publisher configuration &#8594; listener Channel &#8594; connector mapping is automatic when using KafkaConnector.configBuilder() Prepare Kafka connector, can be used by any channel <markup lang=\"java\" title=\"Example of producing to Kafka:\" >String kafkaServer = config.get(\"app.kafka.bootstrap.servers\").asString().get(); String topic = config.get(\"app.kafka.topic\").asString().get(); Channel&lt;String&gt; toKafka = Channel.&lt;String&gt;builder() .subscriberConfig(KafkaConnector.configBuilder() .bootstrapServers(kafkaServer) .topic(topic) .keySerializer(StringSerializer.class) .valueSerializer(StringSerializer.class) .build() ).build(); KafkaConnector kafkaConnector = KafkaConnector.create(); messaging = Messaging.builder() .publisher(toKafka, Multi.just(\"test1\", \"test2\").map(Message::of)) .connector(kafkaConnector) .build() .start(); Prepare a channel for connecting kafka connector with specific publisher configuration &#8594; listener Channel &#8594; connector mapping is automatic when using KafkaConnector.configBuilder() Prepare Kafka connector, can be used by any channel ",
            "title": "Explicit Config with Config Builder for Kafka Connector"
        },
        {
            "location": "/se/reactive-messaging",
            "text": "<markup lang=\"yaml\" title=\"Example of connector config:\" >mp.messaging: incoming.from-kafka: connector: helidon-kafka topic: messaging-test-topic-1 auto.offset.reset: latest enable.auto.commit: true group.id: example-group-id outgoing.to-kafka: connector: helidon-kafka topic: messaging-test-topic-1 connector: helidon-kafka: bootstrap.servers: localhost:9092 key.serializer: org.apache.kafka.common.serialization.StringSerializer value.serializer: org.apache.kafka.common.serialization.StringSerializer key.deserializer: org.apache.kafka.common.serialization.StringDeserializer value.deserializer: org.apache.kafka.common.serialization.StringDeserializer Kafka client consumer&#8217;s property auto.offset.reset configuration for from-kafka channel only Kafka client&#8217;s property bootstrap.servers configuration for all channels using the connector <markup lang=\"java\" title=\"Example of consuming from Kafka:\" >Config config = Config.create(); Channel&lt;String&gt; fromKafka = Channel.create(\"from-kafka\"); KafkaConnector kafkaConnector = KafkaConnector.create(); Messaging messaging = Messaging.builder() .config(config) .connector(kafkaConnector) .listener(fromKafka, payload -&gt; { System.out.println(\"Kafka says: \" + payload); }) .build() .start(); Prepare Kafka connector, can be used by any channel <markup lang=\"java\" title=\"Example of producing to Kafka:\" >Config config = Config.create(); Channel&lt;String&gt; toKafka = Channel.create(\"to-kafka\"); KafkaConnector kafkaConnector = KafkaConnector.create(); messaging = Messaging.builder() .config(config) .publisher(toKafka, Multi.just(\"test1\", \"test2\").map(Message::of)) .connector(kafkaConnector) .build() .start(); Prepare Kafka connector, can be used by any channel Don&#8217;t forget to check out the examples with pre-configured Kafka docker image, for easy testing: https://github.com/oracle/helidon/tree/master/examples/messaging ",
            "title": "Implicit Helidon Config for Kafka Connector"
        },
        {
            "location": "/se/reactive-messaging",
            "text": "<markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.messaging.kafka&lt;/groupId&gt; &lt;artifactId&gt;helidon-messaging-kafka&lt;/artifactId&gt; &lt;/dependency&gt; Reactive Kafka Connector Connecting streams to Kafka with Reactive Messaging couldn&#8217;t be easier. Explicit Config with Config Builder for Kafka Connector <markup lang=\"java\" title=\"Example of consuming from Kafka:\" >String kafkaServer = config.get(\"app.kafka.bootstrap.servers\").asString().get(); String topic = config.get(\"app.kafka.topic\").asString().get(); Channel&lt;String&gt; fromKafka = Channel.&lt;String&gt;builder() .name(\"from-kafka\") .publisherConfig(KafkaConnector.configBuilder() .bootstrapServers(kafkaServer) .groupId(\"example-group-\" + session.getId()) .topic(topic) .autoOffsetReset(KafkaConfigBuilder.AutoOffsetReset.LATEST) .enableAutoCommit(true) .keyDeserializer(StringDeserializer.class) .valueDeserializer(StringDeserializer.class) .build() ) .build(); KafkaConnector kafkaConnector = KafkaConnector.create(); Messaging messaging = Messaging.builder() .connector(kafkaConnector) .listener(fromKafka, payload -&gt; { System.out.println(\"Kafka says: \" + payload); }) .build() .start(); Prepare a channel for connecting kafka connector with specific publisher configuration &#8594; listener Channel &#8594; connector mapping is automatic when using KafkaConnector.configBuilder() Prepare Kafka connector, can be used by any channel <markup lang=\"java\" title=\"Example of producing to Kafka:\" >String kafkaServer = config.get(\"app.kafka.bootstrap.servers\").asString().get(); String topic = config.get(\"app.kafka.topic\").asString().get(); Channel&lt;String&gt; toKafka = Channel.&lt;String&gt;builder() .subscriberConfig(KafkaConnector.configBuilder() .bootstrapServers(kafkaServer) .topic(topic) .keySerializer(StringSerializer.class) .valueSerializer(StringSerializer.class) .build() ).build(); KafkaConnector kafkaConnector = KafkaConnector.create(); messaging = Messaging.builder() .publisher(toKafka, Multi.just(\"test1\", \"test2\").map(Message::of)) .connector(kafkaConnector) .build() .start(); Prepare a channel for connecting kafka connector with specific publisher configuration &#8594; listener Channel &#8594; connector mapping is automatic when using KafkaConnector.configBuilder() Prepare Kafka connector, can be used by any channel Implicit Helidon Config for Kafka Connector <markup lang=\"yaml\" title=\"Example of connector config:\" >mp.messaging: incoming.from-kafka: connector: helidon-kafka topic: messaging-test-topic-1 auto.offset.reset: latest enable.auto.commit: true group.id: example-group-id outgoing.to-kafka: connector: helidon-kafka topic: messaging-test-topic-1 connector: helidon-kafka: bootstrap.servers: localhost:9092 key.serializer: org.apache.kafka.common.serialization.StringSerializer value.serializer: org.apache.kafka.common.serialization.StringSerializer key.deserializer: org.apache.kafka.common.serialization.StringDeserializer value.deserializer: org.apache.kafka.common.serialization.StringDeserializer Kafka client consumer&#8217;s property auto.offset.reset configuration for from-kafka channel only Kafka client&#8217;s property bootstrap.servers configuration for all channels using the connector <markup lang=\"java\" title=\"Example of consuming from Kafka:\" >Config config = Config.create(); Channel&lt;String&gt; fromKafka = Channel.create(\"from-kafka\"); KafkaConnector kafkaConnector = KafkaConnector.create(); Messaging messaging = Messaging.builder() .config(config) .connector(kafkaConnector) .listener(fromKafka, payload -&gt; { System.out.println(\"Kafka says: \" + payload); }) .build() .start(); Prepare Kafka connector, can be used by any channel <markup lang=\"java\" title=\"Example of producing to Kafka:\" >Config config = Config.create(); Channel&lt;String&gt; toKafka = Channel.create(\"to-kafka\"); KafkaConnector kafkaConnector = KafkaConnector.create(); messaging = Messaging.builder() .config(config) .publisher(toKafka, Multi.just(\"test1\", \"test2\").map(Message::of)) .connector(kafkaConnector) .build() .start(); Prepare Kafka connector, can be used by any channel Don&#8217;t forget to check out the examples with pre-configured Kafka docker image, for easy testing: https://github.com/oracle/helidon/tree/master/examples/messaging ",
            "title": "Kafka Connector"
        },
        {
            "location": "/se/reactive-messaging",
            "text": " Connecting streams to JMS with Reactive Messaging couldn&#8217;t be easier. ",
            "title": "Reactive JMS Connector"
        },
        {
            "location": "/se/reactive-messaging",
            "text": "<markup lang=\"java\" title=\"Example of consuming from JMS:\" >Channel&lt;String&gt; fromJms = Channel.&lt;String&gt;builder() .name(\"from-jms\") .publisherConfig(JmsConnector.configBuilder() .jndiInitialFactory(ActiveMQInitialContextFactory.class) .jndiProviderUrl(\"tcp://127.0.0.1:61616\") .type(JmsConfigBuilder.Type.QUEUE) .destination(\"se-example-queue-1\") .build() ) .build(); JmsConnector jmsConnector = JmsConnector.create(); Messaging messaging = Messaging.builder() .connector(jmsConnector) .listener(fromJms, payload -&gt; { System.out.println(\"Jms says: \" + payload); }) .build() .start(); Prepare a channel for connecting jms connector with specific publisher configuration &#8594; listener Channel &#8594; connector mapping is automatic when using JmsConnector.configBuilder() Prepare JMS connector, can be used by any channel <markup lang=\"java\" title=\"Example of producing to JMS:\" >Channel&lt;String&gt; toJms = Channel.&lt;String&gt;builder() .subscriberConfig(JmsConnector.configBuilder() .jndiInitialFactory(ActiveMQInitialContextFactory.class) .jndiProviderUrl(\"tcp://127.0.0.1:61616\") .type(JmsConfigBuilder.Type.QUEUE) .destination(\"se-example-queue-1\") .build() ).build(); JmsConnector jmsConnector = JmsConnector.create(); messaging = Messaging.builder() .publisher(toJms, Multi.just(\"test1\", \"test2\").map(Message::of)) .connector(jmsConnector) .build() .start(); Prepare a channel for connecting jms connector with specific publisher configuration &#8594; listener Channel &#8594; connector mapping is automatic when using JmsConnector.configBuilder() Prepare JMS connector, can be used by any channel ",
            "title": "Explicit Config with Config Builder for JMS Connector"
        },
        {
            "location": "/se/reactive-messaging",
            "text": "<markup lang=\"yaml\" title=\"Example of connector config:\" >mp.messaging: incoming.from-jms: connector: helidon-jms destination: se-example-queue-1 session-group-id: session-group-1 type: queue outgoing.to-jms: connector: helidon-jms destination: se-example-queue-1 type: queue connector: helidon-jms: jndi: jms-factory: ConnectionFactory env-properties: java.naming.factory.initial: org.apache.activemq.jndi.ActiveMQInitialContextFactory java.naming.provider.url: tcp://127.0.0.1:61616 <markup lang=\"java\" title=\"Example of consuming from JMS:\" >Config config = Config.create(); Channel&lt;String&gt; fromJms = Channel.create(\"from-jms\"); JmsConnector jmsConnector = JmsConnector.create(); Messaging messaging = Messaging.builder() .config(config) .connector(jmsConnector) .listener(fromJms, payload -&gt; { System.out.println(\"Jms says: \" + payload); }) .build() .start(); Prepare JMS connector, can be used by any channel <markup lang=\"java\" title=\"Example of producing to JMS:\" >Config config = Config.create(); Channel&lt;String&gt; toJms = Channel.create(\"to-jms\"); JmsConnector jmsConnector = JmsConnector.create(); messaging = Messaging.builder() .config(config) .publisher(toJms, Multi.just(\"test1\", \"test2\").map(Message::of)) .connector(jmsConnector) .build() .start(); Prepare JMS connector, can be used by any channel Don&#8217;t forget to check out the examples with pre-configured ActiveMQ docker image, for easy testing: https://github.com/oracle/helidon/tree/master/examples/messaging ",
            "title": "Implicit Helidon Config for JMS Connector"
        },
        {
            "location": "/se/reactive-messaging",
            "text": "<markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.messaging.jms&lt;/groupId&gt; &lt;artifactId&gt;helidon-messaging-jms&lt;/artifactId&gt; &lt;/dependency&gt; Reactive JMS Connector Connecting streams to JMS with Reactive Messaging couldn&#8217;t be easier. Explicit Config with Config Builder for JMS Connector <markup lang=\"java\" title=\"Example of consuming from JMS:\" >Channel&lt;String&gt; fromJms = Channel.&lt;String&gt;builder() .name(\"from-jms\") .publisherConfig(JmsConnector.configBuilder() .jndiInitialFactory(ActiveMQInitialContextFactory.class) .jndiProviderUrl(\"tcp://127.0.0.1:61616\") .type(JmsConfigBuilder.Type.QUEUE) .destination(\"se-example-queue-1\") .build() ) .build(); JmsConnector jmsConnector = JmsConnector.create(); Messaging messaging = Messaging.builder() .connector(jmsConnector) .listener(fromJms, payload -&gt; { System.out.println(\"Jms says: \" + payload); }) .build() .start(); Prepare a channel for connecting jms connector with specific publisher configuration &#8594; listener Channel &#8594; connector mapping is automatic when using JmsConnector.configBuilder() Prepare JMS connector, can be used by any channel <markup lang=\"java\" title=\"Example of producing to JMS:\" >Channel&lt;String&gt; toJms = Channel.&lt;String&gt;builder() .subscriberConfig(JmsConnector.configBuilder() .jndiInitialFactory(ActiveMQInitialContextFactory.class) .jndiProviderUrl(\"tcp://127.0.0.1:61616\") .type(JmsConfigBuilder.Type.QUEUE) .destination(\"se-example-queue-1\") .build() ).build(); JmsConnector jmsConnector = JmsConnector.create(); messaging = Messaging.builder() .publisher(toJms, Multi.just(\"test1\", \"test2\").map(Message::of)) .connector(jmsConnector) .build() .start(); Prepare a channel for connecting jms connector with specific publisher configuration &#8594; listener Channel &#8594; connector mapping is automatic when using JmsConnector.configBuilder() Prepare JMS connector, can be used by any channel Implicit Helidon Config for JMS Connector <markup lang=\"yaml\" title=\"Example of connector config:\" >mp.messaging: incoming.from-jms: connector: helidon-jms destination: se-example-queue-1 session-group-id: session-group-1 type: queue outgoing.to-jms: connector: helidon-jms destination: se-example-queue-1 type: queue connector: helidon-jms: jndi: jms-factory: ConnectionFactory env-properties: java.naming.factory.initial: org.apache.activemq.jndi.ActiveMQInitialContextFactory java.naming.provider.url: tcp://127.0.0.1:61616 <markup lang=\"java\" title=\"Example of consuming from JMS:\" >Config config = Config.create(); Channel&lt;String&gt; fromJms = Channel.create(\"from-jms\"); JmsConnector jmsConnector = JmsConnector.create(); Messaging messaging = Messaging.builder() .config(config) .connector(jmsConnector) .listener(fromJms, payload -&gt; { System.out.println(\"Jms says: \" + payload); }) .build() .start(); Prepare JMS connector, can be used by any channel <markup lang=\"java\" title=\"Example of producing to JMS:\" >Config config = Config.create(); Channel&lt;String&gt; toJms = Channel.create(\"to-jms\"); JmsConnector jmsConnector = JmsConnector.create(); messaging = Messaging.builder() .config(config) .publisher(toJms, Multi.just(\"test1\", \"test2\").map(Message::of)) .connector(jmsConnector) .build() .start(); Prepare JMS connector, can be used by any channel Don&#8217;t forget to check out the examples with pre-configured ActiveMQ docker image, for easy testing: https://github.com/oracle/helidon/tree/master/examples/messaging ",
            "title": "JMS Connector"
        },
        {
            "location": "/se/reactive-messaging",
            "text": "",
            "title": "Reactive Oracle AQ Connector"
        },
        {
            "location": "/se/reactive-messaging",
            "text": "<markup lang=\"java\" title=\"Example of producing to and consuming from Oracle AQ:\" >PoolDataSource pds = PoolDataSourceFactory.getPoolDataSource(); pds.setConnectionFactoryClassName(\"oracle.jdbc.pool.OracleDataSource\"); pds.setURL(\"jdbc:oracle:thin:@(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(Host=192.168.0.123)(Port=1521))(CONNECT_DATA=(SID=XE)))\"); pds.setUser(\"frank\"); pds.setPassword(\"frank\"); AqConnector seConn = AqConnector.builder() .dataSource(\"test-ds\", pds) .build(); Channel&lt;String&gt; toAq = Channel.&lt;String&gt;builder() .name(\"toAq\") .subscriberConfig(AqConnector.configBuilder() .queue(\"example_queue_1\") .dataSource(\"test-ds\") .build()) .build(); Channel&lt;String&gt; fromAq = Channel.&lt;String&gt;builder() .name(\"fromAq\") .publisherConfig(AqConnector.configBuilder() .queue(\"example_queue_1\") .dataSource(\"test-ds\") .build()) .build(); Messaging.builder() .connector(seConn) .publisher(toAq, Multi.just(\"Hello\", \"world\", \"from\", \"Oracle\", \"DB!\").map(Message::of)) .listener(fromAq, s -&gt; System.out.pritln(\"Message received: \"+s)) .build() .start(); Prepare Oracle UCP Setup AQ connector and provide datasource with an identifier test-ds Setup channel for sending messages to queue example_queue_1 with datasource test-ds Setup channel for receiving messages from queue example_queue_1 with datasource test-ds Register connector and channels Add a publisher for several test messages to publish them to example_queue_1 immediately Subscribe callback for any message coming from example_queue_1 ",
            "title": "Sending and Receiving"
        },
        {
            "location": "/se/reactive-messaging",
            "text": "<markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.messaging.aq&lt;/groupId&gt; &lt;artifactId&gt;helidon-messaging-aq&lt;/artifactId&gt; &lt;/dependency&gt; Reactive Oracle AQ Connector Sending and Receiving <markup lang=\"java\" title=\"Example of producing to and consuming from Oracle AQ:\" >PoolDataSource pds = PoolDataSourceFactory.getPoolDataSource(); pds.setConnectionFactoryClassName(\"oracle.jdbc.pool.OracleDataSource\"); pds.setURL(\"jdbc:oracle:thin:@(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(Host=192.168.0.123)(Port=1521))(CONNECT_DATA=(SID=XE)))\"); pds.setUser(\"frank\"); pds.setPassword(\"frank\"); AqConnector seConn = AqConnector.builder() .dataSource(\"test-ds\", pds) .build(); Channel&lt;String&gt; toAq = Channel.&lt;String&gt;builder() .name(\"toAq\") .subscriberConfig(AqConnector.configBuilder() .queue(\"example_queue_1\") .dataSource(\"test-ds\") .build()) .build(); Channel&lt;String&gt; fromAq = Channel.&lt;String&gt;builder() .name(\"fromAq\") .publisherConfig(AqConnector.configBuilder() .queue(\"example_queue_1\") .dataSource(\"test-ds\") .build()) .build(); Messaging.builder() .connector(seConn) .publisher(toAq, Multi.just(\"Hello\", \"world\", \"from\", \"Oracle\", \"DB!\").map(Message::of)) .listener(fromAq, s -&gt; System.out.pritln(\"Message received: \"+s)) .build() .start(); Prepare Oracle UCP Setup AQ connector and provide datasource with an identifier test-ds Setup channel for sending messages to queue example_queue_1 with datasource test-ds Setup channel for receiving messages from queue example_queue_1 with datasource test-ds Register connector and channels Add a publisher for several test messages to publish them to example_queue_1 immediately Subscribe callback for any message coming from example_queue_1 ",
            "title": "AQ Connector"
        },
        {
            "location": "/se/reactive-messaging",
            "text": " Connectors are used to connect channels to external sources. To make the creation and usage of connectors as easy and versatile as possible, Helidon SE Messaging uses the same API for connectors that MicroProfile Reactive Messaging does. This allows connectors to be used in both flavors of Helidon with one limitation which is that the connector has to be able to work without CDI. Examples of versatile connectors in Helidon include the following: Kafka connector JMS connector AQ Connector Messaging Connector A connector for Reactive Messaging is a factory that produces Publishers and Subscribers for Channels in Reactive Messaging. Messaging connector is just an implementation of IncomingConnectorFactory , OutgoingConnectorFactory or both. <markup lang=\"java\" title=\"Example connector example-connector :\" >@Connector(\"example-connector\") public class ExampleConnector implements IncomingConnectorFactory, OutgoingConnectorFactory { @Override public PublisherBuilder&lt;? extends Message&lt;?&gt;&gt; getPublisherBuilder(Config config) { return ReactiveStreams.of(\"foo\", \"bar\") .map(Message::of); } @Override public SubscriberBuilder&lt;? extends Message&lt;?&gt;, Void&gt; getSubscriberBuilder(Config config) { return ReactiveStreams.&lt;Message&lt;?&gt;&gt;builder() .map(Message::getPayload) .forEach(o -&gt; System.out.println(\"Connector says: \" + o)); } } <markup lang=\"yaml\" title=\"Example of channel to connector mapping config:\" >mp.messaging.outgoing.to-connector-channel.connector: example-connector mp.messaging.incoming.from-connector-channel.connector: example-connector <markup lang=\"java\" title=\"Example producing to connector:\" >Config config = Config.create(); Messaging.builder() .config(config) .connector(new ExampleConnector()) .publisher(Channel.create(\"to-connector-channel\"), ReactiveStreams.of(\"fee\", \"fie\") .map(Message::of) ) .build() .start(); &gt; Connector says: fee &gt; Connector says: fie <markup lang=\"java\" title=\"Example consuming from connector:\" >Messaging.builder() .connector(new ExampleConnector()) .subscriber(Channel.create(\"from-connector-channel\"), ReactiveStreams.&lt;Message&lt;String&gt;&gt;builder() .peek(Message::ack) .map(Message::getPayload) .forEach(s -&gt; System.out.println(\"Consuming: \" + s)) ) .build() .start(); &gt; Consuming: foo &gt; Consuming: bar Configuration for Messaging Connector A messaging connector in Helidon SE can be configured explicitly by API or implicitly by config following the notation of MicroProfile Reactive Messaging . Configuration that is supplied to connector by the Messaging implementation must include two mandatory attributes: channel-name which is the name of the channel that has the connector configured as Publisher or Subscriber, or Channel.create('name-of-channel') in case of explicit configuration or mp.messaging.incoming.name-of-channel.connector: connector-name in case of implicit config connector name of the connector @Connector(\"connector-name\") <markup lang=\"java\" title=\"Example connector accessing configuration:\" >@Connector(\"example-connector\") public class ExampleConnector implements IncomingConnectorFactory { @Override public PublisherBuilder&lt;? extends Message&lt;?&gt;&gt; getPublisherBuilder(final Config config) { String firstPropValue = config.getValue(\"first-test-prop\", String.class); String secondPropValue = config.getValue(\"second-test-prop\", String.class); return ReactiveStreams.of(firstPropValue, secondPropValue) .map(Message::of); } } Config context is merged from channel and connector contexts Explicit Config for Messaging Connector An explicit config for channel&#8217;s publisher is possible with Channel.Builder#publisherConfig(Config config) and for a subscriber with the Channel.Builder#subscriberConfig(Config config) . The supplied Helidon Config is merged with the mandatory attributes and any implicit configuration found. The resulting configuration is then served to the Connector. <markup lang=\"java\" title=\"Example consuming from Kafka connector with explicit config:\" >String kafkaServer = config.get(\"app.kafka.bootstrap.servers\").asString().get(); String topic = config.get(\"app.kafka.topic\").asString().get(); Channel&lt;String&gt; fromKafka = Channel.&lt;String&gt;builder() .name(\"from-kafka\") .publisherConfig(KafkaConnector.configBuilder() .bootstrapServers(kafkaServer) .groupId(\"example-group-\" + session.getId()) .topic(topic) .autoOffsetReset(KafkaConfigBuilder.AutoOffsetReset.LATEST) .enableAutoCommit(true) .keyDeserializer(StringDeserializer.class) .valueDeserializer(StringDeserializer.class) .build() ) .build(); KafkaConnector kafkaConnector = KafkaConnector.create(); Messaging messaging = Messaging.builder() .connector(kafkaConnector) .listener(fromKafka, payload -&gt; { System.out.println(\"Kafka says: \" + payload); }) .build() .start(); Prepare channel for connecting kafka connector with specific publisher configuration &#8594; listener, Channel &#8594; connector mapping is automatic when using KafkaConnector.configBuilder() Prepare Kafka connector, can be used by any channel Implicit Config for Messaging Connector Implicit config without any hard-coding is possible with Helidon Config following notation of MicroProfile Reactive Messaging . <markup lang=\"yaml\" title=\"Example of channel to connector mapping config with custom properties:\" >mp.messaging.incoming.from-connector-channel.connector: example-connector mp.messaging.incoming.from-connector-channel.first-test-prop: foo mp.messaging.connector.example-connector.second-test-prop: bar Channel &#8594; Connector mapping Channel configuration properties Connector configuration properties <markup lang=\"java\" title=\"Example consuming from connector:\" >Config config = Config.create(); Messaging.builder() .config(config) .connector(new ExampleConnector()) .listener(Channel.create(\"from-connector-channel\"), s -&gt; System.out.println(\"Consuming: \" + s)) .build() .start(); &gt; Consuming: foo &gt; Consuming: bar Reusability in MP Messaging As the API is the same for MicroProfile Reactive Messaging connectors, all that is needed to make connector work in both ways is annotating it with @ApplicationScoped . Such connector is treated as a bean in Helidon MP. For specific information about creating messaging connectors for Helidon MP visit MicroProfile Reactive Messaging . Kafka Connector <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.messaging.kafka&lt;/groupId&gt; &lt;artifactId&gt;helidon-messaging-kafka&lt;/artifactId&gt; &lt;/dependency&gt; Reactive Kafka Connector Connecting streams to Kafka with Reactive Messaging couldn&#8217;t be easier. Explicit Config with Config Builder for Kafka Connector <markup lang=\"java\" title=\"Example of consuming from Kafka:\" >String kafkaServer = config.get(\"app.kafka.bootstrap.servers\").asString().get(); String topic = config.get(\"app.kafka.topic\").asString().get(); Channel&lt;String&gt; fromKafka = Channel.&lt;String&gt;builder() .name(\"from-kafka\") .publisherConfig(KafkaConnector.configBuilder() .bootstrapServers(kafkaServer) .groupId(\"example-group-\" + session.getId()) .topic(topic) .autoOffsetReset(KafkaConfigBuilder.AutoOffsetReset.LATEST) .enableAutoCommit(true) .keyDeserializer(StringDeserializer.class) .valueDeserializer(StringDeserializer.class) .build() ) .build(); KafkaConnector kafkaConnector = KafkaConnector.create(); Messaging messaging = Messaging.builder() .connector(kafkaConnector) .listener(fromKafka, payload -&gt; { System.out.println(\"Kafka says: \" + payload); }) .build() .start(); Prepare a channel for connecting kafka connector with specific publisher configuration &#8594; listener Channel &#8594; connector mapping is automatic when using KafkaConnector.configBuilder() Prepare Kafka connector, can be used by any channel <markup lang=\"java\" title=\"Example of producing to Kafka:\" >String kafkaServer = config.get(\"app.kafka.bootstrap.servers\").asString().get(); String topic = config.get(\"app.kafka.topic\").asString().get(); Channel&lt;String&gt; toKafka = Channel.&lt;String&gt;builder() .subscriberConfig(KafkaConnector.configBuilder() .bootstrapServers(kafkaServer) .topic(topic) .keySerializer(StringSerializer.class) .valueSerializer(StringSerializer.class) .build() ).build(); KafkaConnector kafkaConnector = KafkaConnector.create(); messaging = Messaging.builder() .publisher(toKafka, Multi.just(\"test1\", \"test2\").map(Message::of)) .connector(kafkaConnector) .build() .start(); Prepare a channel for connecting kafka connector with specific publisher configuration &#8594; listener Channel &#8594; connector mapping is automatic when using KafkaConnector.configBuilder() Prepare Kafka connector, can be used by any channel Implicit Helidon Config for Kafka Connector <markup lang=\"yaml\" title=\"Example of connector config:\" >mp.messaging: incoming.from-kafka: connector: helidon-kafka topic: messaging-test-topic-1 auto.offset.reset: latest enable.auto.commit: true group.id: example-group-id outgoing.to-kafka: connector: helidon-kafka topic: messaging-test-topic-1 connector: helidon-kafka: bootstrap.servers: localhost:9092 key.serializer: org.apache.kafka.common.serialization.StringSerializer value.serializer: org.apache.kafka.common.serialization.StringSerializer key.deserializer: org.apache.kafka.common.serialization.StringDeserializer value.deserializer: org.apache.kafka.common.serialization.StringDeserializer Kafka client consumer&#8217;s property auto.offset.reset configuration for from-kafka channel only Kafka client&#8217;s property bootstrap.servers configuration for all channels using the connector <markup lang=\"java\" title=\"Example of consuming from Kafka:\" >Config config = Config.create(); Channel&lt;String&gt; fromKafka = Channel.create(\"from-kafka\"); KafkaConnector kafkaConnector = KafkaConnector.create(); Messaging messaging = Messaging.builder() .config(config) .connector(kafkaConnector) .listener(fromKafka, payload -&gt; { System.out.println(\"Kafka says: \" + payload); }) .build() .start(); Prepare Kafka connector, can be used by any channel <markup lang=\"java\" title=\"Example of producing to Kafka:\" >Config config = Config.create(); Channel&lt;String&gt; toKafka = Channel.create(\"to-kafka\"); KafkaConnector kafkaConnector = KafkaConnector.create(); messaging = Messaging.builder() .config(config) .publisher(toKafka, Multi.just(\"test1\", \"test2\").map(Message::of)) .connector(kafkaConnector) .build() .start(); Prepare Kafka connector, can be used by any channel Don&#8217;t forget to check out the examples with pre-configured Kafka docker image, for easy testing: https://github.com/oracle/helidon/tree/master/examples/messaging JMS Connector <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.messaging.jms&lt;/groupId&gt; &lt;artifactId&gt;helidon-messaging-jms&lt;/artifactId&gt; &lt;/dependency&gt; Reactive JMS Connector Connecting streams to JMS with Reactive Messaging couldn&#8217;t be easier. Explicit Config with Config Builder for JMS Connector <markup lang=\"java\" title=\"Example of consuming from JMS:\" >Channel&lt;String&gt; fromJms = Channel.&lt;String&gt;builder() .name(\"from-jms\") .publisherConfig(JmsConnector.configBuilder() .jndiInitialFactory(ActiveMQInitialContextFactory.class) .jndiProviderUrl(\"tcp://127.0.0.1:61616\") .type(JmsConfigBuilder.Type.QUEUE) .destination(\"se-example-queue-1\") .build() ) .build(); JmsConnector jmsConnector = JmsConnector.create(); Messaging messaging = Messaging.builder() .connector(jmsConnector) .listener(fromJms, payload -&gt; { System.out.println(\"Jms says: \" + payload); }) .build() .start(); Prepare a channel for connecting jms connector with specific publisher configuration &#8594; listener Channel &#8594; connector mapping is automatic when using JmsConnector.configBuilder() Prepare JMS connector, can be used by any channel <markup lang=\"java\" title=\"Example of producing to JMS:\" >Channel&lt;String&gt; toJms = Channel.&lt;String&gt;builder() .subscriberConfig(JmsConnector.configBuilder() .jndiInitialFactory(ActiveMQInitialContextFactory.class) .jndiProviderUrl(\"tcp://127.0.0.1:61616\") .type(JmsConfigBuilder.Type.QUEUE) .destination(\"se-example-queue-1\") .build() ).build(); JmsConnector jmsConnector = JmsConnector.create(); messaging = Messaging.builder() .publisher(toJms, Multi.just(\"test1\", \"test2\").map(Message::of)) .connector(jmsConnector) .build() .start(); Prepare a channel for connecting jms connector with specific publisher configuration &#8594; listener Channel &#8594; connector mapping is automatic when using JmsConnector.configBuilder() Prepare JMS connector, can be used by any channel Implicit Helidon Config for JMS Connector <markup lang=\"yaml\" title=\"Example of connector config:\" >mp.messaging: incoming.from-jms: connector: helidon-jms destination: se-example-queue-1 session-group-id: session-group-1 type: queue outgoing.to-jms: connector: helidon-jms destination: se-example-queue-1 type: queue connector: helidon-jms: jndi: jms-factory: ConnectionFactory env-properties: java.naming.factory.initial: org.apache.activemq.jndi.ActiveMQInitialContextFactory java.naming.provider.url: tcp://127.0.0.1:61616 <markup lang=\"java\" title=\"Example of consuming from JMS:\" >Config config = Config.create(); Channel&lt;String&gt; fromJms = Channel.create(\"from-jms\"); JmsConnector jmsConnector = JmsConnector.create(); Messaging messaging = Messaging.builder() .config(config) .connector(jmsConnector) .listener(fromJms, payload -&gt; { System.out.println(\"Jms says: \" + payload); }) .build() .start(); Prepare JMS connector, can be used by any channel <markup lang=\"java\" title=\"Example of producing to JMS:\" >Config config = Config.create(); Channel&lt;String&gt; toJms = Channel.create(\"to-jms\"); JmsConnector jmsConnector = JmsConnector.create(); messaging = Messaging.builder() .config(config) .publisher(toJms, Multi.just(\"test1\", \"test2\").map(Message::of)) .connector(jmsConnector) .build() .start(); Prepare JMS connector, can be used by any channel Don&#8217;t forget to check out the examples with pre-configured ActiveMQ docker image, for easy testing: https://github.com/oracle/helidon/tree/master/examples/messaging AQ Connector <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.messaging.aq&lt;/groupId&gt; &lt;artifactId&gt;helidon-messaging-aq&lt;/artifactId&gt; &lt;/dependency&gt; Reactive Oracle AQ Connector Sending and Receiving <markup lang=\"java\" title=\"Example of producing to and consuming from Oracle AQ:\" >PoolDataSource pds = PoolDataSourceFactory.getPoolDataSource(); pds.setConnectionFactoryClassName(\"oracle.jdbc.pool.OracleDataSource\"); pds.setURL(\"jdbc:oracle:thin:@(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(Host=192.168.0.123)(Port=1521))(CONNECT_DATA=(SID=XE)))\"); pds.setUser(\"frank\"); pds.setPassword(\"frank\"); AqConnector seConn = AqConnector.builder() .dataSource(\"test-ds\", pds) .build(); Channel&lt;String&gt; toAq = Channel.&lt;String&gt;builder() .name(\"toAq\") .subscriberConfig(AqConnector.configBuilder() .queue(\"example_queue_1\") .dataSource(\"test-ds\") .build()) .build(); Channel&lt;String&gt; fromAq = Channel.&lt;String&gt;builder() .name(\"fromAq\") .publisherConfig(AqConnector.configBuilder() .queue(\"example_queue_1\") .dataSource(\"test-ds\") .build()) .build(); Messaging.builder() .connector(seConn) .publisher(toAq, Multi.just(\"Hello\", \"world\", \"from\", \"Oracle\", \"DB!\").map(Message::of)) .listener(fromAq, s -&gt; System.out.pritln(\"Message received: \"+s)) .build() .start(); Prepare Oracle UCP Setup AQ connector and provide datasource with an identifier test-ds Setup channel for sending messages to queue example_queue_1 with datasource test-ds Setup channel for receiving messages from queue example_queue_1 with datasource test-ds Register connector and channels Add a publisher for several test messages to publish them to example_queue_1 immediately Subscribe callback for any message coming from example_queue_1 ",
            "title": "Connectors"
        },
        {
            "location": "/se/reactive-messaging",
            "text": " Connecting your streams to external services usually requires a lot of boiler-plate code for configuration handling, backpressure propagation, acknowledgement and more. In Helidon there is a system of connectors, emitters and means to orchestrate these tasks called Reactive Messaging . It&#8217;s basically an API for connecting and configuring connectors and emitters with your reactive streams through Channels . Reactive Messaging relates to MicroProfile Reactive Messaging as the making of connectors and configuring them can be a repetitive task that ultimately leads to the same results. Helidon SE Reactive Messaging supports the very same configuration format for connectors as its MicroProfile counterpart does. Also, MP Connectors are reusable in Helidon SE Messaging with some limitations such as there is no CDI in Helidon SE. All Messaging connectors in Helidon are made to be universally usable by Helidon MP and SE. Channel A channel is a named pair of Publisher and Subscriber . Channels can be connected together by processors . Registering a Publisher or Subscriber for a channel can be done by Messaging API, or configured implicitly using registered connectors to generate the Publisher or Subscriber . <markup lang=\"java\" title=\"Example of simple channel:\" >Channel&lt;String&gt; channel1 = Channel.create(\"channel1\"); Messaging.builder() .publisher(channel1, Multi.just(\"message 1\", \"message 2\") .map(Message::of)) .listener(channel1, s -&gt; System.out.println(\"Intecepted message \" + s)) .build() .start(); Processor Processor is a typical reactive processor acting as a Subscriber to upstream and as a Publisher to downstream. In terms of reactive messaging, it is able to connect two channels to one reactive stream. <markup lang=\"java\" title=\"Example of processor usage:\" >Channel&lt;String&gt; firstChannel = Channel.create(\"first-channel\"); Channel&lt;String&gt; secondChannel = Channel.create(\"second-channel\"); Messaging.builder() .publisher(secondChannel, ReactiveStreams.of(\"test1\", \"test2\", \"test3\") .map(Message::of)) .processor(secondChannel, firstChannel, ReactiveStreams.&lt;Message&lt;String&gt;&gt;builder() .map(Message::getPayload) .map(String::toUpperCase) .map(Message::of) ) .subscriber(firstChannel, ReactiveStreams.&lt;Message&lt;String&gt;&gt;builder() .peek(Message::ack) .map(Message::getPayload) .forEach(s -&gt; System.out.println(\"Consuming message \" + s))) .build() .start(); &gt;Consuming message TEST1 &gt;Consuming message TEST2 &gt;Consuming message TEST3 Message Reactive Messaging in Helidon SE uses the same concept of message wrapping as MicroProfile messaging. The only notable difference is that SE Messaging does almost no implicit or automatic acknowledgement due to no magic philosophy of Helidon SE. The only exception to this are the variants of the methods Messaging.Builder#listener and Messaging.Builder#processor configured with consumer or function parameters which will conveniently unwrap the payload for you. Once the payload is automatically unwrapped, it is not possible to do a manual acknowledgement, therefore an implicit acknowledgement is executed before the callback. Connectors Connectors are used to connect channels to external sources. To make the creation and usage of connectors as easy and versatile as possible, Helidon SE Messaging uses the same API for connectors that MicroProfile Reactive Messaging does. This allows connectors to be used in both flavors of Helidon with one limitation which is that the connector has to be able to work without CDI. Examples of versatile connectors in Helidon include the following: Kafka connector JMS connector AQ Connector Messaging Connector A connector for Reactive Messaging is a factory that produces Publishers and Subscribers for Channels in Reactive Messaging. Messaging connector is just an implementation of IncomingConnectorFactory , OutgoingConnectorFactory or both. <markup lang=\"java\" title=\"Example connector example-connector :\" >@Connector(\"example-connector\") public class ExampleConnector implements IncomingConnectorFactory, OutgoingConnectorFactory { @Override public PublisherBuilder&lt;? extends Message&lt;?&gt;&gt; getPublisherBuilder(Config config) { return ReactiveStreams.of(\"foo\", \"bar\") .map(Message::of); } @Override public SubscriberBuilder&lt;? extends Message&lt;?&gt;, Void&gt; getSubscriberBuilder(Config config) { return ReactiveStreams.&lt;Message&lt;?&gt;&gt;builder() .map(Message::getPayload) .forEach(o -&gt; System.out.println(\"Connector says: \" + o)); } } <markup lang=\"yaml\" title=\"Example of channel to connector mapping config:\" >mp.messaging.outgoing.to-connector-channel.connector: example-connector mp.messaging.incoming.from-connector-channel.connector: example-connector <markup lang=\"java\" title=\"Example producing to connector:\" >Config config = Config.create(); Messaging.builder() .config(config) .connector(new ExampleConnector()) .publisher(Channel.create(\"to-connector-channel\"), ReactiveStreams.of(\"fee\", \"fie\") .map(Message::of) ) .build() .start(); &gt; Connector says: fee &gt; Connector says: fie <markup lang=\"java\" title=\"Example consuming from connector:\" >Messaging.builder() .connector(new ExampleConnector()) .subscriber(Channel.create(\"from-connector-channel\"), ReactiveStreams.&lt;Message&lt;String&gt;&gt;builder() .peek(Message::ack) .map(Message::getPayload) .forEach(s -&gt; System.out.println(\"Consuming: \" + s)) ) .build() .start(); &gt; Consuming: foo &gt; Consuming: bar Configuration for Messaging Connector A messaging connector in Helidon SE can be configured explicitly by API or implicitly by config following the notation of MicroProfile Reactive Messaging . Configuration that is supplied to connector by the Messaging implementation must include two mandatory attributes: channel-name which is the name of the channel that has the connector configured as Publisher or Subscriber, or Channel.create('name-of-channel') in case of explicit configuration or mp.messaging.incoming.name-of-channel.connector: connector-name in case of implicit config connector name of the connector @Connector(\"connector-name\") <markup lang=\"java\" title=\"Example connector accessing configuration:\" >@Connector(\"example-connector\") public class ExampleConnector implements IncomingConnectorFactory { @Override public PublisherBuilder&lt;? extends Message&lt;?&gt;&gt; getPublisherBuilder(final Config config) { String firstPropValue = config.getValue(\"first-test-prop\", String.class); String secondPropValue = config.getValue(\"second-test-prop\", String.class); return ReactiveStreams.of(firstPropValue, secondPropValue) .map(Message::of); } } Config context is merged from channel and connector contexts Explicit Config for Messaging Connector An explicit config for channel&#8217;s publisher is possible with Channel.Builder#publisherConfig(Config config) and for a subscriber with the Channel.Builder#subscriberConfig(Config config) . The supplied Helidon Config is merged with the mandatory attributes and any implicit configuration found. The resulting configuration is then served to the Connector. <markup lang=\"java\" title=\"Example consuming from Kafka connector with explicit config:\" >String kafkaServer = config.get(\"app.kafka.bootstrap.servers\").asString().get(); String topic = config.get(\"app.kafka.topic\").asString().get(); Channel&lt;String&gt; fromKafka = Channel.&lt;String&gt;builder() .name(\"from-kafka\") .publisherConfig(KafkaConnector.configBuilder() .bootstrapServers(kafkaServer) .groupId(\"example-group-\" + session.getId()) .topic(topic) .autoOffsetReset(KafkaConfigBuilder.AutoOffsetReset.LATEST) .enableAutoCommit(true) .keyDeserializer(StringDeserializer.class) .valueDeserializer(StringDeserializer.class) .build() ) .build(); KafkaConnector kafkaConnector = KafkaConnector.create(); Messaging messaging = Messaging.builder() .connector(kafkaConnector) .listener(fromKafka, payload -&gt; { System.out.println(\"Kafka says: \" + payload); }) .build() .start(); Prepare channel for connecting kafka connector with specific publisher configuration &#8594; listener, Channel &#8594; connector mapping is automatic when using KafkaConnector.configBuilder() Prepare Kafka connector, can be used by any channel Implicit Config for Messaging Connector Implicit config without any hard-coding is possible with Helidon Config following notation of MicroProfile Reactive Messaging . <markup lang=\"yaml\" title=\"Example of channel to connector mapping config with custom properties:\" >mp.messaging.incoming.from-connector-channel.connector: example-connector mp.messaging.incoming.from-connector-channel.first-test-prop: foo mp.messaging.connector.example-connector.second-test-prop: bar Channel &#8594; Connector mapping Channel configuration properties Connector configuration properties <markup lang=\"java\" title=\"Example consuming from connector:\" >Config config = Config.create(); Messaging.builder() .config(config) .connector(new ExampleConnector()) .listener(Channel.create(\"from-connector-channel\"), s -&gt; System.out.println(\"Consuming: \" + s)) .build() .start(); &gt; Consuming: foo &gt; Consuming: bar Reusability in MP Messaging As the API is the same for MicroProfile Reactive Messaging connectors, all that is needed to make connector work in both ways is annotating it with @ApplicationScoped . Such connector is treated as a bean in Helidon MP. For specific information about creating messaging connectors for Helidon MP visit MicroProfile Reactive Messaging . Kafka Connector <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.messaging.kafka&lt;/groupId&gt; &lt;artifactId&gt;helidon-messaging-kafka&lt;/artifactId&gt; &lt;/dependency&gt; Reactive Kafka Connector Connecting streams to Kafka with Reactive Messaging couldn&#8217;t be easier. Explicit Config with Config Builder for Kafka Connector <markup lang=\"java\" title=\"Example of consuming from Kafka:\" >String kafkaServer = config.get(\"app.kafka.bootstrap.servers\").asString().get(); String topic = config.get(\"app.kafka.topic\").asString().get(); Channel&lt;String&gt; fromKafka = Channel.&lt;String&gt;builder() .name(\"from-kafka\") .publisherConfig(KafkaConnector.configBuilder() .bootstrapServers(kafkaServer) .groupId(\"example-group-\" + session.getId()) .topic(topic) .autoOffsetReset(KafkaConfigBuilder.AutoOffsetReset.LATEST) .enableAutoCommit(true) .keyDeserializer(StringDeserializer.class) .valueDeserializer(StringDeserializer.class) .build() ) .build(); KafkaConnector kafkaConnector = KafkaConnector.create(); Messaging messaging = Messaging.builder() .connector(kafkaConnector) .listener(fromKafka, payload -&gt; { System.out.println(\"Kafka says: \" + payload); }) .build() .start(); Prepare a channel for connecting kafka connector with specific publisher configuration &#8594; listener Channel &#8594; connector mapping is automatic when using KafkaConnector.configBuilder() Prepare Kafka connector, can be used by any channel <markup lang=\"java\" title=\"Example of producing to Kafka:\" >String kafkaServer = config.get(\"app.kafka.bootstrap.servers\").asString().get(); String topic = config.get(\"app.kafka.topic\").asString().get(); Channel&lt;String&gt; toKafka = Channel.&lt;String&gt;builder() .subscriberConfig(KafkaConnector.configBuilder() .bootstrapServers(kafkaServer) .topic(topic) .keySerializer(StringSerializer.class) .valueSerializer(StringSerializer.class) .build() ).build(); KafkaConnector kafkaConnector = KafkaConnector.create(); messaging = Messaging.builder() .publisher(toKafka, Multi.just(\"test1\", \"test2\").map(Message::of)) .connector(kafkaConnector) .build() .start(); Prepare a channel for connecting kafka connector with specific publisher configuration &#8594; listener Channel &#8594; connector mapping is automatic when using KafkaConnector.configBuilder() Prepare Kafka connector, can be used by any channel Implicit Helidon Config for Kafka Connector <markup lang=\"yaml\" title=\"Example of connector config:\" >mp.messaging: incoming.from-kafka: connector: helidon-kafka topic: messaging-test-topic-1 auto.offset.reset: latest enable.auto.commit: true group.id: example-group-id outgoing.to-kafka: connector: helidon-kafka topic: messaging-test-topic-1 connector: helidon-kafka: bootstrap.servers: localhost:9092 key.serializer: org.apache.kafka.common.serialization.StringSerializer value.serializer: org.apache.kafka.common.serialization.StringSerializer key.deserializer: org.apache.kafka.common.serialization.StringDeserializer value.deserializer: org.apache.kafka.common.serialization.StringDeserializer Kafka client consumer&#8217;s property auto.offset.reset configuration for from-kafka channel only Kafka client&#8217;s property bootstrap.servers configuration for all channels using the connector <markup lang=\"java\" title=\"Example of consuming from Kafka:\" >Config config = Config.create(); Channel&lt;String&gt; fromKafka = Channel.create(\"from-kafka\"); KafkaConnector kafkaConnector = KafkaConnector.create(); Messaging messaging = Messaging.builder() .config(config) .connector(kafkaConnector) .listener(fromKafka, payload -&gt; { System.out.println(\"Kafka says: \" + payload); }) .build() .start(); Prepare Kafka connector, can be used by any channel <markup lang=\"java\" title=\"Example of producing to Kafka:\" >Config config = Config.create(); Channel&lt;String&gt; toKafka = Channel.create(\"to-kafka\"); KafkaConnector kafkaConnector = KafkaConnector.create(); messaging = Messaging.builder() .config(config) .publisher(toKafka, Multi.just(\"test1\", \"test2\").map(Message::of)) .connector(kafkaConnector) .build() .start(); Prepare Kafka connector, can be used by any channel Don&#8217;t forget to check out the examples with pre-configured Kafka docker image, for easy testing: https://github.com/oracle/helidon/tree/master/examples/messaging JMS Connector <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.messaging.jms&lt;/groupId&gt; &lt;artifactId&gt;helidon-messaging-jms&lt;/artifactId&gt; &lt;/dependency&gt; Reactive JMS Connector Connecting streams to JMS with Reactive Messaging couldn&#8217;t be easier. Explicit Config with Config Builder for JMS Connector <markup lang=\"java\" title=\"Example of consuming from JMS:\" >Channel&lt;String&gt; fromJms = Channel.&lt;String&gt;builder() .name(\"from-jms\") .publisherConfig(JmsConnector.configBuilder() .jndiInitialFactory(ActiveMQInitialContextFactory.class) .jndiProviderUrl(\"tcp://127.0.0.1:61616\") .type(JmsConfigBuilder.Type.QUEUE) .destination(\"se-example-queue-1\") .build() ) .build(); JmsConnector jmsConnector = JmsConnector.create(); Messaging messaging = Messaging.builder() .connector(jmsConnector) .listener(fromJms, payload -&gt; { System.out.println(\"Jms says: \" + payload); }) .build() .start(); Prepare a channel for connecting jms connector with specific publisher configuration &#8594; listener Channel &#8594; connector mapping is automatic when using JmsConnector.configBuilder() Prepare JMS connector, can be used by any channel <markup lang=\"java\" title=\"Example of producing to JMS:\" >Channel&lt;String&gt; toJms = Channel.&lt;String&gt;builder() .subscriberConfig(JmsConnector.configBuilder() .jndiInitialFactory(ActiveMQInitialContextFactory.class) .jndiProviderUrl(\"tcp://127.0.0.1:61616\") .type(JmsConfigBuilder.Type.QUEUE) .destination(\"se-example-queue-1\") .build() ).build(); JmsConnector jmsConnector = JmsConnector.create(); messaging = Messaging.builder() .publisher(toJms, Multi.just(\"test1\", \"test2\").map(Message::of)) .connector(jmsConnector) .build() .start(); Prepare a channel for connecting jms connector with specific publisher configuration &#8594; listener Channel &#8594; connector mapping is automatic when using JmsConnector.configBuilder() Prepare JMS connector, can be used by any channel Implicit Helidon Config for JMS Connector <markup lang=\"yaml\" title=\"Example of connector config:\" >mp.messaging: incoming.from-jms: connector: helidon-jms destination: se-example-queue-1 session-group-id: session-group-1 type: queue outgoing.to-jms: connector: helidon-jms destination: se-example-queue-1 type: queue connector: helidon-jms: jndi: jms-factory: ConnectionFactory env-properties: java.naming.factory.initial: org.apache.activemq.jndi.ActiveMQInitialContextFactory java.naming.provider.url: tcp://127.0.0.1:61616 <markup lang=\"java\" title=\"Example of consuming from JMS:\" >Config config = Config.create(); Channel&lt;String&gt; fromJms = Channel.create(\"from-jms\"); JmsConnector jmsConnector = JmsConnector.create(); Messaging messaging = Messaging.builder() .config(config) .connector(jmsConnector) .listener(fromJms, payload -&gt; { System.out.println(\"Jms says: \" + payload); }) .build() .start(); Prepare JMS connector, can be used by any channel <markup lang=\"java\" title=\"Example of producing to JMS:\" >Config config = Config.create(); Channel&lt;String&gt; toJms = Channel.create(\"to-jms\"); JmsConnector jmsConnector = JmsConnector.create(); messaging = Messaging.builder() .config(config) .publisher(toJms, Multi.just(\"test1\", \"test2\").map(Message::of)) .connector(jmsConnector) .build() .start(); Prepare JMS connector, can be used by any channel Don&#8217;t forget to check out the examples with pre-configured ActiveMQ docker image, for easy testing: https://github.com/oracle/helidon/tree/master/examples/messaging AQ Connector <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.messaging.aq&lt;/groupId&gt; &lt;artifactId&gt;helidon-messaging-aq&lt;/artifactId&gt; &lt;/dependency&gt; Reactive Oracle AQ Connector Sending and Receiving <markup lang=\"java\" title=\"Example of producing to and consuming from Oracle AQ:\" >PoolDataSource pds = PoolDataSourceFactory.getPoolDataSource(); pds.setConnectionFactoryClassName(\"oracle.jdbc.pool.OracleDataSource\"); pds.setURL(\"jdbc:oracle:thin:@(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(Host=192.168.0.123)(Port=1521))(CONNECT_DATA=(SID=XE)))\"); pds.setUser(\"frank\"); pds.setPassword(\"frank\"); AqConnector seConn = AqConnector.builder() .dataSource(\"test-ds\", pds) .build(); Channel&lt;String&gt; toAq = Channel.&lt;String&gt;builder() .name(\"toAq\") .subscriberConfig(AqConnector.configBuilder() .queue(\"example_queue_1\") .dataSource(\"test-ds\") .build()) .build(); Channel&lt;String&gt; fromAq = Channel.&lt;String&gt;builder() .name(\"fromAq\") .publisherConfig(AqConnector.configBuilder() .queue(\"example_queue_1\") .dataSource(\"test-ds\") .build()) .build(); Messaging.builder() .connector(seConn) .publisher(toAq, Multi.just(\"Hello\", \"world\", \"from\", \"Oracle\", \"DB!\").map(Message::of)) .listener(fromAq, s -&gt; System.out.pritln(\"Message received: \"+s)) .build() .start(); Prepare Oracle UCP Setup AQ connector and provide datasource with an identifier test-ds Setup channel for sending messages to queue example_queue_1 with datasource test-ds Setup channel for receiving messages from queue example_queue_1 with datasource test-ds Register connector and channels Add a publisher for several test messages to publish them to example_queue_1 immediately Subscribe callback for any message coming from example_queue_1 ",
            "title": "Usage"
        },
        {
            "location": "/se/reactive-messaging",
            "text": " Configuration for Messaging Connector Explicit Configuration with Config Builder for Kafka Connector Implicit Helidon Configuration for Kafka Connector Explicit Configuration with Config Builder for JMS Connector Implicit Helidon Configuration for JMS Connector ",
            "title": "Configuration"
        },
        {
            "location": "/se/reactive-messaging",
            "text": " MicroProfile Reactive Messaging Specification MicroProfile Reactive Messaging on GitHub Helidon Messaging Examples ",
            "title": "Reference"
        },
        {
            "location": "/se/reactivestreams/engine",
            "text": " Overview Maven Coordinates Usage ",
            "title": "Contents"
        },
        {
            "location": "/se/reactivestreams/engine",
            "text": " Helidon has its own set of reactive operators that have no dependencies outside of the Helidon ecosystem. These operators can be used with java.util.concurrent.Flow based reactive streams. ",
            "title": "Overview"
        },
        {
            "location": "/se/reactivestreams/engine",
            "text": " To enable Reactive Engine add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.common&lt;/groupId&gt; &lt;artifactId&gt;helidon-common-reactive&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/reactivestreams/engine",
            "text": " In the situations when part of the operator chain needs to be prepared in advance, compose and to operators are at hand. <markup lang=\"java\" title=\"Combining operator chains:\" >// Assembly of stream, nothing is streamed yet Multi&lt;String&gt; publisherStage = Multi.just(\"foo\", \"bar\") .map(String::trim); Function&lt;Multi&lt;T&gt;, Multi&lt;T&gt;&gt; processorStage = upstream -&gt; upstream.map(String::toUpperCase); // Execution of pre-prepared stream publisherStage .compose(processorStage) .map(s -&gt; \"Item received: \" + s) .forEach(System.out::println); &gt; Item received: FOO &gt; Item received: BAR ",
            "title": "Operator Chains Composition"
        },
        {
            "location": "/se/reactivestreams/engine",
            "text": " The stream processing operator chain can be easily constructed by io.helidon.common.reactive.Multi , or io.helidon.common.reactive.Single for streams with single value. <markup lang=\"java\" title=\"Example of Multi usage:\" >AtomicInteger sum = new AtomicInteger(); Multi.just(\"1\", \"2\", \"3\", \"4\", \"5\") .limit(3) .map(Integer::parseInt) .forEach(sum::addAndGet); System.out.println(\"Sum: \" + sum.get()); &gt; Sum: 6 <markup lang=\"java\" title=\"Example of Single usage:\" >Single.just(\"1\") .map(Integer::parseInt) .map(i -&gt; i + 5) .toStage() .whenComplete((i, t) -&gt; System.out.println(\"Result: \" + i)); &gt; Result: 6 Operators defer Call the given supplier function for each individual downstream Subscriber to return a Flow.Publisher to subscribe to. map Map this Multi instance to a new Multi of another type using the given Mapper . defaultIfEmpty Signals the default item if the upstream is empty. switchIfEmpty Switch to the other publisher if the upstream is empty. peek Invoke provided consumer for every item in stream. distinct Filter out all duplicates. filter Filter stream items with provided predicate. takeWhile Take the longest prefix of elements from this stream that satisfy the given predicate. As long as predicate returns true, items from upstream are sent to downstream, when predicate returns false stream is completed. dropWhile Drop the longest prefix of elements from this stream that satisfy the given predicate. As long as predicate returns true, items from upstream are NOT sent to downstream but being dropped, predicate is never called again after it returns false for the first time. limit Limit stream to allow only specified number of items to pass. skip Skip first n items, all the others are emitted. flatMap Transform each upstream item with the supplied function into a Flow.Publisher , subscribe to them and then flatten their items into a single sequence of items emitted to the downstream. flatMap Transform each upstream item with the supplied function and flatten the resulting Flow.Publisher to downstream while limiting the maximum number of concurrent inner `Flow.Publisher`s and their in-flight item count, optionally aggregating and delaying all errors until all sources terminate. flatMapCompletionStage Transform each upstream item with the supplied function and flatten the resulting CompletionStage results to downstream. flatMapIterable Transform each upstream item with the supplied function and flatten the resulting Iterable to the downstream. flatMapOptional Transform each upstream item with the supplied function and flatten the resulting Optional to the downstream as item if present. observeOn Re-emit the upstream&#8217;s signals to the downstream on the given executor&#8217;s thread using a default buffer size of 32 and errors skipping ahead of items. observeOn Re-emit the upstream&#8217;s signals to the downstream on the given executor&#8217;s thread. forEach Terminal stage, invokes provided consumer for every item in the stream with no backpressure. forEachCompletionStage Terminal stage, invokes provided function for every item in the stream with strict backpressure, requests another item only when previous operation is finished. collectList Collect the items of this Multi instance into a Single of List . collect Collect the items of this Multi instance into a Single . collect Collect the items of this Multi into a collection provided via a Supplier and mutated by a BiConsumer callback. collectStream Collects up upstream items with the help of the callbacks of a java.util.stream.Collector . reduce Combine subsequent items via a callback function and emit the final value result as a Single. reduce Combine every upstream item with an accumulator value to produce a new accumulator value and emit the final accumulator value as a Single. first Get the first item of this Multi instance as a Single . from Wrap a CompletionStage into a Multi and signal its outcome non-blockingly. from Wrap a CompletionStage into a Multi and signal its outcome non-blockingly. from Create a Multi instance wrapped around the given publisher. from Create a Multi instance that publishes the given iterable. from Create a Multi instance that publishes the given Stream . just Create a Multi instance that publishes the given items to a single subscriber. just Create a Multi instance that publishes the given items to a single subscriber. singleton Create a Multi that emits a pre-existing item and then completes. error Create a Multi instance that reports the given exception to its subscriber(s). The exception is reported by invoking Subscriber#onError(java.lang.Throwable) when Publisher#subscribe(Subscriber) is called. empty Get a Multi instance that completes immediately. never Get a Multi instance that never completes. concat Concat streams to one. onTerminate Executes given java.lang.Runnable when any of signals onComplete, onCancel or onError is received. ifEmpty Executes given java.lang.Runnable when stream is finished without value(empty stream). onComplete Executes given java.lang.Runnable when onComplete signal is received. onError Executes the given java.util.function.Consumer when an onError signal is received. onCancel Executes given java.lang.Runnable when a cancel signal is received. takeUntil Relay upstream items until the other source signals an item or completes. range Emits a range of ever increasing integers. rangeLong Emits a range of ever increasing longs. timer Signal 0L and complete the sequence after the given time elapsed. interval Signal 0L, 1L and so on periodically to the downstream. interval Signal 0L after an initial delay, then 1L, 2L and so on periodically to the downstream. timeout Signals a TimeoutException if the upstream doesn&#8217;t signal the next item, error or completion within the specified time. timeout Switches to a fallback source if the upstream doesn&#8217;t signal the next item, error or completion within the specified time. onErrorResume java.util.function.Function providing one item to be submitted as onNext in case of onError signal is received. onErrorResumeWith Resume stream from supplied publisher if onError signal is intercepted. retry Retry a failing upstream at most the given number of times before giving up. retry Retry a failing upstream if the predicate returns true. retryWhen Retry a failing upstream when the given function returns a publisher that signals an item. Operator Chains Composition In the situations when part of the operator chain needs to be prepared in advance, compose and to operators are at hand. <markup lang=\"java\" title=\"Combining operator chains:\" >// Assembly of stream, nothing is streamed yet Multi&lt;String&gt; publisherStage = Multi.just(\"foo\", \"bar\") .map(String::trim); Function&lt;Multi&lt;T&gt;, Multi&lt;T&gt;&gt; processorStage = upstream -&gt; upstream.map(String::toUpperCase); // Execution of pre-prepared stream publisherStage .compose(processorStage) .map(s -&gt; \"Item received: \" + s) .forEach(System.out::println); &gt; Item received: FOO &gt; Item received: BAR ",
            "title": "Usage"
        },
        {
            "location": "/se/reactivestreams/rsoperators",
            "text": " Overview Maven Coordinates Usage Reference ",
            "title": "Contents"
        },
        {
            "location": "/se/reactivestreams/rsoperators",
            "text": " Helidon implements MicroProfile Reactive Streams Operators specification which defines reactive operators and provides a standardized tool for manipulation with Reactive Streams . You can use MicroProfile Reactive Streams Operators when you want to maintain source-level portability between different implementations. ",
            "title": "Overview"
        },
        {
            "location": "/se/reactivestreams/rsoperators",
            "text": " To enable Reactive Streams add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.reactive-streams&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-reactive-streams&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/reactivestreams/rsoperators",
            "text": " Graphs are pre-prepared stream builders with stages , which can be combined to closed graph with methods via and to . <markup lang=\"java\" title=\"Combining the graphs and running the stream:\" >// Assembly of stream, nothing is streamed yet PublisherBuilder&lt;String&gt; publisherStage = ReactiveStreams.of(\"foo\", \"bar\") .map(String::trim); ProcessorBuilder&lt;String, String&gt; processorStage = ReactiveStreams.&lt;String&gt;builder() .map(String::toUpperCase); SubscriberBuilder&lt;String, Void&gt; subscriberStage = ReactiveStreams.&lt;String&gt;builder() .map(s -&gt; \"Item received: \" + s) .forEach(System.out::println); // Execution of pre-prepared stream publisherStage .via(processorStage) .to(subscriberStage).run(); &gt; Item received: FOO &gt; Item received: BAR ",
            "title": "Graphs"
        },
        {
            "location": "/se/reactivestreams/rsoperators",
            "text": " The MicroProfile Reactive Streams Operators specification provides a set of operators within stages, as well as the builders used to prepare graphs of stages from which streams can be built. <markup lang=\"java\" title=\"Example of simple closed graph usage:\" >AtomicInteger sum = new AtomicInteger(); ReactiveStreams.of(\"1\", \"2\", \"3\", \"4\", \"5\") .limit(3) .map(Integer::parseInt) .forEach(sum::addAndGet) .run() .whenComplete((r, t) -&gt; System.out.println(\"Sum: \" + sum.get())); &gt; Sum: 6 Operators(Stages) fromIterable Create new PublisherBuilder from supplied Iterable of Create new PublisherBuilder emitting supplied elements ofNullable Empty stream if supplied item is null iterate Create infinite stream with every next item created by supplied operator from previous item generate Create infinite stream with every item created by invocation of supplier empty Create new PublisherBuilder emitting as a first thing complete signal failed Create new PublisherBuilder emitting as a first thing error signal concat Concat two streams coupled Two parallel streams sharing cancel, onError and onComplete signals limit Limit the size of the stream, when limit is reached completes peek Invoke consumer for every item passing this operator filter Drop item when expression result to false map Transform items flatMap Flatten supplied stream to current stream flatMapIterable Flatten supplied iterable to current stream flatMapCompletionStage Map elements to completion stage and wait for each to be completed, keeps the order flatMapRSPublisher Map elements to Publishers and flatten this sub streams to original stream takeWhile Let items pass until expression is true, first time its false completes dropWhile Drop items until expression is true, first time its false let everything pass skip Drop first n items distinct Let pass only distinct items via Connect supplied processor to current stream return supplied processor onError Invoke supplied consumer when onError signal received onErrorResume Emit one last supplied item when onError signal received onErrorResumeWith When onError signal received continue emitting from supplied publisher builder onErrorResumeWithRsPublisher When onError signal received continue emitting from supplied publisher onComplete Invoke supplied runnable when onComplete signal received onTerminate Invoke supplied runnable when onComplete or onError signal received ifEmpty Executes given java.lang.Runnable when stream is finished without value(empty stream). to Connect this stream to supplied subscriber toList Collect all intercepted items to List collect Collect all intercepted items with provided collector forEach Invoke supplied Consumer for each intercepted item ignore Ignore all onNext signals, wait for onComplete reduce Reduction with provided expression cancel Cancel stream immediately findFirst Return first intercepted element Graphs Graphs are pre-prepared stream builders with stages , which can be combined to closed graph with methods via and to . <markup lang=\"java\" title=\"Combining the graphs and running the stream:\" >// Assembly of stream, nothing is streamed yet PublisherBuilder&lt;String&gt; publisherStage = ReactiveStreams.of(\"foo\", \"bar\") .map(String::trim); ProcessorBuilder&lt;String, String&gt; processorStage = ReactiveStreams.&lt;String&gt;builder() .map(String::toUpperCase); SubscriberBuilder&lt;String, Void&gt; subscriberStage = ReactiveStreams.&lt;String&gt;builder() .map(s -&gt; \"Item received: \" + s) .forEach(System.out::println); // Execution of pre-prepared stream publisherStage .via(processorStage) .to(subscriberStage).run(); &gt; Item received: FOO &gt; Item received: BAR ",
            "title": "Usage"
        },
        {
            "location": "/se/reactivestreams/rsoperators",
            "text": " MicroProfile Reactive Streams Operators Specification MicroProfile Reactive Streams Operators JavaDoc MicroProfile Reactive Streams Operators on GitHub ",
            "title": "Reference"
        },
        {
            "location": "/se/scheduling",
            "text": " Overview Maven Coordinates Usage Configuration Cron Fixed Rate Examples Reference ",
            "title": "Contents"
        },
        {
            "location": "/se/scheduling",
            "text": " Scheduling is an essential feature for the Enterprise. Helidon has its own implementation of Scheduling functionality based on Cron-utils . ",
            "title": "Overview"
        },
        {
            "location": "/se/scheduling",
            "text": " To enable Scheduling add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.scheduling&lt;/groupId&gt; &lt;artifactId&gt;helidon-scheduling&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/scheduling",
            "text": " Required configuration options key type default value description delay long &#160; Fixed rate delay between each invocation. Time unit is by default java.util.concurrent.TimeUnit#SECONDS, can be specified with io.helidon.scheduling.Scheduling.FixedRateBuilder#timeUnit(java.util.concurrent.TimeUnit). @return delay between each invocation Optional configuration options key type default value description delay-type DelayType (SINCE_PREVIOUS_START, SINCE_PREVIOUS_END) @io.helidon.scheduling.FixedRate.DelayType@.SINCE_PREVIOUS_START Configure whether the delay between the invocations should be calculated from the time when previous task started or ended. Delay type is by default FixedRate.DelayType#SINCE_PREVIOUS_START. @return delay type initial-delay long 0 Initial delay of the first invocation. Time unit is by default java.util.concurrent.TimeUnit#SECONDS, can be specified with io.helidon.scheduling.Scheduling.FixedRateBuilder#timeUnit(java.util.concurrent.TimeUnit) timeUnit(). @return initial delay value time-unit TimeUnit (NANOSECONDS, MICROSECONDS, MILLISECONDS, SECONDS, MINUTES, HOURS, DAYS) TimeUnit.SECONDS java.util.concurrent.TimeUnit TimeUnit used for interpretation of values provided with io.helidon.scheduling.Scheduling.FixedRateBuilder#delay(long) and io.helidon.scheduling.Scheduling.FixedRateBuilder#initialDelay(long). @return time unit for interpreting values in io.helidon.scheduling.Scheduling.FixedRateBuilder#delay(long) and io.helidon.scheduling.Scheduling.FixedRateBuilder#initialDelay(long) ",
            "title": "Configuration options"
        },
        {
            "location": "/se/scheduling",
            "text": "<markup lang=\"java\" title=\"Scheduling with fixed rate use Scheduling.fixedRate() builder.\" >Scheduling.fixedRate() .delay(10) .initialDelay(5) .timeUnit(TimeUnit.MINUTES) .task(inv -&gt; System.out.println(\"Every 10 minutes, first invocation 5 minutes after start\")) .build(); Metadata like human-readable interval description or configured values are available through FixedRateInvocation provided as task parameter. <markup lang=\"java\" title=\"Invocation metadata\" >Scheduling.fixedRate() .delay(10) .task(inv -&gt; System.out.println(\"Method invoked \" + inv.description())) .build(); Type: io.helidon.scheduling.FixedRate Configuration options Required configuration options key type default value description delay long &#160; Fixed rate delay between each invocation. Time unit is by default java.util.concurrent.TimeUnit#SECONDS, can be specified with io.helidon.scheduling.Scheduling.FixedRateBuilder#timeUnit(java.util.concurrent.TimeUnit). @return delay between each invocation Optional configuration options key type default value description delay-type DelayType (SINCE_PREVIOUS_START, SINCE_PREVIOUS_END) @io.helidon.scheduling.FixedRate.DelayType@.SINCE_PREVIOUS_START Configure whether the delay between the invocations should be calculated from the time when previous task started or ended. Delay type is by default FixedRate.DelayType#SINCE_PREVIOUS_START. @return delay type initial-delay long 0 Initial delay of the first invocation. Time unit is by default java.util.concurrent.TimeUnit#SECONDS, can be specified with io.helidon.scheduling.Scheduling.FixedRateBuilder#timeUnit(java.util.concurrent.TimeUnit) timeUnit(). @return initial delay value time-unit TimeUnit (NANOSECONDS, MICROSECONDS, MILLISECONDS, SECONDS, MINUTES, HOURS, DAYS) TimeUnit.SECONDS java.util.concurrent.TimeUnit TimeUnit used for interpretation of values provided with io.helidon.scheduling.Scheduling.FixedRateBuilder#delay(long) and io.helidon.scheduling.Scheduling.FixedRateBuilder#initialDelay(long). @return time unit for interpreting values in io.helidon.scheduling.Scheduling.FixedRateBuilder#delay(long) and io.helidon.scheduling.Scheduling.FixedRateBuilder#initialDelay(long) ",
            "title": "Fixed rate"
        },
        {
            "location": "/se/scheduling",
            "text": " Required configuration options key type default value description expression string &#160; Cron expression for specifying period of execution. &lt;b&gt;Examples:&lt;/b&gt; 0/2 * * * * ? * - Every 2 seconds 0 45 9 ? * * - Every day at 9:45 0 15 8 ? * MON-FRI - Every workday at 8:15 @return cron expression Optional configuration options key type default value description concurrent boolean true Allow concurrent execution if previous task didn&#8217;t finish before next execution. Default value is true . @return true for allow concurrent execution. ",
            "title": "Configuration options"
        },
        {
            "location": "/se/scheduling",
            "text": " For more complicated interval definition, Cron expression can be leveraged with Scheduling.cron() builder. <markup lang=\"java\" title=\"Scheduling with Cron expression\" >Scheduling.cron() .expression(\"0 15 8 ? * *\") .task(inv -&gt; System.out.println(\"Executer every day at 8:15\")) .build(); Type: io.helidon.scheduling.Cron Configuration options Required configuration options key type default value description expression string &#160; Cron expression for specifying period of execution. &lt;b&gt;Examples:&lt;/b&gt; 0/2 * * * * ? * - Every 2 seconds 0 45 9 ? * * - Every day at 9:45 0 15 8 ? * MON-FRI - Every workday at 8:15 @return cron expression Optional configuration options key type default value description concurrent boolean true Allow concurrent execution if previous task didn&#8217;t finish before next execution. Default value is true . @return true for allow concurrent execution. ",
            "title": "Cron"
        },
        {
            "location": "/se/scheduling",
            "text": " Cron expressions should be configured as follows. ",
            "title": "Cron expression syntax"
        },
        {
            "location": "/se/scheduling",
            "text": "<markup title=\"Cron expression format\" >&lt;seconds&gt; &lt;minutes&gt; &lt;hours&gt; &lt;day-of-month&gt; &lt;month&gt; &lt;day-of-week&gt; &lt;year&gt; Cron expression fields Order Name Supported values Supported field format Optional 1 seconds 0-59 CONST, LIST, RANGE, WILDCARD, INCREMENT false 2 minutes 0-59 CONST, LIST, RANGE, WILDCARD, INCREMENT false 3 hours 0-23 CONST, LIST, RANGE, WILDCARD, INCREMENT false 4 day-of-month 1-31 CONST, LIST, RANGE, WILDCARD, INCREMENT, ANY, LAST, WEEKDAY false 5 month 1-12 or JAN-DEC CONST, LIST, RANGE, WILDCARD, INCREMENT false 6 day-of-week 1-7 or SUN-SAT CONST, LIST, RANGE, WILDCARD, INCREMENT, ANY, NTH, LAST false 7 year 1970-2099 CONST, LIST, RANGE, WILDCARD, INCREMENT true Field formats Name Regex format Example Description CONST \\d+ 12 exact value LIST \\d+,\\d+(,\\d+)* 1,2,3,4 list of constants RANGE \\d+-\\d+ 15-30 range of values from-to WILDCARD \\* * all values withing the field INCREMENT \\d+\\/\\d+ 0/5 inital number / increments, 2/5 means 2,7,9,11,16,&#8230;&#8203; ANY \\? ? any day(apply only to day-of-week and day-of-month) NTH \\# 1#3 nth day of the month, 2#3 means third monday of the month LAST \\d*L(+\\d+|\\-\\d+)? 3L-3 last day of the month in day-of-month or last nth day in the day-of-week WEEKDAY \\# 1#3 nearest weekday of the nth day of month, 1W is the first monday of the week Examples Cron expression Description * * * * * ? Every second 0/2 * * * * ? * Every 2 seconds 0 45 9 ? * * Every day at 9:45 0 15 8 ? * MON-FRI Every workday at 8:15 Metadata like human-readable interval description or configured values are available through CronInvocation provided as task parameter. ",
            "title": "Cron expression"
        },
        {
            "location": "/se/scheduling",
            "text": " For scheduling periodic tasks, it is possible to choose a fixed rate or a Cron expression. Fixed rate <markup lang=\"java\" title=\"Scheduling with fixed rate use Scheduling.fixedRate() builder.\" >Scheduling.fixedRate() .delay(10) .initialDelay(5) .timeUnit(TimeUnit.MINUTES) .task(inv -&gt; System.out.println(\"Every 10 minutes, first invocation 5 minutes after start\")) .build(); Metadata like human-readable interval description or configured values are available through FixedRateInvocation provided as task parameter. <markup lang=\"java\" title=\"Invocation metadata\" >Scheduling.fixedRate() .delay(10) .task(inv -&gt; System.out.println(\"Method invoked \" + inv.description())) .build(); Type: io.helidon.scheduling.FixedRate Configuration options Required configuration options key type default value description delay long &#160; Fixed rate delay between each invocation. Time unit is by default java.util.concurrent.TimeUnit#SECONDS, can be specified with io.helidon.scheduling.Scheduling.FixedRateBuilder#timeUnit(java.util.concurrent.TimeUnit). @return delay between each invocation Optional configuration options key type default value description delay-type DelayType (SINCE_PREVIOUS_START, SINCE_PREVIOUS_END) @io.helidon.scheduling.FixedRate.DelayType@.SINCE_PREVIOUS_START Configure whether the delay between the invocations should be calculated from the time when previous task started or ended. Delay type is by default FixedRate.DelayType#SINCE_PREVIOUS_START. @return delay type initial-delay long 0 Initial delay of the first invocation. Time unit is by default java.util.concurrent.TimeUnit#SECONDS, can be specified with io.helidon.scheduling.Scheduling.FixedRateBuilder#timeUnit(java.util.concurrent.TimeUnit) timeUnit(). @return initial delay value time-unit TimeUnit (NANOSECONDS, MICROSECONDS, MILLISECONDS, SECONDS, MINUTES, HOURS, DAYS) TimeUnit.SECONDS java.util.concurrent.TimeUnit TimeUnit used for interpretation of values provided with io.helidon.scheduling.Scheduling.FixedRateBuilder#delay(long) and io.helidon.scheduling.Scheduling.FixedRateBuilder#initialDelay(long). @return time unit for interpreting values in io.helidon.scheduling.Scheduling.FixedRateBuilder#delay(long) and io.helidon.scheduling.Scheduling.FixedRateBuilder#initialDelay(long) Cron For more complicated interval definition, Cron expression can be leveraged with Scheduling.cron() builder. <markup lang=\"java\" title=\"Scheduling with Cron expression\" >Scheduling.cron() .expression(\"0 15 8 ? * *\") .task(inv -&gt; System.out.println(\"Executer every day at 8:15\")) .build(); Type: io.helidon.scheduling.Cron Configuration options Required configuration options key type default value description expression string &#160; Cron expression for specifying period of execution. &lt;b&gt;Examples:&lt;/b&gt; 0/2 * * * * ? * - Every 2 seconds 0 45 9 ? * * - Every day at 9:45 0 15 8 ? * MON-FRI - Every workday at 8:15 @return cron expression Optional configuration options key type default value description concurrent boolean true Allow concurrent execution if previous task didn&#8217;t finish before next execution. Default value is true . @return true for allow concurrent execution. Cron expression syntax Cron expressions should be configured as follows. Cron expression <markup title=\"Cron expression format\" >&lt;seconds&gt; &lt;minutes&gt; &lt;hours&gt; &lt;day-of-month&gt; &lt;month&gt; &lt;day-of-week&gt; &lt;year&gt; Cron expression fields Order Name Supported values Supported field format Optional 1 seconds 0-59 CONST, LIST, RANGE, WILDCARD, INCREMENT false 2 minutes 0-59 CONST, LIST, RANGE, WILDCARD, INCREMENT false 3 hours 0-23 CONST, LIST, RANGE, WILDCARD, INCREMENT false 4 day-of-month 1-31 CONST, LIST, RANGE, WILDCARD, INCREMENT, ANY, LAST, WEEKDAY false 5 month 1-12 or JAN-DEC CONST, LIST, RANGE, WILDCARD, INCREMENT false 6 day-of-week 1-7 or SUN-SAT CONST, LIST, RANGE, WILDCARD, INCREMENT, ANY, NTH, LAST false 7 year 1970-2099 CONST, LIST, RANGE, WILDCARD, INCREMENT true Field formats Name Regex format Example Description CONST \\d+ 12 exact value LIST \\d+,\\d+(,\\d+)* 1,2,3,4 list of constants RANGE \\d+-\\d+ 15-30 range of values from-to WILDCARD \\* * all values withing the field INCREMENT \\d+\\/\\d+ 0/5 inital number / increments, 2/5 means 2,7,9,11,16,&#8230;&#8203; ANY \\? ? any day(apply only to day-of-week and day-of-month) NTH \\# 1#3 nth day of the month, 2#3 means third monday of the month LAST \\d*L(+\\d+|\\-\\d+)? 3L-3 last day of the month in day-of-month or last nth day in the day-of-week WEEKDAY \\# 1#3 nearest weekday of the nth day of month, 1W is the first monday of the week Examples Cron expression Description * * * * * ? Every second 0/2 * * * * ? * Every 2 seconds 0 45 9 ? * * Every day at 9:45 0 15 8 ? * MON-FRI Every workday at 8:15 Metadata like human-readable interval description or configured values are available through CronInvocation provided as task parameter. ",
            "title": "Usage"
        },
        {
            "location": "/se/scheduling",
            "text": " Scheduling is configurable with Helidon Config . <markup lang=\"java\" title=\"Example of configuring\" >Scheduling.fixedRate() .config(Config.create(() -&gt; ConfigSources.create( \"\"\" delay: 4 delay-type: SINCE_PREVIOUS_END initial-delay: 1 time-unit: SECONDS \"\"\", MediaTypes.APPLICATION_X_YAML))) .task(inv -&gt; System.out.println(\"Every 4 minutes, first invocation 1 minutes after start\")) .build(); ",
            "title": "Configuration"
        },
        {
            "location": "/se/scheduling",
            "text": " For simple fixed rate invocation use . <markup lang=\"java\" title=\"Example of scheduling with fixed rate use Scheduling.fixedRate() builder.\" >Scheduling.fixedRate() .delay(10) .initialDelay(5) .timeUnit(TimeUnit.MINUTES) .task(inv -&gt; System.out.println(\"Every 10 minutes, first invocation 5 minutes after start\")) .build(); Metadata like human-readable interval description or configured values are available through FixedRateInvocation provided as task parameter. <markup lang=\"java\" title=\"Example with invocation metadata\" >Scheduling.fixedRate() .delay(10) .task(inv -&gt; System.out.println(\"Method invoked \" + inv.description())) .build(); ",
            "title": "Fixed rate"
        },
        {
            "location": "/se/scheduling",
            "text": " Fixed rate For simple fixed rate invocation use . <markup lang=\"java\" title=\"Example of scheduling with fixed rate use Scheduling.fixedRate() builder.\" >Scheduling.fixedRate() .delay(10) .initialDelay(5) .timeUnit(TimeUnit.MINUTES) .task(inv -&gt; System.out.println(\"Every 10 minutes, first invocation 5 minutes after start\")) .build(); Metadata like human-readable interval description or configured values are available through FixedRateInvocation provided as task parameter. <markup lang=\"java\" title=\"Example with invocation metadata\" >Scheduling.fixedRate() .delay(10) .task(inv -&gt; System.out.println(\"Method invoked \" + inv.description())) .build(); ",
            "title": "Examples"
        },
        {
            "location": "/se/scheduling",
            "text": " Cron-utils GitHub page Helidon Scheduling JavaDoc ",
            "title": "Reference"
        },
        {
            "location": "/se/security/containers-integration",
            "text": " There are two steps to configure security with WebServer: Create a security instance and register it with the server. Protect server routes with optional security features. <markup lang=\"java\" title=\"Example using builders\" >// web server's Routing HttpRouting.builder() // This is step 1 - register security instance with web server processing // security - instance of security either from config or from a builder // securityDefaults - default enforcement for each route that has a security definition .addFeature(SecurityFeature.create(security).securityDefaults(SecurityFeature.authenticate())) // this is step 2 - protect a route // protect this route with authentication (from defaults) and role \"user\" .get(\"/service1\", SecurityFeature.rolesAllowed(\"user\"), (req, res) -&gt; { processService1Request(req, res); }) .build(); <markup lang=\"java\" title=\"Example using configuration\" >HttpRouting.builder() // helper method to load both security and web server security from configuration .addFeature(SecurityFeature.create(config)) // continue with web server route configuration .build(); <markup lang=\"yaml\" title=\"Example using configuration (YAML)\" ># This may change in the future - to align with web server configuration, once it is supported security.web-server: # Configuration of integration with web server defaults: authenticate: true paths: - path: \"/service1/[/{*}]\" methods: [\"get\"] roles-allowed: [\"user\"] ",
            "title": "Configure Security with WebServer"
        },
        {
            "location": "/se/security/containers-integration",
            "text": " The configuration is usually placed under security.web-server (this can be customized in Helidon SE). The following shows an example we will explain in detail: <markup lang=\"yaml\" title=\"application.yaml\" >security: providers: - abac: - provider-key: web-server: defaults: authenticate: true paths: - path: \"/metrics[/{*}]\" roles-allowed: \"admin\" - path: \"/health[/{*}]\" roles-allowed: \"monitor\" - path: \"/openapi[/{*}]\" abac: scopes: [\"openapi\"] - path: \"/static[/{*}]\" roles-allowed: [\"user\", \"monitor\"] Attribute based access control provider that checks roles and scopes The provider(s) used in your application, such as oidc Default configuration for all configured paths Protection of /metrics and all nested paths with admin role required Protection of /health and all nested paths with monitor role required Protection of /openapi and all nested paths with openapi scope required Protection of static content configured on /static path with either user or monitor role required If you need to use a properties file, such as microprofile-config.properties , you can convert the file by using index based numbers for arrays, such as: <markup lang=\"properties\" title=\"microprofile-config.properties\" >security.providers.0.abac= security.providers.1.provider-key.optional=false security.web-server.defaults.authenticate=true security.web-server.paths.0.path=/metrics[/{*}] security.web-server.paths.0.roles-allowed=admin security.web-server.paths.3.path=/static[/{*}] security.web-server.paths.3.roles-allowed=user,monitor ",
            "title": "Configuring endpoint protection"
        },
        {
            "location": "/se/security/containers-integration",
            "text": " There are several endpoints provided by Helidon services, such as: Health endpoint ( /health ) Metrics endpoint ( /metrics ) OpenAPI endpoint ( /openapi ) Configured static content (can use any path configured) These endpoints are all implemented using Helidon WebServer and as such can be protected only through Security integration with WebServer. The following section describes configuration of such protection using configuration files, in this case using a yaml file, as it provides a tree structure. Configuring endpoint protection The configuration is usually placed under security.web-server (this can be customized in Helidon SE). The following shows an example we will explain in detail: <markup lang=\"yaml\" title=\"application.yaml\" >security: providers: - abac: - provider-key: web-server: defaults: authenticate: true paths: - path: \"/metrics[/{*}]\" roles-allowed: \"admin\" - path: \"/health[/{*}]\" roles-allowed: \"monitor\" - path: \"/openapi[/{*}]\" abac: scopes: [\"openapi\"] - path: \"/static[/{*}]\" roles-allowed: [\"user\", \"monitor\"] Attribute based access control provider that checks roles and scopes The provider(s) used in your application, such as oidc Default configuration for all configured paths Protection of /metrics and all nested paths with admin role required Protection of /health and all nested paths with monitor role required Protection of /openapi and all nested paths with openapi scope required Protection of static content configured on /static path with either user or monitor role required If you need to use a properties file, such as microprofile-config.properties , you can convert the file by using index based numbers for arrays, such as: <markup lang=\"properties\" title=\"microprofile-config.properties\" >security.providers.0.abac= security.providers.1.provider-key.optional=false security.web-server.defaults.authenticate=true security.web-server.paths.0.path=/metrics[/{*}] security.web-server.paths.0.roles-allowed=admin security.web-server.paths.3.path=/static[/{*}] security.web-server.paths.3.roles-allowed=user,monitor ",
            "title": "Protecting Helidon endpoints"
        },
        {
            "location": "/se/security/containers-integration",
            "text": " To integrate web server , add the following dependency to your project&#8217;s pom.xml file: <markup lang=\"xml\" title=\"Maven Dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webserver&lt;/groupId&gt; &lt;artifactId&gt;helidon-webserver-security&lt;/artifactId&gt; &lt;/dependency&gt; Configure Security with WebServer There are two steps to configure security with WebServer: Create a security instance and register it with the server. Protect server routes with optional security features. <markup lang=\"java\" title=\"Example using builders\" >// web server's Routing HttpRouting.builder() // This is step 1 - register security instance with web server processing // security - instance of security either from config or from a builder // securityDefaults - default enforcement for each route that has a security definition .addFeature(SecurityFeature.create(security).securityDefaults(SecurityFeature.authenticate())) // this is step 2 - protect a route // protect this route with authentication (from defaults) and role \"user\" .get(\"/service1\", SecurityFeature.rolesAllowed(\"user\"), (req, res) -&gt; { processService1Request(req, res); }) .build(); <markup lang=\"java\" title=\"Example using configuration\" >HttpRouting.builder() // helper method to load both security and web server security from configuration .addFeature(SecurityFeature.create(config)) // continue with web server route configuration .build(); <markup lang=\"yaml\" title=\"Example using configuration (YAML)\" ># This may change in the future - to align with web server configuration, once it is supported security.web-server: # Configuration of integration with web server defaults: authenticate: true paths: - path: \"/service1/[/{*}]\" methods: [\"get\"] roles-allowed: [\"user\"] Protecting Helidon endpoints There are several endpoints provided by Helidon services, such as: Health endpoint ( /health ) Metrics endpoint ( /metrics ) OpenAPI endpoint ( /openapi ) Configured static content (can use any path configured) These endpoints are all implemented using Helidon WebServer and as such can be protected only through Security integration with WebServer. The following section describes configuration of such protection using configuration files, in this case using a yaml file, as it provides a tree structure. Configuring endpoint protection The configuration is usually placed under security.web-server (this can be customized in Helidon SE). The following shows an example we will explain in detail: <markup lang=\"yaml\" title=\"application.yaml\" >security: providers: - abac: - provider-key: web-server: defaults: authenticate: true paths: - path: \"/metrics[/{*}]\" roles-allowed: \"admin\" - path: \"/health[/{*}]\" roles-allowed: \"monitor\" - path: \"/openapi[/{*}]\" abac: scopes: [\"openapi\"] - path: \"/static[/{*}]\" roles-allowed: [\"user\", \"monitor\"] Attribute based access control provider that checks roles and scopes The provider(s) used in your application, such as oidc Default configuration for all configured paths Protection of /metrics and all nested paths with admin role required Protection of /health and all nested paths with monitor role required Protection of /openapi and all nested paths with openapi scope required Protection of static content configured on /static path with either user or monitor role required If you need to use a properties file, such as microprofile-config.properties , you can convert the file by using index based numbers for arrays, such as: <markup lang=\"properties\" title=\"microprofile-config.properties\" >security.providers.0.abac= security.providers.1.provider-key.optional=false security.web-server.defaults.authenticate=true security.web-server.paths.0.path=/metrics[/{*}] security.web-server.paths.0.roles-allowed=admin security.web-server.paths.3.path=/static[/{*}] security.web-server.paths.3.roles-allowed=user,monitor ",
            "title": "WebServer"
        },
        {
            "location": "/se/security/containers-integration",
            "text": " Helidon WebServer Security Integration ",
            "title": "Reference"
        },
        {
            "location": "/se/security/extensibility",
            "text": " This guide describes how you can extend the Security component. The component has the following extension points: Security Providers Provider Selection Policy Framework Integration ",
            "title": "preambule"
        },
        {
            "location": "/se/security/extensibility",
            "text": " To create a custom authentication provider, create a class that implements io.helidon.security.spi.AuthenticationProvider . Implementation is responsible for taking a request and asserting a subject based on that request. In case the protocol is multi-request (e.g. challenge for basic authentication), you have the possibility to return specific headers and a response code. The default semantics of these is HTTP, though providers may exist that are not HTTP specific. ",
            "title": "Authentication Provider"
        },
        {
            "location": "/se/security/extensibility",
            "text": " To create a custom authorization provider, create a class that implements io.helidon.security.spi.AuthorizationProvider . Implementation is responsible for taking a request and checking whether the request can continue processing (e.g. if the current user and/or service subject has a right to execute it). If authentication is configured, the Security component guarantees it resolved before authorization. ",
            "title": "Authorization Provider"
        },
        {
            "location": "/se/security/extensibility",
            "text": " To create a custom outbound security provider, create a class that implements io.helidon.security.spi.OutboundSecurityProvider . Implementation can update outgoing message headers to handle security for an outgoing request (e.g. identity propagation, mapping etc.). ",
            "title": "Outbound Security Provider"
        },
        {
            "location": "/se/security/extensibility",
            "text": " To create a custom audit provider, create a class that implements io.helidon.security.spi.AuditProvider . Security component feeds each audit provider all messages from all components that invoke audit method on \"Security\" class, including internal audit events pre-configured in the component itself (e.g. authentication, authorization events). Implementation may do whatever desired with these messages, e.g.: filter them log them store them to a database forward them to an audit component discard them ",
            "title": "Audit Provider"
        },
        {
            "location": "/se/security/extensibility",
            "text": " You can build a custom provider for each type of security concept supported. You have two options: Implement a provider interface and reference it in configuration (or from builder) by class Implement a provider interface and provide a Java ServiceLoader service implementing io.helidon.security.spi.SecurityProviderService The second option allows for easier configuration, as the configuration key can be used without a class definition and creates a default name of a provider. Authentication Provider To create a custom authentication provider, create a class that implements io.helidon.security.spi.AuthenticationProvider . Implementation is responsible for taking a request and asserting a subject based on that request. In case the protocol is multi-request (e.g. challenge for basic authentication), you have the possibility to return specific headers and a response code. The default semantics of these is HTTP, though providers may exist that are not HTTP specific. Authorization Provider To create a custom authorization provider, create a class that implements io.helidon.security.spi.AuthorizationProvider . Implementation is responsible for taking a request and checking whether the request can continue processing (e.g. if the current user and/or service subject has a right to execute it). If authentication is configured, the Security component guarantees it resolved before authorization. Outbound Security Provider To create a custom outbound security provider, create a class that implements io.helidon.security.spi.OutboundSecurityProvider . Implementation can update outgoing message headers to handle security for an outgoing request (e.g. identity propagation, mapping etc.). Audit Provider To create a custom audit provider, create a class that implements io.helidon.security.spi.AuditProvider . Security component feeds each audit provider all messages from all components that invoke audit method on \"Security\" class, including internal audit events pre-configured in the component itself (e.g. authentication, authorization events). Implementation may do whatever desired with these messages, e.g.: filter them log them store them to a database forward them to an audit component discard them ",
            "title": "Security Providers"
        },
        {
            "location": "/se/security/extensibility",
            "text": " Each request is processed by a single authentication and/or authorization provider. The selection policy provides the security component information about which provider to use. Out of the box, there are three policies: \"First\" policy - first configured provider (or explicitly defined default provider) is used by default, if a named provider is requested, it would be used \"Composite\" policy - this policy allows for a sequence of providers to be executed (e.g. one request may have more than one provider) - used for example to resolve service and user authentication \"Class\" policy - this allows usage of a custom policy defined by fully qualified class name To create a custom provider selection policy, create a class that implements \"io.helidon.security.spi.ProviderSelectionPolicy\". ",
            "title": "Provider Selection Policy"
        },
        {
            "location": "/se/security/extensibility",
            "text": " The Security component supports integration with Helidon WebServer ( helidon-security-integration-webserver ) and with Jersey ( helidon-security-integration-jersey ). Existing integrations (WebServer and Jersey) use Helidon Security APIs that are available to integrate any framework/application (for example we could integrate security with messaging, such as JMS). To create a new integration, an instance of Security class is needed, as it handles all configured providers. Usually a single Security instance is used for an application. Security is then used to create an instance of SecurityContext , which is used for interaction with a single user. A single SecurityContext is created for each HTTP request in Jersey and WebServer integration. SecurityContext is used to invoke authentication, authorization, and outbound security requests. Helidon Security also defines a set of annotations: @Authenticated - access to resources must follow authentication rules defined by the annotation @Authorized - access to resources must follow authorization rules defined by the annotation @Audited - to configure auditing If the protected resources (in Helidon MP, these are JAX-RS resource classes and methods) can be annotated, the integration component must use these annotations when deciding how to secure the endpoint. For example, the Jersey integration checks whether the @Authenticated annotation exists. If it does, then the integration component attempts to authenticate the request. Because other components of Helidon Security (such as ABAC validators) query the request for annotations, the integration component should also collect all annotations from the resource and correctly configure them when creating the security request. ",
            "title": "Framework Integration"
        },
        {
            "location": "/se/security/introduction",
            "text": " Overview Maven Coordinates Usage ",
            "title": "Contents"
        },
        {
            "location": "/se/security/introduction",
            "text": " Helidon Security provides authentication, authorization, and auditing for your Helidon application. It includes the following features: Authentication - support for authenticating incoming requests, creating a security Subject with Principal and Grants. Principal represents current user/service. Grant may represent a Role, Scope etc. Responsibility to create Principals and Grants lies with with AuthenticationProvider SPI. The following Principals are expected and supported by default: UserPrincipal - the party is an end-user (e.g. a person) - there can be zero to one user principals in a subject ServicePrincipal - the party is a service (e.g. a computer program) - there can be zero to one service principals in a subject Authorization - support for authorizing incoming requests. Out-of-the-box the security module supports ABAC and RBAC (Attribute based access control and Role based access control). RBAC is handled through RolesAllowed annotation (for integrations that support injection). Outbound security - support for propagating identity or (in general) securing outbound requests. Modification of a request to include outbound security is responsibility of OutboundSecurityProvider SPI Audit - security module audits most important events through its own API (e.g. Authentication events, Authorization events, outbound security events). A default AuditProvider is provided as well, logging to Java util logging (JUL) logger called \"AUDIT\" (may be overridden through configuration). AuditProvider SPI may be implemented to support other auditing options. Security module is quite HTTP centric (as most common use cases are related to HTTP REST), though it is not HTTP specific (the security module may be used to secure even other transports, such as JMS, Kafka messages etc. if an appropriate integration module is developed, as all APIs can be mapped to a non-HTTP protocol). Nevertheless there may be security providers that only make sense with HTTP (such as HTTP digest authentication). ",
            "title": "Overview"
        },
        {
            "location": "/se/security/introduction",
            "text": " To enable Security add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security&lt;/groupId&gt; &lt;artifactId&gt;helidon-security&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/security/introduction",
            "text": "<markup lang=\"java\" title=\"Security through a builder\" >Security security = Security.builder() // create a provider instance based on the provider documentation .addProvider(...) .build(); ",
            "title": "Builder Pattern"
        },
        {
            "location": "/se/security/introduction",
            "text": " When a configuration needs to be overridden, we may have problems with the list type of the providers configuration. To simplify overrides using properties, you can explicitly setup a type of provider using a type key. Example: <markup lang=\"properties\" >security.providers.1.type=header-atn security.providers.1.header-atn.authenticate=false Would explicitly override the second provider ( http-basic-auth in example above) with header-atn provider. Note that the type and the key of the provider must match. ",
            "title": "Overriding Configuration"
        },
        {
            "location": "/se/security/introduction",
            "text": " See Secure config for details about encrypting passwords in configuration files. <markup lang=\"java\" title=\"Security from configuration\" >// uses io.helidon.Config Security security = Security.create(config); <markup lang=\"yaml\" title=\"Security from configuration - application.yaml\" ># Uses config encryption filter to encrypt passwords security: providers: - abac: - http-basic-auth: realm: \"helidon\" users: - login: \"jack\" password: \"${CLEAR=password}\" roles: [\"user\", \"admin\"] - login: \"jill\" password: \"${CLEAR=password}\" roles: [\"user\"] Overriding Configuration When a configuration needs to be overridden, we may have problems with the list type of the providers configuration. To simplify overrides using properties, you can explicitly setup a type of provider using a type key. Example: <markup lang=\"properties\" >security.providers.1.type=header-atn security.providers.1.header-atn.authenticate=false Would explicitly override the second provider ( http-basic-auth in example above) with header-atn provider. Note that the type and the key of the provider must match. ",
            "title": "Configuration Pattern"
        },
        {
            "location": "/se/security/introduction",
            "text": "<markup lang=\"java\" title=\"Security from configuration and builder\" >// uses io.helidon.Config Security security = Security.builder(config) .addProvider(...) .build(); // or reverse order: Security security = Security.builder() .addProvider() .config(config) .build(); ",
            "title": "Hybrid Pattern (Builder with Configuration)"
        },
        {
            "location": "/se/security/introduction",
            "text": " To integrate with a container, or to use Security standalone, we must create an instance of security. In general, Security supports three approaches a fluent-API builder pattern - you configure everything \"by hand\" a configuration based pattern - you configure everything in a configuration file hybrid - you load a builder from configuration and update it in a program Once a security instance is built, it can be used to initialize an integration with a container , or to use security from a program directly: <markup lang=\"java\" title=\"Security direct usage\" >// create a security context SecurityContext context = security.contextBuilder(UUID.randomUUID().toString()) .env(SecurityEnvironment.builder() .method(\"get\") .path(\"/test\") .transport(\"http\") .header(\"Authorization\", \"Bearer abcdefgh\") .build()) .build(); // use the context to authenticate a request AuthenticationResponse response = context.atnClientBuilder().submit(); if (response.status().isSuccess()) { System.out.println(response.user()); System.out.println(response.service()); } else { System.out.println(\"Authentication failed: \" + response.description()); } Builder Pattern <markup lang=\"java\" title=\"Security through a builder\" >Security security = Security.builder() // create a provider instance based on the provider documentation .addProvider(...) .build(); Configuration Pattern See Secure config for details about encrypting passwords in configuration files. <markup lang=\"java\" title=\"Security from configuration\" >// uses io.helidon.Config Security security = Security.create(config); <markup lang=\"yaml\" title=\"Security from configuration - application.yaml\" ># Uses config encryption filter to encrypt passwords security: providers: - abac: - http-basic-auth: realm: \"helidon\" users: - login: \"jack\" password: \"${CLEAR=password}\" roles: [\"user\", \"admin\"] - login: \"jill\" password: \"${CLEAR=password}\" roles: [\"user\"] Overriding Configuration When a configuration needs to be overridden, we may have problems with the list type of the providers configuration. To simplify overrides using properties, you can explicitly setup a type of provider using a type key. Example: <markup lang=\"properties\" >security.providers.1.type=header-atn security.providers.1.header-atn.authenticate=false Would explicitly override the second provider ( http-basic-auth in example above) with header-atn provider. Note that the type and the key of the provider must match. Hybrid Pattern (Builder with Configuration) <markup lang=\"java\" title=\"Security from configuration and builder\" >// uses io.helidon.Config Security security = Security.builder(config) .addProvider(...) .build(); // or reverse order: Security security = Security.builder() .addProvider() .config(config) .build(); ",
            "title": "Usage"
        },
        {
            "location": "/se/security/jep-290",
            "text": " Overview Deserialization setup System property configuration Programmatic configuration ",
            "title": "Contents"
        },
        {
            "location": "/se/security/jep-290",
            "text": " JEP-290 brought support for deserialization filters to Java programming language. Such filtering allows us to control which classes may be deserialized using Java serialization. ",
            "title": "Overview"
        },
        {
            "location": "/se/security/jep-290",
            "text": " Helidon default settings forbids any deserialization except for patterns defined in a pattern property of any META-INF/helidon/serial-config.properties on classpath. The patterns are semicolon delimited strings, such as io.myapp.&#42;&#42;;java.util.HashMap (any subpackage of io.myapp and class java.util.HashMap ). Helidon will always add a deny-all filter pattern to the end of the pattern string (to make sure we exclude any unspecified class - we only operate on whitelists) These defaults can be modified either through system properties, or programmatically. ",
            "title": "Deserialization setup"
        },
        {
            "location": "/se/security/jep-290",
            "text": " The following system properties can be used to control deserialization in Helidon: System properties property default value description helidon.serialFilter.pattern !&#42; Filter pattern to use, deny all is always added helidon.serialFilter.ignoreFiles false Whether to ignore files META-INF/helidon/serial-config.properties in libraries on the classpath helidon.serialFilter.failure.action FAIL Action to do when the configuration of global filter exists and is not consistent with our security expectations (e.g. contains a pattern to include all). Options: FAIL - throw an exception to terminate startup WARN - log a warning IGNORE - ignore this and silently continue helidon.serialFilter.missing.action CONFIGURE Action to do when there is no global configuration. Options: CONFIGURE - configure Helidon defaults FAIL - throw an exception to terminate startup WARN - log a warning IGNORE - ignore this and silently continue helidon.serialFilter.trace NONE Tracing configuration for deserialization. Controls what information (if any) will be logged to a logger io.helidon.common.SerializationConfig.TracingObjectInputFilter in INFO log level. Options: NONE - do not trace BASIC - trace only classes, and only once per class FULL - trace all deserialization filter requests ",
            "title": "System property configuration"
        },
        {
            "location": "/se/security/jep-290",
            "text": " Custom SerializationConfig may be registered, but it must be done before Helidon server is started. <markup lang=\"java\" title=\"Configure custom Helidon serialization config\" >SerializationConfig.builder() .traceSerialization(SerializationConfig.TraceOption.BASIC) .filterPattern(MyType.class.getName()) .ignoreFiles(true) .onWrongConfig(SerializationConfig.Action.IGNORE) .build() .configure(); Trace first instance of each class that is deserialized Configure a single class filter pattern (only allows deserialization of class MyType Ignore files defined in META-INF/helidon/serial-config.properties In case there is an existing global serialization configuration on JDK, ignore it and continue (global filter cannot be reconfigured) Configure this serialization config as the default for this JVM ",
            "title": "Programmatic configuration"
        },
        {
            "location": "/se/security/providers",
            "text": " Implemented Security Providers Maven Coordinates Reference ",
            "title": "Contents"
        },
        {
            "location": "/se/security/providers",
            "text": " Helidon provides the following security providers for endpoint protection: Provider Type Outbound supported Description OIDC Provider Authentication ✅ Open ID Connect supporting JWT, Scopes, Groups and OIDC code flow HTTP Basic Authentication Authentication ✅ HTTP Basic Authentication support HTTP Digest Authentication Authentication 🚫 HTTP Digest Authentication support Header Assertion Authentication ✅ Asserting a user based on a header value HTTP Signatures Authentication ✅ Protecting service to service communication through signatures IDCS Roles Role Mapping 🚫 Retrieves roles from IDCS provider for authenticated user ABAC Authorization Authorization 🚫 Attribute based access control authorization policies The following providers are no longer evolved: Provider Type Outbound supported Description Google Login Authentication ✅ Authenticates a token from request against Google servers JWT Provider Authentication ✅ JWT tokens passed from frontend ",
            "title": "Implemented Security Providers"
        },
        {
            "location": "/se/security/providers",
            "text": " In Helidon SE, we need to register the redirection support with routing (in addition to SecurityFeature that integrates with WebServer ). This is not required when redirect is set to false. <markup lang=\"java\" title=\"Adding support for OIDC redirects\" >HttpRouting routing = HttpRouting.builder() .addFeature(SecurityFeature.create(config.get(\"security\"))) .addFeature(OidcFeature.create(config)) .build(); Open ID Connect security provider Type: io.helidon.security.providers.oidc.OidcProvider <markup lang=\"text\" title=\"Config key\" >oidc This type provides the following service implementations: io.helidon.security.spi.AuthenticationProvider io.helidon.security.spi.SecurityProvider ",
            "title": "Overview"
        },
        {
            "location": "/se/security/providers",
            "text": " Optional configuration options key type default value description audience string &#160; Audience of issued tokens. authorization-endpoint-uri URI &#160; URI of an authorization endpoint used to redirect users to for logging-in. If not defined, it is obtained from #oidcMetadata(Resource), if that is not defined an attempt is made to use #identityUri(URI)/oauth2/v1/authorize. base-scopes string openid Configure base scopes. By default, this is DEFAULT_BASE_SCOPES . If scope has a qualifier, it must be used here. check-audience boolean false Configure audience claim check. client-id string &#160; Client ID as generated by OIDC server. client-secret string &#160; Client secret as generated by OIDC server. Used to authenticate this application with the server when requesting JWT based on a code. client-timeout-millis Duration 30000 Timeout of calls using web client. cookie-domain string &#160; Domain the cookie is valid for. Not used by default. cookie-http-only boolean true When using cookie, if set to true, the HttpOnly attribute will be configured. Defaults to OidcCookieHandler.Builder#DEFAULT_HTTP_ONLY . cookie-max-age-seconds long &#160; When using cookie, used to set MaxAge attribute of the cookie, defining how long the cookie is valid. Not used by default. cookie-name string JSESSIONID Name of the cookie to use. Defaults to DEFAULT_COOKIE_NAME . cookie-name-tenant string HELIDON_TENANT The name of the cookie to use for the tenant name. Defaults to DEFAULT_TENANT_COOKIE_NAME . cookie-path string / Path the cookie is valid for. Defaults to \"/\". cookie-same-site SameSite (LAX, STRICT, NONE) LAX When using cookie, used to set the SameSite cookie value. Can be \"Strict\" or \"Lax\". cookie-secure boolean false When using cookie, if set to true, the Secure attribute will be configured. Defaults to false. cookie-use boolean true Whether to use cookie to store JWT between requests. Defaults to DEFAULT_COOKIE_USE . cors CrossOriginConfig &#160; Assign cross-origin resource sharing settings. force-https-redirects boolean false Force HTTPS for redirects to identity provider. Defaults to false . frontend-uri string &#160; Full URI of this application that is visible from user browser. Used to redirect request back from identity server after successful login. header-token TokenHandler &#160; A TokenHandler to process header containing a JWT. Default is \"Authorization\" header with a prefix \"bearer \". header-use boolean true Whether to expect JWT in a header field. identity-uri URI &#160; URI of the identity server, base used to retrieve OIDC metadata. introspect-endpoint-uri URI &#160; Endpoint to use to validate JWT. Either use this or set #signJwk(JwkKeys) or #signJwk(Resource). issuer string &#160; Issuer of issued tokens. max-redirects int 5 Configure maximal number of redirects when redirecting to an OIDC provider within a single authentication attempt. Defaults to `DEFAULT_MAX_REDIRECTS` oidc-metadata-well-known boolean true If set to true, metadata will be loaded from default (well known) location, unless it is explicitly defined using oidc-metadata-resource. If set to false, it would not be loaded even if oidc-metadata-resource is not defined. In such a case all URIs must be explicitly defined (e.g. token-endpoint-uri). oidc-metadata.resource Resource &#160; Resource configuration for OIDC Metadata containing endpoints to various identity services, as well as information about the identity server. optional boolean false Whether authentication is required. By default, request will fail if the authentication cannot be verified. If set to true, request will process and this provider will abstain. optional-audience boolean false Allow audience claim to be optional. outbound OutboundTarget[&#93; &#160; Add a new target configuration. propagate boolean false Whether to propagate identity. proxy-host string &#160; Proxy host to use. When defined, triggers usage of proxy for HTTP requests. Setting to empty String has the same meaning as setting to null - disables proxy. proxy-port int 80 Proxy port. Defaults to DEFAULT_PROXY_PORT proxy-protocol string http Proxy protocol to use when proxy is used. Defaults to DEFAULT_PROXY_PROTOCOL . query-param-name string accessToken Name of a query parameter that contains the JWT token when parameter is used. query-param-tenant-name string h_tenant Name of a query parameter that contains the tenant name when the parameter is used. Defaults to #DEFAULT_TENANT_PARAM_NAME. query-param-use boolean false Whether to use a query parameter to send JWT token from application to this server. redirect boolean false By default, the client should redirect to the identity server for the user to log in. This behavior can be overridden by setting redirect to false. When token is not present in the request, the client will not redirect and just return appropriate error response code. redirect-attempt-param string h_ra Configure the parameter used to store the number of attempts in redirect. Defaults to `DEFAULT_ATTEMPT_PARAM` redirect-uri string /oidc/redirect URI to register web server component on, used by the OIDC server to redirect authorization requests to after a user logs in or approves scopes. Note that usually the redirect URI configured here must be the same one as configured on OIDC server. Defaults to `DEFAULT_REDIRECT_URI` relative-uris boolean false Can be set to true to force the use of relative URIs in all requests, regardless of the presence or absence of proxies or no-proxy lists. By default, requests that use the Proxy will have absolute URIs. Set this flag to true if the host is unable to accept absolute URIs. Defaults to DEFAULT_RELATIVE_URIS . scope-audience string &#160; Audience of the scope required by this application. This is prefixed to the scope name when requesting scopes from the identity server. Defaults to empty string. server-type string @default Configure one of the supported types of identity servers. If the type does not have an explicit mapping, a warning is logged and the default implementation is used. sign-jwk.resource Resource &#160; A resource pointing to JWK with public keys of signing certificates used to validate JWT. tenants TenantConfig &#160; Configurations of the tenants token-endpoint-auth ClientAuthentication (CLIENT_SECRET_BASIC, CLIENT_SECRET_POST, CLIENT_SECRET_JWT, PRIVATE_KEY_JWT, NONE) CLIENT_SECRET_BASIC Type of authentication to use when invoking the token endpoint. Current supported options: io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#CLIENT_SECRET_BASIC io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#CLIENT_SECRET_POST io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#NONE token-endpoint-uri URI &#160; URI of a token endpoint used to obtain a JWT based on the authentication code. If not defined, it is obtained from #oidcMetadata(Resource), if that is not defined an attempt is made to use #identityUri(URI)/oauth2/v1/token. use-jwt-groups boolean true Claim groups from JWT will be used to automatically add groups to current subject (may be used with jakarta.annotation.security.RolesAllowed annotation). validate-jwt-with-jwk boolean true Use JWK (a set of keys to validate signatures of JWT) to validate tokens. Use this method when you want to use default values for JWK or introspection endpoint URI. ",
            "title": "Configuration options"
        },
        {
            "location": "/se/security/providers",
            "text": "<markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-oidc&lt;/artifactId&gt; &lt;/dependency&gt; Overview In Helidon SE, we need to register the redirection support with routing (in addition to SecurityFeature that integrates with WebServer ). This is not required when redirect is set to false. <markup lang=\"java\" title=\"Adding support for OIDC redirects\" >HttpRouting routing = HttpRouting.builder() .addFeature(SecurityFeature.create(config.get(\"security\"))) .addFeature(OidcFeature.create(config)) .build(); Open ID Connect security provider Type: io.helidon.security.providers.oidc.OidcProvider <markup lang=\"text\" title=\"Config key\" >oidc This type provides the following service implementations: io.helidon.security.spi.AuthenticationProvider io.helidon.security.spi.SecurityProvider Configuration options Optional configuration options key type default value description audience string &#160; Audience of issued tokens. authorization-endpoint-uri URI &#160; URI of an authorization endpoint used to redirect users to for logging-in. If not defined, it is obtained from #oidcMetadata(Resource), if that is not defined an attempt is made to use #identityUri(URI)/oauth2/v1/authorize. base-scopes string openid Configure base scopes. By default, this is DEFAULT_BASE_SCOPES . If scope has a qualifier, it must be used here. check-audience boolean false Configure audience claim check. client-id string &#160; Client ID as generated by OIDC server. client-secret string &#160; Client secret as generated by OIDC server. Used to authenticate this application with the server when requesting JWT based on a code. client-timeout-millis Duration 30000 Timeout of calls using web client. cookie-domain string &#160; Domain the cookie is valid for. Not used by default. cookie-http-only boolean true When using cookie, if set to true, the HttpOnly attribute will be configured. Defaults to OidcCookieHandler.Builder#DEFAULT_HTTP_ONLY . cookie-max-age-seconds long &#160; When using cookie, used to set MaxAge attribute of the cookie, defining how long the cookie is valid. Not used by default. cookie-name string JSESSIONID Name of the cookie to use. Defaults to DEFAULT_COOKIE_NAME . cookie-name-tenant string HELIDON_TENANT The name of the cookie to use for the tenant name. Defaults to DEFAULT_TENANT_COOKIE_NAME . cookie-path string / Path the cookie is valid for. Defaults to \"/\". cookie-same-site SameSite (LAX, STRICT, NONE) LAX When using cookie, used to set the SameSite cookie value. Can be \"Strict\" or \"Lax\". cookie-secure boolean false When using cookie, if set to true, the Secure attribute will be configured. Defaults to false. cookie-use boolean true Whether to use cookie to store JWT between requests. Defaults to DEFAULT_COOKIE_USE . cors CrossOriginConfig &#160; Assign cross-origin resource sharing settings. force-https-redirects boolean false Force HTTPS for redirects to identity provider. Defaults to false . frontend-uri string &#160; Full URI of this application that is visible from user browser. Used to redirect request back from identity server after successful login. header-token TokenHandler &#160; A TokenHandler to process header containing a JWT. Default is \"Authorization\" header with a prefix \"bearer \". header-use boolean true Whether to expect JWT in a header field. identity-uri URI &#160; URI of the identity server, base used to retrieve OIDC metadata. introspect-endpoint-uri URI &#160; Endpoint to use to validate JWT. Either use this or set #signJwk(JwkKeys) or #signJwk(Resource). issuer string &#160; Issuer of issued tokens. max-redirects int 5 Configure maximal number of redirects when redirecting to an OIDC provider within a single authentication attempt. Defaults to `DEFAULT_MAX_REDIRECTS` oidc-metadata-well-known boolean true If set to true, metadata will be loaded from default (well known) location, unless it is explicitly defined using oidc-metadata-resource. If set to false, it would not be loaded even if oidc-metadata-resource is not defined. In such a case all URIs must be explicitly defined (e.g. token-endpoint-uri). oidc-metadata.resource Resource &#160; Resource configuration for OIDC Metadata containing endpoints to various identity services, as well as information about the identity server. optional boolean false Whether authentication is required. By default, request will fail if the authentication cannot be verified. If set to true, request will process and this provider will abstain. optional-audience boolean false Allow audience claim to be optional. outbound OutboundTarget[&#93; &#160; Add a new target configuration. propagate boolean false Whether to propagate identity. proxy-host string &#160; Proxy host to use. When defined, triggers usage of proxy for HTTP requests. Setting to empty String has the same meaning as setting to null - disables proxy. proxy-port int 80 Proxy port. Defaults to DEFAULT_PROXY_PORT proxy-protocol string http Proxy protocol to use when proxy is used. Defaults to DEFAULT_PROXY_PROTOCOL . query-param-name string accessToken Name of a query parameter that contains the JWT token when parameter is used. query-param-tenant-name string h_tenant Name of a query parameter that contains the tenant name when the parameter is used. Defaults to #DEFAULT_TENANT_PARAM_NAME. query-param-use boolean false Whether to use a query parameter to send JWT token from application to this server. redirect boolean false By default, the client should redirect to the identity server for the user to log in. This behavior can be overridden by setting redirect to false. When token is not present in the request, the client will not redirect and just return appropriate error response code. redirect-attempt-param string h_ra Configure the parameter used to store the number of attempts in redirect. Defaults to `DEFAULT_ATTEMPT_PARAM` redirect-uri string /oidc/redirect URI to register web server component on, used by the OIDC server to redirect authorization requests to after a user logs in or approves scopes. Note that usually the redirect URI configured here must be the same one as configured on OIDC server. Defaults to `DEFAULT_REDIRECT_URI` relative-uris boolean false Can be set to true to force the use of relative URIs in all requests, regardless of the presence or absence of proxies or no-proxy lists. By default, requests that use the Proxy will have absolute URIs. Set this flag to true if the host is unable to accept absolute URIs. Defaults to DEFAULT_RELATIVE_URIS . scope-audience string &#160; Audience of the scope required by this application. This is prefixed to the scope name when requesting scopes from the identity server. Defaults to empty string. server-type string @default Configure one of the supported types of identity servers. If the type does not have an explicit mapping, a warning is logged and the default implementation is used. sign-jwk.resource Resource &#160; A resource pointing to JWK with public keys of signing certificates used to validate JWT. tenants TenantConfig &#160; Configurations of the tenants token-endpoint-auth ClientAuthentication (CLIENT_SECRET_BASIC, CLIENT_SECRET_POST, CLIENT_SECRET_JWT, PRIVATE_KEY_JWT, NONE) CLIENT_SECRET_BASIC Type of authentication to use when invoking the token endpoint. Current supported options: io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#CLIENT_SECRET_BASIC io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#CLIENT_SECRET_POST io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#NONE token-endpoint-uri URI &#160; URI of a token endpoint used to obtain a JWT based on the authentication code. If not defined, it is obtained from #oidcMetadata(Resource), if that is not defined an attempt is made to use #identityUri(URI)/oauth2/v1/token. use-jwt-groups boolean true Claim groups from JWT will be used to automatically add groups to current subject (may be used with jakarta.annotation.security.RolesAllowed annotation). validate-jwt-with-jwk boolean true Use JWK (a set of keys to validate signatures of JWT) to validate tokens. Use this method when you want to use default values for JWK or introspection endpoint URI. ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/security/providers",
            "text": " See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - oidc: client-id: \"client-id-of-this-service\" client-secret: \"${CLEAR=client-secret-of-this-service}\" identity-uri: \"http://your-tenant.identity-server.com\" frontend-uri: \"http://my-service:8080\" audience: \"http://my-service\" cors: allow-origins: [\"http://foo.com\", \"http://there.com\"] allow-methods: [\"PUT\", \"DELETE\"] outbound: - name: \"internal-services\" hosts: [\"*.example.org\"] outbound-token: header: \"X-Internal-Auth\" ",
            "title": "Example code"
        },
        {
            "location": "/se/security/providers",
            "text": " At Helidon startup, if OIDC provider is configured, the following will happen: client-id , client-secret , and identityUri are validated - these must provide values Unless all resources are configured as local resources, the provider attempts to contact the oidc-metadata.resource endpoint to retrieve all endpoints At runtime, depending on configuration&#8230;&#8203; If a request comes without a token or with insufficient scopes: If redirect is set to true (default), request is redirected to the authorization endpoint of the identity server. If set to false, 401 is returned User authenticates against the identity server The identity server redirects back to Helidon service with a code Helidon service contacts the identity server&#8217;s token endpoint, to exchange the code for a JWT The JWT is stored in a cookie (if cookie support is enabled, which it is by default) Helidon service redirects to original endpoint (on itself) Helidon obtains a token from request (from cookie, header, or query parameter): Token is parsed as a singed JWT We validate the JWT signature either against local JWK or against the identity server&#8217;s introspection endpoint depending on configuration We validate the issuer and audience of the token if it matches the configured values A subject is created from the JWT, including scopes from the token We validate that we have sufficient scopes to proceed, and return 403 if not Handling is returned to security to process other security providers ",
            "title": "How does it work?"
        },
        {
            "location": "/se/security/providers",
            "text": " Required configuration options key type default value description name string &#160; Name of the tenant. Optional configuration options key type default value description audience string &#160; Audience of issued tokens. authorization-endpoint-uri URI &#160; URI of an authorization endpoint used to redirect users to for logging-in. If not defined, it is obtained from #oidcMetadata(Resource), if that is not defined an attempt is made to use #identityUri(URI)/oauth2/v1/authorize. base-scopes string openid Configure base scopes. By default, this is DEFAULT_BASE_SCOPES . If scope has a qualifier, it must be used here. check-audience boolean false Configure audience claim check. client-id string &#160; Client ID as generated by OIDC server. client-secret string &#160; Client secret as generated by OIDC server. Used to authenticate this application with the server when requesting JWT based on a code. client-timeout-millis Duration 30000 Timeout of calls using web client. identity-uri URI &#160; URI of the identity server, base used to retrieve OIDC metadata. introspect-endpoint-uri URI &#160; Endpoint to use to validate JWT. Either use this or set #signJwk(JwkKeys) or #signJwk(Resource). issuer string &#160; Issuer of issued tokens. oidc-metadata-well-known boolean true If set to true, metadata will be loaded from default (well known) location, unless it is explicitly defined using oidc-metadata-resource. If set to false, it would not be loaded even if oidc-metadata-resource is not defined. In such a case all URIs must be explicitly defined (e.g. token-endpoint-uri). oidc-metadata.resource Resource &#160; Resource configuration for OIDC Metadata containing endpoints to various identity services, as well as information about the identity server. optional-audience boolean false Allow audience claim to be optional. scope-audience string &#160; Audience of the scope required by this application. This is prefixed to the scope name when requesting scopes from the identity server. Defaults to empty string. server-type string @default Configure one of the supported types of identity servers. If the type does not have an explicit mapping, a warning is logged and the default implementation is used. sign-jwk.resource Resource &#160; A resource pointing to JWK with public keys of signing certificates used to validate JWT. token-endpoint-auth ClientAuthentication (CLIENT_SECRET_BASIC, CLIENT_SECRET_POST, CLIENT_SECRET_JWT, PRIVATE_KEY_JWT, NONE) CLIENT_SECRET_BASIC Type of authentication to use when invoking the token endpoint. Current supported options: io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#CLIENT_SECRET_BASIC io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#CLIENT_SECRET_POST io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#NONE token-endpoint-uri URI &#160; URI of a token endpoint used to obtain a JWT based on the authentication code. If not defined, it is obtained from #oidcMetadata(Resource), if that is not defined an attempt is made to use #identityUri(URI)/oauth2/v1/token. validate-jwt-with-jwk boolean true Use JWK (a set of keys to validate signatures of JWT) to validate tokens. Use this method when you want to use default values for JWK or introspection endpoint URI. ",
            "title": "Configuration options"
        },
        {
            "location": "/se/security/providers",
            "text": " Open ID Connect tenant configuration Type: io.helidon.security.providers.oidc.common.TenantConfig Configuration options Required configuration options key type default value description name string &#160; Name of the tenant. Optional configuration options key type default value description audience string &#160; Audience of issued tokens. authorization-endpoint-uri URI &#160; URI of an authorization endpoint used to redirect users to for logging-in. If not defined, it is obtained from #oidcMetadata(Resource), if that is not defined an attempt is made to use #identityUri(URI)/oauth2/v1/authorize. base-scopes string openid Configure base scopes. By default, this is DEFAULT_BASE_SCOPES . If scope has a qualifier, it must be used here. check-audience boolean false Configure audience claim check. client-id string &#160; Client ID as generated by OIDC server. client-secret string &#160; Client secret as generated by OIDC server. Used to authenticate this application with the server when requesting JWT based on a code. client-timeout-millis Duration 30000 Timeout of calls using web client. identity-uri URI &#160; URI of the identity server, base used to retrieve OIDC metadata. introspect-endpoint-uri URI &#160; Endpoint to use to validate JWT. Either use this or set #signJwk(JwkKeys) or #signJwk(Resource). issuer string &#160; Issuer of issued tokens. oidc-metadata-well-known boolean true If set to true, metadata will be loaded from default (well known) location, unless it is explicitly defined using oidc-metadata-resource. If set to false, it would not be loaded even if oidc-metadata-resource is not defined. In such a case all URIs must be explicitly defined (e.g. token-endpoint-uri). oidc-metadata.resource Resource &#160; Resource configuration for OIDC Metadata containing endpoints to various identity services, as well as information about the identity server. optional-audience boolean false Allow audience claim to be optional. scope-audience string &#160; Audience of the scope required by this application. This is prefixed to the scope name when requesting scopes from the identity server. Defaults to empty string. server-type string @default Configure one of the supported types of identity servers. If the type does not have an explicit mapping, a warning is logged and the default implementation is used. sign-jwk.resource Resource &#160; A resource pointing to JWK with public keys of signing certificates used to validate JWT. token-endpoint-auth ClientAuthentication (CLIENT_SECRET_BASIC, CLIENT_SECRET_POST, CLIENT_SECRET_JWT, PRIVATE_KEY_JWT, NONE) CLIENT_SECRET_BASIC Type of authentication to use when invoking the token endpoint. Current supported options: io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#CLIENT_SECRET_BASIC io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#CLIENT_SECRET_POST io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#NONE token-endpoint-uri URI &#160; URI of a token endpoint used to obtain a JWT based on the authentication code. If not defined, it is obtained from #oidcMetadata(Resource), if that is not defined an attempt is made to use #identityUri(URI)/oauth2/v1/token. validate-jwt-with-jwk boolean true Use JWK (a set of keys to validate signatures of JWT) to validate tokens. Use this method when you want to use default values for JWK or introspection endpoint URI. ",
            "title": "Available tenant config options"
        },
        {
            "location": "/se/security/providers",
            "text": " Multitenant support requires to obtain tenant name from the incoming request. OIDC configuration is selected based on the received tenant name. The way this tenant name has to be provided is configured via tenant-id-style configuration. See How to enable tenants for more information. After matching tenant configuration with the received name, the rest of the OIDC flow if exactly the same as in How does OIDC work . Base OIDC configuration is treated as a default tenant, which is used, if no tenant name is provided. This default tenant is having @default name specified. It is also important to note, that each tenant configuration is based on the default tenant configuration (base OIDC configuration), and therefore its configuration do not need to change all the properties, if they do not differ from the base OIDC configuration. ",
            "title": "How does that work?"
        },
        {
            "location": "/se/security/providers",
            "text": " The OIDC provider also supports multiple tenants. To enable this feature, it is required to do several steps. To enable the default multi-tenant support, add the multi-tenant: true option to the OIDC provider configuration Specify the desired way to provide the tenant name. This step is done over adding the tenant-id-style configuration option. For more information, see the table below Add the tenants section to the OIDC provider configuration <markup lang=\"yaml\" >tenants: - name: \"example-tenant\" ... tenant configuration options There are four ways to provide the required tenant information to Helidon by default. Possible tenant-id-style configuration options key description additional config options host-header Tenant configuration will be selected based on your host present in the Host header value. &#160; domain Similar to the host-header style, but now the tenant name is identified just as a part of the host name. By default, it selects the third domain level. Example: Host header value from inbound request is my.helidon.com &#8594; domain level 3 is my , domain level 2 is helidon and domain level 1 is com . <markup lang=\"yaml\" >tenant-id-domain-level: &lt;domain level&gt; token-handler The tenant name information is expected to be provided through the configured custom header value. <markup lang=\"yaml\" >tenant-id-handler: header: \"my-custom-header\" none No tenant name finding is used. Default tenant name @default is used instead. You can also implement a custom way of discovering the tenant name and tenant configuration. The custom tenant name discovery from request can be done by implementing SPI: io.helidon.security.providers.oidc.common.spi.TenantIdProvider and the custom tenant configuration discovery can be provided by implementing SPI: io.helidon.security.providers.oidc.common.spi.TenantConfigProvider Available tenant config options Open ID Connect tenant configuration Type: io.helidon.security.providers.oidc.common.TenantConfig Configuration options Required configuration options key type default value description name string &#160; Name of the tenant. Optional configuration options key type default value description audience string &#160; Audience of issued tokens. authorization-endpoint-uri URI &#160; URI of an authorization endpoint used to redirect users to for logging-in. If not defined, it is obtained from #oidcMetadata(Resource), if that is not defined an attempt is made to use #identityUri(URI)/oauth2/v1/authorize. base-scopes string openid Configure base scopes. By default, this is DEFAULT_BASE_SCOPES . If scope has a qualifier, it must be used here. check-audience boolean false Configure audience claim check. client-id string &#160; Client ID as generated by OIDC server. client-secret string &#160; Client secret as generated by OIDC server. Used to authenticate this application with the server when requesting JWT based on a code. client-timeout-millis Duration 30000 Timeout of calls using web client. identity-uri URI &#160; URI of the identity server, base used to retrieve OIDC metadata. introspect-endpoint-uri URI &#160; Endpoint to use to validate JWT. Either use this or set #signJwk(JwkKeys) or #signJwk(Resource). issuer string &#160; Issuer of issued tokens. oidc-metadata-well-known boolean true If set to true, metadata will be loaded from default (well known) location, unless it is explicitly defined using oidc-metadata-resource. If set to false, it would not be loaded even if oidc-metadata-resource is not defined. In such a case all URIs must be explicitly defined (e.g. token-endpoint-uri). oidc-metadata.resource Resource &#160; Resource configuration for OIDC Metadata containing endpoints to various identity services, as well as information about the identity server. optional-audience boolean false Allow audience claim to be optional. scope-audience string &#160; Audience of the scope required by this application. This is prefixed to the scope name when requesting scopes from the identity server. Defaults to empty string. server-type string @default Configure one of the supported types of identity servers. If the type does not have an explicit mapping, a warning is logged and the default implementation is used. sign-jwk.resource Resource &#160; A resource pointing to JWK with public keys of signing certificates used to validate JWT. token-endpoint-auth ClientAuthentication (CLIENT_SECRET_BASIC, CLIENT_SECRET_POST, CLIENT_SECRET_JWT, PRIVATE_KEY_JWT, NONE) CLIENT_SECRET_BASIC Type of authentication to use when invoking the token endpoint. Current supported options: io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#CLIENT_SECRET_BASIC io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#CLIENT_SECRET_POST io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#NONE token-endpoint-uri URI &#160; URI of a token endpoint used to obtain a JWT based on the authentication code. If not defined, it is obtained from #oidcMetadata(Resource), if that is not defined an attempt is made to use #identityUri(URI)/oauth2/v1/token. validate-jwt-with-jwk boolean true Use JWK (a set of keys to validate signatures of JWT) to validate tokens. Use this method when you want to use default values for JWK or introspection endpoint URI. How does that work? Multitenant support requires to obtain tenant name from the incoming request. OIDC configuration is selected based on the received tenant name. The way this tenant name has to be provided is configured via tenant-id-style configuration. See How to enable tenants for more information. After matching tenant configuration with the received name, the rest of the OIDC flow if exactly the same as in How does OIDC work . Base OIDC configuration is treated as a default tenant, which is used, if no tenant name is provided. This default tenant is having @default name specified. It is also important to note, that each tenant configuration is based on the default tenant configuration (base OIDC configuration), and therefore its configuration do not need to change all the properties, if they do not differ from the base OIDC configuration. ",
            "title": "Multiple tenants"
        },
        {
            "location": "/se/security/providers",
            "text": " Open ID Connect security provider. Maven Coordinates <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-oidc&lt;/artifactId&gt; &lt;/dependency&gt; Overview In Helidon SE, we need to register the redirection support with routing (in addition to SecurityFeature that integrates with WebServer ). This is not required when redirect is set to false. <markup lang=\"java\" title=\"Adding support for OIDC redirects\" >HttpRouting routing = HttpRouting.builder() .addFeature(SecurityFeature.create(config.get(\"security\"))) .addFeature(OidcFeature.create(config)) .build(); Open ID Connect security provider Type: io.helidon.security.providers.oidc.OidcProvider <markup lang=\"text\" title=\"Config key\" >oidc This type provides the following service implementations: io.helidon.security.spi.AuthenticationProvider io.helidon.security.spi.SecurityProvider Configuration options Optional configuration options key type default value description audience string &#160; Audience of issued tokens. authorization-endpoint-uri URI &#160; URI of an authorization endpoint used to redirect users to for logging-in. If not defined, it is obtained from #oidcMetadata(Resource), if that is not defined an attempt is made to use #identityUri(URI)/oauth2/v1/authorize. base-scopes string openid Configure base scopes. By default, this is DEFAULT_BASE_SCOPES . If scope has a qualifier, it must be used here. check-audience boolean false Configure audience claim check. client-id string &#160; Client ID as generated by OIDC server. client-secret string &#160; Client secret as generated by OIDC server. Used to authenticate this application with the server when requesting JWT based on a code. client-timeout-millis Duration 30000 Timeout of calls using web client. cookie-domain string &#160; Domain the cookie is valid for. Not used by default. cookie-http-only boolean true When using cookie, if set to true, the HttpOnly attribute will be configured. Defaults to OidcCookieHandler.Builder#DEFAULT_HTTP_ONLY . cookie-max-age-seconds long &#160; When using cookie, used to set MaxAge attribute of the cookie, defining how long the cookie is valid. Not used by default. cookie-name string JSESSIONID Name of the cookie to use. Defaults to DEFAULT_COOKIE_NAME . cookie-name-tenant string HELIDON_TENANT The name of the cookie to use for the tenant name. Defaults to DEFAULT_TENANT_COOKIE_NAME . cookie-path string / Path the cookie is valid for. Defaults to \"/\". cookie-same-site SameSite (LAX, STRICT, NONE) LAX When using cookie, used to set the SameSite cookie value. Can be \"Strict\" or \"Lax\". cookie-secure boolean false When using cookie, if set to true, the Secure attribute will be configured. Defaults to false. cookie-use boolean true Whether to use cookie to store JWT between requests. Defaults to DEFAULT_COOKIE_USE . cors CrossOriginConfig &#160; Assign cross-origin resource sharing settings. force-https-redirects boolean false Force HTTPS for redirects to identity provider. Defaults to false . frontend-uri string &#160; Full URI of this application that is visible from user browser. Used to redirect request back from identity server after successful login. header-token TokenHandler &#160; A TokenHandler to process header containing a JWT. Default is \"Authorization\" header with a prefix \"bearer \". header-use boolean true Whether to expect JWT in a header field. identity-uri URI &#160; URI of the identity server, base used to retrieve OIDC metadata. introspect-endpoint-uri URI &#160; Endpoint to use to validate JWT. Either use this or set #signJwk(JwkKeys) or #signJwk(Resource). issuer string &#160; Issuer of issued tokens. max-redirects int 5 Configure maximal number of redirects when redirecting to an OIDC provider within a single authentication attempt. Defaults to `DEFAULT_MAX_REDIRECTS` oidc-metadata-well-known boolean true If set to true, metadata will be loaded from default (well known) location, unless it is explicitly defined using oidc-metadata-resource. If set to false, it would not be loaded even if oidc-metadata-resource is not defined. In such a case all URIs must be explicitly defined (e.g. token-endpoint-uri). oidc-metadata.resource Resource &#160; Resource configuration for OIDC Metadata containing endpoints to various identity services, as well as information about the identity server. optional boolean false Whether authentication is required. By default, request will fail if the authentication cannot be verified. If set to true, request will process and this provider will abstain. optional-audience boolean false Allow audience claim to be optional. outbound OutboundTarget[&#93; &#160; Add a new target configuration. propagate boolean false Whether to propagate identity. proxy-host string &#160; Proxy host to use. When defined, triggers usage of proxy for HTTP requests. Setting to empty String has the same meaning as setting to null - disables proxy. proxy-port int 80 Proxy port. Defaults to DEFAULT_PROXY_PORT proxy-protocol string http Proxy protocol to use when proxy is used. Defaults to DEFAULT_PROXY_PROTOCOL . query-param-name string accessToken Name of a query parameter that contains the JWT token when parameter is used. query-param-tenant-name string h_tenant Name of a query parameter that contains the tenant name when the parameter is used. Defaults to #DEFAULT_TENANT_PARAM_NAME. query-param-use boolean false Whether to use a query parameter to send JWT token from application to this server. redirect boolean false By default, the client should redirect to the identity server for the user to log in. This behavior can be overridden by setting redirect to false. When token is not present in the request, the client will not redirect and just return appropriate error response code. redirect-attempt-param string h_ra Configure the parameter used to store the number of attempts in redirect. Defaults to `DEFAULT_ATTEMPT_PARAM` redirect-uri string /oidc/redirect URI to register web server component on, used by the OIDC server to redirect authorization requests to after a user logs in or approves scopes. Note that usually the redirect URI configured here must be the same one as configured on OIDC server. Defaults to `DEFAULT_REDIRECT_URI` relative-uris boolean false Can be set to true to force the use of relative URIs in all requests, regardless of the presence or absence of proxies or no-proxy lists. By default, requests that use the Proxy will have absolute URIs. Set this flag to true if the host is unable to accept absolute URIs. Defaults to DEFAULT_RELATIVE_URIS . scope-audience string &#160; Audience of the scope required by this application. This is prefixed to the scope name when requesting scopes from the identity server. Defaults to empty string. server-type string @default Configure one of the supported types of identity servers. If the type does not have an explicit mapping, a warning is logged and the default implementation is used. sign-jwk.resource Resource &#160; A resource pointing to JWK with public keys of signing certificates used to validate JWT. tenants TenantConfig &#160; Configurations of the tenants token-endpoint-auth ClientAuthentication (CLIENT_SECRET_BASIC, CLIENT_SECRET_POST, CLIENT_SECRET_JWT, PRIVATE_KEY_JWT, NONE) CLIENT_SECRET_BASIC Type of authentication to use when invoking the token endpoint. Current supported options: io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#CLIENT_SECRET_BASIC io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#CLIENT_SECRET_POST io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#NONE token-endpoint-uri URI &#160; URI of a token endpoint used to obtain a JWT based on the authentication code. If not defined, it is obtained from #oidcMetadata(Resource), if that is not defined an attempt is made to use #identityUri(URI)/oauth2/v1/token. use-jwt-groups boolean true Claim groups from JWT will be used to automatically add groups to current subject (may be used with jakarta.annotation.security.RolesAllowed annotation). validate-jwt-with-jwk boolean true Use JWK (a set of keys to validate signatures of JWT) to validate tokens. Use this method when you want to use default values for JWK or introspection endpoint URI. Example code See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - oidc: client-id: \"client-id-of-this-service\" client-secret: \"${CLEAR=client-secret-of-this-service}\" identity-uri: \"http://your-tenant.identity-server.com\" frontend-uri: \"http://my-service:8080\" audience: \"http://my-service\" cors: allow-origins: [\"http://foo.com\", \"http://there.com\"] allow-methods: [\"PUT\", \"DELETE\"] outbound: - name: \"internal-services\" hosts: [\"*.example.org\"] outbound-token: header: \"X-Internal-Auth\" How does it work? At Helidon startup, if OIDC provider is configured, the following will happen: client-id , client-secret , and identityUri are validated - these must provide values Unless all resources are configured as local resources, the provider attempts to contact the oidc-metadata.resource endpoint to retrieve all endpoints At runtime, depending on configuration&#8230;&#8203; If a request comes without a token or with insufficient scopes: If redirect is set to true (default), request is redirected to the authorization endpoint of the identity server. If set to false, 401 is returned User authenticates against the identity server The identity server redirects back to Helidon service with a code Helidon service contacts the identity server&#8217;s token endpoint, to exchange the code for a JWT The JWT is stored in a cookie (if cookie support is enabled, which it is by default) Helidon service redirects to original endpoint (on itself) Helidon obtains a token from request (from cookie, header, or query parameter): Token is parsed as a singed JWT We validate the JWT signature either against local JWK or against the identity server&#8217;s introspection endpoint depending on configuration We validate the issuer and audience of the token if it matches the configured values A subject is created from the JWT, including scopes from the token We validate that we have sufficient scopes to proceed, and return 403 if not Handling is returned to security to process other security providers Multiple tenants The OIDC provider also supports multiple tenants. To enable this feature, it is required to do several steps. To enable the default multi-tenant support, add the multi-tenant: true option to the OIDC provider configuration Specify the desired way to provide the tenant name. This step is done over adding the tenant-id-style configuration option. For more information, see the table below Add the tenants section to the OIDC provider configuration <markup lang=\"yaml\" >tenants: - name: \"example-tenant\" ... tenant configuration options There are four ways to provide the required tenant information to Helidon by default. Possible tenant-id-style configuration options key description additional config options host-header Tenant configuration will be selected based on your host present in the Host header value. &#160; domain Similar to the host-header style, but now the tenant name is identified just as a part of the host name. By default, it selects the third domain level. Example: Host header value from inbound request is my.helidon.com &#8594; domain level 3 is my , domain level 2 is helidon and domain level 1 is com . <markup lang=\"yaml\" >tenant-id-domain-level: &lt;domain level&gt; token-handler The tenant name information is expected to be provided through the configured custom header value. <markup lang=\"yaml\" >tenant-id-handler: header: \"my-custom-header\" none No tenant name finding is used. Default tenant name @default is used instead. You can also implement a custom way of discovering the tenant name and tenant configuration. The custom tenant name discovery from request can be done by implementing SPI: io.helidon.security.providers.oidc.common.spi.TenantIdProvider and the custom tenant configuration discovery can be provided by implementing SPI: io.helidon.security.providers.oidc.common.spi.TenantConfigProvider Available tenant config options Open ID Connect tenant configuration Type: io.helidon.security.providers.oidc.common.TenantConfig Configuration options Required configuration options key type default value description name string &#160; Name of the tenant. Optional configuration options key type default value description audience string &#160; Audience of issued tokens. authorization-endpoint-uri URI &#160; URI of an authorization endpoint used to redirect users to for logging-in. If not defined, it is obtained from #oidcMetadata(Resource), if that is not defined an attempt is made to use #identityUri(URI)/oauth2/v1/authorize. base-scopes string openid Configure base scopes. By default, this is DEFAULT_BASE_SCOPES . If scope has a qualifier, it must be used here. check-audience boolean false Configure audience claim check. client-id string &#160; Client ID as generated by OIDC server. client-secret string &#160; Client secret as generated by OIDC server. Used to authenticate this application with the server when requesting JWT based on a code. client-timeout-millis Duration 30000 Timeout of calls using web client. identity-uri URI &#160; URI of the identity server, base used to retrieve OIDC metadata. introspect-endpoint-uri URI &#160; Endpoint to use to validate JWT. Either use this or set #signJwk(JwkKeys) or #signJwk(Resource). issuer string &#160; Issuer of issued tokens. oidc-metadata-well-known boolean true If set to true, metadata will be loaded from default (well known) location, unless it is explicitly defined using oidc-metadata-resource. If set to false, it would not be loaded even if oidc-metadata-resource is not defined. In such a case all URIs must be explicitly defined (e.g. token-endpoint-uri). oidc-metadata.resource Resource &#160; Resource configuration for OIDC Metadata containing endpoints to various identity services, as well as information about the identity server. optional-audience boolean false Allow audience claim to be optional. scope-audience string &#160; Audience of the scope required by this application. This is prefixed to the scope name when requesting scopes from the identity server. Defaults to empty string. server-type string @default Configure one of the supported types of identity servers. If the type does not have an explicit mapping, a warning is logged and the default implementation is used. sign-jwk.resource Resource &#160; A resource pointing to JWK with public keys of signing certificates used to validate JWT. token-endpoint-auth ClientAuthentication (CLIENT_SECRET_BASIC, CLIENT_SECRET_POST, CLIENT_SECRET_JWT, PRIVATE_KEY_JWT, NONE) CLIENT_SECRET_BASIC Type of authentication to use when invoking the token endpoint. Current supported options: io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#CLIENT_SECRET_BASIC io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#CLIENT_SECRET_POST io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#NONE token-endpoint-uri URI &#160; URI of a token endpoint used to obtain a JWT based on the authentication code. If not defined, it is obtained from #oidcMetadata(Resource), if that is not defined an attempt is made to use #identityUri(URI)/oauth2/v1/token. validate-jwt-with-jwk boolean true Use JWK (a set of keys to validate signatures of JWT) to validate tokens. Use this method when you want to use default values for JWK or introspection endpoint URI. How does that work? Multitenant support requires to obtain tenant name from the incoming request. OIDC configuration is selected based on the received tenant name. The way this tenant name has to be provided is configured via tenant-id-style configuration. See How to enable tenants for more information. After matching tenant configuration with the received name, the rest of the OIDC flow if exactly the same as in How does OIDC work . Base OIDC configuration is treated as a default tenant, which is used, if no tenant name is provided. This default tenant is having @default name specified. It is also important to note, that each tenant configuration is based on the default tenant configuration (base OIDC configuration), and therefore its configuration do not need to change all the properties, if they do not differ from the base OIDC configuration. ",
            "title": "OIDC Provider"
        },
        {
            "location": "/se/security/providers",
            "text": "<markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-http-auth&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Setup"
        },
        {
            "location": "/se/security/providers",
            "text": " HTTP Basic Authentication provider Type: io.helidon.security.providers.httpauth.HttpBasicAuthProvider <markup lang=\"text\" title=\"Config key\" >http-basic-auth This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthenticationProvider ",
            "title": "Overview"
        },
        {
            "location": "/se/security/providers",
            "text": " Optional configuration options key type default value description optional boolean false Whether authentication is required. By default, request will fail if the authentication cannot be verified. If set to false, request will process and this provider will abstain. outbound OutboundTarget[&#93; &#160; Add a new outbound target to configure identity propagation or explicit username/password. principal-type SubjectType (USER, SERVICE) USER Principal type this provider extracts (and also propagates). realm string helidon Set the realm to use when challenging users. users ConfigUser[&#93; &#160; Set user store to validate users. Removes any other stores added through #addUserStore(SecureUserStore). ",
            "title": "Configuration options"
        },
        {
            "location": "/se/security/providers",
            "text": " See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - http-basic-auth: realm: \"helidon\" users: - login: \"john\" password: \"${CLEAR=password}\" roles: [\"admin\"] - login: \"jack\" password: \"password\" roles: [\"user\", \"admin\"] outbound: - name: \"internal-services\" hosts: [\"*.example.org\"] # Propagates current user's identity or identity from request property outbound-token: header: \"X-Internal-Auth\" - name: \"partner-service\" hosts: [\"*.partner.org\"] # Uses this username and password username: \"partner-user-1\" password: \"${CLEAR=password}\" ",
            "title": "Example code"
        },
        {
            "location": "/se/security/providers",
            "text": " See https://tools.ietf.org/html/rfc7617 . Authentication of request When a request is received without the Authorization: basic &#8230;&#8203;. header, a challenge is returned to provide such authentication. When a request is received with the Authorization: basic &#8230;&#8203;. header, the username and password is validated against configured users (and users obtained from custom service if any provided). Subject is created based on the username and roles provided by the user store. Identity propagation When identity propagation is configured, there are several options for identifying username and password to propagate: We propagate the current username and password (inbound request must be authenticated using basic authentication). We use username and password from an explicitly configured property (See EndpointConfig.PROPERTY_OUTBOUND_ID and EndpointConfig.PROPERTY_OUTBOUND_SECRET ) We use username and password associated with an outbound target (see example configuration above) Identity is propagated only if: There is an outbound target configured for the endpoint Or there is an explicitly configured username/password for the current request (through request property) Custom user store Java service loader service io.helidon.security.providers.httpauth.spi.UserStoreService can be implemented to provide users to the provider, such as when validated against an internal database or LDAP server. The user store is defined so you never need the clear text password of the user. Warning on security of HTTP Basic Authentication (or lack thereof) Basic authentication uses base64 encoded username and password and passes it over the network. Base64 is only encoding, not encryption - so anybody that gets hold of the header value can learn the actual username and password of the user. This is a security risk and an attack vector that everybody should be aware of before using HTTP Basic Authentication. We recommend using this approach only for testing and demo purposes. ",
            "title": "How does it work?"
        },
        {
            "location": "/se/security/providers",
            "text": " HTTP Basic authentication support Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-http-auth&lt;/artifactId&gt; &lt;/dependency&gt; Overview HTTP Basic Authentication provider Type: io.helidon.security.providers.httpauth.HttpBasicAuthProvider <markup lang=\"text\" title=\"Config key\" >http-basic-auth This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthenticationProvider Configuration options Optional configuration options key type default value description optional boolean false Whether authentication is required. By default, request will fail if the authentication cannot be verified. If set to false, request will process and this provider will abstain. outbound OutboundTarget[&#93; &#160; Add a new outbound target to configure identity propagation or explicit username/password. principal-type SubjectType (USER, SERVICE) USER Principal type this provider extracts (and also propagates). realm string helidon Set the realm to use when challenging users. users ConfigUser[&#93; &#160; Set user store to validate users. Removes any other stores added through #addUserStore(SecureUserStore). Example code See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - http-basic-auth: realm: \"helidon\" users: - login: \"john\" password: \"${CLEAR=password}\" roles: [\"admin\"] - login: \"jack\" password: \"password\" roles: [\"user\", \"admin\"] outbound: - name: \"internal-services\" hosts: [\"*.example.org\"] # Propagates current user's identity or identity from request property outbound-token: header: \"X-Internal-Auth\" - name: \"partner-service\" hosts: [\"*.partner.org\"] # Uses this username and password username: \"partner-user-1\" password: \"${CLEAR=password}\" How does it work? See https://tools.ietf.org/html/rfc7617 . Authentication of request When a request is received without the Authorization: basic &#8230;&#8203;. header, a challenge is returned to provide such authentication. When a request is received with the Authorization: basic &#8230;&#8203;. header, the username and password is validated against configured users (and users obtained from custom service if any provided). Subject is created based on the username and roles provided by the user store. Identity propagation When identity propagation is configured, there are several options for identifying username and password to propagate: We propagate the current username and password (inbound request must be authenticated using basic authentication). We use username and password from an explicitly configured property (See EndpointConfig.PROPERTY_OUTBOUND_ID and EndpointConfig.PROPERTY_OUTBOUND_SECRET ) We use username and password associated with an outbound target (see example configuration above) Identity is propagated only if: There is an outbound target configured for the endpoint Or there is an explicitly configured username/password for the current request (through request property) Custom user store Java service loader service io.helidon.security.providers.httpauth.spi.UserStoreService can be implemented to provide users to the provider, such as when validated against an internal database or LDAP server. The user store is defined so you never need the clear text password of the user. Warning on security of HTTP Basic Authentication (or lack thereof) Basic authentication uses base64 encoded username and password and passes it over the network. Base64 is only encoding, not encryption - so anybody that gets hold of the header value can learn the actual username and password of the user. This is a security risk and an attack vector that everybody should be aware of before using HTTP Basic Authentication. We recommend using this approach only for testing and demo purposes. ",
            "title": "HTTP Basic Authentication Provider"
        },
        {
            "location": "/se/security/providers",
            "text": "<markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-http-auth&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Setup"
        },
        {
            "location": "/se/security/providers",
            "text": " Http digest authentication security provider Type: io.helidon.security.providers.httpauth.HttpDigestAuthProvider <markup lang=\"text\" title=\"Config key\" >http-digest-auth This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthenticationProvider ",
            "title": "Overview"
        },
        {
            "location": "/se/security/providers",
            "text": " Optional configuration options key type default value description algorithm Algorithm (MD5) MD5 Digest algorithm to use. nonce-timeout-millis long 86400000 How long will the nonce value be valid. When timed-out, browser will re-request username/password. optional boolean false Whether authentication is required. By default, request will fail if the authentication cannot be verified. If set to false, request will process and this provider will abstain. principal-type SubjectType (USER, SERVICE) USER Principal type this provider extracts (and also propagates). qop Qop (NONE, AUTH) NONE Only AUTH supported. If left empty, uses the legacy approach (older RFC version). AUTH-INT is not supported. realm string Helidon Set the realm to use when challenging users. server-secret string &#160; The nonce is encrypted using this secret - to make sure the nonce we get back was generated by us and to make sure we can safely time-out nonce values. This secret must be the same for all service instances (or all services that want to share the same authentication). Defaults to a random password - e.g. if deployed to multiple servers, the authentication WILL NOT WORK. You MUST provide your own password to work in a distributed environment with non-sticky load balancing. users ConfigUser[&#93; &#160; Set user store to obtain passwords and roles based on logins. ",
            "title": "Configuration options"
        },
        {
            "location": "/se/security/providers",
            "text": "<markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - http-digest-auth: realm: \"helidon\" server-secret: \"${CLEAR=service-wide-secret-not-known-outside}\" users: - login: \"john\" password: \"${CLEAR=password}\" roles: [\"admin\"] - login: \"jack\" password: \"password\" roles: [\"user\", \"admin\"] ",
            "title": "Example code"
        },
        {
            "location": "/se/security/providers",
            "text": " See https://tools.ietf.org/html/rfc7616 . Authentication of request When a request is received without the Authorization: digest &#8230;&#8203;. header, a challenge is returned to provide such authentication using WWW-Authenticate header. When a request is received with the Authorization: digest &#8230;&#8203;. header, the request is validated against configured users (and users obtained from custom service if any provided). Subject is created based on the username and roles provided by the user store. Custom user store Java service loader service io.helidon.security.providers.httpauth.spi.UserStoreService can be implemented to provide users to the provider, such as when validated against an internal database or LDAP server. The user store is defined so you never need the clear text password of the user. Note on security of HTTP Digest Authentication These authentication schemes should be obsolete , though they provide a very easy way to test a protected resource. ",
            "title": "How does it work?"
        },
        {
            "location": "/se/security/providers",
            "text": " HTTP Digest authentication support Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-http-auth&lt;/artifactId&gt; &lt;/dependency&gt; Overview Http digest authentication security provider Type: io.helidon.security.providers.httpauth.HttpDigestAuthProvider <markup lang=\"text\" title=\"Config key\" >http-digest-auth This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthenticationProvider Configuration options Optional configuration options key type default value description algorithm Algorithm (MD5) MD5 Digest algorithm to use. nonce-timeout-millis long 86400000 How long will the nonce value be valid. When timed-out, browser will re-request username/password. optional boolean false Whether authentication is required. By default, request will fail if the authentication cannot be verified. If set to false, request will process and this provider will abstain. principal-type SubjectType (USER, SERVICE) USER Principal type this provider extracts (and also propagates). qop Qop (NONE, AUTH) NONE Only AUTH supported. If left empty, uses the legacy approach (older RFC version). AUTH-INT is not supported. realm string Helidon Set the realm to use when challenging users. server-secret string &#160; The nonce is encrypted using this secret - to make sure the nonce we get back was generated by us and to make sure we can safely time-out nonce values. This secret must be the same for all service instances (or all services that want to share the same authentication). Defaults to a random password - e.g. if deployed to multiple servers, the authentication WILL NOT WORK. You MUST provide your own password to work in a distributed environment with non-sticky load balancing. users ConfigUser[&#93; &#160; Set user store to obtain passwords and roles based on logins. Example code <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - http-digest-auth: realm: \"helidon\" server-secret: \"${CLEAR=service-wide-secret-not-known-outside}\" users: - login: \"john\" password: \"${CLEAR=password}\" roles: [\"admin\"] - login: \"jack\" password: \"password\" roles: [\"user\", \"admin\"] How does it work? See https://tools.ietf.org/html/rfc7616 . Authentication of request When a request is received without the Authorization: digest &#8230;&#8203;. header, a challenge is returned to provide such authentication using WWW-Authenticate header. When a request is received with the Authorization: digest &#8230;&#8203;. header, the request is validated against configured users (and users obtained from custom service if any provided). Subject is created based on the username and roles provided by the user store. Custom user store Java service loader service io.helidon.security.providers.httpauth.spi.UserStoreService can be implemented to provide users to the provider, such as when validated against an internal database or LDAP server. The user store is defined so you never need the clear text password of the user. Note on security of HTTP Digest Authentication These authentication schemes should be obsolete , though they provide a very easy way to test a protected resource. ",
            "title": "HTTP Digest Authentication Provider"
        },
        {
            "location": "/se/security/providers",
            "text": "<markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-header&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Setup"
        },
        {
            "location": "/se/security/providers",
            "text": " Security provider that extracts a username (or service name) from a header. Type: io.helidon.security.providers.header.HeaderAtnProvider <markup lang=\"text\" title=\"Config key\" >header-atn This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthenticationProvider ",
            "title": "Overview"
        },
        {
            "location": "/se/security/providers",
            "text": " Optional configuration options key type default value description atn-token TokenHandler &#160; Token handler to extract username from request. authenticate boolean true Whether to authenticate requests. optional boolean false Whether authentication is required. By default, request will fail if the username cannot be extracted. If set to false, request will process and this provider will abstain. outbound OutboundTarget[&#93; &#160; Configure outbound target for identity propagation. outbound-token TokenHandler &#160; Token handler to create outbound headers to propagate identity. If not defined, #atnTokenHandler will be used. principal-type SubjectType (USER, SERVICE) USER Principal type this provider extracts (and also propagates). propagate boolean false Whether to propagate identity. ",
            "title": "Configuration options"
        },
        {
            "location": "/se/security/providers",
            "text": "<markup lang=\"yaml\" title=\"Configuration example\" >security: providers: header-atn: atn-token: header: \"X-AUTH-USER\" outbound: - name: \"internal-services\" hosts: [\"*.example.org\"] # propagates the current user or service id using the same header as authentication - name: \"partner-service\" hosts: [\"*.partner.org\"] # propagates an explicit username in a custom header username: \"service-27\" outbound-token: header: \"X-Service-Auth\" ",
            "title": "Example code"
        },
        {
            "location": "/se/security/providers",
            "text": " This provider inspects a specified request header and extracts the username/service name from it and asserts it as current subject&#8217;s principal. This can be used when we use perimeter authentication (e.g. there is a gateway that takes care of authentication and propagates the user in a header). Identity propagation Identity is propagated only if an outbound target matches the target service. The following options exist when propagating identity: 1. We propagate the current username using the configured header 2. We use username associated with an outbound target (see example configuration above) Caution When using this provider, you must be sure the header cannot be explicitly configured by a user or another service. All requests should go through a gateway that removes this header from inbound traffic, and only configures it for authenticated users/services. Another option is to use this with fully trusted parties (such as services within a single company, on a single protected network not accessible to any users), and of course for testing and demo purposes. ",
            "title": "How does it work?"
        },
        {
            "location": "/se/security/providers",
            "text": " Asserts user or service identity based on a value of a header. Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-header&lt;/artifactId&gt; &lt;/dependency&gt; Overview Security provider that extracts a username (or service name) from a header. Type: io.helidon.security.providers.header.HeaderAtnProvider <markup lang=\"text\" title=\"Config key\" >header-atn This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthenticationProvider Configuration options Optional configuration options key type default value description atn-token TokenHandler &#160; Token handler to extract username from request. authenticate boolean true Whether to authenticate requests. optional boolean false Whether authentication is required. By default, request will fail if the username cannot be extracted. If set to false, request will process and this provider will abstain. outbound OutboundTarget[&#93; &#160; Configure outbound target for identity propagation. outbound-token TokenHandler &#160; Token handler to create outbound headers to propagate identity. If not defined, #atnTokenHandler will be used. principal-type SubjectType (USER, SERVICE) USER Principal type this provider extracts (and also propagates). propagate boolean false Whether to propagate identity. Example code <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: header-atn: atn-token: header: \"X-AUTH-USER\" outbound: - name: \"internal-services\" hosts: [\"*.example.org\"] # propagates the current user or service id using the same header as authentication - name: \"partner-service\" hosts: [\"*.partner.org\"] # propagates an explicit username in a custom header username: \"service-27\" outbound-token: header: \"X-Service-Auth\" How does it work? This provider inspects a specified request header and extracts the username/service name from it and asserts it as current subject&#8217;s principal. This can be used when we use perimeter authentication (e.g. there is a gateway that takes care of authentication and propagates the user in a header). Identity propagation Identity is propagated only if an outbound target matches the target service. The following options exist when propagating identity: 1. We propagate the current username using the configured header 2. We use username associated with an outbound target (see example configuration above) Caution When using this provider, you must be sure the header cannot be explicitly configured by a user or another service. All requests should go through a gateway that removes this header from inbound traffic, and only configures it for authenticated users/services. Another option is to use this with fully trusted parties (such as services within a single company, on a single protected network not accessible to any users), and of course for testing and demo purposes. ",
            "title": "Header Authentication Provider"
        },
        {
            "location": "/se/security/providers",
            "text": "<markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-http-sign&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Setup"
        },
        {
            "location": "/se/security/providers",
            "text": " HTTP header signature provider. Type: io.helidon.security.providers.httpsign.HttpSignProvider <markup lang=\"text\" title=\"Config key\" >http-signatures This type provides the following service implementations: io.helidon.security.spi.AuthenticationProvider ",
            "title": "Overview"
        },
        {
            "location": "/se/security/providers",
            "text": " Optional configuration options key type default value description backward-compatible-eol boolean false Enable support for Helidon versions before 3.0.0 (exclusive). Until version 3.0.0 (exclusive) there was a trailing end of line added to the signed data. To be able to communicate cross versions, we must configure this when talking to older versions of Helidon. Default value is `false`. In Helidon 2.x, this switch exists as well and the default is `true`, to allow communication between versions as needed. headers HttpSignHeader[&#93; (SIGNATURE, AUTHORIZATION, CUSTOM) &#160; Add a header that is validated on inbound requests. Provider may support more than one header to validate. inbound.keys InboundClientDefinition[&#93; &#160; Add inbound configuration. This is used to validate signature and authenticate the party. The same can be done through configuration: &lt;pre&gt; { name = \"http-signatures\" class = \"HttpSignProvider\" http-signatures { inbound { # This configures the InboundClientDefinition keys: [ { key-id = \"service1\" hmac.secret = \"${CLEAR=password}\" }] } } } &lt;/pre&gt; optional boolean true Set whether the signature is optional. If set to true (default), this provider will SecurityResponse.SecurityStatus#ABSTAIN from this request if signature is not present. If set to false, this provider will SecurityResponse.SecurityStatus#FAILURE fail if signature is not present. outbound OutboundConfig &#160; Add outbound targets to this builder. The targets are used to chose what to do for outbound communication. The targets should have OutboundTargetDefinition attached through OutboundTarget.Builder#customObject(Class, Object) to tell us how to sign the request. The same can be done through configuration: &lt;pre&gt; { name = \"http-signatures\" class = \"HttpSignProvider\" http-signatures { targets: [ { name = \"service2\" hosts = [\"localhost\"] paths = [\"/service2/.*\"] # This configures the OutboundTargetDefinition signature { key-id = \"service1\" hmac.secret = \"${CLEAR=password}\" } }] } } &lt;/pre&gt; realm string helidon Realm to use for challenging inbound requests that do not have \"Authorization\" header in case header is HttpSignHeader#AUTHORIZATION and singatures are not optional. sign-headers HeadersConfig[&#93; &#160; Override the default inbound required headers (e.g. headers that MUST be signed and headers that MUST be signed IF present). Defaults: get, head, delete methods: date, (request-target), host are mandatory; authorization if present (unless we are creating/validating the HttpSignHeader#AUTHORIZATION ourselves put, post: same as above, with addition of: content-length, content-type and digest if present for other methods: date, (request-target) Note that this provider DOES NOT validate the \"Digest\" HTTP header, only the signature. ",
            "title": "Configuration options"
        },
        {
            "location": "/se/security/providers",
            "text": " See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - http-signatures: inbound: keys: - key-id: \"service1-hmac\" principal-name: \"Service1 - HMAC signature\" hmac.secret: \"${CLEAR=somePasswordForHmacShouldBeEncrypted}\" - key-id: \"service1-rsa\" principal-name: \"Service1 - RSA signature\" public-key: keystore: resource.path: \"src/main/resources/keystore.p12\" passphrase: \"password\" cert.alias: \"service_cert\" outbound: - name: \"service2-hmac\" hosts: [\"localhost\"] paths: [\"/service2\"] signature: key-id: \"service1-hmac\" hmac.secret: \"${CLEAR=somePasswordForHmacShouldBeEncrypted}\" - name: \"service2-rsa\" hosts: [\"localhost\"] paths: [\"/service2-rsa.*\"] signature: key-id: \"service1-rsa\" private-key: keystore: resource.path: \"src/main/resources/keystore.p12\" passphrase: \"password\" key.alias: \"myPrivateKey\" ",
            "title": "Example code"
        },
        {
            "location": "/se/security/providers",
            "text": " standard: based on https://tools.ietf.org/html/draft-cavage-http-signatures-03 key-id: an arbitrary string used to locate signature configuration - when a request is received the provider locates validation configuration based on this id (e.g. HMAC shared secret or RSA public key). Commonly used meanings are: key fingerprint (RSA); API Key ",
            "title": "Signature basics"
        },
        {
            "location": "/se/security/providers",
            "text": " Inbound Signatures We act as a server and another party is calling us with a signed HTTP request. We validate the signature and assume identity of the caller. Outbound Signatures We act as a client and we sign our outgoing requests. If there is a matching outbound target specified in configuration, its configuration will be applied for signing the outgoing request, otherwise there is no signature added ",
            "title": "How does it work?"
        },
        {
            "location": "/se/security/providers",
            "text": " Support for HTTP Signatures. Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-http-sign&lt;/artifactId&gt; &lt;/dependency&gt; Overview HTTP header signature provider. Type: io.helidon.security.providers.httpsign.HttpSignProvider <markup lang=\"text\" title=\"Config key\" >http-signatures This type provides the following service implementations: io.helidon.security.spi.AuthenticationProvider Configuration options Optional configuration options key type default value description backward-compatible-eol boolean false Enable support for Helidon versions before 3.0.0 (exclusive). Until version 3.0.0 (exclusive) there was a trailing end of line added to the signed data. To be able to communicate cross versions, we must configure this when talking to older versions of Helidon. Default value is `false`. In Helidon 2.x, this switch exists as well and the default is `true`, to allow communication between versions as needed. headers HttpSignHeader[&#93; (SIGNATURE, AUTHORIZATION, CUSTOM) &#160; Add a header that is validated on inbound requests. Provider may support more than one header to validate. inbound.keys InboundClientDefinition[&#93; &#160; Add inbound configuration. This is used to validate signature and authenticate the party. The same can be done through configuration: &lt;pre&gt; { name = \"http-signatures\" class = \"HttpSignProvider\" http-signatures { inbound { # This configures the InboundClientDefinition keys: [ { key-id = \"service1\" hmac.secret = \"${CLEAR=password}\" }] } } } &lt;/pre&gt; optional boolean true Set whether the signature is optional. If set to true (default), this provider will SecurityResponse.SecurityStatus#ABSTAIN from this request if signature is not present. If set to false, this provider will SecurityResponse.SecurityStatus#FAILURE fail if signature is not present. outbound OutboundConfig &#160; Add outbound targets to this builder. The targets are used to chose what to do for outbound communication. The targets should have OutboundTargetDefinition attached through OutboundTarget.Builder#customObject(Class, Object) to tell us how to sign the request. The same can be done through configuration: &lt;pre&gt; { name = \"http-signatures\" class = \"HttpSignProvider\" http-signatures { targets: [ { name = \"service2\" hosts = [\"localhost\"] paths = [\"/service2/.*\"] # This configures the OutboundTargetDefinition signature { key-id = \"service1\" hmac.secret = \"${CLEAR=password}\" } }] } } &lt;/pre&gt; realm string helidon Realm to use for challenging inbound requests that do not have \"Authorization\" header in case header is HttpSignHeader#AUTHORIZATION and singatures are not optional. sign-headers HeadersConfig[&#93; &#160; Override the default inbound required headers (e.g. headers that MUST be signed and headers that MUST be signed IF present). Defaults: get, head, delete methods: date, (request-target), host are mandatory; authorization if present (unless we are creating/validating the HttpSignHeader#AUTHORIZATION ourselves put, post: same as above, with addition of: content-length, content-type and digest if present for other methods: date, (request-target) Note that this provider DOES NOT validate the \"Digest\" HTTP header, only the signature. Example code See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - http-signatures: inbound: keys: - key-id: \"service1-hmac\" principal-name: \"Service1 - HMAC signature\" hmac.secret: \"${CLEAR=somePasswordForHmacShouldBeEncrypted}\" - key-id: \"service1-rsa\" principal-name: \"Service1 - RSA signature\" public-key: keystore: resource.path: \"src/main/resources/keystore.p12\" passphrase: \"password\" cert.alias: \"service_cert\" outbound: - name: \"service2-hmac\" hosts: [\"localhost\"] paths: [\"/service2\"] signature: key-id: \"service1-hmac\" hmac.secret: \"${CLEAR=somePasswordForHmacShouldBeEncrypted}\" - name: \"service2-rsa\" hosts: [\"localhost\"] paths: [\"/service2-rsa.*\"] signature: key-id: \"service1-rsa\" private-key: keystore: resource.path: \"src/main/resources/keystore.p12\" passphrase: \"password\" key.alias: \"myPrivateKey\" Signature basics standard: based on https://tools.ietf.org/html/draft-cavage-http-signatures-03 key-id: an arbitrary string used to locate signature configuration - when a request is received the provider locates validation configuration based on this id (e.g. HMAC shared secret or RSA public key). Commonly used meanings are: key fingerprint (RSA); API Key How does it work? Inbound Signatures We act as a server and another party is calling us with a signed HTTP request. We validate the signature and assume identity of the caller. Outbound Signatures We act as a client and we sign our outgoing requests. If there is a matching outbound target specified in configuration, its configuration will be applied for signing the outgoing request, otherwise there is no signature added ",
            "title": "HTTP Signatures Provider"
        },
        {
            "location": "/se/security/providers",
            "text": "<markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-idcs-mapper&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Setup"
        },
        {
            "location": "/se/security/providers",
            "text": " IDCS role mapping provider Type: io.helidon.security.providers.idcs.mapper.IdcsRoleMapperProvider <markup lang=\"text\" title=\"Config key\" >idcs-role-mapper This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.SubjectMappingProvider ",
            "title": "Single-tenant IDCS Role Mapper"
        },
        {
            "location": "/se/security/providers",
            "text": " Optional configuration options key type default value description cache-config EvictableCache &#160; Use explicit io.helidon.security.providers.common.EvictableCache for role caching. default-idcs-subject-type string user Configure subject type to use when requesting roles from IDCS. Can be either #IDCS_SUBJECT_TYPE_USER or #IDCS_SUBJECT_TYPE_CLIENT. Defaults to #IDCS_SUBJECT_TYPE_USER. oidc-config OidcConfig &#160; Use explicit io.helidon.security.providers.oidc.common.OidcConfig instance, e.g. when using it also for OIDC provider. subject-types SubjectType[&#93; (USER, SERVICE) USER Add a supported subject type. If none added, io.helidon.security.SubjectType#USER is used. If any added, only the ones added will be used (e.g. if you want to use both io.helidon.security.SubjectType#USER and io.helidon.security.SubjectType#SERVICE, both need to be added. ",
            "title": "Configuration options"
        },
        {
            "location": "/se/security/providers",
            "text": " Multitenant IDCS role mapping provider Type: io.helidon.security.providers.idcs.mapper.IdcsMtRoleMapperProvider <markup lang=\"text\" title=\"Config key\" >idcs-role-mapper This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.SubjectMappingProvider ",
            "title": "Multi-tenant IDCS Role Mapper"
        },
        {
            "location": "/se/security/providers",
            "text": " Optional configuration options key type default value description cache-config EvictableCache &#160; Use explicit io.helidon.security.providers.common.EvictableCache for role caching. default-idcs-subject-type string user Configure subject type to use when requesting roles from IDCS. Can be either #IDCS_SUBJECT_TYPE_USER or #IDCS_SUBJECT_TYPE_CLIENT. Defaults to #IDCS_SUBJECT_TYPE_USER. idcs-app-name-handler TokenHandler &#160; Configure token handler for IDCS Application name. By default the header IdcsMtRoleMapperProvider#IDCS_APP_HEADER is used. idcs-tenant-handler TokenHandler &#160; Configure token handler for IDCS Tenant ID. By default the header IdcsMtRoleMapperProvider#IDCS_TENANT_HEADER is used. oidc-config OidcConfig &#160; Use explicit io.helidon.security.providers.oidc.common.OidcConfig instance, e.g. when using it also for OIDC provider. subject-types SubjectType[&#93; (USER, SERVICE) USER Add a supported subject type. If none added, io.helidon.security.SubjectType#USER is used. If any added, only the ones added will be used (e.g. if you want to use both io.helidon.security.SubjectType#USER and io.helidon.security.SubjectType#SERVICE, both need to be added. ",
            "title": "Configuration options"
        },
        {
            "location": "/se/security/providers",
            "text": " See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - idcs-role-mapper: multitenant: false oidc-config: client-id: \"client-id\" client-secret: \"client-secret\" identity-uri: \"IDCS identity server address\" ",
            "title": "Example code"
        },
        {
            "location": "/se/security/providers",
            "text": " The provider asks the IDCS server to provide list of roles for the currently authenticated user. The result is cached for a certain period of time (see cache-config above). ",
            "title": "How does it work?"
        },
        {
            "location": "/se/security/providers",
            "text": " A role mapper to retrieve roles from Oracle IDCS. Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-idcs-mapper&lt;/artifactId&gt; &lt;/dependency&gt; Single-tenant IDCS Role Mapper IDCS role mapping provider Type: io.helidon.security.providers.idcs.mapper.IdcsRoleMapperProvider <markup lang=\"text\" title=\"Config key\" >idcs-role-mapper This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.SubjectMappingProvider Configuration options Optional configuration options key type default value description cache-config EvictableCache &#160; Use explicit io.helidon.security.providers.common.EvictableCache for role caching. default-idcs-subject-type string user Configure subject type to use when requesting roles from IDCS. Can be either #IDCS_SUBJECT_TYPE_USER or #IDCS_SUBJECT_TYPE_CLIENT. Defaults to #IDCS_SUBJECT_TYPE_USER. oidc-config OidcConfig &#160; Use explicit io.helidon.security.providers.oidc.common.OidcConfig instance, e.g. when using it also for OIDC provider. subject-types SubjectType[&#93; (USER, SERVICE) USER Add a supported subject type. If none added, io.helidon.security.SubjectType#USER is used. If any added, only the ones added will be used (e.g. if you want to use both io.helidon.security.SubjectType#USER and io.helidon.security.SubjectType#SERVICE, both need to be added. Multi-tenant IDCS Role Mapper Multitenant IDCS role mapping provider Type: io.helidon.security.providers.idcs.mapper.IdcsMtRoleMapperProvider <markup lang=\"text\" title=\"Config key\" >idcs-role-mapper This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.SubjectMappingProvider Configuration options Optional configuration options key type default value description cache-config EvictableCache &#160; Use explicit io.helidon.security.providers.common.EvictableCache for role caching. default-idcs-subject-type string user Configure subject type to use when requesting roles from IDCS. Can be either #IDCS_SUBJECT_TYPE_USER or #IDCS_SUBJECT_TYPE_CLIENT. Defaults to #IDCS_SUBJECT_TYPE_USER. idcs-app-name-handler TokenHandler &#160; Configure token handler for IDCS Application name. By default the header IdcsMtRoleMapperProvider#IDCS_APP_HEADER is used. idcs-tenant-handler TokenHandler &#160; Configure token handler for IDCS Tenant ID. By default the header IdcsMtRoleMapperProvider#IDCS_TENANT_HEADER is used. oidc-config OidcConfig &#160; Use explicit io.helidon.security.providers.oidc.common.OidcConfig instance, e.g. when using it also for OIDC provider. subject-types SubjectType[&#93; (USER, SERVICE) USER Add a supported subject type. If none added, io.helidon.security.SubjectType#USER is used. If any added, only the ones added will be used (e.g. if you want to use both io.helidon.security.SubjectType#USER and io.helidon.security.SubjectType#SERVICE, both need to be added. Example code See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - idcs-role-mapper: multitenant: false oidc-config: client-id: \"client-id\" client-secret: \"client-secret\" identity-uri: \"IDCS identity server address\" How does it work? The provider asks the IDCS server to provide list of roles for the currently authenticated user. The result is cached for a certain period of time (see cache-config above). ",
            "title": "IDCS Role Mapper"
        },
        {
            "location": "/se/security/providers",
            "text": "<markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-abac&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Setup"
        },
        {
            "location": "/se/security/providers",
            "text": " Attribute Based Access Control provider Type: io.helidon.security.providers.abac.AbacProvider <markup lang=\"text\" title=\"Config key\" >abac This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthorizationProvider ",
            "title": "Overview"
        },
        {
            "location": "/se/security/providers",
            "text": " Optional configuration options key type default value description fail-if-none-validated boolean true Whether to fail if NONE of the attributes is validated. fail-on-unvalidated boolean true Whether to fail if any attribute is left unvalidated. ",
            "title": "Configuration options"
        },
        {
            "location": "/se/security/providers",
            "text": " See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - abac: ",
            "title": "Example code"
        },
        {
            "location": "/se/security/providers",
            "text": " The following table shows all configuration options of the provider and their default values key default value description fail-on-unvalidated true \"Unvalidated\" means: an attribute is defined, but there is no validator available for it fail-if-none-validated true \"None validated\" means: there was not a single attribute that was validated ",
            "title": "Configuration options"
        },
        {
            "location": "/se/security/providers",
            "text": " ABAC uses available validators and validates them against attributes of the authenticated user. Combinations of fail-on-unvalidated and fail-if-none-validated : true &amp; true : Will fail if any attribute is not validated and if any has failed validation false &amp; true : Will fail if there is one or more attributes present and NONE of them is validated or if any has failed validation, Will NOT fail if there is at least one validated attribute and any number of not validated attributes (and NONE failed) false &amp; false : Will fail if there is any attribute that failed validation, Will NOT fail if there are no failed validation or if there are NONE validated Any attribute of the following objects can be used: environment (such as time of request) - e.g. env.time.year subject (user) - e.g. subject.principal.id subject (service) - e.g. service.principal.id object (must be explicitly invoked by developer in code, as object cannot be automatically added to security context) - e.g. object.owner This provider checks that all defined ABAC validators are validated. If there is a definition for a validator that is not checked, the request is denied (depending on configuration as mentioned above). ABAC provider also allows an object to be used in authorization process, such as when evaluating if an object&#8217;s owner is the current user. The following example uses the Expression language validator to demonstrate the point in a JAX-RS resource: <markup lang=\"java\" title=\"Example of using an object\" >@Authenticated @Path(\"/abac\") public class AbacResource { @GET @Authorized(explicit = true) @PolicyStatement(\"${env.time.year &gt;= 2017 &amp;&amp; object.owner == subject.principal.id}\") public Response process(@Context SecurityContext context) { // probably looked up from a database SomeResource res = new SomeResource(\"user\"); AuthorizationResponse atzResponse = context.authorize(res); if (atzResponse.isPermitted()) { //do the update return Response.ok().entity(\"fine, sir\").build(); } else { return Response.status(Response.Status.FORBIDDEN) .entity(atzResponse.description().orElse(\"Access not granted\")) .build(); } } } The following validators are implemented: Roles Scopes EL Policy ",
            "title": "How does it work?"
        },
        {
            "location": "/se/security/providers",
            "text": " When using sub-resource locators in JAX-RS, the roles allowed are collected from each \"level\" of execution: - Application class annotations - Resource class annotations + resource method annotations - Sub-resource class annotations + sub-resource method annotations - Sub-resource class annotations + sub-resource method annotations (for every sub-resource on the path) The RolesAllowed or Roles annotation to be used is the last one in the path as defined above. Example 1: There is a RolesAllowed(\"admin\") defined on a sub-resource locator resource class. In this case the required role is admin . Example 2: There is a RolesAllowed(\"admin\") defined on a sub-resource locator resource class and a RolesAllowed(\"user\") defined on the method of the sub-resource that provides the response. In this case the required role is user . ",
            "title": "Interaction with JAX-RS sub-resource locators"
        },
        {
            "location": "/se/security/providers",
            "text": " Checks whether user/service is in either of the required role(s). Configuration Key: role-validator Annotations: @RolesAllowed , @RoleValidator.Roles <markup lang=\"yaml\" title=\"Configuration example for WebServer \" >security: web-server.paths: - path: \"/user[/{*}]\" roles-allowed: [\"user\"] <markup lang=\"java\" title=\"JAX-RS example\" >@RolesAllowed(\"user\") @RoleValidator.Roles(value = \"service_role\", subjectType = SubjectType.SERVICE) @Authenticated @Path(\"/abac\") public class AbacResource { } Interaction with JAX-RS sub-resource locators When using sub-resource locators in JAX-RS, the roles allowed are collected from each \"level\" of execution: - Application class annotations - Resource class annotations + resource method annotations - Sub-resource class annotations + sub-resource method annotations - Sub-resource class annotations + sub-resource method annotations (for every sub-resource on the path) The RolesAllowed or Roles annotation to be used is the last one in the path as defined above. Example 1: There is a RolesAllowed(\"admin\") defined on a sub-resource locator resource class. In this case the required role is admin . Example 2: There is a RolesAllowed(\"admin\") defined on a sub-resource locator resource class and a RolesAllowed(\"user\") defined on the method of the sub-resource that provides the response. In this case the required role is user . ",
            "title": "Role Validator"
        },
        {
            "location": "/se/security/providers",
            "text": " Checks whether user has all the required scopes. Configuration Key: scope-validator Annotations: @Scope <markup lang=\"yaml\" title=\"Configuration example for WebServer \" >security: web-server.paths: - path: \"/user[/{*}]\" abac.scopes: [\"calendar_read\", \"calendar_edit\"] <markup lang=\"java\" title=\"JAX-RS example\" >@Scope(\"calendar_read\") @Scope(\"calendar_edit\") @Authenticated @Path(\"/abac\") public class AbacResource { } ",
            "title": "Scope Validator"
        },
        {
            "location": "/se/security/providers",
            "text": " Policy executor using Java EE policy expression language (EL) Configuration Key: policy-javax-el Annotations: @PolicyStatement Example of a policy statement: ${env.time.year &gt;= 2017} <markup lang=\"yaml\" title=\"Configuration example for WebServer \" >security: web-server.paths: - path: \"/user[/{*}]\" policy: statement: \"hasScopes('calendar_read','calendar_edit') AND timeOfDayBetween('8:15', '17:30')\" <markup lang=\"java\" title=\"JAX-RS example\" >@PolicyStatement(\"${env.time.year &gt;= 2017}\") @Authenticated @Path(\"/abac\") public class AbacResource { } ",
            "title": "Expression Language Policy Validator"
        },
        {
            "location": "/se/security/providers",
            "text": " Attribute based access control authorization provider. Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-abac&lt;/artifactId&gt; &lt;/dependency&gt; Overview Attribute Based Access Control provider Type: io.helidon.security.providers.abac.AbacProvider <markup lang=\"text\" title=\"Config key\" >abac This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthorizationProvider Configuration options Optional configuration options key type default value description fail-if-none-validated boolean true Whether to fail if NONE of the attributes is validated. fail-on-unvalidated boolean true Whether to fail if any attribute is left unvalidated. Example code See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - abac: Configuration options The following table shows all configuration options of the provider and their default values key default value description fail-on-unvalidated true \"Unvalidated\" means: an attribute is defined, but there is no validator available for it fail-if-none-validated true \"None validated\" means: there was not a single attribute that was validated How does it work? ABAC uses available validators and validates them against attributes of the authenticated user. Combinations of fail-on-unvalidated and fail-if-none-validated : true &amp; true : Will fail if any attribute is not validated and if any has failed validation false &amp; true : Will fail if there is one or more attributes present and NONE of them is validated or if any has failed validation, Will NOT fail if there is at least one validated attribute and any number of not validated attributes (and NONE failed) false &amp; false : Will fail if there is any attribute that failed validation, Will NOT fail if there are no failed validation or if there are NONE validated Any attribute of the following objects can be used: environment (such as time of request) - e.g. env.time.year subject (user) - e.g. subject.principal.id subject (service) - e.g. service.principal.id object (must be explicitly invoked by developer in code, as object cannot be automatically added to security context) - e.g. object.owner This provider checks that all defined ABAC validators are validated. If there is a definition for a validator that is not checked, the request is denied (depending on configuration as mentioned above). ABAC provider also allows an object to be used in authorization process, such as when evaluating if an object&#8217;s owner is the current user. The following example uses the Expression language validator to demonstrate the point in a JAX-RS resource: <markup lang=\"java\" title=\"Example of using an object\" >@Authenticated @Path(\"/abac\") public class AbacResource { @GET @Authorized(explicit = true) @PolicyStatement(\"${env.time.year &gt;= 2017 &amp;&amp; object.owner == subject.principal.id}\") public Response process(@Context SecurityContext context) { // probably looked up from a database SomeResource res = new SomeResource(\"user\"); AuthorizationResponse atzResponse = context.authorize(res); if (atzResponse.isPermitted()) { //do the update return Response.ok().entity(\"fine, sir\").build(); } else { return Response.status(Response.Status.FORBIDDEN) .entity(atzResponse.description().orElse(\"Access not granted\")) .build(); } } } The following validators are implemented: Roles Scopes EL Policy Role Validator Checks whether user/service is in either of the required role(s). Configuration Key: role-validator Annotations: @RolesAllowed , @RoleValidator.Roles <markup lang=\"yaml\" title=\"Configuration example for WebServer \" >security: web-server.paths: - path: \"/user[/{*}]\" roles-allowed: [\"user\"] <markup lang=\"java\" title=\"JAX-RS example\" >@RolesAllowed(\"user\") @RoleValidator.Roles(value = \"service_role\", subjectType = SubjectType.SERVICE) @Authenticated @Path(\"/abac\") public class AbacResource { } Interaction with JAX-RS sub-resource locators When using sub-resource locators in JAX-RS, the roles allowed are collected from each \"level\" of execution: - Application class annotations - Resource class annotations + resource method annotations - Sub-resource class annotations + sub-resource method annotations - Sub-resource class annotations + sub-resource method annotations (for every sub-resource on the path) The RolesAllowed or Roles annotation to be used is the last one in the path as defined above. Example 1: There is a RolesAllowed(\"admin\") defined on a sub-resource locator resource class. In this case the required role is admin . Example 2: There is a RolesAllowed(\"admin\") defined on a sub-resource locator resource class and a RolesAllowed(\"user\") defined on the method of the sub-resource that provides the response. In this case the required role is user . Scope Validator Checks whether user has all the required scopes. Configuration Key: scope-validator Annotations: @Scope <markup lang=\"yaml\" title=\"Configuration example for WebServer \" >security: web-server.paths: - path: \"/user[/{*}]\" abac.scopes: [\"calendar_read\", \"calendar_edit\"] <markup lang=\"java\" title=\"JAX-RS example\" >@Scope(\"calendar_read\") @Scope(\"calendar_edit\") @Authenticated @Path(\"/abac\") public class AbacResource { } Expression Language Policy Validator Policy executor using Java EE policy expression language (EL) Configuration Key: policy-javax-el Annotations: @PolicyStatement Example of a policy statement: ${env.time.year &gt;= 2017} <markup lang=\"yaml\" title=\"Configuration example for WebServer \" >security: web-server.paths: - path: \"/user[/{*}]\" policy: statement: \"hasScopes('calendar_read','calendar_edit') AND timeOfDayBetween('8:15', '17:30')\" <markup lang=\"java\" title=\"JAX-RS example\" >@PolicyStatement(\"${env.time.year &gt;= 2017}\") @Authenticated @Path(\"/abac\") public class AbacResource { } ",
            "title": "ABAC Provider"
        },
        {
            "location": "/se/security/providers",
            "text": "<markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-google-login&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Setup"
        },
        {
            "location": "/se/security/providers",
            "text": " Google Authentication provider Type: io.helidon.security.providers.google.login.GoogleTokenProvider <markup lang=\"text\" title=\"Config key\" >google-login This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthenticationProvider ",
            "title": "Overview"
        },
        {
            "location": "/se/security/providers",
            "text": " Optional configuration options key type default value description client-id string &#160; Google application client id, to validate that the token was generated by Google for us. optional boolean false If set to true, this provider will return io.helidon.security.SecurityResponse.SecurityStatus#ABSTAIN instead of failing in case of invalid request. outbound OutboundConfig &#160; Outbound configuration - a set of outbound targets that will have the token propagated. proxy-host string &#160; Set proxy host when talking to Google. proxy-port int 80 Set proxy port when talking to Google. realm string helidon Set the authentication realm to build challenge, defaults to \"helidon\". token TokenHandler &#x60;Authorization&#x60; header with &#x60;bearer&#x60; prefix Token provider to extract Google access token from request, defaults to \"Authorization\" header with a \"bearer \" prefix. ",
            "title": "Configuration options"
        },
        {
            "location": "/se/security/providers",
            "text": " See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - provider: client-id: \"Google client id\" ",
            "title": "Example code"
        },
        {
            "location": "/se/security/providers",
            "text": " We expect to receive a token (with sufficient scopes) from the inbound request, such as when using the Google login button on a page. The page has access to the token in javascript and can send it to backend with every request in a header field ( Authorization with `bearer ` prefix is assumed by default). Once we receive the token in Helidon, we parse it and: Validate if it timed out locally Return a cached response (see EvictableCache with default values) Otherwise verify using Google API - GoogleIdTokenVerifier We build a subject from the Google token with the following attributes filled (if in token): userId email name emailVerified locale family_name given_name picture (URL) Outbound security The token will be propagated to outbound calls if an outbound target exists that matches the invoked endpoint (see outbound configuration above). ",
            "title": "How does it work?"
        },
        {
            "location": "/se/security/providers",
            "text": " Authenticates a token from request against Google identity provider Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-google-login&lt;/artifactId&gt; &lt;/dependency&gt; Overview Google Authentication provider Type: io.helidon.security.providers.google.login.GoogleTokenProvider <markup lang=\"text\" title=\"Config key\" >google-login This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthenticationProvider Configuration options Optional configuration options key type default value description client-id string &#160; Google application client id, to validate that the token was generated by Google for us. optional boolean false If set to true, this provider will return io.helidon.security.SecurityResponse.SecurityStatus#ABSTAIN instead of failing in case of invalid request. outbound OutboundConfig &#160; Outbound configuration - a set of outbound targets that will have the token propagated. proxy-host string &#160; Set proxy host when talking to Google. proxy-port int 80 Set proxy port when talking to Google. realm string helidon Set the authentication realm to build challenge, defaults to \"helidon\". token TokenHandler &#x60;Authorization&#x60; header with &#x60;bearer&#x60; prefix Token provider to extract Google access token from request, defaults to \"Authorization\" header with a \"bearer \" prefix. Example code See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - provider: client-id: \"Google client id\" How does it work? We expect to receive a token (with sufficient scopes) from the inbound request, such as when using the Google login button on a page. The page has access to the token in javascript and can send it to backend with every request in a header field ( Authorization with `bearer ` prefix is assumed by default). Once we receive the token in Helidon, we parse it and: Validate if it timed out locally Return a cached response (see EvictableCache with default values) Otherwise verify using Google API - GoogleIdTokenVerifier We build a subject from the Google token with the following attributes filled (if in token): userId email name emailVerified locale family_name given_name picture (URL) Outbound security The token will be propagated to outbound calls if an outbound target exists that matches the invoked endpoint (see outbound configuration above). ",
            "title": "Google Login Provider"
        },
        {
            "location": "/se/security/providers",
            "text": "<markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-jwt&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Setup"
        },
        {
            "location": "/se/security/providers",
            "text": " JWT authentication provider Type: io.helidon.security.providers.jwt.JwtProvider <markup lang=\"text\" title=\"Config key\" >jwt This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthenticationProvider ",
            "title": "Overview"
        },
        {
            "location": "/se/security/providers",
            "text": " Optional configuration options key type default value description allow-impersonation boolean false Whether to allow impersonation by explicitly overriding username from outbound requests using io.helidon.security.EndpointConfig#PROPERTY_OUTBOUND_ID property. By default this is not allowed and identity can only be propagated. allow-unsigned boolean false Configure support for unsigned JWT. If this is set to true any JWT that has algorithm set to none and no kid defined will be accepted. Note that this has serious security impact - if JWT can be sent from a third party, this allows the third party to send ANY JWT and it would be accpted as valid. atn-token.handler TokenHandler &#160; Token handler to extract username from request. atn-token.jwk.resource Resource &#160; JWK resource used to verify JWTs created by other parties. atn-token.jwt-audience string &#160; Audience expected in inbound JWTs. atn-token.verify-signature boolean true Configure whether to verify signatures. Signatures verification is enabled by default. You can configure the provider not to verify signatures. &lt;b&gt;Make sure your service is properly secured on network level and only accessible from a secure endpoint that provides the JWTs when signature verification is disabled. If signature verification is disabled, this service will accept &lt;i&gt;ANY&lt;/i&gt; JWT&lt;/b&gt; authenticate boolean true Whether to authenticate requests. optional boolean false Whether authentication is required. By default, request will fail if the username cannot be extracted. If set to false, request will process and this provider will abstain. principal-type SubjectType (USER, SERVICE) USER Principal type this provider extracts (and also propagates). propagate boolean true Whether to propagate identity. sign-token OutboundConfig &#160; Configuration of outbound rules. sign-token.jwk.resource Resource &#160; JWK resource used to sign JWTs created by us. sign-token.jwt-issuer string &#160; Issuer used to create new JWTs. use-jwt-groups boolean true Claim groups from JWT will be used to automatically add groups to current subject (may be used with jakarta.annotation.security.RolesAllowed annotation). ",
            "title": "Configuration options"
        },
        {
            "location": "/se/security/providers",
            "text": " See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - provider: atn-token: jwk.resource.resource-path: \"verifying-jwk.json\" jwt-audience: \"http://my.service\" sign-token: jwk.resource.resource-path: \"signing-jwk.json\" jwt-issuer: \"http://my.server/identity\" outbound: - name: \"propagate-token\" hosts: [\"*.internal.org\"] - name: \"generate-token\" hosts: [\"1.partner-service\"] jwk-kid: \"partner-1\" jwt-kid: \"helidon\" jwt-audience: \"http://1.partner-service\" ",
            "title": "Example code"
        },
        {
            "location": "/se/security/providers",
            "text": " JSON Web Token (JWT) provider has support for authentication and outbound security. Authentication is based on validating the token (signature, valid before etc.) and on asserting the subject of the JWT subject claim. For outbound, we support either token propagation (e.g. the token from request is propagated further) or support for generating a brand new token based on configuration of this provider. ",
            "title": "How does it work?"
        },
        {
            "location": "/se/security/providers",
            "text": " JWT token authentication and outbound security provider. Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-jwt&lt;/artifactId&gt; &lt;/dependency&gt; Overview JWT authentication provider Type: io.helidon.security.providers.jwt.JwtProvider <markup lang=\"text\" title=\"Config key\" >jwt This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthenticationProvider Configuration options Optional configuration options key type default value description allow-impersonation boolean false Whether to allow impersonation by explicitly overriding username from outbound requests using io.helidon.security.EndpointConfig#PROPERTY_OUTBOUND_ID property. By default this is not allowed and identity can only be propagated. allow-unsigned boolean false Configure support for unsigned JWT. If this is set to true any JWT that has algorithm set to none and no kid defined will be accepted. Note that this has serious security impact - if JWT can be sent from a third party, this allows the third party to send ANY JWT and it would be accpted as valid. atn-token.handler TokenHandler &#160; Token handler to extract username from request. atn-token.jwk.resource Resource &#160; JWK resource used to verify JWTs created by other parties. atn-token.jwt-audience string &#160; Audience expected in inbound JWTs. atn-token.verify-signature boolean true Configure whether to verify signatures. Signatures verification is enabled by default. You can configure the provider not to verify signatures. &lt;b&gt;Make sure your service is properly secured on network level and only accessible from a secure endpoint that provides the JWTs when signature verification is disabled. If signature verification is disabled, this service will accept &lt;i&gt;ANY&lt;/i&gt; JWT&lt;/b&gt; authenticate boolean true Whether to authenticate requests. optional boolean false Whether authentication is required. By default, request will fail if the username cannot be extracted. If set to false, request will process and this provider will abstain. principal-type SubjectType (USER, SERVICE) USER Principal type this provider extracts (and also propagates). propagate boolean true Whether to propagate identity. sign-token OutboundConfig &#160; Configuration of outbound rules. sign-token.jwk.resource Resource &#160; JWK resource used to sign JWTs created by us. sign-token.jwt-issuer string &#160; Issuer used to create new JWTs. use-jwt-groups boolean true Claim groups from JWT will be used to automatically add groups to current subject (may be used with jakarta.annotation.security.RolesAllowed annotation). Example code See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - provider: atn-token: jwk.resource.resource-path: \"verifying-jwk.json\" jwt-audience: \"http://my.service\" sign-token: jwk.resource.resource-path: \"signing-jwk.json\" jwt-issuer: \"http://my.server/identity\" outbound: - name: \"propagate-token\" hosts: [\"*.internal.org\"] - name: \"generate-token\" hosts: [\"1.partner-service\"] jwk-kid: \"partner-1\" jwt-kid: \"helidon\" jwt-audience: \"http://1.partner-service\" How does it work? JSON Web Token (JWT) provider has support for authentication and outbound security. Authentication is based on validating the token (signature, valid before etc.) and on asserting the subject of the JWT subject claim. For outbound, we support either token propagation (e.g. the token from request is propagated further) or support for generating a brand new token based on configuration of this provider. ",
            "title": "JWT Provider"
        },
        {
            "location": "/se/security/providers",
            "text": " As an experimental feature, you can set up cross-origin handling for the redirect and logout endpoints in an optional cors block inside the oidc configuration. The table below lists the configuration keys that identify the CORS characteristics. include::[tag=cors-config-table] The following example of basic cross-origin configuration, when loaded and used by the application, limits cross-origin resource sharing for PUT and DELETE operations to only foo.com and there.com : <markup lang=\"yaml\" >restrictive-cors: allow-origins: [\"http://foo.com\", \"http://there.com\"] allow-methods: [\"PUT\", \"DELETE\"] HTTP Basic Authentication Provider HTTP Basic authentication support Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-http-auth&lt;/artifactId&gt; &lt;/dependency&gt; Overview HTTP Basic Authentication provider Type: io.helidon.security.providers.httpauth.HttpBasicAuthProvider <markup lang=\"text\" title=\"Config key\" >http-basic-auth This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthenticationProvider Configuration options Optional configuration options key type default value description optional boolean false Whether authentication is required. By default, request will fail if the authentication cannot be verified. If set to false, request will process and this provider will abstain. outbound OutboundTarget[&#93; &#160; Add a new outbound target to configure identity propagation or explicit username/password. principal-type SubjectType (USER, SERVICE) USER Principal type this provider extracts (and also propagates). realm string helidon Set the realm to use when challenging users. users ConfigUser[&#93; &#160; Set user store to validate users. Removes any other stores added through #addUserStore(SecureUserStore). Example code See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - http-basic-auth: realm: \"helidon\" users: - login: \"john\" password: \"${CLEAR=password}\" roles: [\"admin\"] - login: \"jack\" password: \"password\" roles: [\"user\", \"admin\"] outbound: - name: \"internal-services\" hosts: [\"*.example.org\"] # Propagates current user's identity or identity from request property outbound-token: header: \"X-Internal-Auth\" - name: \"partner-service\" hosts: [\"*.partner.org\"] # Uses this username and password username: \"partner-user-1\" password: \"${CLEAR=password}\" How does it work? See https://tools.ietf.org/html/rfc7617 . Authentication of request When a request is received without the Authorization: basic &#8230;&#8203;. header, a challenge is returned to provide such authentication. When a request is received with the Authorization: basic &#8230;&#8203;. header, the username and password is validated against configured users (and users obtained from custom service if any provided). Subject is created based on the username and roles provided by the user store. Identity propagation When identity propagation is configured, there are several options for identifying username and password to propagate: We propagate the current username and password (inbound request must be authenticated using basic authentication). We use username and password from an explicitly configured property (See EndpointConfig.PROPERTY_OUTBOUND_ID and EndpointConfig.PROPERTY_OUTBOUND_SECRET ) We use username and password associated with an outbound target (see example configuration above) Identity is propagated only if: There is an outbound target configured for the endpoint Or there is an explicitly configured username/password for the current request (through request property) Custom user store Java service loader service io.helidon.security.providers.httpauth.spi.UserStoreService can be implemented to provide users to the provider, such as when validated against an internal database or LDAP server. The user store is defined so you never need the clear text password of the user. Warning on security of HTTP Basic Authentication (or lack thereof) Basic authentication uses base64 encoded username and password and passes it over the network. Base64 is only encoding, not encryption - so anybody that gets hold of the header value can learn the actual username and password of the user. This is a security risk and an attack vector that everybody should be aware of before using HTTP Basic Authentication. We recommend using this approach only for testing and demo purposes. HTTP Digest Authentication Provider HTTP Digest authentication support Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-http-auth&lt;/artifactId&gt; &lt;/dependency&gt; Overview Http digest authentication security provider Type: io.helidon.security.providers.httpauth.HttpDigestAuthProvider <markup lang=\"text\" title=\"Config key\" >http-digest-auth This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthenticationProvider Configuration options Optional configuration options key type default value description algorithm Algorithm (MD5) MD5 Digest algorithm to use. nonce-timeout-millis long 86400000 How long will the nonce value be valid. When timed-out, browser will re-request username/password. optional boolean false Whether authentication is required. By default, request will fail if the authentication cannot be verified. If set to false, request will process and this provider will abstain. principal-type SubjectType (USER, SERVICE) USER Principal type this provider extracts (and also propagates). qop Qop (NONE, AUTH) NONE Only AUTH supported. If left empty, uses the legacy approach (older RFC version). AUTH-INT is not supported. realm string Helidon Set the realm to use when challenging users. server-secret string &#160; The nonce is encrypted using this secret - to make sure the nonce we get back was generated by us and to make sure we can safely time-out nonce values. This secret must be the same for all service instances (or all services that want to share the same authentication). Defaults to a random password - e.g. if deployed to multiple servers, the authentication WILL NOT WORK. You MUST provide your own password to work in a distributed environment with non-sticky load balancing. users ConfigUser[&#93; &#160; Set user store to obtain passwords and roles based on logins. Example code <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - http-digest-auth: realm: \"helidon\" server-secret: \"${CLEAR=service-wide-secret-not-known-outside}\" users: - login: \"john\" password: \"${CLEAR=password}\" roles: [\"admin\"] - login: \"jack\" password: \"password\" roles: [\"user\", \"admin\"] How does it work? See https://tools.ietf.org/html/rfc7616 . Authentication of request When a request is received without the Authorization: digest &#8230;&#8203;. header, a challenge is returned to provide such authentication using WWW-Authenticate header. When a request is received with the Authorization: digest &#8230;&#8203;. header, the request is validated against configured users (and users obtained from custom service if any provided). Subject is created based on the username and roles provided by the user store. Custom user store Java service loader service io.helidon.security.providers.httpauth.spi.UserStoreService can be implemented to provide users to the provider, such as when validated against an internal database or LDAP server. The user store is defined so you never need the clear text password of the user. Note on security of HTTP Digest Authentication These authentication schemes should be obsolete , though they provide a very easy way to test a protected resource. Header Authentication Provider Asserts user or service identity based on a value of a header. Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-header&lt;/artifactId&gt; &lt;/dependency&gt; Overview Security provider that extracts a username (or service name) from a header. Type: io.helidon.security.providers.header.HeaderAtnProvider <markup lang=\"text\" title=\"Config key\" >header-atn This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthenticationProvider Configuration options Optional configuration options key type default value description atn-token TokenHandler &#160; Token handler to extract username from request. authenticate boolean true Whether to authenticate requests. optional boolean false Whether authentication is required. By default, request will fail if the username cannot be extracted. If set to false, request will process and this provider will abstain. outbound OutboundTarget[&#93; &#160; Configure outbound target for identity propagation. outbound-token TokenHandler &#160; Token handler to create outbound headers to propagate identity. If not defined, #atnTokenHandler will be used. principal-type SubjectType (USER, SERVICE) USER Principal type this provider extracts (and also propagates). propagate boolean false Whether to propagate identity. Example code <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: header-atn: atn-token: header: \"X-AUTH-USER\" outbound: - name: \"internal-services\" hosts: [\"*.example.org\"] # propagates the current user or service id using the same header as authentication - name: \"partner-service\" hosts: [\"*.partner.org\"] # propagates an explicit username in a custom header username: \"service-27\" outbound-token: header: \"X-Service-Auth\" How does it work? This provider inspects a specified request header and extracts the username/service name from it and asserts it as current subject&#8217;s principal. This can be used when we use perimeter authentication (e.g. there is a gateway that takes care of authentication and propagates the user in a header). Identity propagation Identity is propagated only if an outbound target matches the target service. The following options exist when propagating identity: 1. We propagate the current username using the configured header 2. We use username associated with an outbound target (see example configuration above) Caution When using this provider, you must be sure the header cannot be explicitly configured by a user or another service. All requests should go through a gateway that removes this header from inbound traffic, and only configures it for authenticated users/services. Another option is to use this with fully trusted parties (such as services within a single company, on a single protected network not accessible to any users), and of course for testing and demo purposes. HTTP Signatures Provider Support for HTTP Signatures. Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-http-sign&lt;/artifactId&gt; &lt;/dependency&gt; Overview HTTP header signature provider. Type: io.helidon.security.providers.httpsign.HttpSignProvider <markup lang=\"text\" title=\"Config key\" >http-signatures This type provides the following service implementations: io.helidon.security.spi.AuthenticationProvider Configuration options Optional configuration options key type default value description backward-compatible-eol boolean false Enable support for Helidon versions before 3.0.0 (exclusive). Until version 3.0.0 (exclusive) there was a trailing end of line added to the signed data. To be able to communicate cross versions, we must configure this when talking to older versions of Helidon. Default value is `false`. In Helidon 2.x, this switch exists as well and the default is `true`, to allow communication between versions as needed. headers HttpSignHeader[&#93; (SIGNATURE, AUTHORIZATION, CUSTOM) &#160; Add a header that is validated on inbound requests. Provider may support more than one header to validate. inbound.keys InboundClientDefinition[&#93; &#160; Add inbound configuration. This is used to validate signature and authenticate the party. The same can be done through configuration: &lt;pre&gt; { name = \"http-signatures\" class = \"HttpSignProvider\" http-signatures { inbound { # This configures the InboundClientDefinition keys: [ { key-id = \"service1\" hmac.secret = \"${CLEAR=password}\" }] } } } &lt;/pre&gt; optional boolean true Set whether the signature is optional. If set to true (default), this provider will SecurityResponse.SecurityStatus#ABSTAIN from this request if signature is not present. If set to false, this provider will SecurityResponse.SecurityStatus#FAILURE fail if signature is not present. outbound OutboundConfig &#160; Add outbound targets to this builder. The targets are used to chose what to do for outbound communication. The targets should have OutboundTargetDefinition attached through OutboundTarget.Builder#customObject(Class, Object) to tell us how to sign the request. The same can be done through configuration: &lt;pre&gt; { name = \"http-signatures\" class = \"HttpSignProvider\" http-signatures { targets: [ { name = \"service2\" hosts = [\"localhost\"] paths = [\"/service2/.*\"] # This configures the OutboundTargetDefinition signature { key-id = \"service1\" hmac.secret = \"${CLEAR=password}\" } }] } } &lt;/pre&gt; realm string helidon Realm to use for challenging inbound requests that do not have \"Authorization\" header in case header is HttpSignHeader#AUTHORIZATION and singatures are not optional. sign-headers HeadersConfig[&#93; &#160; Override the default inbound required headers (e.g. headers that MUST be signed and headers that MUST be signed IF present). Defaults: get, head, delete methods: date, (request-target), host are mandatory; authorization if present (unless we are creating/validating the HttpSignHeader#AUTHORIZATION ourselves put, post: same as above, with addition of: content-length, content-type and digest if present for other methods: date, (request-target) Note that this provider DOES NOT validate the \"Digest\" HTTP header, only the signature. Example code See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - http-signatures: inbound: keys: - key-id: \"service1-hmac\" principal-name: \"Service1 - HMAC signature\" hmac.secret: \"${CLEAR=somePasswordForHmacShouldBeEncrypted}\" - key-id: \"service1-rsa\" principal-name: \"Service1 - RSA signature\" public-key: keystore: resource.path: \"src/main/resources/keystore.p12\" passphrase: \"password\" cert.alias: \"service_cert\" outbound: - name: \"service2-hmac\" hosts: [\"localhost\"] paths: [\"/service2\"] signature: key-id: \"service1-hmac\" hmac.secret: \"${CLEAR=somePasswordForHmacShouldBeEncrypted}\" - name: \"service2-rsa\" hosts: [\"localhost\"] paths: [\"/service2-rsa.*\"] signature: key-id: \"service1-rsa\" private-key: keystore: resource.path: \"src/main/resources/keystore.p12\" passphrase: \"password\" key.alias: \"myPrivateKey\" Signature basics standard: based on https://tools.ietf.org/html/draft-cavage-http-signatures-03 key-id: an arbitrary string used to locate signature configuration - when a request is received the provider locates validation configuration based on this id (e.g. HMAC shared secret or RSA public key). Commonly used meanings are: key fingerprint (RSA); API Key How does it work? Inbound Signatures We act as a server and another party is calling us with a signed HTTP request. We validate the signature and assume identity of the caller. Outbound Signatures We act as a client and we sign our outgoing requests. If there is a matching outbound target specified in configuration, its configuration will be applied for signing the outgoing request, otherwise there is no signature added IDCS Role Mapper A role mapper to retrieve roles from Oracle IDCS. Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-idcs-mapper&lt;/artifactId&gt; &lt;/dependency&gt; Single-tenant IDCS Role Mapper IDCS role mapping provider Type: io.helidon.security.providers.idcs.mapper.IdcsRoleMapperProvider <markup lang=\"text\" title=\"Config key\" >idcs-role-mapper This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.SubjectMappingProvider Configuration options Optional configuration options key type default value description cache-config EvictableCache &#160; Use explicit io.helidon.security.providers.common.EvictableCache for role caching. default-idcs-subject-type string user Configure subject type to use when requesting roles from IDCS. Can be either #IDCS_SUBJECT_TYPE_USER or #IDCS_SUBJECT_TYPE_CLIENT. Defaults to #IDCS_SUBJECT_TYPE_USER. oidc-config OidcConfig &#160; Use explicit io.helidon.security.providers.oidc.common.OidcConfig instance, e.g. when using it also for OIDC provider. subject-types SubjectType[&#93; (USER, SERVICE) USER Add a supported subject type. If none added, io.helidon.security.SubjectType#USER is used. If any added, only the ones added will be used (e.g. if you want to use both io.helidon.security.SubjectType#USER and io.helidon.security.SubjectType#SERVICE, both need to be added. Multi-tenant IDCS Role Mapper Multitenant IDCS role mapping provider Type: io.helidon.security.providers.idcs.mapper.IdcsMtRoleMapperProvider <markup lang=\"text\" title=\"Config key\" >idcs-role-mapper This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.SubjectMappingProvider Configuration options Optional configuration options key type default value description cache-config EvictableCache &#160; Use explicit io.helidon.security.providers.common.EvictableCache for role caching. default-idcs-subject-type string user Configure subject type to use when requesting roles from IDCS. Can be either #IDCS_SUBJECT_TYPE_USER or #IDCS_SUBJECT_TYPE_CLIENT. Defaults to #IDCS_SUBJECT_TYPE_USER. idcs-app-name-handler TokenHandler &#160; Configure token handler for IDCS Application name. By default the header IdcsMtRoleMapperProvider#IDCS_APP_HEADER is used. idcs-tenant-handler TokenHandler &#160; Configure token handler for IDCS Tenant ID. By default the header IdcsMtRoleMapperProvider#IDCS_TENANT_HEADER is used. oidc-config OidcConfig &#160; Use explicit io.helidon.security.providers.oidc.common.OidcConfig instance, e.g. when using it also for OIDC provider. subject-types SubjectType[&#93; (USER, SERVICE) USER Add a supported subject type. If none added, io.helidon.security.SubjectType#USER is used. If any added, only the ones added will be used (e.g. if you want to use both io.helidon.security.SubjectType#USER and io.helidon.security.SubjectType#SERVICE, both need to be added. Example code See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - idcs-role-mapper: multitenant: false oidc-config: client-id: \"client-id\" client-secret: \"client-secret\" identity-uri: \"IDCS identity server address\" How does it work? The provider asks the IDCS server to provide list of roles for the currently authenticated user. The result is cached for a certain period of time (see cache-config above). ABAC Provider Attribute based access control authorization provider. Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-abac&lt;/artifactId&gt; &lt;/dependency&gt; Overview Attribute Based Access Control provider Type: io.helidon.security.providers.abac.AbacProvider <markup lang=\"text\" title=\"Config key\" >abac This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthorizationProvider Configuration options Optional configuration options key type default value description fail-if-none-validated boolean true Whether to fail if NONE of the attributes is validated. fail-on-unvalidated boolean true Whether to fail if any attribute is left unvalidated. Example code See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - abac: Configuration options The following table shows all configuration options of the provider and their default values key default value description fail-on-unvalidated true \"Unvalidated\" means: an attribute is defined, but there is no validator available for it fail-if-none-validated true \"None validated\" means: there was not a single attribute that was validated How does it work? ABAC uses available validators and validates them against attributes of the authenticated user. Combinations of fail-on-unvalidated and fail-if-none-validated : true &amp; true : Will fail if any attribute is not validated and if any has failed validation false &amp; true : Will fail if there is one or more attributes present and NONE of them is validated or if any has failed validation, Will NOT fail if there is at least one validated attribute and any number of not validated attributes (and NONE failed) false &amp; false : Will fail if there is any attribute that failed validation, Will NOT fail if there are no failed validation or if there are NONE validated Any attribute of the following objects can be used: environment (such as time of request) - e.g. env.time.year subject (user) - e.g. subject.principal.id subject (service) - e.g. service.principal.id object (must be explicitly invoked by developer in code, as object cannot be automatically added to security context) - e.g. object.owner This provider checks that all defined ABAC validators are validated. If there is a definition for a validator that is not checked, the request is denied (depending on configuration as mentioned above). ABAC provider also allows an object to be used in authorization process, such as when evaluating if an object&#8217;s owner is the current user. The following example uses the Expression language validator to demonstrate the point in a JAX-RS resource: <markup lang=\"java\" title=\"Example of using an object\" >@Authenticated @Path(\"/abac\") public class AbacResource { @GET @Authorized(explicit = true) @PolicyStatement(\"${env.time.year &gt;= 2017 &amp;&amp; object.owner == subject.principal.id}\") public Response process(@Context SecurityContext context) { // probably looked up from a database SomeResource res = new SomeResource(\"user\"); AuthorizationResponse atzResponse = context.authorize(res); if (atzResponse.isPermitted()) { //do the update return Response.ok().entity(\"fine, sir\").build(); } else { return Response.status(Response.Status.FORBIDDEN) .entity(atzResponse.description().orElse(\"Access not granted\")) .build(); } } } The following validators are implemented: Roles Scopes EL Policy Role Validator Checks whether user/service is in either of the required role(s). Configuration Key: role-validator Annotations: @RolesAllowed , @RoleValidator.Roles <markup lang=\"yaml\" title=\"Configuration example for WebServer \" >security: web-server.paths: - path: \"/user[/{*}]\" roles-allowed: [\"user\"] <markup lang=\"java\" title=\"JAX-RS example\" >@RolesAllowed(\"user\") @RoleValidator.Roles(value = \"service_role\", subjectType = SubjectType.SERVICE) @Authenticated @Path(\"/abac\") public class AbacResource { } Interaction with JAX-RS sub-resource locators When using sub-resource locators in JAX-RS, the roles allowed are collected from each \"level\" of execution: - Application class annotations - Resource class annotations + resource method annotations - Sub-resource class annotations + sub-resource method annotations - Sub-resource class annotations + sub-resource method annotations (for every sub-resource on the path) The RolesAllowed or Roles annotation to be used is the last one in the path as defined above. Example 1: There is a RolesAllowed(\"admin\") defined on a sub-resource locator resource class. In this case the required role is admin . Example 2: There is a RolesAllowed(\"admin\") defined on a sub-resource locator resource class and a RolesAllowed(\"user\") defined on the method of the sub-resource that provides the response. In this case the required role is user . Scope Validator Checks whether user has all the required scopes. Configuration Key: scope-validator Annotations: @Scope <markup lang=\"yaml\" title=\"Configuration example for WebServer \" >security: web-server.paths: - path: \"/user[/{*}]\" abac.scopes: [\"calendar_read\", \"calendar_edit\"] <markup lang=\"java\" title=\"JAX-RS example\" >@Scope(\"calendar_read\") @Scope(\"calendar_edit\") @Authenticated @Path(\"/abac\") public class AbacResource { } Expression Language Policy Validator Policy executor using Java EE policy expression language (EL) Configuration Key: policy-javax-el Annotations: @PolicyStatement Example of a policy statement: ${env.time.year &gt;= 2017} <markup lang=\"yaml\" title=\"Configuration example for WebServer \" >security: web-server.paths: - path: \"/user[/{*}]\" policy: statement: \"hasScopes('calendar_read','calendar_edit') AND timeOfDayBetween('8:15', '17:30')\" <markup lang=\"java\" title=\"JAX-RS example\" >@PolicyStatement(\"${env.time.year &gt;= 2017}\") @Authenticated @Path(\"/abac\") public class AbacResource { } Google Login Provider Authenticates a token from request against Google identity provider Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-google-login&lt;/artifactId&gt; &lt;/dependency&gt; Overview Google Authentication provider Type: io.helidon.security.providers.google.login.GoogleTokenProvider <markup lang=\"text\" title=\"Config key\" >google-login This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthenticationProvider Configuration options Optional configuration options key type default value description client-id string &#160; Google application client id, to validate that the token was generated by Google for us. optional boolean false If set to true, this provider will return io.helidon.security.SecurityResponse.SecurityStatus#ABSTAIN instead of failing in case of invalid request. outbound OutboundConfig &#160; Outbound configuration - a set of outbound targets that will have the token propagated. proxy-host string &#160; Set proxy host when talking to Google. proxy-port int 80 Set proxy port when talking to Google. realm string helidon Set the authentication realm to build challenge, defaults to \"helidon\". token TokenHandler &#x60;Authorization&#x60; header with &#x60;bearer&#x60; prefix Token provider to extract Google access token from request, defaults to \"Authorization\" header with a \"bearer \" prefix. Example code See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - provider: client-id: \"Google client id\" How does it work? We expect to receive a token (with sufficient scopes) from the inbound request, such as when using the Google login button on a page. The page has access to the token in javascript and can send it to backend with every request in a header field ( Authorization with `bearer ` prefix is assumed by default). Once we receive the token in Helidon, we parse it and: Validate if it timed out locally Return a cached response (see EvictableCache with default values) Otherwise verify using Google API - GoogleIdTokenVerifier We build a subject from the Google token with the following attributes filled (if in token): userId email name emailVerified locale family_name given_name picture (URL) Outbound security The token will be propagated to outbound calls if an outbound target exists that matches the invoked endpoint (see outbound configuration above). JWT Provider JWT token authentication and outbound security provider. Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-jwt&lt;/artifactId&gt; &lt;/dependency&gt; Overview JWT authentication provider Type: io.helidon.security.providers.jwt.JwtProvider <markup lang=\"text\" title=\"Config key\" >jwt This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthenticationProvider Configuration options Optional configuration options key type default value description allow-impersonation boolean false Whether to allow impersonation by explicitly overriding username from outbound requests using io.helidon.security.EndpointConfig#PROPERTY_OUTBOUND_ID property. By default this is not allowed and identity can only be propagated. allow-unsigned boolean false Configure support for unsigned JWT. If this is set to true any JWT that has algorithm set to none and no kid defined will be accepted. Note that this has serious security impact - if JWT can be sent from a third party, this allows the third party to send ANY JWT and it would be accpted as valid. atn-token.handler TokenHandler &#160; Token handler to extract username from request. atn-token.jwk.resource Resource &#160; JWK resource used to verify JWTs created by other parties. atn-token.jwt-audience string &#160; Audience expected in inbound JWTs. atn-token.verify-signature boolean true Configure whether to verify signatures. Signatures verification is enabled by default. You can configure the provider not to verify signatures. &lt;b&gt;Make sure your service is properly secured on network level and only accessible from a secure endpoint that provides the JWTs when signature verification is disabled. If signature verification is disabled, this service will accept &lt;i&gt;ANY&lt;/i&gt; JWT&lt;/b&gt; authenticate boolean true Whether to authenticate requests. optional boolean false Whether authentication is required. By default, request will fail if the username cannot be extracted. If set to false, request will process and this provider will abstain. principal-type SubjectType (USER, SERVICE) USER Principal type this provider extracts (and also propagates). propagate boolean true Whether to propagate identity. sign-token OutboundConfig &#160; Configuration of outbound rules. sign-token.jwk.resource Resource &#160; JWK resource used to sign JWTs created by us. sign-token.jwt-issuer string &#160; Issuer used to create new JWTs. use-jwt-groups boolean true Claim groups from JWT will be used to automatically add groups to current subject (may be used with jakarta.annotation.security.RolesAllowed annotation). Example code See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - provider: atn-token: jwk.resource.resource-path: \"verifying-jwk.json\" jwt-audience: \"http://my.service\" sign-token: jwk.resource.resource-path: \"signing-jwk.json\" jwt-issuer: \"http://my.server/identity\" outbound: - name: \"propagate-token\" hosts: [\"*.internal.org\"] - name: \"generate-token\" hosts: [\"1.partner-service\"] jwk-kid: \"partner-1\" jwt-kid: \"helidon\" jwt-audience: \"http://1.partner-service\" How does it work? JSON Web Token (JWT) provider has support for authentication and outbound security. Authentication is based on validating the token (signature, valid before etc.) and on asserting the subject of the JWT subject claim. For outbound, we support either token propagation (e.g. the token from request is propagated further) or support for generating a brand new token based on configuration of this provider. ",
            "title": "CORS Settings"
        },
        {
            "location": "/se/security/providers",
            "text": " Helidon Security Examples Helidon OIDC JavaDoc Helidon HTTP Authentication JavaDoc Helidon Header Authentication JavaDoc Helidon HTTP Signature JavaDoc Helidon IDCS Role Mapper JavaDoc Helidon ABAC JavaDoc Helidon Google Login JavaDoc Helidon JWT JavaDoc ",
            "title": "Reference"
        },
        {
            "location": "/se/security/tools",
            "text": " Support for encrypting secrets in configuration files. <markup lang=\"xml\" title=\"Maven Dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.config&lt;/groupId&gt; &lt;artifactId&gt;helidon-config-encryption&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Secure configuration"
        },
        {
            "location": "/se/security/tools",
            "text": " Configuration support for accessing private keys, public keys, certificates and certificate chains including runtime access to instances of such. <markup lang=\"xml\" title=\"Maven Dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.common&lt;/groupId&gt; &lt;artifactId&gt;helidon-common-key-util&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Key and certificate configuration"
        },
        {
            "location": "/se/security/tools",
            "text": " Secure configuration Support for encrypting secrets in configuration files. <markup lang=\"xml\" title=\"Maven Dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.config&lt;/groupId&gt; &lt;artifactId&gt;helidon-config-encryption&lt;/artifactId&gt; &lt;/dependency&gt; Key and certificate configuration Configuration support for accessing private keys, public keys, certificates and certificate chains including runtime access to instances of such. <markup lang=\"xml\" title=\"Maven Dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.common&lt;/groupId&gt; &lt;artifactId&gt;helidon-common-key-util&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Tools"
        },
        {
            "location": "/se/sse/sse",
            "text": " Overview Server API Maven Coordinates Usage Client API Maven Coordinates Usage Additional Information ",
            "title": "Contents"
        },
        {
            "location": "/se/sse/sse",
            "text": " Server-sent events (SSE) enable servers to push data to clients (e.g. Web browsers) using standard HTTP or HTTPS through a unidirectional server-to-client connection. In the server-sent events communication model, the client establishes the initial connection, and the server provides the data in the form of event streams . For more information about server-sent events, see the Server-sent events specification. SSE is an alternative technology to WebSockets when only server-to-client messaging is required and can be accomplished without the need to switch protocols (upgrades) and without using imperfect solutions such as long polling. A server-sent connection is typically a long-lived connection in which messages are sent to the client over a longer period of time compared to a normal request-response connection. It is useful for updating live data such as stock tickers, results of live events, etc. Helidon provides support for server and client APIs, although Web browsers are popular client alternatives. The following sections describe these APIs in more detail. ",
            "title": "Overview"
        },
        {
            "location": "/se/sse/sse",
            "text": "<markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webserver&lt;/groupId&gt; &lt;artifactId&gt;helidon-webserver-sse&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/sse/sse",
            "text": " Sending events is accomplished by obtaining an SseSink instance from a ServerResponse using the SseSink.TYPE constant. The following example converts the response into an SseSink , emits two string messages and then closes the connection. <markup lang=\"java\" >void sseString(ServerRequest req, ServerResponse res) { try (SseSink sseSink = res.sink(SseSink.TYPE)) { sseSink.emit(SseEvent.create(\"hello\")) .emit(SseEvent.create(\"world\")); } } Once an SseSink is obtained from a ServerResponse , the latter is no longer usable to send additional data to the client given that response Content-Type will be automatically set to text/event-stream . Note that an SseSink is auto closeable, so it can be part of a try-with-resources block as shown above. Events can be created using any of the static create methods in SseEvent as well as via a builder obtained by calling SseEvent.builder() . For more information see the Javadocs for those classes. In the example above, a simple create method with a string param is used to showcase a very common use case. The API supports integration with Helidon&#8217;s media type providers, so the event data may actually be of any type as long as it is possible to convert it to a string value. ",
            "title": "Usage"
        },
        {
            "location": "/se/sse/sse",
            "text": " It is possible to serialize event data using the media support. For example, if JSON-P is available in your class path, you can create an SSE event from a JsonObject and Helidon will find the appropriate media converter and serialize the event data on your behalf. <markup lang=\"java\" >void sseJsonp(ServerRequest req, ServerResponse res) { JsonObject json = Json.createObjectBuilder() .add(\"hello\", \"world\") .build(); try (SseSink sseSink = res.sink(SseSink.TYPE)) { sseSink.emit(SseEvent.create(json)); } } Similarly, if JSON-B support is available in your class path, an event can be created from an arbitrary Java class and serialized as shown next: <markup lang=\"java\" >class HelloWorld { private String hello; public String getHello() { return hello; } public void setHello(String hello) { this.hello = hello; } } void sseJsonb(ServerRequest req, ServerResponse res) { HelloWorld json = new HelloWorld(); json.setHello(\"world\"); try (SseSink sseSink = res.sink(SseSink.TYPE)) { sseSink.emit(SseEvent.create(json)); } } An optional media type can be specified alongside the event&#8217;s data, in case a different type of serialization is required or when multiple media converters are available in the class path. For example, when passing a Java instance, you may request XML instead of JSON serialization by using application/xml as the event&#8217;s media type. ",
            "title": "Integration with Media Types"
        },
        {
            "location": "/se/sse/sse",
            "text": " The Server API is available as a loadable service in the Helidon WebServer. The following additional dependency is required to find and load the SSE service in the WebServer. Maven Coordinates <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webserver&lt;/groupId&gt; &lt;artifactId&gt;helidon-webserver-sse&lt;/artifactId&gt; &lt;/dependency&gt; Usage Sending events is accomplished by obtaining an SseSink instance from a ServerResponse using the SseSink.TYPE constant. The following example converts the response into an SseSink , emits two string messages and then closes the connection. <markup lang=\"java\" >void sseString(ServerRequest req, ServerResponse res) { try (SseSink sseSink = res.sink(SseSink.TYPE)) { sseSink.emit(SseEvent.create(\"hello\")) .emit(SseEvent.create(\"world\")); } } Once an SseSink is obtained from a ServerResponse , the latter is no longer usable to send additional data to the client given that response Content-Type will be automatically set to text/event-stream . Note that an SseSink is auto closeable, so it can be part of a try-with-resources block as shown above. Events can be created using any of the static create methods in SseEvent as well as via a builder obtained by calling SseEvent.builder() . For more information see the Javadocs for those classes. In the example above, a simple create method with a string param is used to showcase a very common use case. The API supports integration with Helidon&#8217;s media type providers, so the event data may actually be of any type as long as it is possible to convert it to a string value. Integration with Media Types It is possible to serialize event data using the media support. For example, if JSON-P is available in your class path, you can create an SSE event from a JsonObject and Helidon will find the appropriate media converter and serialize the event data on your behalf. <markup lang=\"java\" >void sseJsonp(ServerRequest req, ServerResponse res) { JsonObject json = Json.createObjectBuilder() .add(\"hello\", \"world\") .build(); try (SseSink sseSink = res.sink(SseSink.TYPE)) { sseSink.emit(SseEvent.create(json)); } } Similarly, if JSON-B support is available in your class path, an event can be created from an arbitrary Java class and serialized as shown next: <markup lang=\"java\" >class HelloWorld { private String hello; public String getHello() { return hello; } public void setHello(String hello) { this.hello = hello; } } void sseJsonb(ServerRequest req, ServerResponse res) { HelloWorld json = new HelloWorld(); json.setHello(\"world\"); try (SseSink sseSink = res.sink(SseSink.TYPE)) { sseSink.emit(SseEvent.create(json)); } } An optional media type can be specified alongside the event&#8217;s data, in case a different type of serialization is required or when multiple media converters are available in the class path. For example, when passing a Java instance, you may request XML instead of JSON serialization by using application/xml as the event&#8217;s media type. ",
            "title": "Server API"
        },
        {
            "location": "/se/sse/sse",
            "text": "<markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-webclient-sse&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/sse/sse",
            "text": " Receiving events is accomplished by providing an SseSource handler using the source type SseSource.TYPE . An SseSource is a functional interface defined for the purpose of processing events. The following example, obtains an Http1ClientResponse from a request and registers an SseSource to process a single event. <markup lang=\"java\" >try (Http1ClientResponse r = client.get(\"/sseJson\") .header(ACCEPT_EVENT_STREAM) .request()) { CountDownLatch latch = new CountDownLatch(1); r.source(SseSource.TYPE, event -&gt; { // ... latch.countDown(); }); } The SseSource type defines other methods such as onOpen , onClose and onError . The following example waits for zero or more string events until the connection is closed. A CountDownLatch is a convenient way to asynchronously wait until all the events are received. <markup lang=\"java\" >try (Http1ClientResponse r = client.get(\"/sseString\") .header(ACCEPT_EVENT_STREAM) .request()) { CountDownLatch latch = new CountDownLatch(1); r.source(SseSource.TYPE, new SseSource() { @Override public void onEvent(SseEvent event) { // ... } @Override public void onClose() { latch.countDown(); } }); assertThat(latch.await(5, TimeUnit.SECONDS), is(true)); } ",
            "title": "Usage"
        },
        {
            "location": "/se/sse/sse",
            "text": " The Client API is also integrated with Helidon&#8217;s media type support. The data received as part of an event can be deserialized using any of the media converters available in your class path. There are special methods in SseEvent for this purpose. Without a parameter, the method data() in SseEvent will always return a string. Other types can be requested using data(Class&lt;T&gt;) and data(Class&lt;T&gt;, MediaType) . The latter is necessary to select the correct media converter given that there is no (standard) content type available as part of each event --but only a single text/event-stream content type for the whole response. For example, to convert an event into a Java instance using JSON-B, the application/json media type is required as a second parameter --the first parameter HelloWorld.class simply does not convey sufficient information to select the appropriate converter for the event&#8217;s data in this case. <markup lang=\"java\" >try (Http1ClientResponse r = client.get(\"/sseJson\") .header(ACCEPT_EVENT_STREAM) .request()) { CountDownLatch latch = new CountDownLatch(1); r.source(SseSource.TYPE, event -&gt; { HelloWorld json = event.data(HelloWorld.class, MediaTypes.APPLICATION_JSON); // ... latch.countDown(); }); } ",
            "title": "Integration with Media Types"
        },
        {
            "location": "/se/sse/sse",
            "text": " The Client API is available as a loadable service in the Helidon WebClient. The following additional dependency is required to find and load the service in the WebClient. Maven Coordinates <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-webclient-sse&lt;/artifactId&gt; &lt;/dependency&gt; Usage Receiving events is accomplished by providing an SseSource handler using the source type SseSource.TYPE . An SseSource is a functional interface defined for the purpose of processing events. The following example, obtains an Http1ClientResponse from a request and registers an SseSource to process a single event. <markup lang=\"java\" >try (Http1ClientResponse r = client.get(\"/sseJson\") .header(ACCEPT_EVENT_STREAM) .request()) { CountDownLatch latch = new CountDownLatch(1); r.source(SseSource.TYPE, event -&gt; { // ... latch.countDown(); }); } The SseSource type defines other methods such as onOpen , onClose and onError . The following example waits for zero or more string events until the connection is closed. A CountDownLatch is a convenient way to asynchronously wait until all the events are received. <markup lang=\"java\" >try (Http1ClientResponse r = client.get(\"/sseString\") .header(ACCEPT_EVENT_STREAM) .request()) { CountDownLatch latch = new CountDownLatch(1); r.source(SseSource.TYPE, new SseSource() { @Override public void onEvent(SseEvent event) { // ... } @Override public void onClose() { latch.countDown(); } }); assertThat(latch.await(5, TimeUnit.SECONDS), is(true)); } Integration with Media Types The Client API is also integrated with Helidon&#8217;s media type support. The data received as part of an event can be deserialized using any of the media converters available in your class path. There are special methods in SseEvent for this purpose. Without a parameter, the method data() in SseEvent will always return a string. Other types can be requested using data(Class&lt;T&gt;) and data(Class&lt;T&gt;, MediaType) . The latter is necessary to select the correct media converter given that there is no (standard) content type available as part of each event --but only a single text/event-stream content type for the whole response. For example, to convert an event into a Java instance using JSON-B, the application/json media type is required as a second parameter --the first parameter HelloWorld.class simply does not convey sufficient information to select the appropriate converter for the event&#8217;s data in this case. <markup lang=\"java\" >try (Http1ClientResponse r = client.get(\"/sseJson\") .header(ACCEPT_EVENT_STREAM) .request()) { CountDownLatch latch = new CountDownLatch(1); r.source(SseSource.TYPE, event -&gt; { HelloWorld json = event.data(HelloWorld.class, MediaTypes.APPLICATION_JSON); // ... latch.countDown(); }); } ",
            "title": "Client API"
        },
        {
            "location": "/se/sse/sse",
            "text": " The Server-sent events specification. ",
            "title": "Additional Information"
        },
        {
            "location": "/se/testing",
            "text": " Overview Maven Coordinates Usage Examples Additional Information Reference ",
            "title": "Contents"
        },
        {
            "location": "/se/testing",
            "text": " Helidon provides built-in test support for Helidon testing with JUnit 5. ",
            "title": "Overview"
        },
        {
            "location": "/se/testing",
            "text": " To enable Helidon Testing Framework add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webserver.testing.junit5&lt;/groupId&gt; &lt;artifactId&gt;helidon-webserver-testing-junit5&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/testing",
            "text": " Helidon provides a rich set of extensions based on JUnit 5 for Helidon WebServer testing. Testing can be done with automatic server start-up, configuration, and shutdown. Testing can also be done without full server start-up with DirectClient when no real sockets are created. ",
            "title": "Usage"
        },
        {
            "location": "/se/testing",
            "text": " There are two main annotations that you can use to test Helidon WebServer. @ServerTest is an integration test annotation that starts the server (opens ports) and provides client injection pre-configured for the server port(s). @RoutingTest is a unit test annotation that does not start the server and does not open ports but provides a direct client (with the same API as the usual network client) to test routing. The additional annotation @Socket can be used to qualify the injection of parameters into test constructors or methods, such as to obtain a client configured for the named socket. The following table lists the supported types of parameters for the @SetUpRoute annotated methods. Such methods MUST be static and may have any name. The @SetUpRoute annotation has value with socket name (to customize the setup for a different socket). Parameter type - supported class of a parameter Annotation - which annotations support this parameter Modules - which webserver extension modules support this signature Parameters for the @SetUpRoute annotated methods. Parameter Type Annotation Modules Notes HttpRouting.Builder @ServerTest , @RoutingTest HttpRules @ServerTest , @RoutingTest Same as HttpRouting.Builder , only routing setup Router.RouterBuilder&lt;?&gt; @ServerTest , @RoutingTest SocketListener.Builder @ServerTest WebSocketRouting.Builder @ServerTest , @RoutingTest websocket In addition, a static method annotated with @SetUpServer can be defined for @ServerTest , which has a single parameter of WebServer.Builder . The following table lists the injectable types (through constructor or method injection). Type - type that can be injected Socket - if checked, you can use the @Socket annotation to obtain a value specific to that named socket Annotation - which annotations support this injection Modules - which WebServer extension modules support this injection Notes - additional details Injectable types. Type Socket? Annotation Modules Notes WebServer @ServerTest Server instance (already started) URI x @ServerTest URI pointing to a port of the webserver SocketHttpClient x @ServerTest This client allows you to send anything in order to test for bad requests or other issues. Http1Client x @ServerTest DirectClient x @RoutingTest Implements Http1Client API WsClient x @ServerTest websocket DirectWsClient x @RoutingTest websocket Implements WsClient API Extensions can enhance the features for the module helidon-testing-junit5-webserver to support additional protocols. ",
            "title": "API"
        },
        {
            "location": "/se/testing",
            "text": " If there is no need to set up and run a server, a DirectClient client can be used. It is a testing client that bypasses HTTP transport and directly invokes the router. <markup lang=\"java\" title=\"Routing test using @RoutingTest and DirectClient .\" >@RoutingTest class RoutingTest { private final Http1Client client; protected RoutingTest(DirectClient client) { this.client = client; } @SetUpRoute static void routing(HttpRouting.Builder builder) { QuickstartMain.routing(builder); } @Test void testRootRoute() { try (Http1ClientResponse response = client.get(\"/greet\") .request()) { JsonObject json = response.as(JsonObject.class); assertThat(json.getString(\"message\"), is(\"Hello World!\")); } } } Use @RoutingTest to trigger the testing framework. Inject DirectClient for the test. SetUp routing for the test. A regular JUnit test method. Call the client to obtain server response. Perform the necessary assertions. If only routing tests are required, this is a \"lighter\" way of testing because the framework will not configure and run the full Helidon server. This way, no real ports will be opened. All the communication will be done through DirectClient , which makes the tests very effective. It is required to annotate the test class with the @RoutingTest annotation to trigger the server to do the configuration. Thus, it will inject the DirectClient client, which can then be used in unit tests. Routing is configured the same way as in full server testing using the @SetUpRoute annotation. ",
            "title": "Routing Tests"
        },
        {
            "location": "/se/testing",
            "text": " You can create the following test to validate that the server returns the correct response: <markup lang=\"java\" title=\"Basic Helidon test framework usage.\" >@ServerTest class IntegrationTest { private final Http1Client client; protected IntegrationTest(Http1Client client) { this.client = client; } @SetUpRoute static void routing(HttpRouting.Builder builder) { QuickstartMain.routing(builder); } @Test void testRootRoute() { try (Http1ClientResponse response = client.get(\"/greet\") .request()) { assertThat(response.status(), is(Http.Status.OK_200)); } } } Use @ServerTest to trigger the testing framework. Inject Http1Client for the test. SetUp routing for the test. Regular JUnit test method. Call the client to obtain server response Perform the necessary assertions. To trigger the framework to start and configure the server, annotate the testing class with the @ServerTest annotation. In this test, the Http1Client client is used, which means that the framework will create, configure, and inject this object as a parameter to the constructor. To set up routing, a static method annotated with @SetUpRoute is present. The framework uses this method to inject the configured routing to the subject of testing – in the current case, the Quickstart application. As everything above is performed by the testing framework, regular unit tests can be done. After completing all tests, the testing framework will shut down the server. Routing Tests If there is no need to set up and run a server, a DirectClient client can be used. It is a testing client that bypasses HTTP transport and directly invokes the router. <markup lang=\"java\" title=\"Routing test using @RoutingTest and DirectClient .\" >@RoutingTest class RoutingTest { private final Http1Client client; protected RoutingTest(DirectClient client) { this.client = client; } @SetUpRoute static void routing(HttpRouting.Builder builder) { QuickstartMain.routing(builder); } @Test void testRootRoute() { try (Http1ClientResponse response = client.get(\"/greet\") .request()) { JsonObject json = response.as(JsonObject.class); assertThat(json.getString(\"message\"), is(\"Hello World!\")); } } } Use @RoutingTest to trigger the testing framework. Inject DirectClient for the test. SetUp routing for the test. A regular JUnit test method. Call the client to obtain server response. Perform the necessary assertions. If only routing tests are required, this is a \"lighter\" way of testing because the framework will not configure and run the full Helidon server. This way, no real ports will be opened. All the communication will be done through DirectClient , which makes the tests very effective. It is required to annotate the test class with the @RoutingTest annotation to trigger the server to do the configuration. Thus, it will inject the DirectClient client, which can then be used in unit tests. Routing is configured the same way as in full server testing using the @SetUpRoute annotation. ",
            "title": "Examples"
        },
        {
            "location": "/se/testing",
            "text": " If WebSocket testing is required, there is an additional module for it. It is necessary to include the following Maven dependency to the Project&#8217;s pom file: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.testing.junit5&lt;/groupId&gt; &lt;artifactId&gt;helidon-testing-junit5-websocket&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; ",
            "title": "WebSocket Testing"
        },
        {
            "location": "/se/testing",
            "text": " The WebSocket Testing extension adds support for routing configuration and injection of WebSocket related artifacts, such as WebSockets and DirectWsClient in Helidon unit tests. <markup lang=\"java\" title=\"WebSocket sample test.\" >@ServerTest class WsSocketTest { private static final ServerSideListener WS_LISTENER = new ServerSideListener(); private final WsClient wsClient; protected WsSocketTest(WsClient wsClient) { this.wsClient = wsClient; } @SetUpRoute static void routing(WsRouting.Builder ws) { ws.endpoint(\"/testWs\", WS_LISTENER); } @Test void testWsEndpoint() { WS_LISTENER.reset(); ClientSideListener clientListener = new ClientSideListener(); wsClient.connect(\"/testWs\", clientListener); assertThat(clientListener.message, is(\"ws\")); } } Declare WsClient and later inject it in the constructor. Using @SetUpRoute, create WebSocket routing and assign a serverside listener. Test the WebSocket endpoint using the regular @Test annotation. Create and assign the clientside listener. Check if the received message is correct. Note The WebSocket ClientSideListener is a helper class that implements WsListener . ClientSideListener is very simple and as shown below: <markup lang=\"java\" title=\" ClientSideListener helper class.\" >private static class ClientSideListener implements WsListener { private final CountDownLatch cdl = new CountDownLatch(1); private String message; private volatile Throwable throwable; @Override public void onOpen(WsSession session) { session.send(\"hello\", true); } @Override public void onMessage(WsSession session, String text, boolean last) { this.message = text; session.close(WsCloseCodes.NORMAL_CLOSE, \"End\"); } @Override public void onClose(WsSession session, int status, String reason) { cdl.countDown(); } @Override public void onError(WsSession session, Throwable t) { this.throwable = t; cdl.countDown(); } } Send \"Hello\" when a connection is opened. Save the message when received and close the connection. Close the connection. React on an error. The WebSocket ClientSideListener is also a helper class that implements WsListener and is very straightforward: <markup lang=\"java\" title=\" ServerSideListener helper class.\" >private static class ServerSideListener implements WsListener { boolean opened; boolean closed; String message; @Override public void onMessage(WsSession session, String text, boolean last) { message = text; session.send(\"ws\", true); } @Override public void onClose(WsSession session, int status, String reason) { closed = true; } @Override public void onOpen(WsSession session) { opened = true; } void reset() { opened = false; closed = false; message = null; } } Send \"ws\" on a received message. Called when the connection is called. Called on connection is opened. Used to reset the state. The testing class should be annotated with @RoutingTest only if routing tests are required without real port opening. Instead of WsClient , use DirectWsClient . ",
            "title": "WebSocket Testing Example"
        },
        {
            "location": "/se/testing",
            "text": " WebSocket Testing If WebSocket testing is required, there is an additional module for it. It is necessary to include the following Maven dependency to the Project&#8217;s pom file: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.testing.junit5&lt;/groupId&gt; &lt;artifactId&gt;helidon-testing-junit5-websocket&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; WebSocket Testing Example The WebSocket Testing extension adds support for routing configuration and injection of WebSocket related artifacts, such as WebSockets and DirectWsClient in Helidon unit tests. <markup lang=\"java\" title=\"WebSocket sample test.\" >@ServerTest class WsSocketTest { private static final ServerSideListener WS_LISTENER = new ServerSideListener(); private final WsClient wsClient; protected WsSocketTest(WsClient wsClient) { this.wsClient = wsClient; } @SetUpRoute static void routing(WsRouting.Builder ws) { ws.endpoint(\"/testWs\", WS_LISTENER); } @Test void testWsEndpoint() { WS_LISTENER.reset(); ClientSideListener clientListener = new ClientSideListener(); wsClient.connect(\"/testWs\", clientListener); assertThat(clientListener.message, is(\"ws\")); } } Declare WsClient and later inject it in the constructor. Using @SetUpRoute, create WebSocket routing and assign a serverside listener. Test the WebSocket endpoint using the regular @Test annotation. Create and assign the clientside listener. Check if the received message is correct. Note The WebSocket ClientSideListener is a helper class that implements WsListener . ClientSideListener is very simple and as shown below: <markup lang=\"java\" title=\" ClientSideListener helper class.\" >private static class ClientSideListener implements WsListener { private final CountDownLatch cdl = new CountDownLatch(1); private String message; private volatile Throwable throwable; @Override public void onOpen(WsSession session) { session.send(\"hello\", true); } @Override public void onMessage(WsSession session, String text, boolean last) { this.message = text; session.close(WsCloseCodes.NORMAL_CLOSE, \"End\"); } @Override public void onClose(WsSession session, int status, String reason) { cdl.countDown(); } @Override public void onError(WsSession session, Throwable t) { this.throwable = t; cdl.countDown(); } } Send \"Hello\" when a connection is opened. Save the message when received and close the connection. Close the connection. React on an error. The WebSocket ClientSideListener is also a helper class that implements WsListener and is very straightforward: <markup lang=\"java\" title=\" ServerSideListener helper class.\" >private static class ServerSideListener implements WsListener { boolean opened; boolean closed; String message; @Override public void onMessage(WsSession session, String text, boolean last) { message = text; session.send(\"ws\", true); } @Override public void onClose(WsSession session, int status, String reason) { closed = true; } @Override public void onOpen(WsSession session) { opened = true; } void reset() { opened = false; closed = false; message = null; } } Send \"ws\" on a received message. Called when the connection is called. Called on connection is opened. Used to reset the state. The testing class should be annotated with @RoutingTest only if routing tests are required without real port opening. Instead of WsClient , use DirectWsClient . ",
            "title": "Additional Information"
        },
        {
            "location": "/se/testing",
            "text": " JUnit 5 User Guide ",
            "title": "Reference"
        },
        {
            "location": "/se/tracing",
            "text": " Overview Maven Coordinates Usage Configuration Additional Information Jaeger Tracing Zipkin Tracing Reference ",
            "title": "Contents"
        },
        {
            "location": "/se/tracing",
            "text": " Distributed tracing is a critical feature of micro-service based applications, since it traces workflow both within a service and across multiple services. This provides insight to sequence and timing data for specific blocks of work, which helps you identify performance and operational issues. Helidon includes support for distributed tracing through its own API, backed by either through the OpenTelemetry API , or by OpenTracing API . Tracing is integrated with WebServer and Security. ",
            "title": "Overview"
        },
        {
            "location": "/se/tracing",
            "text": " To enable Helidon Tracing add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.webserver.observe&lt;/groupId&gt; &lt;artifactId&gt;helidon-webserver-observe-tracing&lt;/artifactId&gt; &lt;/dependency&gt; Helidon tracing dependency. Observability dependencies for tracing. For further processing of the tracing data, different providers are used. For Jaeger: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-providers-jaeger&lt;/artifactId&gt; &lt;/dependency&gt; For Zipkin: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-providers-zipkin&lt;/artifactId&gt; &lt;/dependency&gt; For OpenTelemetry: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-providers-opentelemetry&lt;/artifactId&gt; &lt;/dependency&gt; For OpenTracing: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-providers-opentracing&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/tracing",
            "text": "<markup lang=\"java\" title=\"Configuring Tracer \" >Tracer tracer = TracerBuilder.create(\"helidon\") .build(); WebServer.builder() .addFeature(ObserveFeature.builder() .addObserver(TracingObserver.create(tracer)) .build()) ... .build() .start(); Create a Tracer . Add an observability feature using the created Tracer . ",
            "title": "Setup WebServer"
        },
        {
            "location": "/se/tracing",
            "text": " To create a custom span from tracer: <markup lang=\"java\" >Span span = tracer.spanBuilder(\"name\") .tag(\"key\", \"value\") .start(); try (...){ //do some work span.end(); } catch (Throwable t) { span.end(t); } Create span from tracer. Do some work and end span. End span with exception. ",
            "title": "Creating Custom Spans"
        },
        {
            "location": "/se/tracing",
            "text": " This section explains a few concepts that you need to understand before you get started with tracing. In the context of this document, a service is synonymous with an application. A span is the basic unit of work done within a single service, on a single host. Every span has a name, starting timestamp, and duration. For example, the work done by a REST endpoint is a span. A span is associated to a single service, but its descendants can belong to different services and hosts. A trace contains a collection of spans from one or more services, running on one or more hosts. For example, if you trace a service endpoint that calls another service, then the trace would contain spans from both services. Within a trace, spans are organized as a directed acyclic graph (DAG) and can belong to multiple services, running on multiple hosts. Support for specific tracers is abstracted. Your application can depend on the Helidon abstraction layer and provide a specific tracer implementation as a Java ServiceLoader service. Helidon provides such an implementation for: OpenTracing tracers, either using the GlobalTracer , provider resolver approach, or explicitly using Zipkin tracer OpenTelemetry tracers, either using the global OpenTelemetry instance, or explicitly using Jaeger tracer Setup WebServer <markup lang=\"java\" title=\"Configuring Tracer \" >Tracer tracer = TracerBuilder.create(\"helidon\") .build(); WebServer.builder() .addFeature(ObserveFeature.builder() .addObserver(TracingObserver.create(tracer)) .build()) ... .build() .start(); Create a Tracer . Add an observability feature using the created Tracer . Creating Custom Spans To create a custom span from tracer: <markup lang=\"java\" >Span span = tracer.spanBuilder(\"name\") .tag(\"key\", \"value\") .start(); try (...){ //do some work span.end(); } catch (Throwable t) { span.end(t); } Create span from tracer. Do some work and end span. End span with exception. ",
            "title": "Usage"
        },
        {
            "location": "/se/tracing",
            "text": "",
            "title": "Helidon Spans"
        },
        {
            "location": "/se/tracing",
            "text": " The following table lists all spans traced by Helidon components: <div class=\"table__overflow elevation-1 flex sm10 \"> component span name description web-server HTTP Request The overall span of the Web Server from request initiation until response Note that in Zipkin the name is replaced with jax-rs span name if jax-rs tracing is used. web-server content-read Span for reading the request entity web-server content-write Span for writing the response entity security security Processing of request security security security:atn Span for request authentication security security:atz Span for request authorization security security:response Processing of response security security security:outbound Processing of outbound security jax-rs A generated name Span for the resource method invocation, name is generated from class and method name jax-rs jersey-client-call Span for outbound client call Some of these spans log to the span. These log events can be (in most cases) configured: <div class=\"table__overflow elevation-1 flex sm10 \"> span name log name configurable enabled by default description HTTP Request handler.class YES YES Each handler has its class and event logged security status YES YES Logs either \"status: PROCEED\" or \"status: DENY\" security:atn security.user YES NO The username of the user if logged in security:atn security.service YES NO The name of the service if logged in security:atn status YES YES Logs the status of security response (such as SUCCESS ) security:atz status YES YES Logs the status of security response (such as SUCCESS ) security:outbound status YES YES Logs the status of security response (such as SUCCESS ) There are also tags that are set by Helidon components. These are not configurable. <div class=\"table__overflow elevation-1 flex sm10 \"> span name tag name description HTTP Request component name of the component - helidon-webserver , or jaxrs when using MP HTTP Request http.method HTTP method of the request, such as GET , POST HTTP Request http.status_code HTTP status code of the response HTTP Request http.url The path of the request (for SE without protocol, host and port) HTTP Request error If the request ends in error, this tag is set to true , usually accompanied by logs with details security security.id ID of the security context created for this request (if security is used) jersey-client-call http.method HTTP method of the client request jersey-client-call http.status_code HTTP status code of client response jersey-client-call http.url Full URL of the request (such as http://localhost:8080/greet ) ",
            "title": "Traced spans"
        },
        {
            "location": "/se/tracing",
            "text": " The following configuration should be supported by all tracer implementations (if feasible) Jaeger tracer configuration. Type: io.helidon.tracing.Tracer This is a standalone configuration type, prefix from configuration root: tracing ",
            "title": "Configuration"
        },
        {
            "location": "/se/tracing",
            "text": " Builder approach, example that disables a single span log event: <markup lang=\"java\" title=\"Configure tracing using a builder\" >TracingConfig.builder() .addComponent(ComponentTracingConfig.builder(\"web-server\") .addSpan(SpanTracingConfig.builder(\"HTTP Request\") .addSpanLog(SpanLogTracingConfig.builder(\"content-write\").enabled(false).build()) .build()) .build()) .build() ",
            "title": "Configuration Using Builder"
        },
        {
            "location": "/se/tracing",
            "text": " Tracing configuration can be defined in a config file. <markup lang=\"yaml\" title=\"Tracing configuration\" >tracing: components: web-server: spans: - name: \"HTTP Request\" logs: - name: \"content-write\" enabled: false <markup lang=\"java\" title=\"Use the configuration in web server\" >Tracer tracer = TracerBuilder.create(config.get(\"tracing\")).build(); server.addFeature(ObserveFeature.builder() .addObserver(TracingObserver.create(tracer)) .build()) Create Tracer using TracerBuilder from configuration. Add the Tracer as an observability feature. ",
            "title": "Configuration using Helidon Config"
        },
        {
            "location": "/se/tracing",
            "text": " For Web Server we have path-based support for configuring tracing, in addition to the configuration described above. Configuration of path can use any path string supported by the WebServer. The configuration itself has the same possibilities as traced configuration described above. The path-specific configuration will be merged with global configuration (path is the \"newer\" configuration, global is the \"older\") <markup lang=\"yaml\" title=\"Configuration in YAML\" >tracing: paths: - path: \"/favicon.ico\" enabled: false - path: \"/metrics\" enabled: false - path: \"/health\" enabled: false - path: \"/greet\" components: web-server: spans: - name: \"content-read\" new-name: \"read\" enabled: false <markup lang=\"java\" title=\"Configuration with Web Server\" >Tracer tracer = TracerBuilder.create(config.get(\"tracing\")).build(); server.addFeature(ObserveFeature.builder() .addObserver(TracingObserver.create(tracer)) .build()) Create Tracer using TracerBuilder from configuration. Add the Tracer as an observability feature. ",
            "title": "Path-based Configuration in Helidon WebServer"
        },
        {
            "location": "/se/tracing",
            "text": " To have a nicer overview in search pane of a tracer, you can customize the top-level span name using configuration. Example: <markup lang=\"yaml\" title=\"Configuration in YAML\" >tracing: components: web-server: spans: - name: \"HTTP Request\" new-name: \"HTTP %1$s %2$s\" This is supported ONLY for the span named \"HTTP Request\" on component \"web-server\". Parameters provided: Method - HTTP method Path - path of the request (such as '/greet') Query - query of the request (may be null) ",
            "title": "Renaming top level span using request properties"
        },
        {
            "location": "/se/tracing",
            "text": " Each component and its spans can be configured using Config. The traced configuration has the following layers: TracingConfig - the overall configuration of traced components of Helidon ComponentTracingConfig - a component of Helidon that traces spans (such as web-server , security , jax-rs ) SpanTracingConfig - a single traced span within a component (such as security:atn ) SpanLogTracingConfig - a single log event on a span (such as security.user in span security:atn ) The components using tracing configuration use the TracingConfigUtil . This uses the io.helidon.common.Context to retrieve current configuration. Configuration Using Builder Builder approach, example that disables a single span log event: <markup lang=\"java\" title=\"Configure tracing using a builder\" >TracingConfig.builder() .addComponent(ComponentTracingConfig.builder(\"web-server\") .addSpan(SpanTracingConfig.builder(\"HTTP Request\") .addSpanLog(SpanLogTracingConfig.builder(\"content-write\").enabled(false).build()) .build()) .build()) .build() Configuration using Helidon Config Tracing configuration can be defined in a config file. <markup lang=\"yaml\" title=\"Tracing configuration\" >tracing: components: web-server: spans: - name: \"HTTP Request\" logs: - name: \"content-write\" enabled: false <markup lang=\"java\" title=\"Use the configuration in web server\" >Tracer tracer = TracerBuilder.create(config.get(\"tracing\")).build(); server.addFeature(ObserveFeature.builder() .addObserver(TracingObserver.create(tracer)) .build()) Create Tracer using TracerBuilder from configuration. Add the Tracer as an observability feature. Path-based Configuration in Helidon WebServer For Web Server we have path-based support for configuring tracing, in addition to the configuration described above. Configuration of path can use any path string supported by the WebServer. The configuration itself has the same possibilities as traced configuration described above. The path-specific configuration will be merged with global configuration (path is the \"newer\" configuration, global is the \"older\") <markup lang=\"yaml\" title=\"Configuration in YAML\" >tracing: paths: - path: \"/favicon.ico\" enabled: false - path: \"/metrics\" enabled: false - path: \"/health\" enabled: false - path: \"/greet\" components: web-server: spans: - name: \"content-read\" new-name: \"read\" enabled: false <markup lang=\"java\" title=\"Configuration with Web Server\" >Tracer tracer = TracerBuilder.create(config.get(\"tracing\")).build(); server.addFeature(ObserveFeature.builder() .addObserver(TracingObserver.create(tracer)) .build()) Create Tracer using TracerBuilder from configuration. Add the Tracer as an observability feature. Renaming top level span using request properties To have a nicer overview in search pane of a tracer, you can customize the top-level span name using configuration. Example: <markup lang=\"yaml\" title=\"Configuration in YAML\" >tracing: components: web-server: spans: - name: \"HTTP Request\" new-name: \"HTTP %1$s %2$s\" This is supported ONLY for the span named \"HTTP Request\" on component \"web-server\". Parameters provided: Method - HTTP method Path - path of the request (such as '/greet') Query - query of the request (may be null) ",
            "title": "Traced Spans Configuration"
        },
        {
            "location": "/se/tracing",
            "text": " Optional configuration options key type default value description client-cert-pem Resource &#160; Certificate of client in PEM format. exporter-timeout Duration PT10S Timeout of exporter requests. max-export-batch-size int 512 Maximum Export Batch Size of exporter requests. max-queue-size int 2048 Maximum Queue Size of exporter requests. private-key-pem Resource &#160; Private key in PEM format. propagation PropagationFormat[&#93; (B3, B3_SINGLE, JAEGER, W3C) JAEGER Add propagation format to use. sampler-param Number 1 The sampler parameter (number). sampler-type SamplerType (CONSTANT, RATIO) CONSTANT Sampler type. See &lt;a href=\"https://www.jaegertracing.io/docs/latest/sampling/#client-sampling-configuration\"&gt;Sampler types&lt;/a&gt;. schedule-delay Duration PT5S Schedule Delay of exporter requests. span-processor-type SpanProcessorType (SIMPLE, BATCH) batch Span Processor type used. trusted-cert-pem Resource &#160; Trusted certificates in PEM format. Traced Spans Configuration Each component and its spans can be configured using Config. The traced configuration has the following layers: TracingConfig - the overall configuration of traced components of Helidon ComponentTracingConfig - a component of Helidon that traces spans (such as web-server , security , jax-rs ) SpanTracingConfig - a single traced span within a component (such as security:atn ) SpanLogTracingConfig - a single log event on a span (such as security.user in span security:atn ) The components using tracing configuration use the TracingConfigUtil . This uses the io.helidon.common.Context to retrieve current configuration. Configuration Using Builder Builder approach, example that disables a single span log event: <markup lang=\"java\" title=\"Configure tracing using a builder\" >TracingConfig.builder() .addComponent(ComponentTracingConfig.builder(\"web-server\") .addSpan(SpanTracingConfig.builder(\"HTTP Request\") .addSpanLog(SpanLogTracingConfig.builder(\"content-write\").enabled(false).build()) .build()) .build()) .build() Configuration using Helidon Config Tracing configuration can be defined in a config file. <markup lang=\"yaml\" title=\"Tracing configuration\" >tracing: components: web-server: spans: - name: \"HTTP Request\" logs: - name: \"content-write\" enabled: false <markup lang=\"java\" title=\"Use the configuration in web server\" >Tracer tracer = TracerBuilder.create(config.get(\"tracing\")).build(); server.addFeature(ObserveFeature.builder() .addObserver(TracingObserver.create(tracer)) .build()) Create Tracer using TracerBuilder from configuration. Add the Tracer as an observability feature. Path-based Configuration in Helidon WebServer For Web Server we have path-based support for configuring tracing, in addition to the configuration described above. Configuration of path can use any path string supported by the WebServer. The configuration itself has the same possibilities as traced configuration described above. The path-specific configuration will be merged with global configuration (path is the \"newer\" configuration, global is the \"older\") <markup lang=\"yaml\" title=\"Configuration in YAML\" >tracing: paths: - path: \"/favicon.ico\" enabled: false - path: \"/metrics\" enabled: false - path: \"/health\" enabled: false - path: \"/greet\" components: web-server: spans: - name: \"content-read\" new-name: \"read\" enabled: false <markup lang=\"java\" title=\"Configuration with Web Server\" >Tracer tracer = TracerBuilder.create(config.get(\"tracing\")).build(); server.addFeature(ObserveFeature.builder() .addObserver(TracingObserver.create(tracer)) .build()) Create Tracer using TracerBuilder from configuration. Add the Tracer as an observability feature. Renaming top level span using request properties To have a nicer overview in search pane of a tracer, you can customize the top-level span name using configuration. Example: <markup lang=\"yaml\" title=\"Configuration in YAML\" >tracing: components: web-server: spans: - name: \"HTTP Request\" new-name: \"HTTP %1$s %2$s\" This is supported ONLY for the span named \"HTTP Request\" on component \"web-server\". Parameters provided: Method - HTTP method Path - path of the request (such as '/greet') Query - query of the request (may be null) ",
            "title": "Configuration options"
        },
        {
            "location": "/se/tracing",
            "text": " Span propagation is supported with Helidon WebClient. Tracing propagation is automatic as long as the current span context is available in Helidon Context (which is automatic when running within a WebServer request). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-webclient&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.webclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-webclient-tracing&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"java\" title=\"Tracing propagation with Helidon WebClient\" >WebClient client = WebClient.builder() .addService(WebClientTracing.create()) .build(); String response = client.get() .uri(uri) .request(String.class); ",
            "title": "WebClient Span Propagation"
        },
        {
            "location": "/se/tracing",
            "text": "<markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-providers-jaeger&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Jaeger Tracing"
        },
        {
            "location": "/se/tracing",
            "text": " WebClient Span Propagation Span propagation is supported with Helidon WebClient. Tracing propagation is automatic as long as the current span context is available in Helidon Context (which is automatic when running within a WebServer request). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-webclient&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.webclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-webclient-tracing&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"java\" title=\"Tracing propagation with Helidon WebClient\" >WebClient client = WebClient.builder() .addService(WebClientTracing.create()) .build(); String response = client.get() .uri(uri) .request(String.class); Jaeger Tracing <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-providers-jaeger&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Additional Information"
        },
        {
            "location": "/se/tracing",
            "text": " Jaeger tracer configuration. Type: io.helidon.tracing.Tracer This is a standalone configuration type, prefix from configuration root: tracing ",
            "title": "Configuring Jaeger"
        },
        {
            "location": "/se/tracing",
            "text": " As the Jaeger Tracing section describes, you can use Jaeger tracing in your Helidon application. ",
            "title": "Jaeger Tracing Metrics"
        },
        {
            "location": "/se/tracing",
            "text": "<markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-providers-zipkin&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Zipkin Tracing"
        },
        {
            "location": "/se/tracing",
            "text": " Optional configuration options key type default value description client-cert-pem Resource &#160; Certificate of client in PEM format. exporter-timeout Duration PT10S Timeout of exporter requests. max-export-batch-size int 512 Maximum Export Batch Size of exporter requests. max-queue-size int 2048 Maximum Queue Size of exporter requests. private-key-pem Resource &#160; Private key in PEM format. propagation PropagationFormat[&#93; (B3, B3_SINGLE, JAEGER, W3C) JAEGER Add propagation format to use. sampler-param Number 1 The sampler parameter (number). sampler-type SamplerType (CONSTANT, RATIO) CONSTANT Sampler type. See &lt;a href=\"https://www.jaegertracing.io/docs/latest/sampling/#client-sampling-configuration\"&gt;Sampler types&lt;/a&gt;. schedule-delay Duration PT5S Schedule Delay of exporter requests. span-processor-type SpanProcessorType (SIMPLE, BATCH) batch Span Processor type used. trusted-cert-pem Resource &#160; Trusted certificates in PEM format. The following is an example of a Jaeger configuration, specified in the YAML format. <markup lang=\"yaml\" >tracing: service: \"helidon-full-http\" protocol: \"https\" host: \"jaeger\" port: 14240 Jaeger Tracing Metrics As the Jaeger Tracing section describes, you can use Jaeger tracing in your Helidon application. Zipkin Tracing <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-providers-zipkin&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Configuration options"
        },
        {
            "location": "/se/tracing",
            "text": " Zipkin tracer configuration Type: io.opentracing.Tracer This is a standalone configuration type, prefix from configuration root: tracing ",
            "title": "Configuring Zipkin"
        },
        {
            "location": "/se/tracing",
            "text": " Optional configuration options key type default value description api-version Version (V1, V2) V2 Version of Zipkin API to use. Defaults to Version#V2. The following is an example of a Zipkin configuration, specified in the YAML format. <markup lang=\"yaml\" >tracing: zipkin: service: \"helidon-service\" protocol: \"https\" host: \"zipkin\" port: 9987 api-version: 1 # this is the default path for API version 2 path: \"/api/v2/spans\" tags: tag1: \"tag1-value\" tag2: \"tag2-value\" boolean-tags: tag3: true tag4: false int-tags: tag5: 145 tag6: 741 Example of Zipkin trace: ",
            "title": "Configuration options"
        },
        {
            "location": "/se/tracing",
            "text": " Opentracing Project OpenTelemetry API OpenTelemetry API ",
            "title": "Reference"
        },
        {
            "location": "/se/webclient",
            "text": " Overview Maven Coordinates Usage Configuring the WebClient Examples Reference ",
            "title": "Contents"
        },
        {
            "location": "/se/webclient",
            "text": " WebClient is an HTTP client for Helidon SE. It can be used to send requests and retrieve corresponding responses in a programmatic way. Helidon WebClient provides the following features: Blocking approach The Webclient uses the blocking approach to synchronously process a request and its correspond response. Both HTTP/1.1 and HTTP/2 request and response will run in the thread of the user. Additionally, for HTTP/2 , virtual thread is employed to manage the connection. Builder-like setup and execution Creates every client and request as a builder pattern. This improves readability and code maintenance. Redirect chain Follows the redirect chain and perform requests on the correct endpoint by itself. Tracing and security propagation Automatically propagates the configured tracing and security settings of the Helidon WebServer to the WebClient and uses them during request and response. ",
            "title": "Overview"
        },
        {
            "location": "/se/webclient",
            "text": " To enable WebClient add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-webclient&lt;/artifactId&gt; &lt;/dependency&gt; The helidon-webclient dependency has built-in support for HTTP/1.1 . If support for HTTP/2 is a requirement, below dependency needs to be added: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-webclient-http2&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/webclient",
            "text": " You can create an instance of a WebClient by executing WebClient.create() which will have default settings and without a base uri set. To change the default settings and register additional services, you can use simple builder that allows you to customize the client behavior. <markup lang=\"java\" title=\"Create a WebClient with simple builder:\" >WebClient client = WebClient.builder() .baseUri(\"http://localhost\") .build(); ",
            "title": "Instantiating the WebClient"
        },
        {
            "location": "/se/webclient",
            "text": " WebClient offers a set of request methods that are used to specify the type of action to be performed on a given resource. Below are some examples of request methods: get() post() put() method(String methodName) Check out HttpClient API to learn more about request methods. These methods will create a new instance of HttpClientRequest which can then be configured to add optional settings that will customize the behavior of the request. ",
            "title": "Creating the Request"
        },
        {
            "location": "/se/webclient",
            "text": " Configuration can be set for every request type before it is sent. Below are some examples of the optional parameters. Parameter Description uri(\"http://example.com\") Overrides baseUri from WebClient path(\"/path\") Adds path to the uri queryParam(\"query\", \"parameter\") Adds query parameter to the request fragment(\"someFragment\") Adds fragment to the request headers(headers &#8594; headers.addAccept(MediaType.APPLICATION_JSON)) Adds header to the request For more information about these optional parameters, check out ClientRequestBase API, which is a parent class of HttpClientRequest . HttpClientRequest class also provides specific header methods that help the user to set a particular header. Some examples of these are: contentType (MediaType contentType) accept (MediaType&#8230;&#8203; mediaTypes) For more information about these methods, check out ClientRequest API, which is a parent class of HttpClientRequest . ",
            "title": "Customizing the Request"
        },
        {
            "location": "/se/webclient",
            "text": " Once the request setup is completed, the following methods can be used to send it: HttpClientResponse request() &lt;E&gt; ClientResponseTyped&lt;E&gt; request(Class&lt;E&gt; type) &lt;E&gt; E requestEntity(Class&lt;E&gt; type) HttpClientResponse submit(Object entity) &lt;T&gt; ClientResponseTyped&lt;T&gt; submit(Object entity, Class&lt;T&gt; requestedType) HttpClientResponse outputStream(OutputStreamHandler outputStreamConsumer) &lt;T&gt; ClientResponseTyped&lt;T&gt; outputStream(OutputStreamHandler outputStreamConsumer, Class&lt;T&gt; requestedType) Each of the methods will provide a way to allow response to be retrieved in a particular response type. Refer to ClientRequest API for more details about these methods. <markup lang=\"java\" title=\"Execute a simple GET request to endpoint and receive a String response:\" >ClientResponseTyped&lt;String&gt; response = webClient.get() .path(\"/endpoint\") .request(String.class); String entityString = response.entity(); ",
            "title": "Sending the Request"
        },
        {
            "location": "/se/webclient",
            "text": " WebClient currently supports HTTP/1.1 and HTTP/2 protocols. Below are the rules on which specific protocol will be used: Using plain socket triggers WebClient to process a request using HTTP/1.1 . When using TLS, the client will use ALPN (protocol negotiation) to use appropriate HTTP version (either 1.1, or 2). HTTP/2 has a higher weight, so it is chosen if supported by both sides. A specific protocol can be explicitly selected by calling HttpClientRequest#protocolId(String) . String result = webClient.get() .protocolId(\"http/1.1\") .requestEntity(String.class); If HTTP/2 is used, an upgrade attempt will be performed. If it fails, the client falls-back to HTTP/1.1 . The parameter prior-knowledge can be defined using HTTP/2 protocol configuration. Please refer to on how to customize HTTP/2 . In such a case, prior-knowledge will be used and fail if it is unable to switch to HTTP/2 . ",
            "title": "Protocol Used"
        },
        {
            "location": "/se/webclient",
            "text": " Webclient supports the following built-in Helidon Media Support libraries: JSON Processing (JSON-P) JSON Binding (JSON-B) Jackson They can be activated by adding their corresponding libraries into the classpath. This can simply be done by adding their corresponding dependencies. <markup lang=\"xml\" title=\"Add JSON-P support:\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.http.media&lt;/groupId&gt; &lt;artifactId&gt;helidon-http-media-jsonp&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"xml\" title=\"Add JSON-B support:\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.http.media&lt;/groupId&gt; &lt;artifactId&gt;helidon-http-media-jsonb&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"xml\" title=\"Add Jackson support:\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.http.media&lt;/groupId&gt; &lt;artifactId&gt;helidon-http-media-jackson&lt;/artifactId&gt; &lt;/dependency&gt; Users can also create their own Custom Media Support library and make them work by following either of the approaches: Create a Provider of the Custom Media Support and expose it via Service Loader followed by adding the Media Support library to the classpath. Explicitly register the Custom Media Support from WebClient. <markup lang=\"java\" >WebClient webclient = WebClient.builder() .mediaContext(MediaContext.builder() .addMediaSupport(CustomMediaSupport.create()) .build()) .build() Register CustomMedia support from the WebClient. ",
            "title": "Adding Media Support"
        },
        {
            "location": "/se/webclient",
            "text": " Webclient provides three DNS resolver implementations out of the box: Java DNS resolution is the default. First DNS resolution uses the first IP address from a DNS lookup. To enable this option, add below dependency: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webclient.dns.resolver&lt;/groupId&gt; &lt;artifactId&gt;helidon-webclient-dns-resolver-first&lt;/artifactId&gt; &lt;/dependency&gt; Round-Robin DNS resolution cycles through IP addresses from a DNS lookup. To enable this option, add this dependency: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webclient.dns.resolver&lt;/groupId&gt; &lt;artifactId&gt;helidon-webclient-dns-resolver-round-robin&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "DNS Resolving"
        },
        {
            "location": "/se/webclient",
            "text": " Instantiating the WebClient You can create an instance of a WebClient by executing WebClient.create() which will have default settings and without a base uri set. To change the default settings and register additional services, you can use simple builder that allows you to customize the client behavior. <markup lang=\"java\" title=\"Create a WebClient with simple builder:\" >WebClient client = WebClient.builder() .baseUri(\"http://localhost\") .build(); Creating the Request WebClient offers a set of request methods that are used to specify the type of action to be performed on a given resource. Below are some examples of request methods: get() post() put() method(String methodName) Check out HttpClient API to learn more about request methods. These methods will create a new instance of HttpClientRequest which can then be configured to add optional settings that will customize the behavior of the request. Customizing the Request Configuration can be set for every request type before it is sent. Below are some examples of the optional parameters. Parameter Description uri(\"http://example.com\") Overrides baseUri from WebClient path(\"/path\") Adds path to the uri queryParam(\"query\", \"parameter\") Adds query parameter to the request fragment(\"someFragment\") Adds fragment to the request headers(headers &#8594; headers.addAccept(MediaType.APPLICATION_JSON)) Adds header to the request For more information about these optional parameters, check out ClientRequestBase API, which is a parent class of HttpClientRequest . HttpClientRequest class also provides specific header methods that help the user to set a particular header. Some examples of these are: contentType (MediaType contentType) accept (MediaType&#8230;&#8203; mediaTypes) For more information about these methods, check out ClientRequest API, which is a parent class of HttpClientRequest . Sending the Request Once the request setup is completed, the following methods can be used to send it: HttpClientResponse request() &lt;E&gt; ClientResponseTyped&lt;E&gt; request(Class&lt;E&gt; type) &lt;E&gt; E requestEntity(Class&lt;E&gt; type) HttpClientResponse submit(Object entity) &lt;T&gt; ClientResponseTyped&lt;T&gt; submit(Object entity, Class&lt;T&gt; requestedType) HttpClientResponse outputStream(OutputStreamHandler outputStreamConsumer) &lt;T&gt; ClientResponseTyped&lt;T&gt; outputStream(OutputStreamHandler outputStreamConsumer, Class&lt;T&gt; requestedType) Each of the methods will provide a way to allow response to be retrieved in a particular response type. Refer to ClientRequest API for more details about these methods. <markup lang=\"java\" title=\"Execute a simple GET request to endpoint and receive a String response:\" >ClientResponseTyped&lt;String&gt; response = webClient.get() .path(\"/endpoint\") .request(String.class); String entityString = response.entity(); Protocol Used WebClient currently supports HTTP/1.1 and HTTP/2 protocols. Below are the rules on which specific protocol will be used: Using plain socket triggers WebClient to process a request using HTTP/1.1 . When using TLS, the client will use ALPN (protocol negotiation) to use appropriate HTTP version (either 1.1, or 2). HTTP/2 has a higher weight, so it is chosen if supported by both sides. A specific protocol can be explicitly selected by calling HttpClientRequest#protocolId(String) . String result = webClient.get() .protocolId(\"http/1.1\") .requestEntity(String.class); If HTTP/2 is used, an upgrade attempt will be performed. If it fails, the client falls-back to HTTP/1.1 . The parameter prior-knowledge can be defined using HTTP/2 protocol configuration. Please refer to on how to customize HTTP/2 . In such a case, prior-knowledge will be used and fail if it is unable to switch to HTTP/2 . Adding Media Support Webclient supports the following built-in Helidon Media Support libraries: JSON Processing (JSON-P) JSON Binding (JSON-B) Jackson They can be activated by adding their corresponding libraries into the classpath. This can simply be done by adding their corresponding dependencies. <markup lang=\"xml\" title=\"Add JSON-P support:\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.http.media&lt;/groupId&gt; &lt;artifactId&gt;helidon-http-media-jsonp&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"xml\" title=\"Add JSON-B support:\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.http.media&lt;/groupId&gt; &lt;artifactId&gt;helidon-http-media-jsonb&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"xml\" title=\"Add Jackson support:\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.http.media&lt;/groupId&gt; &lt;artifactId&gt;helidon-http-media-jackson&lt;/artifactId&gt; &lt;/dependency&gt; Users can also create their own Custom Media Support library and make them work by following either of the approaches: Create a Provider of the Custom Media Support and expose it via Service Loader followed by adding the Media Support library to the classpath. Explicitly register the Custom Media Support from WebClient. <markup lang=\"java\" >WebClient webclient = WebClient.builder() .mediaContext(MediaContext.builder() .addMediaSupport(CustomMediaSupport.create()) .build()) .build() Register CustomMedia support from the WebClient. DNS Resolving Webclient provides three DNS resolver implementations out of the box: Java DNS resolution is the default. First DNS resolution uses the first IP address from a DNS lookup. To enable this option, add below dependency: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webclient.dns.resolver&lt;/groupId&gt; &lt;artifactId&gt;helidon-webclient-dns-resolver-first&lt;/artifactId&gt; &lt;/dependency&gt; Round-Robin DNS resolution cycles through IP addresses from a DNS lookup. To enable this option, add this dependency: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webclient.dns.resolver&lt;/groupId&gt; &lt;artifactId&gt;helidon-webclient-dns-resolver-round-robin&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Usage"
        },
        {
            "location": "/se/webclient",
            "text": " Optional configuration options key type default value description base-uri string &#160; Base uri used by the client in all requests. @return base uri of the client requests connect-timeout Duration &#160; Connect timeout. @return connect timeout @see io.helidon.common.socket.SocketOptions#connectTimeout() connection-cache-size int 256 Maximal size of the connection cache. For most HTTP protocols, we may cache connections to various endpoints for keep alive (or stream reuse in case of HTTP/2). This option limits the size. Setting this number lower than the \"usual\" number of target services will cause connections to be closed and reopened frequently. content-encoding ContentEncodingContext &#160; Configure the listener specific io.helidon.http.encoding.ContentEncodingContext. This method discards all previously registered ContentEncodingContext. If no content encoding context is registered, default encoding context is used. @return content encoding context cookie-manager WebClientCookieManager &#160; WebClient cookie manager. @return cookie manager to use default-headers Map&lt;string, string&gt; &#160; Default headers to be used in every request from configuration. @return default headers follow-redirects boolean true Whether to follow redirects. @return whether to follow redirects keep-alive boolean true Determines if connection keep alive is enabled (NOT socket keep alive, but HTTP connection keep alive, to re-use the same connection for multiple requests). @return keep alive for this connection @see io.helidon.common.socket.SocketOptions#socketKeepAlive() max-in-memory-entity int 131072 If the entity is expected to be smaller that this number of bytes, it would be buffered in memory to optimize performance. If bigger, streaming will be used. Note that for some entity types we cannot use streaming, as they are already fully in memory (String, byte[]), for such cases, this option is ignored. Default is 128Kb. @return maximal number of bytes to buffer in memory for supported writers max-redirects int 10 Max number of followed redirects. This is ignored if #followRedirects() option is false . @return max number of followed redirects media-context MediaContext create() Configure the listener specific io.helidon.http.media.MediaContext. This method discards all previously registered MediaContext. If no media context is registered, default media context is used. @return media context media-type-parser-mode ParserMode (STRICT, RELAXED) STRICT Configure media type parsing mode for HTTP Content-Type header. @return media type parsing mode properties Map&lt;string, string&gt; &#160; Properties configured for this client. These properties are propagated through client request, to be used by services (and possibly for other purposes). @return map of client properties protocol-configs io.helidon.webclient.spi.ProtocolConfig[&#93; (service provider interface) &#160; Configuration of client protocols. @return client protocol configurations proxy Proxy &#160; Proxy configuration to be used for requests. @return proxy to use, defaults to Proxy#noProxy() read-continue-timeout Duration PT1S Socket 100-Continue read timeout. Default is 1 second. This read timeout is used when 100-Continue is sent by the client, before it sends an entity. @return read 100-Continue timeout duration read-timeout Duration &#160; Read timeout. @return read timeout @see io.helidon.common.socket.SocketOptions#readTimeout() relative-uris boolean false Can be set to true to force the use of relative URIs in all requests, regardless of the presence or absence of proxies or no-proxy lists. @return relative URIs flag send-expect-continue boolean true Whether Expect-100-Continue header is sent to verify server availability before sending an entity. Defaults to `true`. @return whether Expect:100-Continue header should be sent on streamed transfers services io.helidon.webclient.spi.WebClientService[&#93; (service provider interface) &#160; WebClient services. @return services to use with this web client share-connection-cache boolean true Whether to share connection cache between all the WebClient instances in JVM. @return true if connection cache is shared socket-options SocketOptions &#160; Socket options for connections opened by this client. If there is a value explicitly configured on this type and on the socket options, the one configured on this type&#8217;s builder will win: #readTimeout() #connectTimeout() @return socket options tls Tls &#160; TLS configuration for any TLS request from this client. TLS can also be configured per request. TLS is used when the protocol is set to https . @return TLS configuration to use ",
            "title": "Configuration options"
        },
        {
            "location": "/se/webclient",
            "text": " Optional configuration options key type default value description default-keep-alive boolean true Whether to use keep alive by default. @return `true` for keeping connections alive and re-using them for multiple requests (default), `false` to create a new connection for each request max-header-size int 16384 Configure the maximum allowed header size of the response. @return maximum header size max-status-line-length int 256 Configure the maximum allowed length of the status line from the response. @return maximum status line length name string http_1_1 validate-request-headers boolean false Sets whether the request header format is validated or not. Defaults to `false` as user has control on the header creation. @return whether request header validation should be enabled validate-response-headers boolean true Sets whether the response header format is validated or not. Defaults to `true`. @return whether response header validation should be enabled HTTP/2 Type: io.helidon.webclient.http2.Http2ClientProtocolConfig ",
            "title": "Configuration options"
        },
        {
            "location": "/se/webclient",
            "text": " Optional configuration options key type default value description flow-control-block-timeout Duration PT0.1S Timeout for blocking between windows size check iterations. @return timeout initial-window-size int 65535 Configure INITIAL_WINDOW_SIZE setting for new HTTP/2 connections. Sends to the server the size of the largest frame payload client is willing to receive. Defaults to io.helidon.http.http2.WindowSize#DEFAULT_WIN_SIZE . @return units of octets max-frame-size int 16384 Configure initial MAX_FRAME_SIZE setting for new HTTP/2 connections. Maximum size of data frames in bytes the client is prepared to accept from the server. Default value is 2^14(16_384). @return data frame size in bytes between 2^14(16_384) and 2^24-1(16_777_215) max-header-list-size long -1 Configure initial MAX_HEADER_LIST_SIZE setting for new HTTP/2 connections. Sends to the server the maximum header field section size client is prepared to accept. Defaults to -1 , which means \"unconfigured\". @return units of octets name string h2 ping boolean false Check healthiness of cached connections with HTTP/2.0 ping frame. Defaults to false . @return use ping if true ping-timeout Duration PT0.5S Timeout for ping probe used for checking healthiness of cached connections. Defaults to PT0.5S , which means 500 milliseconds. @return timeout prior-knowledge boolean false Prior knowledge of HTTP/2 capabilities of the server. If server we are connecting to does not support HTTP/2 and prior knowledge is set to false , only features supported by HTTP/1 will be available and attempts to use HTTP/2 specific will throw an UnsupportedOperationException. &lt;h4&gt;Plain text connection&lt;/h4&gt; If prior knowledge is set to true , we will not attempt an upgrade of connection and use prior knowledge. If prior knowledge is set to false , we will initiate an HTTP/1 connection and upgrade it to HTTP/2, if supported by the server. plaintext connection ( h2c ). &lt;h4&gt;TLS protected connection&lt;/h4&gt; If prior knowledge is set to true , we will negotiate protocol using HTTP/2 only, failing if not supported. if prior knowledge is set to false , we will negotiate protocol using both HTTP/2 and HTTP/1, using the protocol supported by server. @return whether to use prior knowledge of HTTP/2 ",
            "title": "Configuration options"
        },
        {
            "location": "/se/webclient",
            "text": " Protocol specific configuration can be set using the protocol-configs parameter. Webclient currently supports HTTP/1.1. and HTTP/2 . Below are the options for each of the protocol type: HTTP/1.1 Type: io.helidon.webclient.http1.Http1ClientProtocolConfig Configuration options Optional configuration options key type default value description default-keep-alive boolean true Whether to use keep alive by default. @return `true` for keeping connections alive and re-using them for multiple requests (default), `false` to create a new connection for each request max-header-size int 16384 Configure the maximum allowed header size of the response. @return maximum header size max-status-line-length int 256 Configure the maximum allowed length of the status line from the response. @return maximum status line length name string http_1_1 validate-request-headers boolean false Sets whether the request header format is validated or not. Defaults to `false` as user has control on the header creation. @return whether request header validation should be enabled validate-response-headers boolean true Sets whether the response header format is validated or not. Defaults to `true`. @return whether response header validation should be enabled HTTP/2 Type: io.helidon.webclient.http2.Http2ClientProtocolConfig Configuration options Optional configuration options key type default value description flow-control-block-timeout Duration PT0.1S Timeout for blocking between windows size check iterations. @return timeout initial-window-size int 65535 Configure INITIAL_WINDOW_SIZE setting for new HTTP/2 connections. Sends to the server the size of the largest frame payload client is willing to receive. Defaults to io.helidon.http.http2.WindowSize#DEFAULT_WIN_SIZE . @return units of octets max-frame-size int 16384 Configure initial MAX_FRAME_SIZE setting for new HTTP/2 connections. Maximum size of data frames in bytes the client is prepared to accept from the server. Default value is 2^14(16_384). @return data frame size in bytes between 2^14(16_384) and 2^24-1(16_777_215) max-header-list-size long -1 Configure initial MAX_HEADER_LIST_SIZE setting for new HTTP/2 connections. Sends to the server the maximum header field section size client is prepared to accept. Defaults to -1 , which means \"unconfigured\". @return units of octets name string h2 ping boolean false Check healthiness of cached connections with HTTP/2.0 ping frame. Defaults to false . @return use ping if true ping-timeout Duration PT0.5S Timeout for ping probe used for checking healthiness of cached connections. Defaults to PT0.5S , which means 500 milliseconds. @return timeout prior-knowledge boolean false Prior knowledge of HTTP/2 capabilities of the server. If server we are connecting to does not support HTTP/2 and prior knowledge is set to false , only features supported by HTTP/1 will be available and attempts to use HTTP/2 specific will throw an UnsupportedOperationException. &lt;h4&gt;Plain text connection&lt;/h4&gt; If prior knowledge is set to true , we will not attempt an upgrade of connection and use prior knowledge. If prior knowledge is set to false , we will initiate an HTTP/1 connection and upgrade it to HTTP/2, if supported by the server. plaintext connection ( h2c ). &lt;h4&gt;TLS protected connection&lt;/h4&gt; If prior knowledge is set to true , we will negotiate protocol using HTTP/2 only, failing if not supported. if prior knowledge is set to false , we will negotiate protocol using both HTTP/2 and HTTP/1, using the protocol supported by server. @return whether to use prior knowledge of HTTP/2 ",
            "title": "Protocol Specific Configuration"
        },
        {
            "location": "/se/webclient",
            "text": "<markup lang=\"java\" >Config config = Config.create(); WebClient client = WebClient.builder() .baseUri(\"http://localhost\") .config(config.get(\"client\")) .build(); ",
            "title": "Example of a WebClient Runtime Configuration"
        },
        {
            "location": "/se/webclient",
            "text": "<markup lang=\"java\" >client: connect-timeout-millis: 2000 read-timeout-millis: 2000 follow-redirects: true max-redirects: 5 cookie-manager: automatic-store-enabled: true default-cookies: flavor3: strawberry flavor4: raspberry default-headers: Accept: '\"application/json\",\"text/plain\"' services: metrics: - methods: [\"PUT\", \"POST\", \"DELETE\"] type: METER name-format: \"client.meter.overall\" - type: TIMER # meter per method name-format: \"client.meter.%1$s\" - methods: [\"GET\"] type: COUNTER errors: false name-format: \"client.counter.%1$s.success\" description: \"Counter of successful GET requests\" - methods: [\"PUT\", \"POST\", \"DELETE\"] type: COUNTER success: false name-format: \"wc.counter.%1$s.error\" description: \"Counter of failed PUT, POST and DELETE requests\" tracing: protocol-configs: http_1_1: max-header-size: 20000 validate-request-headers: true h2: prior-knowledge: true proxy: host: \"hostName\" port: 80 no-proxy: [\"localhost:8080\", \".helidon.io\", \"192.168.1.1\"] tls: trust: keystore: passphrase: \"password\" trust-store: true resource: resource-path: \"client.p12\" Client functional settings Cookie management Default client headers Client service configuration Protocol configuration Proxy configuration TLS configuration ",
            "title": "Example of a WebClient YAML Configuration"
        },
        {
            "location": "/se/webclient",
            "text": " The class responsible for WebClient configuration is: Type: io.helidon.webclient.api.WebClient This is a standalone configuration type, prefix from configuration root: clients Configuration options Optional configuration options key type default value description base-uri string &#160; Base uri used by the client in all requests. @return base uri of the client requests connect-timeout Duration &#160; Connect timeout. @return connect timeout @see io.helidon.common.socket.SocketOptions#connectTimeout() connection-cache-size int 256 Maximal size of the connection cache. For most HTTP protocols, we may cache connections to various endpoints for keep alive (or stream reuse in case of HTTP/2). This option limits the size. Setting this number lower than the \"usual\" number of target services will cause connections to be closed and reopened frequently. content-encoding ContentEncodingContext &#160; Configure the listener specific io.helidon.http.encoding.ContentEncodingContext. This method discards all previously registered ContentEncodingContext. If no content encoding context is registered, default encoding context is used. @return content encoding context cookie-manager WebClientCookieManager &#160; WebClient cookie manager. @return cookie manager to use default-headers Map&lt;string, string&gt; &#160; Default headers to be used in every request from configuration. @return default headers follow-redirects boolean true Whether to follow redirects. @return whether to follow redirects keep-alive boolean true Determines if connection keep alive is enabled (NOT socket keep alive, but HTTP connection keep alive, to re-use the same connection for multiple requests). @return keep alive for this connection @see io.helidon.common.socket.SocketOptions#socketKeepAlive() max-in-memory-entity int 131072 If the entity is expected to be smaller that this number of bytes, it would be buffered in memory to optimize performance. If bigger, streaming will be used. Note that for some entity types we cannot use streaming, as they are already fully in memory (String, byte[]), for such cases, this option is ignored. Default is 128Kb. @return maximal number of bytes to buffer in memory for supported writers max-redirects int 10 Max number of followed redirects. This is ignored if #followRedirects() option is false . @return max number of followed redirects media-context MediaContext create() Configure the listener specific io.helidon.http.media.MediaContext. This method discards all previously registered MediaContext. If no media context is registered, default media context is used. @return media context media-type-parser-mode ParserMode (STRICT, RELAXED) STRICT Configure media type parsing mode for HTTP Content-Type header. @return media type parsing mode properties Map&lt;string, string&gt; &#160; Properties configured for this client. These properties are propagated through client request, to be used by services (and possibly for other purposes). @return map of client properties protocol-configs io.helidon.webclient.spi.ProtocolConfig[&#93; (service provider interface) &#160; Configuration of client protocols. @return client protocol configurations proxy Proxy &#160; Proxy configuration to be used for requests. @return proxy to use, defaults to Proxy#noProxy() read-continue-timeout Duration PT1S Socket 100-Continue read timeout. Default is 1 second. This read timeout is used when 100-Continue is sent by the client, before it sends an entity. @return read 100-Continue timeout duration read-timeout Duration &#160; Read timeout. @return read timeout @see io.helidon.common.socket.SocketOptions#readTimeout() relative-uris boolean false Can be set to true to force the use of relative URIs in all requests, regardless of the presence or absence of proxies or no-proxy lists. @return relative URIs flag send-expect-continue boolean true Whether Expect-100-Continue header is sent to verify server availability before sending an entity. Defaults to `true`. @return whether Expect:100-Continue header should be sent on streamed transfers services io.helidon.webclient.spi.WebClientService[&#93; (service provider interface) &#160; WebClient services. @return services to use with this web client share-connection-cache boolean true Whether to share connection cache between all the WebClient instances in JVM. @return true if connection cache is shared socket-options SocketOptions &#160; Socket options for connections opened by this client. If there is a value explicitly configured on this type and on the socket options, the one configured on this type&#8217;s builder will win: #readTimeout() #connectTimeout() @return socket options tls Tls &#160; TLS configuration for any TLS request from this client. TLS can also be configured per request. TLS is used when the protocol is set to https . @return TLS configuration to use Protocol Specific Configuration Protocol specific configuration can be set using the protocol-configs parameter. Webclient currently supports HTTP/1.1. and HTTP/2 . Below are the options for each of the protocol type: HTTP/1.1 Type: io.helidon.webclient.http1.Http1ClientProtocolConfig Configuration options Optional configuration options key type default value description default-keep-alive boolean true Whether to use keep alive by default. @return `true` for keeping connections alive and re-using them for multiple requests (default), `false` to create a new connection for each request max-header-size int 16384 Configure the maximum allowed header size of the response. @return maximum header size max-status-line-length int 256 Configure the maximum allowed length of the status line from the response. @return maximum status line length name string http_1_1 validate-request-headers boolean false Sets whether the request header format is validated or not. Defaults to `false` as user has control on the header creation. @return whether request header validation should be enabled validate-response-headers boolean true Sets whether the response header format is validated or not. Defaults to `true`. @return whether response header validation should be enabled HTTP/2 Type: io.helidon.webclient.http2.Http2ClientProtocolConfig Configuration options Optional configuration options key type default value description flow-control-block-timeout Duration PT0.1S Timeout for blocking between windows size check iterations. @return timeout initial-window-size int 65535 Configure INITIAL_WINDOW_SIZE setting for new HTTP/2 connections. Sends to the server the size of the largest frame payload client is willing to receive. Defaults to io.helidon.http.http2.WindowSize#DEFAULT_WIN_SIZE . @return units of octets max-frame-size int 16384 Configure initial MAX_FRAME_SIZE setting for new HTTP/2 connections. Maximum size of data frames in bytes the client is prepared to accept from the server. Default value is 2^14(16_384). @return data frame size in bytes between 2^14(16_384) and 2^24-1(16_777_215) max-header-list-size long -1 Configure initial MAX_HEADER_LIST_SIZE setting for new HTTP/2 connections. Sends to the server the maximum header field section size client is prepared to accept. Defaults to -1 , which means \"unconfigured\". @return units of octets name string h2 ping boolean false Check healthiness of cached connections with HTTP/2.0 ping frame. Defaults to false . @return use ping if true ping-timeout Duration PT0.5S Timeout for ping probe used for checking healthiness of cached connections. Defaults to PT0.5S , which means 500 milliseconds. @return timeout prior-knowledge boolean false Prior knowledge of HTTP/2 capabilities of the server. If server we are connecting to does not support HTTP/2 and prior knowledge is set to false , only features supported by HTTP/1 will be available and attempts to use HTTP/2 specific will throw an UnsupportedOperationException. &lt;h4&gt;Plain text connection&lt;/h4&gt; If prior knowledge is set to true , we will not attempt an upgrade of connection and use prior knowledge. If prior knowledge is set to false , we will initiate an HTTP/1 connection and upgrade it to HTTP/2, if supported by the server. plaintext connection ( h2c ). &lt;h4&gt;TLS protected connection&lt;/h4&gt; If prior knowledge is set to true , we will negotiate protocol using HTTP/2 only, failing if not supported. if prior knowledge is set to false , we will negotiate protocol using both HTTP/2 and HTTP/1, using the protocol supported by server. @return whether to use prior knowledge of HTTP/2 Example of a WebClient Runtime Configuration <markup lang=\"java\" >Config config = Config.create(); WebClient client = WebClient.builder() .baseUri(\"http://localhost\") .config(config.get(\"client\")) .build(); Example of a WebClient YAML Configuration <markup lang=\"java\" >client: connect-timeout-millis: 2000 read-timeout-millis: 2000 follow-redirects: true max-redirects: 5 cookie-manager: automatic-store-enabled: true default-cookies: flavor3: strawberry flavor4: raspberry default-headers: Accept: '\"application/json\",\"text/plain\"' services: metrics: - methods: [\"PUT\", \"POST\", \"DELETE\"] type: METER name-format: \"client.meter.overall\" - type: TIMER # meter per method name-format: \"client.meter.%1$s\" - methods: [\"GET\"] type: COUNTER errors: false name-format: \"client.counter.%1$s.success\" description: \"Counter of successful GET requests\" - methods: [\"PUT\", \"POST\", \"DELETE\"] type: COUNTER success: false name-format: \"wc.counter.%1$s.error\" description: \"Counter of failed PUT, POST and DELETE requests\" tracing: protocol-configs: http_1_1: max-header-size: 20000 validate-request-headers: true h2: prior-knowledge: true proxy: host: \"hostName\" port: 80 no-proxy: [\"localhost:8080\", \".helidon.io\", \"192.168.1.1\"] tls: trust: keystore: passphrase: \"password\" trust-store: true resource: resource-path: \"client.p12\" Client functional settings Cookie management Default client headers Client service configuration Protocol configuration Proxy configuration TLS configuration ",
            "title": "Configuring the WebClient"
        },
        {
            "location": "/se/webclient",
            "text": " Proxy can be set directly from WebClient builder. <markup lang=\"java\" >Proxy proxy = Proxy.builder() .type(Proxy.ProxyType.HTTP) .host(PROXY_HOST) .port(PROXY_PORT) .build(); WebClient webClient = WebClient.builder() .proxy(proxy) .build(); Alternative is to set proxy directly from the request via HttpClientRequest . <markup lang=\"java\" >// Using System Proxy Proxy proxy = Proxy.create(); System.setProperty(\"http.proxyHost\", PROXY_HOST); System.setProperty(\"http.proxyPort\", PROXY_PORT); System.setProperty(\"http.nonProxyHosts\", \"localhost|127.0.0.1|10.*.*.*|*.example.com|etc|\" + TARGET_HOST); webClient.get(\"/proxiedresource\").proxy(proxy).request() ",
            "title": "Configuring Proxy in your code"
        },
        {
            "location": "/se/webclient",
            "text": " Proxy can also be configured in WebClient through the application.yaml configuration file. <markup lang=\"yaml\" title=\"WebClient Proxy configuration in application.yaml \" >webclient: proxy: host: \"hostName\" port: 80 no-proxy: [\"localhost:8080\", \".helidon.io\", \"192.168.1.1\"] Then, in your application code, load the configuration from that file. <markup lang=\"java\" title=\"WebClient initialization using the application.yaml file located on the classpath\" >Config config = Config.create(); WebClient webClient = WebClient.create(config.get(\"webclient\")); ",
            "title": "Configuring Proxy in the config file"
        },
        {
            "location": "/se/webclient",
            "text": " Configure Proxy setup either programmatically or via the Helidon configuration framework. Configuring Proxy in your code Proxy can be set directly from WebClient builder. <markup lang=\"java\" >Proxy proxy = Proxy.builder() .type(Proxy.ProxyType.HTTP) .host(PROXY_HOST) .port(PROXY_PORT) .build(); WebClient webClient = WebClient.builder() .proxy(proxy) .build(); Alternative is to set proxy directly from the request via HttpClientRequest . <markup lang=\"java\" >// Using System Proxy Proxy proxy = Proxy.create(); System.setProperty(\"http.proxyHost\", PROXY_HOST); System.setProperty(\"http.proxyPort\", PROXY_PORT); System.setProperty(\"http.nonProxyHosts\", \"localhost|127.0.0.1|10.*.*.*|*.example.com|etc|\" + TARGET_HOST); webClient.get(\"/proxiedresource\").proxy(proxy).request() Configuring Proxy in the config file Proxy can also be configured in WebClient through the application.yaml configuration file. <markup lang=\"yaml\" title=\"WebClient Proxy configuration in application.yaml \" >webclient: proxy: host: \"hostName\" port: 80 no-proxy: [\"localhost:8080\", \".helidon.io\", \"192.168.1.1\"] Then, in your application code, load the configuration from that file. <markup lang=\"java\" title=\"WebClient initialization using the application.yaml file located on the classpath\" >Config config = Config.create(); WebClient webClient = WebClient.create(config.get(\"webclient\")); ",
            "title": "Webclient with Proxy"
        },
        {
            "location": "/se/webclient",
            "text": " One way to configure TLS in WebClient is in your application code as shown below. <markup lang=\"java\" >WebClient.builder() .tls(Tls.builder() .trust(trust -&gt; trust .keystore(store -&gt; store .passphrase(\"password\") .trustStore(true) .keystore(Resource.create(\"client.p12\")))) .build()) .build(); ",
            "title": "Configuring TLS in your code"
        },
        {
            "location": "/se/webclient",
            "text": " Another way to configure TLS in WebClient is through the application.yaml configuration file. <markup lang=\"yaml\" title=\"WebClient TLS configuration in application.yaml \" >webclient: tls: trust: keystore: passphrase: \"password\" trust-store: true resource: resource-path: \"client.p12\" The passphrase value on the config file can be encrypted if stronger security is required. For more information on how secrets can be encrypted using a master password and store them in a configuration file, please see Configuration Secrets . In the application code, load the settings from the configuration file. <markup lang=\"java\" title=\"WebClient initialization using the application.yaml file located on the classpath\" >Config config = Config.create(); WebClient webClient = WebClient.create(config.get(\"webclient\")); ",
            "title": "Configuring TLS in the config file"
        },
        {
            "location": "/se/webclient",
            "text": " Configure TLS either programmatically or by the Helidon configuration framework. Configuring TLS in your code One way to configure TLS in WebClient is in your application code as shown below. <markup lang=\"java\" >WebClient.builder() .tls(Tls.builder() .trust(trust -&gt; trust .keystore(store -&gt; store .passphrase(\"password\") .trustStore(true) .keystore(Resource.create(\"client.p12\")))) .build()) .build(); Configuring TLS in the config file Another way to configure TLS in WebClient is through the application.yaml configuration file. <markup lang=\"yaml\" title=\"WebClient TLS configuration in application.yaml \" >webclient: tls: trust: keystore: passphrase: \"password\" trust-store: true resource: resource-path: \"client.p12\" The passphrase value on the config file can be encrypted if stronger security is required. For more information on how secrets can be encrypted using a master password and store them in a configuration file, please see Configuration Secrets . In the application code, load the settings from the configuration file. <markup lang=\"java\" title=\"WebClient initialization using the application.yaml file located on the classpath\" >Config config = Config.create(); WebClient webClient = WebClient.create(config.get(\"webclient\")); ",
            "title": "WebClient TLS Setup"
        },
        {
            "location": "/se/webclient",
            "text": " In order for a service to function, their dependency needs to be added in the application&#8217;s pom.xml. Below are examples on how to enable the built-in services: metrics &lt;dependency&gt; &lt;groupId&gt;io.helidon.webclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-webclient-metrics&lt;/artifactId&gt; &lt;/dependency&gt; tracing &lt;dependency&gt; &lt;groupId&gt;io.helidon.webclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-webclient-tracing&lt;/artifactId&gt; &lt;/dependency&gt; security &lt;dependency&gt; &lt;groupId&gt;io.helidon.webclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-webclient-security&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Enabling the service"
        },
        {
            "location": "/se/webclient",
            "text": " Services can be added in WebClient as shown in the code below. <markup lang=\"java\" >//Creates new metric which will count all GET requests and has format of example.metric.GET.&lt;host-name&gt; WebClientService clientService = WebClientMetrics.counter() .methods(Method.GET) .nameFormat(\"example.metric.%1$s.%2$s\") .build(); //This newly created metric now needs to be registered to WebClient. WebClient client = WebClient.builder() .baseUri(url) .config(config) .addService(clientService) .build(); ",
            "title": "Adding a service in your code"
        },
        {
            "location": "/se/webclient",
            "text": " Adding service in WebClient can also be done through the application.yaml configuration file. <markup lang=\"yaml\" title=\"WebClient Service configuration in application.yaml \" >webclient: services: metrics: - type: METER name-format: \"client.meter.overall\" - type: TIMER # meter per method name-format: \"client.meter.%1$s\" - methods: [\"PUT\", \"POST\", \"DELETE\"] type: COUNTER success: false name-format: \"wc.counter.%1$s.error\" description: \"Counter of failed PUT, POST and DELETE requests\" tracing: Then, in your application code, load the configuration from that file. <markup lang=\"java\" title=\"WebClient initialization using the application.yaml file located on the classpath\" >Config config = Config.create(); WebClient webClient = WebClient.create(config.get(\"webclient\")); ",
            "title": "Adding service in the config file"
        },
        {
            "location": "/se/webclient",
            "text": " WebClient currently supports 3 built-in services namely metrics , tracing and security . Enabling the service In order for a service to function, their dependency needs to be added in the application&#8217;s pom.xml. Below are examples on how to enable the built-in services: metrics &lt;dependency&gt; &lt;groupId&gt;io.helidon.webclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-webclient-metrics&lt;/artifactId&gt; &lt;/dependency&gt; tracing &lt;dependency&gt; &lt;groupId&gt;io.helidon.webclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-webclient-tracing&lt;/artifactId&gt; &lt;/dependency&gt; security &lt;dependency&gt; &lt;groupId&gt;io.helidon.webclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-webclient-security&lt;/artifactId&gt; &lt;/dependency&gt; Adding a service in your code Services can be added in WebClient as shown in the code below. <markup lang=\"java\" >//Creates new metric which will count all GET requests and has format of example.metric.GET.&lt;host-name&gt; WebClientService clientService = WebClientMetrics.counter() .methods(Method.GET) .nameFormat(\"example.metric.%1$s.%2$s\") .build(); //This newly created metric now needs to be registered to WebClient. WebClient client = WebClient.builder() .baseUri(url) .config(config) .addService(clientService) .build(); Adding service in the config file Adding service in WebClient can also be done through the application.yaml configuration file. <markup lang=\"yaml\" title=\"WebClient Service configuration in application.yaml \" >webclient: services: metrics: - type: METER name-format: \"client.meter.overall\" - type: TIMER # meter per method name-format: \"client.meter.%1$s\" - methods: [\"PUT\", \"POST\", \"DELETE\"] type: COUNTER success: false name-format: \"wc.counter.%1$s.error\" description: \"Counter of failed PUT, POST and DELETE requests\" tracing: Then, in your application code, load the configuration from that file. <markup lang=\"java\" title=\"WebClient initialization using the application.yaml file located on the classpath\" >Config config = Config.create(); WebClient webClient = WebClient.create(config.get(\"webclient\")); ",
            "title": "Adding Service to WebClient"
        },
        {
            "location": "/se/webclient",
            "text": " Below is an example of customizing HTTP/1.1 protocol in the application code. <markup lang=\"java\" >WebClient client = WebClient.builder() .baseUri(url) .config(config.get(\"client\")) .addProtocolConfig(Http1ClientProtocolConfig.builder() .defaultKeepAlive(false) .validateRequestHeaders(true) .validateResponseHeaders(false) .build()) .build(); ",
            "title": "Setting up protocol configuration in your code"
        },
        {
            "location": "/se/webclient",
            "text": " Protocol configuration can also be set in the application.yaml configuration file. <markup lang=\"yaml\" title=\"Setting up HTTP/1.1 and HTTP/2 protocol using application.yaml file.\" >webclient: protocol-configs: http_1_1: max-header-size: 20000 validate-request-headers: true h2: prior-knowledge: true Then, in your application code, load the configuration from that file. <markup lang=\"java\" title=\"WebClient initialization using the application.yaml file located on the classpath\" >Config config = Config.create(); WebClient webClient = WebClient.create(config.get(\"webclient\")); ",
            "title": "Setting up protocol configuration in the config file"
        },
        {
            "location": "/se/webclient",
            "text": " Individual protocols can be customized using the protocol-config parameter. Setting up protocol configuration in your code Below is an example of customizing HTTP/1.1 protocol in the application code. <markup lang=\"java\" >WebClient client = WebClient.builder() .baseUri(url) .config(config.get(\"client\")) .addProtocolConfig(Http1ClientProtocolConfig.builder() .defaultKeepAlive(false) .validateRequestHeaders(true) .validateResponseHeaders(false) .build()) .build(); Setting up protocol configuration in the config file Protocol configuration can also be set in the application.yaml configuration file. <markup lang=\"yaml\" title=\"Setting up HTTP/1.1 and HTTP/2 protocol using application.yaml file.\" >webclient: protocol-configs: http_1_1: max-header-size: 20000 validate-request-headers: true h2: prior-knowledge: true Then, in your application code, load the configuration from that file. <markup lang=\"java\" title=\"WebClient initialization using the application.yaml file located on the classpath\" >Config config = Config.create(); WebClient webClient = WebClient.create(config.get(\"webclient\")); ",
            "title": "Setting Protocol configuration"
        },
        {
            "location": "/se/webclient",
            "text": " Webclient with Proxy Configure Proxy setup either programmatically or via the Helidon configuration framework. Configuring Proxy in your code Proxy can be set directly from WebClient builder. <markup lang=\"java\" >Proxy proxy = Proxy.builder() .type(Proxy.ProxyType.HTTP) .host(PROXY_HOST) .port(PROXY_PORT) .build(); WebClient webClient = WebClient.builder() .proxy(proxy) .build(); Alternative is to set proxy directly from the request via HttpClientRequest . <markup lang=\"java\" >// Using System Proxy Proxy proxy = Proxy.create(); System.setProperty(\"http.proxyHost\", PROXY_HOST); System.setProperty(\"http.proxyPort\", PROXY_PORT); System.setProperty(\"http.nonProxyHosts\", \"localhost|127.0.0.1|10.*.*.*|*.example.com|etc|\" + TARGET_HOST); webClient.get(\"/proxiedresource\").proxy(proxy).request() Configuring Proxy in the config file Proxy can also be configured in WebClient through the application.yaml configuration file. <markup lang=\"yaml\" title=\"WebClient Proxy configuration in application.yaml \" >webclient: proxy: host: \"hostName\" port: 80 no-proxy: [\"localhost:8080\", \".helidon.io\", \"192.168.1.1\"] Then, in your application code, load the configuration from that file. <markup lang=\"java\" title=\"WebClient initialization using the application.yaml file located on the classpath\" >Config config = Config.create(); WebClient webClient = WebClient.create(config.get(\"webclient\")); WebClient TLS Setup Configure TLS either programmatically or by the Helidon configuration framework. Configuring TLS in your code One way to configure TLS in WebClient is in your application code as shown below. <markup lang=\"java\" >WebClient.builder() .tls(Tls.builder() .trust(trust -&gt; trust .keystore(store -&gt; store .passphrase(\"password\") .trustStore(true) .keystore(Resource.create(\"client.p12\")))) .build()) .build(); Configuring TLS in the config file Another way to configure TLS in WebClient is through the application.yaml configuration file. <markup lang=\"yaml\" title=\"WebClient TLS configuration in application.yaml \" >webclient: tls: trust: keystore: passphrase: \"password\" trust-store: true resource: resource-path: \"client.p12\" The passphrase value on the config file can be encrypted if stronger security is required. For more information on how secrets can be encrypted using a master password and store them in a configuration file, please see Configuration Secrets . In the application code, load the settings from the configuration file. <markup lang=\"java\" title=\"WebClient initialization using the application.yaml file located on the classpath\" >Config config = Config.create(); WebClient webClient = WebClient.create(config.get(\"webclient\")); Adding Service to WebClient WebClient currently supports 3 built-in services namely metrics , tracing and security . Enabling the service In order for a service to function, their dependency needs to be added in the application&#8217;s pom.xml. Below are examples on how to enable the built-in services: metrics &lt;dependency&gt; &lt;groupId&gt;io.helidon.webclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-webclient-metrics&lt;/artifactId&gt; &lt;/dependency&gt; tracing &lt;dependency&gt; &lt;groupId&gt;io.helidon.webclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-webclient-tracing&lt;/artifactId&gt; &lt;/dependency&gt; security &lt;dependency&gt; &lt;groupId&gt;io.helidon.webclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-webclient-security&lt;/artifactId&gt; &lt;/dependency&gt; Adding a service in your code Services can be added in WebClient as shown in the code below. <markup lang=\"java\" >//Creates new metric which will count all GET requests and has format of example.metric.GET.&lt;host-name&gt; WebClientService clientService = WebClientMetrics.counter() .methods(Method.GET) .nameFormat(\"example.metric.%1$s.%2$s\") .build(); //This newly created metric now needs to be registered to WebClient. WebClient client = WebClient.builder() .baseUri(url) .config(config) .addService(clientService) .build(); Adding service in the config file Adding service in WebClient can also be done through the application.yaml configuration file. <markup lang=\"yaml\" title=\"WebClient Service configuration in application.yaml \" >webclient: services: metrics: - type: METER name-format: \"client.meter.overall\" - type: TIMER # meter per method name-format: \"client.meter.%1$s\" - methods: [\"PUT\", \"POST\", \"DELETE\"] type: COUNTER success: false name-format: \"wc.counter.%1$s.error\" description: \"Counter of failed PUT, POST and DELETE requests\" tracing: Then, in your application code, load the configuration from that file. <markup lang=\"java\" title=\"WebClient initialization using the application.yaml file located on the classpath\" >Config config = Config.create(); WebClient webClient = WebClient.create(config.get(\"webclient\")); Setting Protocol configuration Individual protocols can be customized using the protocol-config parameter. Setting up protocol configuration in your code Below is an example of customizing HTTP/1.1 protocol in the application code. <markup lang=\"java\" >WebClient client = WebClient.builder() .baseUri(url) .config(config.get(\"client\")) .addProtocolConfig(Http1ClientProtocolConfig.builder() .defaultKeepAlive(false) .validateRequestHeaders(true) .validateResponseHeaders(false) .build()) .build(); Setting up protocol configuration in the config file Protocol configuration can also be set in the application.yaml configuration file. <markup lang=\"yaml\" title=\"Setting up HTTP/1.1 and HTTP/2 protocol using application.yaml file.\" >webclient: protocol-configs: http_1_1: max-header-size: 20000 validate-request-headers: true h2: prior-knowledge: true Then, in your application code, load the configuration from that file. <markup lang=\"java\" title=\"WebClient initialization using the application.yaml file located on the classpath\" >Config config = Config.create(); WebClient webClient = WebClient.create(config.get(\"webclient\")); ",
            "title": "Examples"
        },
        {
            "location": "/se/webclient",
            "text": " Helidon Webclient API Helidon WebClient HTTP/1.1 Support Helidon WebClient HTTP/2 Support Helidon WebClient DNS Resolver First Support Helidon WebClient DNS Resolver Round Robin Support Helidon WebClient Metrics Support Helidon WebClient Security Support Helidon WebClient Tracing Support ",
            "title": "Reference"
        },
        {
            "location": "/se/webserver",
            "text": " Overview Maven Coordinates Configuration Configuring the WebServer in Your Code Configuring the WebServer in a Configuration File Configuration Options Routing Request Handling Error Handling Supported Technologies HTTP/2 Support Static Content Support Media Types Support HTTP Content Encoding Proxy Protocol Support Reference Additional Information ",
            "title": "Contents"
        },
        {
            "location": "/se/webserver",
            "text": " WebServer provides an API for creating HTTP servers. It uses virtual threads and can handle nearly unlimited concurrent requests. ",
            "title": "Overview"
        },
        {
            "location": "/se/webserver",
            "text": " To enable WebServer add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webserver&lt;/groupId&gt; &lt;artifactId&gt;helidon-webserver&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/webserver",
            "text": " The easiest way to configure the WebServer is in your application code. <markup lang=\"java\" >WebServer webServer = WebServer.builder() .address(InetAddress.getLocalHost()) .port(8080) .build(); ",
            "title": "Configuring the WebServer in Your Code"
        },
        {
            "location": "/se/webserver",
            "text": " You can also define the configuration in a file. <markup lang=\"yaml\" title=\"WebServer configuration file application.yaml \" >server: port: 8080 host: \"0.0.0.0\" Then, in your application code, load the configuration from that file. <markup lang=\"java\" title=\"WebServer initialization using the application.yaml file located on the classpath\" >Config config = Config.create(); WebServer webServer = WebServer.create(routing, config.get(\"server\")); application.yaml is a default configuration source loaded when YAML support is on classpath, so we can just use Config.create() Server expects the configuration tree located on the node of server ",
            "title": "Configuring the WebServer in a Configuration File"
        },
        {
            "location": "/se/webserver",
            "text": " Optional configuration options key type default value description backlog int 1024 Accept backlog. @return backlog connection-config ConnectionConfig &#160; Configuration of a connection (established from client against our server). @return connection configuration connection-options SocketOptions &#160; Options for connections accepted by this listener. This is not used to setup server connection. @return socket options content-encoding ContentEncodingContext &#160; Configure the listener specific io.helidon.http.encoding.ContentEncodingContext. This method discards all previously registered ContentEncodingContext. If no content encoding context is registered, content encoding context of the webserver would be used. @return content encoding context features io.helidon.webserver.spi.ServerFeature[&#93; (service provider interface) Such as: observe (ObserveFeature) context (ContextFeature) cors (CorsFeature) security (SecurityFeature) access-log (AccessLogFeature) &#160; Server features allow customization of the server, listeners, or routings. @return server features host string 0.0.0.0 Host of the default socket. Defaults to all host addresses ( 0.0.0.0 ). @return host address to listen on (for the default socket) idle-connection-period Duration PT2M How often should we check for #idleConnectionTimeout(). Defaults to PT2M (2 minutes). @return period of checking for idle connections idle-connection-timeout Duration PT5M How long should we wait before closing a connection that has no traffic on it. Defaults to PT5M (5 minutes). Note that the timestamp is refreshed max. once per second, so this setting would be useless if configured for shorter periods of time (also not a very good support for connection keep alive, if the connections are killed so soon anyway). @return timeout of idle connections max-concurrent-requests int -1 Limits the number of requests that can be executed at the same time (the number of active virtual threads of requests). Defaults to -1 , meaning \"unlimited\" - what the system allows. Also make sure that this number is higher than the expected time it takes to handle a single request in your application, as otherwise you may stop in-progress requests. @return number of requests that can be processed on this listener, regardless of protocol max-in-memory-entity int 131072 If the entity is expected to be smaller that this number of bytes, it would be buffered in memory to optimize performance when writing it. If bigger, streaming will be used. Note that for some entity types we cannot use streaming, as they are already fully in memory (String, byte[]), for such cases, this option is ignored. Default is 128Kb. @return maximal number of bytes to buffer in memory for supported writers max-payload-size long -1 Maximal number of bytes an entity may have. If io.helidon.http.HeaderNames#CONTENT_LENGTH is used, this is checked immediately, if io.helidon.http.HeaderValues#TRANSFER_ENCODING_CHUNKED is used, we will fail when the number of bytes read would exceed the max payload size. Defaults to unlimited ( -1 ). @return maximal number of bytes of entity max-tcp-connections int -1 Limits the number of connections that can be opened at a single point in time. Defaults to -1 , meaning \"unlimited\" - what the system allows. @return number of TCP connections that can be opened to this listener, regardless of protocol media-context MediaContext &#160; Configure the listener specific io.helidon.http.media.MediaContext. This method discards all previously registered MediaContext. If no media context is registered, media context of the webserver would be used. @return media context name string @default Name of this socket. Defaults to @default . Must be defined if more than one socket is needed. @return name of the socket port int 0 Port of the default socket. If configured to 0 (the default), server starts on a random port. @return port to listen on (for the default socket) protocols io.helidon.webserver.spi.ProtocolConfig[&#93; (service provider interface) &#160; Configuration of protocols. This may be either protocol selectors, or protocol upgraders from HTTP/1.1. As the order is not important (providers are ordered by weight by default), we can use a configuration as an object, such as: &lt;pre&gt; protocols: providers: http_1_1: max-prologue-length: 8192 http_2: max-frame-size: 4096 websocket: &#8230;&#8203;. &lt;/pre&gt; @return all defined protocol configurations, loaded from service loader by default receive-buffer-size int &#160; Listener receive buffer size. @return buffer size in bytes shutdown-grace-period Duration PT0.5S Grace period in ISO 8601 duration format to allow running tasks to complete before listener&#8217;s shutdown. Default is 500 milliseconds. Configuration file values example: PT0.5S , PT2S . @return grace period shutdown-hook boolean true When true the webserver registers a shutdown hook with the JVM Runtime. Defaults to true. Set this to false such that a shutdown hook is not registered. @return whether to register a shutdown hook sockets Map&lt;string, ListenerConfig&gt; &#160; Socket configurations. Note that socket named WebServer#DEFAULT_SOCKET_NAME cannot be used, configure the values on the server directly. @return map of listener configurations, except for the default one tls Tls &#160; Listener TLS configuration. @return tls of this configuration write-buffer-size int 512 Initial buffer size in bytes of java.io.BufferedOutputStream created internally to write data to a socket connection. Default is 512 . @return initial buffer size used for writing write-queue-length int 0 Number of buffers queued for write operations. @return maximal number of queued writes, defaults to 0 ",
            "title": "Configuration options"
        },
        {
            "location": "/se/webserver",
            "text": " Type: io.helidon.webserver.WebServer This is a standalone configuration type, prefix from configuration root: server Configuration options Optional configuration options key type default value description backlog int 1024 Accept backlog. @return backlog connection-config ConnectionConfig &#160; Configuration of a connection (established from client against our server). @return connection configuration connection-options SocketOptions &#160; Options for connections accepted by this listener. This is not used to setup server connection. @return socket options content-encoding ContentEncodingContext &#160; Configure the listener specific io.helidon.http.encoding.ContentEncodingContext. This method discards all previously registered ContentEncodingContext. If no content encoding context is registered, content encoding context of the webserver would be used. @return content encoding context features io.helidon.webserver.spi.ServerFeature[&#93; (service provider interface) Such as: observe (ObserveFeature) context (ContextFeature) cors (CorsFeature) security (SecurityFeature) access-log (AccessLogFeature) &#160; Server features allow customization of the server, listeners, or routings. @return server features host string 0.0.0.0 Host of the default socket. Defaults to all host addresses ( 0.0.0.0 ). @return host address to listen on (for the default socket) idle-connection-period Duration PT2M How often should we check for #idleConnectionTimeout(). Defaults to PT2M (2 minutes). @return period of checking for idle connections idle-connection-timeout Duration PT5M How long should we wait before closing a connection that has no traffic on it. Defaults to PT5M (5 minutes). Note that the timestamp is refreshed max. once per second, so this setting would be useless if configured for shorter periods of time (also not a very good support for connection keep alive, if the connections are killed so soon anyway). @return timeout of idle connections max-concurrent-requests int -1 Limits the number of requests that can be executed at the same time (the number of active virtual threads of requests). Defaults to -1 , meaning \"unlimited\" - what the system allows. Also make sure that this number is higher than the expected time it takes to handle a single request in your application, as otherwise you may stop in-progress requests. @return number of requests that can be processed on this listener, regardless of protocol max-in-memory-entity int 131072 If the entity is expected to be smaller that this number of bytes, it would be buffered in memory to optimize performance when writing it. If bigger, streaming will be used. Note that for some entity types we cannot use streaming, as they are already fully in memory (String, byte[]), for such cases, this option is ignored. Default is 128Kb. @return maximal number of bytes to buffer in memory for supported writers max-payload-size long -1 Maximal number of bytes an entity may have. If io.helidon.http.HeaderNames#CONTENT_LENGTH is used, this is checked immediately, if io.helidon.http.HeaderValues#TRANSFER_ENCODING_CHUNKED is used, we will fail when the number of bytes read would exceed the max payload size. Defaults to unlimited ( -1 ). @return maximal number of bytes of entity max-tcp-connections int -1 Limits the number of connections that can be opened at a single point in time. Defaults to -1 , meaning \"unlimited\" - what the system allows. @return number of TCP connections that can be opened to this listener, regardless of protocol media-context MediaContext &#160; Configure the listener specific io.helidon.http.media.MediaContext. This method discards all previously registered MediaContext. If no media context is registered, media context of the webserver would be used. @return media context name string @default Name of this socket. Defaults to @default . Must be defined if more than one socket is needed. @return name of the socket port int 0 Port of the default socket. If configured to 0 (the default), server starts on a random port. @return port to listen on (for the default socket) protocols io.helidon.webserver.spi.ProtocolConfig[&#93; (service provider interface) &#160; Configuration of protocols. This may be either protocol selectors, or protocol upgraders from HTTP/1.1. As the order is not important (providers are ordered by weight by default), we can use a configuration as an object, such as: &lt;pre&gt; protocols: providers: http_1_1: max-prologue-length: 8192 http_2: max-frame-size: 4096 websocket: &#8230;&#8203;. &lt;/pre&gt; @return all defined protocol configurations, loaded from service loader by default receive-buffer-size int &#160; Listener receive buffer size. @return buffer size in bytes shutdown-grace-period Duration PT0.5S Grace period in ISO 8601 duration format to allow running tasks to complete before listener&#8217;s shutdown. Default is 500 milliseconds. Configuration file values example: PT0.5S , PT2S . @return grace period shutdown-hook boolean true When true the webserver registers a shutdown hook with the JVM Runtime. Defaults to true. Set this to false such that a shutdown hook is not registered. @return whether to register a shutdown hook sockets Map&lt;string, ListenerConfig&gt; &#160; Socket configurations. Note that socket named WebServer#DEFAULT_SOCKET_NAME cannot be used, configure the values on the server directly. @return map of listener configurations, except for the default one tls Tls &#160; Listener TLS configuration. @return tls of this configuration write-buffer-size int 512 Initial buffer size in bytes of java.io.BufferedOutputStream created internally to write data to a socket connection. Default is 512 . @return initial buffer size used for writing write-queue-length int 0 Number of buffers queued for write operations. @return maximal number of queued writes, defaults to 0 ",
            "title": "Configuration Options"
        },
        {
            "location": "/se/webserver",
            "text": " You can configure the WebServer either programmatically or by the Helidon configuration framework. Configuring the WebServer in Your Code The easiest way to configure the WebServer is in your application code. <markup lang=\"java\" >WebServer webServer = WebServer.builder() .address(InetAddress.getLocalHost()) .port(8080) .build(); Configuring the WebServer in a Configuration File You can also define the configuration in a file. <markup lang=\"yaml\" title=\"WebServer configuration file application.yaml \" >server: port: 8080 host: \"0.0.0.0\" Then, in your application code, load the configuration from that file. <markup lang=\"java\" title=\"WebServer initialization using the application.yaml file located on the classpath\" >Config config = Config.create(); WebServer webServer = WebServer.create(routing, config.get(\"server\")); application.yaml is a default configuration source loaded when YAML support is on classpath, so we can just use Config.create() Server expects the configuration tree located on the node of server Configuration Options Type: io.helidon.webserver.WebServer This is a standalone configuration type, prefix from configuration root: server Configuration options Optional configuration options key type default value description backlog int 1024 Accept backlog. @return backlog connection-config ConnectionConfig &#160; Configuration of a connection (established from client against our server). @return connection configuration connection-options SocketOptions &#160; Options for connections accepted by this listener. This is not used to setup server connection. @return socket options content-encoding ContentEncodingContext &#160; Configure the listener specific io.helidon.http.encoding.ContentEncodingContext. This method discards all previously registered ContentEncodingContext. If no content encoding context is registered, content encoding context of the webserver would be used. @return content encoding context features io.helidon.webserver.spi.ServerFeature[&#93; (service provider interface) Such as: observe (ObserveFeature) context (ContextFeature) cors (CorsFeature) security (SecurityFeature) access-log (AccessLogFeature) &#160; Server features allow customization of the server, listeners, or routings. @return server features host string 0.0.0.0 Host of the default socket. Defaults to all host addresses ( 0.0.0.0 ). @return host address to listen on (for the default socket) idle-connection-period Duration PT2M How often should we check for #idleConnectionTimeout(). Defaults to PT2M (2 minutes). @return period of checking for idle connections idle-connection-timeout Duration PT5M How long should we wait before closing a connection that has no traffic on it. Defaults to PT5M (5 minutes). Note that the timestamp is refreshed max. once per second, so this setting would be useless if configured for shorter periods of time (also not a very good support for connection keep alive, if the connections are killed so soon anyway). @return timeout of idle connections max-concurrent-requests int -1 Limits the number of requests that can be executed at the same time (the number of active virtual threads of requests). Defaults to -1 , meaning \"unlimited\" - what the system allows. Also make sure that this number is higher than the expected time it takes to handle a single request in your application, as otherwise you may stop in-progress requests. @return number of requests that can be processed on this listener, regardless of protocol max-in-memory-entity int 131072 If the entity is expected to be smaller that this number of bytes, it would be buffered in memory to optimize performance when writing it. If bigger, streaming will be used. Note that for some entity types we cannot use streaming, as they are already fully in memory (String, byte[]), for such cases, this option is ignored. Default is 128Kb. @return maximal number of bytes to buffer in memory for supported writers max-payload-size long -1 Maximal number of bytes an entity may have. If io.helidon.http.HeaderNames#CONTENT_LENGTH is used, this is checked immediately, if io.helidon.http.HeaderValues#TRANSFER_ENCODING_CHUNKED is used, we will fail when the number of bytes read would exceed the max payload size. Defaults to unlimited ( -1 ). @return maximal number of bytes of entity max-tcp-connections int -1 Limits the number of connections that can be opened at a single point in time. Defaults to -1 , meaning \"unlimited\" - what the system allows. @return number of TCP connections that can be opened to this listener, regardless of protocol media-context MediaContext &#160; Configure the listener specific io.helidon.http.media.MediaContext. This method discards all previously registered MediaContext. If no media context is registered, media context of the webserver would be used. @return media context name string @default Name of this socket. Defaults to @default . Must be defined if more than one socket is needed. @return name of the socket port int 0 Port of the default socket. If configured to 0 (the default), server starts on a random port. @return port to listen on (for the default socket) protocols io.helidon.webserver.spi.ProtocolConfig[&#93; (service provider interface) &#160; Configuration of protocols. This may be either protocol selectors, or protocol upgraders from HTTP/1.1. As the order is not important (providers are ordered by weight by default), we can use a configuration as an object, such as: &lt;pre&gt; protocols: providers: http_1_1: max-prologue-length: 8192 http_2: max-frame-size: 4096 websocket: &#8230;&#8203;. &lt;/pre&gt; @return all defined protocol configurations, loaded from service loader by default receive-buffer-size int &#160; Listener receive buffer size. @return buffer size in bytes shutdown-grace-period Duration PT0.5S Grace period in ISO 8601 duration format to allow running tasks to complete before listener&#8217;s shutdown. Default is 500 milliseconds. Configuration file values example: PT0.5S , PT2S . @return grace period shutdown-hook boolean true When true the webserver registers a shutdown hook with the JVM Runtime. Defaults to true. Set this to false such that a shutdown hook is not registered. @return whether to register a shutdown hook sockets Map&lt;string, ListenerConfig&gt; &#160; Socket configurations. Note that socket named WebServer#DEFAULT_SOCKET_NAME cannot be used, configure the values on the server directly. @return map of listener configurations, except for the default one tls Tls &#160; Listener TLS configuration. @return tls of this configuration write-buffer-size int 512 Initial buffer size in bytes of java.io.BufferedOutputStream created internally to write data to a socket connection. Default is 512 . @return initial buffer size used for writing write-queue-length int 0 Number of buffers queued for write operations. @return maximal number of queued writes, defaults to 0 ",
            "title": "Configuration"
        },
        {
            "location": "/se/webserver",
            "text": " Routing also supports Error Routing which binds Java Throwable to the handling logic. Configure HTTP request routing using HttpRouting.Builder . <markup lang=\"java\" title=\"Using HttpRouting.Builder to specify how HTTP requests are handled\" >WebServer webServer = WebServer.builder() .routing(routing -&gt; routing.get(\"/hello\", (req, res) -&gt; res.send(\"Hello World!\"))) .build(); Handle all GETs to /hello path. Send the Hello World! string. Create a server instance with the provided routing ",
            "title": "Routing Basics"
        },
        {
            "location": "/se/webserver",
            "text": " HttpRouting.Builder lets you specify how to handle each HTTP method. For example: <div class=\"table__overflow elevation-1 flex sm7 \"> HTTP Method HttpRouting.Builder example GET .get((req, res) -&gt; { /* handler */ }) PUT .put((req, res) -&gt; { /* handler */ }) POST .post((req, res) -&gt; { /* handler */ }) HEAD .head((req, res) -&gt; { /* handler */ }) DELETE .delete((req, res) -&gt; { /* handler */ }) TRACE .trace((req, res) -&gt; { /* handler */ }) OPTIONS .options((req, res) -&gt; { /* handler */ }) any method .any((req, res) -&gt; { /* handler */ }) multiple methods `+.route(Method.predicate(Method.GET, Method.POST), PathMatchers.any(), (req, res) &#8594; { /* handler */ }) custom method +.route(Method.create(\"CUSTOM\"), (req, res) &#8594; { /* handler */ }) ",
            "title": "HTTP Method Routing"
        },
        {
            "location": "/se/webserver",
            "text": " You can combine HTTP method routing with request path matching. <markup lang=\"java\" >HttpRouting.builder() .post(\"/some/path\", (req, res) -&gt; { /* handler */ }) You can use path pattern instead of path with the following syntax: /foo/bar/baz - Exact path match against resolved path even with non-usual characters /foo/* - convenience method to match /foo or any subpath (but not /foobar ) /foo/{}/baz - {} Unnamed regular expression segment ([^/]+) /foo/{var}/baz - Named regular expression segment ([^/]+) /foo/{var:\\d+} - Named regular expression segment with a specified expression /foo/{:\\d+} - Unnamed regular expression segment with a specified expression /foo/{+var} - Convenience shortcut for {var:.+}. A matcher is not a true URI template (as defined by RFC) but this convenience is in sync with the Apiary templates /foo/{+} - Convenience shortcut for unnamed segment with regular expression {:.+} /foo[/bar] - An optional block, which translates to the /foo(/bar)? regular expression / or /foo - * Wildcard character can be matched with any number of characters. Path (matcher) routing is exact . For example, a /foo/bar request is not routed to .post('/foo', &#8230;&#8203;) . Always start path and path patterns with the / character. For more precise setup of path, you can use factory methods on io.helidon.http.PathMatchers and register using HttpRouting.Builder.route(Predicate&lt;Method&gt;, PathMatcher, Handler) method. ",
            "title": "Path Matcher Routing"
        },
        {
            "location": "/se/webserver",
            "text": " To have more control over selecting which requests should be handled by a specific route, you can use the io.helidon.webserver.http.HttpRoute interface, and either setup a route using its Builder , or implement the interface directly. The HttpRoute is queried base on the request io.helidon.http.HttpPrologue . <markup lang=\"java\" >.route(new MyCustomRoute()); ",
            "title": "Using full HttpRoute "
        },
        {
            "location": "/se/webserver",
            "text": " By implementing the io.helidon.webserver.http.HttpService interface you can organize your code into one or more services, each with its own path prefix and set of handlers. <markup lang=\"java\" title=\"Use HttpRouting.Builder.register to register your service\" >.register(\"/hello\", new HelloService()) <markup lang=\"java\" title=\"Service implementation\" >public class HelloService implements HttpService { @Override public void routing(HttpRules rules) { rules.get(\"/subpath\", this::getHandler); } private void getHandler(ServerRequest request, ServerResponse response) { // Some logic } } In this example, the GET handler matches requests to /hello/subpath . ",
            "title": "Organizing Code into Services"
        },
        {
            "location": "/se/webserver",
            "text": " Routing lets you use request matching criteria to bind requests to a handler that implements your custom business logic. Matching criteria include one or more HTTP Method(s) and, optionally, a request path matcher . Use the RequestPredicate class to specify more routing criteria. Routing Basics Routing also supports Error Routing which binds Java Throwable to the handling logic. Configure HTTP request routing using HttpRouting.Builder . <markup lang=\"java\" title=\"Using HttpRouting.Builder to specify how HTTP requests are handled\" >WebServer webServer = WebServer.builder() .routing(routing -&gt; routing.get(\"/hello\", (req, res) -&gt; res.send(\"Hello World!\"))) .build(); Handle all GETs to /hello path. Send the Hello World! string. Create a server instance with the provided routing HTTP Method Routing HttpRouting.Builder lets you specify how to handle each HTTP method. For example: <div class=\"table__overflow elevation-1 flex sm7 \"> HTTP Method HttpRouting.Builder example GET .get((req, res) -&gt; { /* handler */ }) PUT .put((req, res) -&gt; { /* handler */ }) POST .post((req, res) -&gt; { /* handler */ }) HEAD .head((req, res) -&gt; { /* handler */ }) DELETE .delete((req, res) -&gt; { /* handler */ }) TRACE .trace((req, res) -&gt; { /* handler */ }) OPTIONS .options((req, res) -&gt; { /* handler */ }) any method .any((req, res) -&gt; { /* handler */ }) multiple methods `+.route(Method.predicate(Method.GET, Method.POST), PathMatchers.any(), (req, res) &#8594; { /* handler */ }) custom method +.route(Method.create(\"CUSTOM\"), (req, res) &#8594; { /* handler */ }) Path Matcher Routing You can combine HTTP method routing with request path matching. <markup lang=\"java\" >HttpRouting.builder() .post(\"/some/path\", (req, res) -&gt; { /* handler */ }) You can use path pattern instead of path with the following syntax: /foo/bar/baz - Exact path match against resolved path even with non-usual characters /foo/* - convenience method to match /foo or any subpath (but not /foobar ) /foo/{}/baz - {} Unnamed regular expression segment ([^/]+) /foo/{var}/baz - Named regular expression segment ([^/]+) /foo/{var:\\d+} - Named regular expression segment with a specified expression /foo/{:\\d+} - Unnamed regular expression segment with a specified expression /foo/{+var} - Convenience shortcut for {var:.+}. A matcher is not a true URI template (as defined by RFC) but this convenience is in sync with the Apiary templates /foo/{+} - Convenience shortcut for unnamed segment with regular expression {:.+} /foo[/bar] - An optional block, which translates to the /foo(/bar)? regular expression / or /foo - * Wildcard character can be matched with any number of characters. Path (matcher) routing is exact . For example, a /foo/bar request is not routed to .post('/foo', &#8230;&#8203;) . Always start path and path patterns with the / character. For more precise setup of path, you can use factory methods on io.helidon.http.PathMatchers and register using HttpRouting.Builder.route(Predicate&lt;Method&gt;, PathMatcher, Handler) method. Using full HttpRoute To have more control over selecting which requests should be handled by a specific route, you can use the io.helidon.webserver.http.HttpRoute interface, and either setup a route using its Builder , or implement the interface directly. The HttpRoute is queried base on the request io.helidon.http.HttpPrologue . <markup lang=\"java\" >.route(new MyCustomRoute()); Organizing Code into Services By implementing the io.helidon.webserver.http.HttpService interface you can organize your code into one or more services, each with its own path prefix and set of handlers. <markup lang=\"java\" title=\"Use HttpRouting.Builder.register to register your service\" >.register(\"/hello\", new HelloService()) <markup lang=\"java\" title=\"Service implementation\" >public class HelloService implements HttpService { @Override public void routing(HttpRules rules) { rules.get(\"/subpath\", this::getHandler); } private void getHandler(ServerRequest request, ServerResponse response) { // Some logic } } In this example, the GET handler matches requests to /hello/subpath . ",
            "title": "Routing"
        },
        {
            "location": "/se/webserver",
            "text": " Each Handler has two parameters. ServerRequest and ServerResponse . Request provides access to the request method, URI, path, query parameters, headers and entity. Response provides an ability to set response code, headers, and entity. ",
            "title": "Process Request and Produce Response"
        },
        {
            "location": "/se/webserver",
            "text": " You can register a io.helidon.webserver.http.Filter with HTTP routing to handle filtering in interception style. A simple filter example: <markup lang=\"java\" >routing.addFilter((chain, req, res) -&gt; { try { chain.proceed(); } finally { // do something for any finished request } }) ",
            "title": "Filter"
        },
        {
            "location": "/se/webserver",
            "text": " The handler forwards the request to the downstream handlers by nexting . There are two options: call res.next() <markup lang=\"java\" >.any(\"/hello\", (req, res) -&gt; { // filtering logic res.next(); }) handler for any HTTP method using the /hello path business logic implementation forward the current request to the downstream handler throw an exception to forward to error handling error handling <markup lang=\"java\" >.any(\"/hello\", (req, res) -&gt; { // filtering logic (e.g., validating parameters) if (userParametersOk()) { res.next(); } else { throw new IllegalArgumentException(\"Invalid parameters.\"); } }) handler for any HTTP method using the /hello path custom logic forward the current request to the downstream handler forward the request to the error handler ",
            "title": "Routes"
        },
        {
            "location": "/se/webserver",
            "text": " Filtering can be done either using a dedicated Filter , or through routes. Filter You can register a io.helidon.webserver.http.Filter with HTTP routing to handle filtering in interception style. A simple filter example: <markup lang=\"java\" >routing.addFilter((chain, req, res) -&gt; { try { chain.proceed(); } finally { // do something for any finished request } }) Routes The handler forwards the request to the downstream handlers by nexting . There are two options: call res.next() <markup lang=\"java\" >.any(\"/hello\", (req, res) -&gt; { // filtering logic res.next(); }) handler for any HTTP method using the /hello path business logic implementation forward the current request to the downstream handler throw an exception to forward to error handling error handling <markup lang=\"java\" >.any(\"/hello\", (req, res) -&gt; { // filtering logic (e.g., validating parameters) if (userParametersOk()) { res.next(); } else { throw new IllegalArgumentException(\"Invalid parameters.\"); } }) handler for any HTTP method using the /hello path custom logic forward the current request to the downstream handler forward the request to the error handler ",
            "title": "Filtering"
        },
        {
            "location": "/se/webserver",
            "text": " To complete the request handling, you must send a response by calling the res.send() method. one of the variants of send method MUST be invoked in the same thread the request is started in; as we run in Virtual Threads, you can simply wait for any asynchronous tasks that must complete before sending a response <markup lang=\"java\" >.get(\"/hello\", (req, res) -&gt; { // terminating logic res.status(Status.ACCEPTED_202) .send(\"Saved!\"); }) handler that terminates the request handling for any HTTP method using the /hello path send the response ",
            "title": "Sending a Response"
        },
        {
            "location": "/se/webserver",
            "text": " Implement the logic to handle requests to WebServer in a Handler , which is a FunctionalInterface . Handlers: Process the request and send a response. Act as a filter and forward requests to downstream handlers using the response.next() method. Throw an exception to begin error handling . Process Request and Produce Response Each Handler has two parameters. ServerRequest and ServerResponse . Request provides access to the request method, URI, path, query parameters, headers and entity. Response provides an ability to set response code, headers, and entity. Filtering Filtering can be done either using a dedicated Filter , or through routes. Filter You can register a io.helidon.webserver.http.Filter with HTTP routing to handle filtering in interception style. A simple filter example: <markup lang=\"java\" >routing.addFilter((chain, req, res) -&gt; { try { chain.proceed(); } finally { // do something for any finished request } }) Routes The handler forwards the request to the downstream handlers by nexting . There are two options: call res.next() <markup lang=\"java\" >.any(\"/hello\", (req, res) -&gt; { // filtering logic res.next(); }) handler for any HTTP method using the /hello path business logic implementation forward the current request to the downstream handler throw an exception to forward to error handling error handling <markup lang=\"java\" >.any(\"/hello\", (req, res) -&gt; { // filtering logic (e.g., validating parameters) if (userParametersOk()) { res.next(); } else { throw new IllegalArgumentException(\"Invalid parameters.\"); } }) handler for any HTTP method using the /hello path custom logic forward the current request to the downstream handler forward the request to the error handler Sending a Response To complete the request handling, you must send a response by calling the res.send() method. one of the variants of send method MUST be invoked in the same thread the request is started in; as we run in Virtual Threads, you can simply wait for any asynchronous tasks that must complete before sending a response <markup lang=\"java\" >.get(\"/hello\", (req, res) -&gt; { // terminating logic res.status(Status.ACCEPTED_202) .send(\"Saved!\"); }) handler that terminates the request handling for any HTTP method using the /hello path send the response ",
            "title": "Request Handling"
        },
        {
            "location": "/se/webserver",
            "text": " Handling routes based on the protocol version is possible by registering specific routes on routing builder. <markup lang=\"java\" title=\"Routing based on HTTP version\" >.routing(r -&gt; r .get(\"/any-version\", (req, res) -&gt; res.send(\"HTTP Version \" + req.prologue().protocolVersion())) .route(Http1Route.route(Method.GET, \"/version-specific\", (req, res) -&gt; res.send(\"HTTP/1.1 route\"))) .route(Http2Route.route(Method.GET, \"/version-specific\", (req, res) -&gt; res.send(\"HTTP/2 route\"))) ) An HTTP route registered on /any-version path that prints the version of HTTP protocol An HTTP/1.1 route registered on /version-specific path An HTTP/2 route registered on /version-specific path While Http1Route for Http/1 is always available with Helidon webserver, other routes like Http2Route for HTTP/2 needs to be added as additional dependency. ",
            "title": "Protocol-Specific Routing"
        },
        {
            "location": "/se/webserver",
            "text": " To set up requested URI discovery on the default socket for your server, use the WebServer.Builder : <markup lang=\"java\" title=\"Requested URI set-up for the default server socket\" >import io.helidon.common.configurable.AllowList; import static io.helidon.http.RequestedUriDiscoveryContext.RequestedUriDiscoveryType.FORWARDED; import static io.helidon.http.RequestedUriDiscoveryContext.RequestedUriDiscoveryType.X_FORWARDED; AllowList trustedProxies = AllowList.builder() .addAllowedPattern(Pattern.compile(\"lb.+\\\\.mycorp\\\\.com\")) .addDenied(\"lbtest.mycorp.com\") .build(); WebServer.Builder builder = WebServer.builder() .host(\"localhost\") .requestedUriDiscoveryContext(it -&gt; it.addDiscoveryType(FORWARDED) .addDiscoveryType(X_FORWARDED) .trustedProxies(trustedProxies)) .routing(Main::routing) .config(serverConfig); Create the AllowList describing the intermediate networks nodes to trust and not trust. Presumably the lbxxx.mycorp.com nodes are trusted load balancers except for the test load balancer lbtest , and no other nodes are trusted. AllowList accepts prefixes, suffixes, predicates, regex patterns, and exact matches. See the AllowList JavaDoc for complete information. Use Forwarded first, then try X-Forwarded-* on each request. Set the AllowList for trusted intermediaries. If you build your server with additional sockets, you can control requested URI discovery separately for each. ",
            "title": "Setting Up Requested URI Discovery Programmatically"
        },
        {
            "location": "/se/webserver",
            "text": " You can also use configuration to set up the requested URI discovery behavior. The following example replicates the settings assigned programmatically in the earlier code example: <markup lang=\"yaml\" title=\"Configuring requested URI behavior\" >server: port: 0 requested-uri-discovery: types: FORWARDED,X_FORWARDED trusted-proxies: allow: pattern: \"lb.*\\\\.mycorp\\\\.com\" deny: exact: \"lbtest.mycorp.com\"\" ",
            "title": "Setting Up Requested URI Discovery using Configuration"
        },
        {
            "location": "/se/webserver",
            "text": " Your code obtains the requested URI information from the Helidon server request object: <markup lang=\"java\" title=\"Retrieving Requested URI Information\" >import io.helidon.common.uri.UriInfo; public class MyHandler implements Handler { @Override public void accept(ServerRequest req, ServerResponse res) { UriInfo uriInfo = req.requestedUri(); // ... } } See the UriInfo JavaDoc for more information. ",
            "title": "Obtaining the Requested URI Information"
        },
        {
            "location": "/se/webserver",
            "text": " Proxies and reverse proxies between an HTTP client and your Helidon application mask important information (for example Host header, originating IP address, protocol) about the request the client sent. Fortunately, many of these intermediary network nodes set or update either the standard HTTP Forwarded header or the non-standard X-Forwarded-* family of headers to preserve information about the original client request. Helidon&#8217;s requested URI discovery feature allows your application&#8212;&#8203;and Helidon itself&#8212;&#8203;to reconstruct information about the original request using the Forwarded header and the X-Forwarded-* family of headers. When you prepare the connections in your server you can include the following optional requested URI discovery settings: enabled or disabled which type or types of requested URI discovery to use: FORWARDED - uses the Forwarded header X_FORWARDED - uses the X-Forwarded-* headers HOST - uses the Host header what intermediate nodes to trust When your application invokes request.requestedUri() Helidon iterates through the discovery types you set up for the receiving connection, gathering information from the corresponding header(s) for that type. If the request does not have the corresponding header(s), or your settings do not trust the intermediate nodes reflected in those headers, then Helidon tries the next discovery type you set up. Helidon uses the HOST discovery type if you do not set up discovery yourself or if, for a particular request, it cannot assemble the request information using any discovery type you did set up for the socket. Setting Up Requested URI Discovery Programmatically To set up requested URI discovery on the default socket for your server, use the WebServer.Builder : <markup lang=\"java\" title=\"Requested URI set-up for the default server socket\" >import io.helidon.common.configurable.AllowList; import static io.helidon.http.RequestedUriDiscoveryContext.RequestedUriDiscoveryType.FORWARDED; import static io.helidon.http.RequestedUriDiscoveryContext.RequestedUriDiscoveryType.X_FORWARDED; AllowList trustedProxies = AllowList.builder() .addAllowedPattern(Pattern.compile(\"lb.+\\\\.mycorp\\\\.com\")) .addDenied(\"lbtest.mycorp.com\") .build(); WebServer.Builder builder = WebServer.builder() .host(\"localhost\") .requestedUriDiscoveryContext(it -&gt; it.addDiscoveryType(FORWARDED) .addDiscoveryType(X_FORWARDED) .trustedProxies(trustedProxies)) .routing(Main::routing) .config(serverConfig); Create the AllowList describing the intermediate networks nodes to trust and not trust. Presumably the lbxxx.mycorp.com nodes are trusted load balancers except for the test load balancer lbtest , and no other nodes are trusted. AllowList accepts prefixes, suffixes, predicates, regex patterns, and exact matches. See the AllowList JavaDoc for complete information. Use Forwarded first, then try X-Forwarded-* on each request. Set the AllowList for trusted intermediaries. If you build your server with additional sockets, you can control requested URI discovery separately for each. Setting Up Requested URI Discovery using Configuration You can also use configuration to set up the requested URI discovery behavior. The following example replicates the settings assigned programmatically in the earlier code example: <markup lang=\"yaml\" title=\"Configuring requested URI behavior\" >server: port: 0 requested-uri-discovery: types: FORWARDED,X_FORWARDED trusted-proxies: allow: pattern: \"lb.*\\\\.mycorp\\\\.com\" deny: exact: \"lbtest.mycorp.com\"\" Obtaining the Requested URI Information Your code obtains the requested URI information from the Helidon server request object: <markup lang=\"java\" title=\"Retrieving Requested URI Information\" >import io.helidon.common.uri.UriInfo; public class MyHandler implements Handler { @Override public void accept(ServerRequest req, ServerResponse res) { UriInfo uriInfo = req.requestedUri(); // ... } } See the UriInfo JavaDoc for more information. ",
            "title": "Requested URI Discovery"
        },
        {
            "location": "/se/webserver",
            "text": " You may register an error handler for a specific Throwable in a HttpRouting.Builder method. <markup lang=\"java\" >HttpRouting.Builder routing = HttpRouting.builder() .error(MyException.class, (req, res, ex) -&gt; { // handle the error, set the HTTP status code res.send(errorDescriptionObject); }); Registers an error handler that handles MyException that are thrown from the upstream handlers Finishes the request handling by sending a response Error handlers are called when an exception is thrown from a handler As with the standard handlers, the error handler must either send a response <markup lang=\"java\" >.error(MyException.class, (req, res, ex) -&gt; { res.status(Http.Status.BAD_REQUEST_400); res.send(\"Unable to parse request. Message: \" + ex.getMessage()); }) or throw an exception <markup lang=\"java\" >.error(Throwable.class, (req, res, ex) -&gt; { // some logic throw ex; }) Exceptions thrown from error handlers are not error handled, and will end up in an InternalServerError. ",
            "title": "Error Routing"
        },
        {
            "location": "/se/webserver",
            "text": " If no user-defined error handler is matched, or if the error handler of the exception threw an exception, then the exception is translated to an HTTP response as follows: Subtypes of HttpException are translated to their associated HTTP error codes. <markup lang=\"java\" title=\"Reply with the 406 HTTP error code by throwing an exception\" >(req, res) -&gt; throw new HttpException(\"Amount of money must be greater than 0.\", Http.Status.NOT_ACCEPTABLE_406) Otherwise, the exceptions are translated to an Internal Server Error HTTP error code 500 . ",
            "title": "Default Error Handling"
        },
        {
            "location": "/se/webserver",
            "text": " Error Routing You may register an error handler for a specific Throwable in a HttpRouting.Builder method. <markup lang=\"java\" >HttpRouting.Builder routing = HttpRouting.builder() .error(MyException.class, (req, res, ex) -&gt; { // handle the error, set the HTTP status code res.send(errorDescriptionObject); }); Registers an error handler that handles MyException that are thrown from the upstream handlers Finishes the request handling by sending a response Error handlers are called when an exception is thrown from a handler As with the standard handlers, the error handler must either send a response <markup lang=\"java\" >.error(MyException.class, (req, res, ex) -&gt; { res.status(Http.Status.BAD_REQUEST_400); res.send(\"Unable to parse request. Message: \" + ex.getMessage()); }) or throw an exception <markup lang=\"java\" >.error(Throwable.class, (req, res, ex) -&gt; { // some logic throw ex; }) Exceptions thrown from error handlers are not error handled, and will end up in an InternalServerError. Default Error Handling If no user-defined error handler is matched, or if the error handler of the exception threw an exception, then the exception is translated to an HTTP response as follows: Subtypes of HttpException are translated to their associated HTTP error codes. <markup lang=\"java\" title=\"Reply with the 406 HTTP error code by throwing an exception\" >(req, res) -&gt; throw new HttpException(\"Amount of money must be greater than 0.\", Http.Status.NOT_ACCEPTABLE_406) Otherwise, the exceptions are translated to an Internal Server Error HTTP error code 500 . ",
            "title": "Error Handling"
        },
        {
            "location": "/se/webserver",
            "text": "",
            "title": "Supported Technologies"
        },
        {
            "location": "/se/webserver",
            "text": " To enable HTTP/2 support add the following dependency to your project&#8217;s pom.xml . <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webserver&lt;/groupId&gt; &lt;artifactId&gt;helidon-webserver-http2&lt;/artifactId&gt;&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/webserver",
            "text": " Helidon supports HTTP/2 upgrade from HTTP/1, HTTP/2 without prior knowledge, HTTP/2 with prior knowledge, and HTTP/2 with ALPN over TLS. HTTP/2 support is enabled in WebServer by default when it&#8217;s artifact is available on classpath. Maven Coordinates To enable HTTP/2 support add the following dependency to your project&#8217;s pom.xml . <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webserver&lt;/groupId&gt; &lt;artifactId&gt;helidon-webserver-http2&lt;/artifactId&gt;&gt; &lt;/dependency&gt; ",
            "title": "HTTP/2 Support"
        },
        {
            "location": "/se/webserver",
            "text": " To enable Static Content Support add the following dependency to your project&#8217;s pom.xml . <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webserver&lt;/groupId&gt; &lt;artifactId&gt;helidon-webserver-static-content&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/webserver",
            "text": " To register static content based on a file system ( /pictures ), and classpath ( / ): <markup lang=\"java\" >HttpRouting.builder() .register(\"/pictures\", StaticContentService.create(Paths.get(\"/some/WEB/pics\"))) .register(\"/\", StaticContentService.builder(\"/static-content\") .welcomeFileName(\"index.html\") .build()); Create a new StaticContentService object to serve data from the file system, and associate it with the \"/pictures\" context path. Create a StaticContentService object to serve resources from the contextual ClassLoader . The specific classloader can be also defined. A builder lets you provide more configuration values. index.html is the file that is returned if a directory is requested. A StaticContentService object can be created using create(&#8230;&#8203;) factory methods or a builder . The builder lets you provide more configuration values, including welcome file-name and mappings of filename extensions to media types. ",
            "title": "Registering Static Content"
        },
        {
            "location": "/se/webserver",
            "text": " +Use the io.helidon.webserver.staticcontent.StaticContentService class to serve files and classpath resources. StaticContentService can be created for any readable directory or classpath context root and registered on a path in HttpRouting . You can combine dynamic handlers with StaticContentService objects: if no file matches the request path, then the request is forwarded to the next handler. Maven Coordinates To enable Static Content Support add the following dependency to your project&#8217;s pom.xml . <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webserver&lt;/groupId&gt; &lt;artifactId&gt;helidon-webserver-static-content&lt;/artifactId&gt; &lt;/dependency&gt; Registering Static Content To register static content based on a file system ( /pictures ), and classpath ( / ): <markup lang=\"java\" >HttpRouting.builder() .register(\"/pictures\", StaticContentService.create(Paths.get(\"/some/WEB/pics\"))) .register(\"/\", StaticContentService.builder(\"/static-content\") .welcomeFileName(\"index.html\") .build()); Create a new StaticContentService object to serve data from the file system, and associate it with the \"/pictures\" context path. Create a StaticContentService object to serve resources from the contextual ClassLoader . The specific classloader can be also defined. A builder lets you provide more configuration values. index.html is the file that is returned if a directory is requested. A StaticContentService object can be created using create(&#8230;&#8203;) factory methods or a builder . The builder lets you provide more configuration values, including welcome file-name and mappings of filename extensions to media types. ",
            "title": "Static Content Support"
        },
        {
            "location": "/se/webserver",
            "text": " To enable JSON Support add the following dependency to your project&#8217;s pom.xml . <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.http.media&lt;/groupId&gt; &lt;artifactId&gt;helidon-http-media-jsonp&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/webserver",
            "text": "<markup lang=\"java\" title=\"Handler that receives and returns JSON objects\" >private static final JsonBuilderFactory JSON_FACTORY = Json.createBuilderFactory(Collections.emptyMap()); private void sayHello(ServerRequest req, ServerResponse res, JsonObject json) { JsonObject msg = JSON_FACTORY.createObjectBuilder() .add(\"message\", \"Hello \" + json.getString(\"name\")) .build(); res.send(msg); } Using a JsonBuilderFactory is more efficient than Json.createObjectBuilder() JsonObject is passed to handler Create a JsonObject using JSON-P to hold return data Send JsonObject in response <markup lang=\"bash\" title=\"Example of posting JSON to sayHello endpoint\" >curl --noproxy '*' -X POST -H \"Content-Type: application/json\" \\ http://localhost:8080/sayhello -d '{\"name\":\"Joe\"}' <markup lang=\"json\" title=\"Response body\" >{\"message\":\"Hello Joe\"} ",
            "title": "Usage"
        },
        {
            "location": "/se/webserver",
            "text": " The WebServer supports JSON-P. When enabled, you can send and receive JSON-P objects transparently. Maven Coordinates To enable JSON Support add the following dependency to your project&#8217;s pom.xml . <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.http.media&lt;/groupId&gt; &lt;artifactId&gt;helidon-http-media-jsonp&lt;/artifactId&gt; &lt;/dependency&gt; Usage <markup lang=\"java\" title=\"Handler that receives and returns JSON objects\" >private static final JsonBuilderFactory JSON_FACTORY = Json.createBuilderFactory(Collections.emptyMap()); private void sayHello(ServerRequest req, ServerResponse res, JsonObject json) { JsonObject msg = JSON_FACTORY.createObjectBuilder() .add(\"message\", \"Hello \" + json.getString(\"name\")) .build(); res.send(msg); } Using a JsonBuilderFactory is more efficient than Json.createObjectBuilder() JsonObject is passed to handler Create a JsonObject using JSON-P to hold return data Send JsonObject in response <markup lang=\"bash\" title=\"Example of posting JSON to sayHello endpoint\" >curl --noproxy '*' -X POST -H \"Content-Type: application/json\" \\ http://localhost:8080/sayhello -d '{\"name\":\"Joe\"}' <markup lang=\"json\" title=\"Response body\" >{\"message\":\"Hello Joe\"} ",
            "title": "JSON-P Support"
        },
        {
            "location": "/se/webserver",
            "text": " To enable JSON-B Support add the following dependency to your project&#8217;s pom.xml . <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.http.media&lt;/groupId&gt; &lt;artifactId&gt;helidon-http-media-jsonb&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/webserver",
            "text": " Now that automatic JSON serialization and deserialization facilities have been set up, you can register a Handler that works with Java objects instead of raw JSON. Deserialization from and serialization to JSON will be handled according to the JSON-B specification . Suppose you have a Person class that looks like this: <markup lang=\"java\" title=\"Hypothetical Person class\" >public class Person { private String name; public Person() { super(); } public String getName() { return this.name; } public void setName(String name) { this.name = name; } } Then you can set up a Handler like this: <markup lang=\"java\" title=\"A Handler that works with Java objects instead of raw JSON\" >HttpRouting.Builder routing = routingBuilder.post(\"/echo\", (req, res) -&gt; res.send(req.content().as(Person.class))); This handler consumes a Person instance and simply echoes it back. Note that there is no working with raw JSON here. <markup lang=\"bash\" title=\"Example of posting JSON to the /echo endpoint\" >curl --noproxy '*' -X POST -H \"Content-Type: application/json\" \\ http://localhost:8080/echo -d '{\"name\":\"Joe\"}' {\"name\":\"Joe\"} ",
            "title": "Usage"
        },
        {
            "location": "/se/webserver",
            "text": " The WebServer supports the JSON-B specification . When this support is enabled, Java objects will be serialized to and deserialized from JSON automatically using Yasson , an implementation of the JSON-B specification . Maven Coordinates To enable JSON-B Support add the following dependency to your project&#8217;s pom.xml . <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.http.media&lt;/groupId&gt; &lt;artifactId&gt;helidon-http-media-jsonb&lt;/artifactId&gt; &lt;/dependency&gt; Usage Now that automatic JSON serialization and deserialization facilities have been set up, you can register a Handler that works with Java objects instead of raw JSON. Deserialization from and serialization to JSON will be handled according to the JSON-B specification . Suppose you have a Person class that looks like this: <markup lang=\"java\" title=\"Hypothetical Person class\" >public class Person { private String name; public Person() { super(); } public String getName() { return this.name; } public void setName(String name) { this.name = name; } } Then you can set up a Handler like this: <markup lang=\"java\" title=\"A Handler that works with Java objects instead of raw JSON\" >HttpRouting.Builder routing = routingBuilder.post(\"/echo\", (req, res) -&gt; res.send(req.content().as(Person.class))); This handler consumes a Person instance and simply echoes it back. Note that there is no working with raw JSON here. <markup lang=\"bash\" title=\"Example of posting JSON to the /echo endpoint\" >curl --noproxy '*' -X POST -H \"Content-Type: application/json\" \\ http://localhost:8080/echo -d '{\"name\":\"Joe\"}' {\"name\":\"Joe\"} ",
            "title": "JSON-B Support"
        },
        {
            "location": "/se/webserver",
            "text": " To enable Jackson Support add the following dependency to your project&#8217;s pom.xml . <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.http.media&lt;/groupId&gt; &lt;artifactId&gt;helidon-http-media-jackson&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/webserver",
            "text": " Now that automatic JSON serialization and deserialization facilities have been set up, you can register a Handler that works with Java objects instead of raw JSON. Deserialization from and serialization to JSON will be handled by Jackson . Suppose you have a Person class that looks like this: <markup lang=\"java\" title=\"Hypothetical Person class\" >public class Person { private String name; public Person() { super(); } public String getName() { return this.name; } public void setName(final String name) { this.name = name; } } Then you can set up a Handler like this: <markup lang=\"java\" title=\"A Handler that works with Java objects instead of raw JSON\" >HttpRouting.Builder routing = routingBuilder.post(\"/echo\", (req, res) -&gt; res.send(req.content().as(Person.class))); This handler consumes a Person instance and simply echoes it back. Note that there is no working with raw JSON here. <markup lang=\"bash\" title=\"Example of posting JSON to the /echo endpoint\" >curl --noproxy '*' -X POST -H \"Content-Type: application/json\" \\ http://localhost:8080/echo -d '{\"name\":\"Joe\"}' <markup lang=\"json\" title=\"Response body\" >{\"name\":\"Joe\"} ",
            "title": "Usage"
        },
        {
            "location": "/se/webserver",
            "text": " The WebServer supports Jackson . When this support is enabled, Java objects will be serialized to and deserialized from JSON automatically using Jackson. Maven Coordinates To enable Jackson Support add the following dependency to your project&#8217;s pom.xml . <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.http.media&lt;/groupId&gt; &lt;artifactId&gt;helidon-http-media-jackson&lt;/artifactId&gt; &lt;/dependency&gt; Usage Now that automatic JSON serialization and deserialization facilities have been set up, you can register a Handler that works with Java objects instead of raw JSON. Deserialization from and serialization to JSON will be handled by Jackson . Suppose you have a Person class that looks like this: <markup lang=\"java\" title=\"Hypothetical Person class\" >public class Person { private String name; public Person() { super(); } public String getName() { return this.name; } public void setName(final String name) { this.name = name; } } Then you can set up a Handler like this: <markup lang=\"java\" title=\"A Handler that works with Java objects instead of raw JSON\" >HttpRouting.Builder routing = routingBuilder.post(\"/echo\", (req, res) -&gt; res.send(req.content().as(Person.class))); This handler consumes a Person instance and simply echoes it back. Note that there is no working with raw JSON here. <markup lang=\"bash\" title=\"Example of posting JSON to the /echo endpoint\" >curl --noproxy '*' -X POST -H \"Content-Type: application/json\" \\ http://localhost:8080/echo -d '{\"name\":\"Joe\"}' <markup lang=\"json\" title=\"Response body\" >{\"name\":\"Joe\"} ",
            "title": "Jackson Support"
        },
        {
            "location": "/se/webserver",
            "text": " WebServer and WebClient share the HTTP media support of Helidon, and any supported media type can be used in both. The media type support is automatically discovered from classpath. Programmatic support is of course enabled as well through MediaContext . Customized media support for WebServer <markup lang=\"java\" >WebServer server = WebServer.builder() .routing(Main::routing) .mediaContext(MediaContext.builder() .mediaSupportsDiscoverServices(false) .addMediaSupport(JsonpSupport.create()) .build()) .build(); Each registered (or discovered) media support adds support for writing and reading entities of a specific type. The following table lists JSON media supports: <div class=\"table__overflow elevation-1 flex sm7 \"> Media type TypeName Maven groupId:artifactId Supported Java type(s) JSON-P JsonpSupport io.helidon.http.media:helidon-http-media-jsonp JsonObject, JsonArray JSON-B JsonbSupport io.helidon.http.media:helidon-http-media-jsonb Any * Jackson JacksonSupport io.helidon.http.media:helidon-http-media-jackson Any * JSON-B and Jackson have lower weight, so they are used only when no other media type matched the object being written or read JSON-P Support The WebServer supports JSON-P. When enabled, you can send and receive JSON-P objects transparently. Maven Coordinates To enable JSON Support add the following dependency to your project&#8217;s pom.xml . <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.http.media&lt;/groupId&gt; &lt;artifactId&gt;helidon-http-media-jsonp&lt;/artifactId&gt; &lt;/dependency&gt; Usage <markup lang=\"java\" title=\"Handler that receives and returns JSON objects\" >private static final JsonBuilderFactory JSON_FACTORY = Json.createBuilderFactory(Collections.emptyMap()); private void sayHello(ServerRequest req, ServerResponse res, JsonObject json) { JsonObject msg = JSON_FACTORY.createObjectBuilder() .add(\"message\", \"Hello \" + json.getString(\"name\")) .build(); res.send(msg); } Using a JsonBuilderFactory is more efficient than Json.createObjectBuilder() JsonObject is passed to handler Create a JsonObject using JSON-P to hold return data Send JsonObject in response <markup lang=\"bash\" title=\"Example of posting JSON to sayHello endpoint\" >curl --noproxy '*' -X POST -H \"Content-Type: application/json\" \\ http://localhost:8080/sayhello -d '{\"name\":\"Joe\"}' <markup lang=\"json\" title=\"Response body\" >{\"message\":\"Hello Joe\"} JSON-B Support The WebServer supports the JSON-B specification . When this support is enabled, Java objects will be serialized to and deserialized from JSON automatically using Yasson , an implementation of the JSON-B specification . Maven Coordinates To enable JSON-B Support add the following dependency to your project&#8217;s pom.xml . <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.http.media&lt;/groupId&gt; &lt;artifactId&gt;helidon-http-media-jsonb&lt;/artifactId&gt; &lt;/dependency&gt; Usage Now that automatic JSON serialization and deserialization facilities have been set up, you can register a Handler that works with Java objects instead of raw JSON. Deserialization from and serialization to JSON will be handled according to the JSON-B specification . Suppose you have a Person class that looks like this: <markup lang=\"java\" title=\"Hypothetical Person class\" >public class Person { private String name; public Person() { super(); } public String getName() { return this.name; } public void setName(String name) { this.name = name; } } Then you can set up a Handler like this: <markup lang=\"java\" title=\"A Handler that works with Java objects instead of raw JSON\" >HttpRouting.Builder routing = routingBuilder.post(\"/echo\", (req, res) -&gt; res.send(req.content().as(Person.class))); This handler consumes a Person instance and simply echoes it back. Note that there is no working with raw JSON here. <markup lang=\"bash\" title=\"Example of posting JSON to the /echo endpoint\" >curl --noproxy '*' -X POST -H \"Content-Type: application/json\" \\ http://localhost:8080/echo -d '{\"name\":\"Joe\"}' {\"name\":\"Joe\"} Jackson Support The WebServer supports Jackson . When this support is enabled, Java objects will be serialized to and deserialized from JSON automatically using Jackson. Maven Coordinates To enable Jackson Support add the following dependency to your project&#8217;s pom.xml . <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.http.media&lt;/groupId&gt; &lt;artifactId&gt;helidon-http-media-jackson&lt;/artifactId&gt; &lt;/dependency&gt; Usage Now that automatic JSON serialization and deserialization facilities have been set up, you can register a Handler that works with Java objects instead of raw JSON. Deserialization from and serialization to JSON will be handled by Jackson . Suppose you have a Person class that looks like this: <markup lang=\"java\" title=\"Hypothetical Person class\" >public class Person { private String name; public Person() { super(); } public String getName() { return this.name; } public void setName(final String name) { this.name = name; } } Then you can set up a Handler like this: <markup lang=\"java\" title=\"A Handler that works with Java objects instead of raw JSON\" >HttpRouting.Builder routing = routingBuilder.post(\"/echo\", (req, res) -&gt; res.send(req.content().as(Person.class))); This handler consumes a Person instance and simply echoes it back. Note that there is no working with raw JSON here. <markup lang=\"bash\" title=\"Example of posting JSON to the /echo endpoint\" >curl --noproxy '*' -X POST -H \"Content-Type: application/json\" \\ http://localhost:8080/echo -d '{\"name\":\"Joe\"}' <markup lang=\"json\" title=\"Response body\" >{\"name\":\"Joe\"} ",
            "title": "Media types support"
        },
        {
            "location": "/se/webserver",
            "text": " AccessLogFeature is discovered automatically by default, and configured through server.features.access-log . You can also configure this feature in code by registering it with WebServer (which will replace the discovered feature). <markup lang=\"java\" >WebServer.builder() .addFeature(AccessLogFeature.builder() .commonLogFormat() .build()); ",
            "title": "Configuring Access Log in Your Code"
        },
        {
            "location": "/se/webserver",
            "text": " Access log can be configured as follows: <markup lang=\"yaml\" title=\"Access Log configuration file\" >server: port: 8080 features: access-log: format: \"%h %l %u %t %r %s %b %{Referer}i\" All options shown below are also available programmatically when using builder. ",
            "title": "Configuring Access Log in a Configuration File"
        },
        {
            "location": "/se/webserver",
            "text": " Access logging in Helidon is done by a dedicated module that can be added to WebServer and configured. Access logging is a Helidon WebServer ServerFeature . Access Log feature has a very high weight, so it is registered before other features (such as security) that may terminate a request. This is to ensure the log contains all requests with appropriate status codes. To enable Access logging add the following dependency to project&#8217;s pom.xml : <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webserver&lt;/groupId&gt; &lt;artifactId&gt;helidon-webserver-access-log&lt;/artifactId&gt; &lt;/dependency&gt; Configuring Access Log in Your Code AccessLogFeature is discovered automatically by default, and configured through server.features.access-log . You can also configure this feature in code by registering it with WebServer (which will replace the discovered feature). <markup lang=\"java\" >WebServer.builder() .addFeature(AccessLogFeature.builder() .commonLogFormat() .build()); Configuring Access Log in a Configuration File Access log can be configured as follows: <markup lang=\"yaml\" title=\"Access Log configuration file\" >server: port: 8080 features: access-log: format: \"%h %l %u %t %r %s %b %{Referer}i\" All options shown below are also available programmatically when using builder. ",
            "title": "Access Log"
        },
        {
            "location": "/se/webserver",
            "text": " Optional configuration options key type default value description enabled boolean true Whether this feature will be enabled. @return whether enabled format string &#160; The format for log entries (similar to the Apache LogFormat ). &lt;table class=\"config\"&gt; &lt;caption&gt;Log format elements&lt;/caption&gt; &lt;tr&gt; &lt;td&gt;%h&lt;/td&gt; &lt;td&gt;IP address of the remote host&lt;/td&gt; &lt;td&gt;HostLogEntry&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;%l&lt;/td&gt; &lt;td&gt;The client identity. This is always undefined in Helidon.&lt;/td&gt; &lt;td&gt;UserIdLogEntry&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;%u&lt;/td&gt; &lt;td&gt;User ID as asserted by Helidon Security.&lt;/td&gt; &lt;td&gt;UserLogEntry&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;%t&lt;/td&gt; &lt;td&gt;The timestamp&lt;/td&gt; &lt;td&gt;TimestampLogEntry&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;%r&lt;/td&gt; &lt;td&gt;The request line ( \"GET /favicon.ico HTTP/1.0\" )&lt;/td&gt; &lt;td&gt;RequestLineLogEntry&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;%s&lt;/td&gt; &lt;td&gt;The status code returned to the client&lt;/td&gt; &lt;td&gt;StatusLogEntry&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;%b&lt;/td&gt; &lt;td&gt;The entity size in bytes&lt;/td&gt; &lt;td&gt;SizeLogEntry&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;%D&lt;/td&gt; &lt;td&gt;The time taken in microseconds (start of request until last byte written)&lt;/td&gt; &lt;td&gt;TimeTakenLogEntry&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;%T&lt;/td&gt; &lt;td&gt;The time taken in seconds (start of request until last byte written), integer&lt;/td&gt; &lt;td&gt;TimeTakenLogEntry&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;%{header-name}i&lt;/td&gt; &lt;td&gt;Value of header header-name &lt;/td&gt; &lt;td&gt;HeaderLogEntry&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; @return format string, such as `%h %l %u %t %r %b %{Referer`i} logger-name string io.helidon.webserver.AccessLog Name of the logger used to obtain access log logger from System#getLogger(String). Defaults to AccessLogFeature#DEFAULT_LOGGER_NAME . @return name of the logger to use sockets string[&#93; &#160; List of sockets to register this feature on. If empty, it would get registered on all sockets. The logger used will have the expected logger with a suffix of the socket name. @return socket names to register on, defaults to empty (all available sockets) weight double 1000.0 Weight of the access log feature. We need to log access for anything happening on the server, so weight is high: io.helidon.webserver.accesslog.AccessLogFeature#WEIGHT . @return weight of the feature ",
            "title": "Configuration options"
        },
        {
            "location": "/se/webserver",
            "text": " Type: io.helidon.webserver.accesslog.AccessLogFeature <markup lang=\"text\" title=\"Config key\" >access-log This type provides the following service implementations: io.helidon.webserver.spi.ServerFeatureProvider Configuration options Optional configuration options key type default value description enabled boolean true Whether this feature will be enabled. @return whether enabled format string &#160; The format for log entries (similar to the Apache LogFormat ). &lt;table class=\"config\"&gt; &lt;caption&gt;Log format elements&lt;/caption&gt; &lt;tr&gt; &lt;td&gt;%h&lt;/td&gt; &lt;td&gt;IP address of the remote host&lt;/td&gt; &lt;td&gt;HostLogEntry&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;%l&lt;/td&gt; &lt;td&gt;The client identity. This is always undefined in Helidon.&lt;/td&gt; &lt;td&gt;UserIdLogEntry&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;%u&lt;/td&gt; &lt;td&gt;User ID as asserted by Helidon Security.&lt;/td&gt; &lt;td&gt;UserLogEntry&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;%t&lt;/td&gt; &lt;td&gt;The timestamp&lt;/td&gt; &lt;td&gt;TimestampLogEntry&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;%r&lt;/td&gt; &lt;td&gt;The request line ( \"GET /favicon.ico HTTP/1.0\" )&lt;/td&gt; &lt;td&gt;RequestLineLogEntry&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;%s&lt;/td&gt; &lt;td&gt;The status code returned to the client&lt;/td&gt; &lt;td&gt;StatusLogEntry&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;%b&lt;/td&gt; &lt;td&gt;The entity size in bytes&lt;/td&gt; &lt;td&gt;SizeLogEntry&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;%D&lt;/td&gt; &lt;td&gt;The time taken in microseconds (start of request until last byte written)&lt;/td&gt; &lt;td&gt;TimeTakenLogEntry&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;%T&lt;/td&gt; &lt;td&gt;The time taken in seconds (start of request until last byte written), integer&lt;/td&gt; &lt;td&gt;TimeTakenLogEntry&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;%{header-name}i&lt;/td&gt; &lt;td&gt;Value of header header-name &lt;/td&gt; &lt;td&gt;HeaderLogEntry&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; @return format string, such as `%h %l %u %t %r %b %{Referer`i} logger-name string io.helidon.webserver.AccessLog Name of the logger used to obtain access log logger from System#getLogger(String). Defaults to AccessLogFeature#DEFAULT_LOGGER_NAME . @return name of the logger to use sockets string[&#93; &#160; List of sockets to register this feature on. If empty, it would get registered on all sockets. The logger used will have the expected logger with a suffix of the socket name. @return socket names to register on, defaults to empty (all available sockets) weight double 1000.0 Weight of the access log feature. We need to log access for anything happening on the server, so weight is high: io.helidon.webserver.accesslog.AccessLogFeature#WEIGHT . @return weight of the feature ",
            "title": "AccessLogFeature (webserver.accesslog) Configuration"
        },
        {
            "location": "/se/webserver",
            "text": " To configure TLS in WebServer programmatically create your keystore configuration and pass it to the WebServer builder. <markup lang=\"java\" >Tls tls = Tls.builder() .privateKey(pk -&gt; pk.keystore(pkKeystore -&gt; pkKeystore.keystore(Resource.create(\"private-key.p12\")) .passphrase(\"password\".toCharArray()))) .trust(trust -&gt; trust.keystore(trustStore -&gt; trustStore.keystore(Resource.create(\"trust.p12\")))) .build(); WebServer.builder() .tls(tls) .build(); ",
            "title": "Configuring TLS in Your Code"
        },
        {
            "location": "/se/webserver",
            "text": " It is also possible to configure TLS via the config file. <markup lang=\"yaml\" title=\"WebServer TLS configuration file application.yaml \" >server: tls: #Truststore setup trust: keystore: passphrase: \"password\" trust-store: true resource: resource-path: \"keystore.p12\" #Keystore with private key and server certificate private-key: keystore: passphrase: \"password\" resource: resource-path: \"keystore.p12\" Then, in your application code, load the configuration from that file. <markup lang=\"java\" title=\"WebServer initialization using the application.yaml file located on the classpath\" >Config config = Config.create(); WebServer webClient = WebServer.create(routing, config.get(\"server\")); Or you can only create WebServerTls instance based on the config file. <markup lang=\"java\" title=\"WebServerTls instance based on application.yaml file located on the classpath\" >Config config = Config.create(); WebServerTls.builder() .config(config.get(\"server.tls\")) .build(); This can alternatively be configured with paths to PKCS#8 PEM files rather than KeyStores: <markup lang=\"yaml\" title=\"WebServer TLS configuration file application.yaml \" >server: tls: #Truststore setup trust: pem: certificates: resource: resource-path: \"ca-bundle.pem\" private-key: pem: key: resource: resource-path: \"key.pem\" cert-chain: resource: resource-path: \"chain.pem\" ",
            "title": "Configuring TLS in the Config File"
        },
        {
            "location": "/se/webserver",
            "text": " Optional configuration options key type default value description cipher-suite string[&#93; &#160; Enabled cipher suites for TLS communication. @return cipher suits to enable, by default (or if list is empty), all available cipher suites are enabled client-auth TlsClientAuth (REQUIRED, OPTIONAL, NONE) NONE Configure requirement for mutual TLS. @return what type of mutual TLS to use, defaults to TlsClientAuth#NONE enabled boolean true Flag indicating whether Tls is enabled. @return enabled flag endpoint-identification-algorithm string HTTPS Identification algorithm for SSL endpoints. @return configure endpoint identification algorithm, or set to `NONE` to disable endpoint identification (equivalent to hostname verification). Defaults to `Tls#ENDPOINT_IDENTIFICATION_HTTPS` internal-keystore-provider string &#160; Provider of the key stores used internally to create a key and trust manager factories. @return keystore provider, if not defined, provider is not specified internal-keystore-type string &#160; Type of the key stores used internally to create a key and trust manager factories. @return keystore type, defaults to java.security.KeyStore#getDefaultType() key-manager-factory-algorithm string &#160; Algorithm of the key manager factory used when private key is defined. Defaults to javax.net.ssl.KeyManagerFactory#getDefaultAlgorithm(). @return algorithm to use manager io.helidon.common.tls.TlsManager (service provider interface) &#160; The Tls manager. If one is not explicitly defined in the config then a default manager will be created. @return the tls manager of the tls instance @see ConfiguredTlsManager private-key PrivateKey &#160; Private key to use. For server side TLS, this is required. For client side TLS, this is optional (used when mutual TLS is enabled). @return private key to use protocol string TLS Configure the protocol used to obtain an instance of javax.net.ssl.SSLContext. @return protocol to use, defaults to `DEFAULT_PROTOCOL` protocols string[&#93; &#160; Enabled protocols for TLS communication. Example of valid values for TLS protocol: TLSv1.3 , TLSv1.2 @return protocols to enable, by default (or if list is empty), all available protocols are enabled provider string &#160; Use explicit provider to obtain an instance of javax.net.ssl.SSLContext. @return provider to use, defaults to none (only #protocol() is used by default) secure-random-algorithm string &#160; Algorithm to use when creating a new secure random. @return algorithm to use, by default uses java.security.SecureRandom constructor secure-random-provider string &#160; Provider to use when creating a new secure random. When defined, #secureRandomAlgorithm() must be defined as well. @return provider to use, by default no provider is specified session-cache-size int 1024 SSL session cache size. @return session cache size, defaults to 1024 session-timeout Duration PT30M SSL session timeout. @return session timeout, defaults to 30 minutes trust X509Certificate[&#93; &#160; List of certificates that form the trust manager. @return certificates to be trusted trust-all boolean false Trust any certificate provided by the other side of communication. &lt;b&gt;This is a dangerous setting: &lt;/b&gt; if set to `true`, any certificate will be accepted, throwing away most of the security advantages of TLS. &lt;b&gt;NEVER&lt;/b&gt; do this in production. @return whether to trust all certificates, do not use in production trust-manager-factory-algorithm string &#160; Trust manager factory algorithm. @return algorithm to use ",
            "title": "Configuration options"
        },
        {
            "location": "/se/webserver",
            "text": " Type: io.helidon.common.tls.Tls Configuration options Optional configuration options key type default value description cipher-suite string[&#93; &#160; Enabled cipher suites for TLS communication. @return cipher suits to enable, by default (or if list is empty), all available cipher suites are enabled client-auth TlsClientAuth (REQUIRED, OPTIONAL, NONE) NONE Configure requirement for mutual TLS. @return what type of mutual TLS to use, defaults to TlsClientAuth#NONE enabled boolean true Flag indicating whether Tls is enabled. @return enabled flag endpoint-identification-algorithm string HTTPS Identification algorithm for SSL endpoints. @return configure endpoint identification algorithm, or set to `NONE` to disable endpoint identification (equivalent to hostname verification). Defaults to `Tls#ENDPOINT_IDENTIFICATION_HTTPS` internal-keystore-provider string &#160; Provider of the key stores used internally to create a key and trust manager factories. @return keystore provider, if not defined, provider is not specified internal-keystore-type string &#160; Type of the key stores used internally to create a key and trust manager factories. @return keystore type, defaults to java.security.KeyStore#getDefaultType() key-manager-factory-algorithm string &#160; Algorithm of the key manager factory used when private key is defined. Defaults to javax.net.ssl.KeyManagerFactory#getDefaultAlgorithm(). @return algorithm to use manager io.helidon.common.tls.TlsManager (service provider interface) &#160; The Tls manager. If one is not explicitly defined in the config then a default manager will be created. @return the tls manager of the tls instance @see ConfiguredTlsManager private-key PrivateKey &#160; Private key to use. For server side TLS, this is required. For client side TLS, this is optional (used when mutual TLS is enabled). @return private key to use protocol string TLS Configure the protocol used to obtain an instance of javax.net.ssl.SSLContext. @return protocol to use, defaults to `DEFAULT_PROTOCOL` protocols string[&#93; &#160; Enabled protocols for TLS communication. Example of valid values for TLS protocol: TLSv1.3 , TLSv1.2 @return protocols to enable, by default (or if list is empty), all available protocols are enabled provider string &#160; Use explicit provider to obtain an instance of javax.net.ssl.SSLContext. @return provider to use, defaults to none (only #protocol() is used by default) secure-random-algorithm string &#160; Algorithm to use when creating a new secure random. @return algorithm to use, by default uses java.security.SecureRandom constructor secure-random-provider string &#160; Provider to use when creating a new secure random. When defined, #secureRandomAlgorithm() must be defined as well. @return provider to use, by default no provider is specified session-cache-size int 1024 SSL session cache size. @return session cache size, defaults to 1024 session-timeout Duration PT30M SSL session timeout. @return session timeout, defaults to 30 minutes trust X509Certificate[&#93; &#160; List of certificates that form the trust manager. @return certificates to be trusted trust-all boolean false Trust any certificate provided by the other side of communication. &lt;b&gt;This is a dangerous setting: &lt;/b&gt; if set to `true`, any certificate will be accepted, throwing away most of the security advantages of TLS. &lt;b&gt;NEVER&lt;/b&gt; do this in production. @return whether to trust all certificates, do not use in production trust-manager-factory-algorithm string &#160; Trust manager factory algorithm. @return algorithm to use ",
            "title": "Configuration Options"
        },
        {
            "location": "/se/webserver",
            "text": " Configure TLS either programmatically, or by the Helidon configuration framework. Configuring TLS in Your Code To configure TLS in WebServer programmatically create your keystore configuration and pass it to the WebServer builder. <markup lang=\"java\" >Tls tls = Tls.builder() .privateKey(pk -&gt; pk.keystore(pkKeystore -&gt; pkKeystore.keystore(Resource.create(\"private-key.p12\")) .passphrase(\"password\".toCharArray()))) .trust(trust -&gt; trust.keystore(trustStore -&gt; trustStore.keystore(Resource.create(\"trust.p12\")))) .build(); WebServer.builder() .tls(tls) .build(); Configuring TLS in the Config File It is also possible to configure TLS via the config file. <markup lang=\"yaml\" title=\"WebServer TLS configuration file application.yaml \" >server: tls: #Truststore setup trust: keystore: passphrase: \"password\" trust-store: true resource: resource-path: \"keystore.p12\" #Keystore with private key and server certificate private-key: keystore: passphrase: \"password\" resource: resource-path: \"keystore.p12\" Then, in your application code, load the configuration from that file. <markup lang=\"java\" title=\"WebServer initialization using the application.yaml file located on the classpath\" >Config config = Config.create(); WebServer webClient = WebServer.create(routing, config.get(\"server\")); Or you can only create WebServerTls instance based on the config file. <markup lang=\"java\" title=\"WebServerTls instance based on application.yaml file located on the classpath\" >Config config = Config.create(); WebServerTls.builder() .config(config.get(\"server.tls\")) .build(); This can alternatively be configured with paths to PKCS#8 PEM files rather than KeyStores: <markup lang=\"yaml\" title=\"WebServer TLS configuration file application.yaml \" >server: tls: #Truststore setup trust: pem: certificates: resource: resource-path: \"ca-bundle.pem\" private-key: pem: key: resource: resource-path: \"key.pem\" cert-chain: resource: resource-path: \"chain.pem\" Configuration Options Type: io.helidon.common.tls.Tls Configuration options Optional configuration options key type default value description cipher-suite string[&#93; &#160; Enabled cipher suites for TLS communication. @return cipher suits to enable, by default (or if list is empty), all available cipher suites are enabled client-auth TlsClientAuth (REQUIRED, OPTIONAL, NONE) NONE Configure requirement for mutual TLS. @return what type of mutual TLS to use, defaults to TlsClientAuth#NONE enabled boolean true Flag indicating whether Tls is enabled. @return enabled flag endpoint-identification-algorithm string HTTPS Identification algorithm for SSL endpoints. @return configure endpoint identification algorithm, or set to `NONE` to disable endpoint identification (equivalent to hostname verification). Defaults to `Tls#ENDPOINT_IDENTIFICATION_HTTPS` internal-keystore-provider string &#160; Provider of the key stores used internally to create a key and trust manager factories. @return keystore provider, if not defined, provider is not specified internal-keystore-type string &#160; Type of the key stores used internally to create a key and trust manager factories. @return keystore type, defaults to java.security.KeyStore#getDefaultType() key-manager-factory-algorithm string &#160; Algorithm of the key manager factory used when private key is defined. Defaults to javax.net.ssl.KeyManagerFactory#getDefaultAlgorithm(). @return algorithm to use manager io.helidon.common.tls.TlsManager (service provider interface) &#160; The Tls manager. If one is not explicitly defined in the config then a default manager will be created. @return the tls manager of the tls instance @see ConfiguredTlsManager private-key PrivateKey &#160; Private key to use. For server side TLS, this is required. For client side TLS, this is optional (used when mutual TLS is enabled). @return private key to use protocol string TLS Configure the protocol used to obtain an instance of javax.net.ssl.SSLContext. @return protocol to use, defaults to `DEFAULT_PROTOCOL` protocols string[&#93; &#160; Enabled protocols for TLS communication. Example of valid values for TLS protocol: TLSv1.3 , TLSv1.2 @return protocols to enable, by default (or if list is empty), all available protocols are enabled provider string &#160; Use explicit provider to obtain an instance of javax.net.ssl.SSLContext. @return provider to use, defaults to none (only #protocol() is used by default) secure-random-algorithm string &#160; Algorithm to use when creating a new secure random. @return algorithm to use, by default uses java.security.SecureRandom constructor secure-random-provider string &#160; Provider to use when creating a new secure random. When defined, #secureRandomAlgorithm() must be defined as well. @return provider to use, by default no provider is specified session-cache-size int 1024 SSL session cache size. @return session cache size, defaults to 1024 session-timeout Duration PT30M SSL session timeout. @return session timeout, defaults to 30 minutes trust X509Certificate[&#93; &#160; List of certificates that form the trust manager. @return certificates to be trusted trust-all boolean false Trust any certificate provided by the other side of communication. &lt;b&gt;This is a dangerous setting: &lt;/b&gt; if set to `true`, any certificate will be accepted, throwing away most of the security advantages of TLS. &lt;b&gt;NEVER&lt;/b&gt; do this in production. @return whether to trust all certificates, do not use in production trust-manager-factory-algorithm string &#160; Trust manager factory algorithm. @return algorithm to use ",
            "title": "TLS Configuration"
        },
        {
            "location": "/se/webserver",
            "text": " Optional configuration options key type default value description content-encodings io.helidon.http.encoding.ContentEncoding[&#93; (service provider interface) &#160; List of content encodings that should be used. Encodings configured here have priority over encodings discovered through service loader. @return list of content encodings to be used (such as `gzip,deflate`) The following providers are currently available (simply add the library on the classpath): <div class=\"table__overflow elevation-1 flex sm7 \"> Encoding type TypeName Maven groupId:artifactId gzip GzipEncoding io.helidon.http.encoding:helidon-http-encoding-gzip deflate DeflateSupport io.helidon.http.encoding:helidon-http-encoding-deflate ",
            "title": "Configuration options"
        },
        {
            "location": "/se/webserver",
            "text": " HTTP encoding support is discovered automatically by WebServer from the classpath, or it can be customized programmatically. Encoding can be configured per socket. Disabling discovery and registering a Gzip encoding support: <markup lang=\"java\" >WebServer.builder() .contentEncoding(ContentEncodingContextConfig.builder() .contentEncodingsDiscoverServices(false) .addContentEncoding(GzipEncoding.create()) .build()); Or use a config file using the following options: Type: io.helidon.http.encoding.ContentEncodingContext Configuration options Optional configuration options key type default value description content-encodings io.helidon.http.encoding.ContentEncoding[&#93; (service provider interface) &#160; List of content encodings that should be used. Encodings configured here have priority over encodings discovered through service loader. @return list of content encodings to be used (such as `gzip,deflate`) The following providers are currently available (simply add the library on the classpath): <div class=\"table__overflow elevation-1 flex sm7 \"> Encoding type TypeName Maven groupId:artifactId gzip GzipEncoding io.helidon.http.encoding:helidon-http-encoding-gzip deflate DeflateSupport io.helidon.http.encoding:helidon-http-encoding-deflate ",
            "title": "Configuring HTTP Encoding"
        },
        {
            "location": "/se/webserver",
            "text": " HTTP compression negotiation is controlled by clients using the Accept-Encoding header. The value of this header is a comma-separated list of encodings. The WebServer will select one of these encodings for compression purposes; it currently supports gzip and deflate . For example, if the request includes Accept-Encoding: gzip, deflate , and HTTP compression has been enabled as shown above, the response shall include the header Content-Encoding: gzip and a compressed payload. ",
            "title": "HTTP Compression Negotiation"
        },
        {
            "location": "/se/webserver",
            "text": " HTTP encoding can improve bandwidth utilization and transfer speeds in certain scenarios. It requires a few extra CPU cycles for compressing and uncompressing, but these can be offset if data is transferred over low-bandwidth network links. A client advertises the compression encodings it supports at request time, and the WebServer responds by selecting an encoding it supports and setting it in a header, effectively negotiating the content encoding of the response. If none of the advertised encodings is supported by the WebServer, the response is returned uncompressed. Configuring HTTP Encoding HTTP encoding support is discovered automatically by WebServer from the classpath, or it can be customized programmatically. Encoding can be configured per socket. Disabling discovery and registering a Gzip encoding support: <markup lang=\"java\" >WebServer.builder() .contentEncoding(ContentEncodingContextConfig.builder() .contentEncodingsDiscoverServices(false) .addContentEncoding(GzipEncoding.create()) .build()); Or use a config file using the following options: Type: io.helidon.http.encoding.ContentEncodingContext Configuration options Optional configuration options key type default value description content-encodings io.helidon.http.encoding.ContentEncoding[&#93; (service provider interface) &#160; List of content encodings that should be used. Encodings configured here have priority over encodings discovered through service loader. @return list of content encodings to be used (such as `gzip,deflate`) The following providers are currently available (simply add the library on the classpath): <div class=\"table__overflow elevation-1 flex sm7 \"> Encoding type TypeName Maven groupId:artifactId gzip GzipEncoding io.helidon.http.encoding:helidon-http-encoding-gzip deflate DeflateSupport io.helidon.http.encoding:helidon-http-encoding-deflate HTTP Compression Negotiation HTTP compression negotiation is controlled by clients using the Accept-Encoding header. The value of this header is a comma-separated list of encodings. The WebServer will select one of these encodings for compression purposes; it currently supports gzip and deflate . For example, if the request includes Accept-Encoding: gzip, deflate , and HTTP compression has been enabled as shown above, the response shall include the header Content-Encoding: gzip and a compressed payload. ",
            "title": "HTTP Content Encoding"
        },
        {
            "location": "/se/webserver",
            "text": " There are two ways in which the header data can be accessed in your application. One way is by obtaining the protocol data directly from a request as shown next: <markup lang=\"java\" >routing.get(\"/\", (req, res) -&gt; { ProxyProtocolData data = req.proxyProtocolData().orElse(null); if (data != null &amp;&amp; data.family() == ProxyProtocolData.Family.IPv4 &amp;&amp; data.protocol() == ProxyProtocolData.Protocol.TCP &amp;&amp; data.sourceAddress().equals(\"192.168.0.1\") &amp;&amp; data.destAddress().equals(\"192.168.0.11\") &amp;&amp; data.sourcePort() == 56324 &amp;&amp; data.destPort() == 443) { // ... } }); Every request associated with a certain connection shall have access to the Proxy Protocol data received when the connection was opened. Alternatively, the WebServer also makes the original client source address and source port available in the HTTP headers X-Forwarded-For and X-Forwarded-Port , respectively. In some cases, it is just simpler to inspect these headers instead of getting the complete ProxyProtocolData instance as shown above. ",
            "title": "Accessing Proxy Protocol Data"
        },
        {
            "location": "/se/webserver",
            "text": " The Proxy Protocol provides a way to convey client information across reverse proxies or load balancers which would otherwise be lost given that new connections are established for each network hop. Often times, this information can be carried in HTTP headers, but not all proxies support this feature. Helidon is capable of parsing a proxy protocol header (i.e., a network preamble) that is based on either V1 or V2 of the protocol, thus making client information available to service developers. Proxy Protocol support is enabled via configuration, and can be done either declaratively or programmatically. Once enabled, every new connection on the corresponding port MUST be preambled by a proxy header for the connection not to be rejected as invalid --that is, proxy headers are never optional. Programmatically, support for the Proxy Protocol is enabled as follows: <markup lang=\"java\" >WebServer server = WebServer.builder() .enableProxyProtocol(true) .routing(...) .build() .start(); Declaratively, support for the Proxy Protocol is enabled as follows: <markup lang=\"yaml\" >server: port: 8080 host: 0.0.0.0 enable-proxy-protocol: true Accessing Proxy Protocol Data There are two ways in which the header data can be accessed in your application. One way is by obtaining the protocol data directly from a request as shown next: <markup lang=\"java\" >routing.get(\"/\", (req, res) -&gt; { ProxyProtocolData data = req.proxyProtocolData().orElse(null); if (data != null &amp;&amp; data.family() == ProxyProtocolData.Family.IPv4 &amp;&amp; data.protocol() == ProxyProtocolData.Protocol.TCP &amp;&amp; data.sourceAddress().equals(\"192.168.0.1\") &amp;&amp; data.destAddress().equals(\"192.168.0.11\") &amp;&amp; data.sourcePort() == 56324 &amp;&amp; data.destPort() == 443) { // ... } }); Every request associated with a certain connection shall have access to the Proxy Protocol data received when the connection was opened. Alternatively, the WebServer also makes the original client source address and source port available in the HTTP headers X-Forwarded-For and X-Forwarded-Port , respectively. In some cases, it is just simpler to inspect these headers instead of getting the complete ProxyProtocolData instance as shown above. ",
            "title": "Proxy Protocol Support"
        },
        {
            "location": "/se/webserver",
            "text": " Here is the code for a minimalist web application that runs on a random free port: <markup lang=\"java\" >public static void main(String[] args) { WebServer webServer = WebServer.builder() .routing(routing -&gt; routing.any((req, res) -&gt; res.send(\"It works!\"))) .build() .start(); System.out.println(\"Server started at: http://localhost:\" + webServer.port()); } For any kind of request, at any path, respond with It works! . Build the server with the provided configuraiton Start the server (and wait for it to open the port). The server is bound to a random free port. ",
            "title": "Additional Information"
        },
        {
            "location": "/se/webserver",
            "text": " Helidon WebServer JavaDoc Helidon WebServer Static Content JavaDoc Helidon JSON-B Support JavaDoc Helidon JSON-P Support JavaDoc Helidon Jackson Support JavaDoc Proxy Protocol Specification ",
            "title": "Reference"
        },
        {
            "location": "/se/websocket",
            "text": " Overview Maven Coordinates Example Reference ",
            "title": "Contents"
        },
        {
            "location": "/se/websocket",
            "text": " Helidon integrates with Tyrus to provide support for the Jakarta WebSocket API . The WebSocket API enables Java applications to participate in WebSocket interactions as both servers and clients. The server API supports two flavors: annotated and programmatic endpoints. Annotated endpoints, as suggested by their name, use Java annotations to provide the necessary meta-data to define WebSocket handlers; programmatic endpoints implement API interfaces and are annotation free. Annotated endpoints tend to be more flexible since they allow different method signatures depending on the application needs, whereas programmatic endpoints must implement an interface and are, therefore, bounded to its definition. Helidon SE support is based on the WebSocketRouting class which enables Helidon application to configure routing for both annotated and programmatic WebSocket endpoints. ",
            "title": "Overview"
        },
        {
            "location": "/se/websocket",
            "text": " To enable {feature-name} add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webserver&lt;/groupId&gt; &lt;artifactId&gt;helidon-webserver-websocket&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/websocket",
            "text": " This section describes the implementation of a simple application that uses a REST resource to push messages into a shared queue and a programmatic WebSocket endpoint to download messages from the queue, one at a time, over a connection. The example will show how REST and WebSocket connections can be seamlessly combined into a Helidon application. The complete Helidon SE example is available here . Let us start by looking at MessageQueueService : <markup lang=\"java\" >public class MessageQueueService implements HttpService { private final MessageQueue messageQueue = MessageQueue.instance(); @Override public void routing(HttpRules routingRules) { routingRules.post(\"/board\", this::handlePost); } private void handlePost(ServerRequest request, ServerResponse response) { messageQueue.push(request.content().as(String.class)); response.status(204).send(); } } This class exposes a REST resource where messages can be posted. Upon receiving a message, it simply pushes it into a shared queue and returns 204 (No Content). Messages pushed into the queue can be obtained by opening a WebSocket connection served by MessageBoardEndpoint : <markup lang=\"java\" >public class MessageBoardEndpoint implements WsListener { private final MessageQueue messageQueue = MessageQueue.instance(); @Override public void onMessage(WsSession session, String text, boolean last) { // Send all messages in the queue if (text.equals(\"send\")) { while (!messageQueue.isEmpty()) { session.send(messageQueue.pop(), last); } } } } This is an example of a programmatic endpoint that extends WsListener . The method onMessage will be invoked for every message. In this example, when the special send message is received, it empties the shared queue sending messages one at a time over the WebSocket connection. In Helidon SE, REST and WebSocket classes need to be manually registered into the web server. This is accomplished via a Routing builder: <markup lang=\"java\" >StaticContentService staticContent = StaticContentService.builder(\"/WEB\") .welcomeFileName(\"index.html\") .build(); MessageQueueService messageQueueService = new MessageQueueService(); server.routing(routing -&gt; routing .register(\"/web\", staticContent) .register(\"/rest\", messageQueueService)) .addRouting(WsRouting.builder() .endpoint(\"/websocket/board\", new MessageBoardEndpoint()) .build()); This code snippet registers MessageBoardEndpoint at \"/websocket/board\" and associates. ",
            "title": "Example"
        },
        {
            "location": "/se/websocket",
            "text": " Helidon WebSocket JavaDoc ",
            "title": "Reference"
        }
 ]
}
