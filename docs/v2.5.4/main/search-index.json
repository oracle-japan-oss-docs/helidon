{
    "docs": [
        {
            "location": "/about/04_managing-dependencies",
            "text": " Helidon provides a &#8220;Bill Of Materials&#8221; (BOM) to manage dependencies. This is a special Maven pom file that provides dependency management. Using the Helidon BOM allows you to use Helidon component dependencies with a single version: the Helidon version. ",
            "title": "preambule"
        },
        {
            "location": "/about/04_managing-dependencies",
            "text": " If you created your application using the Helidon CLI or archetypes then your project will have a Helidon Application POM as its parent POM. In this case you will get Helidon&#8217;s dependency management automatically. If your project doesn&#8217;t use a Helidon Application POM as its parent, then you will need to import the Helidon BOM POM. ",
            "title": "The Helidon Application POMs"
        },
        {
            "location": "/about/04_managing-dependencies",
            "text": " To import the Helidon BOM POM add the following snippet to your pom.xml file. <markup lang=\"xml\" title=\"Import the Helidon BOM\" >&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon&lt;/groupId&gt; &lt;artifactId&gt;helidon-bom&lt;/artifactId&gt; &lt;version&gt;2.5.4&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; ",
            "title": "The Helidon BOM POM"
        },
        {
            "location": "/about/04_managing-dependencies",
            "text": " Once you have imported the BOM, you can declare dependencies on Helidon components without specifying a version. <markup lang=\"xml\" title=\"Component dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webserver&lt;/groupId&gt; &lt;artifactId&gt;helidon-webserver&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Using Helidon Component Dependencies"
        },
        {
            "location": "/about/04_managing-dependencies",
            "text": " Maven Build Guide for SE and MP Gradle Build Guide for SE and MP ",
            "title": "For More Information"
        },
        {
            "location": "/se/guides/01_overview",
            "text": " Quickstart SE Create your first Helidon SE application in under 5 minutes. ",
            "title": "Getting Started"
        },
        {
            "location": "/se/guides/01_overview",
            "text": " Config Guide Learn how to configure a Helidon SE application. Health Check Guide Learn how to use Helidon SE built-in and custom health checks. Metrics Guide Learn how to use Helidon SE built-in and application metrics. Tracing Guide Learn how to trace a Helidon SE application. ",
            "title": "Helidon SE Guides"
        },
        {
            "location": "/se/guides/01_overview",
            "text": " Maven Guide Using Helidon in your Maven project. Gradle Guide Using Helidon in your Gradle project. GraalVM Native Images Learn how to build a GraalVM native image for your Helidon application both on your desktop and as part of a Docker image. Custom Runtime Images using jlink Learn how to build a custom runtime Java image for your Helidon application both on your desktop and as part of a Docker image. Building Container Images with Jib Learn how to use Jib to create a container image without Docker. Deploying to OKE Learn how to deploy your application to Oracle Cloud Infrastructure Container Engine for Kubernetes (OKE). ",
            "title": "Build and Deploy"
        },
        {
            "location": "/mp/jaxrs/02_server-configuration",
            "text": " By default, the server uses the MicroProfile Config, but you may also want to use Helidon configuration. ",
            "title": "preambule"
        },
        {
            "location": "/mp/jaxrs/02_server-configuration",
            "text": " There are 3 default MicroProfile Config sources: System.getProperties() System.getenv() all META-INF/microprofile-config.properties files on the class path application.yaml on the classpath (read by default by Helidon Config) In this example, the configuration is in a file, and it includes Helidon configuration options. <markup lang=\"properties\" title=\"META-INF/microprofile-config.properties - Server configuration\" ># default is localhost server.host=some.host # default is 7001 server.port=7011 # Helidon configuration (optional) # Length of queue for incoming connections. Default is 1024 server.backlog=512 # TCP receive window. Default is 0 to use implementation default server.receive-buffer=256 # Socket timeout milliseconds - defaults to 0 (infinite) server.timeout=30000 # Defaults to Runtime.availableProcessors() server.workers=4 ",
            "title": "Configuring the Server"
        },
        {
            "location": "/mp/jaxrs/02_server-configuration",
            "text": " Helidon MP also supports custom TLS configuration. User is able to set following properties: Server truststore Keystore with trusted certificates Private key and certificate Server certificate which will be used in TLS handshake <markup lang=\"properties\" title=\"META-INF/microprofile-config.properties - Server configuration\" >#Truststore setup server.tls.trust.keystore.resource.resource-path=server.p12 server.tls.trust.keystore.passphrase=password server.tls.trust.keystore.trust-store=true #Keystore with private key and server certificate server.tls.private-key.keystore.resource.resource-path=server.p12 server.tls.private-key.keystore.passphrase=password Or the same configuration done in application.yaml file. <markup lang=\"yaml\" title=\"application.yaml - Server configuration\" >server: tls: #Truststore setup trust: keystore: passphrase: \"password\" trust-store: true resource: resource-path: \"keystore.p12\" #Keystore with private key and server certificate private-key: keystore: passphrase: \"password\" resource: resource-path: \"keystore.p12\" ",
            "title": "Configuring TLS"
        },
        {
            "location": "/mp/jaxrs/02_server-configuration",
            "text": " Helidon MP can expose multiple ports, with the following limitations: The default port is the port that serves your application (JAX-RS applications and resources) Other ports (in this example we configure one \"admin\" port) can be assigned endpoints that are exposed by Helidon components, currently supported by MP Health and MP Metrics For this example, we will use a yaml file: The port 7011 is the default port and will serve your application The port 8011 is named \"admin\" (this is an arbitrary name) MP Metrics are configured to use the \"admin\" port through the routing configuration (reference is by name) MP Health is configured the same way to reference the \"admin\" port <markup lang=\"yaml\" title=\"application.yaml - Server configuration\" >server: port: 7011 host: \"some.host\" sockets: admin: port: 8011 bind-address: \"some.host\" metrics: routing: \"admin\" health: routing: \"admin\" ",
            "title": "Configuring additional ports"
        },
        {
            "location": "/mp/jaxrs/02_server-configuration",
            "text": " You can annotate an application with this annotation to assign it to a specific named routing, that is (most likely) going to be bound to a specific port. The annotation has two attributes: - value that defines the routing name - required to mark that the routing name MUST be configured in Helidon server <markup lang=\"yaml\" title=\" @RoutingName example\" >@ApplicationScoped @ApplicationPath(\"/admin\") @RoutingName(value=\"admin\", required=\"true\") public class AdminApplication extends Application { //.... } The example above will be bound to admin routing (and port) and will fail if such a port is not configured. ",
            "title": "Annotation @RoutingName "
        },
        {
            "location": "/mp/jaxrs/02_server-configuration",
            "text": " For each application class you can define the routing name and its required flag by specifying a configuration option class-name.routing-name.name and class-name.routing-name.required . Example (YAML) configuration for a class io.helidon.examples.AdminApplication that changes the routing name to management and its required flag to false : <markup lang=\"yaml\" >io.helidon.examples.AdminApplication: routing-name: name: \"management\" required: false ",
            "title": "Configuration override of routing name"
        },
        {
            "location": "/mp/jaxrs/02_server-configuration",
            "text": " Since 1.4 Helidon has the concept of named routings. These correspond to the named ports we have described in the previous section. You can assign a JAX-RS application to a named routing (and as a result to a named port) using either an annotation or configuration (or both to override the value from annotation). Annotation @RoutingName You can annotate an application with this annotation to assign it to a specific named routing, that is (most likely) going to be bound to a specific port. The annotation has two attributes: - value that defines the routing name - required to mark that the routing name MUST be configured in Helidon server <markup lang=\"yaml\" title=\" @RoutingName example\" >@ApplicationScoped @ApplicationPath(\"/admin\") @RoutingName(value=\"admin\", required=\"true\") public class AdminApplication extends Application { //.... } The example above will be bound to admin routing (and port) and will fail if such a port is not configured. Configuration override of routing name For each application class you can define the routing name and its required flag by specifying a configuration option class-name.routing-name.name and class-name.routing-name.required . Example (YAML) configuration for a class io.helidon.examples.AdminApplication that changes the routing name to management and its required flag to false : <markup lang=\"yaml\" >io.helidon.examples.AdminApplication: routing-name: name: \"management\" required: false ",
            "title": "Assigning JAX-RS applications to ports"
        },
        {
            "location": "/mp/jaxrs/02_server-configuration",
            "text": " Since Helidon 1.4 In JAX-RS we can use @ApplicationPath to configure a path the JAX-RS application is available on. As this is compiled into the source code, Helidon provides a way to override this using configuration. For each application class you can define the routing path by specifying a configuration option class-name.routing-path.path . Example (YAML) configuration for a class io.helidon.example.AdminApplication that changes the routing path to /management : <markup lang=\"yaml\" >io.helidon.examples.AdminApplication: routing-path: path: \"/management\" ",
            "title": "Overriding JAX-RS application path"
        },
        {
            "location": "/mp/jaxrs/02_server-configuration",
            "text": " A full configuration example (YAML): <markup lang=\"yaml\" >server: port: 8080 sockets: management: port: 8090 io.helidon.examples.AdminApplication: routing-name: name: \"management\" required: true routing-path: path: \"/management\" ",
            "title": "Example configuration of JAX-RS application"
        },
        {
            "location": "/mp/metrics/01_introduction",
            "text": " To enable MicroProfile Metrics either add a dependency on the helidon-microprofile bundle or add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-metrics&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/metrics/01_introduction",
            "text": " Helidon provides three types of metrics: base, vendor, and application. Helidon automatically provides built-in base and vendor metrics. Applications can use these metrics without additional configuration or code changes. ",
            "title": "Overview"
        },
        {
            "location": "/mp/metrics/01_introduction",
            "text": " Learn more about MicroProfile Metrics specification . Create a sample MicroProfile (MP) project that can be used to run some basic examples using both built-in and custom metrics with Helidon MP. Helidon MP Metrics Guide . ",
            "title": "Next Steps"
        },
        {
            "location": "/mp/reactivestreams/03_rsoperators",
            "text": "",
            "title": "Reactive Streams Operators"
        },
        {
            "location": "/mp/reactivestreams/03_rsoperators",
            "text": " To enable Reactive Streams add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.reactive-streams&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-reactive-streams&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/reactivestreams/03_rsoperators",
            "text": " Graphs are pre-prepared stream builders with stages , which can be combined together to closed graph with methods via and to . <markup lang=\"java\" title=\"Combining the graphs and running the stream:\" > // Assembly of stream, nothing is streamed yet PublisherBuilder&lt;String&gt; publisherStage = ReactiveStreams.of(\"foo\", \"bar\") .map(String::trim); ProcessorBuilder&lt;String, String&gt; processorStage = ReactiveStreams.&lt;String&gt;builder() .map(String::toUpperCase); SubscriberBuilder&lt;String, Void&gt; subscriberStage = ReactiveStreams.&lt;String&gt;builder() .map(s -&gt; \"Item received: \" + s) .forEach(System.out::println); // Execution of pre-prepared stream publisherStage .via(processorStage) .to(subscriberStage).run(); &gt; Item received: FOO &gt; Item received: BAR ",
            "title": "Graphs"
        },
        {
            "location": "/mp/reactivestreams/03_rsoperators",
            "text": " Implementation of MicroProfile Reactive Streams Operators specification. A standardised tool for manipulation with Reactive Streams , provides set of operators as so called stages, and the builders to prepare graphs of stages for streams to be build from. <markup lang=\"java\" title=\"Example of simple closed graph usage:\" >AtomicInteger sum = new AtomicInteger(); ReactiveStreams.of(\"1\", \"2\", \"3\", \"4\", \"5\") .limit(3) .map(Integer::parseInt) .forEach(sum::addAndGet) .run() .whenComplete((r, t) -&gt; System.out.println(\"Sum: \" + sum.get())); &gt; Sum: 6 Operators(Stages) fromIterable Create new PublisherBuilder from supplied Iterable of Create new PublisherBuilder emitting supplied elements ofNullable Empty stream if supplied item is null iterate Create infinite stream with every next item created by supplied operator from previous item generate Create infinite stream with every item created by invocation of supplier empty Create new PublisherBuilder emitting as a first thing complete signal failed Create new PublisherBuilder emitting as a first thing error signal concat Concat two streams coupled Two parallel streams sharing cancel, onError and onComplete signals limit Limit the size of the stream, when limit is reached completes peek Invoke consumer for every item passing this operator filter Drop item when expression result to false map Transform items flatMap Flatten supplied stream to current stream flatMapIterable Flatten supplied iterable to current stream flatMapCompletionStage Map elements to completion stage and wait for each to be completed, keeps the order flatMapRSPublisher Map elements to Publishers and flatten this sub streams to original stream takeWhile Let items pass until expression is true, first time its false completes dropWhile Drop items until expression is true, first time its false let everything pass skip Drop first n items distinct Let pass only distinct items via Connect supplied processor to current stream return supplied processor onError Invoke supplied consumer when onError signal received onErrorResume Emit one last supplied item when onError signal received onErrorResumeWith When onError signal received continue emitting from supplied publisher builder onErrorResumeWithRsPublisher When onError signal received continue emitting from supplied publisher onComplete Invoke supplied runnable when onComplete signal received onTerminate Invoke supplied runnable when onComplete or onError signal received ifEmpty Executes given java.lang.Runnable when stream is finished without value(empty stream). to Connect this stream to supplied subscriber toList Collect all intercepted items to List collect Collect all intercepted items with provided collector forEach Invoke supplied Consumer for each intercepted item ignore Ignore all onNext signals, wait for onComplete reduce Reduction with provided expression cancel Cancel stream immediately findFirst Return first intercepted element Graphs Graphs are pre-prepared stream builders with stages , which can be combined together to closed graph with methods via and to . <markup lang=\"java\" title=\"Combining the graphs and running the stream:\" > // Assembly of stream, nothing is streamed yet PublisherBuilder&lt;String&gt; publisherStage = ReactiveStreams.of(\"foo\", \"bar\") .map(String::trim); ProcessorBuilder&lt;String, String&gt; processorStage = ReactiveStreams.&lt;String&gt;builder() .map(String::toUpperCase); SubscriberBuilder&lt;String, Void&gt; subscriberStage = ReactiveStreams.&lt;String&gt;builder() .map(s -&gt; \"Item received: \" + s) .forEach(System.out::println); // Execution of pre-prepared stream publisherStage .via(processorStage) .to(subscriberStage).run(); &gt; Item received: FOO &gt; Item received: BAR ",
            "title": "Reactive Streams Operators"
        },
        {
            "location": "/se/grpc/21_client_introduction",
            "text": " Helidon gRPC Client provides a framework for creating gRPC client applications. The client framework allows a uniform way to access gRPC services that use either Protobuf or some custom serialization format. It also allows access to gRPC services that use either Java serialization, Protobuf or a custom serialization format. The class GrpcServiceClient acts as the client object for accessing a gRPC service. Creating a GrpcServiceClient involves: Creating a ClientServiceDescriptor which describes the methods in the service that this client can invoke. Creating a gRPC Channel through which the client communicates with the server. In later sections in this document, you will see how to customize both ClientServiceDescriptor and the Channel . ",
            "title": "preambule"
        },
        {
            "location": "/se/grpc/21_client_introduction",
            "text": " To enable gRPC Client add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.grpc&lt;/groupId&gt; &lt;artifactId&gt;helidon-grpc-client&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/grpc/21_client_introduction",
            "text": " First, create and run a minimalist HelloService gRPC server application as described in the gRPC Server documentation. Assuming that the server is running on port 1408, create a client as follows: <markup lang=\"java\" >public static void main(String[] args) throws Exception { ClientServiceDescriptor descriptor = ClientServiceDescriptor.builder(HelloService.class) // (1) .unary(\"SayHello\") // (2) .build(); Channel channel = ManagedChannelBuilder.forAddress(\"localhost\", 1408) // (3) .usePlaintext() .build(); GrpcServiceClient client = GrpcServiceClient.create(channel, descriptor); // (4) CompletionStage&lt;String&gt; future = client.unary(\"SayHello\", \"Helidon gRPC!!\"); // (5) System.out.println(future.get()); // (6) } Create a ClientServiceDescriptor for the HelloService . Add the SayHello unary method to the ClientServiceDescriptor . This method, by default, uses Java serialization for marshalling and unmarshalling the request and response values. Create a gRPC Channel that is communicates with the server that is running in localhost and on port 1408 (using plaintext). Create the GrpcServiceClient that uses the above Channel and ClientServiceDescriptor . GrpcClientService represents a client that can be used to define the set of methods described by the specified ClientServiceDescriptor . In our case, the ClientServiceDescriptor defines one unary method called SayHello . Invoke the SayHello method which returns a CompletionStage&lt;String&gt; . Print the result. The example above creates a very simple client to the gRPC server that by default uses Java serialization to marshall requests and responses. We will look into deployment of \"standard\" gRPC services that use Protobuf for request and response marshalling, as well as how you can configure custom marshallers, later in this document. ",
            "title": "Quick Start"
        },
        {
            "location": "/mp/graphql/01_mp_graphql",
            "text": " The Microprofile GraphQL APIs are an extension to Helidon MP to allow building of applications that can expose a GraphQL endpoint. ",
            "title": "preambule"
        },
        {
            "location": "/mp/graphql/01_mp_graphql",
            "text": " The Helidon GraphQL feature is currently experimental and the APIs are subject to changes until GraphQL support is stabilized. ",
            "title": "Experimental"
        },
        {
            "location": "/mp/graphql/01_mp_graphql",
            "text": " To enable MicroProfile GraphQL add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.graphql&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-graphql-server&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/graphql/01_mp_graphql",
            "text": " Helidon MP implements the MicroProfile GraphQL spec version 1.1.0. The spec prescribes how applications can be built to expose an endpoint for GraphQL. GraphQL is an open-source data query and manipulation language for APIs, and a runtime for fulfilling queries with existing data. It provides an alternative to, though not necessarily a replacement for, REST. For more information on GraphQL see https://graphql.org/ . ",
            "title": "About the MicroProfile GraphQL Specification"
        },
        {
            "location": "/mp/graphql/01_mp_graphql",
            "text": " The MicroProfile GraphQL specification defines a number of key annotations to be used when writing a GraphQL endpoint: @GraphQLApi - identifies a CDI Bean as a GraphQL Endpoint @Query - identifies a method as returning specified fields for an object or collection of entities @Mutation - identifies a method which creates, deletes or updates entities Please see the Microprofile GraphQL spec for the full list of available annotations. For example, the following defines a GraphQL endpoint with a number of queries and mutations that work against a fictional CustomerService service and Customer class. <markup lang=\"java\" title=\"Simple ContactGraphQLApi\" >@ApplicationScoped @org.eclipse.microprofile.graphql.GraphQLApi public class ContactGraphQLApi { @Inject private CustomerService customerService; @org.eclipse.microprofile.graphql.Query public Collection&lt;Customer&gt; findAllCustomers() { return customerService.getAllCustomers(); } @org.eclipse.microprofile.graphql.Query public Customer findCustomer(@Name(\"customerId\") int id) { return customerService.getCustomer(id); } @org.eclipse.microprofile.graphql.Query public Collection&lt;Customer&gt; findCustomersByName(@Name(\"name\") String name) { return customerService.getAllCustomers(name); } @org.eclipse.microprofile.graphql.Mutation public Contact createCustomer(@Name(\"customerId\") int id, @Name(\"name\") String name, @Name(\"balance\") float balance) { return customerService.createCustomer(id, name, balance); } } public class customer { private int id; @NonNull private String name; private float balance; // getters and setters omitted for brevity } a query with no-arguments that will return all Customers a query that takes an argument to return a specific Customer a query that optionally takes a name and returns a collection of Customers a mutation that creates a Customer and returns the newly created Customer The above would generate a GraphQL schema as shown below: <markup lang=\"graphql\" title=\"Sample GraphQL Schema\" >type Query { findAllCustomers: [Customer] findCustomer(customerId: Int!): Customer findCustomersByName(name: String): [Customers] } type Mutation { createCustomer(customerId: Int!, name: String!, balance: Float!): Customer } type Customer { id: Int! name: String! balance: Float } After application startup, a GraphQL schema will be generated from your annotated API classes and POJO&#8217;s and you will be able to access these via the URL&#8217;s described below. ",
            "title": "Defining your API"
        },
        {
            "location": "/mp/graphql/01_mp_graphql",
            "text": " As per the instructions here ensure you have added a src/main/resources/META-INF/beans.xml file, so the CDI implementation can pick up your classes. A Main class is not needed, you can configure io.helidon.microprofile.cdi.Main as the entry point. Optionally, you can configure a custom entry point (such as when you need custom configuration setup). <markup lang=\"java\" title=\"Sample Entry-point\" >public class MyMain { public static void main(String[] args) { io.helidon.microprofile.cdi.Main.main(args); } } ",
            "title": "Creating your entry-point"
        },
        {
            "location": "/mp/graphql/01_mp_graphql",
            "text": " As part of building your application, you must create a Jandex index using the jandex-maven-plugin for all API and POJO classes that are used. <markup lang=\"xml\" title=\"Generate Jandex index\" >&lt;plugin&gt; &lt;groupId&gt;org.jboss.jandex&lt;/groupId&gt; &lt;artifactId&gt;jandex-maven-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;make-index&lt;/id&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; ",
            "title": "Building your application"
        },
        {
            "location": "/mp/graphql/01_mp_graphql",
            "text": " Defining your API The MicroProfile GraphQL specification defines a number of key annotations to be used when writing a GraphQL endpoint: @GraphQLApi - identifies a CDI Bean as a GraphQL Endpoint @Query - identifies a method as returning specified fields for an object or collection of entities @Mutation - identifies a method which creates, deletes or updates entities Please see the Microprofile GraphQL spec for the full list of available annotations. For example, the following defines a GraphQL endpoint with a number of queries and mutations that work against a fictional CustomerService service and Customer class. <markup lang=\"java\" title=\"Simple ContactGraphQLApi\" >@ApplicationScoped @org.eclipse.microprofile.graphql.GraphQLApi public class ContactGraphQLApi { @Inject private CustomerService customerService; @org.eclipse.microprofile.graphql.Query public Collection&lt;Customer&gt; findAllCustomers() { return customerService.getAllCustomers(); } @org.eclipse.microprofile.graphql.Query public Customer findCustomer(@Name(\"customerId\") int id) { return customerService.getCustomer(id); } @org.eclipse.microprofile.graphql.Query public Collection&lt;Customer&gt; findCustomersByName(@Name(\"name\") String name) { return customerService.getAllCustomers(name); } @org.eclipse.microprofile.graphql.Mutation public Contact createCustomer(@Name(\"customerId\") int id, @Name(\"name\") String name, @Name(\"balance\") float balance) { return customerService.createCustomer(id, name, balance); } } public class customer { private int id; @NonNull private String name; private float balance; // getters and setters omitted for brevity } a query with no-arguments that will return all Customers a query that takes an argument to return a specific Customer a query that optionally takes a name and returns a collection of Customers a mutation that creates a Customer and returns the newly created Customer The above would generate a GraphQL schema as shown below: <markup lang=\"graphql\" title=\"Sample GraphQL Schema\" >type Query { findAllCustomers: [Customer] findCustomer(customerId: Int!): Customer findCustomersByName(name: String): [Customers] } type Mutation { createCustomer(customerId: Int!, name: String!, balance: Float!): Customer } type Customer { id: Int! name: String! balance: Float } After application startup, a GraphQL schema will be generated from your annotated API classes and POJO&#8217;s and you will be able to access these via the URL&#8217;s described below. Creating your entry-point As per the instructions here ensure you have added a src/main/resources/META-INF/beans.xml file, so the CDI implementation can pick up your classes. A Main class is not needed, you can configure io.helidon.microprofile.cdi.Main as the entry point. Optionally, you can configure a custom entry point (such as when you need custom configuration setup). <markup lang=\"java\" title=\"Sample Entry-point\" >public class MyMain { public static void main(String[] args) { io.helidon.microprofile.cdi.Main.main(args); } } Building your application As part of building your application, you must create a Jandex index using the jandex-maven-plugin for all API and POJO classes that are used. <markup lang=\"xml\" title=\"Generate Jandex index\" >&lt;plugin&gt; &lt;groupId&gt;org.jboss.jandex&lt;/groupId&gt; &lt;artifactId&gt;jandex-maven-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;make-index&lt;/id&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; ",
            "title": "Getting Started"
        },
        {
            "location": "/mp/graphql/01_mp_graphql",
            "text": " After starting your application you should see a message similar to the following indicating the GraphQL support is available: <markup lang=\"bash\" title=\"Sample Startup output\" >2020.11.16 12:29:58 INFO io.helidon.common.HelidonFeatures Thread[features-thread,5,main]: Helidon MP 2.1.1-SNAPSHOT features: [CDI, Config, Fault Tolerance, GraphQL, Health, JAX-RS, Metrics, Open API, Security, Server, Tracing] 2020.11.16 12:29:58 INFO io.helidon.common.HelidonFeatures.experimental Thread[features-thread,5,main]: You are using experimental features. These APIs may change, please follow changelog! 2020.11.16 12:29:58 INFO io.helidon.common.HelidonFeatures.experimental Thread[features-thread,5,main]: Experimental feature: GraphQL (GraphQL) You can then use your GraphQL client via the default endpoint http://host:port/graphql . The GraphQL Schema is available via http://host:port/graphql/schema.graphql . If you wish to use the GraphiQL UI ( https://github.com/graphql/graphiql ) then please see the Helidon Microprofile GraphQL example at the following URL: https://github.com/oracle/helidon/tree/master/examples/microprofile/graphql ",
            "title": "Accessing the GraphQL end-points"
        },
        {
            "location": "/mp/graphql/01_mp_graphql",
            "text": " The specification defines the following configuration options: key default value description mp.graphql.defaultErrorMessage Server Error Error message to send to caller in case of error mp.graphql.exceptionsBlackList &#160; Array of checked exception classes that should return default error message mp.graphql.exceptionsWhiteList &#160; Array of unchecked exception classes that should return message to caller (instead of default error message) These configuration options are more significant that the configuration options that can be used to configure GraphQL invocation (see below). ",
            "title": "MicroProfile GraphQL"
        },
        {
            "location": "/mp/graphql/01_mp_graphql",
            "text": " In addition, we provide the following configuration options: The following configuration keys can be used to set up integration with WebServer: key default value description graphql.web-context /graphql Context that serves the GraphQL endpoint. graphql.schema-uri /schema.graphql URI that serves the schema (under web context) graphql.cors &#160; CORS configuration for this service graphql.executor-service &#160; Configuration of ServerThreadPoolSupplier used to set up executor service The following configuration keys can be used to set up GraphQL invocation: key default value description graphql.default-error-message Server Error Error message to send to caller in case of error graphql.exception-white-list &#160; Array of checked exception classes that should return default error message graphql.exception-black-list &#160; Array of unchecked exception classes that should return message to caller (instead of default error message) ",
            "title": "Helidon GraphQL"
        },
        {
            "location": "/mp/graphql/01_mp_graphql",
            "text": " MicroProfile GraphQL The specification defines the following configuration options: key default value description mp.graphql.defaultErrorMessage Server Error Error message to send to caller in case of error mp.graphql.exceptionsBlackList &#160; Array of checked exception classes that should return default error message mp.graphql.exceptionsWhiteList &#160; Array of unchecked exception classes that should return message to caller (instead of default error message) These configuration options are more significant that the configuration options that can be used to configure GraphQL invocation (see below). Helidon GraphQL In addition, we provide the following configuration options: The following configuration keys can be used to set up integration with WebServer: key default value description graphql.web-context /graphql Context that serves the GraphQL endpoint. graphql.schema-uri /schema.graphql URI that serves the schema (under web context) graphql.cors &#160; CORS configuration for this service graphql.executor-service &#160; Configuration of ServerThreadPoolSupplier used to set up executor service The following configuration keys can be used to set up GraphQL invocation: key default value description graphql.default-error-message Server Error Error message to send to caller in case of error graphql.exception-white-list &#160; Array of checked exception classes that should return default error message graphql.exception-black-list &#160; Array of unchecked exception classes that should return message to caller (instead of default error message) ",
            "title": "Configuration Options"
        },
        {
            "location": "/mp/cors/02_using-cors",
            "text": " To enable CORS behavior for a resource in your Helidon MP application, you simply add the Helidon MP @CrossOrigin annotation to a particular method in your resource class. ",
            "title": "preambule"
        },
        {
            "location": "/mp/cors/02_using-cors",
            "text": " To enable CORS add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-cors&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/cors/02_using-cors",
            "text": " You set up CORS in Helidon MP using the @CrossOrigin annotation. The following example of the @CrossOrigin annotation allows the resource associated with it to be shared with the origins http://foo.bar and http://bar.foo using DELETE or PUT , and permits requests to include the non-standard headers X-foo and X-bar . <markup lang=\"java\" >@CrossOrigin(value = {\"http://foo.bar\", \"http://bar.foo\"}, allowHeaders = {\"X-foo\", \"X-bar\"}, allowMethods = {HttpMethod.DELETE, HttpMethod.PUT}) ",
            "title": "Understanding the @CrossOrigin Annotation"
        },
        {
            "location": "/mp/cors/02_using-cors",
            "text": " To add CORS support to your Helidon MP application: Determine the type of cross-origin resource sharing you want to allow for each endpoint in your application. Add a dependency on the Helidon MP CORS artifact to your Maven pom.xml file. Edit each JAX-RS resource class in your application to add the desired CORS behavior as described in the following sections. ",
            "title": "Getting Started"
        },
        {
            "location": "/mp/cors/02_using-cors",
            "text": " Adding CORS behavior to your Helidon MP application involves three simple steps: For reach resource class in your application: Identify the resources and subresources&#8212;&#8203;in other words, the paths&#8212;&#8203;supported in each. For each of those resources and subresources make sure you have a Java method annotated with @OPTIONS and with the correct @Path . Create these methods for each resource (for each path) if you do not already have them. To each of those @OPTIONS methods add a @CrossOrigin annotation that describes the cross-origin sharing you want for that resource. Using @CrossOrigin Correctly Use the @CrossOrigin annotation only on methods which also have the @OPTIONS annotation. Remember that the @CrossOrigin settings apply to a given path and therefore to all Java resource methods which share that path. Helidon MP aborts the server start-up if a resource method other than an @OPTIONS method has the @CrossOrigin annotation. The Helidon MP CORS implementation automatically uses the @CrossOrigin annotation you add to each @OPTIONS method to enforce cross-origin sharing behavior for the resource identified by that method&#8217;s @Path annotation. For an informal look at the reasons for applying the @CrossOrigin annotation to the @OPTIONS method, instead of another method, see Why @OPTIONS ? . ",
            "title": "Adding CORS Support to Your Helidon MP Application"
        },
        {
            "location": "/mp/cors/02_using-cors",
            "text": " In the Helidon MP Quickstart application you can change the greeting by sending a PUT request to the /greet/greeting resource. The example below extends the Helidon MP QuickStart application (the greeting app) to: Permit unrestricted sharing of the resource that returns greetings, and Restrict sharing of the resource that updates the greeting so that only the origins http://foo.com and http://there.com can change the greeting. <markup lang=\"java\" >@OPTIONS @CrossOrigin() public void options() {} @OPTIONS @Path(\"/greeting\") @CrossOrigin(allowMethods = {\"PUT\"}, allowOrigins = {\"http://foo.com\", \"http://there.com\"}) public void optionsForGreeting() {} Uses the default cross-origin sharing, which permits sharing via all HTTP methods to all origins. Specifies sharing only via the PUT HTTP method and only to the two listed origins. ",
            "title": "Sample Application Using the @CrossOrigin Annotation"
        },
        {
            "location": "/mp/cors/02_using-cors",
            "text": " Use MicroProfile configuration to override the CORS behavior set in the application code. Learn more. See the Helidon CORS support in action by building and running the CORS example . ",
            "title": "Next steps"
        },
        {
            "location": "/mp/scheduling/01_introduction",
            "text": " To enable Scheduling add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.scheduling&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-scheduling&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/scheduling/01_introduction",
            "text": " For simple fixed rate invocation interval is @FixedRate the easiest way for scheduling task invocation. <markup lang=\"java\" title=\"Example of scheduling with fixed rate\" >@FixedRate(initialDelay = 5, value = 10, timeUnit = TimeUnit.MINUTES) public void methodName() { System.out.println(\"Every 10 minutes, first invocation 5 minutes after start\"); } All values defined with the annotation can be overridden from the config. <markup lang=\"yaml\" title=\"Overiding annotated values from config\" >fully.quallified.ClassName.methodName: schedule: initial-delay: 5 delay: 15 time-unit: HOURS Metadata like human-readable interval description or configured values are available through FixedRateInvocation injected as method parameter. <markup lang=\"java\" title=\"Example with ivocation metadata\" >@FixedRate(initialDelay = 5, value = 10, timeUnit = TimeUnit.MINUTES) public void methodName(FixedRateInvocation inv) { System.out.println(\"Method invoked \" + inv.description()); } ",
            "title": "Fixed rate"
        },
        {
            "location": "/mp/scheduling/01_introduction",
            "text": " For more complicated interval definition, cron expression can be leveraged with @Schedule annotation. <markup lang=\"java\" title=\"Example of scheduling with cron expression\" >@Scheduled(\"0 15 8 ? * *\", concurrentExecution = false) public void methodName() { System.out.println(\"Executer every day at 8:15\"); } <markup title=\"Cron expression format\" >&lt;seconds&gt; &lt;minutes&gt; &lt;hours&gt; &lt;day-of-month&gt; &lt;month&gt; &lt;day-of-week&gt; &lt;year&gt; Cron expression fields Order Name Supported values Supported field format Optional 1 seconds 0-59 CONST, LIST, RANGE, WILDCARD, INCREMENT false 2 minutes 0-59 CONST, LIST, RANGE, WILDCARD, INCREMENT false 3 hours 0-23 CONST, LIST, RANGE, WILDCARD, INCREMENT false 4 day-of-month 1-31 CONST, LIST, RANGE, WILDCARD, INCREMENT, ANY, LAST, WEEKDAY false 5 month 1-12 or JAN-DEC CONST, LIST, RANGE, WILDCARD, INCREMENT false 6 day-of-week 1-7 or SUN-SAT CONST, LIST, RANGE, WILDCARD, INCREMENT, ANY, NTH, LAST false 7 year 1970-2099 CONST, LIST, RANGE, WILDCARD, INCREMENT true Field formats Name Regex format Example Description CONST \\d+ 12 exact value LIST \\d+,\\d+(,\\d+)* 1,2,3,4 list of constants RANGE \\d+-\\d+ 15-30 range of values from-to WILDCARD \\* * all values withing the field INCREMENT \\d+\\/\\d+ 0/5 inital number / increments, 2/5 means 2,7,9,11,16,&#8230;&#8203; ANY \\? ? any day(apply only to day-of-week and day-of-month) NTH \\# 1#3 nth day of the month, 2#3 means third monday of the month LAST \\d*L(+\\d+|\\-\\d+)? 3L-3 last day of the month in day-of-month or last nth day in the day-of-week WEEKDAY \\# 1#3 nearest weekday of the nth day of month, 1W is the first monday of the week Examples Cron expression Description * * * * * ? Every second 0/2 * * * * ? * Every 2 seconds 0 45 9 ? * * Every day at 9:45 0 15 8 ? * MON-FRI Every workday at 8:15 Metadata like human-readable interval description or configured values are available through CronInvocation injected as method parameter. <markup lang=\"java\" title=\"Example with invocation metadata\" >@Scheduled(\"0 15 8 ? * *\") public void methodName(CronInvocation inv) { System.out.println(\"Method invoked \" + inv.description()); } Scheduled annotation properties can be overridden using application.yaml properties <markup lang=\"yaml\" title=\"Overriding annotated values from config\" >fully.quallified.ClassName.methodName: schedule: cron: \"* * * * * ?\" concurrent: false Configuration properties Property Description cron String containing cron setup concurrent Boolean, equivalent concurrentExecution property of @Scheduled . Default true . ",
            "title": "Cron expression"
        },
        {
            "location": "/mp/scheduling/01_introduction",
            "text": " For scheduling tasks in Helidon you can choose from @Scheduled or @FixedRate annotations by required complexity of invocation interval. All you need is define method with one of the annotations in application scoped bean. Fixed rate For simple fixed rate invocation interval is @FixedRate the easiest way for scheduling task invocation. <markup lang=\"java\" title=\"Example of scheduling with fixed rate\" >@FixedRate(initialDelay = 5, value = 10, timeUnit = TimeUnit.MINUTES) public void methodName() { System.out.println(\"Every 10 minutes, first invocation 5 minutes after start\"); } All values defined with the annotation can be overridden from the config. <markup lang=\"yaml\" title=\"Overiding annotated values from config\" >fully.quallified.ClassName.methodName: schedule: initial-delay: 5 delay: 15 time-unit: HOURS Metadata like human-readable interval description or configured values are available through FixedRateInvocation injected as method parameter. <markup lang=\"java\" title=\"Example with ivocation metadata\" >@FixedRate(initialDelay = 5, value = 10, timeUnit = TimeUnit.MINUTES) public void methodName(FixedRateInvocation inv) { System.out.println(\"Method invoked \" + inv.description()); } Cron expression For more complicated interval definition, cron expression can be leveraged with @Schedule annotation. <markup lang=\"java\" title=\"Example of scheduling with cron expression\" >@Scheduled(\"0 15 8 ? * *\", concurrentExecution = false) public void methodName() { System.out.println(\"Executer every day at 8:15\"); } <markup title=\"Cron expression format\" >&lt;seconds&gt; &lt;minutes&gt; &lt;hours&gt; &lt;day-of-month&gt; &lt;month&gt; &lt;day-of-week&gt; &lt;year&gt; Cron expression fields Order Name Supported values Supported field format Optional 1 seconds 0-59 CONST, LIST, RANGE, WILDCARD, INCREMENT false 2 minutes 0-59 CONST, LIST, RANGE, WILDCARD, INCREMENT false 3 hours 0-23 CONST, LIST, RANGE, WILDCARD, INCREMENT false 4 day-of-month 1-31 CONST, LIST, RANGE, WILDCARD, INCREMENT, ANY, LAST, WEEKDAY false 5 month 1-12 or JAN-DEC CONST, LIST, RANGE, WILDCARD, INCREMENT false 6 day-of-week 1-7 or SUN-SAT CONST, LIST, RANGE, WILDCARD, INCREMENT, ANY, NTH, LAST false 7 year 1970-2099 CONST, LIST, RANGE, WILDCARD, INCREMENT true Field formats Name Regex format Example Description CONST \\d+ 12 exact value LIST \\d+,\\d+(,\\d+)* 1,2,3,4 list of constants RANGE \\d+-\\d+ 15-30 range of values from-to WILDCARD \\* * all values withing the field INCREMENT \\d+\\/\\d+ 0/5 inital number / increments, 2/5 means 2,7,9,11,16,&#8230;&#8203; ANY \\? ? any day(apply only to day-of-week and day-of-month) NTH \\# 1#3 nth day of the month, 2#3 means third monday of the month LAST \\d*L(+\\d+|\\-\\d+)? 3L-3 last day of the month in day-of-month or last nth day in the day-of-week WEEKDAY \\# 1#3 nearest weekday of the nth day of month, 1W is the first monday of the week Examples Cron expression Description * * * * * ? Every second 0/2 * * * * ? * Every 2 seconds 0 45 9 ? * * Every day at 9:45 0 15 8 ? * MON-FRI Every workday at 8:15 Metadata like human-readable interval description or configured values are available through CronInvocation injected as method parameter. <markup lang=\"java\" title=\"Example with invocation metadata\" >@Scheduled(\"0 15 8 ? * *\") public void methodName(CronInvocation inv) { System.out.println(\"Method invoked \" + inv.description()); } Scheduled annotation properties can be overridden using application.yaml properties <markup lang=\"yaml\" title=\"Overriding annotated values from config\" >fully.quallified.ClassName.methodName: schedule: cron: \"* * * * * ?\" concurrent: false Configuration properties Property Description cron String containing cron setup concurrent Boolean, equivalent concurrentExecution property of @Scheduled . Default true . ",
            "title": "Scheduling"
        },
        {
            "location": "/se/reactivemessaging/04_kafka",
            "text": " To enable Kafka Connector add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.messaging.kafka&lt;/groupId&gt; &lt;artifactId&gt;helidon-messaging-kafka&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/reactivemessaging/04_kafka",
            "text": "<markup lang=\"java\" title=\"Example of consuming from Kafka:\" >String kafkaServer = config.get(\"app.kafka.bootstrap.servers\").asString().get(); String topic = config.get(\"app.kafka.topic\").asString().get(); Channel&lt;String&gt; fromKafka = Channel.&lt;String&gt;builder() .name(\"from-kafka\") .publisherConfig(KafkaConnector.configBuilder() .bootstrapServers(kafkaServer) .groupId(\"example-group-\" + session.getId()) .topic(topic) .autoOffsetReset(KafkaConfigBuilder.AutoOffsetReset.LATEST) .enableAutoCommit(true) .keyDeserializer(StringDeserializer.class) .valueDeserializer(StringDeserializer.class) .build() ) .build(); KafkaConnector kafkaConnector = KafkaConnector.create(); Messaging messaging = Messaging.builder() .connector(kafkaConnector) .listener(fromKafka, payload -&gt; { System.out.println(\"Kafka says: \" + payload); }) .build() .start(); Prepare a channel for connecting kafka connector with specific publisher configuration &#8594; listener Channel &#8594; connector mapping is automatic when using KafkaConnector.configBuilder() Prepare Kafka connector, can be used by any channel <markup lang=\"java\" title=\"Example of producing to Kafka:\" >String kafkaServer = config.get(\"app.kafka.bootstrap.servers\").asString().get(); String topic = config.get(\"app.kafka.topic\").asString().get(); Channel&lt;String&gt; toKafka = Channel.&lt;String&gt;builder() .subscriberConfig(KafkaConnector.configBuilder() .bootstrapServers(kafkaServer) .topic(topic) .keySerializer(StringSerializer.class) .valueSerializer(StringSerializer.class) .build() ).build(); KafkaConnector kafkaConnector = KafkaConnector.create(); messaging = Messaging.builder() .publisher(toKafka, Multi.just(\"test1\", \"test2\").map(Message::of)) .connector(kafkaConnector) .build() .start(); Prepare a channel for connecting kafka connector with specific publisher configuration &#8594; listener Channel &#8594; connector mapping is automatic when using KafkaConnector.configBuilder() Prepare Kafka connector, can be used by any channel ",
            "title": "Explicit config with config builder"
        },
        {
            "location": "/se/reactivemessaging/04_kafka",
            "text": "<markup lang=\"yaml\" title=\"Example of connector config:\" >mp.messaging: incoming.from-kafka: connector: helidon-kafka topic: messaging-test-topic-1 auto.offset.reset: latest enable.auto.commit: true group.id: example-group-id outgoing.to-kafka: connector: helidon-kafka topic: messaging-test-topic-1 connector: helidon-kafka: bootstrap.servers: localhost:9092 key.serializer: org.apache.kafka.common.serialization.StringSerializer value.serializer: org.apache.kafka.common.serialization.StringSerializer key.deserializer: org.apache.kafka.common.serialization.StringDeserializer value.deserializer: org.apache.kafka.common.serialization.StringDeserializer <markup lang=\"java\" title=\"Example of consuming from Kafka:\" >Config config = Config.create(); Channel&lt;String&gt; fromKafka = Channel.create(\"from-kafka\"); KafkaConnector kafkaConnector = KafkaConnector.create(); Messaging messaging = Messaging.builder() .config(config) .connector(kafkaConnector) .listener(fromKafka, payload -&gt; { System.out.println(\"Kafka says: \" + payload); }) .build() .start(); Prepare Kafka connector, can be used by any channel <markup lang=\"java\" title=\"Example of producing to Kafka:\" >Config config = Config.create(); Channel&lt;String&gt; toKafka = Channel.create(\"to-kafka\"); KafkaConnector kafkaConnector = KafkaConnector.create(); messaging = Messaging.builder() .config(config) .publisher(toKafka, Multi.just(\"test1\", \"test2\").map(Message::of)) .connector(kafkaConnector) .build() .start(); Prepare Kafka connector, can be used by any channel Don&#8217;t forget to check out the examples with pre-configured Kafka docker image, for easy testing: https://github.com/oracle/helidon/tree/master/examples/messaging ",
            "title": "Implicit Helidon Config"
        },
        {
            "location": "/se/reactivemessaging/04_kafka",
            "text": " Connecting streams to Kafka with Reactive Messaging couldn&#8217;t be easier. Explicit config with config builder <markup lang=\"java\" title=\"Example of consuming from Kafka:\" >String kafkaServer = config.get(\"app.kafka.bootstrap.servers\").asString().get(); String topic = config.get(\"app.kafka.topic\").asString().get(); Channel&lt;String&gt; fromKafka = Channel.&lt;String&gt;builder() .name(\"from-kafka\") .publisherConfig(KafkaConnector.configBuilder() .bootstrapServers(kafkaServer) .groupId(\"example-group-\" + session.getId()) .topic(topic) .autoOffsetReset(KafkaConfigBuilder.AutoOffsetReset.LATEST) .enableAutoCommit(true) .keyDeserializer(StringDeserializer.class) .valueDeserializer(StringDeserializer.class) .build() ) .build(); KafkaConnector kafkaConnector = KafkaConnector.create(); Messaging messaging = Messaging.builder() .connector(kafkaConnector) .listener(fromKafka, payload -&gt; { System.out.println(\"Kafka says: \" + payload); }) .build() .start(); Prepare a channel for connecting kafka connector with specific publisher configuration &#8594; listener Channel &#8594; connector mapping is automatic when using KafkaConnector.configBuilder() Prepare Kafka connector, can be used by any channel <markup lang=\"java\" title=\"Example of producing to Kafka:\" >String kafkaServer = config.get(\"app.kafka.bootstrap.servers\").asString().get(); String topic = config.get(\"app.kafka.topic\").asString().get(); Channel&lt;String&gt; toKafka = Channel.&lt;String&gt;builder() .subscriberConfig(KafkaConnector.configBuilder() .bootstrapServers(kafkaServer) .topic(topic) .keySerializer(StringSerializer.class) .valueSerializer(StringSerializer.class) .build() ).build(); KafkaConnector kafkaConnector = KafkaConnector.create(); messaging = Messaging.builder() .publisher(toKafka, Multi.just(\"test1\", \"test2\").map(Message::of)) .connector(kafkaConnector) .build() .start(); Prepare a channel for connecting kafka connector with specific publisher configuration &#8594; listener Channel &#8594; connector mapping is automatic when using KafkaConnector.configBuilder() Prepare Kafka connector, can be used by any channel Implicit Helidon Config <markup lang=\"yaml\" title=\"Example of connector config:\" >mp.messaging: incoming.from-kafka: connector: helidon-kafka topic: messaging-test-topic-1 auto.offset.reset: latest enable.auto.commit: true group.id: example-group-id outgoing.to-kafka: connector: helidon-kafka topic: messaging-test-topic-1 connector: helidon-kafka: bootstrap.servers: localhost:9092 key.serializer: org.apache.kafka.common.serialization.StringSerializer value.serializer: org.apache.kafka.common.serialization.StringSerializer key.deserializer: org.apache.kafka.common.serialization.StringDeserializer value.deserializer: org.apache.kafka.common.serialization.StringDeserializer <markup lang=\"java\" title=\"Example of consuming from Kafka:\" >Config config = Config.create(); Channel&lt;String&gt; fromKafka = Channel.create(\"from-kafka\"); KafkaConnector kafkaConnector = KafkaConnector.create(); Messaging messaging = Messaging.builder() .config(config) .connector(kafkaConnector) .listener(fromKafka, payload -&gt; { System.out.println(\"Kafka says: \" + payload); }) .build() .start(); Prepare Kafka connector, can be used by any channel <markup lang=\"java\" title=\"Example of producing to Kafka:\" >Config config = Config.create(); Channel&lt;String&gt; toKafka = Channel.create(\"to-kafka\"); KafkaConnector kafkaConnector = KafkaConnector.create(); messaging = Messaging.builder() .config(config) .publisher(toKafka, Multi.just(\"test1\", \"test2\").map(Message::of)) .connector(kafkaConnector) .build() .start(); Prepare Kafka connector, can be used by any channel Don&#8217;t forget to check out the examples with pre-configured Kafka docker image, for easy testing: https://github.com/oracle/helidon/tree/master/examples/messaging ",
            "title": "Reactive Kafka Connector"
        },
        {
            "location": "/mp/guides/05_security-oidc",
            "text": " This guide describes how to set up Keycloak and Helidon to secure an application with OIDC security provider. ",
            "title": "preambule"
        },
        {
            "location": "/mp/guides/05_security-oidc",
            "text": " For this 20 minute tutorial, you will need the following: <div class=\"table__overflow elevation-1 flex sm7 \"> A Helidon {upper-case-flavor} Application You can use your own application or use the Helidon {upper-case-flavor} Quickstart to create a sample application. Java&#160;SE&#160;11 ( Open&#160;JDK&#160;11 ) Helidon requires Java 11+. Maven 3.6.1+ Helidon requires Maven 3.6.1+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop ). <markup lang=\"bash\" title=\"Verify Prerequisites\" >java -version mvn --version docker --version kubectl version --short <markup lang=\"bash\" title=\"Setting JAVA_HOME\" ># On Mac export JAVA_HOME=`/usr/libexec/java_home -v 11` # On Linux # Use the appropriate path to your JDK export JAVA_HOME=/usr/lib/jvm/jdk-11 ",
            "title": "What You Need"
        },
        {
            "location": "/mp/guides/05_security-oidc",
            "text": " This guide describes the steps required to protect your whole application or a specific area with Open ID Connect (OIDC) security. OIDC is a secure mechanism for an application to contact an identity service. Its built on top of OAuth 2.0 and provides full-fledged authentication and authorization protocols. ",
            "title": "Introduction"
        },
        {
            "location": "/mp/guides/05_security-oidc",
            "text": " To install Keycloak with Docker, open a terminal and make sure the port 8080 is free. <markup lang=\"bash\" title=\"Enter the following command\" >docker run -p 8080:8080 -e KEYCLOAK_USER=admin -e KEYCLOAK_PASSWORD=admin quay.io/keycloak/keycloak:11.0.2 This will start Keycloak on local port 8080. It will create the admin user with username admin and password admin Feel free to modify 11.0.2 by any keycloak version of your wish. If you are running docker behind a proxy server, make sure it is either configured into docker or disabled. Otherwise, you might face a connection timeout because docker cannot download the required data. To verify that Keycloak is running correctly, go to the admin console : http://localhost:8080/auth/admin Log in using the username and password mentioned above: admin . You should be logged in successfully, and it prompts the admin console. ",
            "title": "On Docker"
        },
        {
            "location": "/mp/guides/05_security-oidc",
            "text": " Download the last version of Keycloak from Keycloak website : https://www.keycloak.org/downloads In the table Server choose Standalone server distribution. ZIP or Tar format are available, click on either to download Keycloak. After extracting the archive file, you should have a directory named keycloak followed by the version. For example, if you chose version 11.0.2, the folder must be named keycloak-11.0.2. Open keycloak folder to make it your current directory. <markup lang=\"bash\" title=\"Run this command from command prompt to open the directory:\" >cd keycloak-11.0.2 ",
            "title": "On JDK"
        },
        {
            "location": "/mp/guides/05_security-oidc",
            "text": " To start keycloak and have it ready for further steps, run the following command. <markup lang=\"bash\" title=\"On Linux run:\" >bin/standalone.sh <markup lang=\"bash\" title=\"On Windows run:\" >bin/standalone.bat Keycloak runs on localhost:8080 by default. ",
            "title": "Start Keycloak"
        },
        {
            "location": "/mp/guides/05_security-oidc",
            "text": " You need to create an admin user because it does not come by default when installing Keycloak. To do this, open http://localhost:8080/auth in your favorite browser. A window Welcome to Keycloak should be prompted. If not, check if any error appear in the terminal. Fill the form by adding Username and Password. Click on Create to create the admin user. Above Administration Console should be printed \"User created\" in a green rectangle. To check that the admin user was created correctly, click on Administration user which should redirect you to a Login form. Enter the Username and Password created earlier to log in. After successfully logged in, the admin console is prompted. ",
            "title": "Create an Admin User"
        },
        {
            "location": "/mp/guides/05_security-oidc",
            "text": " On Docker To install Keycloak with Docker, open a terminal and make sure the port 8080 is free. <markup lang=\"bash\" title=\"Enter the following command\" >docker run -p 8080:8080 -e KEYCLOAK_USER=admin -e KEYCLOAK_PASSWORD=admin quay.io/keycloak/keycloak:11.0.2 This will start Keycloak on local port 8080. It will create the admin user with username admin and password admin Feel free to modify 11.0.2 by any keycloak version of your wish. If you are running docker behind a proxy server, make sure it is either configured into docker or disabled. Otherwise, you might face a connection timeout because docker cannot download the required data. To verify that Keycloak is running correctly, go to the admin console : http://localhost:8080/auth/admin Log in using the username and password mentioned above: admin . You should be logged in successfully, and it prompts the admin console. On JDK Download the last version of Keycloak from Keycloak website : https://www.keycloak.org/downloads In the table Server choose Standalone server distribution. ZIP or Tar format are available, click on either to download Keycloak. After extracting the archive file, you should have a directory named keycloak followed by the version. For example, if you chose version 11.0.2, the folder must be named keycloak-11.0.2. Open keycloak folder to make it your current directory. <markup lang=\"bash\" title=\"Run this command from command prompt to open the directory:\" >cd keycloak-11.0.2 Start Keycloak To start keycloak and have it ready for further steps, run the following command. <markup lang=\"bash\" title=\"On Linux run:\" >bin/standalone.sh <markup lang=\"bash\" title=\"On Windows run:\" >bin/standalone.bat Keycloak runs on localhost:8080 by default. Create an Admin User You need to create an admin user because it does not come by default when installing Keycloak. To do this, open http://localhost:8080/auth in your favorite browser. A window Welcome to Keycloak should be prompted. If not, check if any error appear in the terminal. Fill the form by adding Username and Password. Click on Create to create the admin user. Above Administration Console should be printed \"User created\" in a green rectangle. To check that the admin user was created correctly, click on Administration user which should redirect you to a Login form. Enter the Username and Password created earlier to log in. After successfully logged in, the admin console is prompted. ",
            "title": "Install Keycloak"
        },
        {
            "location": "/mp/guides/05_security-oidc",
            "text": " A realm is the place where groups of applications, and their environment, can be created. It gathers : One or several applications One or several users Sessions Events Clients and their scopes By default, there is a realm called Master . It is used to manage Keycloak. It is not recommended to associate your application with this realm as it could disturb Keycloak functioning. To create a new realm to manage your application: Open Keycloak admin console http://localhost:8080/auth/admin . Hover the mouse over the dropdown in the top-left corner where it says Master , and press Add realm . Fill the form by adding the realm name, myRealm for example. Click on Create to create the new realm. To verify that your realm is created, on the top-left corner where it said Master previously should be now your realm name or myRealm is you followed the example. To switch from a realm to another, hover the realm name, and the other realm created appear in the dropdown. Click on any realm name to change the current realm. Make sure all configuration or modification are saved before changing the current realm or be subject to lose your configuration. ",
            "title": "Create a Realm"
        },
        {
            "location": "/mp/guides/05_security-oidc",
            "text": " Initially there are no users in a new realm. An unlimited number of user can be created per realm. A realm contains resources such as client which can be accessed by users. To create a new user: Open the Keycloak admin console: http://localhost:8080/auth/admin Click on Users in the left menu Press Add user Fill the form (Username is the only mandatory field) with this value Username: myUser Click Save A new user is just created but it needs a password to be able to login. To initialize it, do this: Click on Credentials at the top of the page, under Myuser . Fill Password and Password confirmation with the user password of your choice. If the Temporary field is set to ON , the user has to update password on next login. Click ON to make it OFF and prevent it. Press Set Password . A pop-up window is popping off. Click on Set Password to confirm the new password. To verify that the new user is created correctly: Open the Keycloak account console: http://localhost:8080/auth/realms/myRealm/account . Login with myUser and password chosen earlier. You should now be logged-in to the account console where users can manage their accounts. ",
            "title": "Create a User"
        },
        {
            "location": "/mp/guides/05_security-oidc",
            "text": " To create your first client: Open the Keycloak admin console: http://localhost:8080/auth/admin . Make sure the current realm is myRealm and not Master . Navigate to the left menu, into configure section, click on Clients . This window displays a table with every client from the realm. Click on Create . Fill the following: Client ID : myClientID Client Protocol : openid-connect Press Save Modify Access type : confidential Update Valid Redirect URIs : http://localhost:7987/* Click on + to add the new URI. Click on Save . A new tab named Credentials is created. Click on it to access this new tab. Select Client Authenticator : Client ID and Secret Click on generate secret to generate client secret. Keycloak is now configured and ready. Keep keycloak running on your terminal and open a new tab to set up Helidon. ",
            "title": "Create a Client"
        },
        {
            "location": "/mp/guides/05_security-oidc",
            "text": " To set up Keycloak properly, go to the admin console: http://localhost:8080/auth/admin If you are using Docker, use Username admin and password admin as it is the default admin user. Otherwise, use the username and password you used to create the admin user. Create a Realm A realm is the place where groups of applications, and their environment, can be created. It gathers : One or several applications One or several users Sessions Events Clients and their scopes By default, there is a realm called Master . It is used to manage Keycloak. It is not recommended to associate your application with this realm as it could disturb Keycloak functioning. To create a new realm to manage your application: Open Keycloak admin console http://localhost:8080/auth/admin . Hover the mouse over the dropdown in the top-left corner where it says Master , and press Add realm . Fill the form by adding the realm name, myRealm for example. Click on Create to create the new realm. To verify that your realm is created, on the top-left corner where it said Master previously should be now your realm name or myRealm is you followed the example. To switch from a realm to another, hover the realm name, and the other realm created appear in the dropdown. Click on any realm name to change the current realm. Make sure all configuration or modification are saved before changing the current realm or be subject to lose your configuration. Create a User Initially there are no users in a new realm. An unlimited number of user can be created per realm. A realm contains resources such as client which can be accessed by users. To create a new user: Open the Keycloak admin console: http://localhost:8080/auth/admin Click on Users in the left menu Press Add user Fill the form (Username is the only mandatory field) with this value Username: myUser Click Save A new user is just created but it needs a password to be able to login. To initialize it, do this: Click on Credentials at the top of the page, under Myuser . Fill Password and Password confirmation with the user password of your choice. If the Temporary field is set to ON , the user has to update password on next login. Click ON to make it OFF and prevent it. Press Set Password . A pop-up window is popping off. Click on Set Password to confirm the new password. To verify that the new user is created correctly: Open the Keycloak account console: http://localhost:8080/auth/realms/myRealm/account . Login with myUser and password chosen earlier. You should now be logged-in to the account console where users can manage their accounts. Create a Client To create your first client: Open the Keycloak admin console: http://localhost:8080/auth/admin . Make sure the current realm is myRealm and not Master . Navigate to the left menu, into configure section, click on Clients . This window displays a table with every client from the realm. Click on Create . Fill the following: Client ID : myClientID Client Protocol : openid-connect Press Save Modify Access type : confidential Update Valid Redirect URIs : http://localhost:7987/* Click on + to add the new URI. Click on Save . A new tab named Credentials is created. Click on it to access this new tab. Select Client Authenticator : Client ID and Secret Click on generate secret to generate client secret. Keycloak is now configured and ready. Keep keycloak running on your terminal and open a new tab to set up Helidon. ",
            "title": "Set up Keycloak"
        },
        {
            "location": "/mp/guides/05_security-oidc",
            "text": " Update the pom.xml file and add the following Helidon dependency to the &lt;dependencies&gt; section. <markup lang=\"xml\" title=\"Add the following dependency to pom.xml :\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-oidc&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Update Project Dependencies"
        },
        {
            "location": "/mp/guides/05_security-oidc",
            "text": " The OIDC security provider configuration can be joined to helidon configuration file. This file is located here: src/main/resources/application.yaml . It can be easily used to configure the web server without modifying application code. <markup lang=\"yaml\" title=\"Create application.yaml file and add the following line\" >security: providers: - abac: # Adds ABAC Provider - it does not require any configuration - oidc: redirect-uri: \"/oidc/redirect\" audience: \"account\" client-id: \"myClientID\" header-use: true client-secret: \"Client secret generated into Keycloak client credential\" identity-uri: \"http://localhost:8080/auth/realms/myRealm\" frontend-uri: \"http://localhost:7987\" client-id must be the same as the one configure in keycloak. The client secret generate by Keycloak during Create a client section. identity-uri is used to redirect the user to keycloak. frontend-uri will direct you back to the application. The client secret is the one generate into Keycloak Client Credentials. It must be copy past into client-id variable from application.yaml. Make sure keycloak and the application are not running on the same port. The application port value can be changed into microprofile-config.properties. <markup lang=\"properties\" title=\"Change these properties to configure the server host and port\" >server.port=7987 server.host=localhost If the port 7987 is already used, check what port is free on your machine. <markup lang=\"properties\" title=\"Replace the old port into microprofile-config.properties\" >server.port=\"{Your-new-port}\" <markup lang=\"yaml\" title=\"Replace the old port into application.yaml\" >frontend-uri: \"http://localhost:{Your-new-port}\" ",
            "title": "Add OIDC Security Properties"
        },
        {
            "location": "/mp/guides/05_security-oidc",
            "text": " The GreetResource class is a JAX-RS resource available at the endpoint /greet . Use @Authenticated annotation to protect any method or endpoint. Modify the getDefaultMessage method with the @Authenticated to limit its access. <markup lang=\"java\" title=\"Import Authenticated annotation:\" >import io.helidon.security.annotations.Authenticated; <markup lang=\"java\" title=\"Add @Authenticated to secure getDefaultMessage \" > @Authenticated @GET @Produces(MediaType.APPLICATION_JSON) public JsonObject getDefaultMessage() { return createResponse(\"World\"); } When a client will send an HTTP GET request at the endpoint http://localhost:7987/greet , he will be redirected to keycloak. Keycloak will check if the client has the required authorisation to access this endpoint. If the client can log in successfully, keycloak redirect it to the wished endpoint. If the client cannot log in, or the required access data are incomplete, Keycloak refuses the access. ",
            "title": "Secure Your Application"
        },
        {
            "location": "/mp/guides/05_security-oidc",
            "text": " Use the Helidon MP Maven archetype to create a simple project. It will be used as an example to show how to set up Helidon. Replace 2.5.4 by the latest helidon version. It will download the quickstart project into the current directory. <markup lang=\"bash\" title=\"Run the Maven archetype\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-mp \\ -DarchetypeVersion=2.5.4 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-mp \\ -Dpackage=io.helidon.examples.quickstart.mp <markup lang=\"bash\" title=\"The project will be built and run from the helidon-quickstart-mp directory:\" >cd helidon-quickstart-mp Update Project Dependencies Update the pom.xml file and add the following Helidon dependency to the &lt;dependencies&gt; section. <markup lang=\"xml\" title=\"Add the following dependency to pom.xml :\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-oidc&lt;/artifactId&gt; &lt;/dependency&gt; Add OIDC Security Properties The OIDC security provider configuration can be joined to helidon configuration file. This file is located here: src/main/resources/application.yaml . It can be easily used to configure the web server without modifying application code. <markup lang=\"yaml\" title=\"Create application.yaml file and add the following line\" >security: providers: - abac: # Adds ABAC Provider - it does not require any configuration - oidc: redirect-uri: \"/oidc/redirect\" audience: \"account\" client-id: \"myClientID\" header-use: true client-secret: \"Client secret generated into Keycloak client credential\" identity-uri: \"http://localhost:8080/auth/realms/myRealm\" frontend-uri: \"http://localhost:7987\" client-id must be the same as the one configure in keycloak. The client secret generate by Keycloak during Create a client section. identity-uri is used to redirect the user to keycloak. frontend-uri will direct you back to the application. The client secret is the one generate into Keycloak Client Credentials. It must be copy past into client-id variable from application.yaml. Make sure keycloak and the application are not running on the same port. The application port value can be changed into microprofile-config.properties. <markup lang=\"properties\" title=\"Change these properties to configure the server host and port\" >server.port=7987 server.host=localhost If the port 7987 is already used, check what port is free on your machine. <markup lang=\"properties\" title=\"Replace the old port into microprofile-config.properties\" >server.port=\"{Your-new-port}\" <markup lang=\"yaml\" title=\"Replace the old port into application.yaml\" >frontend-uri: \"http://localhost:{Your-new-port}\" Secure Your Application The GreetResource class is a JAX-RS resource available at the endpoint /greet . Use @Authenticated annotation to protect any method or endpoint. Modify the getDefaultMessage method with the @Authenticated to limit its access. <markup lang=\"java\" title=\"Import Authenticated annotation:\" >import io.helidon.security.annotations.Authenticated; <markup lang=\"java\" title=\"Add @Authenticated to secure getDefaultMessage \" > @Authenticated @GET @Produces(MediaType.APPLICATION_JSON) public JsonObject getDefaultMessage() { return createResponse(\"World\"); } When a client will send an HTTP GET request at the endpoint http://localhost:7987/greet , he will be redirected to keycloak. Keycloak will check if the client has the required authorisation to access this endpoint. If the client can log in successfully, keycloak redirect it to the wished endpoint. If the client cannot log in, or the required access data are incomplete, Keycloak refuses the access. ",
            "title": "Set up Helidon"
        },
        {
            "location": "/mp/guides/05_security-oidc",
            "text": " At this stage of the application, tests cannot pass because of OIDC security. The only way to authenticate a user is through the front end of that server which can be accessed with the browser for example. In order to keep security and test the application locally, a new security provider must be provided. By adding specific configuration to the test, it is possible to override the application configuration. The following explains how to set a basic authentication instead of oidc security provider only for the tests. Which means, at the end of this guide, the application will be secured by oidc and the tests will use basic authentication. In the test folder helidon-quickstart-mp/src/test : <markup lang=\"bash\" title=\"Create a new directory and another one inside\" >mkdir resources cd resources touch application.yaml Open the application.yaml file you just created. <markup lang=\"yaml\" title=\"Copy these properties into the new application.yaml\" >app: greeting: \"Hello\" server: port: 7987 host: localhost security: providers: - abac: - http-basic-auth: users: - login: \"jack\" password: \"jackIsGreat\" By adding this new application.yaml, it will append the properties to the application.yaml located into java/resources . The oidc properties are not overridden, and the server cannot decide which security provider to choose. Excluding oidc dependency during the test leaves only basic authentication security available for the tests. <markup lang=\"xml\" title=\"Add this plugin to the build\" >&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;classpathDependencyExcludes&gt; &lt;classpathDependencyExclude&gt;io.helidon.microprofile:helidon-microprofile-oidc&lt;/classpathDependencyExclude&gt; &lt;/classpathDependencyExcludes&gt; &lt;/configuration&gt; &lt;/plugin&gt; In the MainTest.java file, tests need to be modified to check the application security when accessing /greet path with a GET method. First step is to configure the server with the new application.yaml. <markup lang=\"java\" title=\"Import the Config class\" >import io.helidon.config.Config; <markup lang=\"java\" title=\"Replace the startTheServer method by this one:\" >@BeforeAll public static void startTheServer() { server = Server.builder() .config(Config.create()) .build() .start(); serverUrl = \"http://localhost:\" + server.port(); } The server has now one security provider, basic authentication configured. Next step is to modify the test to check that the application is correctly protected. <markup lang=\"java\" title=\"Replace the JsonObject declaration into testHelloWorld method by this code:\" >JsonObject jsonObject; Response response = client .target(serverUrl) .path(\"/greet\") .request() .get(Response.class); Assertions.assertEquals(401, response.getStatus()); This piece of code uses the webclient to access the application on /greet path with a GET method. The http basic authentication security provider protects this path, so the client should receive an HTTP 401 code for unauthorized. Only jack user has access to this part of the application. <markup lang=\"java\" title=\"Add new check to the testHelloWorld method:\" >String encoding = Base64.getEncoder().encodeToString(\"jack:jackIsGreat\".getBytes()); jsonObject = client .target(serverUrl) .path(\"/greet\") .request() .header(Http.Header.AUTHORIZATION, \"Basic \" + encoding) .get(JsonObject.class); Assertions.assertEquals(\"Hello World!\", jsonObject.getString(\"message\"), \"default message\"); The username and password are encoded and placed inside the header in order to authenticate as jack to access the application. If the authentication is successful, the application send the Hello World back as a JsonObject . Now, the project can be build without skiping test. <markup lang=\"bash\" title=\"Build the project\" >mvn clean install ",
            "title": "Update Tests to the Secure Environment"
        },
        {
            "location": "/mp/guides/05_security-oidc",
            "text": " The Authorization Code flow is suitable for browser-based applications. It is composed of three main steps: The browser visits the application. The user is not logged in, so it redirects the browser to Keycloak which requires username and password for authentication. Keycloak authenticates the user and returns a temporary authorization code as a query parameter in the URL. The authorization code is used to get access and refresh token from Keycloak token endpoint. For the first step, paste the following URL into your browser: http://localhost:8080/auth/realms/myRealm/protocol/openid-connect/auth?client_id=myClientID&amp;response_type=code . The first part of the url http:/../auth is the Keycloak endpoint to request an authorization code. Two query parameters are provided, the client id and the response type. Press enter and Keycloak responds with different URL containing a query parameter code . You successfully received the authorization code. In order to achieve the third step, we can use Postman to exchange the authorization code for tokens. In Postman, select the Http POST method. Keycloak endpoint to get token is the following: http://localhost:8080/auth/realms/myRealm/protocol/openid-connect/token . In the body of the request, select x-www-form-urlencoded type. Add the following data: <markup lang=\"json\" title=\"Enter the key:value\" >[{\"key\":\"grant_type\",\"value\":\"authorization_code\"}, {\"key\":\"client_id\",\"value\":\"myClientID\"}, {\"key\":\"client_secret\",\"value\":\"client secret\"}, {\"key\":\"code\",\"value\":\"authorization code\"}] Do not forget to replace the client secret by its value (generated during Create a Client), and authorization code by the code value in the query parameter. Send the request by pressing Send . Keycloak returns an access token and a refresh token. ",
            "title": "Authorization Code Flow"
        },
        {
            "location": "/mp/guides/05_security-oidc",
            "text": " The Direct Access Grants flow is used by REST clients that want to request tokens on behalf of a user. To use Postman to make this request on behalf of myuser , select the GET method and enter this URL: http://localhost:7987/greet/ . Under Authorization tab, select authorization type`OAuth 2.0`. Under it, complete the sentence Add authorization data to with Request Headers , and complete the required fields. <markup lang=\"json\" title=\"Enter the following information:\" >[{\"key\":\"Header Prefix\",\"value\":\"bearer\"}, {\"key\":\"Grant type\",\"value\":\"Password Credentials\"}, {\"key\":\"Access Token URL\",\"value\":\"http://localhost:8080/auth/realms/myRealm/protocol/openid-connect/token\"}, {\"key\":\"Client ID\",\"value\":\"myClientID\"}, {\"key\":\"Client Secret\",\"value\":\"client secret\"}, {\"key\":\"Username\",\"value\":\"myuser\"}, {\"key\":\"Password\",\"value\":\"password\"}, {\"key\":\"Scope\",\"value\":\"openid\"}, {\"key\":\"Client Authentication\",\"value\":\"Send as Basic Auth Header\"}] Again, make sure to replace client secret by the actual client secret. Click on Get New Access Token . A popup window appears with Authentication complete, click on proceed to display access, refresh and identity token. Copy and paste the access token to Access Token field and press Send . Helidon greeting application sends back Hello World ! . ",
            "title": "Resource Owner Password Credentials Grant (Direct Access Grants)"
        },
        {
            "location": "/mp/guides/05_security-oidc",
            "text": " Keycloak supports many authentication and authorization flows, but only two of them will be shown. This section describes another way you can get an access token or refresh a token or identity token. The identity token contains information about the user. The access token contains access information that the application can use to determine what resources the user is allowed to access. Once expired, the refresh token allows the application to obtain a new access token. As these tokens contain sensitive information, they are valid for a very short period. It is possible to make them last longer in order to let you manipulate them with Postman. To do so: Open the Postman Console. Click on the Realm Setting in the left menu. Navigate to the Tokens tab. You can increase the access token lifespan. Authorization Code Flow The Authorization Code flow is suitable for browser-based applications. It is composed of three main steps: The browser visits the application. The user is not logged in, so it redirects the browser to Keycloak which requires username and password for authentication. Keycloak authenticates the user and returns a temporary authorization code as a query parameter in the URL. The authorization code is used to get access and refresh token from Keycloak token endpoint. For the first step, paste the following URL into your browser: http://localhost:8080/auth/realms/myRealm/protocol/openid-connect/auth?client_id=myClientID&amp;response_type=code . The first part of the url http:/../auth is the Keycloak endpoint to request an authorization code. Two query parameters are provided, the client id and the response type. Press enter and Keycloak responds with different URL containing a query parameter code . You successfully received the authorization code. In order to achieve the third step, we can use Postman to exchange the authorization code for tokens. In Postman, select the Http POST method. Keycloak endpoint to get token is the following: http://localhost:8080/auth/realms/myRealm/protocol/openid-connect/token . In the body of the request, select x-www-form-urlencoded type. Add the following data: <markup lang=\"json\" title=\"Enter the key:value\" >[{\"key\":\"grant_type\",\"value\":\"authorization_code\"}, {\"key\":\"client_id\",\"value\":\"myClientID\"}, {\"key\":\"client_secret\",\"value\":\"client secret\"}, {\"key\":\"code\",\"value\":\"authorization code\"}] Do not forget to replace the client secret by its value (generated during Create a Client), and authorization code by the code value in the query parameter. Send the request by pressing Send . Keycloak returns an access token and a refresh token. Resource Owner Password Credentials Grant (Direct Access Grants) The Direct Access Grants flow is used by REST clients that want to request tokens on behalf of a user. To use Postman to make this request on behalf of myuser , select the GET method and enter this URL: http://localhost:7987/greet/ . Under Authorization tab, select authorization type`OAuth 2.0`. Under it, complete the sentence Add authorization data to with Request Headers , and complete the required fields. <markup lang=\"json\" title=\"Enter the following information:\" >[{\"key\":\"Header Prefix\",\"value\":\"bearer\"}, {\"key\":\"Grant type\",\"value\":\"Password Credentials\"}, {\"key\":\"Access Token URL\",\"value\":\"http://localhost:8080/auth/realms/myRealm/protocol/openid-connect/token\"}, {\"key\":\"Client ID\",\"value\":\"myClientID\"}, {\"key\":\"Client Secret\",\"value\":\"client secret\"}, {\"key\":\"Username\",\"value\":\"myuser\"}, {\"key\":\"Password\",\"value\":\"password\"}, {\"key\":\"Scope\",\"value\":\"openid\"}, {\"key\":\"Client Authentication\",\"value\":\"Send as Basic Auth Header\"}] Again, make sure to replace client secret by the actual client secret. Click on Get New Access Token . A popup window appears with Authentication complete, click on proceed to display access, refresh and identity token. Copy and paste the access token to Access Token field and press Send . Helidon greeting application sends back Hello World ! . ",
            "title": "Test Keycloak process with Postman"
        },
        {
            "location": "/mp/guides/05_security-oidc",
            "text": " To give less access to a specific endpoint, it is possible to configure user role. So the application will grant access only the user with the required role. Navigate to the GreetResource and find the getDefaultMessage with @Authenticate annotation. <markup lang=\"java\" title=\"Import the RolesAllowed annotation\" >import javax.annotation.security.RolesAllowed; <markup lang=\"java\" title=\"Add the @RolesAllowed annotation under the @Authenticate annotation:\" >@RolesAllowed(\"admin\") The annotation parameter is the role with access to the method. In this case, only user with admin role can have access. Then, add a user and roles to the helidon-quickstart-mp/src/test/resources/application.yaml file. <markup lang=\"yaml\" title=\"Add jack roles and create a new user named john:\" >- http-basic-auth: users: - login: \"jack\" password: \"jackIsGreat\" roles: [ \"admin\", \"user\" ] - login: \"john\" password: \"johnPassword\" roles: [ \"user\" ] Now, only Jack has access to secure endpoint as he has an admin role. Jhon, as a simple user, can not access it. Once it is done, go to the tests to check the application behavior. The test from previous section is still passing because jack has access. The user john has only the user role so when accessing protected endpoint, a 403 (Forbidden) http code is returned. <markup lang=\"java\" title=\"Check that jhon does not have access\" >encoding = Base64.getEncoder().encodeToString(\"john:johnPassword\".getBytes()); response = client .target(serverUrl) .path(\"/greet\") .request() .header(Http.Header.AUTHORIZATION, \"Basic \" + encoding) .get(Response.class); Assertions.assertEquals(403, response.getStatus()); <markup lang=\"bash\" title=\"Build the project\" >mvn clean install The tests pass, and your application is secured with specific roles in addition to user IDs. ",
            "title": "Restrict Access to a Specific Role"
        },
        {
            "location": "/mp/guides/05_security-oidc",
            "text": " Helidon and Keycloak are now correctly configured and your application is safe. <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-mp.jar The tests must be skipped, otherwise it produces test failure. As the /greet endpoint for GET request is now protected, its access is limited, and the tests are not built to take oidc security in account. Open your favourite browser and try to access http://localhost:7987/greet/Michael . You should not be redirected and receive greeting from the application. Enter the following into URL : http://localhost:7987/greet . Keycloak redirect you to its login page. Enter the username and associated password: Username : myUser Password : password After successful log in, keycloak redirect you to the http://localhost:7987/greet endpoint and print Hello word. Press Ctrl+C to stop the application. From the actual settings, the user needs to log in only once, then Keycloak saves all the connection data. Update Tests to the Secure Environment At this stage of the application, tests cannot pass because of OIDC security. The only way to authenticate a user is through the front end of that server which can be accessed with the browser for example. In order to keep security and test the application locally, a new security provider must be provided. By adding specific configuration to the test, it is possible to override the application configuration. The following explains how to set a basic authentication instead of oidc security provider only for the tests. Which means, at the end of this guide, the application will be secured by oidc and the tests will use basic authentication. In the test folder helidon-quickstart-mp/src/test : <markup lang=\"bash\" title=\"Create a new directory and another one inside\" >mkdir resources cd resources touch application.yaml Open the application.yaml file you just created. <markup lang=\"yaml\" title=\"Copy these properties into the new application.yaml\" >app: greeting: \"Hello\" server: port: 7987 host: localhost security: providers: - abac: - http-basic-auth: users: - login: \"jack\" password: \"jackIsGreat\" By adding this new application.yaml, it will append the properties to the application.yaml located into java/resources . The oidc properties are not overridden, and the server cannot decide which security provider to choose. Excluding oidc dependency during the test leaves only basic authentication security available for the tests. <markup lang=\"xml\" title=\"Add this plugin to the build\" >&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;classpathDependencyExcludes&gt; &lt;classpathDependencyExclude&gt;io.helidon.microprofile:helidon-microprofile-oidc&lt;/classpathDependencyExclude&gt; &lt;/classpathDependencyExcludes&gt; &lt;/configuration&gt; &lt;/plugin&gt; In the MainTest.java file, tests need to be modified to check the application security when accessing /greet path with a GET method. First step is to configure the server with the new application.yaml. <markup lang=\"java\" title=\"Import the Config class\" >import io.helidon.config.Config; <markup lang=\"java\" title=\"Replace the startTheServer method by this one:\" >@BeforeAll public static void startTheServer() { server = Server.builder() .config(Config.create()) .build() .start(); serverUrl = \"http://localhost:\" + server.port(); } The server has now one security provider, basic authentication configured. Next step is to modify the test to check that the application is correctly protected. <markup lang=\"java\" title=\"Replace the JsonObject declaration into testHelloWorld method by this code:\" >JsonObject jsonObject; Response response = client .target(serverUrl) .path(\"/greet\") .request() .get(Response.class); Assertions.assertEquals(401, response.getStatus()); This piece of code uses the webclient to access the application on /greet path with a GET method. The http basic authentication security provider protects this path, so the client should receive an HTTP 401 code for unauthorized. Only jack user has access to this part of the application. <markup lang=\"java\" title=\"Add new check to the testHelloWorld method:\" >String encoding = Base64.getEncoder().encodeToString(\"jack:jackIsGreat\".getBytes()); jsonObject = client .target(serverUrl) .path(\"/greet\") .request() .header(Http.Header.AUTHORIZATION, \"Basic \" + encoding) .get(JsonObject.class); Assertions.assertEquals(\"Hello World!\", jsonObject.getString(\"message\"), \"default message\"); The username and password are encoded and placed inside the header in order to authenticate as jack to access the application. If the authentication is successful, the application send the Hello World back as a JsonObject . Now, the project can be build without skiping test. <markup lang=\"bash\" title=\"Build the project\" >mvn clean install Test Keycloak process with Postman Keycloak supports many authentication and authorization flows, but only two of them will be shown. This section describes another way you can get an access token or refresh a token or identity token. The identity token contains information about the user. The access token contains access information that the application can use to determine what resources the user is allowed to access. Once expired, the refresh token allows the application to obtain a new access token. As these tokens contain sensitive information, they are valid for a very short period. It is possible to make them last longer in order to let you manipulate them with Postman. To do so: Open the Postman Console. Click on the Realm Setting in the left menu. Navigate to the Tokens tab. You can increase the access token lifespan. Authorization Code Flow The Authorization Code flow is suitable for browser-based applications. It is composed of three main steps: The browser visits the application. The user is not logged in, so it redirects the browser to Keycloak which requires username and password for authentication. Keycloak authenticates the user and returns a temporary authorization code as a query parameter in the URL. The authorization code is used to get access and refresh token from Keycloak token endpoint. For the first step, paste the following URL into your browser: http://localhost:8080/auth/realms/myRealm/protocol/openid-connect/auth?client_id=myClientID&amp;response_type=code . The first part of the url http:/../auth is the Keycloak endpoint to request an authorization code. Two query parameters are provided, the client id and the response type. Press enter and Keycloak responds with different URL containing a query parameter code . You successfully received the authorization code. In order to achieve the third step, we can use Postman to exchange the authorization code for tokens. In Postman, select the Http POST method. Keycloak endpoint to get token is the following: http://localhost:8080/auth/realms/myRealm/protocol/openid-connect/token . In the body of the request, select x-www-form-urlencoded type. Add the following data: <markup lang=\"json\" title=\"Enter the key:value\" >[{\"key\":\"grant_type\",\"value\":\"authorization_code\"}, {\"key\":\"client_id\",\"value\":\"myClientID\"}, {\"key\":\"client_secret\",\"value\":\"client secret\"}, {\"key\":\"code\",\"value\":\"authorization code\"}] Do not forget to replace the client secret by its value (generated during Create a Client), and authorization code by the code value in the query parameter. Send the request by pressing Send . Keycloak returns an access token and a refresh token. Resource Owner Password Credentials Grant (Direct Access Grants) The Direct Access Grants flow is used by REST clients that want to request tokens on behalf of a user. To use Postman to make this request on behalf of myuser , select the GET method and enter this URL: http://localhost:7987/greet/ . Under Authorization tab, select authorization type`OAuth 2.0`. Under it, complete the sentence Add authorization data to with Request Headers , and complete the required fields. <markup lang=\"json\" title=\"Enter the following information:\" >[{\"key\":\"Header Prefix\",\"value\":\"bearer\"}, {\"key\":\"Grant type\",\"value\":\"Password Credentials\"}, {\"key\":\"Access Token URL\",\"value\":\"http://localhost:8080/auth/realms/myRealm/protocol/openid-connect/token\"}, {\"key\":\"Client ID\",\"value\":\"myClientID\"}, {\"key\":\"Client Secret\",\"value\":\"client secret\"}, {\"key\":\"Username\",\"value\":\"myuser\"}, {\"key\":\"Password\",\"value\":\"password\"}, {\"key\":\"Scope\",\"value\":\"openid\"}, {\"key\":\"Client Authentication\",\"value\":\"Send as Basic Auth Header\"}] Again, make sure to replace client secret by the actual client secret. Click on Get New Access Token . A popup window appears with Authentication complete, click on proceed to display access, refresh and identity token. Copy and paste the access token to Access Token field and press Send . Helidon greeting application sends back Hello World ! . Restrict Access to a Specific Role To give less access to a specific endpoint, it is possible to configure user role. So the application will grant access only the user with the required role. Navigate to the GreetResource and find the getDefaultMessage with @Authenticate annotation. <markup lang=\"java\" title=\"Import the RolesAllowed annotation\" >import javax.annotation.security.RolesAllowed; <markup lang=\"java\" title=\"Add the @RolesAllowed annotation under the @Authenticate annotation:\" >@RolesAllowed(\"admin\") The annotation parameter is the role with access to the method. In this case, only user with admin role can have access. Then, add a user and roles to the helidon-quickstart-mp/src/test/resources/application.yaml file. <markup lang=\"yaml\" title=\"Add jack roles and create a new user named john:\" >- http-basic-auth: users: - login: \"jack\" password: \"jackIsGreat\" roles: [ \"admin\", \"user\" ] - login: \"john\" password: \"johnPassword\" roles: [ \"user\" ] Now, only Jack has access to secure endpoint as he has an admin role. Jhon, as a simple user, can not access it. Once it is done, go to the tests to check the application behavior. The test from previous section is still passing because jack has access. The user john has only the user role so when accessing protected endpoint, a 403 (Forbidden) http code is returned. <markup lang=\"java\" title=\"Check that jhon does not have access\" >encoding = Base64.getEncoder().encodeToString(\"john:johnPassword\".getBytes()); response = client .target(serverUrl) .path(\"/greet\") .request() .header(Http.Header.AUTHORIZATION, \"Basic \" + encoding) .get(Response.class); Assertions.assertEquals(403, response.getStatus()); <markup lang=\"bash\" title=\"Build the project\" >mvn clean install The tests pass, and your application is secured with specific roles in addition to user IDs. ",
            "title": "Try it!"
        },
        {
            "location": "/se/guides/02_quickstart",
            "text": " This guide describes a basic example of an Helidon SE application using Docker and Kubernetes. ",
            "title": "preambule"
        },
        {
            "location": "/se/guides/02_quickstart",
            "text": " For this 5 minute tutorial, you will need the following: <div class=\"table__overflow elevation-1 flex sm7 \"> A Helidon {upper-case-flavor} Application You can use your own application or use the Helidon {upper-case-flavor} Quickstart to create a sample application. Java&#160;SE&#160;11 ( Open&#160;JDK&#160;11 ) Helidon requires Java 11+. Maven 3.6.1+ Helidon requires Maven 3.6.1+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop ). <markup lang=\"bash\" title=\"Verify Prerequisites\" >java -version mvn --version docker --version kubectl version --short <markup lang=\"bash\" title=\"Setting JAVA_HOME\" ># On Mac export JAVA_HOME=`/usr/libexec/java_home -v 11` # On Linux # Use the appropriate path to your JDK export JAVA_HOME=/usr/lib/jvm/jdk-11 ",
            "title": "What You Need"
        },
        {
            "location": "/se/guides/02_quickstart",
            "text": " Generate the project sources using one (or both) of the Helidon Maven archetypes. The result is a simple project that shows the basics of configuring the WebServer and implementing basic routing rules. <markup lang=\"bash\" title=\"Run the Maven archetype\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-se \\ -DarchetypeVersion=2.5.4 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-se \\ -Dpackage=io.helidon.examples.quickstart.se The archetype generates a Maven project in your current directory (for example, helidon-quickstart-se ). Change into this directory. <markup lang=\"bash\" >cd helidon-quickstart-se If you want to use the generated project as a starter for your own application, then you can replace groupId, artifactId and package with values appropriate for your application. <markup lang=\"bash\" title=\"Build the Application\" >mvn package The project builds an application jar for the example and saves all runtime dependencies in the target/libs directory. This means you can easily start the application by running the application jar file: <markup lang=\"bash\" title=\"Run the application\" >java -jar target/helidon-quickstart-se.jar The example is a very simple \"Hello World\" greeting service. It supports GET requests for generating a greeting message, and a PUT request for changing the greeting itself. The response is encoded using JSON. For example: <markup lang=\"bash\" title=\"Try the Application\" >curl -X GET http://localhost:8080/greet {\"message\":\"Hello World!\"} curl -X GET http://localhost:8080/greet/Joe {\"message\":\"Hello Joe!\"} curl -X PUT -H \"Content-Type: application/json\" -d '{\"greeting\" : \"Hola\"}' http://localhost:8080/greet/greeting curl -X GET http://localhost:8080/greet/Jose {\"message\":\"Hola Jose!\"} ",
            "title": "Generate The Project"
        },
        {
            "location": "/se/guides/02_quickstart",
            "text": " Helidon provides built-in support for health and metrics endpoints. <markup lang=\"bash\" title=\"Health\" >curl -s -X GET http://localhost:8080/health <markup lang=\"bash\" title=\"Metrics in Prometheus Format\" >curl -s -X GET http://localhost:8080/metrics <markup lang=\"bash\" title=\"Metrics in JSON Format\" >curl -H 'Accept: application/json' -X GET http://localhost:8080/metrics ",
            "title": "Health and Metrics"
        },
        {
            "location": "/se/guides/02_quickstart",
            "text": " The project also contains a Dockerfile so that you can easily build and run a Docker image. To build the Docker image, you need to have Docker installed and running on your system. <markup lang=\"bash\" title=\"Docker build\" >docker build -t helidon-quickstart-se . <markup lang=\"bash\" title=\"Run Docker Image\" >docker run --rm -p 8080:8080 helidon-quickstart-se:latest Then you can try the application as you did before. ",
            "title": "Build a Docker Image"
        },
        {
            "location": "/se/guides/02_quickstart",
            "text": " If you don&#8217;t have access to a Kubernetes cluster, you can install one on your desktop . Then deploy the example: <markup lang=\"bash\" title=\"Verify connectivity to cluster\" >kubectl cluster-info kubectl get nodes <markup lang=\"bash\" title=\"Deploy the application to Kubernetes\" >kubectl create -f app.yaml kubectl get pods # Wait for quickstart pod to be RUNNING The step above created a service that is exposed into any node port. Lookup the service to find the port. <markup lang=\"bash\" title=\"Lookup the service\" >kubectl get service helidon-quickstart-se Note the PORTs. You can now exercise the application as you did before but use the second port number (the NodePort) instead of 8080. For example: <markup lang=\"bash\" >curl -X GET http://localhost:31431/greet After you&#8217;re done, cleanup. <markup lang=\"bash\" title=\"Remove the application from Kubernetes\" >kubectl delete -f app.yaml ",
            "title": "Deploy the application to Kubernetes"
        },
        {
            "location": "/se/guides/02_quickstart",
            "text": " Helidon also includes support for GraalVM Native Images and Java Custom Runtime Images. For more information see: GraalVM Native Images Custom Runtime Images using jlink ",
            "title": "Building Native and Custom Runtime Images"
        },
        {
            "location": "/se/guides/02_quickstart",
            "text": " With the Helidon CLI you can create additional types of Helidon applications and use the \"dev loop\" to do fast, iterative development. Try it now . ",
            "title": "The Helidon CLI"
        },
        {
            "location": "/about/10_upgrade",
            "text": " Helidon 2.0 is not fully backwards compatible with Helidon 1.4. For information concerning upgrading from Helidon 1.4 to 2.0 see the following upgrade guides: Helidon MP Upgrade Guide Helidon SE Upgrade Guide ",
            "title": "Upgrade Guides"
        },
        {
            "location": "/mp/beanvalidation/01_overview",
            "text": " Helidon supports Bean Validation via its integration with JAX-RS/Jersey. The Jakarta Bean Validation specification defines an API to validate Java beans. Bean Validation is supported in REST resource classes as well as in regular application beans. ",
            "title": "preambule"
        },
        {
            "location": "/mp/beanvalidation/01_overview",
            "text": " To enable Bean Validation add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;org.glassfish.jersey.ext&lt;/groupId&gt; &lt;artifactId&gt;jersey-bean-validation&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/beanvalidation/01_overview",
            "text": " The following example shows a simple resource method annotated with @POST whose parameter must be not null and valid . Validating a parameter in this case implies making sure that any constraint annotations in the Greeting class are satisfied. The resource method shall never be called if the validation fails, with a 400 (Bad Request) status code returned instead. <markup lang=\"java\" >@Path(\"helloworld\") public class HelloWorld { @POST @Consumes(MediaType.APPLICATION_JSON) public void post(@NotNull @Valid Greeting greeting) { // ... } } ",
            "title": "Validation Example in Helidon MP"
        },
        {
            "location": "/se/webserver/01_introduction",
            "text": " WebServer provides an asynchronous and reactive API for creating web applications. The API is inspired by popular NodeJS and Java frameworks. ",
            "title": "preambule"
        },
        {
            "location": "/se/webserver/01_introduction",
            "text": " To enable WebServer add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webserver&lt;/groupId&gt; &lt;artifactId&gt;helidon-webserver&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/webserver/01_introduction",
            "text": " Here is the code for a minimalist web application that runs on a random free port: <markup lang=\"java\" > public static void main(String[] args) { WebServer webServer = WebServer .create(Routing.builder() .any((req, res) -&gt; res.send(\"It works!\"))) .start() .await(10, TimeUnit.SECONDS); System.out.println(\"Server started at: http://localhost:\" + webServer.port()); } For any kind of request, at any path, respond with It works! . Start the server. Wait for the server to start while throwing possible errors as runtime exceptions. The server is bound to a random free port. ",
            "title": "Quick Start"
        },
        {
            "location": "/about/04_windows",
            "text": " Most of the Helidon documentation is Linux/Mac/Unix centric. This document gives some tips for Windows users. ",
            "title": "Introduction"
        },
        {
            "location": "/about/04_windows",
            "text": " Windows 10 is required. For general pre-requisites like Java and Maven see Getting Started . If you want to use the Helidon CLI you&#8217;ll also need to install the Visual C++ Redistributable Runtime: x64 x86 We also recommend installing the following from the Microsoft Store: PowerShell Windows Terminal This document assumes you will be using PowerShell. ",
            "title": "Prerequisites"
        },
        {
            "location": "/about/04_windows",
            "text": "<markup lang=\"bash\" >mvn \"-U\" \"archetype:generate\" \"-DinteractiveMode=false\" ` \"-DarchetypeGroupId=io.helidon.archetypes\" ` \"-DarchetypeArtifactId=helidon-quickstart-se\" ` \"-DarchetypeVersion=2.5.4\" ` \"-DgroupId=io.helidon.examples\" ` \"-DartifactId=helidon-quickstart-se\" ` \"-Dpackage=io.helidon.examples.quickstart.se\" You can then follow the instructions in the Helidon SE Quickstart . If you do not have curl installed you can use Invoke-WebRequest : <markup lang=\"bash\" >Invoke-WebRequest -Uri \"http://localhost:8080/greet\" ",
            "title": "Helidon SE"
        },
        {
            "location": "/about/04_windows",
            "text": "<markup lang=\"bash\" >mvn \"-U\" \"archetype:generate\" \"-DinteractiveMode=false\" ` \"-DarchetypeGroupId=io.helidon.archetypes\" ` \"-DarchetypeArtifactId=helidon-quickstart-mp\" ` \"-DarchetypeVersion=2.5.4\" ` \"-DgroupId=io.helidon.examples\" ` \"-DartifactId=helidon-quickstart-mp\" ` \"-Dpackage=io.helidon.examples.quickstart.mp\" You can then follow the instructions in the Helidon MP Quickstart . If you do not have curl installed you can use Invoke-WebRequest : <markup lang=\"bash\" >Invoke-WebRequest -Uri \"http://localhost:8080/greet\" ",
            "title": "Helidon MP"
        },
        {
            "location": "/about/04_windows",
            "text": " Helidon SE <markup lang=\"bash\" >mvn \"-U\" \"archetype:generate\" \"-DinteractiveMode=false\" ` \"-DarchetypeGroupId=io.helidon.archetypes\" ` \"-DarchetypeArtifactId=helidon-quickstart-se\" ` \"-DarchetypeVersion=2.5.4\" ` \"-DgroupId=io.helidon.examples\" ` \"-DartifactId=helidon-quickstart-se\" ` \"-Dpackage=io.helidon.examples.quickstart.se\" You can then follow the instructions in the Helidon SE Quickstart . If you do not have curl installed you can use Invoke-WebRequest : <markup lang=\"bash\" >Invoke-WebRequest -Uri \"http://localhost:8080/greet\" Helidon MP <markup lang=\"bash\" >mvn \"-U\" \"archetype:generate\" \"-DinteractiveMode=false\" ` \"-DarchetypeGroupId=io.helidon.archetypes\" ` \"-DarchetypeArtifactId=helidon-quickstart-mp\" ` \"-DarchetypeVersion=2.5.4\" ` \"-DgroupId=io.helidon.examples\" ` \"-DartifactId=helidon-quickstart-mp\" ` \"-Dpackage=io.helidon.examples.quickstart.mp\" You can then follow the instructions in the Helidon MP Quickstart . If you do not have curl installed you can use Invoke-WebRequest : <markup lang=\"bash\" >Invoke-WebRequest -Uri \"http://localhost:8080/greet\" ",
            "title": "Maven Quickstart Archetypes"
        },
        {
            "location": "/mp/extensions/01_overview",
            "text": " Helidon provides CDI portable extensions that you can use to inject the following objects into your Helidon MicroProfile applications: HikariCP data sources Create and inject a HikariCP data source in your application code. Oracle UCP data sources Create and inject an Oracle Universal Connection Pool data source in your application code. Jedis clients Create and inject a Jedis pool in your application code. OCI Object Storage clients Create and inject an Oracle Cloud Infrastructure Object Storage client in your application code. Java Transaction API objects Use the Java Transaction API in your application code. ",
            "title": "CDI extensions"
        },
        {
            "location": "/se/config/04_property-mapping",
            "text": " Although config values are originally text, you can use the config system&#8217;s built-in conversions or add your own to translate text into Java primitive types and simple objects (such as Double ) and to express parts of the config tree as complex types ( List , Map , and custom types specific to your application). This section introduces how to use the built-in mappings and your own custom ones to convert to simple and complex types. ",
            "title": "preambule"
        },
        {
            "location": "/se/config/04_property-mapping",
            "text": " The Config class itself provides many conversions to Java types. See the JavaDoc for the complete list. The methods which support Java primitive types and their related classes follow a common pattern. The examples in the table below deal with conversion to a boolean but the same pattern applies to many data types listed in the JavaDoc. Assume a local variable has been assigned something like <markup lang=\"java\" >Config config = Config.get(\"someKey\"); // shortcut method ConfigValue&lt;Boolean&gt; value = config.asBoolean(); // generic method (for any type) ConfigValue&lt;Boolean&gt; value2 = config.as(Boolean.class); Built-in Conversions to Simple Types (e.g., boolean) Java type Example usage 1 boolean boolean b = value.get(); 2 boolean defaultedB = value.orElse(true); 3 Optional&lt;Boolean&gt; ConfigValue already has all methods of an Optional. If actual optional is needed: Optional&lt;Boolean&gt; b = value.asOptional(); 4 Supplier&lt;Boolean&gt; Boolean b = value.supplier().get(); boolean defaultedB = value.supplier(true).get(); Supplier&lt;Optional&lt;Boolean&gt;&gt; Boolean b = value.optionalSupplier().get().orElse(Boolean.TRUE); Notes on Built-in Conversions to Simple Types 1 All conversions can throw MissingValueException (if no value exists at the requested key and no default is provided) and ConfigMappingException (if some error occurred while performing the data mapping). 2 The Config.asXXX methods internally use the Java-provided XXX.parseXXX methods, so here a missing or unparseable string gives false because that is how Boolean.parseBoolean behaves. 3 User code defaults the value to true . 4 User code defaults the value to Boolean.TRUE if absent; otherwise parses the value using Boolean.parseBoolean . The numerous conversions defined on the Config class for other types (integers, doubles, etc.) will satisfy many of your application&#8217;s needs. The ConfigMappers class includes other related mappings from String (rather than from Config ) to Java types (described in the JavaDoc). For additional type mapping, you can use these methods defined on Config : <markup lang=\"java\" >T as(Class&lt;? extends T&gt; type); T as(Function&lt;Config, T&gt; mapper); T as(GenericType&lt;T&gt; genericType); which maps the current node to a type. The next example, and later ones below showing complex type mapping, use the example application.properties configuration from the config introduction. Part of that example includes this line: <markup >bl.initial-id = 10000000000 Your application can use Config.as to interpret the value as a BigDecimal : <markup lang=\"java\" >BigDecimal initialId = config.get(\"bl.initial-id\").as(BigDecimal.class); ",
            "title": "Converting Configuration to Simple Types"
        },
        {
            "location": "/se/config/04_property-mapping",
            "text": " The Config class exposes several methods for mapping a structured config node to a Java List or Map . The JavaDoc contains complete details, but briefly your application can convert a structured Config node into: a List&lt;T&gt; of a given type a Map&lt;String, String&gt; in which each key is the fully-qualified key String for a config entry and the value is its String value ",
            "title": "Built-in Conversions to List and Map "
        },
        {
            "location": "/se/config/04_property-mapping",
            "text": " Any time your application has a Config instance to map to the target class it invokes Config.as passing an instance of the corresponding conversion function: <markup lang=\"java\" >Config config = Config.get(\"web\"); ConfigValue&lt;WebConfig&gt; web = config.as(WebConfigMapper::map); You do not necessarily need a new instance of the mapper every time you want to use it. In this approach, everywhere your application needs to perform this conversion it specifies the mapper to use. If you decided to change which mapper to use you would need to update each of those places in your application. ",
            "title": "Use Custom Mapper Explicitly: Config.as method"
        },
        {
            "location": "/se/config/04_property-mapping",
            "text": " In this approach, your application: Tells each Config.Builder that needs to know about the custom mapper by either: registering an instance of your mapper by invoking Config.Builder.addMapper , or implementing ConfigMapperProvider so it returns an instance of your mapper (see the JavaDoc for complete information) and creating or editing the file io.helidon.config.spi.ConfigMapperProvider so it contains a line with the fully-qualified class name of your ConfigMapperProvider . The config system will use the Java service loader to find and invoke all ConfigMapperProvider classes listed and add the mappers they provide to each Config.Builder automatically. Converts using the mapper by invoking the Config.as method which accepts the target type to convert to, not the mapper itself that does the conversion. If your application converts to the same target type in several places in the code, this approach allows you to change which mapper it uses by changing only the registration of the mapper, not each use of it. ",
            "title": "Register Custom Mapper Once, Use Implicitly: Config.as method"
        },
        {
            "location": "/se/config/04_property-mapping",
            "text": " The following examples build on the example configuration from the application.properties example file in the introduction. <markup lang=\"java\" title=\"Java POJO to Hold web Properties Config\" >public class WebConfig { private boolean debug; private int pageSize; private double ratio; public WebConfig(boolean debug, int pageSize, double ratio) { this.debug = debug; this.pageSize = pageSize; this.ratio = ratio; } public boolean isDebug() { return debug; } public int getPageSize() { return pageSize; } public double getRatio() { return ratio; } } <markup lang=\"java\" title=\"Custom Mapper Class\" >public class WebConfigMapper implements Function&lt;Config, WebConfig&gt; { @Override public WebConfig apply(Config config) throws ConfigMappingException, MissingValueException { return new WebConfig( config.get(\"debug\").asBoolean().orElse(false), config.get(\"page-size\").asInt().orElse(10), config.get(\"ratio\").asDouble().orElse(1.0) ); } } <markup lang=\"java\" title=\"Explicitly Using the Mapper\" >... Config config = Config.create(classpath(\"application.properties\")); WebConfig web = config.get(\"web\") .as(new WebConfigMapper()) .get(); <markup lang=\"java\" title=\"Registering and Implicitly Using the Mapper\" >... Config config = Config.builder(classpath(\"application.properties\")) .addMapper(WebConfig.class, new WebConfigMapper()) .build(); WebConfig web = config.get(\"web\") .as(WebConfig.class) .get(); Either of the two approaches just described will always work without requiring you to change the POJO class. ",
            "title": "Continuing the Web Example"
        },
        {
            "location": "/se/config/04_property-mapping",
            "text": " Often your code will be simpler if you can treat parts of the configuration as custom, application-specific Java objects, rather than as a group of String keys and values. You will need customized conversions to do so. The config system provides many ways to accomplish this, described in the io.helidon.config package JavaDoc . Some of those approaches require that the target class&#8201;&#8212;&#8201;the class to which you want to convert the configuration data&#8201;&#8212;&#8201;have certain characteristics or that you add a method to the class to help do the mapping. You might want to avoid changing the target class or you might not even be able to if you do not control its source. Here are two approaches that will always work without requiring changes to the target class. For both approaches, you write your own conversion function. The difference is in how your application triggers the use of that mapper. Use Custom Mapper Explicitly: Config.as method Any time your application has a Config instance to map to the target class it invokes Config.as passing an instance of the corresponding conversion function: <markup lang=\"java\" >Config config = Config.get(\"web\"); ConfigValue&lt;WebConfig&gt; web = config.as(WebConfigMapper::map); You do not necessarily need a new instance of the mapper every time you want to use it. In this approach, everywhere your application needs to perform this conversion it specifies the mapper to use. If you decided to change which mapper to use you would need to update each of those places in your application. Register Custom Mapper Once, Use Implicitly: Config.as method In this approach, your application: Tells each Config.Builder that needs to know about the custom mapper by either: registering an instance of your mapper by invoking Config.Builder.addMapper , or implementing ConfigMapperProvider so it returns an instance of your mapper (see the JavaDoc for complete information) and creating or editing the file io.helidon.config.spi.ConfigMapperProvider so it contains a line with the fully-qualified class name of your ConfigMapperProvider . The config system will use the Java service loader to find and invoke all ConfigMapperProvider classes listed and add the mappers they provide to each Config.Builder automatically. Converts using the mapper by invoking the Config.as method which accepts the target type to convert to, not the mapper itself that does the conversion. If your application converts to the same target type in several places in the code, this approach allows you to change which mapper it uses by changing only the registration of the mapper, not each use of it. Continuing the Web Example The following examples build on the example configuration from the application.properties example file in the introduction. <markup lang=\"java\" title=\"Java POJO to Hold web Properties Config\" >public class WebConfig { private boolean debug; private int pageSize; private double ratio; public WebConfig(boolean debug, int pageSize, double ratio) { this.debug = debug; this.pageSize = pageSize; this.ratio = ratio; } public boolean isDebug() { return debug; } public int getPageSize() { return pageSize; } public double getRatio() { return ratio; } } <markup lang=\"java\" title=\"Custom Mapper Class\" >public class WebConfigMapper implements Function&lt;Config, WebConfig&gt; { @Override public WebConfig apply(Config config) throws ConfigMappingException, MissingValueException { return new WebConfig( config.get(\"debug\").asBoolean().orElse(false), config.get(\"page-size\").asInt().orElse(10), config.get(\"ratio\").asDouble().orElse(1.0) ); } } <markup lang=\"java\" title=\"Explicitly Using the Mapper\" >... Config config = Config.create(classpath(\"application.properties\")); WebConfig web = config.get(\"web\") .as(new WebConfigMapper()) .get(); <markup lang=\"java\" title=\"Registering and Implicitly Using the Mapper\" >... Config config = Config.builder(classpath(\"application.properties\")) .addMapper(WebConfig.class, new WebConfigMapper()) .build(); WebConfig web = config.get(\"web\") .as(WebConfig.class) .get(); Either of the two approaches just described will always work without requiring you to change the POJO class. ",
            "title": "Custom Conversions"
        },
        {
            "location": "/se/config/04_property-mapping",
            "text": " The hierarchical features section describes the tree structure used to represent config data. The config system can map subtrees of a config tree to complex Java types. Built-in Conversions to List and Map The Config class exposes several methods for mapping a structured config node to a Java List or Map . The JavaDoc contains complete details, but briefly your application can convert a structured Config node into: a List&lt;T&gt; of a given type a Map&lt;String, String&gt; in which each key is the fully-qualified key String for a config entry and the value is its String value Custom Conversions Often your code will be simpler if you can treat parts of the configuration as custom, application-specific Java objects, rather than as a group of String keys and values. You will need customized conversions to do so. The config system provides many ways to accomplish this, described in the io.helidon.config package JavaDoc . Some of those approaches require that the target class&#8201;&#8212;&#8201;the class to which you want to convert the configuration data&#8201;&#8212;&#8201;have certain characteristics or that you add a method to the class to help do the mapping. You might want to avoid changing the target class or you might not even be able to if you do not control its source. Here are two approaches that will always work without requiring changes to the target class. For both approaches, you write your own conversion function. The difference is in how your application triggers the use of that mapper. Use Custom Mapper Explicitly: Config.as method Any time your application has a Config instance to map to the target class it invokes Config.as passing an instance of the corresponding conversion function: <markup lang=\"java\" >Config config = Config.get(\"web\"); ConfigValue&lt;WebConfig&gt; web = config.as(WebConfigMapper::map); You do not necessarily need a new instance of the mapper every time you want to use it. In this approach, everywhere your application needs to perform this conversion it specifies the mapper to use. If you decided to change which mapper to use you would need to update each of those places in your application. Register Custom Mapper Once, Use Implicitly: Config.as method In this approach, your application: Tells each Config.Builder that needs to know about the custom mapper by either: registering an instance of your mapper by invoking Config.Builder.addMapper , or implementing ConfigMapperProvider so it returns an instance of your mapper (see the JavaDoc for complete information) and creating or editing the file io.helidon.config.spi.ConfigMapperProvider so it contains a line with the fully-qualified class name of your ConfigMapperProvider . The config system will use the Java service loader to find and invoke all ConfigMapperProvider classes listed and add the mappers they provide to each Config.Builder automatically. Converts using the mapper by invoking the Config.as method which accepts the target type to convert to, not the mapper itself that does the conversion. If your application converts to the same target type in several places in the code, this approach allows you to change which mapper it uses by changing only the registration of the mapper, not each use of it. Continuing the Web Example The following examples build on the example configuration from the application.properties example file in the introduction. <markup lang=\"java\" title=\"Java POJO to Hold web Properties Config\" >public class WebConfig { private boolean debug; private int pageSize; private double ratio; public WebConfig(boolean debug, int pageSize, double ratio) { this.debug = debug; this.pageSize = pageSize; this.ratio = ratio; } public boolean isDebug() { return debug; } public int getPageSize() { return pageSize; } public double getRatio() { return ratio; } } <markup lang=\"java\" title=\"Custom Mapper Class\" >public class WebConfigMapper implements Function&lt;Config, WebConfig&gt; { @Override public WebConfig apply(Config config) throws ConfigMappingException, MissingValueException { return new WebConfig( config.get(\"debug\").asBoolean().orElse(false), config.get(\"page-size\").asInt().orElse(10), config.get(\"ratio\").asDouble().orElse(1.0) ); } } <markup lang=\"java\" title=\"Explicitly Using the Mapper\" >... Config config = Config.create(classpath(\"application.properties\")); WebConfig web = config.get(\"web\") .as(new WebConfigMapper()) .get(); <markup lang=\"java\" title=\"Registering and Implicitly Using the Mapper\" >... Config config = Config.builder(classpath(\"application.properties\")) .addMapper(WebConfig.class, new WebConfigMapper()) .build(); WebConfig web = config.get(\"web\") .as(WebConfig.class) .get(); Either of the two approaches just described will always work without requiring you to change the POJO class. ",
            "title": "Converting Configuration to Complex Types"
        },
        {
            "location": "/se/config/04_property-mapping",
            "text": " If you can change the target class you can add any one of the following methods or constructors to the POJO class which the config system will find and use for mapping. Continuing with the WebConfig example introduced earlier: Methods Supporting Auto-mapping static WebConfig create(Config); static WebConfig from(Config); static WebConfig from(String); static WebConfig of(Config); static WebConfig of(String); static WebConfig valueOf(Config); static WebConfig valueOf(String); static WebConfig fromConfig(Config); static WebConfig fromString(String); Constructors Supporting Auto-mapping WebConfig(Config); WebConfig(String); If the config system finds any of these methods or constructors when the application invokes <markup lang=\"java\" >WebConfig wc = config.as(WebConfig.class).get(); it will invoke the one it found to map the config data to a new instance of the target class. You do not need to write a separate class to do the mapping or register it with the Config.Builder for the config instance. ",
            "title": "Adding the Mapping to the POJO"
        },
        {
            "location": "/se/config/04_property-mapping",
            "text": " You can limit the changes to the POJO class by adding a single builder method to the POJO which returns a builder class for the POJO: <markup lang=\"java\" >public class WebConfig { ... static WebConfigBuilder builder() { return new WebConfigBuilder(); } ... } The builder class WebConfigBuilder is expected to be a Java Bean with bean properties named for the config properties of interest, and a method WebConfig build() which creates the mapped instance from the builder&#8217;s own bean properties. When your application invokes config.as(WebConfig.class) the config system finds and invokes the WebConfig.builder() method, assigns the bean properties on the returned builder from the config subtree rooted at config , and invokes the builder&#8217;s build() method yielding the resulting WebConfig instance. ",
            "title": "Writing a Builder Method and Class for the POJO"
        },
        {
            "location": "/se/config/04_property-mapping",
            "text": " If the target Java class you want to use meets certain conditions&#8201;&#8212;&#8201;or if you can change it to meet one of those conditions&#8201;&#8212;&#8201;you might not need to write a separate mapper class. Instead, you add the mapping logic to the POJO itself in one of several ways and the config system uses Java reflection to search for those ways to perform the mapping. Your application facilitates this implicit mapping either by adding to the POJO class or by providing a builder class for it. This feature is available in Object mapping module, and is added through Java ServiceLoader mechanism. This is no longer part of core Config module, as it depends on reflection and introduces a lot of magic (see the list of supported mapping methods below, also uses reflection to invoke the methods and to map configuration values to fields/methods etc.). <markup lang=\"xml\" title=\"Config object mapping Dependency in pom.xml \" >&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.config&lt;/groupId&gt; &lt;artifactId&gt;helidon-config-object-mapping&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; Adding the Mapping to the POJO If you can change the target class you can add any one of the following methods or constructors to the POJO class which the config system will find and use for mapping. Continuing with the WebConfig example introduced earlier: Methods Supporting Auto-mapping static WebConfig create(Config); static WebConfig from(Config); static WebConfig from(String); static WebConfig of(Config); static WebConfig of(String); static WebConfig valueOf(Config); static WebConfig valueOf(String); static WebConfig fromConfig(Config); static WebConfig fromString(String); Constructors Supporting Auto-mapping WebConfig(Config); WebConfig(String); If the config system finds any of these methods or constructors when the application invokes <markup lang=\"java\" >WebConfig wc = config.as(WebConfig.class).get(); it will invoke the one it found to map the config data to a new instance of the target class. You do not need to write a separate class to do the mapping or register it with the Config.Builder for the config instance. Writing a Builder Method and Class for the POJO You can limit the changes to the POJO class by adding a single builder method to the POJO which returns a builder class for the POJO: <markup lang=\"java\" >public class WebConfig { ... static WebConfigBuilder builder() { return new WebConfigBuilder(); } ... } The builder class WebConfigBuilder is expected to be a Java Bean with bean properties named for the config properties of interest, and a method WebConfig build() which creates the mapped instance from the builder&#8217;s own bean properties. When your application invokes config.as(WebConfig.class) the config system finds and invokes the WebConfig.builder() method, assigns the bean properties on the returned builder from the config subtree rooted at config , and invokes the builder&#8217;s build() method yielding the resulting WebConfig instance. ",
            "title": "Advanced Conversions using Explicit Mapping Logic"
        },
        {
            "location": "/se/config/04_property-mapping",
            "text": " If your POJO target class is already a JavaBean&#8201;&#8212;&#8201;or you can modify it to become one&#8201;&#8212;&#8201;you might be able to avoid writing any explicit mapping code yourself. The config system invokes the no-args constructor on the target class to create a new instance. It treats each public setter method and each public non-final field as a JavaBean property. The config system processes any non-primitive property recursively as a JavaBean. In this way the config system builds up the target object from the config data. By default, the system matches potential JavaBean property names with config keys in the configuration. Use the Value annnotation to control some of the JavaBean processing for a given property. Value Annotation Attribute Usage key Indicates which config key should match this JavaBean property withDefault String used for the bean property default value if none is set in the config withDefaultSupplier Supplier of the default bean property value if nont is set in the config To exclude a bean property from the config system bean processing annotate it with Config.Transient . Here is an example using the app portion of the example configuration from the introduction. <markup lang=\"java\" title=\"Java bean to load app propeties into via setters\" >public class AppConfig { private Instant timestamp; private String greeting; private int pageSize; private List&lt;Integer&gt; basicRange; public AppConfig() { } public void setGreeting(String greeting) { this.greeting = greeting; } public String getGreeting() { return greeting; } @Value(key = \"page-size\", withDefault = \"10\") public void setPageSize(int pageSize) { this.pageSize = pageSize; } public int getPageSize() { return pageSize; } @Value(key = \"basic-range\", withDefaultSupplier = BasicRangeSupplier.class) public void setBasicRange(List&lt;Integer&gt; basicRange) { this.basicRange = basicRange; } public List&lt;Integer&gt; getBasicRange() { return basicRange; } @Config.Transient public void setTimestamp(Instant timestamp) { this.timestamp = timestamp; } public Instant getTimestamp() { return timestamp; } public static class BasicRangeSupplier implements Supplier&lt;List&lt;Integer&gt;&gt; { @Override public List&lt;Integer&gt; get() { return List.of(-10, 10); } } } Public no-parameter constructor. Property greeting is not customized and will be set from the config node with the key greeting , if present in the config. Property pageSize is matched to the config key page-size . If the page-size config node does not exist, the pageSize bean property defaults to 10 . Property basicRange is matched to the config key basic-range . If the basic-range config node does not exist, a BasicRangeSupplier instance will provide the default value. The timestamp bean property is never set, even if the config contains a node with the key timestamp . BasicRangeSupplier is used to supply the List&lt;Integer&gt; default value. Here is an example of code loading config and mapping part of it to the AppConfig bean above. <markup lang=\"java\" title=\"Map app config node into AppConfig class\" >Config config = Config.create(classpath(\"application.conf\")); AppConfig app = config.get(\"app\") .as(AppConfig.class) .get(); //assert that all values are loaded from file assert app.getGreeting().equals(\"Hello\"); assert app.getPageSize() == 20; assert app.getBasicRange().size() == 2 &amp;&amp; app.getBasicRange().get(0) == -20 &amp;&amp; app.getBasicRange().get(1) == 20; //assert that Transient property is not set assert app.getTimestamp() == null; The config system finds no registered ConfigMapper for AppConfig and so applies the JavaBean pattern to convert the config to an AppConfig instance. Because the bean property timestamp was marked as transient, the config system did not set it. ",
            "title": "POJO as JavaBean"
        },
        {
            "location": "/se/config/04_property-mapping",
            "text": " If the target class includes the public static method builder() that returns any object, then the config system will make sure that the return type has a method build() which returns an instance of the target class. If so, the config system treats the builder as a JavaBean and invokes the builder() method to instantiate the builder class, treats the builder as a JavaBean and maps the Config subtree to it, invokes the builder&#8217;s build() method to create the new instance of the target class. You can augment the target class with the public static builder() method: <markup lang=\"java\" title=\"JavaBean for app properties, via a Builder \" >public class AppConfig { private String greeting; private int pageSize; private List&lt;Integer&gt; basicRange; private AppConfig(String greeting, int pageSize, List&lt;Integer&gt; basicRange) { this.greeting = greeting; this.pageSize = pageSize; this.basicRange = basicRange; } public String getGreeting() { return greeting; } public int getPageSize() { return pageSize; } public List&lt;Integer&gt; getBasicRange() { return basicRange; } public static Builder builder() { return new Builder(); } public static class Builder { private String greeting; private int pageSize; private List&lt;Integer&gt; basicRange; private Builder() { } public void setGreeting(String greeting) { this.greeting = greeting; } @Value(key = \"page-size\", withDefault = \"10\") public void setPageSize(int pageSize) { this.pageSize = pageSize; } @Value(key = \"basic-range\", withDefaultSupplier = BasicRangeSupplier.class) public void setBasicRange(List&lt;Integer&gt; basicRange) { this.basicRange = basicRange; } public AppConfig build() { return new AppConfig(greeting, pageSize, basicRange); } } } The target class&#8217;s constructor can be private in this case because new instances are created from the inner class Builder which has access to `AppConfig&#8217;s private members. The target class contains public static method builder() which returns an object that itself exposes the method AppConfig build() , so the config system recognizes it. The config system treats the AppConfig.Builder (not the enclosing target class) as a JavaBean. The builder&#8217;s property greeting is not customized and is set from config node with greeting key, if one exists. The builder&#8217;s property pageSize maps to the config key page-size and defaults to 10 if absent. The builder&#8217;s property basicRange maps to the config key basic-range and uses a BasicRangeSupplier instance to get a default value if needed. Finally, the config system invokes the builder&#8217;s public method build() , creating the new instance of AppConfig for use by the application. ",
            "title": "Builder as JavaBean"
        },
        {
            "location": "/se/config/04_property-mapping",
            "text": " Another option is to annotate the parameters to a factory method or to a constructor on the target class. You can add a factory method to the target class, a public static method from with parameters annotated to link them to the corresponding config keys. Or you can add or modify a constructor with parameters, similarly annotated to form the link from each parameter to the corresponding config key. Warning Be sure to annotate each parameter of the from method or constructor with @Value and specify the key to use for the mapping. The parameter names in the Java code are not always available at runtime to map to config keys. (They might be arg0 , arg1 , etc.) <markup lang=\"java\" title=\"Target Class with Factory Method from \" >public class AppConfig { private final String greeting; private final int pageSize; private final List&lt;Integer&gt; basicRange; private AppConfig(String greeting, int pageSize, List&lt;Integer&gt; basicRange) { this.greeting = greeting; this.pageSize = pageSize; this.basicRange = basicRange; } public String getGreeting() { return greeting; } public int getPageSize() { return pageSize; } public List&lt;Integer&gt; getBasicRange() { return basicRange; } public static AppConfig from( @Value(key = \"greeting\") String greeting, @Value(key = \"page-size\", withDefault = \"10\") int pageSize, @Value(key = \"basic-range\", withDefaultSupplier = BasicRangeSupplier.class) List&lt;Integer&gt; basicRange) { return new AppConfig(greeting, pageSize, basicRange); } } The target class constructor can be private because the factory method on the same class has access to it. The config system invokes the factory method from(&#8230;&#8203;) , passing arguments it has fetched from the correspondingly-named config subtrees. The factory method returns the new initialized AppConfig instance. Note the consistent use of @Value(key = \"&#8230;&#8203;\") on each parameter. Because the property greeting does not specify a default value the property is mandatory and must appear in the configuration source. Otherwise the config system throws a ConfigMappingException . Alternatively, you can use an annotated constructor instead of a static factory method. Revising the example above, make the constructor public, annotate its parameters, and remove the now-unneeded from factory method. <markup lang=\"java\" title=\"Target Class with Annotated Public Constructor\" >public class AppConfig { ... public AppConfig( @Value(key = \"greeting\") String greeting, @Value(key = \"page-size\", withDefault = \"10\") int pageSize, @Value(key = \"basic-range\", withDefaultSupplier = BasicRangeSupplier.class) List&lt;Integer&gt; basicRange) { this.greeting = greeting; this.pageSize = pageSize; this.basicRange = basicRange; } Constructor is public . Each parameter has the ConfigValue annotation to at least specify the config key name. When the application invokes config.as(AppConfig.class) , the config system locates the public annotated constructor and invokes it, passing as arguments the data it fetches from the configuration matching the annotation key names with the configuration keys. ",
            "title": "Target Class with Annotated Factory Method or Constructor"
        },
        {
            "location": "/se/config/04_property-mapping",
            "text": " The config system can also interpret your classes as JavaBeans and use the normal bean naming conventions to map configuration data to your POJO classes, using one of these patterns: POJO as JavaBean - The config system treats the target class itself as a JavaBean, assigning values from the config to the bean properties of the POJO class. builder as JavaBean - The config system invokes the POJO&#8217;s builder() method to obtain a builder for that POJO type and treats the builder class as a JavaBean, assigning values from the config to the builder&#8217;s bean properties and then invoking the builder&#8217;s build method to create an instance of the target POJO class. POJO with factory method or decorated constructor - The config system finds a from method or a constructor on the POJO class itself which accepts annotated arguments, then invokes that method or constructor passing the specified arguments based on the config. The from method returns an instance of the POJO class initialized with the values passed as arguments. The following sections describe these patterns in more detail. This feature is available in Object mapping module, and is added through Java ServiceLoader mechanism. This is no longer part of core Config module, as it depends on reflection. <markup lang=\"xml\" title=\"Config object mapping Dependency in pom.xml \" >&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.config&lt;/groupId&gt; &lt;artifactId&gt;helidon-config-object-mapping&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; POJO as JavaBean If your POJO target class is already a JavaBean&#8201;&#8212;&#8201;or you can modify it to become one&#8201;&#8212;&#8201;you might be able to avoid writing any explicit mapping code yourself. The config system invokes the no-args constructor on the target class to create a new instance. It treats each public setter method and each public non-final field as a JavaBean property. The config system processes any non-primitive property recursively as a JavaBean. In this way the config system builds up the target object from the config data. By default, the system matches potential JavaBean property names with config keys in the configuration. Use the Value annnotation to control some of the JavaBean processing for a given property. Value Annotation Attribute Usage key Indicates which config key should match this JavaBean property withDefault String used for the bean property default value if none is set in the config withDefaultSupplier Supplier of the default bean property value if nont is set in the config To exclude a bean property from the config system bean processing annotate it with Config.Transient . Here is an example using the app portion of the example configuration from the introduction. <markup lang=\"java\" title=\"Java bean to load app propeties into via setters\" >public class AppConfig { private Instant timestamp; private String greeting; private int pageSize; private List&lt;Integer&gt; basicRange; public AppConfig() { } public void setGreeting(String greeting) { this.greeting = greeting; } public String getGreeting() { return greeting; } @Value(key = \"page-size\", withDefault = \"10\") public void setPageSize(int pageSize) { this.pageSize = pageSize; } public int getPageSize() { return pageSize; } @Value(key = \"basic-range\", withDefaultSupplier = BasicRangeSupplier.class) public void setBasicRange(List&lt;Integer&gt; basicRange) { this.basicRange = basicRange; } public List&lt;Integer&gt; getBasicRange() { return basicRange; } @Config.Transient public void setTimestamp(Instant timestamp) { this.timestamp = timestamp; } public Instant getTimestamp() { return timestamp; } public static class BasicRangeSupplier implements Supplier&lt;List&lt;Integer&gt;&gt; { @Override public List&lt;Integer&gt; get() { return List.of(-10, 10); } } } Public no-parameter constructor. Property greeting is not customized and will be set from the config node with the key greeting , if present in the config. Property pageSize is matched to the config key page-size . If the page-size config node does not exist, the pageSize bean property defaults to 10 . Property basicRange is matched to the config key basic-range . If the basic-range config node does not exist, a BasicRangeSupplier instance will provide the default value. The timestamp bean property is never set, even if the config contains a node with the key timestamp . BasicRangeSupplier is used to supply the List&lt;Integer&gt; default value. Here is an example of code loading config and mapping part of it to the AppConfig bean above. <markup lang=\"java\" title=\"Map app config node into AppConfig class\" >Config config = Config.create(classpath(\"application.conf\")); AppConfig app = config.get(\"app\") .as(AppConfig.class) .get(); //assert that all values are loaded from file assert app.getGreeting().equals(\"Hello\"); assert app.getPageSize() == 20; assert app.getBasicRange().size() == 2 &amp;&amp; app.getBasicRange().get(0) == -20 &amp;&amp; app.getBasicRange().get(1) == 20; //assert that Transient property is not set assert app.getTimestamp() == null; The config system finds no registered ConfigMapper for AppConfig and so applies the JavaBean pattern to convert the config to an AppConfig instance. Because the bean property timestamp was marked as transient, the config system did not set it. Builder as JavaBean If the target class includes the public static method builder() that returns any object, then the config system will make sure that the return type has a method build() which returns an instance of the target class. If so, the config system treats the builder as a JavaBean and invokes the builder() method to instantiate the builder class, treats the builder as a JavaBean and maps the Config subtree to it, invokes the builder&#8217;s build() method to create the new instance of the target class. You can augment the target class with the public static builder() method: <markup lang=\"java\" title=\"JavaBean for app properties, via a Builder \" >public class AppConfig { private String greeting; private int pageSize; private List&lt;Integer&gt; basicRange; private AppConfig(String greeting, int pageSize, List&lt;Integer&gt; basicRange) { this.greeting = greeting; this.pageSize = pageSize; this.basicRange = basicRange; } public String getGreeting() { return greeting; } public int getPageSize() { return pageSize; } public List&lt;Integer&gt; getBasicRange() { return basicRange; } public static Builder builder() { return new Builder(); } public static class Builder { private String greeting; private int pageSize; private List&lt;Integer&gt; basicRange; private Builder() { } public void setGreeting(String greeting) { this.greeting = greeting; } @Value(key = \"page-size\", withDefault = \"10\") public void setPageSize(int pageSize) { this.pageSize = pageSize; } @Value(key = \"basic-range\", withDefaultSupplier = BasicRangeSupplier.class) public void setBasicRange(List&lt;Integer&gt; basicRange) { this.basicRange = basicRange; } public AppConfig build() { return new AppConfig(greeting, pageSize, basicRange); } } } The target class&#8217;s constructor can be private in this case because new instances are created from the inner class Builder which has access to `AppConfig&#8217;s private members. The target class contains public static method builder() which returns an object that itself exposes the method AppConfig build() , so the config system recognizes it. The config system treats the AppConfig.Builder (not the enclosing target class) as a JavaBean. The builder&#8217;s property greeting is not customized and is set from config node with greeting key, if one exists. The builder&#8217;s property pageSize maps to the config key page-size and defaults to 10 if absent. The builder&#8217;s property basicRange maps to the config key basic-range and uses a BasicRangeSupplier instance to get a default value if needed. Finally, the config system invokes the builder&#8217;s public method build() , creating the new instance of AppConfig for use by the application. Target Class with Annotated Factory Method or Constructor Another option is to annotate the parameters to a factory method or to a constructor on the target class. You can add a factory method to the target class, a public static method from with parameters annotated to link them to the corresponding config keys. Or you can add or modify a constructor with parameters, similarly annotated to form the link from each parameter to the corresponding config key. Warning Be sure to annotate each parameter of the from method or constructor with @Value and specify the key to use for the mapping. The parameter names in the Java code are not always available at runtime to map to config keys. (They might be arg0 , arg1 , etc.) <markup lang=\"java\" title=\"Target Class with Factory Method from \" >public class AppConfig { private final String greeting; private final int pageSize; private final List&lt;Integer&gt; basicRange; private AppConfig(String greeting, int pageSize, List&lt;Integer&gt; basicRange) { this.greeting = greeting; this.pageSize = pageSize; this.basicRange = basicRange; } public String getGreeting() { return greeting; } public int getPageSize() { return pageSize; } public List&lt;Integer&gt; getBasicRange() { return basicRange; } public static AppConfig from( @Value(key = \"greeting\") String greeting, @Value(key = \"page-size\", withDefault = \"10\") int pageSize, @Value(key = \"basic-range\", withDefaultSupplier = BasicRangeSupplier.class) List&lt;Integer&gt; basicRange) { return new AppConfig(greeting, pageSize, basicRange); } } The target class constructor can be private because the factory method on the same class has access to it. The config system invokes the factory method from(&#8230;&#8203;) , passing arguments it has fetched from the correspondingly-named config subtrees. The factory method returns the new initialized AppConfig instance. Note the consistent use of @Value(key = \"&#8230;&#8203;\") on each parameter. Because the property greeting does not specify a default value the property is mandatory and must appear in the configuration source. Otherwise the config system throws a ConfigMappingException . Alternatively, you can use an annotated constructor instead of a static factory method. Revising the example above, make the constructor public, annotate its parameters, and remove the now-unneeded from factory method. <markup lang=\"java\" title=\"Target Class with Annotated Public Constructor\" >public class AppConfig { ... public AppConfig( @Value(key = \"greeting\") String greeting, @Value(key = \"page-size\", withDefault = \"10\") int pageSize, @Value(key = \"basic-range\", withDefaultSupplier = BasicRangeSupplier.class) List&lt;Integer&gt; basicRange) { this.greeting = greeting; this.pageSize = pageSize; this.basicRange = basicRange; } Constructor is public . Each parameter has the ConfigValue annotation to at least specify the config key name. When the application invokes config.as(AppConfig.class) , the config system locates the public annotated constructor and invokes it, passing as arguments the data it fetches from the configuration matching the annotation key names with the configuration keys. ",
            "title": "Conversions using JavaBean Deserialization"
        },
        {
            "location": "/se/grpc/22_client_configuration",
            "text": " Configure the gRPC client using the Helidon configuration framework, either programmatically or via a configuration file. As mentioned earlier, creating a GrpcServiceClient involves: Creating a ClientServiceDescriptor which describes the methods in the service that this client can invoke. Creating a gRPC Channel through which the client communicates with the server. ",
            "title": "preambule"
        },
        {
            "location": "/se/grpc/22_client_configuration",
            "text": " The only way to configure the ClientServiceDescriptor is in your application code. <markup lang=\"java\" >ClientServiceDescriptor descriptor = ClientServiceDescriptor + .builder(HelloService.class) // (1) .unary(\"SayHello\") // (2) .build(); // (3) Create a builder for a ClientServiceDescriptor for the HelloService . Specify that the HelloService has a unary method named SayHello . There are many other methods in this class that allow you to define ClientStreaming , ServerStreaming and Bidirectional methods. Build the ClientServiceDescriptor . ",
            "title": "Configuring the ClientServiceDescriptor in your code"
        },
        {
            "location": "/se/grpc/22_client_configuration",
            "text": " Configuring the ClientServiceDescriptor in your code The only way to configure the ClientServiceDescriptor is in your application code. <markup lang=\"java\" >ClientServiceDescriptor descriptor = ClientServiceDescriptor + .builder(HelloService.class) // (1) .unary(\"SayHello\") // (2) .build(); // (3) Create a builder for a ClientServiceDescriptor for the HelloService . Specify that the HelloService has a unary method named SayHello . There are many other methods in this class that allow you to define ClientStreaming , ServerStreaming and Bidirectional methods. Build the ClientServiceDescriptor . ",
            "title": "Configuring the ClientServiceDescriptor"
        },
        {
            "location": "/se/grpc/22_client_configuration",
            "text": " gRPC allows various channel configurations (deadlines, retries, interceptors etc.) Please refer to gRPC documentation: https://grpc.io/grpc-java/javadoc/io/grpc/ManagedChannelBuilder.html . ",
            "title": "Configuring the gRPC Channel"
        },
        {
            "location": "/mp/metrics/01a_metrics_capable_components",
            "text": " This document explains Helidon MP metrics-capable components and applications and describes how to create and control them. ",
            "title": "preambule"
        },
        {
            "location": "/mp/metrics/01a_metrics_capable_components",
            "text": " Think of Helidon metrics in three related but different parts: The Helidon metrics API allows your code to register, look-up, remove, and update metrics using the RegistryFactory , MetricRegistry , and individual metrics interfaces. Helidon provides two implementations of the Helidon metrics API and selects which one to use at runtime, based on what components are present on the runtime path and whether metrics is configured to be enabled or disabled. The built-in Helidon metrics web service supports the /metrics endpoints by which clients can retrieve metadata and values of the registered metrics. Helidon MP apps which use metrics enable the metrics service by default. As you plan and write Helidon components and applications, you make some choices about exactly how your code will use metrics. This guide gives some background information, describes the choices you face, explains their ramifications, and provides some code examples. ",
            "title": "Introduction"
        },
        {
            "location": "/mp/metrics/01a_metrics_capable_components",
            "text": " We can place each Helidon component and Helidon application into one of three categories based on how it relies on metrics. The type of module dictates the compile-time dependency you declare in the project pom.xml . Types of Metrics Usage Registers, updates, removes metrics? Refers to metrics values? Category times times metrics-independent check times metrics-capable check check metrics-dependent Whenever possible, if your component or app uses metrics write it as metrics-capable code. ",
            "title": "Categorizing Metrics Usage"
        },
        {
            "location": "/mp/metrics/01a_metrics_capable_components",
            "text": " Helidon provides two metrics implementations. Full-featured metrics allows registering, removing, and updating metrics and observing metrics' changing values. The helidon-metrics component contains full-featured metrics. Minimal metrics supports registering, removing, and updating metrics. The metrics objects provided by the minimal implementation are no-ops: their values never change. The minimal implementation is part of the helidon-metrics-api component. Any code compiled with helidon-metrics-api can assume that the runtime path will include the minimal implementation. Both implementations support all the operations of the RegistryFactory and the MetricRegistry . The full implementation provides fully-functional metrics instances (counters, timers, etc.). In the minimal implementations, metrics do not update their values. For Helidon to use the full implementation, two conditions must hold: The helidon-metrics component must be on the runtime path. Metrics must be enabled, using either a builder or configuration. (Enabled is the default.) Otherwise, provided that the runtime path includes helidon-metrics-api , Helidon activates the minimal implementation. ",
            "title": "Understanding the Two Metrics Implementations"
        },
        {
            "location": "/mp/metrics/01a_metrics_capable_components",
            "text": " Helidon includes two implementations of support for the metrics web service endpoint /metrics (or whatever context value is configured). The full-service implementation sends responses which describe the metadata and current values for the metrics registered in metric registries. The helidon-metrics component contains this implementation. The helidon-metrics-service-api component contains the API for the metrics web service support (the MetricsSupport interface) and also a minimal implementation. This implementation simply responds with 404 and an explanatory message that metrics are disabled. Any code compiled with helidon-metrics-service-api can assume that the runtime path will contain the minimal implementation. Helidon activates the full implementation if the runtime path includes the full implementation and metrics is configured as enabled; Helidon uses the minimal implementation otherwise. ",
            "title": "Understanding the Two Metrics Service Implementations"
        },
        {
            "location": "/mp/metrics/01a_metrics_capable_components",
            "text": " Using configuration, your component can let end users control at runtime whether Helidon should use full-featured metrics. If an end user sets metrics.enabled to false , then Helidon activates the minimal metrics and metrics service implementations provided they are in the runtime path. Further, users can set component-name.metrics.enabled to false which disables metrics for just that component so long as the component was written to check that setting and act on it accordingly. ",
            "title": "Enabling and Disabling Metrics"
        },
        {
            "location": "/mp/metrics/01a_metrics_capable_components",
            "text": " Include this dependency: <markup lang=\"xml\" title=\"Dependency for Helidon metrics API\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics-api&lt;/artifactId&gt; &lt;/dependency&gt; This module defines the metrics API: RegistryFactory , MetricRegistry , and the various metrics themselves. Declare an explicit runtime dependency on the full-featured metrics implementation: <markup lang=\"xml\" title=\"Dependency for full metrics and metrics service implementations\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; ",
            "title": "Declaring Dependencies"
        },
        {
            "location": "/mp/metrics/01a_metrics_capable_components",
            "text": " Write your non-application component to accept component-specific configuration that includes an optional metrics section which can include an optional enabled setting. Helidon defaults the value to true . The following example shows one way to accomplish this: <markup lang=\"java\" title=\"Example code to support disabling metrics usage in a component\" >import io.helidon.config.Config; import io.helidon.metrics.api.ComponentMetricsSettings; import io.helidon.metrics.api.MetricsSettings; import io.helidon.metrics.api.RegistryFactory; import org.eclipse.microprofile.metrics.MetricRegistry; public class UtilComponent { private final MetricRegistry metricRegistry; public static class Builder implements io.helidon.common.Builder&lt;UtilComponent&gt; { private ComponentMetricsSettings.Builder componentMetricsSettingsBuilder = ComponentMetricsSettings.builder(); public Builder componentMetricsSettings(ComponentMetricsSettings.Builder componentMetricsSettingsBuilder) { this.componentMetricsSettingsBuilder = componentMetricsSettingsBuilder; return this; } public Builder config(Config componentConfig) { componentConfig .get(ComponentMetricsSettings.Builder.METRICS_CONFIG_KEY) .as(ComponentMetricsSettings::create) .ifPresent(this::componentMetricsSettings); return this; } public UtilComponent build() { return new UtilComponent(this); } ... } private UtilComponent(Builder builder) { ... metricRegistry = RegistryFactory .getInstance(builder.componentMetricsSettingsBuilder.build()) .getRegistry(MetricRegistry.Type.VENDOR); } MetricRegistry metricRegistry() { return metricRegistry; } } Other code in the component uses this metric registry for registering, looking up, and removing metrics. Applications which use instances of MyComponent use this Builder to set up and create those instances. Applications which layer on your component invoke this method to set up the component-level metrics behavior they want your component to use. If an application supports configuration, it passes the util config to this method. The constructor for your component obtains the MetricRegistry which the rest of your component will use. Provides easy access to the MetricRegistry which the component&#8217;s metrics code should use. Helidon returns either a full-featured RegistryFactory or a minimal one, depending on: whether the full-featured metrics implementation is on the runtime path, whether metrics overall is enabled or disabled, and whether the component metrics settings requests enabled or disabled metrics. ",
            "title": "Writing a Non-application Component "
        },
        {
            "location": "/mp/metrics/01a_metrics_capable_components",
            "text": " When your MP application code uses @Inject for either a RegistryFactory or a MetricRegistry , Helidon injects either the full-featured instance or the minimal instance according to whether the runtime path includes the full implementation and, if so, whether metrics is enabled. By choosing and injecting the appropriate implementation, Helidon allows you to write your code without concern for which implementation is available at runtime. ",
            "title": "Writing a Helidon MP Application"
        },
        {
            "location": "/mp/metrics/01a_metrics_capable_components",
            "text": " The Helidon MP metrics implementation depends on the metrics and metrics service APIs as well as helidon-metrics which contains the full implementation of each. Therefore, by default, Helidon MP applications have full-featured metrics and endpoint support. Application code can @Inject the RegistryFactory and MetricRegistry instances. Helidon MP itself uses metrics settings in the configuration to make the correct RegistryFactory and MetricRegistry instances available at injection sites. Helidon&#8217;s MicroProfile metrics component helidon-microprofile-metrics has its own runtime dependency on the minimal implementation, so that implementation, at least, is available at runtime. By default, Helidon MP applications use the full implementation, because Helidon&#8217;s MP metrics depends also on the full metrics implementation. That said, a developer of a Helidon MP app can explicitly exclude the dependency on the full implementation: <markup lang=\"xml\" title=\"Explicit exclusion of helidon-metrics \" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.bundles&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; In the resulting Helidon MP application, Helidon will use the minimal metrics and metrics support implementations. ",
            "title": "Packaging a Metrics-capable Helidon MP Application "
        },
        {
            "location": "/mp/metrics/01a_metrics_capable_components",
            "text": " Here is an example showing how useful metrics-capable code can be. You (or others) could assemble a Docker image with your metrics-capable app as its top layer or your metrics-capable component in a middle layer, built on a lower layer containing several Helidon modules including the full metrics implementation. When that Docker image runs, your app will run with full-featured metrics support. Separately, someone could build a similar Docker image which does not include the Helidon metrics implementation. In this Docker image, your app or component will run successfully but will not incur the overhead of actually updating the metrics it uses. Users can create different Docker images, some with full metrics support and some without, which all use a single version of your metrics-capable app or component which runs properly in either environment without change. ",
            "title": "An Example: Docker Images"
        },
        {
            "location": "/mp/metrics/01a_metrics_capable_components",
            "text": " The way you write a metrics-capable module depends on whether it is a component (that is, not an application) or an application . Writing a Non-application Component Write your non-application component to accept component-specific configuration that includes an optional metrics section which can include an optional enabled setting. Helidon defaults the value to true . The following example shows one way to accomplish this: <markup lang=\"java\" title=\"Example code to support disabling metrics usage in a component\" >import io.helidon.config.Config; import io.helidon.metrics.api.ComponentMetricsSettings; import io.helidon.metrics.api.MetricsSettings; import io.helidon.metrics.api.RegistryFactory; import org.eclipse.microprofile.metrics.MetricRegistry; public class UtilComponent { private final MetricRegistry metricRegistry; public static class Builder implements io.helidon.common.Builder&lt;UtilComponent&gt; { private ComponentMetricsSettings.Builder componentMetricsSettingsBuilder = ComponentMetricsSettings.builder(); public Builder componentMetricsSettings(ComponentMetricsSettings.Builder componentMetricsSettingsBuilder) { this.componentMetricsSettingsBuilder = componentMetricsSettingsBuilder; return this; } public Builder config(Config componentConfig) { componentConfig .get(ComponentMetricsSettings.Builder.METRICS_CONFIG_KEY) .as(ComponentMetricsSettings::create) .ifPresent(this::componentMetricsSettings); return this; } public UtilComponent build() { return new UtilComponent(this); } ... } private UtilComponent(Builder builder) { ... metricRegistry = RegistryFactory .getInstance(builder.componentMetricsSettingsBuilder.build()) .getRegistry(MetricRegistry.Type.VENDOR); } MetricRegistry metricRegistry() { return metricRegistry; } } Other code in the component uses this metric registry for registering, looking up, and removing metrics. Applications which use instances of MyComponent use this Builder to set up and create those instances. Applications which layer on your component invoke this method to set up the component-level metrics behavior they want your component to use. If an application supports configuration, it passes the util config to this method. The constructor for your component obtains the MetricRegistry which the rest of your component will use. Provides easy access to the MetricRegistry which the component&#8217;s metrics code should use. Helidon returns either a full-featured RegistryFactory or a minimal one, depending on: whether the full-featured metrics implementation is on the runtime path, whether metrics overall is enabled or disabled, and whether the component metrics settings requests enabled or disabled metrics. Writing a Helidon MP Application When your MP application code uses @Inject for either a RegistryFactory or a MetricRegistry , Helidon injects either the full-featured instance or the minimal instance according to whether the runtime path includes the full implementation and, if so, whether metrics is enabled. By choosing and injecting the appropriate implementation, Helidon allows you to write your code without concern for which implementation is available at runtime. Packaging a Metrics-capable Helidon MP Application The Helidon MP metrics implementation depends on the metrics and metrics service APIs as well as helidon-metrics which contains the full implementation of each. Therefore, by default, Helidon MP applications have full-featured metrics and endpoint support. Application code can @Inject the RegistryFactory and MetricRegistry instances. Helidon MP itself uses metrics settings in the configuration to make the correct RegistryFactory and MetricRegistry instances available at injection sites. Helidon&#8217;s MicroProfile metrics component helidon-microprofile-metrics has its own runtime dependency on the minimal implementation, so that implementation, at least, is available at runtime. By default, Helidon MP applications use the full implementation, because Helidon&#8217;s MP metrics depends also on the full metrics implementation. That said, a developer of a Helidon MP app can explicitly exclude the dependency on the full implementation: <markup lang=\"xml\" title=\"Explicit exclusion of helidon-metrics \" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.bundles&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; In the resulting Helidon MP application, Helidon will use the minimal metrics and metrics support implementations. An Example: Docker Images Here is an example showing how useful metrics-capable code can be. You (or others) could assemble a Docker image with your metrics-capable app as its top layer or your metrics-capable component in a middle layer, built on a lower layer containing several Helidon modules including the full metrics implementation. When that Docker image runs, your app will run with full-featured metrics support. Separately, someone could build a similar Docker image which does not include the Helidon metrics implementation. In this Docker image, your app or component will run successfully but will not incur the overhead of actually updating the metrics it uses. Users can create different Docker images, some with full metrics support and some without, which all use a single version of your metrics-capable app or component which runs properly in either environment without change. ",
            "title": "Writing the Metrics-capable Code"
        },
        {
            "location": "/mp/metrics/01a_metrics_capable_components",
            "text": " Whoever packages and deploys your application or component can control what code will be on the runtime path and whether metrics is enabled or not. As a result, wherever possible, construct your modules which use metrics so that they do not make decisions based on the values of metrics; that is, design them to be metrics-capable, not metrics-dependent. Doing so allows your code to operate regardless of whether the full-featured metrics implementation is active at runtime. Declaring Dependencies Include this dependency: <markup lang=\"xml\" title=\"Dependency for Helidon metrics API\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics-api&lt;/artifactId&gt; &lt;/dependency&gt; This module defines the metrics API: RegistryFactory , MetricRegistry , and the various metrics themselves. Declare an explicit runtime dependency on the full-featured metrics implementation: <markup lang=\"xml\" title=\"Dependency for full metrics and metrics service implementations\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; Writing the Metrics-capable Code The way you write a metrics-capable module depends on whether it is a component (that is, not an application) or an application . Writing a Non-application Component Write your non-application component to accept component-specific configuration that includes an optional metrics section which can include an optional enabled setting. Helidon defaults the value to true . The following example shows one way to accomplish this: <markup lang=\"java\" title=\"Example code to support disabling metrics usage in a component\" >import io.helidon.config.Config; import io.helidon.metrics.api.ComponentMetricsSettings; import io.helidon.metrics.api.MetricsSettings; import io.helidon.metrics.api.RegistryFactory; import org.eclipse.microprofile.metrics.MetricRegistry; public class UtilComponent { private final MetricRegistry metricRegistry; public static class Builder implements io.helidon.common.Builder&lt;UtilComponent&gt; { private ComponentMetricsSettings.Builder componentMetricsSettingsBuilder = ComponentMetricsSettings.builder(); public Builder componentMetricsSettings(ComponentMetricsSettings.Builder componentMetricsSettingsBuilder) { this.componentMetricsSettingsBuilder = componentMetricsSettingsBuilder; return this; } public Builder config(Config componentConfig) { componentConfig .get(ComponentMetricsSettings.Builder.METRICS_CONFIG_KEY) .as(ComponentMetricsSettings::create) .ifPresent(this::componentMetricsSettings); return this; } public UtilComponent build() { return new UtilComponent(this); } ... } private UtilComponent(Builder builder) { ... metricRegistry = RegistryFactory .getInstance(builder.componentMetricsSettingsBuilder.build()) .getRegistry(MetricRegistry.Type.VENDOR); } MetricRegistry metricRegistry() { return metricRegistry; } } Other code in the component uses this metric registry for registering, looking up, and removing metrics. Applications which use instances of MyComponent use this Builder to set up and create those instances. Applications which layer on your component invoke this method to set up the component-level metrics behavior they want your component to use. If an application supports configuration, it passes the util config to this method. The constructor for your component obtains the MetricRegistry which the rest of your component will use. Provides easy access to the MetricRegistry which the component&#8217;s metrics code should use. Helidon returns either a full-featured RegistryFactory or a minimal one, depending on: whether the full-featured metrics implementation is on the runtime path, whether metrics overall is enabled or disabled, and whether the component metrics settings requests enabled or disabled metrics. Writing a Helidon MP Application When your MP application code uses @Inject for either a RegistryFactory or a MetricRegistry , Helidon injects either the full-featured instance or the minimal instance according to whether the runtime path includes the full implementation and, if so, whether metrics is enabled. By choosing and injecting the appropriate implementation, Helidon allows you to write your code without concern for which implementation is available at runtime. Packaging a Metrics-capable Helidon MP Application The Helidon MP metrics implementation depends on the metrics and metrics service APIs as well as helidon-metrics which contains the full implementation of each. Therefore, by default, Helidon MP applications have full-featured metrics and endpoint support. Application code can @Inject the RegistryFactory and MetricRegistry instances. Helidon MP itself uses metrics settings in the configuration to make the correct RegistryFactory and MetricRegistry instances available at injection sites. Helidon&#8217;s MicroProfile metrics component helidon-microprofile-metrics has its own runtime dependency on the minimal implementation, so that implementation, at least, is available at runtime. By default, Helidon MP applications use the full implementation, because Helidon&#8217;s MP metrics depends also on the full metrics implementation. That said, a developer of a Helidon MP app can explicitly exclude the dependency on the full implementation: <markup lang=\"xml\" title=\"Explicit exclusion of helidon-metrics \" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.bundles&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; In the resulting Helidon MP application, Helidon will use the minimal metrics and metrics support implementations. An Example: Docker Images Here is an example showing how useful metrics-capable code can be. You (or others) could assemble a Docker image with your metrics-capable app as its top layer or your metrics-capable component in a middle layer, built on a lower layer containing several Helidon modules including the full metrics implementation. When that Docker image runs, your app will run with full-featured metrics support. Separately, someone could build a similar Docker image which does not include the Helidon metrics implementation. In this Docker image, your app or component will run successfully but will not incur the overhead of actually updating the metrics it uses. Users can create different Docker images, some with full metrics support and some without, which all use a single version of your metrics-capable app or component which runs properly in either environment without change. ",
            "title": "Designing and Writing Metrics-capable Applications and Components"
        },
        {
            "location": "/mp/metrics/01a_metrics_capable_components",
            "text": " By writing a metrics-capable app or component, you give packagers and deployers of your code the flexibility to include or exclude the full metrics implementation at runtime as they see fit. Because your one module works correctly in either environment: The consumers of your app benefit by not needing to understand and choose between two different implementations of your module, or having to add both your main module and an optional add-on which adds metrics support to your module. You benefit by writing and maintaining a single module, not two: one that is metrics-independent and one that is metrics-dependent. ",
            "title": "Advantages of Writing Metrics-capable Modules"
        },
        {
            "location": "/se/grpc/01_introduction",
            "text": " Helidon gRPC Server provides a framework for creating gRPC applications. ",
            "title": "preambule"
        },
        {
            "location": "/se/grpc/01_introduction",
            "text": " The Helidon gRPC feature is currently experimental and the APIs are subject to changes until gRPC support is stabilized. ",
            "title": "Experimental"
        },
        {
            "location": "/se/grpc/01_introduction",
            "text": " To enable gRPC add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.grpc&lt;/groupId&gt; &lt;artifactId&gt;helidon-grpc-server&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/grpc/01_introduction",
            "text": " Here is the code for a minimalist gRPC application that runs on a default port (1408): <markup lang=\"java\" > public static void main(String[] args) throws Exception { GrpcServer grpcServer = GrpcServer .create(GrpcRouting.builder() .register(new HelloService()) .build()) .start() .toCompletableFuture() .get(10, TimeUnit.SECONDS); // Implement the simplest possible gRPC service. System.out.println(\"gRPC Server started at: http://localhost:\" + grpcServer.port()); } static class HelloService implements GrpcService { @Override public void update(ServiceDescriptor.Rules rules) { rules.unary(\"SayHello\", ((request, responseObserver) -&gt; complete(responseObserver, \"Hello \" + request))); } } Register gRPC service. Start the server. Wait for the server to start while throwing possible errors as exceptions. The server is bound to a default port (1408). Implement the simplest possible gRPC service. Add unary method HelloService/SayHello to the service definition. The example above deploys a very simple service to the gRPC server that by default uses Java serialization to marshall requests and responses. We will look into deployment of \"standard\" gRPC services that use Protobuf for request and response marshalling, as well as how you can configure custom marshallers, later in this document. ",
            "title": "Quick Start"
        },
        {
            "location": "/se/webserver/06_static-content-support",
            "text": " To enable Static Content Support add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webserver&lt;/groupId&gt; &lt;artifactId&gt;helidon-webserver-static-content&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/webserver/06_static-content-support",
            "text": " To register static content based on a file system ( /pictures ), and classpath ( / ): <markup lang=\"java\" >Routing.builder() .register(\"/pictures\", StaticContentSupport.create(Paths.get(\"/some/WEB/pics\"))) .register(\"/\", StaticContentSupport.builder(\"/static-content\") .welcomeFileName(\"index.html\") .build()); Create a new StaticContentSupport object to serve data from the file system, and associate it with the \"/pictures\" context path. Create a StaticContentSupport object to serve resources from the contextual ClassLoader . The specific classloader can be also defined. A builder lets you provide more configuration values. index.html is the file that is returned if a directory is requested. A StaticContentSupport object can be created using create(&#8230;&#8203;) factory methods or a builder . The builder lets you provide more configuration values, including welcome file-name and mappings of filename extensions to media types. ",
            "title": "Registering Static Content"
        },
        {
            "location": "/se/webserver/06_static-content-support",
            "text": " Use the io.helidon.webserver.staticcontent.StaticContentSupport class to serve files and classpath resources. StaticContentSupport can be created for any readable directory or classpath context root and registered on a path in Routing . You can combine dynamic handlers with StaticContentSupport objects: if no file matches the request path, then the request is forwarded to the next handler. Registering Static Content To register static content based on a file system ( /pictures ), and classpath ( / ): <markup lang=\"java\" >Routing.builder() .register(\"/pictures\", StaticContentSupport.create(Paths.get(\"/some/WEB/pics\"))) .register(\"/\", StaticContentSupport.builder(\"/static-content\") .welcomeFileName(\"index.html\") .build()); Create a new StaticContentSupport object to serve data from the file system, and associate it with the \"/pictures\" context path. Create a StaticContentSupport object to serve resources from the contextual ClassLoader . The specific classloader can be also defined. A builder lets you provide more configuration values. index.html is the file that is returned if a directory is requested. A StaticContentSupport object can be created using create(&#8230;&#8203;) factory methods or a builder . The builder lets you provide more configuration values, including welcome file-name and mappings of filename extensions to media types. ",
            "title": "Static Content Support"
        },
        {
            "location": "/se/faulttolerance/01_faulttolerance",
            "text": " To enable Fault Tolerance add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.fault-tolerance&lt;/groupId&gt; &lt;artifactId&gt;helidon-fault-tolerance&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/faulttolerance/01_faulttolerance",
            "text": " In order to use Fault Tolerance you first need to add the maven dependency to your pom.xml . ",
            "title": "Updating your POM"
        },
        {
            "location": "/se/faulttolerance/01_faulttolerance",
            "text": " In what follows we shall assume the reader is familiar with the two core Helidon types Single&lt;T&gt; and Multi&lt;T&gt; from the io.helidon.common.reactive package. Most simply, a Single&lt;T&gt; is a promise to produce zero or one value of type T or signal an error; while a Multi&lt;T&gt; is a promise to produce zero or more values of type T or signal an error. More generally, these two types can be regarded as producers of zero or more values of type T . Note also that Single&lt;T&gt; , like CompletableFuture&lt;T&gt; , extends CompletionStage&lt;T&gt; so conversion among these types is straightforward. We shall use all these types in connection with Fault Tolerance handlers in the next few sections. ",
            "title": "Single&lt;T&gt; and Multi&lt;T&gt;"
        },
        {
            "location": "/se/faulttolerance/01_faulttolerance",
            "text": " Asynchronous tasks can be created or forked by using an Async instance. A supplier of type T is provided as the argument when invoking this handler. For example: <markup lang=\"java\" >Single&lt;Thread&gt; s = Async.create().invoke(() -&gt; Thread.currentThread())); s.thenAccept(t -&gt; System.out.println(\"Async task executed in thread \" + t)); The supplier () &#8594; Thread.currentThread() is executed in a new thread and the value it produces printed by the consumer and passed to thenAccept . The method reference Thread::currentThread is a simplified way of providing a supplier in the example above. Asynchronous tasks are executed in a thread pool managed by the Helidon SE Fault Tolerance module. Thread pools are created during the initialization phase of class io.helidon.faulttolerance.FaultTolerance and can be configured for your application. ",
            "title": "Asynchronous"
        },
        {
            "location": "/se/faulttolerance/01_faulttolerance",
            "text": " Temporal networking problems can sometimes be mitigated by simply retrying a certain task. A Retry handler is created using a RetryPolicy that indicates the number of retries, delay between retries, etc. <markup lang=\"java\" >Retry retry = Retry.builder() .retryPolicy(Retry.JitterRetryPolicy.builder() .calls(3) .delay(Duration.ofMillis(100)) .build()) .build(); retry.invoke(this::retryOnFailure); The sample code above will retry calls to the supplier this::retryOnFailure for up to 3 times with a 100 millisecond delay between them. The return type of method retryOnFailure in the example above must be CompletionStage&lt;T&gt; and the parameter to the retry handler&#8217;s invoke method Supplier&lt;? extends CompletionStage&lt;T&gt;&gt; . If the CompletionStage&lt;T&gt; returned by the method completes exceptionally, the call will be treated as a failure and retried until the maximum number of attempts is reached; finer control is possible by creating a retry policy and using methods such as applyOn(Class&lt;? extends Throwable&gt;&#8230;&#8203; classes) and skipOn(Class&lt;? extends Throwable&gt;&#8230;&#8203; classes) to control those exceptions on which to act and those that can be ignored. ",
            "title": "Retries"
        },
        {
            "location": "/se/faulttolerance/01_faulttolerance",
            "text": " A request to a service that is inaccessible or simply unavailable should be bounded to ensure a certain quality of service and response time. Timeouts can be configured to avoid excessive waiting times. In addition, a fallback action can be defined if a timeout expires as we shall cover in the next section. The following is an example of using Timeout : <markup lang=\"java\" >Single&lt;T&gt; s = Timeout.create(Duration.ofMillis(10)).invoke(this::mayTakeVeryLong); s.handle((t, e) -&gt; { if (e instanceof TimeoutException) { // Invocation has timed out! } ... }); The example above monitors the call to method mayTakeVeryLong and reports a TimeoutException if the execution takes more than 10 milliseconds to complete. ",
            "title": "Timeouts"
        },
        {
            "location": "/se/faulttolerance/01_faulttolerance",
            "text": " A fallback to a known result can sometimes be an alternative to reporting an error. For example, if we are unable to access a service we may fall back to the last result obtained from that service. A Fallback instance is created by providing a function that takes a Throwable and produces a CompletionStage&lt;T&gt; as shown next: <markup lang=\"java\" >Single&lt;T&gt; single = Fallback.create( throwable -&gt; Single.just(lastKnownValue).invoke(this::mayFail); single.thenAccept(t -&gt; ...); In this example, we register a function that can produce a Single&lt;T&gt; (which implements CompletionStage&lt;T&gt; ) if the call to this::mayFail completes exceptionally. ",
            "title": "Fallbacks"
        },
        {
            "location": "/se/faulttolerance/01_faulttolerance",
            "text": " Failing to execute a certain task or call another service repeatedly can have a direct impact on application performance. It is often preferred to avoid calls to non-essential services by simply preventing that logic to execute altogether. A circuit breaker can be configured to monitor such calls and block attempts that are likely to fail, thus improving overall performance. Circuit breakers start in a closed state, letting calls to proceed normally; after detecting a certain number of errors during a pre-defined processing window, they can open to prevent additional failures. After a circuit has been opened, it can transition first to a half-open state before finally transitioning back to a closed state. The use of an intermediate state (half-open) makes transitions from open to close more progressive, and prevents a circuit breaker from eagerly transitioning to states without considering \"sufficient\" observations. Any failure while a circuit breaker is in half-open state will immediately cause it to transition back to an open state. Consider the following example in which this::mayFail is monitored by a circuit breaker: <markup lang=\"java\" >CircuitBreaker breaker = CircuitBreaker.builder() .volume(10) .errorRatio(30) .delay(Duration.ofMillis(200)) .successThreshold(2) .build(); Single&lt;T&gt; result = breaker.invoke(this::mayFail); The circuit breaker in this example defines a processing window of size 10, an error ratio of 30%, a duration to transition to half-open state of 200 milliseconds, and a success threshold to transition from half-open to closed state of 2 observations. It follows that, After completing the processing window, if at least 3 errors were detected, the circuit breaker will transition to the open state, thus blocking the execution of any subsequent calls. After 200 millis, the circuit breaker will transition back to half-open and enable calls to proceed again. If the next two calls after transitioning to half-open are successful, the circuit breaker will transition to closed state; otherwise, it will transition back to open state, waiting for another 200 milliseconds before attempting to transition to half-open again. A circuit breaker will throw a io.helidon.faulttolerance.CircuitBreakerOpenException if an attempt to make an invocation takes place while it is in open state. ",
            "title": "Circuit Breakers"
        },
        {
            "location": "/se/faulttolerance/01_faulttolerance",
            "text": " Concurrent access to certain components may need to be limited to avoid excessive use of resources. For example, if an invocation that opens a network connection is allowed to execute concurrently without any restriction, and if the service on the other end is slow responding, it is possible for the rate at which network connections are opened to exceed the maximum number of connections allowed. Faults of this type can be prevented by guarding these invocations using a bulkhead. The origin of the name bulkhead comes from the partitions that comprise a ship&#8217;s hull. If some partition is somehow compromised (e.g., filled with water) it can be isolated in a manner not to affect the rest of the hull. A waiting queue can be associated with a bulkhead to handle tasks that are submitted when the bulkhead is already at full capacity. <markup lang=\"java\" >Bulkhead bulkhead = Bulkhead.builder() .limit(3) .queueLength(5) .build(); Single&lt;T&gt; single = bulkhead.invoke(this::usesResources); This example creates a bulkhead that limits concurrent execution to this:usesResources to at most 3, and with a queue of size 5. The bulkhead will report a io.helidon.faulttolerance.BulkheadException if unable to proceed with the call: either due to the limit being reached or the queue being at maximum capacity. ",
            "title": "Bulkheads"
        },
        {
            "location": "/se/faulttolerance/01_faulttolerance",
            "text": " Method invocations can be guarded by any combination of the handlers presented above. For example, an invocation that times out can be retried a few times before resorting to a fallback value &mdash;assuming it never succeeds. The easiest way to achieve handler composition is by using a builder in the FaultTolerance class as shown in the following example: <markup lang=\"java\" >FaultTolerance.TypedBuilder&lt;T&gt; builder = FaultTolerance.typedBuilder(); // Create and add timeout Timeout timeout = Timeout.create(Duration.ofMillis(10)); builder.addTimeout(timeout); // Create and add retry Retry retry = Retry.builder() .retryPolicy(Retry.JitterRetryPolicy.builder() .calls(3) .delay(Duration.ofMillis(100)) .build()) .build(); builder.addRetry(retry); // Create and add fallback Fallback fallback = Fallback.create(throwable -&gt; Single.just(lastKnownValue)); builder.addFallback(fallback); // Finally call the method Single&lt;T&gt; single = builder.build().invoke(this::mayTakeVeryLong); The exact order in which handlers are added to a builder depends on the use case, but generally the order starting from innermost to outermost should be: bulkhead, timeout, circuit breaker, retry and fallback. That is, fallback is the first handler in the chain (the last to executed once a value is returned) and bulkhead is the last one (the first to be executed once a value is returned). This is the ordering used by the MicroProfile Fault Tolerance implementation in Helidon when a method is decorated with multiple annotations. ",
            "title": "Handler Composition"
        },
        {
            "location": "/se/faulttolerance/01_faulttolerance",
            "text": " All the examples presented so far have focused on invocations returning a single value of type Single&lt;T&gt; . If the invocation in question can return more than one value (i.e., a Multi&lt;T&gt; ) then all that is needed is to use the method invokeMulti instead of invoke . The supplier passed to this method must return a Flow.Publisher&lt;T&gt; instead of a CompletionStage&lt;T&gt; . A Flow.Publisher&lt;T&gt; is a generalization of a Single&lt;T&gt; that can produce zero or more values. Note that a Flow.Publisher&lt;T&gt; , unlike a Single&lt;T&gt; , can report an error after producing one or more values, introducing additional challenges if all values must be processed transactionally, that is, in an all or nothing manner. The following example creates an instance of Retry and invokes the invokeMulti method, it then registers a subscriber to process the results: <markup lang=\"java\" >Retry retry = Retry.builder() .retryPolicy(Retry.JitterRetryPolicy.builder() .calls(2) .build()) .build(); Multi&lt;Integer&gt; multi = retry.invokeMulti(() -&gt; Multi.just(0, 1, 2)); IntSubscriber ts = new IntSubscriber(); multi.subscribe(ts); ts.request(Integer.MAX_VALUE); The call to Multi.just(0, 1, 2) simply returns a multi that produces the integers 0, 1 and 2. If an error was generated during this process, the policy will retry the call one more time &mdash;for a total of 2 calls. ",
            "title": "Revisiting Multi&#8217;s"
        },
        {
            "location": "/se/faulttolerance/01_faulttolerance",
            "text": " Helidon SE Fault Tolerance support is inspired by MicroProfile Fault Tolerance . The API defines the notion of a fault handler that can be combined with other handlers to improve application robustness. Handlers are created to manage error conditions (faults) that may occur in real-world application environments. Examples include service restarts, network delays, temporal infrastructure instabilities, etc. The interaction of multiple microservices bring some new challenges from distributed systems that require careful planning. Faults in distributed systems should be compartmentalized to avoid unnecessary service interruptions. For example, if comparable information can be obtained from multiples sources, a user request should not be denied when a subset of these sources is unreachable or offline. Similarly, if a non-essential source has been flagged as unreachable, an application should avoid continuous access to that source as that would result in much higher response times. In order to combat the most common types of application faults, the Helidon SE Fault Tolerance API provides support for circuit breakers, retries, timeouts, bulkheads and fallbacks. In addition, the API makes it very easy to create and monitor asynchronous tasks that do not require explicit creation and management of threads/executors. For more information the reader is referred to the Fault Toleance SE API Javadocs . Updating your POM In order to use Fault Tolerance you first need to add the maven dependency to your pom.xml . Single&lt;T&gt; and Multi&lt;T&gt; In what follows we shall assume the reader is familiar with the two core Helidon types Single&lt;T&gt; and Multi&lt;T&gt; from the io.helidon.common.reactive package. Most simply, a Single&lt;T&gt; is a promise to produce zero or one value of type T or signal an error; while a Multi&lt;T&gt; is a promise to produce zero or more values of type T or signal an error. More generally, these two types can be regarded as producers of zero or more values of type T . Note also that Single&lt;T&gt; , like CompletableFuture&lt;T&gt; , extends CompletionStage&lt;T&gt; so conversion among these types is straightforward. We shall use all these types in connection with Fault Tolerance handlers in the next few sections. Asynchronous Asynchronous tasks can be created or forked by using an Async instance. A supplier of type T is provided as the argument when invoking this handler. For example: <markup lang=\"java\" >Single&lt;Thread&gt; s = Async.create().invoke(() -&gt; Thread.currentThread())); s.thenAccept(t -&gt; System.out.println(\"Async task executed in thread \" + t)); The supplier () &#8594; Thread.currentThread() is executed in a new thread and the value it produces printed by the consumer and passed to thenAccept . The method reference Thread::currentThread is a simplified way of providing a supplier in the example above. Asynchronous tasks are executed in a thread pool managed by the Helidon SE Fault Tolerance module. Thread pools are created during the initialization phase of class io.helidon.faulttolerance.FaultTolerance and can be configured for your application. Retries Temporal networking problems can sometimes be mitigated by simply retrying a certain task. A Retry handler is created using a RetryPolicy that indicates the number of retries, delay between retries, etc. <markup lang=\"java\" >Retry retry = Retry.builder() .retryPolicy(Retry.JitterRetryPolicy.builder() .calls(3) .delay(Duration.ofMillis(100)) .build()) .build(); retry.invoke(this::retryOnFailure); The sample code above will retry calls to the supplier this::retryOnFailure for up to 3 times with a 100 millisecond delay between them. The return type of method retryOnFailure in the example above must be CompletionStage&lt;T&gt; and the parameter to the retry handler&#8217;s invoke method Supplier&lt;? extends CompletionStage&lt;T&gt;&gt; . If the CompletionStage&lt;T&gt; returned by the method completes exceptionally, the call will be treated as a failure and retried until the maximum number of attempts is reached; finer control is possible by creating a retry policy and using methods such as applyOn(Class&lt;? extends Throwable&gt;&#8230;&#8203; classes) and skipOn(Class&lt;? extends Throwable&gt;&#8230;&#8203; classes) to control those exceptions on which to act and those that can be ignored. Timeouts A request to a service that is inaccessible or simply unavailable should be bounded to ensure a certain quality of service and response time. Timeouts can be configured to avoid excessive waiting times. In addition, a fallback action can be defined if a timeout expires as we shall cover in the next section. The following is an example of using Timeout : <markup lang=\"java\" >Single&lt;T&gt; s = Timeout.create(Duration.ofMillis(10)).invoke(this::mayTakeVeryLong); s.handle((t, e) -&gt; { if (e instanceof TimeoutException) { // Invocation has timed out! } ... }); The example above monitors the call to method mayTakeVeryLong and reports a TimeoutException if the execution takes more than 10 milliseconds to complete. Fallbacks A fallback to a known result can sometimes be an alternative to reporting an error. For example, if we are unable to access a service we may fall back to the last result obtained from that service. A Fallback instance is created by providing a function that takes a Throwable and produces a CompletionStage&lt;T&gt; as shown next: <markup lang=\"java\" >Single&lt;T&gt; single = Fallback.create( throwable -&gt; Single.just(lastKnownValue).invoke(this::mayFail); single.thenAccept(t -&gt; ...); In this example, we register a function that can produce a Single&lt;T&gt; (which implements CompletionStage&lt;T&gt; ) if the call to this::mayFail completes exceptionally. Circuit Breakers Failing to execute a certain task or call another service repeatedly can have a direct impact on application performance. It is often preferred to avoid calls to non-essential services by simply preventing that logic to execute altogether. A circuit breaker can be configured to monitor such calls and block attempts that are likely to fail, thus improving overall performance. Circuit breakers start in a closed state, letting calls to proceed normally; after detecting a certain number of errors during a pre-defined processing window, they can open to prevent additional failures. After a circuit has been opened, it can transition first to a half-open state before finally transitioning back to a closed state. The use of an intermediate state (half-open) makes transitions from open to close more progressive, and prevents a circuit breaker from eagerly transitioning to states without considering \"sufficient\" observations. Any failure while a circuit breaker is in half-open state will immediately cause it to transition back to an open state. Consider the following example in which this::mayFail is monitored by a circuit breaker: <markup lang=\"java\" >CircuitBreaker breaker = CircuitBreaker.builder() .volume(10) .errorRatio(30) .delay(Duration.ofMillis(200)) .successThreshold(2) .build(); Single&lt;T&gt; result = breaker.invoke(this::mayFail); The circuit breaker in this example defines a processing window of size 10, an error ratio of 30%, a duration to transition to half-open state of 200 milliseconds, and a success threshold to transition from half-open to closed state of 2 observations. It follows that, After completing the processing window, if at least 3 errors were detected, the circuit breaker will transition to the open state, thus blocking the execution of any subsequent calls. After 200 millis, the circuit breaker will transition back to half-open and enable calls to proceed again. If the next two calls after transitioning to half-open are successful, the circuit breaker will transition to closed state; otherwise, it will transition back to open state, waiting for another 200 milliseconds before attempting to transition to half-open again. A circuit breaker will throw a io.helidon.faulttolerance.CircuitBreakerOpenException if an attempt to make an invocation takes place while it is in open state. Bulkheads Concurrent access to certain components may need to be limited to avoid excessive use of resources. For example, if an invocation that opens a network connection is allowed to execute concurrently without any restriction, and if the service on the other end is slow responding, it is possible for the rate at which network connections are opened to exceed the maximum number of connections allowed. Faults of this type can be prevented by guarding these invocations using a bulkhead. The origin of the name bulkhead comes from the partitions that comprise a ship&#8217;s hull. If some partition is somehow compromised (e.g., filled with water) it can be isolated in a manner not to affect the rest of the hull. A waiting queue can be associated with a bulkhead to handle tasks that are submitted when the bulkhead is already at full capacity. <markup lang=\"java\" >Bulkhead bulkhead = Bulkhead.builder() .limit(3) .queueLength(5) .build(); Single&lt;T&gt; single = bulkhead.invoke(this::usesResources); This example creates a bulkhead that limits concurrent execution to this:usesResources to at most 3, and with a queue of size 5. The bulkhead will report a io.helidon.faulttolerance.BulkheadException if unable to proceed with the call: either due to the limit being reached or the queue being at maximum capacity. Handler Composition Method invocations can be guarded by any combination of the handlers presented above. For example, an invocation that times out can be retried a few times before resorting to a fallback value &mdash;assuming it never succeeds. The easiest way to achieve handler composition is by using a builder in the FaultTolerance class as shown in the following example: <markup lang=\"java\" >FaultTolerance.TypedBuilder&lt;T&gt; builder = FaultTolerance.typedBuilder(); // Create and add timeout Timeout timeout = Timeout.create(Duration.ofMillis(10)); builder.addTimeout(timeout); // Create and add retry Retry retry = Retry.builder() .retryPolicy(Retry.JitterRetryPolicy.builder() .calls(3) .delay(Duration.ofMillis(100)) .build()) .build(); builder.addRetry(retry); // Create and add fallback Fallback fallback = Fallback.create(throwable -&gt; Single.just(lastKnownValue)); builder.addFallback(fallback); // Finally call the method Single&lt;T&gt; single = builder.build().invoke(this::mayTakeVeryLong); The exact order in which handlers are added to a builder depends on the use case, but generally the order starting from innermost to outermost should be: bulkhead, timeout, circuit breaker, retry and fallback. That is, fallback is the first handler in the chain (the last to executed once a value is returned) and bulkhead is the last one (the first to be executed once a value is returned). This is the ordering used by the MicroProfile Fault Tolerance implementation in Helidon when a method is decorated with multiple annotations. Revisiting Multi&#8217;s All the examples presented so far have focused on invocations returning a single value of type Single&lt;T&gt; . If the invocation in question can return more than one value (i.e., a Multi&lt;T&gt; ) then all that is needed is to use the method invokeMulti instead of invoke . The supplier passed to this method must return a Flow.Publisher&lt;T&gt; instead of a CompletionStage&lt;T&gt; . A Flow.Publisher&lt;T&gt; is a generalization of a Single&lt;T&gt; that can produce zero or more values. Note that a Flow.Publisher&lt;T&gt; , unlike a Single&lt;T&gt; , can report an error after producing one or more values, introducing additional challenges if all values must be processed transactionally, that is, in an all or nothing manner. The following example creates an instance of Retry and invokes the invokeMulti method, it then registers a subscriber to process the results: <markup lang=\"java\" >Retry retry = Retry.builder() .retryPolicy(Retry.JitterRetryPolicy.builder() .calls(2) .build()) .build(); Multi&lt;Integer&gt; multi = retry.invokeMulti(() -&gt; Multi.just(0, 1, 2)); IntSubscriber ts = new IntSubscriber(); multi.subscribe(ts); ts.request(Integer.MAX_VALUE); The call to Multi.just(0, 1, 2) simply returns a multi that produces the integers 0, 1 and 2. If an error was generated during this process, the policy will retry the call one more time &mdash;for a total of 2 calls. ",
            "title": "Introduction"
        },
        {
            "location": "/se/metrics/04_prometheus_exemplar_support",
            "text": " Add Helidon SE support for OpenMetrics (Prometheus) exemplars for histograms, counters, and simple timers to your application simply by adding dependencies to your project&#8217;s pom.xml . ",
            "title": "preambule"
        },
        {
            "location": "/se/metrics/04_prometheus_exemplar_support",
            "text": " Declare the following dependency in your project: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics-trace-exemplar&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; Also, include either Helidon Zipkin or Helidon Jaeger support: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-zipkin&lt;/artifactId&gt; &lt;/dependency&gt; or <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-jaeger&lt;/artifactId&gt; &lt;/dependency&gt; Be sure Zipkin or Jaeger, whichever you chose, is running and accessible to your server. ",
            "title": "Prerequisites"
        },
        {
            "location": "/se/metrics/04_prometheus_exemplar_support",
            "text": " Note exemplar - one that serves as a model or example &#8201;&#8212;&#8201;Merriam-Webster Dictionary When you add the helidon-metrics-trace-exemplar dependency&#8212;&#8203;and one for either Zipkin or Jaeger&#8212;&#8203;to your application, Helidon automatically records a sample (label, value, and timestamp) with each update to a histogram, simple timer, or counter. Helidon adds the label, value, and timestamp to the OpenMetrics output returned from the Helidon metrics endpoint ( /metrics unless you set it up otherwise). # TYPE application_getTimer_mean_seconds gauge application_getTimer_mean_seconds 8.303030623354298E-4 # {trace_id=\"067632454fe4e8d1\"} 1.14701E-4 1617723032.570000 # TYPE application_getTimer_max_seconds gauge application_getTimer_max_seconds 0.003952636 # {trace_id=\"fce183094e471633\"} 0.003952636 1617723030.108000 # TYPE application_getTimer_min_seconds gauge application_getTimer_min_seconds 5.5254E-5 # {trace_id=\"0b1a4bf22b4e47fd\"} 5.5254E-5 1617723033.311000 This exemplar is a sample with value at least as close to the mean as any other sample. This exemplar is for an exact sample with value the same as the maximum value the timer has observed. # TYPE application_globalRequestTracker_total counter # HELP application_globalRequestTracker_total application_globalRequestTracker_total 4 # {trace_id=\"daf26fe35fee9917\"} 0.001183992 1617725180.234000 # TYPE application_globalRequestTracker_elapsedTime_seconds gauge application_globalRequestTracker_elapsedTime_seconds 0.030309068 # {trace_id=\"daf26fe35fee9917\"} 0.001183992 1617725180.234000 The exemplar for a SimpleTimer is the same for the total and the elapsedTime submetrics: always the most recent sample which updated the SimpleTimer . Helidon adds an exemplar to the output for each statistical value&#8212;&#8203;such as minimum, maximum, mean, and quantiles&#8212;&#8203;for histograms, timers, simple times, and for counters. The exemplar information describes a single, actual sample that is representative of the statistical value. Helidon chooses the representative examplar for each value using information that is already recorded for each type of metric: If a metric necessarily corresponds to a specific sample&#8212;&#8203;for example a minimum or maximum&#8212;&#8203;Helidon associates a sample that has that exact value as the exemplar for the metric. If a metric collects samples into bins (quantiles), Helidon associates a sample from that bin with the bin&#8217;s output. If a metric maintains running statistics (counts, totals), Helidon associates the most recent sample for that metric. If Helidon computes a metric&#8217;s value from a number of samples&#8212;&#8203;for example, mean&#8212;&#8203;Helidon associates a sample for which its value is at least as close as other samples to the statistical calculation. In cases with multiple representative samples (for example, two samples' values are equally close to the mean), Helidon chooses one of them arbitrarily. ",
            "title": "Interpreting Exemplars"
        },
        {
            "location": "/mp/extensions/02_cdi_datasource-hikaricp",
            "text": " This CDI portable extension provides support for injecting HikariCP data sources in your Helidon MicroProfile applications. ",
            "title": "preambule"
        },
        {
            "location": "/mp/extensions/02_cdi_datasource-hikaricp",
            "text": " To enable HikariCP Support add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.cdi&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-cdi-datasource-hikaricp&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/extensions/02_cdi_datasource-hikaricp",
            "text": " The following examples show how to create a DataSource named orders in your application. <markup lang=\"java\" title=\"Field-injection example\" > @Inject @Named(\"orders\") private DataSource ordersDataSource; <markup lang=\"java\" title=\"Constructor-injection example\" > private final DataSource ds; @Inject public YourConstructor(@Named(\"orders\") DataSource ds) { super(); this.ds = ds; } The extension implements this injection point by creating a HikariDataSource object in the application scope . You can configure the object using MicroProfile config . For example, the data source created above can be configured as follows: <markup lang=\"properties\" title=\"META-INF/microprofile-config.properties\" >javax.sql.DataSource.orders.dataSourceClassName=oracle.jdbc.pool.OracleDataSource javax.sql.DataSource.orders.dataSource.url = jdbc:oracle:thin:@localhost:1521:ORCL javax.sql.DataSource.orders.dataSource.user = sys as sysoper javax.sql.DataSource.orders.dataSource.password = Oracle Property names that start with javax.sql.DataSource.dataSourceName. are parsed, and the remaining portion of each name is treated as a Hikari connection pool property . ",
            "title": "Injecting a HikariCP data source"
        },
        {
            "location": "/mp/reactivemessaging/06_aq",
            "text": " To enable AQ Connector add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.messaging.aq&lt;/groupId&gt; &lt;artifactId&gt;helidon-messaging-aq&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/reactivemessaging/06_aq",
            "text": " Connector name: helidon-aq Attributes datasource name of the datasource bean used to connect Oracle DB with AQ url jdbc connection string used to connect Oracle DB with AQ (forbidden when datasource is specified) username User name used to connect Oracle DB with AQ (forbidden when datasource is specified) password Password to connect Oracle DB with AQ (forbidden when datasource is specified) type Possible values are: queue , topic destination Queue or topic name acknowledge-mode Possible values are: AUTO_ACKNOWLEDGE - session automatically acknowledges a client’s receipt of a message, CLIENT_ACKNOWLEDGE - receipt of a message is acknowledged only when Message.ack() is called manually, DUPS_OK_ACKNOWLEDGE - session lazily acknowledges the delivery of messages. Default value: AUTO_ACKNOWLEDGE transacted Indicates whether the session will use a local transaction. Default value: false message-selector JMS API message selector expression based on a subset of the SQL92. Expression can only access headers and properties, not the payload. client-id Client identifier for JMS connection. durable True for creating durable consumer (only for topic). Default value: false subscriber-name Subscriber name for durable consumer used to identify subscription. non-local If true then any messages published to the topic using this session&#8217;s connection, or any other connection with the same client identifier, will not be added to the durable subscription. Default value: false named-factory Select in case factory is injected as a named bean or configured with name. poll-timeout Timeout for polling for next message in every poll cycle in millis. Default value: 50 period-executions Period for executing poll cycles in millis. Default value: 100 session-group-id When multiple channels share same session-group-id , they share same JMS session and same JDBC connection as well. ",
            "title": "Config"
        },
        {
            "location": "/mp/reactivemessaging/06_aq",
            "text": " The simplest possible usage is leaving construction of AQjmsConnectionFactory to the connector. <markup lang=\"yaml\" title=\"Example of connector config:\" >mp: messaging: connector: helidon-aq: transacted: false acknowledge-mode: CLIENT_ACKNOWLEDGE url: jdbc:oracle:thin:@(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(Host=192.168.0.123)(Port=1521))(CONNECT_DATA=(SID=TESTSID))) user: gandalf password: mellon outgoing.to-aq: connector: helidon-aq destination: TESTQUEUE type: queue incoming.from-aq: connector: helidon-aq destination: TESTQUEUE type: queue Its also possible and preferable to refer to configured datasource , in our example Oracle UCP datasource : <markup lang=\"yaml\" title=\"Example of connector config with Oracle UCP datasource:\" >javax: sql: DataSource: aq-test-ds: connectionFactoryClassName: oracle.jdbc.pool.OracleDataSource URL: jdbc:oracle:thin:@exampledb_high?TNS_ADMIN=/home/gandalf/wallets/Wallet_EXAMPLEDB user: gandalf password: SuperSecretPassword1234 mp: messaging: connector: helidon-aq: transacted: false acknowledge-mode: CLIENT_ACKNOWLEDGE data-source: aq-test-ds outgoing.toJms: connector: helidon-aq destination: TESTQUEUE type: queue incoming.fromJms: connector: helidon-aq destination: TESTQUEUE type: queue ",
            "title": "Configured JMS factory"
        },
        {
            "location": "/mp/reactivemessaging/06_aq",
            "text": " In case you need more advanced setup, connector can work with injected AQjmsConnectionFactory <markup lang=\"java\" title=\"Inject:\" > @Produces @ApplicationScoped @Named(\"aq-orderdb-factory\") public AQjmsConnectionFactory connectionFactory() throws JMSException { AQjmsQueueConnectionFactory fact = new AQjmsQueueConnectionFactory(); fact.setJdbcURL(config.get(\"jdbc.url\").asString().get()); fact.setUsername(config.get(\"jdbc.user\").asString().get()); fact.setPassword(config.get(\"jdbc.pass\").asString().get()); return fact; } <markup lang=\"yaml\" title=\"Config:\" >jdbc: url: jdbc:oracle:thin:@(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(Host=192.168.0.123)(Port=1521))(CONNECT_DATA=(SID=TESTSID))) user: gandalf pass: mellon mp: messaging: connector: helidon-aq: named-factory: aq-orderdb-factory outgoing.to-aq: connector: helidon-aq session-group-id: order-connection-1 destination: TESTQUEUE type: queue incoming.from-aq: connector: helidon-aq session-group-id: order-connection-1 destination: TESTQUEUE type: queue ",
            "title": "Injected JMS factory"
        },
        {
            "location": "/mp/reactivemessaging/06_aq",
            "text": "<markup lang=\"java\" title=\"Consuming one by one unwrapped value:\" >@Incoming(\"from-aq\") public void consumeAq(String msg) { System.out.println(\"Oracle AQ says: \" + msg); } <markup lang=\"java\" title=\"Consuming one by one, manual ack:\" >@Incoming(\"from-aq\") @Acknowledgment(Acknowledgment.Strategy.MANUAL) public CompletionStage&lt;?&gt; consumeAq(AqMessage&lt;String&gt; msg) { // direct commit //msg.getDbConnection().commit(); System.out.println(\"Oracle AQ says: \" + msg.getPayload()); // ack commits only in non-transacted mode return msg.ack(); } ",
            "title": "Consuming"
        },
        {
            "location": "/mp/reactivemessaging/06_aq",
            "text": "<markup lang=\"java\" title=\"Producing to AQ:\" >@Outgoing(\"to-aq\") public PublisherBuilder&lt;String&gt; produceToAq() { return ReactiveStreams.of(\"test1\", \"test2\"); } ",
            "title": "Producing"
        },
        {
            "location": "/mp/reactivemessaging/06_aq",
            "text": " Connecting streams to Oracle AQ with Reactive Messaging couldn&#8217;t be easier. This connector extends Helidon&#8217;s JMS connector with Oracle AQ&#8217;s specific API. Config Connector name: helidon-aq Attributes datasource name of the datasource bean used to connect Oracle DB with AQ url jdbc connection string used to connect Oracle DB with AQ (forbidden when datasource is specified) username User name used to connect Oracle DB with AQ (forbidden when datasource is specified) password Password to connect Oracle DB with AQ (forbidden when datasource is specified) type Possible values are: queue , topic destination Queue or topic name acknowledge-mode Possible values are: AUTO_ACKNOWLEDGE - session automatically acknowledges a client’s receipt of a message, CLIENT_ACKNOWLEDGE - receipt of a message is acknowledged only when Message.ack() is called manually, DUPS_OK_ACKNOWLEDGE - session lazily acknowledges the delivery of messages. Default value: AUTO_ACKNOWLEDGE transacted Indicates whether the session will use a local transaction. Default value: false message-selector JMS API message selector expression based on a subset of the SQL92. Expression can only access headers and properties, not the payload. client-id Client identifier for JMS connection. durable True for creating durable consumer (only for topic). Default value: false subscriber-name Subscriber name for durable consumer used to identify subscription. non-local If true then any messages published to the topic using this session&#8217;s connection, or any other connection with the same client identifier, will not be added to the durable subscription. Default value: false named-factory Select in case factory is injected as a named bean or configured with name. poll-timeout Timeout for polling for next message in every poll cycle in millis. Default value: 50 period-executions Period for executing poll cycles in millis. Default value: 100 session-group-id When multiple channels share same session-group-id , they share same JMS session and same JDBC connection as well. Configured JMS factory The simplest possible usage is leaving construction of AQjmsConnectionFactory to the connector. <markup lang=\"yaml\" title=\"Example of connector config:\" >mp: messaging: connector: helidon-aq: transacted: false acknowledge-mode: CLIENT_ACKNOWLEDGE url: jdbc:oracle:thin:@(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(Host=192.168.0.123)(Port=1521))(CONNECT_DATA=(SID=TESTSID))) user: gandalf password: mellon outgoing.to-aq: connector: helidon-aq destination: TESTQUEUE type: queue incoming.from-aq: connector: helidon-aq destination: TESTQUEUE type: queue Its also possible and preferable to refer to configured datasource , in our example Oracle UCP datasource : <markup lang=\"yaml\" title=\"Example of connector config with Oracle UCP datasource:\" >javax: sql: DataSource: aq-test-ds: connectionFactoryClassName: oracle.jdbc.pool.OracleDataSource URL: jdbc:oracle:thin:@exampledb_high?TNS_ADMIN=/home/gandalf/wallets/Wallet_EXAMPLEDB user: gandalf password: SuperSecretPassword1234 mp: messaging: connector: helidon-aq: transacted: false acknowledge-mode: CLIENT_ACKNOWLEDGE data-source: aq-test-ds outgoing.toJms: connector: helidon-aq destination: TESTQUEUE type: queue incoming.fromJms: connector: helidon-aq destination: TESTQUEUE type: queue Injected JMS factory In case you need more advanced setup, connector can work with injected AQjmsConnectionFactory <markup lang=\"java\" title=\"Inject:\" > @Produces @ApplicationScoped @Named(\"aq-orderdb-factory\") public AQjmsConnectionFactory connectionFactory() throws JMSException { AQjmsQueueConnectionFactory fact = new AQjmsQueueConnectionFactory(); fact.setJdbcURL(config.get(\"jdbc.url\").asString().get()); fact.setUsername(config.get(\"jdbc.user\").asString().get()); fact.setPassword(config.get(\"jdbc.pass\").asString().get()); return fact; } <markup lang=\"yaml\" title=\"Config:\" >jdbc: url: jdbc:oracle:thin:@(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(Host=192.168.0.123)(Port=1521))(CONNECT_DATA=(SID=TESTSID))) user: gandalf pass: mellon mp: messaging: connector: helidon-aq: named-factory: aq-orderdb-factory outgoing.to-aq: connector: helidon-aq session-group-id: order-connection-1 destination: TESTQUEUE type: queue incoming.from-aq: connector: helidon-aq session-group-id: order-connection-1 destination: TESTQUEUE type: queue Consuming <markup lang=\"java\" title=\"Consuming one by one unwrapped value:\" >@Incoming(\"from-aq\") public void consumeAq(String msg) { System.out.println(\"Oracle AQ says: \" + msg); } <markup lang=\"java\" title=\"Consuming one by one, manual ack:\" >@Incoming(\"from-aq\") @Acknowledgment(Acknowledgment.Strategy.MANUAL) public CompletionStage&lt;?&gt; consumeAq(AqMessage&lt;String&gt; msg) { // direct commit //msg.getDbConnection().commit(); System.out.println(\"Oracle AQ says: \" + msg.getPayload()); // ack commits only in non-transacted mode return msg.ack(); } Producing <markup lang=\"java\" title=\"Producing to AQ:\" >@Outgoing(\"to-aq\") public PublisherBuilder&lt;String&gt; produceToAq() { return ReactiveStreams.of(\"test1\", \"test2\"); } ",
            "title": "Reactive Oracle Advanced Queueing Connector"
        },
        {
            "location": "/mp/metrics/02_micrometer",
            "text": " Helidon MP simplifies how you can use Micrometer for application-specific metrics: The endpoint /micrometer : A configurable endpoint that exposes metrics according to which Micrometer meter registry responds to the HTTP request. The Micrometer annotations @Timed and @Counted . Configuration to tailor the Prometheus and other Micrometer meter registries. In Helidon 2.5.4, Micrometer support is separate from the Helidon MP metrics API and the built-in Helidon metrics. ",
            "title": "preambule"
        },
        {
            "location": "/mp/metrics/02_micrometer",
            "text": " Declare the following dependency in your project: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.micrometer&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-micrometer-cdi&lt;/artifactId&gt; &lt;/dependency&gt; Micrometer supports different types of meter registries which have different output styles and formats. Helidon provides built-in support for the Prometheus meter registry. To use other meter registry types, you will need to add dependencies for them to your pom.xml and, optionally, add configuration to set them up as you wish. ",
            "title": "Prerequisites"
        },
        {
            "location": "/mp/metrics/02_micrometer",
            "text": "<markup lang=\"java\" title=\"Adding Micrometer annotations to JAX-RS resource GET methods\" >import io.micrometer.core.annotation.Counted; import io.micrometer.core.annotation.Timed; private static final String PERSONALIZED_GETS_COUNTER_NAME = \"personalizedGets\"; private static final String PERSONALIZED_GETS_COUNTER_DESCRIPTION = \"Counts personalized GET operations\"; private static final String GETS_TIMER_NAME = \"allGets\"; private static final String GETS_TIMER_DESCRIPTION = \"Tracks all GET operations\"; @GET @Produces(MediaType.APPLICATION_JSON) @Timed(value = GETS_TIMER_NAME, description = GETS_TIMER_DESCRIPTION, histogram = true) public JsonObject getDefaultMessage() { return createResponse(\"World\"); } @Path(\"/{name}\") @GET @Produces(MediaType.APPLICATION_JSON) @Counted(value = PERSONALIZED_GETS_COUNTER_NAME, description = PERSONALIZED_GETS_COUNTER_DESCRIPTION) @Timed(value = GETS_TIMER_NAME, description = GETS_TIMER_DESCRIPTION, histogram = true) public JsonObject getMessage(@PathParam(\"name\") String name) { return createResponse(name); } Declare constants used in annotating multiple methods. Use @Timed to time and count both GET methods. Use @Counted to count the accesses to the GET method that returns a personalized greeting. ",
            "title": "Add Micrometer annotations"
        },
        {
            "location": "/mp/metrics/02_micrometer",
            "text": " In addition to annotating your methods, you can create, look up, and update metrics explicitly in your code. Add the following injection to a bean: <markup lang=\"java\" title=\"Inject the MeterRegistry \" >@Inject private MeterRegistry registry; Helidon automatically injects a reference to the MeterRegistry it manages into your code. Your code can use the normal Micrometer API with this registry to create, find, update, and even delete meters. ",
            "title": "Using the Helidon-provided Micrometer MeterRegistry from Code"
        },
        {
            "location": "/mp/metrics/02_micrometer",
            "text": " Unless you specify otherwise, Helidon uses defaults for any built-in Micrometer meter registry. For example, Helidon configures the built-in Prometheus registry using PrometheusConfig.DEFAULT . To use configuration to control the selection and behavior of Helidon&#8217;s built-in Micrometer meter registries, include in your configuration (such as application.yaml ) a micrometer.builtin-registries section. <markup lang=\"yaml\" title=\"Enroll Prometheus built-in meter registry using default configuration\" >micrometer: builtin-registries: - type: prometheus <markup lang=\"yaml\" title=\"Enroll Prometheus built-in meter registry with non-default configuration\" >micrometer: builtin-registries: - type: prometheus prefix: myPrefix Note that the first config example is equivalent to the default Helidon Micrometer behavior; Helidon by default supports the Prometheus meter registry. The configuration keys that are valid for the builtin-registries child entries depend on the type of Micrometer meter registry. For example, the Prometheus meter registry supports the prefix configuration setting but other meter registries might not and might support other settings. Refer to the documentation for the meter registry you want to configure to find out what items apply to that registry type. Helidon does not validate the configuration keys you specify for meter registries. ",
            "title": "Overriding Defaults for Built-in Meter Registry Types"
        },
        {
            "location": "/mp/metrics/02_micrometer",
            "text": " Add the Micrometer @Timed and @Counted annotations to methods in your application. The examples below enhance the Helidon MP QuickStart application to track (by time and invocation count) all GET methods and to count all requests for a personalized greeting. Add Micrometer annotations <markup lang=\"java\" title=\"Adding Micrometer annotations to JAX-RS resource GET methods\" >import io.micrometer.core.annotation.Counted; import io.micrometer.core.annotation.Timed; private static final String PERSONALIZED_GETS_COUNTER_NAME = \"personalizedGets\"; private static final String PERSONALIZED_GETS_COUNTER_DESCRIPTION = \"Counts personalized GET operations\"; private static final String GETS_TIMER_NAME = \"allGets\"; private static final String GETS_TIMER_DESCRIPTION = \"Tracks all GET operations\"; @GET @Produces(MediaType.APPLICATION_JSON) @Timed(value = GETS_TIMER_NAME, description = GETS_TIMER_DESCRIPTION, histogram = true) public JsonObject getDefaultMessage() { return createResponse(\"World\"); } @Path(\"/{name}\") @GET @Produces(MediaType.APPLICATION_JSON) @Counted(value = PERSONALIZED_GETS_COUNTER_NAME, description = PERSONALIZED_GETS_COUNTER_DESCRIPTION) @Timed(value = GETS_TIMER_NAME, description = GETS_TIMER_DESCRIPTION, histogram = true) public JsonObject getMessage(@PathParam(\"name\") String name) { return createResponse(name); } Declare constants used in annotating multiple methods. Use @Timed to time and count both GET methods. Use @Counted to count the accesses to the GET method that returns a personalized greeting. Using the Helidon-provided Micrometer MeterRegistry from Code In addition to annotating your methods, you can create, look up, and update metrics explicitly in your code. Add the following injection to a bean: <markup lang=\"java\" title=\"Inject the MeterRegistry \" >@Inject private MeterRegistry registry; Helidon automatically injects a reference to the MeterRegistry it manages into your code. Your code can use the normal Micrometer API with this registry to create, find, update, and even delete meters. Overriding Defaults for Built-in Meter Registry Types Unless you specify otherwise, Helidon uses defaults for any built-in Micrometer meter registry. For example, Helidon configures the built-in Prometheus registry using PrometheusConfig.DEFAULT . To use configuration to control the selection and behavior of Helidon&#8217;s built-in Micrometer meter registries, include in your configuration (such as application.yaml ) a micrometer.builtin-registries section. <markup lang=\"yaml\" title=\"Enroll Prometheus built-in meter registry using default configuration\" >micrometer: builtin-registries: - type: prometheus <markup lang=\"yaml\" title=\"Enroll Prometheus built-in meter registry with non-default configuration\" >micrometer: builtin-registries: - type: prometheus prefix: myPrefix Note that the first config example is equivalent to the default Helidon Micrometer behavior; Helidon by default supports the Prometheus meter registry. The configuration keys that are valid for the builtin-registries child entries depend on the type of Micrometer meter registry. For example, the Prometheus meter registry supports the prefix configuration setting but other meter registries might not and might support other settings. Refer to the documentation for the meter registry you want to configure to find out what items apply to that registry type. Helidon does not validate the configuration keys you specify for meter registries. ",
            "title": "Using Micrometer in Your Application"
        },
        {
            "location": "/mp/metrics/02_micrometer",
            "text": " By default, Helidon Micrometer integration exposes the /micrometer endpoint. You can override this using the micrometer.web-context configuration key. Within Helidon, each type of meter registry is paired with code that examines the incoming HTTP request and decides whether the request matches up with the associated meter registry. The first pairing that accepts the request returns the response. ",
            "title": "Accessing the Helidon Micrometer Endpoint"
        },
        {
            "location": "/mp/websocket/01_overview",
            "text": " Helidon integrates with Tyrus to provide support for the Jakarta WebSocket API . The WebSocket API enables Java applications to participate in WebSocket interactions as both servers and clients. The server API supports two flavors: annotated and programmatic endpoints. Annotated endpoints, as suggested by their name, use Java annotations to provide the necessary meta-data to define WebSocket handlers; programmatic endpoints implement API interfaces and are annotation free. Annotated endpoints tend to be more flexible since they allow different method signatures depending on the application needs, whereas programmatic endpoints must implement an interface and are, therefore, bounded to its definition. Helidon MP support is centered around annotations and bean discovery using CDI. Developers can choose between annotated and programmatic endpoints or use any combination of them. Using annotated endpoints is recommended in MP as they usually result in more succinct and easier-to-read code. ",
            "title": "preambule"
        },
        {
            "location": "/mp/websocket/01_overview",
            "text": " This section describes the implementation of a simple application that uses a REST resource to push messages into a shared queue and a WebSocket endpoint to download messages from the queue, one at a time, over a connection. The example will show how REST and WebSocket connections can be seamlessly combined into a Helidon application. The Helidon MP application shown here takes full advantage of CDI and class scanning and does not require any additional code given that the necessary information is available from the code annotations. The REST endpoint is implemented as a JAX-RS resource, and the shared queue (in application scope) is directly injected: <markup lang=\"java\" >@Path(\"rest\") public class MessageQueueResource { @Inject private MessageQueue messageQueue; @POST @Consumes(\"text/plain\") public void push(String s) { messageQueue.push(s); } } Here we opt for the use of an annotated WebSocket endpoint decorated by @ServerEndpoint that provides all the meta-data necessary for Helidon to create the endpoint. <markup lang=\"java\" >@ServerEndpoint( value = \"/websocket\", encoders = { UppercaseEncoder.class }) public class MessageBoardEndpoint { @Inject private MessageQueue messageQueue; @OnMessage public void onMessage(Session session, String message) { if (message.equals(\"SEND\")) { while (!messageQueue.isEmpty()) { session.getBasicRemote().sendObject(messageQueue.pop()); } } } } Since MessageBoardEndpoint is just a POJO, it uses additional annotations for event handlers such as @OnMessage . One advantage of this approach, much like in the JAX-RS API, is that method signatures are not fixed. In the snipped above, the parameters (which could be specified in any order!) include the WebSocket session and the message received that triggered the call. So what else is needed to run this Helidon MP app? Nothing else other than the supporting classes MessageQueue and UppercaseEncoder . Helidon MP declares both @Path and @ServerEndpoint as bean defining annotation, so all that is needed is for CDI discovery to be enabled --typically in your beans.xml file. By default, both JAX-RS resources and WebSocket endpoints will be available under the root path \"/\" . This default value can be overridden by providing subclasses/implementations for jakarta.ws.rs.Application and jakarta.websocket.server.ServerApplicationConfig , respectively. JAX-RS uses @ApplicationPath on application subclasses to provide this root path, but since there is no equivalent in the WebSocket API, Helidon MP uses its own annotation @RoutingPath on jakarta.websocket.server.ServerApplicationConfig implementations. For instance, if in our example we include the following class: <markup lang=\"java\" >@ApplicationScoped @RoutingPath(\"/web\") public class MessageBoardApplication implements ServerApplicationConfig { @Override public Set&lt;ServerEndpointConfig&gt; getEndpointConfigs( Set&lt;Class&lt;? extends Endpoint&gt;&gt; endpoints) { assert endpoints.isEmpty(); return Collections.emptySet(); // No programmatic endpoints } @Override public Set&lt;Class&lt;?&gt;&gt; getAnnotatedEndpointClasses(Set&lt;Class&lt;?&gt;&gt; endpoints) { return endpoints; // Returned scanned endpoints } } the root path for WebSocket endpoints will be \"/web\" instead of the default \"/\" . Note that @RoutingPath is not a bean defining annotation, thus the need to use @ApplicationScoped --which, as before, requires CDI bean discovery mode to be annotated . In addition to @RoutingPath , these classes can be annotated with @RoutingName to associate an endpoint with a Helidon named socket. Please refer to the Javadoc of that annotation for additional information. All endpoint methods in Helidon MP are executed in a separate thread pool, independently of Netty. Therefore, there is no need to create additional threads for blocking or long-running operations as these will not affect Netty&#8217;s ability to process networking data. For more information see the example . ",
            "title": "Helidon MP Example"
        },
        {
            "location": "/guides/34_Oracle_Kubernetes",
            "text": " Push a Docker image of your Helidon application to Oracle Cloud Infrastructure Registry (OCIR), and deploy the image from the registry to Oracle Cloud Infrastructure Container Engine for Kubernetes (OKE). ",
            "title": "preambule"
        },
        {
            "location": "/guides/34_Oracle_Kubernetes",
            "text": " About 10 minutes Helidon prerequisites An OKE cluster. See the OKE documentation . A Helidon project created from the quickstart Maven archetype. See quickstart Maven archetype . ",
            "title": "What You Need"
        },
        {
            "location": "/guides/34_Oracle_Kubernetes",
            "text": " Your account must be in the Administrators group or another group that has the REPOSITORY_CREATE permission. Sign in to the Oracle Cloud Infrastructure (OCI) web console and generate an authentication token. See Getting an Auth Token . Remember to copy the generated token. You won&#8217;t be able to access it again. <markup lang=\"bash\" title=\"Log in to the OCIR Docker registry:\" >docker login \\ -u &lt;username&gt; \\ -p &lt;password&gt; \\ &lt;region-code&gt;.ocir.io The user name in the format &lt;tenancy_name&gt;/&lt;username&gt; . The password is the generated token. &lt;region-code&gt; is the code for the OCI region that you&#8217;re using. For example, the region code for Phoenix is phx . See Regions and Availability Domains . <markup lang=\"bash\" title=\"Tag the image that you want to push to the registry:\" >docker tag \\ helidon-quickstart-se:latest \\ &lt;region-code&gt;.ocir.io/&lt;tenancy-name&gt;/&lt;repo-name&gt;/&lt;image-name&gt;:&lt;tag&gt; the local image to tag &lt;repo-name&gt; is optional. It is the name of a repository to which you want to push the image (for example, project01 ). <markup lang=\"bash\" title=\"Push the image to the Registry:\" >docker push \\ &lt;region-code&gt;.ocir.io/&lt;tenancy-name&gt;/&lt;repo-name&gt;/&lt;image-name&gt;:&lt;tag&gt; You can pull your image with the image path used above, for example: phx.ocir.io/helidon/example/helidon-quickstart-se:latest ",
            "title": "Push Your Image to OCIR"
        },
        {
            "location": "/guides/34_Oracle_Kubernetes",
            "text": " First, change to the helidon-quickstart-se directory. Then edit app.yaml and add the following under spec in the deployment section: <markup lang=\"yaml\" >spec: imagePullSecrets: - name: ocirsecret containers: - name: helidon-quickstart-se image: phx.ocir.io/helidon/example/helidon-quickstart-se:latest imagePullPolicy: Always ports: - containerPort: 8080 The config secret name The image path <markup lang=\"bash\" title=\"Deploy the application:\" >kubectl create -f app.yaml -n helidon <markup lang=\"bash\" title=\"Get the NodePort number for your new pod:\" >kubectl get svc -n helidon <markup lang=\"bash\" title=\"Get the IP address for your cluster nodes:\" >kubectl get nodes You can now access the application at http://&lt;NodeIpAddress&gt;:&lt;NodePort&gt;/greet . ",
            "title": "Deploy the Image to Kubernetes"
        },
        {
            "location": "/guides/34_Oracle_Kubernetes",
            "text": " Create a namespace (for example, helidon ) for the project: <markup lang=\"bash\" >kubectl create namespace helidon The repository that you created is private. To allow Kubernetes to authenticate with the container registry and pull the private image, you must create and use an image-pull secret. <markup lang=\"bash\" title=\"Create an image-pull secret:\" >kubectl create secret docker-registry \\ ocirsecret \\ --docker-server=&lt;region-code&gt;.ocir.io \\ --docker-username='&lt;tenancy-name&gt;/&lt;oci-username&gt;' \\ --docker-password='&lt;oci-auth-token&gt;' \\ --docker-email='&lt;email-address&gt;' \\ --namespace helidon The name of the config secret The docker registry (see docker tag step above) The user name (see docker login step above) The password (see docker login step above) The namespace created in the previous step Deploy the Image to Kubernetes First, change to the helidon-quickstart-se directory. Then edit app.yaml and add the following under spec in the deployment section: <markup lang=\"yaml\" >spec: imagePullSecrets: - name: ocirsecret containers: - name: helidon-quickstart-se image: phx.ocir.io/helidon/example/helidon-quickstart-se:latest imagePullPolicy: Always ports: - containerPort: 8080 The config secret name The image path <markup lang=\"bash\" title=\"Deploy the application:\" >kubectl create -f app.yaml -n helidon <markup lang=\"bash\" title=\"Get the NodePort number for your new pod:\" >kubectl get svc -n helidon <markup lang=\"bash\" title=\"Get the IP address for your cluster nodes:\" >kubectl get nodes You can now access the application at http://&lt;NodeIpAddress&gt;:&lt;NodePort&gt;/greet . ",
            "title": "Setup your K8s Cluster"
        },
        {
            "location": "/mp/cors/04_support-in-builtin-services",
            "text": " Several built-in Helidon services&#8201;&#8212;&#8201;health, metrics, and OpenAPI&#8201;&#8212;&#8201;have integrated CORS support. You can include these services in your application and control their CORS behavior. ",
            "title": "preambule"
        },
        {
            "location": "/mp/cors/04_support-in-builtin-services",
            "text": " Helidon lets you easily include health , metrics , and OpenAPI services in your Helidon application. These services add endpoints to your application so that clients can retrieve information about it. As with the application endpoints you write, these endpoints represent resources that can be shared across origins. For example, several websites related to OpenAPI run a web application in your browser. You provide the URL for your application to the browser application. The browser application uses the URL to retrieve the OpenAPI document that describes the application&#8217;s endpoints directly from your application. The browser application then displays a user interface that you use to \"drive\" your application. That is, you provide input, have the web application send requests to your application endpoints, and then view the responses. This scenario is exactly the situation CORS addresses: an application in the browser from one origin&#8201;&#8212;&#8201;the user interface downloaded from the website&#8201;&#8212;&#8201;requests a resource from another origin&#8201;&#8212;&#8201;the /openapi endpoint which Helidon&#8217;s OpenAPI built-in service automatically adds to your application. Integrating CORS support into these built-in services allows such third-party web sites and their browser applications&#8201;&#8212;&#8201;or more generally, apps from any other origin&#8201;&#8212;&#8201;to work with your Helidon application. Because all three of these built-in Helidon services serve only GET endpoints, by default the integrated CORS support in all three services permits any origin to share their resources using GET , HEAD , and OPTIONS HTTP requests. You can customize the CORS set-up for these built-in services independently from each other using configuration. You can use this override feature to control the CORS behavior of the built-in services even if you do not add CORS behavior to your own endpoints. ",
            "title": "Understanding CORS Support in Helidon Services"
        },
        {
            "location": "/mp/cors/04_support-in-builtin-services",
            "text": " To use built-in services with CORS support and customize the CORS behavior: Add the built-in service or services to your application. The health, metrics, and OpenAPI services automatically include default CORS support. Add a dependency on the Helidon MP CORS artifact to your Maven pom.xml file. If you want the built-in services to support CORS, then you need to add the CORS dependency even if your own endpoints do not use CORS. The Managing Dependencies page describes how you should declare dependency management for Helidon applications. For CORS support in Helidon MP, you must include the following dependency in your project: Use configuration to customize the CORS behavior as needed. The documentation for the individual built-in services describes how to add each service to your application, including adding a Maven dependency. In your application&#8217;s configuration file, the configuration for each service appears under its own key. Helidon Service Documentation Configuration Key health health metrics metrics OpenAPI openapi The Helidon MP QuickStart example uses these services, so you can use that as a template for your own application, or use the example project itself to experiment with customizing the CORS behavior in the built-in services. ",
            "title": "Getting Started"
        },
        {
            "location": "/mp/cors/04_support-in-builtin-services",
            "text": " You can use configuration to control whether and how each of the built-in services works with CORS. For the health, metrics, and OpenAPI services, your configuration can include a section for CORS. You have full control over the CORS configuration for a built-in Helidon service. Use a basic CORS config section as described in Using Configuration with CORS in Helidon MP . The following example restricts sharing of the /health resource, provided by the health built-in service, to only the origin http://there.com , and the /metrics resource, provided by the metrics built-in service, to only the origin http://foo.com . <markup lang=\"hocon\" >... health: cors: allow-origins: [http://there.com] metrics: cors: allow-origins: [http://foo.com] ... ",
            "title": "Configuring CORS for Built-in Services"
        },
        {
            "location": "/mp/cors/04_support-in-builtin-services",
            "text": " Build and run the QuickStart application as usual. <markup lang=\"bash\" >mvn package java -jar target/helidon-quickstart-mp.jar ... 2020.05.12 05:44:08 INFO io.helidon.microprofile.server.ServerCdiExtension Thread[main,5,main]: Server started on http://localhost:8080 (and all other host addresses) in 5280 milliseconds (since JVM startup). ... ",
            "title": "Build and Run the Application"
        },
        {
            "location": "/mp/cors/04_support-in-builtin-services",
            "text": " The metrics service rejects attempts to access metrics on behalf of a disallowed origin. <markup lang=\"bash\" >curl -i -H \"Origin: http://other.com\" http://localhost:8080/metrics HTTP/1.1 403 Forbidden Date: Mon, 11 May 2020 11:08:09 -0500 transfer-encoding: chunked connection: keep-alive But accesses from foo.com succeed. <markup lang=\"bash\" >curl -i -H \"Origin: http://foo.com\" http://localhost:8080/metrics HTTP/1.1 200 OK Access-Control-Allow-Origin: http://foo.com Content-Type: text/plain Date: Mon, 11 May 2020 11:08:16 -0500 Vary: Origin connection: keep-alive content-length: 6065 # TYPE base_classloader_loadedClasses_count gauge # HELP base_classloader_loadedClasses_count Displays the number of classes that are currently loaded in the Java virtual machine. base_classloader_loadedClasses_count 3568 ... ",
            "title": "Retrieve Metrics"
        },
        {
            "location": "/mp/cors/04_support-in-builtin-services",
            "text": " The health service rejects requests from origins not specifically approved. <markup lang=\"bash\" >curl -i -H \"Origin: http://foo.com\" http://localhost:8080/health HTTP/1.1 403 Forbidden Date: Mon, 11 May 2020 12:06:55 -0500 transfer-encoding: chunked connection: keep-alive And responds successfully only to cross-origin requests from http://there.com . <markup lang=\"bash\" >curl -i -H \"Origin: http://there.com\" http://localhost:8080/health HTTP/1.1 200 OK Access-Control-Allow-Origin: http://there.com Content-Type: application/json Date: Mon, 11 May 2020 12:07:32 -0500 Vary: Origin connection: keep-alive content-length: 461 {\"outcome\":\"UP\",...} ",
            "title": "Retrieve Health"
        },
        {
            "location": "/mp/cors/04_support-in-builtin-services",
            "text": " If you have edited the Helidon MP QuickStart application as described in the previous topics and saved your changes, you can build and run the application. Once you do so you can execute curl commands to demonstrate the behavior changes in the metric and health services with the addition of the CORS functionality. Note the addition of the Origin header value in the curl commands, and the Access-Control-Allow-Origin in the successful responses. Build and Run the Application Build and run the QuickStart application as usual. <markup lang=\"bash\" >mvn package java -jar target/helidon-quickstart-mp.jar ... 2020.05.12 05:44:08 INFO io.helidon.microprofile.server.ServerCdiExtension Thread[main,5,main]: Server started on http://localhost:8080 (and all other host addresses) in 5280 milliseconds (since JVM startup). ... Retrieve Metrics The metrics service rejects attempts to access metrics on behalf of a disallowed origin. <markup lang=\"bash\" >curl -i -H \"Origin: http://other.com\" http://localhost:8080/metrics HTTP/1.1 403 Forbidden Date: Mon, 11 May 2020 11:08:09 -0500 transfer-encoding: chunked connection: keep-alive But accesses from foo.com succeed. <markup lang=\"bash\" >curl -i -H \"Origin: http://foo.com\" http://localhost:8080/metrics HTTP/1.1 200 OK Access-Control-Allow-Origin: http://foo.com Content-Type: text/plain Date: Mon, 11 May 2020 11:08:16 -0500 Vary: Origin connection: keep-alive content-length: 6065 # TYPE base_classloader_loadedClasses_count gauge # HELP base_classloader_loadedClasses_count Displays the number of classes that are currently loaded in the Java virtual machine. base_classloader_loadedClasses_count 3568 ... Retrieve Health The health service rejects requests from origins not specifically approved. <markup lang=\"bash\" >curl -i -H \"Origin: http://foo.com\" http://localhost:8080/health HTTP/1.1 403 Forbidden Date: Mon, 11 May 2020 12:06:55 -0500 transfer-encoding: chunked connection: keep-alive And responds successfully only to cross-origin requests from http://there.com . <markup lang=\"bash\" >curl -i -H \"Origin: http://there.com\" http://localhost:8080/health HTTP/1.1 200 OK Access-Control-Allow-Origin: http://there.com Content-Type: application/json Date: Mon, 11 May 2020 12:07:32 -0500 Vary: Origin connection: keep-alive content-length: 461 {\"outcome\":\"UP\",...} ",
            "title": "Accessing the Shared Resources"
        },
        {
            "location": "/mp/tracing/03_jaeger",
            "text": " Helidon is integrated with the Jaeger tracer. The Jaeger builder is loaded through ServiceLoader and configured. You could also use the Jaeger builder directly, though this would create a source-code dependency on the Jaeger tracer. ",
            "title": "preambule"
        },
        {
            "location": "/mp/tracing/03_jaeger",
            "text": " To enable Jaeger Tracing add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-jaeger&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/tracing/03_jaeger",
            "text": " The Jaeger tracer supports the following configuration options: Key Default value Builder method Description service N/A serviceName Name of the service, to distinguish traces crossing service boundaries; Jaeger is using lower-case only, name will be automatically lower-cased protocol http collectorProtocol Protocol of the Jaeger trace collector ( udp , http or https ), to switch to agent mode, use udp host localhost collectorHost Host of the Jaeger trace collector (IP Address, hostname, or FQDN) port 14268 collectorPort Port of the Jaeger trace collector path /api/traces collectorPath Path of the Jaeger trace collector token N/A token Authentication token to use (token authentication) username N/A username User to authenticate (basic authentication) password N/A password Password of the user to authenticate (basic authentication) propagation library default addPropagation Propagation type ( jaeger or b3 ) log-spans library default logSpans Whether to log spans (boolean) max-queue-size library default maxQueueSize Maximal queue size of the reporter (int) flush-interval-ms library default flushInterval Reporter flush interval in milliseconds sampler-type library default samplerType Sampler type ( probabilistic , ratelimiting , remote ) sampler-param library default samplerParam Numeric parameter specifying details for the sampler type sampler-manager library default samplerManager Host and port of the sampler manager for remote type enabled true enabled If set to false, tracing would be disabled tags N/A addTracerTag(String, String) String tags to add to each span boolean-tags N/A addTracerTag(String, boolean) boolean tags to add to each span int-tags N/A addTracerTag(String, int) int tags to add to each span The following is an example of a Jaeger configuration, specified in the YAML format. <markup lang=\"yaml\" >tracing: service: \"helidon-full-http\" protocol: \"https\" # JAEGER_ENDPOINT (if not udp, http is expected and endpoint is filled) host: \"192.168.1.3\" # JAEGER_ENDPOINT port: 14240 # JAEGER_ENDPOINT path: \"/api/traces/mine\" # JAEGER_ENDPOINT token: \"token\" # JAEGER_AUTH_TOKEN # Either token or username/password #username: \"user\" # JAEGER_USER #password: \"pass\" # JAEGER_PASSWORD propagation: \"jaeger\" # JAEGER_PROPAGATION either \"jaeger\" or \"b3\" log-spans: false # JAEGER_REPORTER_LOG_SPANS max-queue-size: 42 # JAEGER_REPORTER_MAX_QUEUE_SIZE flush-interval-ms: 10001 # JAEGER_REPORTER_FLUSH_INTERVAL sampler-type: \"remote\"# JAEGER_SAMPLER_TYPE (https://www.jaegertracing.io/docs/latest/sampling/#client-sampling-configuration) sampler-param: 0.5 # JAEGER_SAMPLER_PARAM (number) sampler-manager: \"localhost:47877\" # JAEGER_SAMPLER_MANAGER_HOST_PORT tags: tag1: \"tag1-value\" # JAEGER_TAGS tag2: \"tag2-value\" # JAEGER_TAGS boolean-tags: tag3: true # JAEGER_TAGS tag4: false # JAEGER_TAGS int-tags: tag5: 145 # JAEGER_TAGS tag6: 741 # JAEGER_TAGS ",
            "title": "Configuring Jaeger"
        },
        {
            "location": "/mp/tracing/03_jaeger",
            "text": " Jaeger tracks its own behavior using metrics. See Metrics Support for Jaeger to read how to integrate Jaeger metrics with Helidon. ",
            "title": "Integrating with Jaeger Tracing"
        },
        {
            "location": "/mp/lra/02_coordinator",
            "text": " Experimental tool, usage in production is not advised. <markup lang=\"bash\" title=\"Build and run Helidon LRA coordinator\" >docker build -t helidon/lra-coordinator https://github.com/oracle/helidon.git#:lra/coordinator/server docker run -dp 8070:8070 --name lra-coordinator --network=\"host\" helidon/lra-coordinator Helidon LRA coordinator is compatible with Narayana clients, you need to add an additional dependency for Narayana client: <markup lang=\"xml\" title=\"Dependency needed for using Helidon LRA with Narayana compatible coordinator\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.lra&lt;/groupId&gt; &lt;artifactId&gt;helidon-lra-coordinator-narayana-client&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Helidon LRA coordinator"
        },
        {
            "location": "/mp/lra/02_coordinator",
            "text": " Narayana is a transaction manager supporting LRA. To use Narayana LRA coordinator with Helidon LRA client you need to add an additional dependency for Narayana client: <markup lang=\"xml\" title=\"Dependency needed for using Helidon LRA with Narayana coordinator\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.lra&lt;/groupId&gt; &lt;artifactId&gt;helidon-lra-coordinator-narayana-client&lt;/artifactId&gt; &lt;/dependency&gt; The simplest way to run Narayana LRA coordinator locally: <markup lang=\"bash\" title=\"Downloading and running Narayana LRA coordinator\" >wget https://search.maven.org/remotecontent?filepath=org/jboss/narayana/rts/lra-coordinator-quarkus/5.11.1.Final/lra-coordinator-quarkus-5.11.1.Final-runner.jar \\ -O narayana-coordinator.jar \\ &amp;&amp; java -Dquarkus.http.port=8070 -jar narayana-coordinator.jar Narayana LRA coordinator is running by default under lra-coordinator context, with port 8070 defined in the snippet above you need to configure your Helidon LRA app as follows: mp.lra.coordinator.url=http://localhost:8070/lra-coordinator ",
            "title": "Narayana"
        },
        {
            "location": "/mp/lra/02_coordinator",
            "text": " Coordinator is a service that tracks all LRA transactions and calls the compensate REST endpoints of the participants when the LRA transaction gets cancelled or completes (in case it gets closed). In addition, participant also keeps track of timeouts, retries participant calls, and assigns LRA ids. Helidon LRA coordinator Narayana coordinator . Helidon LRA coordinator Experimental tool, usage in production is not advised. <markup lang=\"bash\" title=\"Build and run Helidon LRA coordinator\" >docker build -t helidon/lra-coordinator https://github.com/oracle/helidon.git#:lra/coordinator/server docker run -dp 8070:8070 --name lra-coordinator --network=\"host\" helidon/lra-coordinator Helidon LRA coordinator is compatible with Narayana clients, you need to add an additional dependency for Narayana client: <markup lang=\"xml\" title=\"Dependency needed for using Helidon LRA with Narayana compatible coordinator\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.lra&lt;/groupId&gt; &lt;artifactId&gt;helidon-lra-coordinator-narayana-client&lt;/artifactId&gt; &lt;/dependency&gt; Narayana Narayana is a transaction manager supporting LRA. To use Narayana LRA coordinator with Helidon LRA client you need to add an additional dependency for Narayana client: <markup lang=\"xml\" title=\"Dependency needed for using Helidon LRA with Narayana coordinator\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.lra&lt;/groupId&gt; &lt;artifactId&gt;helidon-lra-coordinator-narayana-client&lt;/artifactId&gt; &lt;/dependency&gt; The simplest way to run Narayana LRA coordinator locally: <markup lang=\"bash\" title=\"Downloading and running Narayana LRA coordinator\" >wget https://search.maven.org/remotecontent?filepath=org/jboss/narayana/rts/lra-coordinator-quarkus/5.11.1.Final/lra-coordinator-quarkus-5.11.1.Final-runner.jar \\ -O narayana-coordinator.jar \\ &amp;&amp; java -Dquarkus.http.port=8070 -jar narayana-coordinator.jar Narayana LRA coordinator is running by default under lra-coordinator context, with port 8070 defined in the snippet above you need to configure your Helidon LRA app as follows: mp.lra.coordinator.url=http://localhost:8070/lra-coordinator ",
            "title": "Coordinator"
        },
        {
            "location": "/mp/extensions/05_cdi_jta",
            "text": " This CDI portable extension provides support for JTA (Java Transaction API) transactions in your Helidon MicroProfile applications. ",
            "title": "preambule"
        },
        {
            "location": "/mp/extensions/05_cdi_jta",
            "text": " To enable JTA Support add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.cdi&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-cdi-jta-weld&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.transaction&lt;/groupId&gt; &lt;artifactId&gt;javax.transaction-api&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/extensions/05_cdi_jta",
            "text": " The following example shows how to declare a transactional method. <markup lang=\"java\" title=\"Transactional method declaration\" >@Transactional(Transactional.TxType.REQUIRED) public void doSomethingTransactionally() { } The extension ensures that a transaction is started before and committed after the method executes. If the method throws an exception, the transaction will be rolled back. You can further specify the transactional behavior of the extension by using different instances of the Transactional annotation. For more information, see the Transactional annotation documentation . Transactional method support is implemented by CDI interception facilities. Among other things, this means that the method to which you apply the Transactional annotation must not be private and must in all other ways be a business method . See the Java Interceptors specification for more details. During a transactional method invocation, the extension makes the following objects available for injection via the Inject annotation: UserTransaction Transaction TransactionManager TransactionSynchronizationRegistry ",
            "title": "Declaring a method to be transactional"
        },
        {
            "location": "/mp/guides/05_metrics",
            "text": " This guide describes how to create a sample Helidon MicroProfile (MP) project that can be used to run some basic examples using both built-in and custom metrics with Helidon. ",
            "title": "preambule"
        },
        {
            "location": "/mp/guides/05_metrics",
            "text": " Use the Helidon MP Maven archetype to create a simple project that can be used for the examples in this guide. <markup lang=\"bash\" title=\"Run the Maven archetype\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-mp \\ -DarchetypeVersion=2.5.4 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-mp \\ -Dpackage=io.helidon.examples.quickstart.mp ",
            "title": "Create a Sample Helidon MP Project"
        },
        {
            "location": "/mp/guides/05_metrics",
            "text": " Helidon provides three scopes of metrics: base, vendor, and application. Here are the metric endpoints: /metrics/base - Base metrics data as specified by the MicroProfile Metrics specification. /metrics/vendor - Helidon-specific metrics data. /metrics/application - Application-specific metrics data. The /metrics endpoint will return data for all scopes. The built-in metrics fall into three categories: JVM behavior (in the base registry), basic key performance indicators for request handling (in the vendor registry), and thread pool utilization (also in the vendor registry). A later section describes the key performance indicator metrics in detail. The following example demonstrates how to use the other built-in metrics. All examples are executed from the root directory of your project (helidon-quickstart-mp). <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-mp.jar Metrics can be returned in either text format (the default), or JSON. The text format uses OpenMetrics (Prometheus) Text Format, see https://prometheus.io/docs/instrumenting/exposition_formats/#text-format-details . <markup lang=\"bash\" title=\"Verify the metrics endpoint in a new terminal window:\" >curl http://localhost:8080/metrics <markup lang=\"text\" title=\"Text response:\" ># TYPE base_REST_request_total counter # HELP base_REST_request_total The number of invocations and total response time of RESTful resource methods since the start of the server. base_REST_request_total{class=\"io.helidon.examples.quickstart.mp.GreetResource\",method=\"getDefaultMessage\"} 0 # TYPE base_REST_request_elapsedTime_seconds gauge base_REST_request_elapsedTime_seconds{class=\"io.helidon.examples.quickstart.mp.GreetResource\",method=\"getDefaultMessage\"} 0.0 base_REST_request_total{class=\"io.helidon.examples.quickstart.mp.GreetResource\",method=\"getMessage_java.lang.String\"} 0 base_REST_request_elapsedTime_seconds{class=\"io.helidon.examples.quickstart.mp.GreetResource\",method=\"getMessage_java.lang.String\"} 0.0 base_REST_request_total{class=\"io.helidon.examples.quickstart.mp.GreetResource\",method=\"updateGreeting_javax.json.JsonObject\"} 0 base_REST_request_elapsedTime_seconds{class=\"io.helidon.examples.quickstart.mp.GreetResource\",method=\"updateGreeting_javax.json.JsonObject\"} 0.0 # TYPE base:classloader_current_loaded_class_count counter # HELP base:classloader_current_loaded_class_count Displays the number of classes that are currently loaded in the Java virtual machine. base:classloader_current_loaded_class_count 7511 # TYPE base:classloader_total_loaded_class_count counter # HELP base:classloader_total_loaded_class_count Displays the total number of classes that have been loaded since the Java virtual machine has started execution. base:classloader_total_loaded_class_count 7512 ... You can get the same data in JSON format. <markup lang=\"bash\" title=\"Verify the metrics endpoint with an HTTP accept header:\" >curl -H \"Accept: application/json\" http://localhost:8080/metrics <markup lang=\"json\" title=\"JSON response:\" >{ \"base\": { \"REST.request\": { \"count;class=io.helidon.examples.quickstart.mp.GreetResource;method=getDefaultMessage\":0, \"elapsedTime;class=io.helidon.examples.quickstart.mp.GreetResource;method=getDefaultMessage\":0.0, \"count;class=io.helidon.examples.quickstart.mp.GreetResource;method=getMessage_java.lang.String\":0, \"elapsedTime;class=io.helidon.examples.quickstart.mp.GreetResource;method=getMessage_java.lang.String\":0.0, \"count;class=io.helidon.examples.quickstart.mp.GreetResource;method=updateGreeting_javax.json.JsonObject\":0, \"elapsedTime;class=io.helidon.examples.quickstart.mp.GreetResource;method=updateGreeting_javax.json.JsonObject\":0.0 }, \"classloader.currentLoadedClass.count\": 7534, \"classloader.totalLoadedClass.count\": 7538, \"classloader.totalUnloadedClass.count\": 1, \"cpu.availableProcessors\": 4, \"cpu.systemLoadAverage\": 2.83349609375, \"gc.PS MarkSweep.count\": 2, \"gc.PS MarkSweep.time\": 77, \"gc.PS Scavenge.count\": 5, \"gc.PS Scavenge.time\": 37, \"jvm.uptime\": 727588, \"memory.committedHeap\": 284164096, \"memory.maxHeap\": 3817865216, \"memory.usedHeap\": 53283088, \"thread.count\": 44, \"thread.daemon.count\": 35, \"thread.max.count\": 44 }, \"vendor\": { \"executor-service.active-count;poolIndex=0;supplierCategory=helidon-thread-pool-2;supplierIndex=0\": 0, \"executor-service.completed-task-count;poolIndex=0;supplierCategory=helidon-thread-pool-2;supplierIndex=0\": 0, \"executor-service.largest-pool-size;poolIndex=0;supplierCategory=helidon-thread-pool-2;supplierIndex=0\": 5, \"executor-service.pool-size;poolIndex=0;supplierCategory=helidon-thread-pool-2;supplierIndex=0\": 5, \"executor-service.queue.remaining-capacity;poolIndex=0;supplierCategory=helidon-thread-pool-2;supplierIndex=0\": 10000, \"executor-service.queue.size;poolIndex=0;supplierCategory=helidon-thread-pool-2;supplierIndex=0\": 0, \"executor-service.task-count;poolIndex=0;supplierCategory=helidon-thread-pool-2;supplierIndex=0\": 0, \"requests.count\": 6, \"requests.meter\": { \"count\": 6, \"meanRate\": 0.008275992296704147, \"oneMinRate\": 0.01576418632772332, \"fiveMinRate\": 0.006695060022357365, \"fifteenMinRate\": 0.0036382699664488415 } } } You can get a single metric by specifying the name in the URL path. <markup lang=\"bash\" title=\"Get the Helidon requests.meter metric:\" >curl -H \"Accept: application/json\" http://localhost:8080/metrics/vendor/requests.meter <markup lang=\"json\" title=\"JSON response:\" >{ \"requests.meter\": { \"count\": 6, \"meanRate\": 0.008275992296704147, \"oneMinRate\": 0.01576418632772332, \"fiveMinRate\": 0.006695060022357365, \"fifteenMinRate\": 0.0036382699664488415 } } You cannot get the individual fields of a metric. For example, you cannot target http://localhost:8080/metrics/vendor/requests.meter.count . The base metrics illustrated above provide some insight into the behavior of the JVM in which the server runs. The vendor metrics shown above appear in two groups: Helidon thread pools Helidon uses these thread pools for its own internal work, and your application can also use Helidon-managed thread pools if it needs to do work asynchronously. (See this example .) The metrics in this group show information about the thread pools which can help you assess how efficiently they are utilized. Helidon uses tags to distinguish the metrics which describe different thread pools. In some cases the specific metrics exposed depend on the particular type of thread pool. basic key performance indicators These metrics give an idea of the request traffic the server is handling. See the later section for more information on the basic and extended key performance indicator metrics. ",
            "title": "Using the Built-In Metrics"
        },
        {
            "location": "/mp/guides/05_metrics",
            "text": " By default, if your application depends on the helidon-metrics Maven module then full-featured metrics are enabled. You can disable the metrics subsystem entirely using configuration: <markup lang=\"properties\" title=\"Configuration properties file disabling metrics\" >metrics.enabled=false With metrics processing disabled, Helidon never updates any metrics and the /metrics endpoints respond with 404 plus a message that the metrics subsystem is disabled. ",
            "title": "Disabling Metrics Subsystem Entirely"
        },
        {
            "location": "/mp/guides/05_metrics",
            "text": " Helidon implements the optional family of metrics, all with the name REST.request , as described in the MicroProfile Metrics specification . Each instance is a SimpleTimer with tags class and method identifying exactly which REST endpoint Java method that instance measures. By default, Helidon MP does not enable this feature. Enable it by editing your application configuration to set metrics.rest-request.enabled to true . Note that the applications you generate using the full Helidon archetype do enable this feature in the generated config file. You can see the results in the sample output shown in earlier example runs. ",
            "title": "Controlling REST.request Metrics"
        },
        {
            "location": "/mp/guides/05_metrics",
            "text": " Helidon contains several components and integrations which register and update metrics. Depending on how the component is written, you might be able to disable just that component&#8217;s use of metrics: <markup lang=\"properties\" title=\"Configuration properties file disabling a component&#8217;s use of metrics\" >some-component.metrics.enabled=false Check the documentation for a specific component to find out whether that component uses metrics and whether it allows you to disable that use. If you disable a component&#8217;s use of metrics, Helidon does not register the component&#8217;s metrics in the visible metrics registries nor do those metrics ever update their values. The response from the /metrics endpoint excludes that component&#8217;s metrics. Note that if you disable metrics processing entirely, no component updates its metrics regardless of any component-level metrics settings. ",
            "title": "Enabling and Disabling Metrics Usage by a Component"
        },
        {
            "location": "/mp/guides/05_metrics",
            "text": " To disable all metrics in a given registry type (application, vendor, or base), add one or more groups to the configuration: <markup lang=\"properties\" title=\"Disabling base and vendor metrics (properties format)\" >metrics.registries.0.type = base metrics.registries.0.enabled = false metrics.registries.1.type = vendor metrics.registries.1.enabled = false <markup lang=\"yaml\" title=\"Disabling base and vendor metrics (YAML format)\" >metrics: registries: - type: base enabled: false - type: vendor enables: false ",
            "title": "Disabling All Metrics of a Given Registry Type"
        },
        {
            "location": "/mp/guides/05_metrics",
            "text": " You can be even more selective. Within a registry type you can configure up to two regular expression patterns: one matching metric names to exclude , and one matching metric names to include . Helidon updates and reports a metric only if two conditions hold: the metric name does not match the exclude regex pattern (if you define one), and either there is no include regex pattern, or the metric name matches the include pattern. Caution Make sure any include regex pattern you specify matches all the metric names you want to capture. Suppose your application creates and updates a group of metrics with names such as myapp.xxx.queries , myapp.xxx.creates , myapp.xxx.updates , and myapp.xxx.deletes where xxx can be either supplier or customer . The following example gathers all metrics except those from your application regarding suppliers: <markup lang=\"properties\" title=\"Disabling metrics by name (properties format)\" >metrics.registries.0.type = application metrics.registries.0.filter.exclude = myapp\\.supplier\\..* The following settings select the particular subset of the metrics created in your application code representing updates of customers and suppliers: <markup lang=\"properties\" title=\"Enabling metrics by name (properties format)\" >metrics.registries.0.type = application metrics.registries.0.filter.include = myapp\\..*\\.updates If you use the YAML configuration format, enclose the regex patterns in single-quote marks: <markup lang=\"yaml\" title=\"Enabling metrics by name (YAML format)\" >metrics: registries: - type: application filter: include: 'myapp\\..*\\.updates' The next example selects only your application&#8217;s metrics while excluding those which refer to deletions: <markup lang=\"properties\" title=\"Combining include and exclude \" >metrics.registries.0.type = application metrics.registries.0.filter.include = myapp\\..* metrics.registries.0.filter.exclude = myapp\\..*/deletes Helidon would not update or report the metric myapp.supplier.queries , for example. To include metrics from your application for both updates and queries (but not for other operations), you could change the settings in the previous example to this: <markup >metrics.registries.0.type = application metrics.registries.0.filter.include = myapp\\..*\\.updates|myapp\\..*\\.queries metrics.registries.0.filter.exclude = myapp\\..*/deletes ",
            "title": "Controlling Metrics by Metric Name"
        },
        {
            "location": "/mp/guides/05_metrics",
            "text": " You can control the collection and reporting of metrics by registry type and metric name within registry type. Disabling All Metrics of a Given Registry Type To disable all metrics in a given registry type (application, vendor, or base), add one or more groups to the configuration: <markup lang=\"properties\" title=\"Disabling base and vendor metrics (properties format)\" >metrics.registries.0.type = base metrics.registries.0.enabled = false metrics.registries.1.type = vendor metrics.registries.1.enabled = false <markup lang=\"yaml\" title=\"Disabling base and vendor metrics (YAML format)\" >metrics: registries: - type: base enabled: false - type: vendor enables: false Controlling Metrics by Metric Name You can be even more selective. Within a registry type you can configure up to two regular expression patterns: one matching metric names to exclude , and one matching metric names to include . Helidon updates and reports a metric only if two conditions hold: the metric name does not match the exclude regex pattern (if you define one), and either there is no include regex pattern, or the metric name matches the include pattern. Caution Make sure any include regex pattern you specify matches all the metric names you want to capture. Suppose your application creates and updates a group of metrics with names such as myapp.xxx.queries , myapp.xxx.creates , myapp.xxx.updates , and myapp.xxx.deletes where xxx can be either supplier or customer . The following example gathers all metrics except those from your application regarding suppliers: <markup lang=\"properties\" title=\"Disabling metrics by name (properties format)\" >metrics.registries.0.type = application metrics.registries.0.filter.exclude = myapp\\.supplier\\..* The following settings select the particular subset of the metrics created in your application code representing updates of customers and suppliers: <markup lang=\"properties\" title=\"Enabling metrics by name (properties format)\" >metrics.registries.0.type = application metrics.registries.0.filter.include = myapp\\..*\\.updates If you use the YAML configuration format, enclose the regex patterns in single-quote marks: <markup lang=\"yaml\" title=\"Enabling metrics by name (YAML format)\" >metrics: registries: - type: application filter: include: 'myapp\\..*\\.updates' The next example selects only your application&#8217;s metrics while excluding those which refer to deletions: <markup lang=\"properties\" title=\"Combining include and exclude \" >metrics.registries.0.type = application metrics.registries.0.filter.include = myapp\\..* metrics.registries.0.filter.exclude = myapp\\..*/deletes Helidon would not update or report the metric myapp.supplier.queries , for example. To include metrics from your application for both updates and queries (but not for other operations), you could change the settings in the previous example to this: <markup >metrics.registries.0.type = application metrics.registries.0.filter.include = myapp\\..*\\.updates|myapp\\..*\\.queries metrics.registries.0.filter.exclude = myapp\\..*/deletes ",
            "title": "Controlling Metrics By Registry Type and Metric Name"
        },
        {
            "location": "/mp/guides/05_metrics",
            "text": " Any time you include the Helidon metrics module in your application, Helidon tracks two basic performance indicator metrics: a Counter of all requests received ( requests.count ), and a Meter of all requests received ( requests.meter ). Helidon MP also includes additional, extended KPI metrics which are disabled by default: current number of requests in-flight - a ConcurrentGauge ( requests.inFlight ) of requests currently being processed long-running requests - a Meter ( requests.longRunning ) measuring the rate at which Helidon processes requests which take at least a given amount of time to complete; configurable, defaults to 10000 milliseconds (10 seconds) load - a Meter ( requests.load ) measuring the rate at which requests are worked on (as opposed to received) deferred - a Meter ( requests.deferred ) measuring the rate at which a request&#8217;s processing is delayed after Helidon receives the request You can enable and control these metrics using configuration: <markup lang=\"properties\" title=\"Configuration properties file controlling extended KPI metrics\" >metrics.key-performance-indicators.extended = true metrics.key-performance-indicators.long-running.threshold-ms = 2000 ",
            "title": "Collecting Basic and Extended Key Performance Indicator (KPI) Metrics"
        },
        {
            "location": "/mp/guides/05_metrics",
            "text": " By adding a metrics section to your application configuration you can control how the Helidon metrics subsystem behaves in any of several ways. Disable metrics subsystem entirely . Control REST.request metrics. Identify groups of metrics to control: registered by a particular component , and by metric registry (application, vendor, and base) and within a registry by metric names which match patterns you provide. Select whether to collect extended key performance indicator metrics . Disabling Metrics Subsystem Entirely By default, if your application depends on the helidon-metrics Maven module then full-featured metrics are enabled. You can disable the metrics subsystem entirely using configuration: <markup lang=\"properties\" title=\"Configuration properties file disabling metrics\" >metrics.enabled=false With metrics processing disabled, Helidon never updates any metrics and the /metrics endpoints respond with 404 plus a message that the metrics subsystem is disabled. Controlling REST.request Metrics Helidon implements the optional family of metrics, all with the name REST.request , as described in the MicroProfile Metrics specification . Each instance is a SimpleTimer with tags class and method identifying exactly which REST endpoint Java method that instance measures. By default, Helidon MP does not enable this feature. Enable it by editing your application configuration to set metrics.rest-request.enabled to true . Note that the applications you generate using the full Helidon archetype do enable this feature in the generated config file. You can see the results in the sample output shown in earlier example runs. Enabling and Disabling Metrics Usage by a Component Helidon contains several components and integrations which register and update metrics. Depending on how the component is written, you might be able to disable just that component&#8217;s use of metrics: <markup lang=\"properties\" title=\"Configuration properties file disabling a component&#8217;s use of metrics\" >some-component.metrics.enabled=false Check the documentation for a specific component to find out whether that component uses metrics and whether it allows you to disable that use. If you disable a component&#8217;s use of metrics, Helidon does not register the component&#8217;s metrics in the visible metrics registries nor do those metrics ever update their values. The response from the /metrics endpoint excludes that component&#8217;s metrics. Note that if you disable metrics processing entirely, no component updates its metrics regardless of any component-level metrics settings. Controlling Metrics By Registry Type and Metric Name You can control the collection and reporting of metrics by registry type and metric name within registry type. Disabling All Metrics of a Given Registry Type To disable all metrics in a given registry type (application, vendor, or base), add one or more groups to the configuration: <markup lang=\"properties\" title=\"Disabling base and vendor metrics (properties format)\" >metrics.registries.0.type = base metrics.registries.0.enabled = false metrics.registries.1.type = vendor metrics.registries.1.enabled = false <markup lang=\"yaml\" title=\"Disabling base and vendor metrics (YAML format)\" >metrics: registries: - type: base enabled: false - type: vendor enables: false Controlling Metrics by Metric Name You can be even more selective. Within a registry type you can configure up to two regular expression patterns: one matching metric names to exclude , and one matching metric names to include . Helidon updates and reports a metric only if two conditions hold: the metric name does not match the exclude regex pattern (if you define one), and either there is no include regex pattern, or the metric name matches the include pattern. Caution Make sure any include regex pattern you specify matches all the metric names you want to capture. Suppose your application creates and updates a group of metrics with names such as myapp.xxx.queries , myapp.xxx.creates , myapp.xxx.updates , and myapp.xxx.deletes where xxx can be either supplier or customer . The following example gathers all metrics except those from your application regarding suppliers: <markup lang=\"properties\" title=\"Disabling metrics by name (properties format)\" >metrics.registries.0.type = application metrics.registries.0.filter.exclude = myapp\\.supplier\\..* The following settings select the particular subset of the metrics created in your application code representing updates of customers and suppliers: <markup lang=\"properties\" title=\"Enabling metrics by name (properties format)\" >metrics.registries.0.type = application metrics.registries.0.filter.include = myapp\\..*\\.updates If you use the YAML configuration format, enclose the regex patterns in single-quote marks: <markup lang=\"yaml\" title=\"Enabling metrics by name (YAML format)\" >metrics: registries: - type: application filter: include: 'myapp\\..*\\.updates' The next example selects only your application&#8217;s metrics while excluding those which refer to deletions: <markup lang=\"properties\" title=\"Combining include and exclude \" >metrics.registries.0.type = application metrics.registries.0.filter.include = myapp\\..* metrics.registries.0.filter.exclude = myapp\\..*/deletes Helidon would not update or report the metric myapp.supplier.queries , for example. To include metrics from your application for both updates and queries (but not for other operations), you could change the settings in the previous example to this: <markup >metrics.registries.0.type = application metrics.registries.0.filter.include = myapp\\..*\\.updates|myapp\\..*\\.queries metrics.registries.0.filter.exclude = myapp\\..*/deletes Collecting Basic and Extended Key Performance Indicator (KPI) Metrics Any time you include the Helidon metrics module in your application, Helidon tracks two basic performance indicator metrics: a Counter of all requests received ( requests.count ), and a Meter of all requests received ( requests.meter ). Helidon MP also includes additional, extended KPI metrics which are disabled by default: current number of requests in-flight - a ConcurrentGauge ( requests.inFlight ) of requests currently being processed long-running requests - a Meter ( requests.longRunning ) measuring the rate at which Helidon processes requests which take at least a given amount of time to complete; configurable, defaults to 10000 milliseconds (10 seconds) load - a Meter ( requests.load ) measuring the rate at which requests are worked on (as opposed to received) deferred - a Meter ( requests.deferred ) measuring the rate at which a request&#8217;s processing is delayed after Helidon receives the request You can enable and control these metrics using configuration: <markup lang=\"properties\" title=\"Configuration properties file controlling extended KPI metrics\" >metrics.key-performance-indicators.extended = true metrics.key-performance-indicators.long-running.threshold-ms = 2000 ",
            "title": "Controlling Metrics Behavior"
        },
        {
            "location": "/mp/guides/05_metrics",
            "text": " Each metric has associated metadata that describes: name: The name of the metric. units: The unit of the metric such as time (seconds, millisecond), size (bytes, megabytes), etc. type: The type of metric: Counter , Timer , Meter , Histogram , SimpleTimer , or Gauge . You can get the metadata for any scope, such as /metrics/base , as shown below: <markup lang=\"bash\" title=\"Get the metrics metadata using HTTP OPTIONS method:\" > curl -X OPTIONS -H \"Accept: application/json\" http://localhost:8080/metrics/base <markup lang=\"json\" title=\"JSON response (truncated):\" >{ \"classloader.currentLoadedClass.count\": { \"unit\": \"none\", \"type\": \"counter\", \"description\": \"Displays the number of classes that are currently loaded in the Java virtual machine.\", \"displayName\": \"Current Loaded Class Count\" }, ... \"jvm.uptime\": { \"unit\": \"milliseconds\", \"type\": \"gauge\", \"description\": \"Displays the start time of the Java virtual machine in milliseconds. This attribute displays the approximate time when the Java virtual machine started.\", \"displayName\": \"JVM Uptime\" }, ... \"memory.usedHeap\": { \"unit\": \"bytes\", \"type\": \"gauge\", \"description\": \"Displays the amount of used heap memory in bytes.\", \"displayName\": \"Used Heap Memory\" } } ",
            "title": "Metrics Metadata"
        },
        {
            "location": "/mp/guides/05_metrics",
            "text": " The following example shows how to integrate the Helidon MP application with Kubernetes. <markup lang=\"bash\" title=\"Stop the application and build the docker image:\" >docker build -t helidon-metrics-mp . <markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named metrics.yaml , with the following content:\" >kind: Service apiVersion: v1 metadata: name: helidon-metrics labels: app: helidon-metrics annotations: prometheus.io/scrape: 'true' spec: type: NodePort selector: app: helidon-metrics ports: - port: 8080 targetPort: 8080 name: http --- kind: Deployment apiVersion: apps/v1 metadata: name: helidon-metrics spec: replicas: 1 selector: matchLabels: app: helidon-metrics template: metadata: labels: app: helidon-metrics version: v1 spec: containers: - name: helidon-metrics image: helidon-metrics-mp imagePullPolicy: IfNotPresent ports: - containerPort: 8080 A service of type NodePort that serves the default routes on port 8080 . An annotation that will allow Prometheus to discover and scrape the application pod. A deployment with one replica of a pod. <markup lang=\"bash\" title=\"Create and deploy the application into Kubernetes:\" >kubectl apply -f ./metrics.yaml <markup lang=\"bash\" title=\"Get the service information:\" >kubectl get service/helidon-metrics <markup lang=\"bash\" >NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE helidon-metrics NodePort 10.99.159.2 &lt;none&gt; 8080:31143/TCP 8s A service of type NodePort that serves the default routes on port 31143 . <markup lang=\"bash\" title=\"Verify the metrics endpoint using port 30116 , your port will likely be different:\" >curl http://localhost:31143/metrics Leave the application running in Kubernetes since it will be used for Prometheus integration. ",
            "title": "Kubernetes Integration"
        },
        {
            "location": "/mp/guides/05_metrics",
            "text": " The metrics service that you just deployed into Kubernetes is already annotated with prometheus.io/scrape: . This will allow Prometheus to discover the service and scrape the metrics. In this exercise, you will install Prometheus into Kubernetes, then verify that it discovered the Helidon metrics in your application. <markup lang=\"bash\" title=\"Install Prometheus and wait until the pod is ready:\" >helm install stable/prometheus --name metrics export POD_NAME=$(kubectl get pods --namespace default -l \"app=prometheus,component=server\" -o jsonpath=\"{.items[0].metadata.name}\") kubectl get pod $POD_NAME You will see output similar to the following. Repeat the kubectl get pod command until you see 2/2 and Running . This may take up to one minute. <markup lang=\"bash\" >metrics-prometheus-server-5fc5dc86cb-79lk4 2/2 Running 0 46s <markup lang=\"bash\" title=\"Create a port-forward so you can access the server URL:\" >kubectl --namespace default port-forward $POD_NAME 7090:9090 Now open your browser and navigate to http://localhost:7090/targets . Search for helidon on the page and you will see your Helidon application as one of the Prometheus targets. ",
            "title": "Prometheus Integration"
        },
        {
            "location": "/mp/guides/05_metrics",
            "text": " You can now delete the Kubernetes resources that were just created during this example. <markup lang=\"bash\" title=\"Delete the Prometheus Kubernetes resources:\" >helm delete --purge metrics <markup lang=\"bash\" title=\"Delete the application Kubernetes resources:\" >kubectl delete -f ./metrics.yaml ",
            "title": "Final Cleanup"
        },
        {
            "location": "/mp/guides/05_metrics",
            "text": " Kubernetes Integration The following example shows how to integrate the Helidon MP application with Kubernetes. <markup lang=\"bash\" title=\"Stop the application and build the docker image:\" >docker build -t helidon-metrics-mp . <markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named metrics.yaml , with the following content:\" >kind: Service apiVersion: v1 metadata: name: helidon-metrics labels: app: helidon-metrics annotations: prometheus.io/scrape: 'true' spec: type: NodePort selector: app: helidon-metrics ports: - port: 8080 targetPort: 8080 name: http --- kind: Deployment apiVersion: apps/v1 metadata: name: helidon-metrics spec: replicas: 1 selector: matchLabels: app: helidon-metrics template: metadata: labels: app: helidon-metrics version: v1 spec: containers: - name: helidon-metrics image: helidon-metrics-mp imagePullPolicy: IfNotPresent ports: - containerPort: 8080 A service of type NodePort that serves the default routes on port 8080 . An annotation that will allow Prometheus to discover and scrape the application pod. A deployment with one replica of a pod. <markup lang=\"bash\" title=\"Create and deploy the application into Kubernetes:\" >kubectl apply -f ./metrics.yaml <markup lang=\"bash\" title=\"Get the service information:\" >kubectl get service/helidon-metrics <markup lang=\"bash\" >NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE helidon-metrics NodePort 10.99.159.2 &lt;none&gt; 8080:31143/TCP 8s A service of type NodePort that serves the default routes on port 31143 . <markup lang=\"bash\" title=\"Verify the metrics endpoint using port 30116 , your port will likely be different:\" >curl http://localhost:31143/metrics Leave the application running in Kubernetes since it will be used for Prometheus integration. Prometheus Integration The metrics service that you just deployed into Kubernetes is already annotated with prometheus.io/scrape: . This will allow Prometheus to discover the service and scrape the metrics. In this exercise, you will install Prometheus into Kubernetes, then verify that it discovered the Helidon metrics in your application. <markup lang=\"bash\" title=\"Install Prometheus and wait until the pod is ready:\" >helm install stable/prometheus --name metrics export POD_NAME=$(kubectl get pods --namespace default -l \"app=prometheus,component=server\" -o jsonpath=\"{.items[0].metadata.name}\") kubectl get pod $POD_NAME You will see output similar to the following. Repeat the kubectl get pod command until you see 2/2 and Running . This may take up to one minute. <markup lang=\"bash\" >metrics-prometheus-server-5fc5dc86cb-79lk4 2/2 Running 0 46s <markup lang=\"bash\" title=\"Create a port-forward so you can access the server URL:\" >kubectl --namespace default port-forward $POD_NAME 7090:9090 Now open your browser and navigate to http://localhost:7090/targets . Search for helidon on the page and you will see your Helidon application as one of the Prometheus targets. Final Cleanup You can now delete the Kubernetes resources that were just created during this example. <markup lang=\"bash\" title=\"Delete the Prometheus Kubernetes resources:\" >helm delete --purge metrics <markup lang=\"bash\" title=\"Delete the application Kubernetes resources:\" >kubectl delete -f ./metrics.yaml ",
            "title": "Integration with Kubernetes and Prometheus"
        },
        {
            "location": "/mp/guides/05_metrics",
            "text": " Each metric has associated metadata that describes: name: The name of the metric. units: The unit of the metric such as time (seconds, millisecond), size (bytes, megabytes), etc. type: The type of metric: Counter , Timer , Meter , Histogram , SimpleTimer , or Gauge . You can get the metadata for any scope, such as /metrics/base , as shown below: <markup lang=\"bash\" title=\"Get the metrics metadata using HTTP OPTIONS method:\" > curl -X OPTIONS -H \"Accept: application/json\" http://localhost:8080/metrics/base <markup lang=\"json\" title=\"JSON response (truncated):\" >{ \"classloader.currentLoadedClass.count\": { \"unit\": \"none\", \"type\": \"counter\", \"description\": \"Displays the number of classes that are currently loaded in the Java virtual machine.\", \"displayName\": \"Current Loaded Class Count\" }, ... \"jvm.uptime\": { \"unit\": \"milliseconds\", \"type\": \"gauge\", \"description\": \"Displays the start time of the Java virtual machine in milliseconds. This attribute displays the approximate time when the Java virtual machine started.\", \"displayName\": \"JVM Uptime\" }, ... \"memory.usedHeap\": { \"unit\": \"bytes\", \"type\": \"gauge\", \"description\": \"Displays the amount of used heap memory in bytes.\", \"displayName\": \"Used Heap Memory\" } } ",
            "title": "Metrics Metadata"
        },
        {
            "location": "/mp/guides/05_metrics",
            "text": " There are four metrics that you can use by annotating a method: @Counted - Register a Counter metric @Timed - Register a Timer metric @Metered - Register a Meter metric @SimplyTimed - Register a SimpleTimer metric The following example will demonstrate how to use the @Counted annotation to track the number of times the /cards endpoint is called. <markup lang=\"java\" title=\"Create a new class GreetingCards with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import javax.enterprise.context.RequestScoped; import javax.json.Json; import javax.json.JsonBuilderFactory; import javax.json.JsonObject; import javax.ws.rs.GET; import javax.ws.rs.Path; import javax.ws.rs.Produces; import javax.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.annotation.Counted; @Path(\"/cards\") @RequestScoped public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"any-card\") public JsonObject anyCard() throws InterruptedException { return createResponse(\"Here are some random cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } } This class is annotated with Path which sets the path for this resource as /cards . The @RequestScoped annotation defines that this bean is request scoped. The request scope is active only for the duration of one web service invocation and it is destroyed at the end of that invocation. The annotation @Counted will register a Counter metric for this method, creating it if needed. The counter is incremented each time the anyCards method is called. The name attribute is optional. For Metrics 1.1, you must set monotonic field to true to force the count to increment when entering the method. The default behavior is to decrement when exiting the method. Here is an example: @Counted(name = \"any-card\", monotonic = true) . <markup lang=\"bash\" title=\"Build and run the application, then invoke the application endpoints below:\" >curl http://localhost:8080/cards curl http://localhost:8080/cards curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response:\" >{ \"io.helidon.examples.quickstart.mp.GreetingCards.any-card\":2 } The any-card count is two, since you invoked the endpoint twice. Notice the counter is fully qualified. You can remove the package prefix by using the absolute=true field in the @Counted annotation. You must use absolute=false for class-level annotations. ",
            "title": "Method Level Metrics"
        },
        {
            "location": "/mp/guides/05_metrics",
            "text": " The @Timed , @Metered , and @SimplyTimed annotations can also be used with a method. For the following example. you can just annotate the same method with @Metered and @Timed . These metrics collect significant information about the measured methods, but at a cost of some overhead and more complicated output. Use @SimplyTimed in cases where capturing the invocation count and the total elapsed time spent in a block of code is sufficient. Note that when using multiple annotations on a method, you must give the metrics different names as shown below. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import javax.enterprise.context.RequestScoped; import javax.json.Json; import javax.json.JsonBuilderFactory; import javax.json.JsonObject; import javax.ws.rs.GET; import javax.ws.rs.Path; import javax.ws.rs.Produces; import javax.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.MetricUnits; import org.eclipse.microprofile.metrics.annotation.Counted; import org.eclipse.microprofile.metrics.annotation.Metered; import org.eclipse.microprofile.metrics.annotation.Timed; @Path(\"/cards\") @RequestScoped public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"cardCount\", absolute = true) @Metered(name = \"cardMeter\", absolute = true, unit = MetricUnits.MILLISECONDS) @Timed(name = \"cardTimer\", absolute = true, unit = MetricUnits.MILLISECONDS) public JsonObject anyCard() throws InterruptedException { return createResponse(\"Here are some random cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } } Specify a custom name for the Counter metric and set absolute=true to remove the path prefix from the name. Add the @Metered annotation to get a Meter metric. Add the @Timed annotation to get a Timer metric. <markup lang=\"bash\" title=\"Build and run the application, then invoke the application endpoints below:\" >curl http://localhost:8080/cards curl http://localhost:8080/cards curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response:\" >{ \"cardCount\": 2, \"cardMeter\": { \"count\": 2, \"meanRate\": 0.3664337145491488, \"oneMinRate\": 0.4, \"fiveMinRate\": 0.4, \"fifteenMinRate\": 0.4 }, \"cardTimer\": { \"count\": 2, \"meanRate\": 0.36649792432150535, \"oneMinRate\": 0.4, \"fiveMinRate\": 0.4, \"fifteenMinRate\": 0.4, \"min\": 12944, \"max\": 2078856, \"mean\": 1045900.0, \"stddev\": 1032956.0, \"p50\": 2078856.0, \"p75\": 2078856.0, \"p95\": 2078856.0, \"p98\": 2078856.0, \"p99\": 2078856.0, \"p999\": 2078856.0 } } The Meter metric includes the count field (it is a superset of Counter ). The Timer metric includes the Meter fields (it is a superset of Meter ). ",
            "title": "Additional Method Level Metrics"
        },
        {
            "location": "/mp/guides/05_metrics",
            "text": " You can share a metric across multiple endpoints by specifying the reusable field in the metric annotation as demonstrated below. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import javax.enterprise.context.RequestScoped; import javax.json.Json; import javax.json.JsonBuilderFactory; import javax.json.JsonObject; import javax.ws.rs.GET; import javax.ws.rs.Path; import javax.ws.rs.Produces; import javax.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.annotation.Counted; @Path(\"/cards\") @RequestScoped public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"anyCard\",absolute = true) public JsonObject anyCard() throws InterruptedException { return createResponse(\"Here are some cards ...\"); } @GET @Path(\"/birthday\") @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"specialEventCard\", absolute = true, reusable = true) public JsonObject birthdayCard() throws InterruptedException { return createResponse(\"Here are some birthday cards ...\"); } @GET @Path(\"/wedding\") @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"specialEventCard\", absolute = true, reusable = true) public JsonObject weddingCard() throws InterruptedException { return createResponse(\"Here are some wedding cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } } The /birthday endpoint uses a Counter metric, named specialEventCard . The /wedding endpoint uses the same Counter metric, named specialEventCard . <markup lang=\"bash\" title=\"Build and run the application, then invoke the following endpoints:\" >curl http://localhost:8080/cards/wedding curl http://localhost:8080/cards/birthday curl http://localhost:8080/cards curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response from /metrics/application :\" >{ \"anyCard\": 1, \"specialEventCard\": 2 } Notice that specialEventCard count is two, since you accessed /cards/wedding and /cards/birthday . ",
            "title": "Reusing Metrics"
        },
        {
            "location": "/mp/guides/05_metrics",
            "text": " You can collect metrics at the class-level to aggregate data from all methods in that class using the same metric. The following example introduces a metric to count all card queries. In the following example, the method-level metrics are not needed to aggregate the counts, but they are left in the example to demonstrate the combined output of all three metrics. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import javax.enterprise.context.RequestScoped; import javax.json.Json; import javax.json.JsonBuilderFactory; import javax.json.JsonObject; import javax.ws.rs.GET; import javax.ws.rs.Path; import javax.ws.rs.Produces; import javax.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.annotation.Counted; @Path(\"/cards\") @RequestScoped @Counted(name = \"totalCards\") public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) @Counted(absolute = true) public JsonObject anyCard() throws InterruptedException { return createResponse(\"Here are some random cards ...\"); } @Path(\"/birthday\") @GET @Produces(MediaType.APPLICATION_JSON) @Counted(absolute = true) public JsonObject birthdayCard() throws InterruptedException { return createResponse(\"Here are some birthday cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } } This class is annotated with @Counted , which aggregates count data from all the method that have a Count annotation. Use absolute=true to remove path prefix for method-level annotations. Add a method with a Counter metric to get birthday cards. <markup lang=\"bash\" title=\"Build and run the application, then invoke the following endpoints:\" >curl http://localhost:8080/cards curl http://localhost:8080/cards/birthday curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response from /metrics/application :\" >{ \"anyCard\": 1, \"birthdayCard\": 1, \"io.helidon.examples.quickstart.mp.totalCards.GreetingCards\": 2 } The totalCards count is a total of all the method-level Counter metrics. Class level metric names are always fully qualified. ",
            "title": "Class Level Metrics"
        },
        {
            "location": "/mp/guides/05_metrics",
            "text": " Field level metrics can be injected into managed objects, but they need to be updated by the application code. This annotation can be used on fields of type Meter , Timer , Counter , and Histogram . The following example shows how to use a field-level Counter metric to track cache hits. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import java.util.Random; import javax.enterprise.context.RequestScoped; import javax.inject.Inject; import javax.json.Json; import javax.json.JsonBuilderFactory; import javax.json.JsonObject; import javax.ws.rs.GET; import javax.ws.rs.Path; import javax.ws.rs.Produces; import javax.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.Counter; import org.eclipse.microprofile.metrics.annotation.Counted; import org.eclipse.microprofile.metrics.annotation.Metric; @Path(\"/cards\") @RequestScoped @Counted(name = \"totalCards\") public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @Inject @Metric(name = \"cacheHits\", absolute = true) private Counter cacheHits; @GET @Produces(MediaType.APPLICATION_JSON) @Counted(absolute = true) public JsonObject anyCard() throws InterruptedException { updateStats(); return createResponse(\"Here are some random cards ...\"); } @Path(\"/birthday\") @GET @Produces(MediaType.APPLICATION_JSON) @Counted(absolute = true) public JsonObject birthdayCard() throws InterruptedException { updateStats(); return createResponse(\"Here are some birthday cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } private void updateStats() { if (new Random().nextInt(3) == 1) { cacheHits.inc(); } } } A Counter metric field, cacheHits , is automatically injected by Helidon. Call updateStats() to update the cache hits. Call updateStats() to update the cache hits. Randomly increment the cacheHits counter. <markup lang=\"bash\" title=\"Build and run the application, then invoke the following endpoints:\" >curl http://localhost:8080/cards curl http://localhost:8080/cards curl http://localhost:8080/cards/birthday curl http://localhost:8080/cards/birthday curl http://localhost:8080/cards/birthday curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response from /metrics/application :\" >{ \"anyCard\": 2, \"birthdayCard\": 3, \"cacheHits\": 2, \"io.helidon.examples.quickstart.mp.totalCards.GreetingCards\": 5 } The cache was hit two times out of five queries. ",
            "title": "Field Level Metrics"
        },
        {
            "location": "/mp/guides/05_metrics",
            "text": " The metrics you have tested so far are updated in response to an application REST request, i.e GET /cards . These metrics can be declared in a request scoped class and Helidon will store the metric in the MetricRegistry , so the value persists across requests. When GET /metrics/application is invoked, Helidon will return the current value of the metric stored in the MetricRegistry . The Gauge metric is different from all the other metrics. The application must provide a getter to return the gauge value in an application scoped class. When GET /metrics/application is invoked, Helidon will call the Gauge getter, store that value in the MetricsRegistry , and return it as part of the metrics response payload. So, the Gauge metric value is updated real-time, in response to the get metrics request. The following example demonstrates how to use a Gauge to track application up-time. <markup lang=\"java\" title=\"Create a new GreetingCardsAppMetrics class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.time.Duration; import java.util.concurrent.atomic.AtomicLong; import javax.enterprise.context.ApplicationScoped; import javax.enterprise.context.Initialized; import javax.enterprise.event.Observes; import org.eclipse.microprofile.metrics.annotation.Gauge; @ApplicationScoped public class GreetingCardsAppMetrics { private AtomicLong startTime = new AtomicLong(0); public void onStartUp(@Observes @Initialized(ApplicationScoped.class) Object init) { startTime = new AtomicLong(System.currentTimeMillis()); } @Gauge(unit = \"TimeSeconds\") public long appUpTimeSeconds() { return Duration.ofMillis(System.currentTimeMillis() - startTime.get()).getSeconds(); } } This managed object must be application scoped to properly register and use the Gauge metric. Declare an AtomicLong field to hold the start time of the application. Initialize the application start time. Return the application appUpTimeSeconds metric, which will be included in the application metrics. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code to simplify the metrics output:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import javax.enterprise.context.RequestScoped; import javax.json.Json; import javax.json.JsonBuilderFactory; import javax.json.JsonObject; import javax.ws.rs.GET; import javax.ws.rs.Path; import javax.ws.rs.Produces; import javax.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.annotation.Counted; @Path(\"/cards\") @RequestScoped public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"cardCount\", absolute = true) public JsonObject anyCard() throws InterruptedException { return createResponse(\"Here are some random cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } } <markup lang=\"bash\" title=\"Build and run the application, then invoke the application metrics endpoint:\" >curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response from /metrics/application :\" >{ \"cardCount\": 0, \"io.helidon.examples.quickstart.mp.GreetingCardsAppMetrics.appUpTimeSeconds\": 6 } The application has been running for 6 seconds. ",
            "title": "Gauge Metric"
        },
        {
            "location": "/mp/guides/05_metrics",
            "text": " You can create application-specific metrics and integrate them with Helidon using CDI. To add a new metric, simply annotate the JAX-RS resource with one of the metric annotations. Metrics can be injected at the class, method, and field-levels. This document shows examples of all three. Helidon will automatically create and register annotated application metrics and store them in the application MetricRegistry , which also contains the metric metadata. The metrics will exist for the lifetime of the application. Each metric annotation has mandatory and optional fields. The name field, for example, is optional. Method Level Metrics There are four metrics that you can use by annotating a method: @Counted - Register a Counter metric @Timed - Register a Timer metric @Metered - Register a Meter metric @SimplyTimed - Register a SimpleTimer metric The following example will demonstrate how to use the @Counted annotation to track the number of times the /cards endpoint is called. <markup lang=\"java\" title=\"Create a new class GreetingCards with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import javax.enterprise.context.RequestScoped; import javax.json.Json; import javax.json.JsonBuilderFactory; import javax.json.JsonObject; import javax.ws.rs.GET; import javax.ws.rs.Path; import javax.ws.rs.Produces; import javax.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.annotation.Counted; @Path(\"/cards\") @RequestScoped public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"any-card\") public JsonObject anyCard() throws InterruptedException { return createResponse(\"Here are some random cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } } This class is annotated with Path which sets the path for this resource as /cards . The @RequestScoped annotation defines that this bean is request scoped. The request scope is active only for the duration of one web service invocation and it is destroyed at the end of that invocation. The annotation @Counted will register a Counter metric for this method, creating it if needed. The counter is incremented each time the anyCards method is called. The name attribute is optional. For Metrics 1.1, you must set monotonic field to true to force the count to increment when entering the method. The default behavior is to decrement when exiting the method. Here is an example: @Counted(name = \"any-card\", monotonic = true) . <markup lang=\"bash\" title=\"Build and run the application, then invoke the application endpoints below:\" >curl http://localhost:8080/cards curl http://localhost:8080/cards curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response:\" >{ \"io.helidon.examples.quickstart.mp.GreetingCards.any-card\":2 } The any-card count is two, since you invoked the endpoint twice. Notice the counter is fully qualified. You can remove the package prefix by using the absolute=true field in the @Counted annotation. You must use absolute=false for class-level annotations. Additional Method Level Metrics The @Timed , @Metered , and @SimplyTimed annotations can also be used with a method. For the following example. you can just annotate the same method with @Metered and @Timed . These metrics collect significant information about the measured methods, but at a cost of some overhead and more complicated output. Use @SimplyTimed in cases where capturing the invocation count and the total elapsed time spent in a block of code is sufficient. Note that when using multiple annotations on a method, you must give the metrics different names as shown below. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import javax.enterprise.context.RequestScoped; import javax.json.Json; import javax.json.JsonBuilderFactory; import javax.json.JsonObject; import javax.ws.rs.GET; import javax.ws.rs.Path; import javax.ws.rs.Produces; import javax.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.MetricUnits; import org.eclipse.microprofile.metrics.annotation.Counted; import org.eclipse.microprofile.metrics.annotation.Metered; import org.eclipse.microprofile.metrics.annotation.Timed; @Path(\"/cards\") @RequestScoped public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"cardCount\", absolute = true) @Metered(name = \"cardMeter\", absolute = true, unit = MetricUnits.MILLISECONDS) @Timed(name = \"cardTimer\", absolute = true, unit = MetricUnits.MILLISECONDS) public JsonObject anyCard() throws InterruptedException { return createResponse(\"Here are some random cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } } Specify a custom name for the Counter metric and set absolute=true to remove the path prefix from the name. Add the @Metered annotation to get a Meter metric. Add the @Timed annotation to get a Timer metric. <markup lang=\"bash\" title=\"Build and run the application, then invoke the application endpoints below:\" >curl http://localhost:8080/cards curl http://localhost:8080/cards curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response:\" >{ \"cardCount\": 2, \"cardMeter\": { \"count\": 2, \"meanRate\": 0.3664337145491488, \"oneMinRate\": 0.4, \"fiveMinRate\": 0.4, \"fifteenMinRate\": 0.4 }, \"cardTimer\": { \"count\": 2, \"meanRate\": 0.36649792432150535, \"oneMinRate\": 0.4, \"fiveMinRate\": 0.4, \"fifteenMinRate\": 0.4, \"min\": 12944, \"max\": 2078856, \"mean\": 1045900.0, \"stddev\": 1032956.0, \"p50\": 2078856.0, \"p75\": 2078856.0, \"p95\": 2078856.0, \"p98\": 2078856.0, \"p99\": 2078856.0, \"p999\": 2078856.0 } } The Meter metric includes the count field (it is a superset of Counter ). The Timer metric includes the Meter fields (it is a superset of Meter ). Reusing Metrics You can share a metric across multiple endpoints by specifying the reusable field in the metric annotation as demonstrated below. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import javax.enterprise.context.RequestScoped; import javax.json.Json; import javax.json.JsonBuilderFactory; import javax.json.JsonObject; import javax.ws.rs.GET; import javax.ws.rs.Path; import javax.ws.rs.Produces; import javax.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.annotation.Counted; @Path(\"/cards\") @RequestScoped public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"anyCard\",absolute = true) public JsonObject anyCard() throws InterruptedException { return createResponse(\"Here are some cards ...\"); } @GET @Path(\"/birthday\") @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"specialEventCard\", absolute = true, reusable = true) public JsonObject birthdayCard() throws InterruptedException { return createResponse(\"Here are some birthday cards ...\"); } @GET @Path(\"/wedding\") @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"specialEventCard\", absolute = true, reusable = true) public JsonObject weddingCard() throws InterruptedException { return createResponse(\"Here are some wedding cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } } The /birthday endpoint uses a Counter metric, named specialEventCard . The /wedding endpoint uses the same Counter metric, named specialEventCard . <markup lang=\"bash\" title=\"Build and run the application, then invoke the following endpoints:\" >curl http://localhost:8080/cards/wedding curl http://localhost:8080/cards/birthday curl http://localhost:8080/cards curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response from /metrics/application :\" >{ \"anyCard\": 1, \"specialEventCard\": 2 } Notice that specialEventCard count is two, since you accessed /cards/wedding and /cards/birthday . Class Level Metrics You can collect metrics at the class-level to aggregate data from all methods in that class using the same metric. The following example introduces a metric to count all card queries. In the following example, the method-level metrics are not needed to aggregate the counts, but they are left in the example to demonstrate the combined output of all three metrics. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import javax.enterprise.context.RequestScoped; import javax.json.Json; import javax.json.JsonBuilderFactory; import javax.json.JsonObject; import javax.ws.rs.GET; import javax.ws.rs.Path; import javax.ws.rs.Produces; import javax.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.annotation.Counted; @Path(\"/cards\") @RequestScoped @Counted(name = \"totalCards\") public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) @Counted(absolute = true) public JsonObject anyCard() throws InterruptedException { return createResponse(\"Here are some random cards ...\"); } @Path(\"/birthday\") @GET @Produces(MediaType.APPLICATION_JSON) @Counted(absolute = true) public JsonObject birthdayCard() throws InterruptedException { return createResponse(\"Here are some birthday cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } } This class is annotated with @Counted , which aggregates count data from all the method that have a Count annotation. Use absolute=true to remove path prefix for method-level annotations. Add a method with a Counter metric to get birthday cards. <markup lang=\"bash\" title=\"Build and run the application, then invoke the following endpoints:\" >curl http://localhost:8080/cards curl http://localhost:8080/cards/birthday curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response from /metrics/application :\" >{ \"anyCard\": 1, \"birthdayCard\": 1, \"io.helidon.examples.quickstart.mp.totalCards.GreetingCards\": 2 } The totalCards count is a total of all the method-level Counter metrics. Class level metric names are always fully qualified. Field Level Metrics Field level metrics can be injected into managed objects, but they need to be updated by the application code. This annotation can be used on fields of type Meter , Timer , Counter , and Histogram . The following example shows how to use a field-level Counter metric to track cache hits. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import java.util.Random; import javax.enterprise.context.RequestScoped; import javax.inject.Inject; import javax.json.Json; import javax.json.JsonBuilderFactory; import javax.json.JsonObject; import javax.ws.rs.GET; import javax.ws.rs.Path; import javax.ws.rs.Produces; import javax.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.Counter; import org.eclipse.microprofile.metrics.annotation.Counted; import org.eclipse.microprofile.metrics.annotation.Metric; @Path(\"/cards\") @RequestScoped @Counted(name = \"totalCards\") public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @Inject @Metric(name = \"cacheHits\", absolute = true) private Counter cacheHits; @GET @Produces(MediaType.APPLICATION_JSON) @Counted(absolute = true) public JsonObject anyCard() throws InterruptedException { updateStats(); return createResponse(\"Here are some random cards ...\"); } @Path(\"/birthday\") @GET @Produces(MediaType.APPLICATION_JSON) @Counted(absolute = true) public JsonObject birthdayCard() throws InterruptedException { updateStats(); return createResponse(\"Here are some birthday cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } private void updateStats() { if (new Random().nextInt(3) == 1) { cacheHits.inc(); } } } A Counter metric field, cacheHits , is automatically injected by Helidon. Call updateStats() to update the cache hits. Call updateStats() to update the cache hits. Randomly increment the cacheHits counter. <markup lang=\"bash\" title=\"Build and run the application, then invoke the following endpoints:\" >curl http://localhost:8080/cards curl http://localhost:8080/cards curl http://localhost:8080/cards/birthday curl http://localhost:8080/cards/birthday curl http://localhost:8080/cards/birthday curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response from /metrics/application :\" >{ \"anyCard\": 2, \"birthdayCard\": 3, \"cacheHits\": 2, \"io.helidon.examples.quickstart.mp.totalCards.GreetingCards\": 5 } The cache was hit two times out of five queries. Gauge Metric The metrics you have tested so far are updated in response to an application REST request, i.e GET /cards . These metrics can be declared in a request scoped class and Helidon will store the metric in the MetricRegistry , so the value persists across requests. When GET /metrics/application is invoked, Helidon will return the current value of the metric stored in the MetricRegistry . The Gauge metric is different from all the other metrics. The application must provide a getter to return the gauge value in an application scoped class. When GET /metrics/application is invoked, Helidon will call the Gauge getter, store that value in the MetricsRegistry , and return it as part of the metrics response payload. So, the Gauge metric value is updated real-time, in response to the get metrics request. The following example demonstrates how to use a Gauge to track application up-time. <markup lang=\"java\" title=\"Create a new GreetingCardsAppMetrics class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.time.Duration; import java.util.concurrent.atomic.AtomicLong; import javax.enterprise.context.ApplicationScoped; import javax.enterprise.context.Initialized; import javax.enterprise.event.Observes; import org.eclipse.microprofile.metrics.annotation.Gauge; @ApplicationScoped public class GreetingCardsAppMetrics { private AtomicLong startTime = new AtomicLong(0); public void onStartUp(@Observes @Initialized(ApplicationScoped.class) Object init) { startTime = new AtomicLong(System.currentTimeMillis()); } @Gauge(unit = \"TimeSeconds\") public long appUpTimeSeconds() { return Duration.ofMillis(System.currentTimeMillis() - startTime.get()).getSeconds(); } } This managed object must be application scoped to properly register and use the Gauge metric. Declare an AtomicLong field to hold the start time of the application. Initialize the application start time. Return the application appUpTimeSeconds metric, which will be included in the application metrics. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code to simplify the metrics output:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import javax.enterprise.context.RequestScoped; import javax.json.Json; import javax.json.JsonBuilderFactory; import javax.json.JsonObject; import javax.ws.rs.GET; import javax.ws.rs.Path; import javax.ws.rs.Produces; import javax.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.annotation.Counted; @Path(\"/cards\") @RequestScoped public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"cardCount\", absolute = true) public JsonObject anyCard() throws InterruptedException { return createResponse(\"Here are some random cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } } <markup lang=\"bash\" title=\"Build and run the application, then invoke the application metrics endpoint:\" >curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response from /metrics/application :\" >{ \"cardCount\": 0, \"io.helidon.examples.quickstart.mp.GreetingCardsAppMetrics.appUpTimeSeconds\": 6 } The application has been running for 6 seconds. ",
            "title": "Application-Specific Metrics Data"
        },
        {
            "location": "/mp/guides/05_metrics",
            "text": " The following example shows how to integrate the Helidon MP application with Kubernetes. <markup lang=\"bash\" title=\"Stop the application and build the docker image:\" >docker build -t helidon-metrics-mp . <markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named metrics.yaml , with the following content:\" >kind: Service apiVersion: v1 metadata: name: helidon-metrics labels: app: helidon-metrics annotations: prometheus.io/scrape: 'true' spec: type: NodePort selector: app: helidon-metrics ports: - port: 8080 targetPort: 8080 name: http --- kind: Deployment apiVersion: apps/v1 metadata: name: helidon-metrics spec: replicas: 1 selector: matchLabels: app: helidon-metrics template: metadata: labels: app: helidon-metrics version: v1 spec: containers: - name: helidon-metrics image: helidon-metrics-mp imagePullPolicy: IfNotPresent ports: - containerPort: 8080 A service of type NodePort that serves the default routes on port 8080 . An annotation that will allow Prometheus to discover and scrape the application pod. A deployment with one replica of a pod. <markup lang=\"bash\" title=\"Create and deploy the application into Kubernetes:\" >kubectl apply -f ./metrics.yaml <markup lang=\"bash\" title=\"Get the service information:\" >kubectl get service/helidon-metrics <markup lang=\"bash\" >NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE helidon-metrics NodePort 10.99.159.2 &lt;none&gt; 8080:31143/TCP 8s A service of type NodePort that serves the default routes on port 31143 . <markup lang=\"bash\" title=\"Verify the metrics endpoint using port 30116 , your port will likely be different:\" >curl http://localhost:31143/metrics Leave the application running in Kubernetes since it will be used for Prometheus integration. ",
            "title": "Kubernetes Integration"
        },
        {
            "location": "/mp/guides/05_metrics",
            "text": " The metrics service that you just deployed into Kubernetes is already annotated with prometheus.io/scrape: . This will allow Prometheus to discover the service and scrape the metrics. In this exercise, you will install Prometheus into Kubernetes, then verify that it discovered the Helidon metrics in your application. <markup lang=\"bash\" title=\"Install Prometheus and wait until the pod is ready:\" >helm install stable/prometheus --name metrics export POD_NAME=$(kubectl get pods --namespace default -l \"app=prometheus,component=server\" -o jsonpath=\"{.items[0].metadata.name}\") kubectl get pod $POD_NAME You will see output similar to the following. Repeat the kubectl get pod command until you see 2/2 and Running . This may take up to one minute. <markup lang=\"bash\" >metrics-prometheus-server-5fc5dc86cb-79lk4 2/2 Running 0 46s <markup lang=\"bash\" title=\"Create a port-forward so you can access the server URL:\" >kubectl --namespace default port-forward $POD_NAME 7090:9090 Now open your browser and navigate to http://localhost:7090/targets . Search for helidon on the page and you will see your Helidon application as one of the Prometheus targets. ",
            "title": "Prometheus Integration"
        },
        {
            "location": "/mp/guides/05_metrics",
            "text": " You can now delete the Kubernetes resources that were just created during this example. <markup lang=\"bash\" title=\"Delete the Prometheus Kubernetes resources:\" >helm delete --purge metrics <markup lang=\"bash\" title=\"Delete the application Kubernetes resources:\" >kubectl delete -f ./metrics.yaml ",
            "title": "Final Cleanup"
        },
        {
            "location": "/mp/guides/05_metrics",
            "text": " Kubernetes Integration The following example shows how to integrate the Helidon MP application with Kubernetes. <markup lang=\"bash\" title=\"Stop the application and build the docker image:\" >docker build -t helidon-metrics-mp . <markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named metrics.yaml , with the following content:\" >kind: Service apiVersion: v1 metadata: name: helidon-metrics labels: app: helidon-metrics annotations: prometheus.io/scrape: 'true' spec: type: NodePort selector: app: helidon-metrics ports: - port: 8080 targetPort: 8080 name: http --- kind: Deployment apiVersion: apps/v1 metadata: name: helidon-metrics spec: replicas: 1 selector: matchLabels: app: helidon-metrics template: metadata: labels: app: helidon-metrics version: v1 spec: containers: - name: helidon-metrics image: helidon-metrics-mp imagePullPolicy: IfNotPresent ports: - containerPort: 8080 A service of type NodePort that serves the default routes on port 8080 . An annotation that will allow Prometheus to discover and scrape the application pod. A deployment with one replica of a pod. <markup lang=\"bash\" title=\"Create and deploy the application into Kubernetes:\" >kubectl apply -f ./metrics.yaml <markup lang=\"bash\" title=\"Get the service information:\" >kubectl get service/helidon-metrics <markup lang=\"bash\" >NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE helidon-metrics NodePort 10.99.159.2 &lt;none&gt; 8080:31143/TCP 8s A service of type NodePort that serves the default routes on port 31143 . <markup lang=\"bash\" title=\"Verify the metrics endpoint using port 30116 , your port will likely be different:\" >curl http://localhost:31143/metrics Leave the application running in Kubernetes since it will be used for Prometheus integration. Prometheus Integration The metrics service that you just deployed into Kubernetes is already annotated with prometheus.io/scrape: . This will allow Prometheus to discover the service and scrape the metrics. In this exercise, you will install Prometheus into Kubernetes, then verify that it discovered the Helidon metrics in your application. <markup lang=\"bash\" title=\"Install Prometheus and wait until the pod is ready:\" >helm install stable/prometheus --name metrics export POD_NAME=$(kubectl get pods --namespace default -l \"app=prometheus,component=server\" -o jsonpath=\"{.items[0].metadata.name}\") kubectl get pod $POD_NAME You will see output similar to the following. Repeat the kubectl get pod command until you see 2/2 and Running . This may take up to one minute. <markup lang=\"bash\" >metrics-prometheus-server-5fc5dc86cb-79lk4 2/2 Running 0 46s <markup lang=\"bash\" title=\"Create a port-forward so you can access the server URL:\" >kubectl --namespace default port-forward $POD_NAME 7090:9090 Now open your browser and navigate to http://localhost:7090/targets . Search for helidon on the page and you will see your Helidon application as one of the Prometheus targets. Final Cleanup You can now delete the Kubernetes resources that were just created during this example. <markup lang=\"bash\" title=\"Delete the Prometheus Kubernetes resources:\" >helm delete --purge metrics <markup lang=\"bash\" title=\"Delete the application Kubernetes resources:\" >kubectl delete -f ./metrics.yaml ",
            "title": "Integration with Kubernetes and Prometheus"
        },
        {
            "location": "/mp/guides/05_metrics",
            "text": " This guide demonstrated how to use metrics in a Helidon MP application using various combinations of metrics and scopes. Access metrics for all three scopes: base, vendor, and application Configure application metrics at the class, method, and field-level Integrate Helidon metrics with Kubernetes and Prometheus Refer to the following references for additional information: MicroProfile Metrics specification at https://github.com/eclipse/microprofile-metrics/releases/tag/2.0 MicroProfile Metrics Javadoc at https://javadoc.io/doc/org.eclipse.microprofile.metrics/microprofile-metrics-api/2.0.0 Helidon Javadoc at https://helidon.io/docs/latest/apidocs/index.html?overview-summary.html ",
            "title": "Summary"
        },
        {
            "location": "/mp/guides/05_metrics",
            "text": " For this 30 minute tutorial, you will need the following: <div class=\"table__overflow elevation-1 flex sm7 \"> A Helidon MP Application You can use your own application or use the Helidon MP Quickstart to create a sample application. Java&#160;SE&#160;11 ( Open&#160;JDK&#160;11 ) Helidon requires Java 11+. Maven 3.6.1+ Helidon requires Maven 3.6.1+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop ). Helm To manage Kubernetes applications. <markup lang=\"bash\" title=\"Verify Prerequisites\" >java -version mvn --version docker --version kubectl version --short <markup lang=\"bash\" title=\"Setting JAVA_HOME\" ># On Mac export JAVA_HOME=`/usr/libexec/java_home -v 11` # On Linux # Use the appropriate path to your JDK export JAVA_HOME=/usr/lib/jvm/jdk-11 Create a Sample Helidon MP Project Use the Helidon MP Maven archetype to create a simple project that can be used for the examples in this guide. <markup lang=\"bash\" title=\"Run the Maven archetype\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-mp \\ -DarchetypeVersion=2.5.4 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-mp \\ -Dpackage=io.helidon.examples.quickstart.mp Using the Built-In Metrics Helidon provides three scopes of metrics: base, vendor, and application. Here are the metric endpoints: /metrics/base - Base metrics data as specified by the MicroProfile Metrics specification. /metrics/vendor - Helidon-specific metrics data. /metrics/application - Application-specific metrics data. The /metrics endpoint will return data for all scopes. The built-in metrics fall into three categories: JVM behavior (in the base registry), basic key performance indicators for request handling (in the vendor registry), and thread pool utilization (also in the vendor registry). A later section describes the key performance indicator metrics in detail. The following example demonstrates how to use the other built-in metrics. All examples are executed from the root directory of your project (helidon-quickstart-mp). <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-mp.jar Metrics can be returned in either text format (the default), or JSON. The text format uses OpenMetrics (Prometheus) Text Format, see https://prometheus.io/docs/instrumenting/exposition_formats/#text-format-details . <markup lang=\"bash\" title=\"Verify the metrics endpoint in a new terminal window:\" >curl http://localhost:8080/metrics <markup lang=\"text\" title=\"Text response:\" ># TYPE base_REST_request_total counter # HELP base_REST_request_total The number of invocations and total response time of RESTful resource methods since the start of the server. base_REST_request_total{class=\"io.helidon.examples.quickstart.mp.GreetResource\",method=\"getDefaultMessage\"} 0 # TYPE base_REST_request_elapsedTime_seconds gauge base_REST_request_elapsedTime_seconds{class=\"io.helidon.examples.quickstart.mp.GreetResource\",method=\"getDefaultMessage\"} 0.0 base_REST_request_total{class=\"io.helidon.examples.quickstart.mp.GreetResource\",method=\"getMessage_java.lang.String\"} 0 base_REST_request_elapsedTime_seconds{class=\"io.helidon.examples.quickstart.mp.GreetResource\",method=\"getMessage_java.lang.String\"} 0.0 base_REST_request_total{class=\"io.helidon.examples.quickstart.mp.GreetResource\",method=\"updateGreeting_javax.json.JsonObject\"} 0 base_REST_request_elapsedTime_seconds{class=\"io.helidon.examples.quickstart.mp.GreetResource\",method=\"updateGreeting_javax.json.JsonObject\"} 0.0 # TYPE base:classloader_current_loaded_class_count counter # HELP base:classloader_current_loaded_class_count Displays the number of classes that are currently loaded in the Java virtual machine. base:classloader_current_loaded_class_count 7511 # TYPE base:classloader_total_loaded_class_count counter # HELP base:classloader_total_loaded_class_count Displays the total number of classes that have been loaded since the Java virtual machine has started execution. base:classloader_total_loaded_class_count 7512 ... You can get the same data in JSON format. <markup lang=\"bash\" title=\"Verify the metrics endpoint with an HTTP accept header:\" >curl -H \"Accept: application/json\" http://localhost:8080/metrics <markup lang=\"json\" title=\"JSON response:\" >{ \"base\": { \"REST.request\": { \"count;class=io.helidon.examples.quickstart.mp.GreetResource;method=getDefaultMessage\":0, \"elapsedTime;class=io.helidon.examples.quickstart.mp.GreetResource;method=getDefaultMessage\":0.0, \"count;class=io.helidon.examples.quickstart.mp.GreetResource;method=getMessage_java.lang.String\":0, \"elapsedTime;class=io.helidon.examples.quickstart.mp.GreetResource;method=getMessage_java.lang.String\":0.0, \"count;class=io.helidon.examples.quickstart.mp.GreetResource;method=updateGreeting_javax.json.JsonObject\":0, \"elapsedTime;class=io.helidon.examples.quickstart.mp.GreetResource;method=updateGreeting_javax.json.JsonObject\":0.0 }, \"classloader.currentLoadedClass.count\": 7534, \"classloader.totalLoadedClass.count\": 7538, \"classloader.totalUnloadedClass.count\": 1, \"cpu.availableProcessors\": 4, \"cpu.systemLoadAverage\": 2.83349609375, \"gc.PS MarkSweep.count\": 2, \"gc.PS MarkSweep.time\": 77, \"gc.PS Scavenge.count\": 5, \"gc.PS Scavenge.time\": 37, \"jvm.uptime\": 727588, \"memory.committedHeap\": 284164096, \"memory.maxHeap\": 3817865216, \"memory.usedHeap\": 53283088, \"thread.count\": 44, \"thread.daemon.count\": 35, \"thread.max.count\": 44 }, \"vendor\": { \"executor-service.active-count;poolIndex=0;supplierCategory=helidon-thread-pool-2;supplierIndex=0\": 0, \"executor-service.completed-task-count;poolIndex=0;supplierCategory=helidon-thread-pool-2;supplierIndex=0\": 0, \"executor-service.largest-pool-size;poolIndex=0;supplierCategory=helidon-thread-pool-2;supplierIndex=0\": 5, \"executor-service.pool-size;poolIndex=0;supplierCategory=helidon-thread-pool-2;supplierIndex=0\": 5, \"executor-service.queue.remaining-capacity;poolIndex=0;supplierCategory=helidon-thread-pool-2;supplierIndex=0\": 10000, \"executor-service.queue.size;poolIndex=0;supplierCategory=helidon-thread-pool-2;supplierIndex=0\": 0, \"executor-service.task-count;poolIndex=0;supplierCategory=helidon-thread-pool-2;supplierIndex=0\": 0, \"requests.count\": 6, \"requests.meter\": { \"count\": 6, \"meanRate\": 0.008275992296704147, \"oneMinRate\": 0.01576418632772332, \"fiveMinRate\": 0.006695060022357365, \"fifteenMinRate\": 0.0036382699664488415 } } } You can get a single metric by specifying the name in the URL path. <markup lang=\"bash\" title=\"Get the Helidon requests.meter metric:\" >curl -H \"Accept: application/json\" http://localhost:8080/metrics/vendor/requests.meter <markup lang=\"json\" title=\"JSON response:\" >{ \"requests.meter\": { \"count\": 6, \"meanRate\": 0.008275992296704147, \"oneMinRate\": 0.01576418632772332, \"fiveMinRate\": 0.006695060022357365, \"fifteenMinRate\": 0.0036382699664488415 } } You cannot get the individual fields of a metric. For example, you cannot target http://localhost:8080/metrics/vendor/requests.meter.count . The base metrics illustrated above provide some insight into the behavior of the JVM in which the server runs. The vendor metrics shown above appear in two groups: Helidon thread pools Helidon uses these thread pools for its own internal work, and your application can also use Helidon-managed thread pools if it needs to do work asynchronously. (See this example .) The metrics in this group show information about the thread pools which can help you assess how efficiently they are utilized. Helidon uses tags to distinguish the metrics which describe different thread pools. In some cases the specific metrics exposed depend on the particular type of thread pool. basic key performance indicators These metrics give an idea of the request traffic the server is handling. See the later section for more information on the basic and extended key performance indicator metrics. Controlling Metrics Behavior By adding a metrics section to your application configuration you can control how the Helidon metrics subsystem behaves in any of several ways. Disable metrics subsystem entirely . Control REST.request metrics. Identify groups of metrics to control: registered by a particular component , and by metric registry (application, vendor, and base) and within a registry by metric names which match patterns you provide. Select whether to collect extended key performance indicator metrics . Disabling Metrics Subsystem Entirely By default, if your application depends on the helidon-metrics Maven module then full-featured metrics are enabled. You can disable the metrics subsystem entirely using configuration: <markup lang=\"properties\" title=\"Configuration properties file disabling metrics\" >metrics.enabled=false With metrics processing disabled, Helidon never updates any metrics and the /metrics endpoints respond with 404 plus a message that the metrics subsystem is disabled. Controlling REST.request Metrics Helidon implements the optional family of metrics, all with the name REST.request , as described in the MicroProfile Metrics specification . Each instance is a SimpleTimer with tags class and method identifying exactly which REST endpoint Java method that instance measures. By default, Helidon MP does not enable this feature. Enable it by editing your application configuration to set metrics.rest-request.enabled to true . Note that the applications you generate using the full Helidon archetype do enable this feature in the generated config file. You can see the results in the sample output shown in earlier example runs. Enabling and Disabling Metrics Usage by a Component Helidon contains several components and integrations which register and update metrics. Depending on how the component is written, you might be able to disable just that component&#8217;s use of metrics: <markup lang=\"properties\" title=\"Configuration properties file disabling a component&#8217;s use of metrics\" >some-component.metrics.enabled=false Check the documentation for a specific component to find out whether that component uses metrics and whether it allows you to disable that use. If you disable a component&#8217;s use of metrics, Helidon does not register the component&#8217;s metrics in the visible metrics registries nor do those metrics ever update their values. The response from the /metrics endpoint excludes that component&#8217;s metrics. Note that if you disable metrics processing entirely, no component updates its metrics regardless of any component-level metrics settings. Controlling Metrics By Registry Type and Metric Name You can control the collection and reporting of metrics by registry type and metric name within registry type. Disabling All Metrics of a Given Registry Type To disable all metrics in a given registry type (application, vendor, or base), add one or more groups to the configuration: <markup lang=\"properties\" title=\"Disabling base and vendor metrics (properties format)\" >metrics.registries.0.type = base metrics.registries.0.enabled = false metrics.registries.1.type = vendor metrics.registries.1.enabled = false <markup lang=\"yaml\" title=\"Disabling base and vendor metrics (YAML format)\" >metrics: registries: - type: base enabled: false - type: vendor enables: false Controlling Metrics by Metric Name You can be even more selective. Within a registry type you can configure up to two regular expression patterns: one matching metric names to exclude , and one matching metric names to include . Helidon updates and reports a metric only if two conditions hold: the metric name does not match the exclude regex pattern (if you define one), and either there is no include regex pattern, or the metric name matches the include pattern. Caution Make sure any include regex pattern you specify matches all the metric names you want to capture. Suppose your application creates and updates a group of metrics with names such as myapp.xxx.queries , myapp.xxx.creates , myapp.xxx.updates , and myapp.xxx.deletes where xxx can be either supplier or customer . The following example gathers all metrics except those from your application regarding suppliers: <markup lang=\"properties\" title=\"Disabling metrics by name (properties format)\" >metrics.registries.0.type = application metrics.registries.0.filter.exclude = myapp\\.supplier\\..* The following settings select the particular subset of the metrics created in your application code representing updates of customers and suppliers: <markup lang=\"properties\" title=\"Enabling metrics by name (properties format)\" >metrics.registries.0.type = application metrics.registries.0.filter.include = myapp\\..*\\.updates If you use the YAML configuration format, enclose the regex patterns in single-quote marks: <markup lang=\"yaml\" title=\"Enabling metrics by name (YAML format)\" >metrics: registries: - type: application filter: include: 'myapp\\..*\\.updates' The next example selects only your application&#8217;s metrics while excluding those which refer to deletions: <markup lang=\"properties\" title=\"Combining include and exclude \" >metrics.registries.0.type = application metrics.registries.0.filter.include = myapp\\..* metrics.registries.0.filter.exclude = myapp\\..*/deletes Helidon would not update or report the metric myapp.supplier.queries , for example. To include metrics from your application for both updates and queries (but not for other operations), you could change the settings in the previous example to this: <markup >metrics.registries.0.type = application metrics.registries.0.filter.include = myapp\\..*\\.updates|myapp\\..*\\.queries metrics.registries.0.filter.exclude = myapp\\..*/deletes Collecting Basic and Extended Key Performance Indicator (KPI) Metrics Any time you include the Helidon metrics module in your application, Helidon tracks two basic performance indicator metrics: a Counter of all requests received ( requests.count ), and a Meter of all requests received ( requests.meter ). Helidon MP also includes additional, extended KPI metrics which are disabled by default: current number of requests in-flight - a ConcurrentGauge ( requests.inFlight ) of requests currently being processed long-running requests - a Meter ( requests.longRunning ) measuring the rate at which Helidon processes requests which take at least a given amount of time to complete; configurable, defaults to 10000 milliseconds (10 seconds) load - a Meter ( requests.load ) measuring the rate at which requests are worked on (as opposed to received) deferred - a Meter ( requests.deferred ) measuring the rate at which a request&#8217;s processing is delayed after Helidon receives the request You can enable and control these metrics using configuration: <markup lang=\"properties\" title=\"Configuration properties file controlling extended KPI metrics\" >metrics.key-performance-indicators.extended = true metrics.key-performance-indicators.long-running.threshold-ms = 2000 Metrics Metadata Each metric has associated metadata that describes: name: The name of the metric. units: The unit of the metric such as time (seconds, millisecond), size (bytes, megabytes), etc. type: The type of metric: Counter , Timer , Meter , Histogram , SimpleTimer , or Gauge . You can get the metadata for any scope, such as /metrics/base , as shown below: <markup lang=\"bash\" title=\"Get the metrics metadata using HTTP OPTIONS method:\" > curl -X OPTIONS -H \"Accept: application/json\" http://localhost:8080/metrics/base <markup lang=\"json\" title=\"JSON response (truncated):\" >{ \"classloader.currentLoadedClass.count\": { \"unit\": \"none\", \"type\": \"counter\", \"description\": \"Displays the number of classes that are currently loaded in the Java virtual machine.\", \"displayName\": \"Current Loaded Class Count\" }, ... \"jvm.uptime\": { \"unit\": \"milliseconds\", \"type\": \"gauge\", \"description\": \"Displays the start time of the Java virtual machine in milliseconds. This attribute displays the approximate time when the Java virtual machine started.\", \"displayName\": \"JVM Uptime\" }, ... \"memory.usedHeap\": { \"unit\": \"bytes\", \"type\": \"gauge\", \"description\": \"Displays the amount of used heap memory in bytes.\", \"displayName\": \"Used Heap Memory\" } } Integration with Kubernetes and Prometheus Kubernetes Integration The following example shows how to integrate the Helidon MP application with Kubernetes. <markup lang=\"bash\" title=\"Stop the application and build the docker image:\" >docker build -t helidon-metrics-mp . <markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named metrics.yaml , with the following content:\" >kind: Service apiVersion: v1 metadata: name: helidon-metrics labels: app: helidon-metrics annotations: prometheus.io/scrape: 'true' spec: type: NodePort selector: app: helidon-metrics ports: - port: 8080 targetPort: 8080 name: http --- kind: Deployment apiVersion: apps/v1 metadata: name: helidon-metrics spec: replicas: 1 selector: matchLabels: app: helidon-metrics template: metadata: labels: app: helidon-metrics version: v1 spec: containers: - name: helidon-metrics image: helidon-metrics-mp imagePullPolicy: IfNotPresent ports: - containerPort: 8080 A service of type NodePort that serves the default routes on port 8080 . An annotation that will allow Prometheus to discover and scrape the application pod. A deployment with one replica of a pod. <markup lang=\"bash\" title=\"Create and deploy the application into Kubernetes:\" >kubectl apply -f ./metrics.yaml <markup lang=\"bash\" title=\"Get the service information:\" >kubectl get service/helidon-metrics <markup lang=\"bash\" >NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE helidon-metrics NodePort 10.99.159.2 &lt;none&gt; 8080:31143/TCP 8s A service of type NodePort that serves the default routes on port 31143 . <markup lang=\"bash\" title=\"Verify the metrics endpoint using port 30116 , your port will likely be different:\" >curl http://localhost:31143/metrics Leave the application running in Kubernetes since it will be used for Prometheus integration. Prometheus Integration The metrics service that you just deployed into Kubernetes is already annotated with prometheus.io/scrape: . This will allow Prometheus to discover the service and scrape the metrics. In this exercise, you will install Prometheus into Kubernetes, then verify that it discovered the Helidon metrics in your application. <markup lang=\"bash\" title=\"Install Prometheus and wait until the pod is ready:\" >helm install stable/prometheus --name metrics export POD_NAME=$(kubectl get pods --namespace default -l \"app=prometheus,component=server\" -o jsonpath=\"{.items[0].metadata.name}\") kubectl get pod $POD_NAME You will see output similar to the following. Repeat the kubectl get pod command until you see 2/2 and Running . This may take up to one minute. <markup lang=\"bash\" >metrics-prometheus-server-5fc5dc86cb-79lk4 2/2 Running 0 46s <markup lang=\"bash\" title=\"Create a port-forward so you can access the server URL:\" >kubectl --namespace default port-forward $POD_NAME 7090:9090 Now open your browser and navigate to http://localhost:7090/targets . Search for helidon on the page and you will see your Helidon application as one of the Prometheus targets. Final Cleanup You can now delete the Kubernetes resources that were just created during this example. <markup lang=\"bash\" title=\"Delete the Prometheus Kubernetes resources:\" >helm delete --purge metrics <markup lang=\"bash\" title=\"Delete the application Kubernetes resources:\" >kubectl delete -f ./metrics.yaml Metrics Metadata Each metric has associated metadata that describes: name: The name of the metric. units: The unit of the metric such as time (seconds, millisecond), size (bytes, megabytes), etc. type: The type of metric: Counter , Timer , Meter , Histogram , SimpleTimer , or Gauge . You can get the metadata for any scope, such as /metrics/base , as shown below: <markup lang=\"bash\" title=\"Get the metrics metadata using HTTP OPTIONS method:\" > curl -X OPTIONS -H \"Accept: application/json\" http://localhost:8080/metrics/base <markup lang=\"json\" title=\"JSON response (truncated):\" >{ \"classloader.currentLoadedClass.count\": { \"unit\": \"none\", \"type\": \"counter\", \"description\": \"Displays the number of classes that are currently loaded in the Java virtual machine.\", \"displayName\": \"Current Loaded Class Count\" }, ... \"jvm.uptime\": { \"unit\": \"milliseconds\", \"type\": \"gauge\", \"description\": \"Displays the start time of the Java virtual machine in milliseconds. This attribute displays the approximate time when the Java virtual machine started.\", \"displayName\": \"JVM Uptime\" }, ... \"memory.usedHeap\": { \"unit\": \"bytes\", \"type\": \"gauge\", \"description\": \"Displays the amount of used heap memory in bytes.\", \"displayName\": \"Used Heap Memory\" } } Application-Specific Metrics Data You can create application-specific metrics and integrate them with Helidon using CDI. To add a new metric, simply annotate the JAX-RS resource with one of the metric annotations. Metrics can be injected at the class, method, and field-levels. This document shows examples of all three. Helidon will automatically create and register annotated application metrics and store them in the application MetricRegistry , which also contains the metric metadata. The metrics will exist for the lifetime of the application. Each metric annotation has mandatory and optional fields. The name field, for example, is optional. Method Level Metrics There are four metrics that you can use by annotating a method: @Counted - Register a Counter metric @Timed - Register a Timer metric @Metered - Register a Meter metric @SimplyTimed - Register a SimpleTimer metric The following example will demonstrate how to use the @Counted annotation to track the number of times the /cards endpoint is called. <markup lang=\"java\" title=\"Create a new class GreetingCards with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import javax.enterprise.context.RequestScoped; import javax.json.Json; import javax.json.JsonBuilderFactory; import javax.json.JsonObject; import javax.ws.rs.GET; import javax.ws.rs.Path; import javax.ws.rs.Produces; import javax.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.annotation.Counted; @Path(\"/cards\") @RequestScoped public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"any-card\") public JsonObject anyCard() throws InterruptedException { return createResponse(\"Here are some random cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } } This class is annotated with Path which sets the path for this resource as /cards . The @RequestScoped annotation defines that this bean is request scoped. The request scope is active only for the duration of one web service invocation and it is destroyed at the end of that invocation. The annotation @Counted will register a Counter metric for this method, creating it if needed. The counter is incremented each time the anyCards method is called. The name attribute is optional. For Metrics 1.1, you must set monotonic field to true to force the count to increment when entering the method. The default behavior is to decrement when exiting the method. Here is an example: @Counted(name = \"any-card\", monotonic = true) . <markup lang=\"bash\" title=\"Build and run the application, then invoke the application endpoints below:\" >curl http://localhost:8080/cards curl http://localhost:8080/cards curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response:\" >{ \"io.helidon.examples.quickstart.mp.GreetingCards.any-card\":2 } The any-card count is two, since you invoked the endpoint twice. Notice the counter is fully qualified. You can remove the package prefix by using the absolute=true field in the @Counted annotation. You must use absolute=false for class-level annotations. Additional Method Level Metrics The @Timed , @Metered , and @SimplyTimed annotations can also be used with a method. For the following example. you can just annotate the same method with @Metered and @Timed . These metrics collect significant information about the measured methods, but at a cost of some overhead and more complicated output. Use @SimplyTimed in cases where capturing the invocation count and the total elapsed time spent in a block of code is sufficient. Note that when using multiple annotations on a method, you must give the metrics different names as shown below. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import javax.enterprise.context.RequestScoped; import javax.json.Json; import javax.json.JsonBuilderFactory; import javax.json.JsonObject; import javax.ws.rs.GET; import javax.ws.rs.Path; import javax.ws.rs.Produces; import javax.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.MetricUnits; import org.eclipse.microprofile.metrics.annotation.Counted; import org.eclipse.microprofile.metrics.annotation.Metered; import org.eclipse.microprofile.metrics.annotation.Timed; @Path(\"/cards\") @RequestScoped public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"cardCount\", absolute = true) @Metered(name = \"cardMeter\", absolute = true, unit = MetricUnits.MILLISECONDS) @Timed(name = \"cardTimer\", absolute = true, unit = MetricUnits.MILLISECONDS) public JsonObject anyCard() throws InterruptedException { return createResponse(\"Here are some random cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } } Specify a custom name for the Counter metric and set absolute=true to remove the path prefix from the name. Add the @Metered annotation to get a Meter metric. Add the @Timed annotation to get a Timer metric. <markup lang=\"bash\" title=\"Build and run the application, then invoke the application endpoints below:\" >curl http://localhost:8080/cards curl http://localhost:8080/cards curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response:\" >{ \"cardCount\": 2, \"cardMeter\": { \"count\": 2, \"meanRate\": 0.3664337145491488, \"oneMinRate\": 0.4, \"fiveMinRate\": 0.4, \"fifteenMinRate\": 0.4 }, \"cardTimer\": { \"count\": 2, \"meanRate\": 0.36649792432150535, \"oneMinRate\": 0.4, \"fiveMinRate\": 0.4, \"fifteenMinRate\": 0.4, \"min\": 12944, \"max\": 2078856, \"mean\": 1045900.0, \"stddev\": 1032956.0, \"p50\": 2078856.0, \"p75\": 2078856.0, \"p95\": 2078856.0, \"p98\": 2078856.0, \"p99\": 2078856.0, \"p999\": 2078856.0 } } The Meter metric includes the count field (it is a superset of Counter ). The Timer metric includes the Meter fields (it is a superset of Meter ). Reusing Metrics You can share a metric across multiple endpoints by specifying the reusable field in the metric annotation as demonstrated below. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import javax.enterprise.context.RequestScoped; import javax.json.Json; import javax.json.JsonBuilderFactory; import javax.json.JsonObject; import javax.ws.rs.GET; import javax.ws.rs.Path; import javax.ws.rs.Produces; import javax.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.annotation.Counted; @Path(\"/cards\") @RequestScoped public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"anyCard\",absolute = true) public JsonObject anyCard() throws InterruptedException { return createResponse(\"Here are some cards ...\"); } @GET @Path(\"/birthday\") @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"specialEventCard\", absolute = true, reusable = true) public JsonObject birthdayCard() throws InterruptedException { return createResponse(\"Here are some birthday cards ...\"); } @GET @Path(\"/wedding\") @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"specialEventCard\", absolute = true, reusable = true) public JsonObject weddingCard() throws InterruptedException { return createResponse(\"Here are some wedding cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } } The /birthday endpoint uses a Counter metric, named specialEventCard . The /wedding endpoint uses the same Counter metric, named specialEventCard . <markup lang=\"bash\" title=\"Build and run the application, then invoke the following endpoints:\" >curl http://localhost:8080/cards/wedding curl http://localhost:8080/cards/birthday curl http://localhost:8080/cards curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response from /metrics/application :\" >{ \"anyCard\": 1, \"specialEventCard\": 2 } Notice that specialEventCard count is two, since you accessed /cards/wedding and /cards/birthday . Class Level Metrics You can collect metrics at the class-level to aggregate data from all methods in that class using the same metric. The following example introduces a metric to count all card queries. In the following example, the method-level metrics are not needed to aggregate the counts, but they are left in the example to demonstrate the combined output of all three metrics. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import javax.enterprise.context.RequestScoped; import javax.json.Json; import javax.json.JsonBuilderFactory; import javax.json.JsonObject; import javax.ws.rs.GET; import javax.ws.rs.Path; import javax.ws.rs.Produces; import javax.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.annotation.Counted; @Path(\"/cards\") @RequestScoped @Counted(name = \"totalCards\") public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) @Counted(absolute = true) public JsonObject anyCard() throws InterruptedException { return createResponse(\"Here are some random cards ...\"); } @Path(\"/birthday\") @GET @Produces(MediaType.APPLICATION_JSON) @Counted(absolute = true) public JsonObject birthdayCard() throws InterruptedException { return createResponse(\"Here are some birthday cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } } This class is annotated with @Counted , which aggregates count data from all the method that have a Count annotation. Use absolute=true to remove path prefix for method-level annotations. Add a method with a Counter metric to get birthday cards. <markup lang=\"bash\" title=\"Build and run the application, then invoke the following endpoints:\" >curl http://localhost:8080/cards curl http://localhost:8080/cards/birthday curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response from /metrics/application :\" >{ \"anyCard\": 1, \"birthdayCard\": 1, \"io.helidon.examples.quickstart.mp.totalCards.GreetingCards\": 2 } The totalCards count is a total of all the method-level Counter metrics. Class level metric names are always fully qualified. Field Level Metrics Field level metrics can be injected into managed objects, but they need to be updated by the application code. This annotation can be used on fields of type Meter , Timer , Counter , and Histogram . The following example shows how to use a field-level Counter metric to track cache hits. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import java.util.Random; import javax.enterprise.context.RequestScoped; import javax.inject.Inject; import javax.json.Json; import javax.json.JsonBuilderFactory; import javax.json.JsonObject; import javax.ws.rs.GET; import javax.ws.rs.Path; import javax.ws.rs.Produces; import javax.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.Counter; import org.eclipse.microprofile.metrics.annotation.Counted; import org.eclipse.microprofile.metrics.annotation.Metric; @Path(\"/cards\") @RequestScoped @Counted(name = \"totalCards\") public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @Inject @Metric(name = \"cacheHits\", absolute = true) private Counter cacheHits; @GET @Produces(MediaType.APPLICATION_JSON) @Counted(absolute = true) public JsonObject anyCard() throws InterruptedException { updateStats(); return createResponse(\"Here are some random cards ...\"); } @Path(\"/birthday\") @GET @Produces(MediaType.APPLICATION_JSON) @Counted(absolute = true) public JsonObject birthdayCard() throws InterruptedException { updateStats(); return createResponse(\"Here are some birthday cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } private void updateStats() { if (new Random().nextInt(3) == 1) { cacheHits.inc(); } } } A Counter metric field, cacheHits , is automatically injected by Helidon. Call updateStats() to update the cache hits. Call updateStats() to update the cache hits. Randomly increment the cacheHits counter. <markup lang=\"bash\" title=\"Build and run the application, then invoke the following endpoints:\" >curl http://localhost:8080/cards curl http://localhost:8080/cards curl http://localhost:8080/cards/birthday curl http://localhost:8080/cards/birthday curl http://localhost:8080/cards/birthday curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response from /metrics/application :\" >{ \"anyCard\": 2, \"birthdayCard\": 3, \"cacheHits\": 2, \"io.helidon.examples.quickstart.mp.totalCards.GreetingCards\": 5 } The cache was hit two times out of five queries. Gauge Metric The metrics you have tested so far are updated in response to an application REST request, i.e GET /cards . These metrics can be declared in a request scoped class and Helidon will store the metric in the MetricRegistry , so the value persists across requests. When GET /metrics/application is invoked, Helidon will return the current value of the metric stored in the MetricRegistry . The Gauge metric is different from all the other metrics. The application must provide a getter to return the gauge value in an application scoped class. When GET /metrics/application is invoked, Helidon will call the Gauge getter, store that value in the MetricsRegistry , and return it as part of the metrics response payload. So, the Gauge metric value is updated real-time, in response to the get metrics request. The following example demonstrates how to use a Gauge to track application up-time. <markup lang=\"java\" title=\"Create a new GreetingCardsAppMetrics class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.time.Duration; import java.util.concurrent.atomic.AtomicLong; import javax.enterprise.context.ApplicationScoped; import javax.enterprise.context.Initialized; import javax.enterprise.event.Observes; import org.eclipse.microprofile.metrics.annotation.Gauge; @ApplicationScoped public class GreetingCardsAppMetrics { private AtomicLong startTime = new AtomicLong(0); public void onStartUp(@Observes @Initialized(ApplicationScoped.class) Object init) { startTime = new AtomicLong(System.currentTimeMillis()); } @Gauge(unit = \"TimeSeconds\") public long appUpTimeSeconds() { return Duration.ofMillis(System.currentTimeMillis() - startTime.get()).getSeconds(); } } This managed object must be application scoped to properly register and use the Gauge metric. Declare an AtomicLong field to hold the start time of the application. Initialize the application start time. Return the application appUpTimeSeconds metric, which will be included in the application metrics. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code to simplify the metrics output:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import javax.enterprise.context.RequestScoped; import javax.json.Json; import javax.json.JsonBuilderFactory; import javax.json.JsonObject; import javax.ws.rs.GET; import javax.ws.rs.Path; import javax.ws.rs.Produces; import javax.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.annotation.Counted; @Path(\"/cards\") @RequestScoped public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"cardCount\", absolute = true) public JsonObject anyCard() throws InterruptedException { return createResponse(\"Here are some random cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } } <markup lang=\"bash\" title=\"Build and run the application, then invoke the application metrics endpoint:\" >curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response from /metrics/application :\" >{ \"cardCount\": 0, \"io.helidon.examples.quickstart.mp.GreetingCardsAppMetrics.appUpTimeSeconds\": 6 } The application has been running for 6 seconds. Integration with Kubernetes and Prometheus Kubernetes Integration The following example shows how to integrate the Helidon MP application with Kubernetes. <markup lang=\"bash\" title=\"Stop the application and build the docker image:\" >docker build -t helidon-metrics-mp . <markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named metrics.yaml , with the following content:\" >kind: Service apiVersion: v1 metadata: name: helidon-metrics labels: app: helidon-metrics annotations: prometheus.io/scrape: 'true' spec: type: NodePort selector: app: helidon-metrics ports: - port: 8080 targetPort: 8080 name: http --- kind: Deployment apiVersion: apps/v1 metadata: name: helidon-metrics spec: replicas: 1 selector: matchLabels: app: helidon-metrics template: metadata: labels: app: helidon-metrics version: v1 spec: containers: - name: helidon-metrics image: helidon-metrics-mp imagePullPolicy: IfNotPresent ports: - containerPort: 8080 A service of type NodePort that serves the default routes on port 8080 . An annotation that will allow Prometheus to discover and scrape the application pod. A deployment with one replica of a pod. <markup lang=\"bash\" title=\"Create and deploy the application into Kubernetes:\" >kubectl apply -f ./metrics.yaml <markup lang=\"bash\" title=\"Get the service information:\" >kubectl get service/helidon-metrics <markup lang=\"bash\" >NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE helidon-metrics NodePort 10.99.159.2 &lt;none&gt; 8080:31143/TCP 8s A service of type NodePort that serves the default routes on port 31143 . <markup lang=\"bash\" title=\"Verify the metrics endpoint using port 30116 , your port will likely be different:\" >curl http://localhost:31143/metrics Leave the application running in Kubernetes since it will be used for Prometheus integration. Prometheus Integration The metrics service that you just deployed into Kubernetes is already annotated with prometheus.io/scrape: . This will allow Prometheus to discover the service and scrape the metrics. In this exercise, you will install Prometheus into Kubernetes, then verify that it discovered the Helidon metrics in your application. <markup lang=\"bash\" title=\"Install Prometheus and wait until the pod is ready:\" >helm install stable/prometheus --name metrics export POD_NAME=$(kubectl get pods --namespace default -l \"app=prometheus,component=server\" -o jsonpath=\"{.items[0].metadata.name}\") kubectl get pod $POD_NAME You will see output similar to the following. Repeat the kubectl get pod command until you see 2/2 and Running . This may take up to one minute. <markup lang=\"bash\" >metrics-prometheus-server-5fc5dc86cb-79lk4 2/2 Running 0 46s <markup lang=\"bash\" title=\"Create a port-forward so you can access the server URL:\" >kubectl --namespace default port-forward $POD_NAME 7090:9090 Now open your browser and navigate to http://localhost:7090/targets . Search for helidon on the page and you will see your Helidon application as one of the Prometheus targets. Final Cleanup You can now delete the Kubernetes resources that were just created during this example. <markup lang=\"bash\" title=\"Delete the Prometheus Kubernetes resources:\" >helm delete --purge metrics <markup lang=\"bash\" title=\"Delete the application Kubernetes resources:\" >kubectl delete -f ./metrics.yaml Summary This guide demonstrated how to use metrics in a Helidon MP application using various combinations of metrics and scopes. Access metrics for all three scopes: base, vendor, and application Configure application metrics at the class, method, and field-level Integrate Helidon metrics with Kubernetes and Prometheus Refer to the following references for additional information: MicroProfile Metrics specification at https://github.com/eclipse/microprofile-metrics/releases/tag/2.0 MicroProfile Metrics Javadoc at https://javadoc.io/doc/org.eclipse.microprofile.metrics/microprofile-metrics-api/2.0.0 Helidon Javadoc at https://helidon.io/docs/latest/apidocs/index.html?overview-summary.html ",
            "title": "What You Need"
        },
        {
            "location": "/se/reactivemessaging/05_jms",
            "text": " To enable JMS Connector add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.messaging.jms&lt;/groupId&gt; &lt;artifactId&gt;helidon-messaging-jms&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/reactivemessaging/05_jms",
            "text": "<markup lang=\"java\" title=\"Example of consuming from JMS:\" >Channel&lt;String&gt; fromJms = Channel.&lt;String&gt;builder() .name(\"from-jms\") .publisherConfig(JmsConnector.configBuilder() .jndiInitialFactory(ActiveMQInitialContextFactory.class) .jndiProviderUrl(\"tcp://127.0.0.1:61616\") .type(JmsConfigBuilder.Type.QUEUE) .destination(\"se-example-queue-1\") .build() ) .build(); JmsConnector jmsConnector = JmsConnector.create(); Messaging messaging = Messaging.builder() .connector(jmsConnector) .listener(fromJms, payload -&gt; { System.out.println(\"Jms says: \" + payload); }) .build() .start(); Prepare a channel for connecting jms connector with specific publisher configuration &#8594; listener Channel &#8594; connector mapping is automatic when using JmsConnector.configBuilder() Prepare JMS connector, can be used by any channel <markup lang=\"java\" title=\"Example of producing to JMS:\" >Channel&lt;String&gt; toJms = Channel.&lt;String&gt;builder() .subscriberConfig(JmsConnector.configBuilder() .jndiInitialFactory(ActiveMQInitialContextFactory.class) .jndiProviderUrl(\"tcp://127.0.0.1:61616\") .type(JmsConfigBuilder.Type.QUEUE) .destination(\"se-example-queue-1\") .build() ).build(); JmsConnector jmsConnector = JmsConnector.create(); messaging = Messaging.builder() .publisher(toJms, Multi.just(\"test1\", \"test2\").map(Message::of)) .connector(jmsConnector) .build() .start(); Prepare a channel for connecting jms connector with specific publisher configuration &#8594; listener Channel &#8594; connector mapping is automatic when using JmsConnector.configBuilder() Prepare JMS connector, can be used by any channel ",
            "title": "Explicit config with config builder"
        },
        {
            "location": "/se/reactivemessaging/05_jms",
            "text": "<markup lang=\"yaml\" title=\"Example of connector config:\" >mp.messaging: incoming.from-jms: connector: helidon-jms destination: se-example-queue-1 session-group-id: session-group-1 type: queue outgoing.to-jms: connector: helidon-jms destination: se-example-queue-1 type: queue connector: helidon-jms: jndi: jms-factory: ConnectionFactory env-properties: java.naming.factory.initial: org.apache.activemq.jndi.ActiveMQInitialContextFactory java.naming.provider.url: tcp://127.0.0.1:61616 <markup lang=\"java\" title=\"Example of consuming from JMS:\" >Config config = Config.create(); Channel&lt;String&gt; fromJms = Channel.create(\"from-jms\"); JmsConnector jmsConnector = JmsConnector.create(); Messaging messaging = Messaging.builder() .config(config) .connector(jmsConnector) .listener(fromJms, payload -&gt; { System.out.println(\"Jms says: \" + payload); }) .build() .start(); Prepare JMS connector, can be used by any channel <markup lang=\"java\" title=\"Example of producing to JMS:\" >Config config = Config.create(); Channel&lt;String&gt; toJms = Channel.create(\"to-jms\"); JmsConnector jmsConnector = JmsConnector.create(); messaging = Messaging.builder() .config(config) .publisher(toJms, Multi.just(\"test1\", \"test2\").map(Message::of)) .connector(jmsConnector) .build() .start(); Prepare JMS connector, can be used by any channel Don&#8217;t forget to check out the examples with pre-configured ActiveMQ docker image, for easy testing: https://github.com/oracle/helidon/tree/master/examples/messaging ",
            "title": "Implicit Helidon Config"
        },
        {
            "location": "/se/reactivemessaging/05_jms",
            "text": " Connecting streams to JMS with Reactive Messaging couldn&#8217;t be easier. Explicit config with config builder <markup lang=\"java\" title=\"Example of consuming from JMS:\" >Channel&lt;String&gt; fromJms = Channel.&lt;String&gt;builder() .name(\"from-jms\") .publisherConfig(JmsConnector.configBuilder() .jndiInitialFactory(ActiveMQInitialContextFactory.class) .jndiProviderUrl(\"tcp://127.0.0.1:61616\") .type(JmsConfigBuilder.Type.QUEUE) .destination(\"se-example-queue-1\") .build() ) .build(); JmsConnector jmsConnector = JmsConnector.create(); Messaging messaging = Messaging.builder() .connector(jmsConnector) .listener(fromJms, payload -&gt; { System.out.println(\"Jms says: \" + payload); }) .build() .start(); Prepare a channel for connecting jms connector with specific publisher configuration &#8594; listener Channel &#8594; connector mapping is automatic when using JmsConnector.configBuilder() Prepare JMS connector, can be used by any channel <markup lang=\"java\" title=\"Example of producing to JMS:\" >Channel&lt;String&gt; toJms = Channel.&lt;String&gt;builder() .subscriberConfig(JmsConnector.configBuilder() .jndiInitialFactory(ActiveMQInitialContextFactory.class) .jndiProviderUrl(\"tcp://127.0.0.1:61616\") .type(JmsConfigBuilder.Type.QUEUE) .destination(\"se-example-queue-1\") .build() ).build(); JmsConnector jmsConnector = JmsConnector.create(); messaging = Messaging.builder() .publisher(toJms, Multi.just(\"test1\", \"test2\").map(Message::of)) .connector(jmsConnector) .build() .start(); Prepare a channel for connecting jms connector with specific publisher configuration &#8594; listener Channel &#8594; connector mapping is automatic when using JmsConnector.configBuilder() Prepare JMS connector, can be used by any channel Implicit Helidon Config <markup lang=\"yaml\" title=\"Example of connector config:\" >mp.messaging: incoming.from-jms: connector: helidon-jms destination: se-example-queue-1 session-group-id: session-group-1 type: queue outgoing.to-jms: connector: helidon-jms destination: se-example-queue-1 type: queue connector: helidon-jms: jndi: jms-factory: ConnectionFactory env-properties: java.naming.factory.initial: org.apache.activemq.jndi.ActiveMQInitialContextFactory java.naming.provider.url: tcp://127.0.0.1:61616 <markup lang=\"java\" title=\"Example of consuming from JMS:\" >Config config = Config.create(); Channel&lt;String&gt; fromJms = Channel.create(\"from-jms\"); JmsConnector jmsConnector = JmsConnector.create(); Messaging messaging = Messaging.builder() .config(config) .connector(jmsConnector) .listener(fromJms, payload -&gt; { System.out.println(\"Jms says: \" + payload); }) .build() .start(); Prepare JMS connector, can be used by any channel <markup lang=\"java\" title=\"Example of producing to JMS:\" >Config config = Config.create(); Channel&lt;String&gt; toJms = Channel.create(\"to-jms\"); JmsConnector jmsConnector = JmsConnector.create(); messaging = Messaging.builder() .config(config) .publisher(toJms, Multi.just(\"test1\", \"test2\").map(Message::of)) .connector(jmsConnector) .build() .start(); Prepare JMS connector, can be used by any channel Don&#8217;t forget to check out the examples with pre-configured ActiveMQ docker image, for easy testing: https://github.com/oracle/helidon/tree/master/examples/messaging ",
            "title": "Reactive JMS Connector"
        },
        {
            "location": "/mp/guides/38_testing_junit5",
            "text": " This guide describes how to write and execute tests for your MicroProfile applications in a JUnit 5 environment using optimized customizations. ",
            "title": "preambule"
        },
        {
            "location": "/mp/guides/38_testing_junit5",
            "text": " For this 20 minute tutorial, you will need the following: <div class=\"table__overflow elevation-1 flex sm7 \"> A Helidon {upper-case-flavor} Application You can use your own application or use the Helidon {upper-case-flavor} Quickstart to create a sample application. Java&#160;SE&#160;11 ( Open&#160;JDK&#160;11 ) Helidon requires Java 11+. Maven 3.6.1+ Helidon requires Maven 3.6.1+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop ). <markup lang=\"bash\" title=\"Verify Prerequisites\" >java -version mvn --version docker --version kubectl version --short <markup lang=\"bash\" title=\"Setting JAVA_HOME\" ># On Mac export JAVA_HOME=`/usr/libexec/java_home -v 11` # On Linux # Use the appropriate path to your JDK export JAVA_HOME=/usr/lib/jvm/jdk-11 ",
            "title": "What You Need"
        },
        {
            "location": "/mp/guides/38_testing_junit5",
            "text": " To start using this feature, add the following dependencies to the testing module: <markup lang=\"xml\" title=\"Maven dependencies\" >&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.tests&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-tests-junit5&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.junit.jupiter&lt;/groupId&gt; &lt;artifactId&gt;junit-jupiter-engine&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; ",
            "title": "Dependencies"
        },
        {
            "location": "/mp/guides/38_testing_junit5",
            "text": " First you&#8217;ll need to create a test class with an empty test method, and annotate it with @HelidonTest : <markup lang=\"java\" title=\"Test Class\" >import io.helidon.microprofile.tests.junit5.HelidonTest; import org.junit.jupiter.api.Test; @HelidonTest class GreetTest { @Test void testDefaultGreeting() { } } The @HelidonTest annotation will cause the test extension to start a Helidon MicroProfile server so that you do not need to manage the server lifecycle in your test. The container is initialized once before the test class is instantiated, and shut down after the last test runs. You can see this in the test output: The @HelidonTest annotation uses a random port regardless of the port configured in the application.yaml. ",
            "title": "Create a Test Class"
        },
        {
            "location": "/mp/guides/38_testing_junit5",
            "text": " The test is only useful if it invokes the server and verifies the result. To support testing, you can inject a WebTarget that is configured for the currently running server (it can also be a parameter to a test method). We can use the target to invoke our endpoint and validate the result. <markup lang=\"java\" title=\"Updated Class with webTarget\" >import static org.junit.jupiter.api.Assertions.assertEquals; @HelidonTest class GreetTest { @Inject WebTarget webTarget; @Test void testDefaultGreeting() { JsonObject jsonObject = webTarget.path(\"/greet\") .request() .get(JsonObject.class); String expected = \"Hello World!\"; String actual = jsonObject.getString(\"message\"); assertEquals(expected, actual, \"Message in JSON\"); } } The test is now complete and verifies the message. ",
            "title": "Inject a WebTarget"
        },
        {
            "location": "/mp/guides/38_testing_junit5",
            "text": " The testing extension supports a few additional annotations that allow for finer control of the test execution. Optional Extension Annotations Annotation Description @HelidonTest(resetPerTest = true) Resets the container for each method. This is useful when we want to modify configuration or beans between executions. In such a case, injection into fields is not possible, as we would need a different instance for each test. @AddConfig(key = \"app.greeting\", value = \"Unite\") Defines a new configuration (either on class level, or method level) by adding a single configuration key/value. @Configuration(configSources = \"test-config.properties\") Adds a whole config source from classpath. Here&#8217;s an example showing how these approaches are used to execute the same endpoint with different configuration: <markup lang=\"java\" >@HelidonTest(resetPerTest = true) class GreetTest { @Test void testDefaultGreeting(WebTarget webTarget) { validate(webTarget, \"/greet\", \"Hello World!\"); } @Test @AddConfig(key = \"app.greeting\", value = \"Unite\") void testConfiguredGreeting(WebTarget webTarget) { validate(webTarget, \"/greet\", \"Unite World!\"); } private void validate(WebTarget webTarget, String path, String expected) { JsonObject jsonObject = webTarget.path(path) .request() .get(JsonObject.class); String actual = jsonObject.getString(\"message\"); assertEquals(expected, actual, \"Message in JSON\"); } } ",
            "title": "Customize the Testing Extension"
        },
        {
            "location": "/mp/guides/38_testing_junit5",
            "text": " If you prefer to use only beans for testing, and want to add a different bean for each test, then you must use the @AddBean annotation. This cannot be achieved by CDI discovery because if we place META-INF/beans.xml on the classpath, then all of our beans would be added. <markup lang=\"java\" >@AddBean(TestBean.class) By default the bean is added to the container with scope set to ApplicationScoped . You can customize scope either by annotating the bean class with another scope or through the annotation: <markup lang=\"java\" >@AddBean(value = TestBean.class, scope = Dependent.class) This annotation can also be placed on a method when running in resetPerTest mode. ",
            "title": "Use Beans for Testing"
        },
        {
            "location": "/mp/guides/38_testing_junit5",
            "text": " When a custom bean is not enough, you may want to extend the CDI with a test-only Extension . Once again, if we use the standard way of doing this, we would need to create a META-INF/services record that would be picked up by every test class. For this purpose, we provide the following annotation which adds the extension to the container and allows you to modify its behavior as a usual CDI Portable Extension: <markup lang=\"java\" >@AddExtension(TestExtension.class) ",
            "title": "Add Test Extension"
        },
        {
            "location": "/mp/guides/38_testing_junit5",
            "text": " If you want to disable discovery and only add custom extensions and beans, then use the following annotation: <markup lang=\"java\" >@DisableDiscovery This annotation is typically used in conjunction with @AddBeans and/or @AddExtension . As you have seen in standard test output, by default Helidon starts with the dependencies defined in pom.xml. ",
            "title": "Disable Discovery"
        },
        {
            "location": "/mp/guides/38_testing_junit5",
            "text": " In this guide we will use the Helidon MP Quick Start project in our examples. This application provides an endpoint /greet , and we want to make sure this endpoint is available and returns expected value. Create a Test Class First you&#8217;ll need to create a test class with an empty test method, and annotate it with @HelidonTest : <markup lang=\"java\" title=\"Test Class\" >import io.helidon.microprofile.tests.junit5.HelidonTest; import org.junit.jupiter.api.Test; @HelidonTest class GreetTest { @Test void testDefaultGreeting() { } } The @HelidonTest annotation will cause the test extension to start a Helidon MicroProfile server so that you do not need to manage the server lifecycle in your test. The container is initialized once before the test class is instantiated, and shut down after the last test runs. You can see this in the test output: The @HelidonTest annotation uses a random port regardless of the port configured in the application.yaml. Inject a WebTarget The test is only useful if it invokes the server and verifies the result. To support testing, you can inject a WebTarget that is configured for the currently running server (it can also be a parameter to a test method). We can use the target to invoke our endpoint and validate the result. <markup lang=\"java\" title=\"Updated Class with webTarget\" >import static org.junit.jupiter.api.Assertions.assertEquals; @HelidonTest class GreetTest { @Inject WebTarget webTarget; @Test void testDefaultGreeting() { JsonObject jsonObject = webTarget.path(\"/greet\") .request() .get(JsonObject.class); String expected = \"Hello World!\"; String actual = jsonObject.getString(\"message\"); assertEquals(expected, actual, \"Message in JSON\"); } } The test is now complete and verifies the message. Customize the Testing Extension The testing extension supports a few additional annotations that allow for finer control of the test execution. Optional Extension Annotations Annotation Description @HelidonTest(resetPerTest = true) Resets the container for each method. This is useful when we want to modify configuration or beans between executions. In such a case, injection into fields is not possible, as we would need a different instance for each test. @AddConfig(key = \"app.greeting\", value = \"Unite\") Defines a new configuration (either on class level, or method level) by adding a single configuration key/value. @Configuration(configSources = \"test-config.properties\") Adds a whole config source from classpath. Here&#8217;s an example showing how these approaches are used to execute the same endpoint with different configuration: <markup lang=\"java\" >@HelidonTest(resetPerTest = true) class GreetTest { @Test void testDefaultGreeting(WebTarget webTarget) { validate(webTarget, \"/greet\", \"Hello World!\"); } @Test @AddConfig(key = \"app.greeting\", value = \"Unite\") void testConfiguredGreeting(WebTarget webTarget) { validate(webTarget, \"/greet\", \"Unite World!\"); } private void validate(WebTarget webTarget, String path, String expected) { JsonObject jsonObject = webTarget.path(path) .request() .get(JsonObject.class); String actual = jsonObject.getString(\"message\"); assertEquals(expected, actual, \"Message in JSON\"); } } Use Beans for Testing If you prefer to use only beans for testing, and want to add a different bean for each test, then you must use the @AddBean annotation. This cannot be achieved by CDI discovery because if we place META-INF/beans.xml on the classpath, then all of our beans would be added. <markup lang=\"java\" >@AddBean(TestBean.class) By default the bean is added to the container with scope set to ApplicationScoped . You can customize scope either by annotating the bean class with another scope or through the annotation: <markup lang=\"java\" >@AddBean(value = TestBean.class, scope = Dependent.class) This annotation can also be placed on a method when running in resetPerTest mode. Add Test Extension When a custom bean is not enough, you may want to extend the CDI with a test-only Extension . Once again, if we use the standard way of doing this, we would need to create a META-INF/services record that would be picked up by every test class. For this purpose, we provide the following annotation which adds the extension to the container and allows you to modify its behavior as a usual CDI Portable Extension: <markup lang=\"java\" >@AddExtension(TestExtension.class) Disable Discovery If you want to disable discovery and only add custom extensions and beans, then use the following annotation: <markup lang=\"java\" >@DisableDiscovery This annotation is typically used in conjunction with @AddBeans and/or @AddExtension . As you have seen in standard test output, by default Helidon starts with the dependencies defined in pom.xml. ",
            "title": "Create a Sample Helidon MP Project"
        },
        {
            "location": "/mp/guides/38_testing_junit5",
            "text": " If you want just the basic test features enabled, then you only have to add a few required extensions and classes to your test. The following example uses only those extensions and classes required to run a bean that injects configuration value: <markup lang=\"java\" >import javax.inject.Inject; import io.helidon.microprofile.config.ConfigCdiExtension; import io.helidon.microprofile.tests.junit5.AddBean; import io.helidon.microprofile.tests.junit5.AddConfig; import io.helidon.microprofile.tests.junit5.AddExtension; import io.helidon.microprofile.tests.junit5.DisableDiscovery; import io.helidon.microprofile.tests.junit5.HelidonTest; import org.eclipse.microprofile.config.inject.ConfigProperty; import org.junit.jupiter.api.Test; import static org.junit.jupiter.api.Assertions.assertEquals; @HelidonTest @DisableDiscovery @AddExtension(ConfigCdiExtension.class) @AddBean(GreetTest.ConfiguredBean.class) @AddConfig(key = \"test.message\", value = \"Hello Guide!\") class GreetTest { @Inject ConfiguredBean bean; @Test void testBean() { assertEquals(\"Hello Guide!\", bean.message()); } public static class ConfiguredBean { @Inject @ConfigProperty(name = \"test.message\") private String message; String message() { return message; } } } ",
            "title": "Write a Basic Test"
        },
        {
            "location": "/mp/guides/38_testing_junit5",
            "text": " This guide demonstrated how to create tests for MicroProfile applications in a JUnit 5 environment. It described some useful customizations that can be added to your testing extension and allow you to configure test outcomes for your Helidon MP applications. Refer to the following references for additional information: JUnit 5 User Guide Testing with JUnit 5 ",
            "title": "Summary"
        },
        {
            "location": "/se/cors/02_using-the-api",
            "text": " Every Helidon SE application explicitly creates routing rules that govern how Helidon delivers each incoming request to the code that needs to respond. The Helidon CORS SE API provides a simple way to include CORS into the routing rules that you construct for your application. ",
            "title": "preambule"
        },
        {
            "location": "/se/cors/02_using-the-api",
            "text": " To enable CORS add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webserver&lt;/groupId&gt; &lt;artifactId&gt;helidon-webserver-cors&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/cors/02_using-the-api",
            "text": " To add CORS behavior to endpoints, you need to make only minimal changes to how you set up the routing for those endpoints. Using the Helidon SE CORS API, you define the CORS behavior that you want and then include that behavior as you build the routing rules for the services in your application. The Helidon SE CORS API provides two key classes that you use in your application: CorsSupport - Represents information about resource sharing for a single resource. Typically, you create one CorsSupport instance for each distinct resource in your application (such as the /greet resource in the QuickStart greeting application) that should participate in CORS. CrossOriginConfig - Represents the details for a particular type of sharing, such as which origins are allowed to have access using which HTTP methods, etc. Create one instance of CrossOriginConfig for each different type of sharing you need. You associate one or more CrossOriginConfig objects with each CorsSupport object. You use the CorsSupport object when you construct the routing rules for the service. When your application is running and requests arrive, the Helidon CORS implementation enforces the CORS behavior represented by the CorsSupport object before routing the request to your endpoint code for the resource. ",
            "title": "Understanding the Helidon SE CORS API"
        },
        {
            "location": "/se/cors/02_using-the-api",
            "text": " To add CORS support to your Helidon SE application: Determine the type of cross origin sharing you want to allow for each endpoint in your application. Add a dependency on the Helidon SE CORS artifact to your Maven pom.xml file. Modify how your application constructs routing rules so they include CORS as described in the following sections. ",
            "title": "Getting Started"
        },
        {
            "location": "/se/cors/02_using-the-api",
            "text": " Because Helidon SE does not use annotation processing to identify endpoints, you need to provide the CORS information for your application another way - by including CORS into the routing you construct for your application. For each distinct resource or subresource your application exposes: Create a CorsSupport instance corresponding to the resource. For each different type of sharing you want to provide for that resource: Create a CrossOriginConfig instance. The CrossOriginConfig Java class represents the details for a particular type of sharing, such as which origins are allowed to share via which HTTP methods, etc. Add the CrossOriginConfig to the CorsSupport instance for this resource. Use the resource&#8217;s CorsSupport object in setting up the routing rules for that resource. Each of these classes has an associated builder that you use in constructing instances of the class. The table below describes the methods on the CrossOriginConfig.Builder class that map to the headers defined in the CORS protocol. Method Default CORS Header Name allowCredentials false Access-Control-Allow-Credentials allowHeaders [\"*\"] Access-Control-Allow-Headers allowMethods [\"*\"] Access-Control-Allow-Methods allowOrigins [\"*\"] Access-Control-Allow-Origins exposeHeaders none Access-Control-Expose-Headers maxAgeSeconds 3600 Access-Control-Max-Age enabled true n/a If the cross-origin configuration is disabled ( enabled = false), then the Helidon CORS implementation ignores the cross-origin configuration entry. ",
            "title": "Adding CORS Support in Your Helidon SE Application"
        },
        {
            "location": "/se/cors/02_using-the-api",
            "text": " The Helidon SE Quickstart application lets you change the greeting by sending a PUT request to the /greet/greeting resource. This example, based on the QuickStart greeting app, uses the low-level CrossOriginConfig API and the CorsSupport API to influence the routing , thereby determining how that resource is shared. (If desired, you can use configuration instead of the low-level API. Learn more. ) The following code shows how to prepare your application&#8217;s routing to support metrics and health support, as well as CORS. <markup lang=\"java\" > private static Routing createRouting(Config config) { MetricsSupport metrics = MetricsSupport.create(); GreetService greetService = new GreetService(config); HealthSupport health = HealthSupport.builder() .addLiveness(HealthChecks.healthChecks()) // Adds a convenient set of checks .build(); CorsSupport corsSupport = CorsSupport.builder() .addCrossOriginConfig(CrossOriginConfig.builder() .allowOrigins(\"http://foo.com\", \"http://there.com\") .allowMethods(\"PUT\", \"DELETE\") .build()) .addCrossOriginConfig(CrossOriginConfig.create()) .build(); // Note: Add the CORS routing *before* registering the GreetService routing. return Routing.builder() .register(JsonSupport.create()) .register(health) // Health at \"/health\" .register(metrics) // Metrics at \"/metrics\" .register(\"/greet\", corsSupport, greetService) .build(); } Create a CorsSupport.Builder instance. Add a CrossOriginSupport instance (using its builder) to constrain resource sharing. List the origins (sites) allowed to share resources from this app. List the HTTP methods the constraint applies to. Build the CrossOriginSupport instance. Add a CrossOriginSupport instance that permits all sharing (the default). Build the CorsSupport instance. Register the new CorsSupport instance with&#8201;&#8212;&#8201;but in front of&#8201;&#8212;&#8201;the service which implements the business logic. The order of steps 2 and 6 above is important. When processing an incoming request, the Helidon CORS implementation scans the CrossOriginConfig instances in the order they were added to the CorsSupport object, stopping as soon as it finds a CrossOriginConfig instance for which allowMethods matches the HTTP method of the request. The few additional lines described above allow the greeting application to participate in CORS. ",
            "title": "Sample Routing Setup Using the CrossOriginConfig API"
        },
        {
            "location": "/se/cors/02_using-the-api",
            "text": " Use configuration in combination with the API to add CORS to your application. Learn more. See the Helidon CORS support in action by building and running the CORS example . ",
            "title": "Next Steps"
        },
        {
            "location": "/se/oci/03_vault",
            "text": " The Helidon SE OCI Vault integration provides a reactive API for the Oracle Cloud Vault service. ",
            "title": "preambule"
        },
        {
            "location": "/se/oci/03_vault",
            "text": " The custom Helidon SE OCI clients documented here are deprecated. It is recommended that you use the OCI Java SDK directly, in particular the Async clients. For more information see: OCI Vault Storage Documentation OCI Vault Storage Javadoc Helidon SE OCI Vault Example ",
            "title": "Deprecated"
        },
        {
            "location": "/se/oci/03_vault",
            "text": " Helidon integration with Oracle Cloud Infrastructure is still experimental and not intended for production use. APIs and features have not yet been fully tested and are subject to change. ",
            "title": "Experimental"
        },
        {
            "location": "/se/oci/03_vault",
            "text": " To enable OCI Vault add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.oci&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-oci-vault&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/oci/03_vault",
            "text": " In order to use the OCI Vault integration, the following setup should be made. The configuration required for Vault integration includes: Vault OCID - to use the correct Vault, as more than one can be configured Compartment OCID - OCI-specific compartment Encryption Key OCID - required when doing encryption/decryption Signature Key OCID - required when doing signatures/verification Cryptographic endpoint - required for all except secrets First specify OCIDs and URLs of Vault items in application.yaml : <markup lang=\"yaml\" >oci: vault: vault-ocid: \"&lt;...&gt;\" compartment-ocid: \"&lt;...&gt;\" encryption-key-ocid: \"&lt;...&gt;\" signature-key-ocid: \"&lt;...&gt;\" cryptographic-endpoint: \"&lt;...&gt;\" Current configuration requires ~/.oci/config to be available in the home folder. This configuration file can be downloaded from OCI. The OCIDs can be set up and found in OCI under Security tab. Next, these values should be read and provided to VaultService : <markup lang=\"java\" >Config vaultConfig = config.get(\"oci.vault\"); // the following three parameters are required String vaultOcid = vaultConfig.get(\"vault-ocid\").asString().get(); String compartmentOcid = vaultConfig.get(\"compartment-ocid\").asString().get(); String encryptionKey = vaultConfig.get(\"encryption-key-ocid\").asString().get(); String signatureKey = vaultConfig.get(\"signature-key-ocid\").asString().get(); // this requires OCI configuration in the usual place // ~/.oci/config OciVaultRx ociVault = OciVaultRx.create(config.get(\"oci\")); WebServer.builder() .config(config.get(\"server\")) .routing(Routing.builder() .register(\"/vault\", new VaultService(ociVault, vaultOcid, compartmentOcid, encryptionKey, signatureKey))) .build() .start() .await(); The VaultService should define an update method to map paths to handler methods: <markup lang=\"java\" >@Override public void update(Routing.Rules rules) { rules.get(\"/encrypt/{text:.*}\", this::encrypt) .get(\"/decrypt/{text:.*}\", this::decrypt) .get(\"/sign/{text}\", this::sign) .get(\"/verify/{text}/{signature:.*}\", this::verify) .get(\"/secret/{id}\", this::getSecret) .post(\"/secret/{name}\", Handler.create(String.class, this::createSecret)) .delete(\"/secret/{id}\", this::deleteSecret); } ",
            "title": "Setting up the OCI Vault"
        },
        {
            "location": "/se/oci/03_vault",
            "text": " To encrypt a text, submit a GET request to the /encrypt endpoint: <markup lang=\"java\" >private void encrypt(ServerRequest req, ServerResponse res) { vault.encrypt(Encrypt.Request.builder() .keyId(encryptionKeyOcid) .data(Base64Value.create(req.path().param(\"text\")))) .map(Encrypt.Response::cipherText) .forSingle(res::send) .exceptionally(res::send); } ",
            "title": "Encryption"
        },
        {
            "location": "/se/oci/03_vault",
            "text": " To decrypt a text, submit a GET request to /decrypt endpoint: <markup lang=\"java\" >private void decrypt(ServerRequest req, ServerResponse res) { vault.decrypt(Decrypt.Request.builder() .keyId(encryptionKeyOcid) .cipherText(req.path().param(\"text\"))) .map(Decrypt.Response::decrypted) .map(Base64Value::toDecodedString) .forSingle(res::send) .exceptionally(res::send); } ",
            "title": "Decryption"
        },
        {
            "location": "/se/oci/03_vault",
            "text": " To verify the correctness of the signature, submit a GET request to /verify endpoint: <markup lang=\"java\" >private void verify(ServerRequest req, ServerResponse res) { String text = req.path().param(\"text\"); String signature = req.path().param(\"signature\"); vault.verify(Verify.Request.builder() .keyId(signatureKeyOcid) .algorithm(Sign.Request.ALGORITHM_SHA_224_RSA_PKCS_PSS) .message(Base64Value.create(text)) .signature(Base64Value.createFromEncoded(signature))) .map(Verify.Response::isValid) .map(it -&gt; it ? \"Signature Valid\" : \"Signature Invalid\") .forSingle(res::send) .exceptionally(res::send); } ",
            "title": "Verification of a Signature"
        },
        {
            "location": "/se/oci/03_vault",
            "text": " To create a secret with a provided name, submit a GET request to /secret : <markup lang=\"java\" >private void createSecret(ServerRequest req, ServerResponse res, String secretText) { vault.createSecret(CreateSecret.Request.builder() .secretContent(CreateSecret.SecretContent.create(secretText)) .vaultId(vaultOcid) .compartmentId(compartmentOcid) .encryptionKeyId(encryptionKeyOcid) .secretName(req.path().param(\"name\"))) .map(CreateSecret.Response::secret) .map(Secret::id) .forSingle(res::send) .exceptionally(res::send); } ",
            "title": "Creating a Signature"
        },
        {
            "location": "/se/oci/03_vault",
            "text": " To get a secret by its OCID, submit a GET request to /secret : <markup lang=\"java\" >private void getSecret(ServerRequest req, ServerResponse res) { vault.getSecretBundle(GetSecretBundle.Request.create(req.path().param(\"id\"))) .forSingle(apiResponse -&gt; { Optional&lt;GetSecretBundle.Response&gt; entity = apiResponse.entity(); if (entity.isEmpty()) { res.status(Http.Status.NOT_FOUND_404).send(); } else { GetSecretBundle.Response response = entity.get(); res.send(response.secretString().orElse(\"\")); } }) .exceptionally(res::send); } ",
            "title": "Getting a Signature"
        },
        {
            "location": "/se/oci/03_vault",
            "text": " To delete a secret, a DELETE request to /secret should be used: <markup lang=\"java\" >private void deleteSecret(ServerRequest req, ServerResponse res) { Instant deleteTime = Instant.now().plus(30, ChronoUnit.DAYS); vault.deleteSecret(DeleteSecret.Request.builder() .secretId(req.path().param(\"id\")) .timeOfDeletion(deleteTime)) .forSingle(it -&gt; res.status(it.status()).send()) .exceptionally(res::send); } ",
            "title": "Deleting a Signature"
        },
        {
            "location": "/se/oci/03_vault",
            "text": " To retrieve a signature, submit a GET request to /sign endpoint: <markup lang=\"java\" >private void sign(ServerRequest req, ServerResponse res) { vault.sign(Sign.Request.builder() .keyId(signatureKeyOcid) .algorithm(Sign.Request.ALGORITHM_SHA_224_RSA_PKCS_PSS) .message(Base64Value.create(req.path().param(\"text\")))) .map(Sign.Response::signature) .map(Base64Value::toBase64) .forSingle(res::send) .exceptionally(res::send); } Verification of a Signature To verify the correctness of the signature, submit a GET request to /verify endpoint: <markup lang=\"java\" >private void verify(ServerRequest req, ServerResponse res) { String text = req.path().param(\"text\"); String signature = req.path().param(\"signature\"); vault.verify(Verify.Request.builder() .keyId(signatureKeyOcid) .algorithm(Sign.Request.ALGORITHM_SHA_224_RSA_PKCS_PSS) .message(Base64Value.create(text)) .signature(Base64Value.createFromEncoded(signature))) .map(Verify.Response::isValid) .map(it -&gt; it ? \"Signature Valid\" : \"Signature Invalid\") .forSingle(res::send) .exceptionally(res::send); } Creating a Signature To create a secret with a provided name, submit a GET request to /secret : <markup lang=\"java\" >private void createSecret(ServerRequest req, ServerResponse res, String secretText) { vault.createSecret(CreateSecret.Request.builder() .secretContent(CreateSecret.SecretContent.create(secretText)) .vaultId(vaultOcid) .compartmentId(compartmentOcid) .encryptionKeyId(encryptionKeyOcid) .secretName(req.path().param(\"name\"))) .map(CreateSecret.Response::secret) .map(Secret::id) .forSingle(res::send) .exceptionally(res::send); } Getting a Signature To get a secret by its OCID, submit a GET request to /secret : <markup lang=\"java\" >private void getSecret(ServerRequest req, ServerResponse res) { vault.getSecretBundle(GetSecretBundle.Request.create(req.path().param(\"id\"))) .forSingle(apiResponse -&gt; { Optional&lt;GetSecretBundle.Response&gt; entity = apiResponse.entity(); if (entity.isEmpty()) { res.status(Http.Status.NOT_FOUND_404).send(); } else { GetSecretBundle.Response response = entity.get(); res.send(response.secretString().orElse(\"\")); } }) .exceptionally(res::send); } Deleting a Signature To delete a secret, a DELETE request to /secret should be used: <markup lang=\"java\" >private void deleteSecret(ServerRequest req, ServerResponse res) { Instant deleteTime = Instant.now().plus(30, ChronoUnit.DAYS); vault.deleteSecret(DeleteSecret.Request.builder() .secretId(req.path().param(\"id\")) .timeOfDeletion(deleteTime)) .forSingle(it -&gt; res.status(it.status()).send()) .exceptionally(res::send); } ",
            "title": "Signature"
        },
        {
            "location": "/se/oci/03_vault",
            "text": " Encryption To encrypt a text, submit a GET request to the /encrypt endpoint: <markup lang=\"java\" >private void encrypt(ServerRequest req, ServerResponse res) { vault.encrypt(Encrypt.Request.builder() .keyId(encryptionKeyOcid) .data(Base64Value.create(req.path().param(\"text\")))) .map(Encrypt.Response::cipherText) .forSingle(res::send) .exceptionally(res::send); } Decryption To decrypt a text, submit a GET request to /decrypt endpoint: <markup lang=\"java\" >private void decrypt(ServerRequest req, ServerResponse res) { vault.decrypt(Decrypt.Request.builder() .keyId(encryptionKeyOcid) .cipherText(req.path().param(\"text\"))) .map(Decrypt.Response::decrypted) .map(Base64Value::toDecodedString) .forSingle(res::send) .exceptionally(res::send); } Signature To retrieve a signature, submit a GET request to /sign endpoint: <markup lang=\"java\" >private void sign(ServerRequest req, ServerResponse res) { vault.sign(Sign.Request.builder() .keyId(signatureKeyOcid) .algorithm(Sign.Request.ALGORITHM_SHA_224_RSA_PKCS_PSS) .message(Base64Value.create(req.path().param(\"text\")))) .map(Sign.Response::signature) .map(Base64Value::toBase64) .forSingle(res::send) .exceptionally(res::send); } Verification of a Signature To verify the correctness of the signature, submit a GET request to /verify endpoint: <markup lang=\"java\" >private void verify(ServerRequest req, ServerResponse res) { String text = req.path().param(\"text\"); String signature = req.path().param(\"signature\"); vault.verify(Verify.Request.builder() .keyId(signatureKeyOcid) .algorithm(Sign.Request.ALGORITHM_SHA_224_RSA_PKCS_PSS) .message(Base64Value.create(text)) .signature(Base64Value.createFromEncoded(signature))) .map(Verify.Response::isValid) .map(it -&gt; it ? \"Signature Valid\" : \"Signature Invalid\") .forSingle(res::send) .exceptionally(res::send); } Creating a Signature To create a secret with a provided name, submit a GET request to /secret : <markup lang=\"java\" >private void createSecret(ServerRequest req, ServerResponse res, String secretText) { vault.createSecret(CreateSecret.Request.builder() .secretContent(CreateSecret.SecretContent.create(secretText)) .vaultId(vaultOcid) .compartmentId(compartmentOcid) .encryptionKeyId(encryptionKeyOcid) .secretName(req.path().param(\"name\"))) .map(CreateSecret.Response::secret) .map(Secret::id) .forSingle(res::send) .exceptionally(res::send); } Getting a Signature To get a secret by its OCID, submit a GET request to /secret : <markup lang=\"java\" >private void getSecret(ServerRequest req, ServerResponse res) { vault.getSecretBundle(GetSecretBundle.Request.create(req.path().param(\"id\"))) .forSingle(apiResponse -&gt; { Optional&lt;GetSecretBundle.Response&gt; entity = apiResponse.entity(); if (entity.isEmpty()) { res.status(Http.Status.NOT_FOUND_404).send(); } else { GetSecretBundle.Response response = entity.get(); res.send(response.secretString().orElse(\"\")); } }) .exceptionally(res::send); } Deleting a Signature To delete a secret, a DELETE request to /secret should be used: <markup lang=\"java\" >private void deleteSecret(ServerRequest req, ServerResponse res) { Instant deleteTime = Instant.now().plus(30, ChronoUnit.DAYS); vault.deleteSecret(DeleteSecret.Request.builder() .secretId(req.path().param(\"id\")) .timeOfDeletion(deleteTime)) .forSingle(it -&gt; res.status(it.status()).send()) .exceptionally(res::send); } ",
            "title": "OCI Vault usage"
        },
        {
            "location": "/se/cors/03_using-configuration",
            "text": " You can use configuration in combination with the Helidon CORS SE API to add CORS support to your resources by replacing some Java code with declarative configuration. This also gives your users a way to override the CORS behavior of your services without requiring the code to change. ",
            "title": "preambule"
        },
        {
            "location": "/se/cors/03_using-configuration",
            "text": " In configuration, Helidon represents basic CORS information as a section, identified by a configuration key of your choosing, that contains one or more key/value pairs. Each key-value pair assigns one characteristic of CORS behavior. The table below lists the configuration keys that identify the CORS characteristics. Configuration Key Default CORS Header Name allow-credentials false Access-Control-Allow-Credentials allow-headers [\"*\"] Access-Control-Allow-Headers allow-methods [\"*\"] Access-Control-Allow-Methods allow-origins [\"*\"] Access-Control-Allow-Origins expose-headers none Access-Control-Expose-Headers max-age 3600 Access-Control-Max-Age enabled true n/a If the cross-origin configuration is disabled ( enabled = false), then the Helidon CORS implementation ignores the cross-origin configuration entry. The following example of basic cross-origin configuration, when loaded and used by the application, limits cross-origin resource sharing for PUT and DELETE operations to only foo.com and there.com : <markup lang=\"hocon\" >... restrictive-cors: allow-origins: [\"http://foo.com\", \"http://there.com\"] allow-methods: [\"PUT\", \"DELETE\"] ... ",
            "title": "Basic Cross-Origin Configuration"
        },
        {
            "location": "/se/cors/03_using-configuration",
            "text": " In some cases, you or your users might want to configure CORS behavior based on URL path matching. Helidon represents mapped CORS information as a section, identified by a configuration key of your choosing, that contains: An optional enabled setting which defaults to true and applies to the whole mapped CORS config section, and An optional paths subsection containing zero or more entries, each of which contains: a basic CORS config section, and a path-pattern path pattern that maps that basic CORS config section to the resource(s) it affects. You can use mapped configuration to your advantage if you want to allow your users to override the CORS behavior set up in the application code. The following example illustrates the mapped cross-origin configuration format. <markup lang=\"hocon\" >... my-cors: paths: - path-pattern: /greeting allow-origins: [\"http://foo.com\", \"http://there.com\", \"http://other.com\"] allow-methods: [\"PUT\", \"DELETE\"] - path-pattern: / allow-methods: [\"GET\", \"HEAD\", \"OPTIONS\", \"POST\"] ... Assigns a unique identifier for this mapped CORS config section. Collects the sequence of entries, each of which maps a basic CORS config to a path pattern. Marks the beginning of an entry (the - character) and maps the associated basic CORS config to the /greeting subresource (the path-pattern key and value). Begins the basic CORS config section for /greeting ; it restricts sharing via PUT and DELETE to the listed origins. Marks the beginning of the next entry (the - character) and maps the associated basic CORS config to the top-level resource in the app (the path-pattern key and value). Begins the basic CORS config section for / ; it permits sharing of resources at the top-level path with all origins for the indicated HTTP methods. Path patterns can be any expression accepted by the PathMatcher class. Be sure to arrange the entries in the order that you want Helidon to check them. Helidon CORS support searches the cross-origin entries in the order you define them until it finds an entry that matches an incoming request&#8217;s path pattern and HTTP method. ",
            "title": "Mapped Cross-Origin Configuration"
        },
        {
            "location": "/se/cors/03_using-configuration",
            "text": " Support in Helidon for CORS configuration uses two closely-related cross-origin configuration formats: basic and mapped. Each format corresponds to a class in the Helidon CORS library. The basic format corresponds to the CrossOriginConfig class, and the mapped format corresponds to the MappedCrossOriginConfig class. Basic Cross-Origin Configuration In configuration, Helidon represents basic CORS information as a section, identified by a configuration key of your choosing, that contains one or more key/value pairs. Each key-value pair assigns one characteristic of CORS behavior. The table below lists the configuration keys that identify the CORS characteristics. Configuration Key Default CORS Header Name allow-credentials false Access-Control-Allow-Credentials allow-headers [\"*\"] Access-Control-Allow-Headers allow-methods [\"*\"] Access-Control-Allow-Methods allow-origins [\"*\"] Access-Control-Allow-Origins expose-headers none Access-Control-Expose-Headers max-age 3600 Access-Control-Max-Age enabled true n/a If the cross-origin configuration is disabled ( enabled = false), then the Helidon CORS implementation ignores the cross-origin configuration entry. The following example of basic cross-origin configuration, when loaded and used by the application, limits cross-origin resource sharing for PUT and DELETE operations to only foo.com and there.com : <markup lang=\"hocon\" >... restrictive-cors: allow-origins: [\"http://foo.com\", \"http://there.com\"] allow-methods: [\"PUT\", \"DELETE\"] ... Mapped Cross-Origin Configuration In some cases, you or your users might want to configure CORS behavior based on URL path matching. Helidon represents mapped CORS information as a section, identified by a configuration key of your choosing, that contains: An optional enabled setting which defaults to true and applies to the whole mapped CORS config section, and An optional paths subsection containing zero or more entries, each of which contains: a basic CORS config section, and a path-pattern path pattern that maps that basic CORS config section to the resource(s) it affects. You can use mapped configuration to your advantage if you want to allow your users to override the CORS behavior set up in the application code. The following example illustrates the mapped cross-origin configuration format. <markup lang=\"hocon\" >... my-cors: paths: - path-pattern: /greeting allow-origins: [\"http://foo.com\", \"http://there.com\", \"http://other.com\"] allow-methods: [\"PUT\", \"DELETE\"] - path-pattern: / allow-methods: [\"GET\", \"HEAD\", \"OPTIONS\", \"POST\"] ... Assigns a unique identifier for this mapped CORS config section. Collects the sequence of entries, each of which maps a basic CORS config to a path pattern. Marks the beginning of an entry (the - character) and maps the associated basic CORS config to the /greeting subresource (the path-pattern key and value). Begins the basic CORS config section for /greeting ; it restricts sharing via PUT and DELETE to the listed origins. Marks the beginning of the next entry (the - character) and maps the associated basic CORS config to the top-level resource in the app (the path-pattern key and value). Begins the basic CORS config section for / ; it permits sharing of resources at the top-level path with all origins for the indicated HTTP methods. Path patterns can be any expression accepted by the PathMatcher class. Be sure to arrange the entries in the order that you want Helidon to check them. Helidon CORS support searches the cross-origin entries in the order you define them until it finds an entry that matches an incoming request&#8217;s path pattern and HTTP method. ",
            "title": "Understanding the CORS Configuration Formats"
        },
        {
            "location": "/se/cors/03_using-configuration",
            "text": " You use configuration in combination with the Helidon CORS SE API to add CORS support to your resources. The example in Sample Routing Setup Using the CrossOriginConfig API uses the low-level Helidon CORS SE API to create a CrossOriginConfig instance that is then used as part of a CorsSupport instance to create the routing rules. As an alternative to using the low-level API, this example uses config to create the CrossOriginConfig instance instead. <markup lang=\"java\" > private static Routing createRouting(Config config) { MetricsSupport metrics = MetricsSupport.create(); GreetService greetService = new GreetService(config); HealthSupport health = HealthSupport.builder() .addLiveness(HealthChecks.healthChecks()) // Adds a convenient set of checks .build(); CorsSupport.Builder builder = CorsSupport.builder(); Config config = Config.create(); // Created from the current config sources config.get(\"my-cors\") .ifExists(builder::mappedConfig); config.get(\"restrictive-cors\") .ifExists(builder::config); builder.addCrossOriginConfig(CrossOriginConfig.create()); CorsSupport corsSupport = builder.build(); // Note: Add the CORS routing *before* registering the GreetService routing. return Routing.builder() .register(JsonSupport.create()) .register(health) // Health at \"/health\" .register(metrics) // Metrics at \"/metrics\" .register(\"/greet\", corsSupport, greetService) .build(); } If my-cors exists in the configuration, use it to add mapped CORS config to the CorsSupport builder. If restrictive-cors exists in the configuration, use it to add basic (not mapped) config to the builder. Provide default CORS handling for requests that do not match earlier entries. Obtain the finished CorsSupport instance. Use corsSupport in constructing the routing rules. As each request arrives, Helidon checks it against the cross-origin config instances in the order that your application added them to the CorsSupport.Builder . The my-cors mapped configuration acts as an override because the application added it to the builder first. If the my-cors config key does not appear in the configuration, then the code skips creating a CrossOriginConfig instance based on that configuration, and no overriding occurs. The CORS behavior that is established by the other CrossOriginConfig instance based on the restrictive-cors config (if present) prevails. Remember that if you set configuration in a file that you include as part of your application JAR file, then you need to rebuild and restart your application for any changes to take effect. ",
            "title": "Using CORS Configuration in the Application"
        },
        {
            "location": "/se/cors/03_using-configuration",
            "text": " Use these same configuration techniques to control the behavior of the CORS-enabled built-in services. Learn more. See the Helidon CORS support in action by building and running the CORS example . ",
            "title": "Next Steps"
        },
        {
            "location": "/se/webserver/02_configuration",
            "text": " Configure the WebServer either programmatically, or by the Helidon configuration framework. ",
            "title": "preambule"
        },
        {
            "location": "/se/webserver/02_configuration",
            "text": " The easiest way to configure the WebServer is in your application code. <markup lang=\"java\" >WebServer webServer = WebServer.builder() .bindAddress(InetAddress.getLocalHost()) .port(8080) .build(); ",
            "title": "Configuring the WebServer in your code"
        },
        {
            "location": "/se/webserver/02_configuration",
            "text": " You can also define the configuration in a file. <markup lang=\"yaml\" title=\"WebServer configuration file application.yaml \" >server: port: 8080 bind-address: \"0.0.0.0\" Then, in your application code, load the configuration from that file. <markup lang=\"java\" title=\"WebServer initialization using the application.yaml file located on the classpath\" >Config config = Config.create(); WebServer webServer = WebServer.create(routing, config.get(\"server\")); application.yaml is a default configuration source loaded when YAML support is on classpath, so we can just use Config.create() Server expects the configuration tree located on the node of server ",
            "title": "Configuring the WebServer in a configuration file"
        },
        {
            "location": "/se/webserver/02_configuration",
            "text": " See all configuration options here . Available socket configuration options: Configuration key Default value Java type Description port &#160; int Port to open server socket on, defaults to an available ephemeral port bind-address all local addresses String Address to listen on (may be an IPV6 address as well) backlog 1024 int Maximum length of the queue of incoming connections on the server socket. max-header-size 16384 int Maximal number of bytes of all header values combined. Returns 400 if headers are bigger max-initial-line-length 4096 int Maximal number of characters in the initial HTTP line. Returns 400 if line is longer timeout-millis no timeout long Server socket timeout. receive-buffer-size implementation default int Proposed value of the TCP receive window that is advertised to the remote peer on the server socket. name @default for default socket String Name used for named sockets, to support additional server sockets (and their named routing) enabled true boolean A socket can be disabled through configuration, in which case it is never opened max-chunk-size 8192 int Maximal size of a chunk to read from incoming requests max-payload-size -1 long Maximal size of a request payload in bytes. If exceeded a 413 error is returned. Negative value means no limit. backpressure-buffer-size long 5242880 Set a maximum length of the unflushed response data sending buffer can keep without applying backpressure. Depends on backpressure-policy what happens if max buffer size is reached. Default is 5*1024*1024 - 5Mb backpressure-policy String LINEAR Sets the strategy for applying backpressure to the reactive stream of response data. * LINEAR - Data chunks are requested one-by-one after previous data chunk has been written to Netty&#8217;s buffer, when backpressure-buffer-size watermark is reached, new chunks are not requested until buffer size decrease under the watermark value. * PREFETCH - After first data chunk arrives, expected number of chunks needed to fill the buffer up to watermark is calculated and requested. * AUTO_FLUSH - Data are requested one-by-one, in case buffer reaches watermark, no other data is requested and extra flush is initiated. * UNBOUNDED - No backpressure is applied, Long.MAX_VALUE(unbounded) is requested from upstream. Default is LINEAR validate-headers true boolean Whether to validate header names, if they contain illegal characters. initial-buffer-size 128 int Initial size of buffer used to parse HTTP line and headers tls &#160; Object Configuration of TLS, please see our TLS example in repository ",
            "title": "Configuration options"
        },
        {
            "location": "/about/03_prerequisites",
            "text": " Everything you need to get started with Helidon is listed here. ",
            "title": "preambule"
        },
        {
            "location": "/about/03_prerequisites",
            "text": " Helidon requires Java 11 (or newer) and Maven. You need Docker if you want to build and deploy Docker containers. If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop ). <div class=\"table__overflow elevation-1 flex sm7 \"> Java&#160;SE&#160;11 ( Open&#160;JDK&#160;11 ) or newer Maven 3.6.1+ Docker 18.09+ Kubectl 1.16.5+ <markup lang=\"bash\" title=\"Verify Prerequisites\" >java -version mvn --version docker --version kubectl version --short ",
            "title": "Prerequisites"
        },
        {
            "location": "/about/03_prerequisites",
            "text": "<markup lang=\"bash\" title=\"Setting JAVA_HOME\" ># On Mac export JAVA_HOME=`/usr/libexec/java_home -v 11` # On Linux # Use the appropriate path to your JDK export JAVA_HOME=/usr/lib/jvm/jdk-11 ",
            "title": "Setting JAVA_HOME"
        },
        {
            "location": "/about/03_prerequisites",
            "text": " Now you are ready to try the Quickstart Examples: Helidon MP Quickstart Example Helidon SE Quickstart Example See About Helidon for more information on the differences between Helidon MP and SE. See Helidon on Windows for some tips on using Helidon on Windows. ",
            "title": "Try the Quickstart Examples"
        },
        {
            "location": "/mp/lra/03_participant",
            "text": " javadoc Marks JAX-RS method which should run in LRA context and needs to be accompanied by at least minimal set of mandatory participant methods( Compensate or AfterLRA ). LRA options: value REQUIRED join incoming LRA or create and join new REQUIRES_NEW create and join new LRA MANDATORY join incoming LRA or fail SUPPORTS join incoming LRA or continue outside LRA context NOT_SUPPORTED always continue outside LRA context NEVER Fail with 412 if executed in LRA context NESTED create and join new LRA nested in the incoming LRA context timeLimit max time limit before LRA gets cancelled automatically by coordinator timeUnit time unit if the timeLimit value end when false LRA is not closed after successful method execution cancelOn which HTTP response codes of the method causes LRA to cancel cancelOnFamily which family of HTTP response codes causes LRA to cancel Method parameters: Header LRA_HTTP_CONTEXT_HEADER - id of the LRA transaction <markup lang=\"java\" >@PUT @LRA(LRA.Type.REQUIRES_NEW, timeLimit = 500, timeUnit = ChronoUnit.MILLIS) @Path(\"start-example\") public Response startLra(@HeaderParam(LRA_HTTP_CONTEXT_HEADER) URI lraId, String data) ",
            "title": "@LRA"
        },
        {
            "location": "/mp/lra/03_participant",
            "text": " Header LRA_HTTP_CONTEXT_HEADER - id of the LRA transaction Header LRA_HTTP_PARENT_CONTEXT_HEADER - parent LRA id in case of nested LRA <markup lang=\"java\" >@PUT @Path(\"/compensate\") @Compensate public Response compensateWork(@HeaderParam(LRA_HTTP_CONTEXT_HEADER) URI lraId, @HeaderParam(LRA_HTTP_PARENT_CONTEXT_HEADER) URI parent){ return LRAResponse.compensated(); } ",
            "title": "JAX-RS variant with supported LRA context values:"
        },
        {
            "location": "/mp/lra/03_participant",
            "text": " URI with LRA id <markup lang=\"java\" >@Compensate public void compensate(URI lraId) ",
            "title": "Non JAX-RS variant with supported LRA context values:"
        },
        {
            "location": "/mp/lra/03_participant",
            "text": " javadoc Expected to be called by LRA coordinator only! Compensate method is called by coordinator when LRA is cancelled, usually by error during execution of method body of @LRA annotated method . If the method responds with 500 or 202, coordinator will eventually try the call again. If participant has @Status annotated method , coordinator retrieves the status to find out if retry should be done. JAX-RS variant with supported LRA context values: Header LRA_HTTP_CONTEXT_HEADER - id of the LRA transaction Header LRA_HTTP_PARENT_CONTEXT_HEADER - parent LRA id in case of nested LRA <markup lang=\"java\" >@PUT @Path(\"/compensate\") @Compensate public Response compensateWork(@HeaderParam(LRA_HTTP_CONTEXT_HEADER) URI lraId, @HeaderParam(LRA_HTTP_PARENT_CONTEXT_HEADER) URI parent){ return LRAResponse.compensated(); } Non JAX-RS variant with supported LRA context values: URI with LRA id <markup lang=\"java\" >@Compensate public void compensate(URI lraId) ",
            "title": "@Compensate"
        },
        {
            "location": "/mp/lra/03_participant",
            "text": " Header LRA_HTTP_CONTEXT_HEADER - id of the LRA transaction Header LRA_HTTP_PARENT_CONTEXT_HEADER - parent LRA id in case of nested LRA <markup lang=\"java\" >@PUT @Path(\"/complete\") @Complete public Response complete(@HeaderParam(LRA_HTTP_CONTEXT_HEADER) URI lraId, @HeaderParam(LRA_HTTP_PARENT_CONTEXT_HEADER) URI parentLraId) ",
            "title": "JAX-RS variant with supported LRA context values:"
        },
        {
            "location": "/mp/lra/03_participant",
            "text": " URI with LRA id <markup lang=\"java\" >@Complete public void complete(URI lraId) ",
            "title": "Non JAX-RS variant with supported LRA context values:"
        },
        {
            "location": "/mp/lra/03_participant",
            "text": " javadoc Expected to be called by LRA coordinator only! Complete method is called by coordinator when LRA is successfully closed. If the method responds with 500 or 202, coordinator will eventually try the call again. If participant has @Status annotated method , coordinator retrieves the status to find out if retry should be done. JAX-RS variant with supported LRA context values: Header LRA_HTTP_CONTEXT_HEADER - id of the LRA transaction Header LRA_HTTP_PARENT_CONTEXT_HEADER - parent LRA id in case of nested LRA <markup lang=\"java\" >@PUT @Path(\"/complete\") @Complete public Response complete(@HeaderParam(LRA_HTTP_CONTEXT_HEADER) URI lraId, @HeaderParam(LRA_HTTP_PARENT_CONTEXT_HEADER) URI parentLraId) Non JAX-RS variant with supported LRA context values: URI with LRA id <markup lang=\"java\" >@Complete public void complete(URI lraId) ",
            "title": "@Complete"
        },
        {
            "location": "/mp/lra/03_participant",
            "text": " Header LRA_HTTP_CONTEXT_HEADER - id of the LRA transaction Header LRA_HTTP_PARENT_CONTEXT_HEADER - parent LRA id in case of nested LRA <markup lang=\"java\" >@DELETE @Path(\"/forget\") @Forget public Response forget(@HeaderParam(LRA_HTTP_CONTEXT_HEADER) URI lraId, @HeaderParam(LRA_HTTP_PARENT_CONTEXT_HEADER) URI parent) ",
            "title": "JAX-RS variant with supported LRA context values:"
        },
        {
            "location": "/mp/lra/03_participant",
            "text": " URI with LRA id <markup lang=\"java\" >@Forget public void forget(URI lraId) } ",
            "title": "Non JAX-RS variant with supported LRA context values:"
        },
        {
            "location": "/mp/lra/03_participant",
            "text": " javadoc Expected to be called by LRA coordinator only! Complete and compensate methods can fail(500) or report that compensation/completion is in progress(202). In such case participant needs to be prepared to report its status over @Status annotated method to coordinator . When coordinator decides all the participants have finished, method annotated with @Forget is called. JAX-RS variant with supported LRA context values: Header LRA_HTTP_CONTEXT_HEADER - id of the LRA transaction Header LRA_HTTP_PARENT_CONTEXT_HEADER - parent LRA id in case of nested LRA <markup lang=\"java\" >@DELETE @Path(\"/forget\") @Forget public Response forget(@HeaderParam(LRA_HTTP_CONTEXT_HEADER) URI lraId, @HeaderParam(LRA_HTTP_PARENT_CONTEXT_HEADER) URI parent) Non JAX-RS variant with supported LRA context values: URI with LRA id <markup lang=\"java\" >@Forget public void forget(URI lraId) } ",
            "title": "@Forget"
        },
        {
            "location": "/mp/lra/03_participant",
            "text": " javadoc Method annotated with @Leave called with LRA context(with header LRA_HTTP_CONTEXT_HEADER ) informs coordinator that current participant is leaving the LRA. Method body is executed after leave signal is sent. As a result, participant methods complete and compensate won&#8217;t be called when the particular LRA ends. Header LRA_HTTP_CONTEXT_HEADER - id of the LRA transaction <markup lang=\"java\" >@PUT @Path(\"/leave\") @Leave public Response leaveLRA(@HeaderParam(LRA_HTTP_CONTEXT_HEADER) URI lraIdtoLeave) ",
            "title": "@Leave"
        },
        {
            "location": "/mp/lra/03_participant",
            "text": " Header LRA_HTTP_CONTEXT_HEADER - id of the LRA transaction ParticipantStatus - Status of the participant reported to coordinator <markup lang=\"java\" >@GET @Path(\"/status\") @Status public Response reportStatus(@HeaderParam(LRA_HTTP_CONTEXT_HEADER) URI lraId) { return Response.status(ParticipantStatus.FailedToCompensate).build(); } ",
            "title": "JAX-RS variant with supported LRA context values:"
        },
        {
            "location": "/mp/lra/03_participant",
            "text": " URI with LRA id ParticipantStatus - Status of the participant reported to coordinator <markup lang=\"java\" >@Status public Response reportStatus(URI lraId){ return Response.ok(ParticipantStatus.FailedToCompensate).build(); } ",
            "title": "Non JAX-RS variant with supported LRA context values:"
        },
        {
            "location": "/mp/lra/03_participant",
            "text": " javadoc Expected to be called by LRA coordinator only! If the coordinator&#8217;s call to the particpant&#8217;s method fails, then it will retry the call. If the participant is not idempotent, then it may need to report its state to coordinator by declaring method annotated with @Status for reporting if previous call did change participant status. Coordinator can call it and decide if compensate or complete retry is needed. JAX-RS variant with supported LRA context values: Header LRA_HTTP_CONTEXT_HEADER - id of the LRA transaction ParticipantStatus - Status of the participant reported to coordinator <markup lang=\"java\" >@GET @Path(\"/status\") @Status public Response reportStatus(@HeaderParam(LRA_HTTP_CONTEXT_HEADER) URI lraId) { return Response.status(ParticipantStatus.FailedToCompensate).build(); } Non JAX-RS variant with supported LRA context values: URI with LRA id ParticipantStatus - Status of the participant reported to coordinator <markup lang=\"java\" >@Status public Response reportStatus(URI lraId){ return Response.ok(ParticipantStatus.FailedToCompensate).build(); } ",
            "title": "@Status"
        },
        {
            "location": "/mp/lra/03_participant",
            "text": " Header LRA_HTTP_ENDED_CONTEXT_HEADER - id of the finished LRA transaction Header LRA_HTTP_PARENT_CONTEXT_HEADER - parent LRA id in case of nested LRA LRAStatus - Final status of the LRA ( Cancelled , Closed , FailedToCancel , FailedToClose ) <markup lang=\"java\" >@PUT @Path(\"/finished\") @AfterLRA public Response whenLRAFinishes(@HeaderParam(LRA_HTTP_ENDED_CONTEXT_HEADER) URI lraId, @HeaderParam(LRA_HTTP_PARENT_CONTEXT_HEADER) URI parentLraId, LRAStatus status) ",
            "title": "JAX-RS variant with supported LRA context values:"
        },
        {
            "location": "/mp/lra/03_participant",
            "text": " URI with finished LRA id LRAStatus - Final status of the LRA ( Cancelled , Closed , FailedToCancel , FailedToClose ) <markup lang=\"java\" >public void whenLRAFinishes(URI lraId, LRAStatus status) ",
            "title": "Non JAX-RS variant with supported LRA context values:"
        },
        {
            "location": "/mp/lra/03_participant",
            "text": " javadoc Expected to be called by LRA coordinator only! Method annotated with @AfterLRA in the same class as the one with @LRA annotation gets invoked after particular LRA finishes. JAX-RS variant with supported LRA context values: Header LRA_HTTP_ENDED_CONTEXT_HEADER - id of the finished LRA transaction Header LRA_HTTP_PARENT_CONTEXT_HEADER - parent LRA id in case of nested LRA LRAStatus - Final status of the LRA ( Cancelled , Closed , FailedToCancel , FailedToClose ) <markup lang=\"java\" >@PUT @Path(\"/finished\") @AfterLRA public Response whenLRAFinishes(@HeaderParam(LRA_HTTP_ENDED_CONTEXT_HEADER) URI lraId, @HeaderParam(LRA_HTTP_PARENT_CONTEXT_HEADER) URI parentLraId, LRAStatus status) Non JAX-RS variant with supported LRA context values: URI with finished LRA id LRAStatus - Final status of the LRA ( Cancelled , Closed , FailedToCancel , FailedToClose ) <markup lang=\"java\" >public void whenLRAFinishes(URI lraId, LRAStatus status) ",
            "title": "@AfterLRA"
        },
        {
            "location": "/mp/lra/03_participant",
            "text": " The Participant, or Compensator, is an LRA resource with at least one of the JAX-RS(or non-JAX-RS) methods annotated with @Compensate or @AfterLRA . @LRA javadoc Marks JAX-RS method which should run in LRA context and needs to be accompanied by at least minimal set of mandatory participant methods( Compensate or AfterLRA ). LRA options: value REQUIRED join incoming LRA or create and join new REQUIRES_NEW create and join new LRA MANDATORY join incoming LRA or fail SUPPORTS join incoming LRA or continue outside LRA context NOT_SUPPORTED always continue outside LRA context NEVER Fail with 412 if executed in LRA context NESTED create and join new LRA nested in the incoming LRA context timeLimit max time limit before LRA gets cancelled automatically by coordinator timeUnit time unit if the timeLimit value end when false LRA is not closed after successful method execution cancelOn which HTTP response codes of the method causes LRA to cancel cancelOnFamily which family of HTTP response codes causes LRA to cancel Method parameters: Header LRA_HTTP_CONTEXT_HEADER - id of the LRA transaction <markup lang=\"java\" >@PUT @LRA(LRA.Type.REQUIRES_NEW, timeLimit = 500, timeUnit = ChronoUnit.MILLIS) @Path(\"start-example\") public Response startLra(@HeaderParam(LRA_HTTP_CONTEXT_HEADER) URI lraId, String data) @Compensate javadoc Expected to be called by LRA coordinator only! Compensate method is called by coordinator when LRA is cancelled, usually by error during execution of method body of @LRA annotated method . If the method responds with 500 or 202, coordinator will eventually try the call again. If participant has @Status annotated method , coordinator retrieves the status to find out if retry should be done. JAX-RS variant with supported LRA context values: Header LRA_HTTP_CONTEXT_HEADER - id of the LRA transaction Header LRA_HTTP_PARENT_CONTEXT_HEADER - parent LRA id in case of nested LRA <markup lang=\"java\" >@PUT @Path(\"/compensate\") @Compensate public Response compensateWork(@HeaderParam(LRA_HTTP_CONTEXT_HEADER) URI lraId, @HeaderParam(LRA_HTTP_PARENT_CONTEXT_HEADER) URI parent){ return LRAResponse.compensated(); } Non JAX-RS variant with supported LRA context values: URI with LRA id <markup lang=\"java\" >@Compensate public void compensate(URI lraId) @Complete javadoc Expected to be called by LRA coordinator only! Complete method is called by coordinator when LRA is successfully closed. If the method responds with 500 or 202, coordinator will eventually try the call again. If participant has @Status annotated method , coordinator retrieves the status to find out if retry should be done. JAX-RS variant with supported LRA context values: Header LRA_HTTP_CONTEXT_HEADER - id of the LRA transaction Header LRA_HTTP_PARENT_CONTEXT_HEADER - parent LRA id in case of nested LRA <markup lang=\"java\" >@PUT @Path(\"/complete\") @Complete public Response complete(@HeaderParam(LRA_HTTP_CONTEXT_HEADER) URI lraId, @HeaderParam(LRA_HTTP_PARENT_CONTEXT_HEADER) URI parentLraId) Non JAX-RS variant with supported LRA context values: URI with LRA id <markup lang=\"java\" >@Complete public void complete(URI lraId) @Forget javadoc Expected to be called by LRA coordinator only! Complete and compensate methods can fail(500) or report that compensation/completion is in progress(202). In such case participant needs to be prepared to report its status over @Status annotated method to coordinator . When coordinator decides all the participants have finished, method annotated with @Forget is called. JAX-RS variant with supported LRA context values: Header LRA_HTTP_CONTEXT_HEADER - id of the LRA transaction Header LRA_HTTP_PARENT_CONTEXT_HEADER - parent LRA id in case of nested LRA <markup lang=\"java\" >@DELETE @Path(\"/forget\") @Forget public Response forget(@HeaderParam(LRA_HTTP_CONTEXT_HEADER) URI lraId, @HeaderParam(LRA_HTTP_PARENT_CONTEXT_HEADER) URI parent) Non JAX-RS variant with supported LRA context values: URI with LRA id <markup lang=\"java\" >@Forget public void forget(URI lraId) } @Leave javadoc Method annotated with @Leave called with LRA context(with header LRA_HTTP_CONTEXT_HEADER ) informs coordinator that current participant is leaving the LRA. Method body is executed after leave signal is sent. As a result, participant methods complete and compensate won&#8217;t be called when the particular LRA ends. Header LRA_HTTP_CONTEXT_HEADER - id of the LRA transaction <markup lang=\"java\" >@PUT @Path(\"/leave\") @Leave public Response leaveLRA(@HeaderParam(LRA_HTTP_CONTEXT_HEADER) URI lraIdtoLeave) @Status javadoc Expected to be called by LRA coordinator only! If the coordinator&#8217;s call to the particpant&#8217;s method fails, then it will retry the call. If the participant is not idempotent, then it may need to report its state to coordinator by declaring method annotated with @Status for reporting if previous call did change participant status. Coordinator can call it and decide if compensate or complete retry is needed. JAX-RS variant with supported LRA context values: Header LRA_HTTP_CONTEXT_HEADER - id of the LRA transaction ParticipantStatus - Status of the participant reported to coordinator <markup lang=\"java\" >@GET @Path(\"/status\") @Status public Response reportStatus(@HeaderParam(LRA_HTTP_CONTEXT_HEADER) URI lraId) { return Response.status(ParticipantStatus.FailedToCompensate).build(); } Non JAX-RS variant with supported LRA context values: URI with LRA id ParticipantStatus - Status of the participant reported to coordinator <markup lang=\"java\" >@Status public Response reportStatus(URI lraId){ return Response.ok(ParticipantStatus.FailedToCompensate).build(); } @AfterLRA javadoc Expected to be called by LRA coordinator only! Method annotated with @AfterLRA in the same class as the one with @LRA annotation gets invoked after particular LRA finishes. JAX-RS variant with supported LRA context values: Header LRA_HTTP_ENDED_CONTEXT_HEADER - id of the finished LRA transaction Header LRA_HTTP_PARENT_CONTEXT_HEADER - parent LRA id in case of nested LRA LRAStatus - Final status of the LRA ( Cancelled , Closed , FailedToCancel , FailedToClose ) <markup lang=\"java\" >@PUT @Path(\"/finished\") @AfterLRA public Response whenLRAFinishes(@HeaderParam(LRA_HTTP_ENDED_CONTEXT_HEADER) URI lraId, @HeaderParam(LRA_HTTP_PARENT_CONTEXT_HEADER) URI parentLraId, LRAStatus status) Non JAX-RS variant with supported LRA context values: URI with finished LRA id LRAStatus - Final status of the LRA ( Cancelled , Closed , FailedToCancel , FailedToClose ) <markup lang=\"java\" >public void whenLRAFinishes(URI lraId, LRAStatus status) ",
            "title": "Participant"
        },
        {
            "location": "/mp/metrics/04_prometheus_exemplar_support",
            "text": " Add Helidon MP support for OpenMetrics (Prometheus) exemplars for histograms, counters, and simple timers to your application simply by adding dependencies to your project&#8217;s pom.xml . ",
            "title": "preambule"
        },
        {
            "location": "/mp/metrics/04_prometheus_exemplar_support",
            "text": " Declare the following dependency in your project: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics-trace-exemplar&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; Also, include either Helidon Zipkin or Helidon Jaeger support: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-zipkin&lt;/artifactId&gt; &lt;/dependency&gt; or <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-jaeger&lt;/artifactId&gt; &lt;/dependency&gt; Be sure Zipkin or Jaeger, whichever you chose, is running and accessible to your server. ",
            "title": "Prerequisites"
        },
        {
            "location": "/mp/metrics/04_prometheus_exemplar_support",
            "text": " Note exemplar - one that serves as a model or example &#8201;&#8212;&#8201;Merriam-Webster Dictionary When you add the helidon-metrics-trace-exemplar dependency&#8212;&#8203;and one for either Zipkin or Jaeger&#8212;&#8203;to your application, Helidon automatically records a sample (label, value, and timestamp) with each update to a histogram, simple timer, or counter. Helidon adds the label, value, and timestamp to the OpenMetrics output returned from the Helidon metrics endpoint ( /metrics unless you set it up otherwise). # TYPE application_getTimer_mean_seconds gauge application_getTimer_mean_seconds 8.303030623354298E-4 # {trace_id=\"067632454fe4e8d1\"} 1.14701E-4 1617723032.570000 # TYPE application_getTimer_max_seconds gauge application_getTimer_max_seconds 0.003952636 # {trace_id=\"fce183094e471633\"} 0.003952636 1617723030.108000 # TYPE application_getTimer_min_seconds gauge application_getTimer_min_seconds 5.5254E-5 # {trace_id=\"0b1a4bf22b4e47fd\"} 5.5254E-5 1617723033.311000 This exemplar is a sample with value at least as close to the mean as any other sample. This exemplar is for an exact sample with value the same as the maximum value the timer has observed. # TYPE application_globalRequestTracker_total counter # HELP application_globalRequestTracker_total application_globalRequestTracker_total 4 # {trace_id=\"daf26fe35fee9917\"} 0.001183992 1617725180.234000 # TYPE application_globalRequestTracker_elapsedTime_seconds gauge application_globalRequestTracker_elapsedTime_seconds 0.030309068 # {trace_id=\"daf26fe35fee9917\"} 0.001183992 1617725180.234000 The exemplar for a SimpleTimer is the same for the total and the elapsedTime submetrics: always the most recent sample which updated the SimpleTimer . Helidon adds an exemplar to the output for each statistical value&#8212;&#8203;such as minimum, maximum, mean, and quantiles&#8212;&#8203;for histograms, timers, simple times, and for counters. The exemplar information describes a single, actual sample that is representative of the statistical value. Helidon chooses the representative examplar for each value using information that is already recorded for each type of metric: If a metric necessarily corresponds to a specific sample&#8212;&#8203;for example a minimum or maximum&#8212;&#8203;Helidon associates a sample that has that exact value as the exemplar for the metric. If a metric collects samples into bins (quantiles), Helidon associates a sample from that bin with the bin&#8217;s output. If a metric maintains running statistics (counts, totals), Helidon associates the most recent sample for that metric. If Helidon computes a metric&#8217;s value from a number of samples&#8212;&#8203;for example, mean&#8212;&#8203;Helidon associates a sample for which its value is at least as close as other samples to the statistical calculation. In cases with multiple representative samples (for example, two samples' values are equally close to the mean), Helidon chooses one of them arbitrarily. ",
            "title": "Interpreting Exemplars"
        },
        {
            "location": "/mp/introduction/02_microprofile",
            "text": " Complete these tasks to get started with your MicroProfile application. ",
            "title": "preambule"
        },
        {
            "location": "/mp/introduction/02_microprofile",
            "text": " The Managing Dependencies page describes how you should declare dependency management for Helidon applications. Then declare the following dependency in your project: <markup lang=\"xml\" title=\"Maven Dependency for full MicroProfile\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.bundles&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile&lt;/artifactId&gt; &lt;/dependency&gt; The above dependency adds all the features available in MicroProfile. If you want to start with a smaller core set of features then you can use the core bundle instead. This bundle includes the base feature in MicroProfile (such as JAX-RS, CDI, JSON-P/B, and Config) and leaves out some of the additional features such as Metrics and Tracing. You can add those dependencies individually if you choose. <markup lang=\"xml\" title=\"Maven Dependency for MicroProfile core features only\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.bundles&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-core&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/introduction/02_microprofile",
            "text": " Create a JAX-RS Resource class with at least one resource method. <markup lang=\"java\" title=\"Sample JAX-RS Resource Class\" >@Path(\"/\") @RequestScoped public class HelloWorldResource { @GET @Produces(MediaType.TEXT_PLAIN) public String message() { return \"Hello World\"; } } And create a JAX-RS application. <markup lang=\"java\" title=\"Sample JAX-RS Application\" >@ApplicationScoped @ApplicationPath(\"/\") public class HelloWorldApplication extends Application { @Override public Set&lt;Class&lt;?&gt;&gt; getClasses() { return Set.of( HelloWorldResource.class ); } } Add beans.xml in src/main/resources/META-INF so the CDI implementation can pick up your classes. <markup lang=\"xml\" title=\"beans.xml\" >&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;beans/&gt; As a last step, add a main method to your application (or a dedicated Main class) to start everything up. <markup lang=\"java\" title=\"Sample JAX-RS Application\" >public static void main(String[] args) { io.helidon.microprofile.server.Main.main(args); } Run the main class. The server will start on port 7001 and serve your resources. ",
            "title": "Project files"
        },
        {
            "location": "/mp/introduction/02_microprofile",
            "text": " Jandex is an indexing tool for Weld (the CDI implementation used by Helidon) that helps speed up the boot time of an application. To use Jandex, configure a Maven plugin that adds the index to your JAR file and a dependency on Jandex. <markup lang=\"xml\" title=\"jandex dependency\" >&lt;dependency&gt; &lt;groupId&gt;org.jboss&lt;/groupId&gt; &lt;artifactId&gt;jandex&lt;/artifactId&gt; &lt;version&gt;2.0.4.Final&lt;/version&gt; &lt;/dependency&gt; <markup lang=\"xml\" title=\"jandex plugin configuration\" >&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.jboss.jandex&lt;/groupId&gt; &lt;artifactId&gt;jandex-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.0.5&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;make-index&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;jandex&lt;/goal&gt; &lt;/goals&gt; &lt;phase&gt;process-classes&lt;/phase&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; ",
            "title": "Adding Jandex"
        },
        {
            "location": "/mp/introduction/02_microprofile",
            "text": " Helidon provides a MicroProfile server implementation ( io.helidon.microprofile.server ) that encapsulates the Helidon WebServer. You can either instantiate the server directly as is done in the Helidon MP Quickstart example or use its built-in main as shown below. Maven Coordinates The Managing Dependencies page describes how you should declare dependency management for Helidon applications. Then declare the following dependency in your project: <markup lang=\"xml\" title=\"Maven Dependency for full MicroProfile\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.bundles&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile&lt;/artifactId&gt; &lt;/dependency&gt; The above dependency adds all the features available in MicroProfile. If you want to start with a smaller core set of features then you can use the core bundle instead. This bundle includes the base feature in MicroProfile (such as JAX-RS, CDI, JSON-P/B, and Config) and leaves out some of the additional features such as Metrics and Tracing. You can add those dependencies individually if you choose. <markup lang=\"xml\" title=\"Maven Dependency for MicroProfile core features only\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.bundles&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-core&lt;/artifactId&gt; &lt;/dependency&gt; Project files Create a JAX-RS Resource class with at least one resource method. <markup lang=\"java\" title=\"Sample JAX-RS Resource Class\" >@Path(\"/\") @RequestScoped public class HelloWorldResource { @GET @Produces(MediaType.TEXT_PLAIN) public String message() { return \"Hello World\"; } } And create a JAX-RS application. <markup lang=\"java\" title=\"Sample JAX-RS Application\" >@ApplicationScoped @ApplicationPath(\"/\") public class HelloWorldApplication extends Application { @Override public Set&lt;Class&lt;?&gt;&gt; getClasses() { return Set.of( HelloWorldResource.class ); } } Add beans.xml in src/main/resources/META-INF so the CDI implementation can pick up your classes. <markup lang=\"xml\" title=\"beans.xml\" >&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;beans/&gt; As a last step, add a main method to your application (or a dedicated Main class) to start everything up. <markup lang=\"java\" title=\"Sample JAX-RS Application\" >public static void main(String[] args) { io.helidon.microprofile.server.Main.main(args); } Run the main class. The server will start on port 7001 and serve your resources. Adding Jandex Jandex is an indexing tool for Weld (the CDI implementation used by Helidon) that helps speed up the boot time of an application. To use Jandex, configure a Maven plugin that adds the index to your JAR file and a dependency on Jandex. <markup lang=\"xml\" title=\"jandex dependency\" >&lt;dependency&gt; &lt;groupId&gt;org.jboss&lt;/groupId&gt; &lt;artifactId&gt;jandex&lt;/artifactId&gt; &lt;version&gt;2.0.4.Final&lt;/version&gt; &lt;/dependency&gt; <markup lang=\"xml\" title=\"jandex plugin configuration\" >&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.jboss.jandex&lt;/groupId&gt; &lt;artifactId&gt;jandex-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.0.5&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;make-index&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;jandex&lt;/goal&gt; &lt;/goals&gt; &lt;phase&gt;process-classes&lt;/phase&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; ",
            "title": "Getting Started with Helidon MicroProfile"
        },
        {
            "location": "/mp/oci/02_object-storage",
            "text": " You can use Helidon&#8217;s OCI SDK Extension to access OCI Services. This document describes how to use it to access OCI Object Storage. ",
            "title": "preambule"
        },
        {
            "location": "/mp/oci/02_object-storage",
            "text": " To enable OCI Object Storage add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.oci.sdk&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-oci-sdk-cdi&lt;/artifactId&gt; &lt;/dependency&gt; Then add a dependency on the OCI SDK&#8217;s Object Storage API: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;com.oracle.oci.sdk&lt;/groupId&gt; &lt;artifactId&gt;oci-java-sdk-objectstorage&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/oci/02_object-storage",
            "text": " Once you have Helidon&#8217;s OCI extension added to your application you can inject OCI SDK Clients. <markup lang=\"java\" title=\"Field-injection example\" > @Inject private ObjectStorage client; <markup lang=\"java\" title=\"Constructor-injection example\" > private final ObjectStorage client; @Inject public YourConstructor(@Named(\"orders\") ObjectStorage client) { super(); this.client = client; } The extension implements this injection point by creating an Object Storage client object in the singleton scope . ",
            "title": "Injecting an Object Storage client"
        },
        {
            "location": "/mp/oci/02_object-storage",
            "text": " By default the extension will select and configure an appropriate OCI Authentication Details Provider for you based on your environment. For this reason it is recommended that you configure your environment first and get it working with the OCI CLI before using the Helidon OCI SDK Extension. For more information see Helidon OCI Extension . ",
            "title": "Configuring the Helidon OCI SDK Extension"
        },
        {
            "location": "/mp/oci/02_object-storage",
            "text": " Once you have injected an ObjectStorage client you can use it as described in: OCI SDK Object Storage Javadocs OCI Object Storage Overview ",
            "title": "Using the Object Storage client"
        },
        {
            "location": "/se/webserver/11_access-log",
            "text": " Access logging in Helidon is done by a dedicated module that can be added to WebServer and configured. Access logging is a Helidon WebServer Service and as such is executed in the order it is registered with WebServer routing. This implies that if you register it last and another Service or Handler finishes the request, the service will not be invoked. ",
            "title": "preambule"
        },
        {
            "location": "/se/webserver/11_access-log",
            "text": " Access log is configured in your code by registering it as a service with Routing <markup lang=\"java\" >Routing.builder() .register(AccessLogSupport.create(config.get(\"server.access-log\"))) .get(\"/greet\", myService) The order of registration is significant - make sure AccessLogSupport is registered first (even before security, tracing etc.). ",
            "title": "Configuring Access Log in your code"
        },
        {
            "location": "/se/webserver/11_access-log",
            "text": " Access log can be configured as follows: <markup lang=\"yaml\" title=\"Access Log configuration file\" >server: port: 8080 access-log: format: \"%h %l %u %t %r %s %b %{Referer}i\" All options shown above are also available programmatically when using builder. ",
            "title": "Configuring Access Log in a configuration file"
        },
        {
            "location": "/se/webserver/11_access-log",
            "text": " The following configuration options can be defined: Config key Default value Builder method Description enabled true enabled(boolean) When this option is set to false , access logging will be disabled logger-name io.helidon.webserver.AccessLog loggerName(String) Name of the logger to use when writing log entries format helidon helidonLogFormat() , commonLogFormat() , add(AccessLogEntry entry) Configuration of access log output, when helidon is defined, the Helidon log format (see below) is used. Can be configured to explicitly define log entries (see below as well) exclude-paths N/A excludePaths(List&lt;String&gt;) List of path patterns to exclude from access log. Path pattern syntax is as defined in io.helidon.webserver.PathMatcher . Can be used to exclude paths such as /health or /metrics to avoid cluttering log. ",
            "title": "Configuration options"
        },
        {
            "location": "/se/webserver/11_access-log",
            "text": " The following log entries are supported in Helidon: Config format Class (to use with builder) Description %h HostLogEntry IP address of the remote host %l UserIdLogEntry Client identity, always undefined in Helidon %u UserLogEntry The username of logged-in user (when Security is used) %t TimestampLogEntry The current timestamp %r RequestLineLogEntry The request line (method, path and HTTP version) %s StatusLogEntry The HTTP status returned to the client %b SizeLogEntry The response entity size (if available) %D TimeTakenLogEntry The time taken in microseconds %T TimeTakenLogEntry The time taken in seconds %{ header-name }i HeaderLogEntry Value of a header (can have multiple such specification to write multiple headers) Currently we only support the entries defined above, with NO support for free text. ",
            "title": "Supported Log Entries"
        },
        {
            "location": "/se/webserver/11_access-log",
            "text": " When format is set to helidon , the format used is: \"%h %u %t %r %s %b %D\" The entries logged: IP Address Username of a logged-in user Timestamp Request Line HTTP Status code Entity size Time taken (microseconds) Access log example: 192.168.0.104 - [18/Jun/2019:22:28:55 +0200] \"GET /greet/test HTTP/1.1\" 200 53 0:0:0:0:0:0:0:1 - [18/Jun/2019:22:29:00 +0200] \"GET /metrics/vendor HTTP/1.1\" 200 1658 0:0:0:0:0:0:0:1 jack [18/Jun/2019:22:29:07 +0200] \"PUT /greet/greeting HTTP/1.1\" 200 21 0:0:0:0:0:0:0:1 jill [18/Jun/2019:22:29:12 +0200] \"PUT /greet/greeting HTTP/1.1\" 403 0 0:0:0:0:0:0:0:1 - [18/Jun/2019:22:29:17 +0200] \"PUT /greet/greeting HTTP/1.1\" 401 0 ",
            "title": "Helidon Log Format"
        },
        {
            "location": "/se/webserver/11_access-log",
            "text": " When format is set to common , the format used is: \"%h %l %u %t %r %s %b\" The entries logged: IP Address Client identity Username of a logged-in user Timestamp Request Line HTTP Status code Entity size Access log example: 192.168.0.104 - - [18/Jun/2019:22:28:55 +0200] \"GET /greet/test HTTP/1.1\" 200 53 0:0:0:0:0:0:0:1 - - [18/Jun/2019:22:29:00 +0200] \"GET /metrics/vendor HTTP/1.1\" 200 1658 0:0:0:0:0:0:0:1 - jack [18/Jun/2019:22:29:07 +0200] \"PUT /greet/greeting HTTP/1.1\" 200 21 0:0:0:0:0:0:0:1 - jill [18/Jun/2019:22:29:12 +0200] \"PUT /greet/greeting HTTP/1.1\" 403 0 0:0:0:0:0:0:0:1 - - [18/Jun/2019:22:29:17 +0200] \"PUT /greet/greeting HTTP/1.1\" 401 0 ",
            "title": "Common Log Format"
        },
        {
            "location": "/se/webserver/11_access-log",
            "text": " Supported Log Entries The following log entries are supported in Helidon: Config format Class (to use with builder) Description %h HostLogEntry IP address of the remote host %l UserIdLogEntry Client identity, always undefined in Helidon %u UserLogEntry The username of logged-in user (when Security is used) %t TimestampLogEntry The current timestamp %r RequestLineLogEntry The request line (method, path and HTTP version) %s StatusLogEntry The HTTP status returned to the client %b SizeLogEntry The response entity size (if available) %D TimeTakenLogEntry The time taken in microseconds %T TimeTakenLogEntry The time taken in seconds %{ header-name }i HeaderLogEntry Value of a header (can have multiple such specification to write multiple headers) Currently we only support the entries defined above, with NO support for free text. Helidon Log Format When format is set to helidon , the format used is: \"%h %u %t %r %s %b %D\" The entries logged: IP Address Username of a logged-in user Timestamp Request Line HTTP Status code Entity size Time taken (microseconds) Access log example: 192.168.0.104 - [18/Jun/2019:22:28:55 +0200] \"GET /greet/test HTTP/1.1\" 200 53 0:0:0:0:0:0:0:1 - [18/Jun/2019:22:29:00 +0200] \"GET /metrics/vendor HTTP/1.1\" 200 1658 0:0:0:0:0:0:0:1 jack [18/Jun/2019:22:29:07 +0200] \"PUT /greet/greeting HTTP/1.1\" 200 21 0:0:0:0:0:0:0:1 jill [18/Jun/2019:22:29:12 +0200] \"PUT /greet/greeting HTTP/1.1\" 403 0 0:0:0:0:0:0:0:1 - [18/Jun/2019:22:29:17 +0200] \"PUT /greet/greeting HTTP/1.1\" 401 0 Common Log Format When format is set to common , the format used is: \"%h %l %u %t %r %s %b\" The entries logged: IP Address Client identity Username of a logged-in user Timestamp Request Line HTTP Status code Entity size Access log example: 192.168.0.104 - - [18/Jun/2019:22:28:55 +0200] \"GET /greet/test HTTP/1.1\" 200 53 0:0:0:0:0:0:0:1 - - [18/Jun/2019:22:29:00 +0200] \"GET /metrics/vendor HTTP/1.1\" 200 1658 0:0:0:0:0:0:0:1 - jack [18/Jun/2019:22:29:07 +0200] \"PUT /greet/greeting HTTP/1.1\" 200 21 0:0:0:0:0:0:0:1 - jill [18/Jun/2019:22:29:12 +0200] \"PUT /greet/greeting HTTP/1.1\" 403 0 0:0:0:0:0:0:0:1 - - [18/Jun/2019:22:29:17 +0200] \"PUT /greet/greeting HTTP/1.1\" 401 0 ",
            "title": "Supported Log Formats"
        },
        {
            "location": "/se/webserver/11_access-log",
            "text": " To support a separate file for Access log entries, Helidon provides a custom log handler, that extends the FileHandler . To log to a file access.log with appending records after restart, you can use the following configuration in logging.properties : <markup lang=\"properties\" title=\"Logging configuration file\" >io.helidon.webserver.accesslog.AccessLogHandler.level=INFO io.helidon.webserver.accesslog.AccessLogHandler.pattern=access.log io.helidon.webserver.accesslog.AccessLogHandler.append=true io.helidon.webserver.AccessLog.level=INFO io.helidon.webserver.AccessLog.useParentHandlers=false io.helidon.webserver.AccessLog.handlers=io.helidon.webserver.accesslog.AccessLogHandler ",
            "title": "Configuring Access Log with Java util logging"
        },
        {
            "location": "/se/grpc/04_service_implementation",
            "text": " While Helidon gRPC Server allows you to deploy any standard gRPC service that implements io.grpc.BindableService interface, including services generated from the Protobuf IDL files (and even allows you to customize them to a certain extent), using Helidon gRPC framework to implement your services has a number of benefits: It allows you to define both HTTP and gRPC services using similar programming model, simplifying learning curve for developers. It provides a number of helper methods that make service implementation significantly simpler. It allows you to configure some of the Helidon value-added features, such as security and metrics collection down to the method level. It allows you to easily specify custom marshaller for requests and responses if Protobuf does not satisfy your needs. It provides built in support for health checks . ",
            "title": "Service Implementation"
        },
        {
            "location": "/se/grpc/04_service_implementation",
            "text": " At the very basic level, all you need to do in order to implement a Helidon gRPC service is create a class that implements io.helidon.grpc.server.GrpcService interface and define one or more methods for the service: <markup lang=\"java\" >class EchoService implements GrpcService { @Override public void update(ServiceDescriptor.Rules rules) { rules.unary(\"Echo\", this::echo); } /** * Echo the message back to the caller. * * @param request the echo request containing the message to echo * @param observer the response observer */ public void echo(String request, StreamObserver&lt;String&gt; observer) { complete(observer, request); } } Define unary method Echo and map it to the this::echo handler. Create a handler for the Echo method. Send the request string back to the client by completing response observer. The complete method shown in the example above is just one of many helper methods available in the GrpcService class. See the full list here . The example above implements a service with a single unary method, which will be exposed at the `EchoService/Echo' endpoint. The service does not explicitly define a marshaller for requests and responses, so Java serialization will be used as a default. Unfortunately, this implies that you will have to implement clients by hand and configure them to use the same marshaller as the server. Obviously, one of the major selling points of gRPC is that it makes it easy to generate clients for a number of languages (as long as you use Protobuf for marshalling), so let&#8217;s see how we would implement Protobuf enabled Helidon gRPC service. ",
            "title": "Service Implementation Basics"
        },
        {
            "location": "/se/grpc/04_service_implementation",
            "text": " For this example, we will re-implement the EchoService above as a Protobuf service in echo.proto file. <markup lang=\"proto\" >syntax = \"proto3\"; option java_package = \"org.example.services.echo\"; service EchoService { rpc Echo (EchoRequest) returns (EchoResponse) {} } message EchoRequest { string message = 1; } message EchoResponse { string message = 1; } Based on this IDL, the gRPC compiler will generate message classes ( EchoRequest and EchoResponse ), client stubs that can be used to make RPC calls to the server, as well as the base class for the server-side service implementation. We can ignore the last one, and implement the service using Helidon gRPC framework instead. ",
            "title": "Define the Service IDL"
        },
        {
            "location": "/se/grpc/04_service_implementation",
            "text": " The service implementation will be very similar to our original implementation: <markup lang=\"java\" >class EchoService implements GrpcService { @Override public void update(ServiceDescriptor.Rules rules) { rules.proto(Echo.getDescriptor()) .unary(\"Echo\", this::echo); } /** * Echo the message back to the caller. * * @param request the echo request containing the message to echo * @param observer the response observer */ public void echo(Echo.EchoRequest request, StreamObserver&lt;Echo.EchoResponse&gt; observer) { String message = request.getMessage(); Echo.EchoResponse response = Echo.EchoResponse.newBuilder().setMessage(message).build(); complete(observer, response); } } Specify proto descriptor in order to provide necessary type information and enable Protobuf marshalling. Define unary method Echo and map it to the this::echo handler. Create a handler for the Echo method, using Protobuf message types for request and response. Extract message string from the request. Create the response containing extracted message. Send the response back to the client by completing response observer. ",
            "title": "Implement the Service"
        },
        {
            "location": "/se/grpc/04_service_implementation",
            "text": " In order to implement Protobuf-based service, you would follow the official instructions on the gRPC web site, which boil down to the following: Define the Service IDL For this example, we will re-implement the EchoService above as a Protobuf service in echo.proto file. <markup lang=\"proto\" >syntax = \"proto3\"; option java_package = \"org.example.services.echo\"; service EchoService { rpc Echo (EchoRequest) returns (EchoResponse) {} } message EchoRequest { string message = 1; } message EchoResponse { string message = 1; } Based on this IDL, the gRPC compiler will generate message classes ( EchoRequest and EchoResponse ), client stubs that can be used to make RPC calls to the server, as well as the base class for the server-side service implementation. We can ignore the last one, and implement the service using Helidon gRPC framework instead. Implement the Service The service implementation will be very similar to our original implementation: <markup lang=\"java\" >class EchoService implements GrpcService { @Override public void update(ServiceDescriptor.Rules rules) { rules.proto(Echo.getDescriptor()) .unary(\"Echo\", this::echo); } /** * Echo the message back to the caller. * * @param request the echo request containing the message to echo * @param observer the response observer */ public void echo(Echo.EchoRequest request, StreamObserver&lt;Echo.EchoResponse&gt; observer) { String message = request.getMessage(); Echo.EchoResponse response = Echo.EchoResponse.newBuilder().setMessage(message).build(); complete(observer, response); } } Specify proto descriptor in order to provide necessary type information and enable Protobuf marshalling. Define unary method Echo and map it to the this::echo handler. Create a handler for the Echo method, using Protobuf message types for request and response. Extract message string from the request. Create the response containing extracted message. Send the response back to the client by completing response observer. ",
            "title": "Implementing Protobuf Services"
        },
        {
            "location": "/mp/tracing/04_jaeger_metrics",
            "text": " Integrate the metrics from Jaeger tracing into your Helidon MP application simply by adding a dependency. ",
            "title": "preambule"
        },
        {
            "location": "/mp/tracing/04_jaeger_metrics",
            "text": " As the Helidon Jaeger Tracing document describes, you can use Jaeger tracing in your Helidon MP application. Jaeger maintains several metrics about its own activity (briefly outlined in the Jaeger client documentation ). This document explains how you can integrate those Jaeger tracing metrics with Helidon&#8217;s metrics. ",
            "title": "Overview"
        },
        {
            "location": "/mp/tracing/04_jaeger_metrics",
            "text": " Your pom.xml file should already contain the dependency for Helidon-Jaeger tracing integration. To enable integration with Jaeger&#8217;s metrics, add the following dependency: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics-jaeger&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; You can leave your application&#8217;s Java code unchanged. By adding this dependency, you instruct Helidon to monitor the Jaeger tracing metrics internally and to publish them using the Helidon metrics system. Rebuild and start your application. ",
            "title": "Prerequisites"
        },
        {
            "location": "/mp/tracing/04_jaeger_metrics",
            "text": " Submit a few requests to your application&#8217;s endpoints. This causes Jaeger to update its internal metrics. Then, when you access your application&#8217;s metrics endpoint ( /metrics by default), Helidon displays the updated Jaeger tracing metrics as part of the vendor metrics section. <markup lang=\"bash\" >curl -H \"Accept: application/json\" -X GET http://localhost:8080/metrics/vendor <markup lang=\"json\" title=\"Partial Helidon Metrics vendor Output Showing Jaeger Metrics\" > ... \"jaeger_tracer_baggage_restrictions_updates;result=err\": 0, \"jaeger_tracer_baggage_restrictions_updates;result=ok\": 0, \"jaeger_tracer_baggage_truncations\": 0, \"jaeger_tracer_baggage_updates;result=err\": 0, \"jaeger_tracer_baggage_updates;result=ok\": 0, \"jaeger_tracer_finished_spans\": 0, \"jaeger_tracer_reporter_queue_length\": 0, \"jaeger_tracer_reporter_spans;result=dropped\": 0, \"jaeger_tracer_reporter_spans;result=err\": 0, \"jaeger_tracer_reporter_spans;result=ok\": 0, \"jaeger_tracer_sampler_queries;result=err\": 1, \"jaeger_tracer_sampler_queries;result=ok\": 0, \"jaeger_tracer_sampler_updates;result=err\": 0, \"jaeger_tracer_sampler_updates;result=ok\": 0, \"jaeger_tracer_span_context_decoding_errors\": 0, \"jaeger_tracer_started_spans;sampled=n\": 15, \"jaeger_tracer_started_spans;sampled=y\": 0, \"jaeger_tracer_traces;sampled=n;state=joined\": 2, \"jaeger_tracer_traces;sampled=n;state=started\": 3, \"jaeger_tracer_traces;sampled=y;state=joined\": 0, \"jaeger_tracer_traces;sampled=y;state=started\": 0, ... Helidon publishes whatever metrics Jaeger creates. ",
            "title": "Accessing Jaeger Tracing Metrics"
        },
        {
            "location": "/se/grpc/07_metrics",
            "text": " Helidon gRPC Server has built-in support for metrics capture, which allows service developers to easily enable application-level metrics for their services. ",
            "title": "preambule"
        },
        {
            "location": "/se/grpc/07_metrics",
            "text": " By default, gRPC Server only captures two vendor-level metrics: grpc.request.count and grpc.request.meter . These metrics provide aggregate view of requests across all services, and serve as an indication of the overall server load. However, users can enable more fine grained metrics by simply configuring a built-in GrpcMetrics interceptor within the routing: <markup lang=\"java\" > private static GrpcRouting createRouting(Config config) { return GrpcRouting.builder() .intercept(GrpcMetrics.timed()) .register(new GreetService(config)) .register(new EchoService()) .build(); } Capture metrics for all methods of all services as a timer In the example above we have chosen to create and keep a timer metric type for each method of each service. Alternatively, we could&#8217;ve chosen to use a counter , meter or a histogram instead. ",
            "title": "Enabling Metrics Capture"
        },
        {
            "location": "/se/grpc/07_metrics",
            "text": " While global metrics capture is certainly useful, it is not always sufficient. Keeping a separate timer for each gRPC method may be an overkill, so the user could decide to use a lighter-weight metric type, such as counter or a meter . However, she may still want to enable histogram or a timer for some services, or even only some methods of some services. This can be easily accomplished by overriding the type of the captured metric at either service or the method level: <markup lang=\"java\" > private static GrpcRouting createRouting(Config config) { return GrpcRouting.builder() .intercept(GrpcMetrics.counted()) .register(new MyService()) .build(); } public static class MyService implements GrpcService { @Override public void update(ServiceDescriptor.Rules rules) { rules .intercept(GrpcMetrics.metered()) .unary(\"MyMethod\", this::myMethod, cfg -&gt; cfg.intercept(GrpcMetrics.timer())) } private &lt;ReqT, ResT&gt; void myMethod(ReqT request, StreamObserver&lt;ResT&gt; observer) { // do something } } Use counter for all methods of all services, unless overridden Use meter for all methods of MyService Use timer for MyService::MyMethod ",
            "title": "Overriding Metrics Capture"
        },
        {
            "location": "/se/grpc/07_metrics",
            "text": " Collected metrics are stored in the standard Helidon Metric Registries, such as vendor and application registry, and can be exposed via standard /metrics REST API. <markup lang=\"java\" > Routing routing = Routing.builder() .register(MetricsSupport.create()) .build(); WebServer.create(webServerConfig(), routing) .start() Add MetricsSupport instance to web server routing Create and start Helidon web server See Helidon Metrics documentation for more details. ",
            "title": "Exposing Metrics Externally"
        },
        {
            "location": "/se/grpc/07_metrics",
            "text": " To add tags to a metric a Map of key/value tags can be supplied. For example: <markup lang=\"java\" >Map&lt;String, String&gt; tagMap = new HashMap&lt;&gt;(); tagMap.put(\"keyOne\", \"valueOne\"); tagMap.put(\"keyTwo\", \"valueTwo\"); GrpcRouting routing = GrpcRouting.builder() .intercept(GrpcMetrics.counted().tags(tagMap)) .register(new MyService()) .build(); the tags() method is used to add the Map of tags to the metric. ",
            "title": "Adding Tags"
        },
        {
            "location": "/se/grpc/07_metrics",
            "text": " A meaningful description can be added to a metric: For example: <markup lang=\"java\" >GrpcRouting routing = GrpcRouting.builder() .intercept(GrpcMetrics.counted().description(\"Something useful\")) .register(new MyService()) .build(); the description() method is used to add the description to the metric. ",
            "title": "Adding a Description"
        },
        {
            "location": "/se/grpc/07_metrics",
            "text": " A units value can be added to the Metric: For example: <markup lang=\"java\" >GrpcRouting routing = GrpcRouting.builder() .intercept(GrpcMetrics.timed().units(MetricUnits.SECONDS)) .register(new MyService()) .build(); the units() method is used to add the metric units to the metric. Typically the units value is one of the constants from org.eclipse.microprofile.metrics.MetricUnits class. ",
            "title": "Adding Metric Units"
        },
        {
            "location": "/se/grpc/07_metrics",
            "text": " Helidon metrics contain meta-data such as tags, a description, units etc. It is possible to add this additional meta-data when specifying the metrics. Adding Tags To add tags to a metric a Map of key/value tags can be supplied. For example: <markup lang=\"java\" >Map&lt;String, String&gt; tagMap = new HashMap&lt;&gt;(); tagMap.put(\"keyOne\", \"valueOne\"); tagMap.put(\"keyTwo\", \"valueTwo\"); GrpcRouting routing = GrpcRouting.builder() .intercept(GrpcMetrics.counted().tags(tagMap)) .register(new MyService()) .build(); the tags() method is used to add the Map of tags to the metric. Adding a Description A meaningful description can be added to a metric: For example: <markup lang=\"java\" >GrpcRouting routing = GrpcRouting.builder() .intercept(GrpcMetrics.counted().description(\"Something useful\")) .register(new MyService()) .build(); the description() method is used to add the description to the metric. Adding Metric Units A units value can be added to the Metric: For example: <markup lang=\"java\" >GrpcRouting routing = GrpcRouting.builder() .intercept(GrpcMetrics.timed().units(MetricUnits.SECONDS)) .register(new MyService()) .build(); the units() method is used to add the metric units to the metric. Typically the units value is one of the constants from org.eclipse.microprofile.metrics.MetricUnits class. ",
            "title": "Specifying Metric Meta-data"
        },
        {
            "location": "/se/grpc/07_metrics",
            "text": " By default the metric name is the gRPC service name followed by a dot ('.') followed by the method name. It is possible to supply a function that can be used to override the default behaviour. The function should implement the io.helidon.grpc.metrics.GrpcMetrics.NamingFunction interface <markup lang=\"java\" > @FunctionalInterface public interface NamingFunction { /** * Create a metric name. * * @param service the service descriptor * @param methodName the method name * @param metricType the metric type * @return the metric name */ String createName(ServiceDescriptor service, String methodName, MetricType metricType); } This is a functional interface so lambda can be used too. For example: <markup lang=\"java\" >GrpcRouting routing = GrpcRouting.builder() .intercept(GrpcMetrics.counted() .nameFunction((svc, method, metric) -&gt; \"grpc.\" + service.name() + '.' + method) the NamingFunction is just a lambda that returns the concatenated service name and method name with the prefix grpc. So for a service \"Foo\", method \"bar\" the above example would produce a name \"grpc.Foo.bar\". ",
            "title": "Overriding the Metric Name"
        },
        {
            "location": "/mp/extensions/03_cdi_jedis",
            "text": " This CDI portable extension provides support for injecting Jedis clients in your Helidon MicroProfile applications. ",
            "title": "preambule"
        },
        {
            "location": "/mp/extensions/03_cdi_jedis",
            "text": " To enable Jedis Support add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.cdi&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-cdi-jedis&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/extensions/03_cdi_jedis",
            "text": " The following examples show how to create and inject a Jedis pool named orders in your application code. <markup lang=\"java\" title=\"Field-injection example\" > @Inject @Named(\"orders\") private JedisPool ordersPool; <markup lang=\"java\" title=\"Constructor-injection example\" > private final JedisPool ordersPool; @Inject public YourConstructor(@Named(\"orders\") JedisPool pool) { super(); this.ordersPool = pool; } The extension implements this injection point by creating a JedisPool object in the application scope . You can configure the object using MicroProfile config . For example, the Jedis pool created above can be configured as follows: <markup lang=\"properties\" title=\"META-INF/microprofile-config.properties\" >redis.clients.jedis.JedisPool.orders.port=6379 Property names that start with redis.clients.jedis.JedisPoolConfig.instanceName. are parsed, and the remaining portion of each name is treated as a Java Bean property of JedisPoolConfig . Because the JedisPoolConfig class inherits from Apache commons-pool&#8217;s GenericObjectPoolConfig class and from Apache commons-pool&#8217;s BaseObjectPoolConfig class, those writable Java Bean properties are available as well. Accordingly, the JedisPoolConfig Java Bean properties that can be set are as follows, where instanceName should be replaced with the actual name used in application code: <div class=\"table__overflow elevation-1 flex md7 \"> redis.clients.jedis.JedisPoolConfig.instanceName.blockWhenExhausted redis.clients.jedis.JedisPoolConfig.instanceName.evictionPolicyClassName redis.clients.jedis.JedisPoolConfig.instanceName.fairness redis.clients.jedis.JedisPoolConfig.instanceName.jmxEnabled redis.clients.jedis.JedisPoolConfig.instanceName.jmxNameBase redis.clients.jedis.JedisPoolConfig.instanceName.jmxNamePrefix redis.clients.jedis.JedisPoolConfig.instanceName.lifo redis.clients.jedis.JedisPoolConfig.instanceName.maxIdle redis.clients.jedis.JedisPoolConfig.instanceName.maxTotal redis.clients.jedis.JedisPoolConfig.instanceName.maxWaitMillis redis.clients.jedis.JedisPoolConfig.instanceName.minEvictableTimeMillis redis.clients.jedis.JedisPoolConfig.instanceName.minIdle redis.clients.jedis.JedisPoolConfig.instanceName.numTestsPerEvictionRun redis.clients.jedis.JedisPoolConfig.instanceName.softMinEvictableIdleTimeMillis redis.clients.jedis.JedisPoolConfig.instanceName.testOnBorrow redis.clients.jedis.JedisPoolConfig.instanceName.testOnCreate redis.clients.jedis.JedisPoolConfig.instanceName.testOnReturn redis.clients.jedis.JedisPoolConfig.instanceName.testWhileIdle redis.clients.jedis.JedisPoolConfig.instanceName.timeBetweenEvictionRunsMillis Any documentation for these properties that exists may be found in the javadocs for the JedisPoolConfig , GenericObjectPoolConfig and BaseObjectPoolConfig classes. Property names that start with redis.clients.jedis.JedisPool.instanceName. are parsed, and the remaining portion of each name is treated as a Java Bean property of JedisPool , or as a primitive value accepted by its constructor . Because the JedisPool class inherits from the Pool class, its writable Java Bean properties are available as well. Accordingly, the JedisPool properties that can be set are as follows, where instanceName should be replaced with the actual named used in application code: <div class=\"table__overflow elevation-1 flex md7 \"> redis.clients.jedis.JedisPool.instanceName.clientName redis.clients.jedis.JedisPool.instanceName.connectionTimeout redis.clients.jedis.JedisPool.instanceName.database redis.clients.jedis.JedisPool.instanceName.host redis.clients.jedis.JedisPool.instanceName.password redis.clients.jedis.JedisPool.instanceName.port redis.clients.jedis.JedisPool.instanceName.socketTimeout redis.clients.jedis.JedisPool.instanceName.ssl Any documentation for these properties that exists may be found in the javadocs for the JedisPool and Pool classes. Injection without a @Named annotation is also possible: <markup lang=\"java\" > @Inject private JedisPool ordersPool; In this case, the properties for JedisPoolConfig and JedisPool that can be set will start wih redis.clients.jedis.JedisPoolConfig.default and redis.clients.jedis.JedisPool.default respectively. ",
            "title": "Injecting a Jedis client"
        },
        {
            "location": "/se/security/02_providers",
            "text": "<markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-oidc&lt;/artifactId&gt; &lt;/dependency&gt; In Helidon SE, we need to register the redirection support with routing (in addition to WebSecurity that integrates with WebServer ). This is not required when redirect is set to false. <markup lang=\"java\" title=\"Adding support for OIDC redirects\" >Routing routing = Routing.builder() .register(WebSecurity.create(config.get(\"security\"))) .register(OidcSupport.create(config)) ... .build(); <markup lang=\"text\" title=\"Provider class name\" >io.helidon.security.providers.oidc.OidcProvider <markup lang=\"text\" title=\"Provider configuration key\" >oidc ",
            "title": "Setup"
        },
        {
            "location": "/se/security/02_providers",
            "text": " https://github.com/oracle/helidon/tree/master/examples/security/idcs-login <markup lang=\"yaml\" title=\"Configuration example\" >security: config.require-encryption: false security: providers: - oidc: client-id: \"client-id-of-this-service\" client-secret: \"${CLEAR=client-secret-of-this-service}\" identity-uri: \"http://your-tenant.identity-server.com\" frontend-uri: \"http://my-service:8080\" audience: \"http://my-service\" cors: allow-origins: [\"http://foo.com\", \"http://there.com\"] allow-methods: [\"PUT\", \"DELETE\"] outbound: - name: \"internal-services\" hosts: [\"*.example.org\"] outbound-token: header: \"X-Internal-Auth\" ",
            "title": "Example code"
        },
        {
            "location": "/se/security/02_providers",
            "text": " The following table shows all configuration options of the provider and their default values key default value description optional false If set to true , failure to authenticate will return ABSTAIN result instead of FAILURE . This is an important distinction when more than one provider is used client-id &#160; Client ID as generated by identity server client-secret &#160; Client secret as generated by identity server identity-uri &#160; URI of the identity server, base used to retrieve OIDC metadata frontend-uri &#160; Full URI of this service for redirects back from OIDC server issuer issuer from OIDC metadata Issuer of token - each JWT is validated to check the issuer audience &#160; Audience of a token - each JWT is validated to check the audience cors &#160; Cross-origin resource sharing settings (see below) proxy-protocol http Proxy protocol to use when proxy is used proxy-host null Proxy host to use. When defined, triggers usage of proxy for HTTP requests proxy-port 80 Port of the proxy server to use redirect-uri /oidc/redirect URI to register web server component on, used by the OIDC server to redirect authorization requests to after a user logs in or approves scopes. Note that usually the redirect URI configured here must be the same one as configured on OIDC server. scope-audience empty string Audience of the scope required by this application. This is prefixed to the scope name when requesting scopes from the identity server. cookie-use true Whether to use cookie to store JWT. If used, redirects happen only in case the user is not authenticated or has insufficient scopes cookie-name JSESSIONID Name of the cookie cookie-domain &#160; Domain the cookie is valid for. Not used by default cookie-path / Path the cookie is valid for. cookie-max-age-seconds {nsbp} When using cookie, used to set MaxAge attribute of the cookie, defining how long the cookie is valid. cookie-http-only true When using cookie, if set to true, the HttpOnly attribute will be configured. cookie-secure false When using cookie, if set to true, the Secure attribute will be configured. cookie-same-site Lax When using cookie, used to set the SameSite cookie value. Can be \"Strict\" or \"Lax\". Setting this to \"Strict\" will result in infinite redirects when calling OIDC on a different host. query-param-use false Whether to expect JWT in a query parameter query-param-name accessToken Name of a query parameter that contains the JWT token when parameter is used. header-use false Whether to expect JWT in a header field. header-token Authorization header with prefix bearer A TokenHandler configuration to process header containing a JWT oidc-metadata-well-known true If set to true, metadata will be loaded from default (well known) location, unless it is explicitly defined using oidc-metadata-resource. If set to false, it would not be loaded even if oidc-metadata-resource is not defined. In such a case all URIs must be explicitly defined (e.g. token-endpoint-uri). oidc-metadata.resource identity-uri/.well-known/openid-configuration Resource configuration for OIDC Metadata containing endpoints to various identity services, as well as information about the identity server. See Resource.create(io.helidon.config.Config) token-endpoint-uri token_endpoint in OIDC metadata, or identity-url/oauth2/v1/token if not available URI of a token endpoint used to obtain a JWT based on the authentication code. authorization-endpoint-uri \"authorization_endpoint\" in OIDC metadata, or identity-uri/oauth2/v1/authorize if not available URI of an authorization endpoint used to redirect users to for logging-in. validate-with-jwk true When true - validate against jwk defined by \"sign-jwk\", when false validate JWT through OIDC Server endpoint \"validation-endpoint-uri\" sign-jwk.resource \"jwks-uri\" in OIDC metadata, or identity-uri/admin/v1/SigningCert/jwk if not available, only needed when jwt validation is done by us A resource pointing to JWK with public keys of signing certificates used to validate JWT. See Resource.create(io.helidon.config.Config) introspect-endpoint-uri \"introspection_endpoint\" in OIDC metadata, or identity-uri/oauth2/v1/introspect When validate-with-jwk is set to \"false\", this is the endpoint used base-scopes openid Configure scopes to be requested by default. If the scope has a qualifier, it must be included here redirect true Whether to redirect to identity server when authentication failed. realm helidon Realm returned in HTTP response if redirect is not enabled or possible. redirect-attempt-param h_ra Query parameter holding the number of times we redirected to an identity server. Customizable to prevent conflicts with application parameters max-redirects 5 Maximal number of times we can redirect to an identity server. When the number is reached, no further redirects happen and the request finishes with an error (status 401) server-type &#160; Type of identity server. Currently supported is idcs or not configured (for default). propagate &#160; Whether to propagate the token we have. Defaults to false unless an outbound configuration is defined outbound &#160; A list of outbound configurations outbound.*.name &#160; Required name of outbound configuration outbound.*.transports any transport An array of transports this outbound configuration should be used for outbound.*.hosts any host An array of hosts this outbound configuration should be used for, can be a regular expression outbound.*.paths any path An array of paths this outbound configuration should be used for (such as /greet ), can be a regular expression outbound.*.methods any method An array of HTTP methods this outbound configuration should be used for outbound.*.outbound-token Authorization header with bearer prefix Configuration of outbound header used to propagate outbound.*.outbound-token.header &#160; Name of the header used to propagate the token outbound.*.outbound-token.prefix &#160; Prefix for the header value, such as \"bearer\" (only one of prefix , regexp and format should be defined, regexp wins over prefix , format wins over regexp ) outbound.*.outbound-token.format &#160; String format with a single parameter to create the header value, such as \"bearer %1s\" outbound.*.outbound-token.regexp &#160; Regular expression to create the header value, such as \"bearer (.*)\" ",
            "title": "Configuration options"
        },
        {
            "location": "/se/security/02_providers",
            "text": " As an experimental feature, you can set up cross-origin handling for the redirect and logout endpoints in an optional cors block inside the oidc configuration. The table below lists the configuration keys that identify the CORS characteristics. Configuration Key Default CORS Header Name allow-credentials false Access-Control-Allow-Credentials allow-headers [\"*\"] Access-Control-Allow-Headers allow-methods [\"*\"] Access-Control-Allow-Methods allow-origins [\"*\"] Access-Control-Allow-Origins expose-headers none Access-Control-Expose-Headers max-age 3600 Access-Control-Max-Age enabled true n/a If the cross-origin configuration is disabled ( enabled = false), then the Helidon CORS implementation ignores the cross-origin configuration entry. The following example of basic cross-origin configuration limits cross-origin resource sharing for PUT and DELETE operations to only foo.com and there.com : <markup lang=\"hocon\" >... allow-origins: [\"http://foo.com\", \"http://there.com\"] allow-methods: [\"PUT\", \"DELETE\"] ... ",
            "title": "CORS Settings"
        },
        {
            "location": "/se/security/02_providers",
            "text": " At Helidon startup, if OIDC provider is configured, the following will happen: client-id , client-secret , and identityUri are validated - these must provide values Unless all resources are configured as local resources, the provider attempts to contact the oidc-metadata.resource endpoint to retrieve all endpoints At runtime, depending on configuration&#8230;&#8203; If a request comes without a token or with insufficient scopes: If redirect is set to true (default), request is redirected to the authorization endpoint of the identity server. If set to false, 401 is returned User authenticates against the identity server The identity server redirects back to Helidon service with a code Helidon service contacts the identity server&#8217;s token endpoint, to exchange the code for a JWT The JWT is stored in a cookie (if cookie support is enabled, which it is by default) Helidon service redirects to original endpoint (on itself) Helidon obtains a token from request (from cookie, header, or query parameter): Token is parsed as a singed JWT We validate the JWT signature either against local JWK or against the identity server&#8217;s introspection endpoint depending on configuration We validate the issuer and audience of the token if it matches the configured values A subject is created from the JWT, including scopes from the token We validate that we have sufficient scopes to proceed, and return 403 if not Handling is returned to security to process other security providers CORS Settings As an experimental feature, you can set up cross-origin handling for the redirect and logout endpoints in an optional cors block inside the oidc configuration. The table below lists the configuration keys that identify the CORS characteristics. Configuration Key Default CORS Header Name allow-credentials false Access-Control-Allow-Credentials allow-headers [\"*\"] Access-Control-Allow-Headers allow-methods [\"*\"] Access-Control-Allow-Methods allow-origins [\"*\"] Access-Control-Allow-Origins expose-headers none Access-Control-Expose-Headers max-age 3600 Access-Control-Max-Age enabled true n/a If the cross-origin configuration is disabled ( enabled = false), then the Helidon CORS implementation ignores the cross-origin configuration entry. The following example of basic cross-origin configuration limits cross-origin resource sharing for PUT and DELETE operations to only foo.com and there.com : <markup lang=\"hocon\" >... allow-origins: [\"http://foo.com\", \"http://there.com\"] allow-methods: [\"PUT\", \"DELETE\"] ... ",
            "title": "How does it work?"
        },
        {
            "location": "/se/security/02_providers",
            "text": " Open ID Connect security provider. Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-oidc&lt;/artifactId&gt; &lt;/dependency&gt; In Helidon SE, we need to register the redirection support with routing (in addition to WebSecurity that integrates with WebServer ). This is not required when redirect is set to false. <markup lang=\"java\" title=\"Adding support for OIDC redirects\" >Routing routing = Routing.builder() .register(WebSecurity.create(config.get(\"security\"))) .register(OidcSupport.create(config)) ... .build(); <markup lang=\"text\" title=\"Provider class name\" >io.helidon.security.providers.oidc.OidcProvider <markup lang=\"text\" title=\"Provider configuration key\" >oidc Example code https://github.com/oracle/helidon/tree/master/examples/security/idcs-login <markup lang=\"yaml\" title=\"Configuration example\" >security: config.require-encryption: false security: providers: - oidc: client-id: \"client-id-of-this-service\" client-secret: \"${CLEAR=client-secret-of-this-service}\" identity-uri: \"http://your-tenant.identity-server.com\" frontend-uri: \"http://my-service:8080\" audience: \"http://my-service\" cors: allow-origins: [\"http://foo.com\", \"http://there.com\"] allow-methods: [\"PUT\", \"DELETE\"] outbound: - name: \"internal-services\" hosts: [\"*.example.org\"] outbound-token: header: \"X-Internal-Auth\" Configuration options The following table shows all configuration options of the provider and their default values key default value description optional false If set to true , failure to authenticate will return ABSTAIN result instead of FAILURE . This is an important distinction when more than one provider is used client-id &#160; Client ID as generated by identity server client-secret &#160; Client secret as generated by identity server identity-uri &#160; URI of the identity server, base used to retrieve OIDC metadata frontend-uri &#160; Full URI of this service for redirects back from OIDC server issuer issuer from OIDC metadata Issuer of token - each JWT is validated to check the issuer audience &#160; Audience of a token - each JWT is validated to check the audience cors &#160; Cross-origin resource sharing settings (see below) proxy-protocol http Proxy protocol to use when proxy is used proxy-host null Proxy host to use. When defined, triggers usage of proxy for HTTP requests proxy-port 80 Port of the proxy server to use redirect-uri /oidc/redirect URI to register web server component on, used by the OIDC server to redirect authorization requests to after a user logs in or approves scopes. Note that usually the redirect URI configured here must be the same one as configured on OIDC server. scope-audience empty string Audience of the scope required by this application. This is prefixed to the scope name when requesting scopes from the identity server. cookie-use true Whether to use cookie to store JWT. If used, redirects happen only in case the user is not authenticated or has insufficient scopes cookie-name JSESSIONID Name of the cookie cookie-domain &#160; Domain the cookie is valid for. Not used by default cookie-path / Path the cookie is valid for. cookie-max-age-seconds {nsbp} When using cookie, used to set MaxAge attribute of the cookie, defining how long the cookie is valid. cookie-http-only true When using cookie, if set to true, the HttpOnly attribute will be configured. cookie-secure false When using cookie, if set to true, the Secure attribute will be configured. cookie-same-site Lax When using cookie, used to set the SameSite cookie value. Can be \"Strict\" or \"Lax\". Setting this to \"Strict\" will result in infinite redirects when calling OIDC on a different host. query-param-use false Whether to expect JWT in a query parameter query-param-name accessToken Name of a query parameter that contains the JWT token when parameter is used. header-use false Whether to expect JWT in a header field. header-token Authorization header with prefix bearer A TokenHandler configuration to process header containing a JWT oidc-metadata-well-known true If set to true, metadata will be loaded from default (well known) location, unless it is explicitly defined using oidc-metadata-resource. If set to false, it would not be loaded even if oidc-metadata-resource is not defined. In such a case all URIs must be explicitly defined (e.g. token-endpoint-uri). oidc-metadata.resource identity-uri/.well-known/openid-configuration Resource configuration for OIDC Metadata containing endpoints to various identity services, as well as information about the identity server. See Resource.create(io.helidon.config.Config) token-endpoint-uri token_endpoint in OIDC metadata, or identity-url/oauth2/v1/token if not available URI of a token endpoint used to obtain a JWT based on the authentication code. authorization-endpoint-uri \"authorization_endpoint\" in OIDC metadata, or identity-uri/oauth2/v1/authorize if not available URI of an authorization endpoint used to redirect users to for logging-in. validate-with-jwk true When true - validate against jwk defined by \"sign-jwk\", when false validate JWT through OIDC Server endpoint \"validation-endpoint-uri\" sign-jwk.resource \"jwks-uri\" in OIDC metadata, or identity-uri/admin/v1/SigningCert/jwk if not available, only needed when jwt validation is done by us A resource pointing to JWK with public keys of signing certificates used to validate JWT. See Resource.create(io.helidon.config.Config) introspect-endpoint-uri \"introspection_endpoint\" in OIDC metadata, or identity-uri/oauth2/v1/introspect When validate-with-jwk is set to \"false\", this is the endpoint used base-scopes openid Configure scopes to be requested by default. If the scope has a qualifier, it must be included here redirect true Whether to redirect to identity server when authentication failed. realm helidon Realm returned in HTTP response if redirect is not enabled or possible. redirect-attempt-param h_ra Query parameter holding the number of times we redirected to an identity server. Customizable to prevent conflicts with application parameters max-redirects 5 Maximal number of times we can redirect to an identity server. When the number is reached, no further redirects happen and the request finishes with an error (status 401) server-type &#160; Type of identity server. Currently supported is idcs or not configured (for default). propagate &#160; Whether to propagate the token we have. Defaults to false unless an outbound configuration is defined outbound &#160; A list of outbound configurations outbound.*.name &#160; Required name of outbound configuration outbound.*.transports any transport An array of transports this outbound configuration should be used for outbound.*.hosts any host An array of hosts this outbound configuration should be used for, can be a regular expression outbound.*.paths any path An array of paths this outbound configuration should be used for (such as /greet ), can be a regular expression outbound.*.methods any method An array of HTTP methods this outbound configuration should be used for outbound.*.outbound-token Authorization header with bearer prefix Configuration of outbound header used to propagate outbound.*.outbound-token.header &#160; Name of the header used to propagate the token outbound.*.outbound-token.prefix &#160; Prefix for the header value, such as \"bearer\" (only one of prefix , regexp and format should be defined, regexp wins over prefix , format wins over regexp ) outbound.*.outbound-token.format &#160; String format with a single parameter to create the header value, such as \"bearer %1s\" outbound.*.outbound-token.regexp &#160; Regular expression to create the header value, such as \"bearer (.*)\" How does it work? At Helidon startup, if OIDC provider is configured, the following will happen: client-id , client-secret , and identityUri are validated - these must provide values Unless all resources are configured as local resources, the provider attempts to contact the oidc-metadata.resource endpoint to retrieve all endpoints At runtime, depending on configuration&#8230;&#8203; If a request comes without a token or with insufficient scopes: If redirect is set to true (default), request is redirected to the authorization endpoint of the identity server. If set to false, 401 is returned User authenticates against the identity server The identity server redirects back to Helidon service with a code Helidon service contacts the identity server&#8217;s token endpoint, to exchange the code for a JWT The JWT is stored in a cookie (if cookie support is enabled, which it is by default) Helidon service redirects to original endpoint (on itself) Helidon obtains a token from request (from cookie, header, or query parameter): Token is parsed as a singed JWT We validate the JWT signature either against local JWK or against the identity server&#8217;s introspection endpoint depending on configuration We validate the issuer and audience of the token if it matches the configured values A subject is created from the JWT, including scopes from the token We validate that we have sufficient scopes to proceed, and return 403 if not Handling is returned to security to process other security providers CORS Settings As an experimental feature, you can set up cross-origin handling for the redirect and logout endpoints in an optional cors block inside the oidc configuration. The table below lists the configuration keys that identify the CORS characteristics. Configuration Key Default CORS Header Name allow-credentials false Access-Control-Allow-Credentials allow-headers [\"*\"] Access-Control-Allow-Headers allow-methods [\"*\"] Access-Control-Allow-Methods allow-origins [\"*\"] Access-Control-Allow-Origins expose-headers none Access-Control-Expose-Headers max-age 3600 Access-Control-Max-Age enabled true n/a If the cross-origin configuration is disabled ( enabled = false), then the Helidon CORS implementation ignores the cross-origin configuration entry. The following example of basic cross-origin configuration limits cross-origin resource sharing for PUT and DELETE operations to only foo.com and there.com : <markup lang=\"hocon\" >... allow-origins: [\"http://foo.com\", \"http://there.com\"] allow-methods: [\"PUT\", \"DELETE\"] ... ",
            "title": "OIDC Provider"
        },
        {
            "location": "/se/security/02_providers",
            "text": "<markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-http-auth&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"text\" title=\"Provider class name\" >io.helidon.security.providers.httpauth.HttpBasicAuthProvider <markup lang=\"text\" title=\"Provider configuration key\" >http-basic-auth ",
            "title": "Setup"
        },
        {
            "location": "/se/security/02_providers",
            "text": " https://github.com/oracle/helidon/tree/master/examples/security/outbound-override <markup lang=\"yaml\" title=\"Configuration example\" >security: config.require-encryption: false security: providers: - http-basic-auth: realm: \"helidon\" users: - login: \"john\" password: \"${CLEAR=password}\" roles: [\"admin\"] - login: \"jack\" password: \"password\" roles: [\"user\", \"admin\"] outbound: - name: \"internal-services\" hosts: [\"*.example.org\"] # Propagates current user's identity or identity from request property outbound-token: header: \"X-Internal-Auth\" - name: \"partner-service\" hosts: [\"*.partner.org\"] # Uses this username and password username: \"partner-user-1\" password: \"${CLEAR=password}\" ",
            "title": "Example code"
        },
        {
            "location": "/se/security/02_providers",
            "text": " The following table shows all configuration options of the provider and their default values key default value description optional false If set to true , failure to authenticate will return ABSTAIN result instead of FAILURE . This is an important distinction when more than one provider is used realm helidon The realm shown in challenge when user accesses a service without authentication principal-type USER Type of authenticated entity - either USER or SERVICE , can be used in combination with other authentication mechanism to authenticate both the user (as in person sitting in front of a computer) and a service (as in the application requesting this service on user&#8217;s behalf) users &#160; List of users when using configuration based approach. As an alternative, you can implement a java service (see below). outbound &#160; A list of outbound configurations outbound.*.name &#160; Required name of outbound configuration outbound.*.username &#160; Optional username used for outbound security; if not provided, current identity is propagated outbound.*.password &#160; Optional password used for outbound security outbound.*.transports any transport An array of transports this outbound configuration should be used for outbound.*.hosts any host An array of hosts this outbound configuration should be used for, can be a regular expression outbound.*.paths any path An array of paths this outbound configuration should be used for (such as /greet ), can be a regular expression outbound.*.methods any method An array of HTTP methods this outbound configuration should be used for outbound.*.outbound-token Authorization header with basic prefix Configuration of outbound header used to propagate outbound.*.outbound-token.header &#160; Name of the header used to propagate the token outbound.*.outbound-token.prefix &#160; Prefix for the header value, such as \"basic \" (only one of prefix , regexp and format should be defined, regexp wins over prefix , format wins over regexp ) outbound.*.outbound-token.format &#160; String format with a single parameter to create the header value, such as \"basic %1s\" outbound.*.outbound-token.regexp &#160; Regular expression to create the header value, such as \"basic (.*)\" ",
            "title": "Configuration options"
        },
        {
            "location": "/se/security/02_providers",
            "text": " See https://tools.ietf.org/html/rfc7617 . Authentication of request When a request is received without the Authorization: basic &#8230;&#8203;. header, a challenge is returned to provide such authentication. When a request is received with the Authorization: basic &#8230;&#8203;. header, the username and password is validated against configured users (and users obtained from custom service if any provided). Subject is created based on the username and roles provided by the user store. Identity propagation When identity propagation is configured, there are several options for identifying username and password to propagate: We propagate the current username and password (inbound request must be authenticated using basic authentication). We use username and password from an explicitly configured property (See HttpBasicAuthProvider.EP_PROPERTY_OUTBOUND_USER and HttpBasicAuthProvider.EP_PROPERTY_OUTBOUND_PASSWORD ) We use username and password associated with an outbound target (see example configuration above) Identity is propagated only if: There is an outbound target configured for the endpoint Or there is an explicitly configured username/password for the current request (through request property) Custom user store Java service loader service io.helidon.security.providers.httpauth.spi.UserStoreService can be implemented to provide users to the provider, such as when validated against an internal database or LDAP server. The user store is defined so you never need the clear text password of the user. Warning on security of HTTP Basic Authenticaton (or lack thereof) Basic authentication uses base64 encoded username and password and passes it over the network. Base64 is only encoding, not encryption - so anybody that gets hold of the header value can learn the actual username and password of the user. This is a security risk and an attack vector that everybody should be aware of before using HTTP Basic Authentication. We recommend using this approach only for testing and demo purposes. ",
            "title": "How does it work?"
        },
        {
            "location": "/se/security/02_providers",
            "text": " HTTP Basic authentication support Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-http-auth&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"text\" title=\"Provider class name\" >io.helidon.security.providers.httpauth.HttpBasicAuthProvider <markup lang=\"text\" title=\"Provider configuration key\" >http-basic-auth Example code https://github.com/oracle/helidon/tree/master/examples/security/outbound-override <markup lang=\"yaml\" title=\"Configuration example\" >security: config.require-encryption: false security: providers: - http-basic-auth: realm: \"helidon\" users: - login: \"john\" password: \"${CLEAR=password}\" roles: [\"admin\"] - login: \"jack\" password: \"password\" roles: [\"user\", \"admin\"] outbound: - name: \"internal-services\" hosts: [\"*.example.org\"] # Propagates current user's identity or identity from request property outbound-token: header: \"X-Internal-Auth\" - name: \"partner-service\" hosts: [\"*.partner.org\"] # Uses this username and password username: \"partner-user-1\" password: \"${CLEAR=password}\" Configuration options The following table shows all configuration options of the provider and their default values key default value description optional false If set to true , failure to authenticate will return ABSTAIN result instead of FAILURE . This is an important distinction when more than one provider is used realm helidon The realm shown in challenge when user accesses a service without authentication principal-type USER Type of authenticated entity - either USER or SERVICE , can be used in combination with other authentication mechanism to authenticate both the user (as in person sitting in front of a computer) and a service (as in the application requesting this service on user&#8217;s behalf) users &#160; List of users when using configuration based approach. As an alternative, you can implement a java service (see below). outbound &#160; A list of outbound configurations outbound.*.name &#160; Required name of outbound configuration outbound.*.username &#160; Optional username used for outbound security; if not provided, current identity is propagated outbound.*.password &#160; Optional password used for outbound security outbound.*.transports any transport An array of transports this outbound configuration should be used for outbound.*.hosts any host An array of hosts this outbound configuration should be used for, can be a regular expression outbound.*.paths any path An array of paths this outbound configuration should be used for (such as /greet ), can be a regular expression outbound.*.methods any method An array of HTTP methods this outbound configuration should be used for outbound.*.outbound-token Authorization header with basic prefix Configuration of outbound header used to propagate outbound.*.outbound-token.header &#160; Name of the header used to propagate the token outbound.*.outbound-token.prefix &#160; Prefix for the header value, such as \"basic \" (only one of prefix , regexp and format should be defined, regexp wins over prefix , format wins over regexp ) outbound.*.outbound-token.format &#160; String format with a single parameter to create the header value, such as \"basic %1s\" outbound.*.outbound-token.regexp &#160; Regular expression to create the header value, such as \"basic (.*)\" How does it work? See https://tools.ietf.org/html/rfc7617 . Authentication of request When a request is received without the Authorization: basic &#8230;&#8203;. header, a challenge is returned to provide such authentication. When a request is received with the Authorization: basic &#8230;&#8203;. header, the username and password is validated against configured users (and users obtained from custom service if any provided). Subject is created based on the username and roles provided by the user store. Identity propagation When identity propagation is configured, there are several options for identifying username and password to propagate: We propagate the current username and password (inbound request must be authenticated using basic authentication). We use username and password from an explicitly configured property (See HttpBasicAuthProvider.EP_PROPERTY_OUTBOUND_USER and HttpBasicAuthProvider.EP_PROPERTY_OUTBOUND_PASSWORD ) We use username and password associated with an outbound target (see example configuration above) Identity is propagated only if: There is an outbound target configured for the endpoint Or there is an explicitly configured username/password for the current request (through request property) Custom user store Java service loader service io.helidon.security.providers.httpauth.spi.UserStoreService can be implemented to provide users to the provider, such as when validated against an internal database or LDAP server. The user store is defined so you never need the clear text password of the user. Warning on security of HTTP Basic Authenticaton (or lack thereof) Basic authentication uses base64 encoded username and password and passes it over the network. Base64 is only encoding, not encryption - so anybody that gets hold of the header value can learn the actual username and password of the user. This is a security risk and an attack vector that everybody should be aware of before using HTTP Basic Authentication. We recommend using this approach only for testing and demo purposes. ",
            "title": "HTTP Basic Authentication Provider"
        },
        {
            "location": "/se/security/02_providers",
            "text": "<markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-http-auth&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"text\" title=\"Provider class name\" >io.helidon.security.providers.httpauth.HttpDigestAuthProvider <markup lang=\"text\" title=\"Provider configuration key\" >http-digest-auth ",
            "title": "Setup"
        },
        {
            "location": "/se/security/02_providers",
            "text": "<markup lang=\"yaml\" title=\"Configuration example\" >security: config.require-encryption: false security: providers: - http-digest-auth: realm: \"helidon\" server-secret: \"${CLEAR=service-wide-secret-not-known-outside}\" users: - login: \"john\" password: \"${CLEAR=password}\" roles: [\"admin\"] - login: \"jack\" password: \"password\" roles: [\"user\", \"admin\"] ",
            "title": "Example code"
        },
        {
            "location": "/se/security/02_providers",
            "text": " The following table shows all configuration options of the provider and their default values key default value description optional false If set to true , failure to authenticate will return ABSTAIN result instead of FAILURE . This is an important distinction when more than one provider is used realm helidon The realm shown in challenge when user accesses a service without authentication principal-type USER Type of authenticated entity - either USER or SERVICE , can be used in combination with other authentication mechanism to authenticate both the user (as in person sitting in front of a computer) and a service (as in the application requesting this service on user&#8217;s behalf) users &#160; List of users when using configuration based approach. As an alternative, you can implement a java service (see below). algorithm MD5 Only MD5 supported nonce-timeout-millis 1 day Number of milliseconds for the nonce timeout server-secret random A string to use as a server secret - this is to use digest auth between multiple servers (e.g. when in a cluster). Used to encrypt nonce. This must not be known outside of this app, as others may create digest requests we would trust. qop NONE only AUTH supported. If left empty, uses the legacy approach (older RFC version). AUTH-INT is not supported. ",
            "title": "Configuration options"
        },
        {
            "location": "/se/security/02_providers",
            "text": " See https://tools.ietf.org/html/rfc7616 . Authentication of request When a request is received without the Authorization: digest &#8230;&#8203;. header, a challenge is returned to provide such authentication using WWW-Authenticate header. When a request is received with the Authorization: digest &#8230;&#8203;. header, the request is validated against configured users (and users obtained from custom service if any provided). Subject is created based on the username and roles provided by the user store. Custom user store Java service loader service io.helidon.security.providers.httpauth.spi.UserStoreService can be implemented to provide users to the provider, such as when validated against an internal database or LDAP server. The user store is defined so you never need the clear text password of the user. Note on security of HTTP Digest Authenticaton These authentication schemes should be obsolete , though they provide a very easy way to test a protected resource. ",
            "title": "How does it work?"
        },
        {
            "location": "/se/security/02_providers",
            "text": " HTTP Digest authentication support Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-http-auth&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"text\" title=\"Provider class name\" >io.helidon.security.providers.httpauth.HttpDigestAuthProvider <markup lang=\"text\" title=\"Provider configuration key\" >http-digest-auth Example code <markup lang=\"yaml\" title=\"Configuration example\" >security: config.require-encryption: false security: providers: - http-digest-auth: realm: \"helidon\" server-secret: \"${CLEAR=service-wide-secret-not-known-outside}\" users: - login: \"john\" password: \"${CLEAR=password}\" roles: [\"admin\"] - login: \"jack\" password: \"password\" roles: [\"user\", \"admin\"] Configuration options The following table shows all configuration options of the provider and their default values key default value description optional false If set to true , failure to authenticate will return ABSTAIN result instead of FAILURE . This is an important distinction when more than one provider is used realm helidon The realm shown in challenge when user accesses a service without authentication principal-type USER Type of authenticated entity - either USER or SERVICE , can be used in combination with other authentication mechanism to authenticate both the user (as in person sitting in front of a computer) and a service (as in the application requesting this service on user&#8217;s behalf) users &#160; List of users when using configuration based approach. As an alternative, you can implement a java service (see below). algorithm MD5 Only MD5 supported nonce-timeout-millis 1 day Number of milliseconds for the nonce timeout server-secret random A string to use as a server secret - this is to use digest auth between multiple servers (e.g. when in a cluster). Used to encrypt nonce. This must not be known outside of this app, as others may create digest requests we would trust. qop NONE only AUTH supported. If left empty, uses the legacy approach (older RFC version). AUTH-INT is not supported. How does it work? See https://tools.ietf.org/html/rfc7616 . Authentication of request When a request is received without the Authorization: digest &#8230;&#8203;. header, a challenge is returned to provide such authentication using WWW-Authenticate header. When a request is received with the Authorization: digest &#8230;&#8203;. header, the request is validated against configured users (and users obtained from custom service if any provided). Subject is created based on the username and roles provided by the user store. Custom user store Java service loader service io.helidon.security.providers.httpauth.spi.UserStoreService can be implemented to provide users to the provider, such as when validated against an internal database or LDAP server. The user store is defined so you never need the clear text password of the user. Note on security of HTTP Digest Authenticaton These authentication schemes should be obsolete , though they provide a very easy way to test a protected resource. ",
            "title": "HTTP Digest Authentication Provider"
        },
        {
            "location": "/se/security/02_providers",
            "text": "<markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-header&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"text\" title=\"Provider class name\" >io.helidon.security.providers.header.HeaderAtnProvider <markup lang=\"text\" title=\"Provider configuration key\" >header-atn ",
            "title": "Setup"
        },
        {
            "location": "/se/security/02_providers",
            "text": "<markup lang=\"yaml\" title=\"Configuration example\" >security: providers: header-atn: atn-token: header: \"X-AUTH-USER\" outbound: - name: \"internal-services\" hosts: [\"*.example.org\"] # propagates the current user or service id using the same header as authentication - name: \"partner-service\" hosts: [\"*.partner.org\"] # propagates an explicit username in a custom header username: \"service-27\" outbound-token: header: \"X-Service-Auth\" ",
            "title": "Example code"
        },
        {
            "location": "/se/security/02_providers",
            "text": " The following table shows all configuration options of the provider and their default values key default value description optional false If set to true , failure to authenticate will return ABSTAIN result instead of FAILURE . This is an important distinction when more than one provider is used authenticate true If set to false , authentication will not be attempted (outbound security can still be used) propagate false If explicitly set to false , identity propagation will not be done. Otherwise it is done if an outbound section is configured principal-type USER Can be USER or SERVICE atn-token none Token extraction and propagation, you can define which header to use and how to extract it outbound &#160; A list of outbound configurations outbound.*.name &#160; Required name of outbound configuration outbound.*.username &#160; Optional username used for outbound security; if not provided, current identity is propagated outbound.*.transports any transport An array of transports this outbound configuration should be used for outbound.*.hosts any host An array of hosts this outbound configuration should be used for, can be a regular expression outbound.*.paths any path An array of paths this outbound configuration should be used for (such as /greet ), can be a regular expression outbound.*.methods any method An array of HTTP methods this outbound configuration should be used for outbound.*.outbound-token same as atn-token Configuration of outbound header used to propagate outbound.*.outbound-token.header &#160; Name of the header used to propagate the token outbound.*.outbound-token.prefix &#160; Prefix for the header value, such as \"username \" (only one of prefix , regexp and format should be defined, regexp wins over prefix , format wins over regexp ) outbound.*.outbound-token.format &#160; String format with a single parameter to create the header value, such as \"username %1s\" outbound.*.outbound-token.regexp &#160; Regular expression to create the header value, such as \"username (.*)\" ",
            "title": "Configuration options"
        },
        {
            "location": "/se/security/02_providers",
            "text": " This provider inspects a specified request header and extracts the username/service name from it and asserts it as current subject&#8217;s principal. This can be used when we use perimeter authentication (e.g. there is a gateway that takes care of authentication and propagates the user in a header). Identity propagation Identity is propagated only if an outbound target matches the target service. The following options exist when propagating identity: 1. We propagate the current username using the configured header 2. We use username associated with an outbound target (see example configuration above) Caution When using this provider, you must be sure the header cannot be explicitly configured by a user or another service. All requests should go through a gateway that removes this header from inbound traffic, and only configures it for authenticated users/services. Another option is to use this with fully trusted parties (such as services within a single company, on a single protected network not accessible to any users), and of course for testing and demo purposes. ",
            "title": "How does it work?"
        },
        {
            "location": "/se/security/02_providers",
            "text": " Asserts user or service identity based on a value of a header. Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-header&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"text\" title=\"Provider class name\" >io.helidon.security.providers.header.HeaderAtnProvider <markup lang=\"text\" title=\"Provider configuration key\" >header-atn Example code <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: header-atn: atn-token: header: \"X-AUTH-USER\" outbound: - name: \"internal-services\" hosts: [\"*.example.org\"] # propagates the current user or service id using the same header as authentication - name: \"partner-service\" hosts: [\"*.partner.org\"] # propagates an explicit username in a custom header username: \"service-27\" outbound-token: header: \"X-Service-Auth\" Configuration options The following table shows all configuration options of the provider and their default values key default value description optional false If set to true , failure to authenticate will return ABSTAIN result instead of FAILURE . This is an important distinction when more than one provider is used authenticate true If set to false , authentication will not be attempted (outbound security can still be used) propagate false If explicitly set to false , identity propagation will not be done. Otherwise it is done if an outbound section is configured principal-type USER Can be USER or SERVICE atn-token none Token extraction and propagation, you can define which header to use and how to extract it outbound &#160; A list of outbound configurations outbound.*.name &#160; Required name of outbound configuration outbound.*.username &#160; Optional username used for outbound security; if not provided, current identity is propagated outbound.*.transports any transport An array of transports this outbound configuration should be used for outbound.*.hosts any host An array of hosts this outbound configuration should be used for, can be a regular expression outbound.*.paths any path An array of paths this outbound configuration should be used for (such as /greet ), can be a regular expression outbound.*.methods any method An array of HTTP methods this outbound configuration should be used for outbound.*.outbound-token same as atn-token Configuration of outbound header used to propagate outbound.*.outbound-token.header &#160; Name of the header used to propagate the token outbound.*.outbound-token.prefix &#160; Prefix for the header value, such as \"username \" (only one of prefix , regexp and format should be defined, regexp wins over prefix , format wins over regexp ) outbound.*.outbound-token.format &#160; String format with a single parameter to create the header value, such as \"username %1s\" outbound.*.outbound-token.regexp &#160; Regular expression to create the header value, such as \"username (.*)\" How does it work? This provider inspects a specified request header and extracts the username/service name from it and asserts it as current subject&#8217;s principal. This can be used when we use perimeter authentication (e.g. there is a gateway that takes care of authentication and propagates the user in a header). Identity propagation Identity is propagated only if an outbound target matches the target service. The following options exist when propagating identity: 1. We propagate the current username using the configured header 2. We use username associated with an outbound target (see example configuration above) Caution When using this provider, you must be sure the header cannot be explicitly configured by a user or another service. All requests should go through a gateway that removes this header from inbound traffic, and only configures it for authenticated users/services. Another option is to use this with fully trusted parties (such as services within a single company, on a single protected network not accessible to any users), and of course for testing and demo purposes. ",
            "title": "Header Authentication Provider"
        },
        {
            "location": "/se/security/02_providers",
            "text": "<markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-http-sign&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"text\" title=\"Provider class name\" >io.helidon.security.providers.httpsign.HttpSignProvider <markup lang=\"text\" title=\"Provider configuration key\" >http-signatures ",
            "title": "Setup"
        },
        {
            "location": "/se/security/02_providers",
            "text": " https://github.com/oracle/helidon/tree/master/examples/security/webserver-signatures <markup lang=\"yaml\" title=\"Configuration example\" >security: config.require-encryption: false security: providers: - http-signatures: inbound: keys: - key-id: \"service1-hmac\" principal-name: \"Service1 - HMAC signature\" hmac.secret: \"${CLEAR=somePasswordForHmacShouldBeEncrypted}\" - key-id: \"service1-rsa\" principal-name: \"Service1 - RSA signature\" public-key: keystore: resource.path: \"src/main/resources/keystore.p12\" passphrase: \"password\" cert.alias: \"service_cert\" outbound: - name: \"service2-hmac\" hosts: [\"localhost\"] paths: [\"/service2\"] signature: key-id: \"service1-hmac\" hmac.secret: \"${CLEAR=somePasswordForHmacShouldBeEncrypted}\" - name: \"service2-rsa\" hosts: [\"localhost\"] paths: [\"/service2-rsa.*\"] signature: key-id: \"service1-rsa\" private-key: keystore: resource.path: \"src/main/resources/keystore.p12\" passphrase: \"password\" key.alias: \"myPrivateKey\" ",
            "title": "Example code"
        },
        {
            "location": "/se/security/02_providers",
            "text": " The following table shows all configuration options of the provider and their default values key default value description optional false If set to true , failure to authenticate will return ABSTAIN result instead of FAILURE . This is an important distinction when more than one provider is used realm helidon Realm used for challenge when request does not have a signature headers [SIGNATURE,AUTHORIZATION,CUSTOM] Headers to look for inbound signatures and to store outbound signatures. CUSTOM is provided using io.helidon.security.util.TokenHandler sign-headers always = [\"date\"] Headers to be signed sign-headers.*.method default for all methods Method this configuration is valid for sign-headers.*.always &#160; Array of headers to be always required in the request signature sign-headers.*.if-present &#160; Array of headers to be part of the signatures if present in the request inbound &#160; Configuration of inbound traffic for authenticating incoming requests inbound.keys &#160; Configuration of signature keys to verify incoming requests inbound.keys.*.key-id &#160; Key id as used in inbound signature to find the correct certificate/hmac configuration to verify the signature inbound.keys.*.principal-name &#160; The principal name (or user name) asserted when the signature is valid inbound.keys.*.principal-type SERVICE The type of principal to assert (can be USER ) inbound.keys.*.algorithm according to other configuration hmac-sha256 or rsa-sha256 is assumed if other configuration options for that type are set inbound.keys.*.hmac.secret &#160; Secret shared by the service that signed the request and this service for hmac-sha256 algorithm inbound.keys.*.public-key &#160; Public key configuration, implies rsa-sha256 algorithm inbound.keys.*.public-key.keystore &#160; Keystore configuration for public key - full configuration as defined by KeyStore class outbound &#160; A list of outbound configurations outbound.*.name &#160; Required name of outbound configuration outbound.*.username &#160; Optional username used for outbound security; if not provided, current identity is propagated outbound.*.password &#160; Optional password used for outbound security outbound.*.transports any transport An array of transports this outbound configuration should be used for outbound.*.hosts any host An array of hosts this outbound configuration should be used for, can be a regular expression outbound.*.paths any path An array of paths this outbound configuration should be used for (such as /greet ), can be a regular expression outbound.*.methods any method An array of HTTP methods this outbound configuration should be used for outbound.*.signature &#160; Configuration related to outbound signature configuration outbound.*.signature.key-id &#160; Key id to use in the outbound signature (to map to appropriate public key in target service&#8217;s configuration) outbound.*.signature.header [SIGNATURE,AUTHORIZATION,CUSTOM] Headers supported by HTTP Signature. CUSTOM is provided using io.helidon.security.util.TokenHandler outbound.*.signature.hmac.secret &#160; Shared secret for hmac outbound.*.signature.private-key &#160; Private key configuration for rsa based signatures outbound.*.signature.private-key.keystore &#160; Keystore configuration for private key - full configuration as defined by KeyStore class ",
            "title": "Configuration options"
        },
        {
            "location": "/se/security/02_providers",
            "text": " standard: based on https://tools.ietf.org/html/draft-cavage-http-signatures-03 key-id: an arbitrary string used to locate signature configuration - when a request is received the provider locates validation configuration based on this id (e.g. HMAC shared secret or RSA public key). Commonly used meanings are: key fingerprint (RSA); API Key ",
            "title": "Signature basics"
        },
        {
            "location": "/se/security/02_providers",
            "text": " Inbound Signatures We act as a server and another party is calling us with a signed HTTP request. We validate the signature and assume identity of the caller. Outbound Signatures We act as a client and we sign our outgoing requests. If there is a matching outbound target specified in configuration, its configuration will be applied for signing the outgoing request, otherwise there is no signature added ",
            "title": "How does it work?"
        },
        {
            "location": "/se/security/02_providers",
            "text": " Support for HTTP Signatures. Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-http-sign&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"text\" title=\"Provider class name\" >io.helidon.security.providers.httpsign.HttpSignProvider <markup lang=\"text\" title=\"Provider configuration key\" >http-signatures Example code https://github.com/oracle/helidon/tree/master/examples/security/webserver-signatures <markup lang=\"yaml\" title=\"Configuration example\" >security: config.require-encryption: false security: providers: - http-signatures: inbound: keys: - key-id: \"service1-hmac\" principal-name: \"Service1 - HMAC signature\" hmac.secret: \"${CLEAR=somePasswordForHmacShouldBeEncrypted}\" - key-id: \"service1-rsa\" principal-name: \"Service1 - RSA signature\" public-key: keystore: resource.path: \"src/main/resources/keystore.p12\" passphrase: \"password\" cert.alias: \"service_cert\" outbound: - name: \"service2-hmac\" hosts: [\"localhost\"] paths: [\"/service2\"] signature: key-id: \"service1-hmac\" hmac.secret: \"${CLEAR=somePasswordForHmacShouldBeEncrypted}\" - name: \"service2-rsa\" hosts: [\"localhost\"] paths: [\"/service2-rsa.*\"] signature: key-id: \"service1-rsa\" private-key: keystore: resource.path: \"src/main/resources/keystore.p12\" passphrase: \"password\" key.alias: \"myPrivateKey\" Configuration options The following table shows all configuration options of the provider and their default values key default value description optional false If set to true , failure to authenticate will return ABSTAIN result instead of FAILURE . This is an important distinction when more than one provider is used realm helidon Realm used for challenge when request does not have a signature headers [SIGNATURE,AUTHORIZATION,CUSTOM] Headers to look for inbound signatures and to store outbound signatures. CUSTOM is provided using io.helidon.security.util.TokenHandler sign-headers always = [\"date\"] Headers to be signed sign-headers.*.method default for all methods Method this configuration is valid for sign-headers.*.always &#160; Array of headers to be always required in the request signature sign-headers.*.if-present &#160; Array of headers to be part of the signatures if present in the request inbound &#160; Configuration of inbound traffic for authenticating incoming requests inbound.keys &#160; Configuration of signature keys to verify incoming requests inbound.keys.*.key-id &#160; Key id as used in inbound signature to find the correct certificate/hmac configuration to verify the signature inbound.keys.*.principal-name &#160; The principal name (or user name) asserted when the signature is valid inbound.keys.*.principal-type SERVICE The type of principal to assert (can be USER ) inbound.keys.*.algorithm according to other configuration hmac-sha256 or rsa-sha256 is assumed if other configuration options for that type are set inbound.keys.*.hmac.secret &#160; Secret shared by the service that signed the request and this service for hmac-sha256 algorithm inbound.keys.*.public-key &#160; Public key configuration, implies rsa-sha256 algorithm inbound.keys.*.public-key.keystore &#160; Keystore configuration for public key - full configuration as defined by KeyStore class outbound &#160; A list of outbound configurations outbound.*.name &#160; Required name of outbound configuration outbound.*.username &#160; Optional username used for outbound security; if not provided, current identity is propagated outbound.*.password &#160; Optional password used for outbound security outbound.*.transports any transport An array of transports this outbound configuration should be used for outbound.*.hosts any host An array of hosts this outbound configuration should be used for, can be a regular expression outbound.*.paths any path An array of paths this outbound configuration should be used for (such as /greet ), can be a regular expression outbound.*.methods any method An array of HTTP methods this outbound configuration should be used for outbound.*.signature &#160; Configuration related to outbound signature configuration outbound.*.signature.key-id &#160; Key id to use in the outbound signature (to map to appropriate public key in target service&#8217;s configuration) outbound.*.signature.header [SIGNATURE,AUTHORIZATION,CUSTOM] Headers supported by HTTP Signature. CUSTOM is provided using io.helidon.security.util.TokenHandler outbound.*.signature.hmac.secret &#160; Shared secret for hmac outbound.*.signature.private-key &#160; Private key configuration for rsa based signatures outbound.*.signature.private-key.keystore &#160; Keystore configuration for private key - full configuration as defined by KeyStore class Signature basics standard: based on https://tools.ietf.org/html/draft-cavage-http-signatures-03 key-id: an arbitrary string used to locate signature configuration - when a request is received the provider locates validation configuration based on this id (e.g. HMAC shared secret or RSA public key). Commonly used meanings are: key fingerprint (RSA); API Key How does it work? Inbound Signatures We act as a server and another party is calling us with a signed HTTP request. We validate the signature and assume identity of the caller. Outbound Signatures We act as a client and we sign our outgoing requests. If there is a matching outbound target specified in configuration, its configuration will be applied for signing the outgoing request, otherwise there is no signature added ",
            "title": "HTTP Signatures Provider"
        },
        {
            "location": "/se/security/02_providers",
            "text": "<markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-idcs-mapper&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"text\" title=\"Provider class name\" >io.helidon.security.providers.idcs.mapper.IdcsRoleMapperProvider <markup lang=\"text\" title=\"Provider configuration key\" >idcs-role-mapper ",
            "title": "Setup"
        },
        {
            "location": "/se/security/02_providers",
            "text": " https://github.com/oracle/helidon/tree/master/examples/security/idcs-login/ <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - idcs-role-mapper: multitenant: false oidc-config: client-id: \"client-id\" client-secret: \"client-secret\" identity-uri: \"IDCS identity server address\" ",
            "title": "Example code"
        },
        {
            "location": "/se/security/02_providers",
            "text": " The following table shows all configuration options of the provider and their default values key default value description multitenant true Whether to support multi-tenancy with this provider idcs-tenant-handler Header X-USER-IDENTITY-SERVICE-GUID Multi-tenant specific TokenHandler configuration to retrieve the tenant id idcs-app-name-handler Header X-RESOURCE-SERVICE-INSTANCE-IDENTITY-APPNAME Multi-tenant specific TokenHandler configuration to retrieve the application name cache-config &#160; Configuration of cache of roles for subjects cache-config.cache-enabled true Possibility to disable the cache altogether cache-config.max-size 100_000 Maximal number of records in the cache cache-config.cache-timeout-millis 1 hour Cache timeout in milliseconds cache-config.cache-evict-delay-millis 1 minute How long to wait before starting the first eviction process cache-config.cache-evict-period-millis 5 minutes Period of running the eviction process cache-config.parallelism-threshold 10_000 Threshold as used by ConcurrentHashMap.forEachKey cache-config.evictor-class &#160; Implementation of BiFunction that receives key and value, and returns true for records that should be removed from the cache. Eviction mechanism should be fast, as it is called within methods of ConcurrentHashMap subject-types USER Can use USER and/or SERVICE default-idcs-subject-type user Default subject type to use when requesting roles, can be user or client oidc-config &#160; OidcConfig configuration, except validate-with-jwk is set to false , and server-type is set to idcs ",
            "title": "Configuration options"
        },
        {
            "location": "/se/security/02_providers",
            "text": " The provider asks the IDCS server to provide list of roles for the currently authenticated user. The result is cached for a certain period of time (see cache-config above). ",
            "title": "How does it work?"
        },
        {
            "location": "/se/security/02_providers",
            "text": " A role mapper to retrieve roles from Oracle IDCS. Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-idcs-mapper&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"text\" title=\"Provider class name\" >io.helidon.security.providers.idcs.mapper.IdcsRoleMapperProvider <markup lang=\"text\" title=\"Provider configuration key\" >idcs-role-mapper Example code https://github.com/oracle/helidon/tree/master/examples/security/idcs-login/ <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - idcs-role-mapper: multitenant: false oidc-config: client-id: \"client-id\" client-secret: \"client-secret\" identity-uri: \"IDCS identity server address\" Configuration options The following table shows all configuration options of the provider and their default values key default value description multitenant true Whether to support multi-tenancy with this provider idcs-tenant-handler Header X-USER-IDENTITY-SERVICE-GUID Multi-tenant specific TokenHandler configuration to retrieve the tenant id idcs-app-name-handler Header X-RESOURCE-SERVICE-INSTANCE-IDENTITY-APPNAME Multi-tenant specific TokenHandler configuration to retrieve the application name cache-config &#160; Configuration of cache of roles for subjects cache-config.cache-enabled true Possibility to disable the cache altogether cache-config.max-size 100_000 Maximal number of records in the cache cache-config.cache-timeout-millis 1 hour Cache timeout in milliseconds cache-config.cache-evict-delay-millis 1 minute How long to wait before starting the first eviction process cache-config.cache-evict-period-millis 5 minutes Period of running the eviction process cache-config.parallelism-threshold 10_000 Threshold as used by ConcurrentHashMap.forEachKey cache-config.evictor-class &#160; Implementation of BiFunction that receives key and value, and returns true for records that should be removed from the cache. Eviction mechanism should be fast, as it is called within methods of ConcurrentHashMap subject-types USER Can use USER and/or SERVICE default-idcs-subject-type user Default subject type to use when requesting roles, can be user or client oidc-config &#160; OidcConfig configuration, except validate-with-jwk is set to false , and server-type is set to idcs How does it work? The provider asks the IDCS server to provide list of roles for the currently authenticated user. The result is cached for a certain period of time (see cache-config above). ",
            "title": "IDCS Role Mapper"
        },
        {
            "location": "/se/security/02_providers",
            "text": "<markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-abac&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"text\" title=\"Provider class name\" >io.helidon.security.providers.abac.AbacProvider <markup lang=\"text\" title=\"Provider configuration key\" >abac ",
            "title": "Setup"
        },
        {
            "location": "/se/security/02_providers",
            "text": " https://github.com/oracle/helidon/tree/master/examples/security/attribute-based-access-control <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - abac: ",
            "title": "Example code"
        },
        {
            "location": "/se/security/02_providers",
            "text": " The following table shows all configuration options of the provider and their default values key default value description fail-on-unvalidated true \"Unvalidated\" means: an attribute is defined, but there is no validator available for it fail-if-none-validated true \"None validated\" means: there was not a single attribute that was validated ",
            "title": "Configuration options"
        },
        {
            "location": "/se/security/02_providers",
            "text": " ABAC uses available validators and validates them against attributes of the authenticated user. Combinations of fail-on-unvalidated and fail-if-none-validated : true &amp; true : Will fail if any attribute is not validated and if any has failed validation false &amp; true : Will fail if there is one or more attributes present and NONE of them is validated or if any has failed validation, Will NOT fail if there is at least one validated attribute and any number of not validated attributes (and NONE failed) false &amp; false : Will fail if there is any attribute that failed validation, Will NOT fail if there are no failed validation or if there are NONE validated Any attribute of the following objects can be used: environment (such as time of request) - e.g. env.time.year subject (user) - e.g. subject.principal.id subject (service) - e.g. service.principal.id object (must be explicitly invoked by developer in code, as object cannot be automatically added to security context) - e.g. object.owner This provider checks that all defined ABAC validators are validated. If there is a definition for a validator that is not checked, the request is denied (depending on configuration as mentioned above). ABAC provider also allows an object to be used in authorization process, such as when evaluating if an object&#8217;s owner is the current user. The following example uses the Expression language validator to demonstrate the point in a JAX-RS resource: <markup lang=\"java\" title=\"Example of using an object\" >@Authenticated @Path(\"/abac\") public class AbacResource { @GET @Authorized(explicit = true) @PolicyStatement(\"${env.time.year &gt;= 2017 &amp;&amp; object.owner == subject.principal.id}\") public Response process(@Context SecurityContext context) { // probably looked up from a database SomeResource res = new SomeResource(\"user\"); AuthorizationResponse atzResponse = context.authorize(res); if (atzResponse.isPermitted()) { //do the update return Response.ok().entity(\"fine, sir\").build(); } else { return Response.status(Response.Status.FORBIDDEN) .entity(atzResponse.getDescription().orElse(\"Access not granted\")) .build(); } } } The following validators are implemented: Roles Scopes EL Policy ",
            "title": "How does it work?"
        },
        {
            "location": "/se/security/02_providers",
            "text": " When using sub-resource locators in JAX-RS, the roles allowed are collected from each \"level\" of execution: - Application class annotations - Resource class annotations + resource method annotations - Sub-resource class annotations + sub-resource method annotations - Sub-resource class annotations + sub-resource method annotations (for every sub-resource on the path) The RolesAllowed or Roles annotation to be used is the last one in the path as defined above. Example 1: There is a RolesAllowed(\"admin\") defined on a sub-resource locator resource class. In this case the required role is admin . Example 2: There is a RolesAllowed(\"admin\") defined on a sub-resource locator resource class and a RolesAllowed(\"user\") defined on the method of the sub-resource that provides the response. In this case the required role is user . ",
            "title": "Interaction with JAX-RS sub-resource locators"
        },
        {
            "location": "/se/security/02_providers",
            "text": " Checks whether user/service is in either of the required role(s). Configuration Key: role-validator Annotations: @RolesAllowed , @RoleValidator.Roles <markup lang=\"yaml\" title=\"Configuration example for WebServer \" >security: web-server.paths: - path: \"/user[/{*}]\" roles-allowed: [\"user\"] <markup lang=\"java\" title=\"JAX-RS example\" >@RolesAllowed(\"user\") @RoleValidator.Roles(value = \"service_role\", subjectType = SubjectType.SERVICE) @Authenticated @Path(\"/abac\") public class AbacResource { } Interaction with JAX-RS sub-resource locators When using sub-resource locators in JAX-RS, the roles allowed are collected from each \"level\" of execution: - Application class annotations - Resource class annotations + resource method annotations - Sub-resource class annotations + sub-resource method annotations - Sub-resource class annotations + sub-resource method annotations (for every sub-resource on the path) The RolesAllowed or Roles annotation to be used is the last one in the path as defined above. Example 1: There is a RolesAllowed(\"admin\") defined on a sub-resource locator resource class. In this case the required role is admin . Example 2: There is a RolesAllowed(\"admin\") defined on a sub-resource locator resource class and a RolesAllowed(\"user\") defined on the method of the sub-resource that provides the response. In this case the required role is user . ",
            "title": "Role Validator"
        },
        {
            "location": "/se/security/02_providers",
            "text": " Checks whether user has all the required scopes. Configuration Key: scope-validator Annotations: @Scope <markup lang=\"yaml\" title=\"Configuration example for WebServer \" >security: web-server.paths: - path: \"/user[/{*}]\" abac.scopes: [\"calendar_read\", \"calendar_edit\"] <markup lang=\"java\" title=\"JAX-RS example\" >@Scope(\"calendar_read\") @Scope(\"calendar_edit\") @Authenticated @Path(\"/abac\") public class AbacResource { } ",
            "title": "Scope Validator"
        },
        {
            "location": "/se/security/02_providers",
            "text": " Policy executor using Java EE policy expression language (EL) Configuration Key: policy-javax-el Annotations: @PolicyStatement Example of a policy statement: ${env.time.year &gt;= 2017} <markup lang=\"yaml\" title=\"Configuration example for WebServer \" >security: web-server.paths: - path: \"/user[/{*}]\" policy: statement: \"hasScopes('calendar_read','calendar_edit') AND timeOfDayBetween('8:15', '17:30')\" <markup lang=\"java\" title=\"JAX-RS example\" >@PolicyStatement(\"${env.time.year &gt;= 2017}\") @Authenticated @Path(\"/abac\") public class AbacResource { } ",
            "title": "Expression Language Policy Validator"
        },
        {
            "location": "/se/security/02_providers",
            "text": " Attribute based access control authorization provider. Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-abac&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"text\" title=\"Provider class name\" >io.helidon.security.providers.abac.AbacProvider <markup lang=\"text\" title=\"Provider configuration key\" >abac Example code https://github.com/oracle/helidon/tree/master/examples/security/attribute-based-access-control <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - abac: Configuration options The following table shows all configuration options of the provider and their default values key default value description fail-on-unvalidated true \"Unvalidated\" means: an attribute is defined, but there is no validator available for it fail-if-none-validated true \"None validated\" means: there was not a single attribute that was validated How does it work? ABAC uses available validators and validates them against attributes of the authenticated user. Combinations of fail-on-unvalidated and fail-if-none-validated : true &amp; true : Will fail if any attribute is not validated and if any has failed validation false &amp; true : Will fail if there is one or more attributes present and NONE of them is validated or if any has failed validation, Will NOT fail if there is at least one validated attribute and any number of not validated attributes (and NONE failed) false &amp; false : Will fail if there is any attribute that failed validation, Will NOT fail if there are no failed validation or if there are NONE validated Any attribute of the following objects can be used: environment (such as time of request) - e.g. env.time.year subject (user) - e.g. subject.principal.id subject (service) - e.g. service.principal.id object (must be explicitly invoked by developer in code, as object cannot be automatically added to security context) - e.g. object.owner This provider checks that all defined ABAC validators are validated. If there is a definition for a validator that is not checked, the request is denied (depending on configuration as mentioned above). ABAC provider also allows an object to be used in authorization process, such as when evaluating if an object&#8217;s owner is the current user. The following example uses the Expression language validator to demonstrate the point in a JAX-RS resource: <markup lang=\"java\" title=\"Example of using an object\" >@Authenticated @Path(\"/abac\") public class AbacResource { @GET @Authorized(explicit = true) @PolicyStatement(\"${env.time.year &gt;= 2017 &amp;&amp; object.owner == subject.principal.id}\") public Response process(@Context SecurityContext context) { // probably looked up from a database SomeResource res = new SomeResource(\"user\"); AuthorizationResponse atzResponse = context.authorize(res); if (atzResponse.isPermitted()) { //do the update return Response.ok().entity(\"fine, sir\").build(); } else { return Response.status(Response.Status.FORBIDDEN) .entity(atzResponse.getDescription().orElse(\"Access not granted\")) .build(); } } } The following validators are implemented: Roles Scopes EL Policy Role Validator Checks whether user/service is in either of the required role(s). Configuration Key: role-validator Annotations: @RolesAllowed , @RoleValidator.Roles <markup lang=\"yaml\" title=\"Configuration example for WebServer \" >security: web-server.paths: - path: \"/user[/{*}]\" roles-allowed: [\"user\"] <markup lang=\"java\" title=\"JAX-RS example\" >@RolesAllowed(\"user\") @RoleValidator.Roles(value = \"service_role\", subjectType = SubjectType.SERVICE) @Authenticated @Path(\"/abac\") public class AbacResource { } Interaction with JAX-RS sub-resource locators When using sub-resource locators in JAX-RS, the roles allowed are collected from each \"level\" of execution: - Application class annotations - Resource class annotations + resource method annotations - Sub-resource class annotations + sub-resource method annotations - Sub-resource class annotations + sub-resource method annotations (for every sub-resource on the path) The RolesAllowed or Roles annotation to be used is the last one in the path as defined above. Example 1: There is a RolesAllowed(\"admin\") defined on a sub-resource locator resource class. In this case the required role is admin . Example 2: There is a RolesAllowed(\"admin\") defined on a sub-resource locator resource class and a RolesAllowed(\"user\") defined on the method of the sub-resource that provides the response. In this case the required role is user . Scope Validator Checks whether user has all the required scopes. Configuration Key: scope-validator Annotations: @Scope <markup lang=\"yaml\" title=\"Configuration example for WebServer \" >security: web-server.paths: - path: \"/user[/{*}]\" abac.scopes: [\"calendar_read\", \"calendar_edit\"] <markup lang=\"java\" title=\"JAX-RS example\" >@Scope(\"calendar_read\") @Scope(\"calendar_edit\") @Authenticated @Path(\"/abac\") public class AbacResource { } Expression Language Policy Validator Policy executor using Java EE policy expression language (EL) Configuration Key: policy-javax-el Annotations: @PolicyStatement Example of a policy statement: ${env.time.year &gt;= 2017} <markup lang=\"yaml\" title=\"Configuration example for WebServer \" >security: web-server.paths: - path: \"/user[/{*}]\" policy: statement: \"hasScopes('calendar_read','calendar_edit') AND timeOfDayBetween('8:15', '17:30')\" <markup lang=\"java\" title=\"JAX-RS example\" >@PolicyStatement(\"${env.time.year &gt;= 2017}\") @Authenticated @Path(\"/abac\") public class AbacResource { } ",
            "title": "ABAC Provider"
        },
        {
            "location": "/se/security/02_providers",
            "text": "<markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-google-login&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"text\" title=\"Provider class name\" >io.helidon.security.providers.google.login.GoogleTokenProvider <markup lang=\"text\" title=\"Provider configuration key\" >google-login ",
            "title": "Setup"
        },
        {
            "location": "/se/security/02_providers",
            "text": " https://github.com/oracle/helidon/tree/master/examples/security/google-login <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - provider: client-id: \"Google client id\" ",
            "title": "Example code"
        },
        {
            "location": "/se/security/02_providers",
            "text": " The following table shows all configuration options of the provider and their default values key default value description client-id &#160; Client id of an application. To create an application, use the Google developer console ( https://developers.google.com/identity/sign-in/web/sign-in ) optional false If set to true , failure to authenticate will return ABSTAIN result instead of FAILURE . This is an important distinction when more than one provider is used realm helidon Realm used in the challenge when authentication is not provided and it is required proxy-host none Configuration of a proxy host to use when authenticating the user proxy-port 80 Proxy port token Authorization header with bearer prefix Configuration of the location of the token (see TokenHandler ) outbound &#160; A list of outbound configurations outbound.*.name &#160; Required name of outbound configuration outbound.*.username &#160; Optional username used for outbound security; if not provided, current identity is propagated outbound.*.password &#160; Optional password used for outbound security outbound.*.transports any transport An array of transports this outbound configuration should be used for outbound.*.hosts any host An array of hosts this outbound configuration should be used for, can be a regular expression outbound.*.paths any path An array of paths this outbound configuration should be used for (such as /greet ), can be a regular expression outbound.*.methods any method An array of HTTP methods this outbound configuration should be used for ",
            "title": "Configuration options"
        },
        {
            "location": "/se/security/02_providers",
            "text": " We expect to receive a token (with sufficient scopes) from the inbound request, such as when using the Google login button on a page. The page has access to the token in javascript and can send it to backend with every request in a header field ( Authorization with `bearer ` prefix is assumed by default). Once we receive the token in Helidon, we parse it and: Validate if it timed out locally Return a cached response (see EvictableCache with default values) Otherwise verify using Google API - GoogleIdTokenVerifier We build a subject from the Google token with the following attributes filled (if in token): userId email name emailVerified locale family_name given_name picture (URL) Outbound security The token will be propagated to outbound calls if an outbound target exists that matches the invoked endpoint (see outbound configuration above). ",
            "title": "How does it work?"
        },
        {
            "location": "/se/security/02_providers",
            "text": " Authenticates a token from request against Google identity provider Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-google-login&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"text\" title=\"Provider class name\" >io.helidon.security.providers.google.login.GoogleTokenProvider <markup lang=\"text\" title=\"Provider configuration key\" >google-login Example code https://github.com/oracle/helidon/tree/master/examples/security/google-login <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - provider: client-id: \"Google client id\" Configuration options The following table shows all configuration options of the provider and their default values key default value description client-id &#160; Client id of an application. To create an application, use the Google developer console ( https://developers.google.com/identity/sign-in/web/sign-in ) optional false If set to true , failure to authenticate will return ABSTAIN result instead of FAILURE . This is an important distinction when more than one provider is used realm helidon Realm used in the challenge when authentication is not provided and it is required proxy-host none Configuration of a proxy host to use when authenticating the user proxy-port 80 Proxy port token Authorization header with bearer prefix Configuration of the location of the token (see TokenHandler ) outbound &#160; A list of outbound configurations outbound.*.name &#160; Required name of outbound configuration outbound.*.username &#160; Optional username used for outbound security; if not provided, current identity is propagated outbound.*.password &#160; Optional password used for outbound security outbound.*.transports any transport An array of transports this outbound configuration should be used for outbound.*.hosts any host An array of hosts this outbound configuration should be used for, can be a regular expression outbound.*.paths any path An array of paths this outbound configuration should be used for (such as /greet ), can be a regular expression outbound.*.methods any method An array of HTTP methods this outbound configuration should be used for How does it work? We expect to receive a token (with sufficient scopes) from the inbound request, such as when using the Google login button on a page. The page has access to the token in javascript and can send it to backend with every request in a header field ( Authorization with `bearer ` prefix is assumed by default). Once we receive the token in Helidon, we parse it and: Validate if it timed out locally Return a cached response (see EvictableCache with default values) Otherwise verify using Google API - GoogleIdTokenVerifier We build a subject from the Google token with the following attributes filled (if in token): userId email name emailVerified locale family_name given_name picture (URL) Outbound security The token will be propagated to outbound calls if an outbound target exists that matches the invoked endpoint (see outbound configuration above). ",
            "title": "Google Login Provider"
        },
        {
            "location": "/se/security/02_providers",
            "text": "<markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-jwt&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"text\" title=\"Provider class name\" >io.helidon.security.providers.jwt.JwtProvider <markup lang=\"text\" title=\"Provider configuration key\" >jwt ",
            "title": "Setup"
        },
        {
            "location": "/se/security/02_providers",
            "text": " https://github.com/oracle/helidon/tree/master/examples/security/outbound-override <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - provider: atn-token: jwk.resource.resource-path: \"verifying-jwk.json\" jwt-audience: \"http://my.service\" sign-token: jwk.resource.resource-path: \"signing-jwk.json\" jwt-issuer: \"http://my.server/identity\" outbound: - name: \"propagate-token\" hosts: [\"*.internal.org\"] - name: \"generate-token\" hosts: [\"1.partner-service\"] jwk-kid: \"partner-1\" jwt-kid: \"helidon\" jwt-audience: \"http://1.partner-service\" ",
            "title": "Example code"
        },
        {
            "location": "/se/security/02_providers",
            "text": " The following table shows all configuration options of the provider and their default values key default value description optional false If set to true , failure to authenticate will return ABSTAIN result instead of FAILURE . This is an important distinction when more than one provider is used authenticate true Whether to attempt authentication propagate true Whether to attempt identity propagation/JWT creation principal-type USER Whether we authenticate a user or a service (other option is SERVICE) atn-token A group for configuring authentication of the request atn-token.verify-signature true Whether to verify signature in incoming JWT. If disabled, ANY JWT will be accepted atn-token.jwt-audience &#160; Expected audience of the JWT. If not defined, any audience is accepted (and we may accept JWT not inteded for us) atn-token.jwk.resource.* &#160; Configuration of the JWK to obtain key(s) to validate signatures of inbound token. The JWK should contain public keys. This may be: jwk.resource.path, jwk.resource.resource-path, jwk.resource.url, jwk.resource.content-plain (actual JSON string), jwk.resource.content (base64) atn-token.handler Authorization header with `bearer ` prefix A handler configuration for inbound token - e.g. how to extract it atn-token.handler.header &#160; Name of a header the token is expected in atn-token.handler.prefix &#160; Prefix before the token value (optional) atn-token.handler.regexp &#160; Regular expression to obtain the token, first matching group is used (optional) sign-token &#160; A group for configuring outbound security sign-token.jwk.resource.* &#160; Configuration of the JWK to use when generating tokens (follows same rules as atn-token.jwk above), this JWK must contain private keys when using asymmetric ciphers sign-token.jwt-issuer &#160; When we issue a new token, this is the issuer to be placed into it (validated by target service) sign-token.outbound &#160; A group for configuring outbound rules (based on transport, host and.or path) sign-token.outbound.*.name &#160; A short descriptive name for configured target service(s) sign-token.outbound.*.transports any An array of transports this outbound matches (e.g. https) sign-token.outbound.*.hosts any An array of hosts this outbound matches, may use * as a wild-card (e.g. *.oracle.com) sign-token.outbound.*.paths any An array of paths on the host this outbound matches, may use * as a wild-card (e.g. /some/path/*) sign-token.outbound.*.outbound-token Authorization header with `bearer ` prefix Configuration of outbound token handler (same as atn-token.handler) sign-token.outbound.*.outbound-token.format &#160; Java text format for generating the value of outbound token header (e.g. \"bearer %1$s\") sign-token.outbound.*.jwk-kid &#160; If this key is defined, we are generating a new token, otherwise we propagate existing. Defines the key id of a key definition in the JWK file to use for signing the outbound token sign-token.outbound.*.jwt-kid &#160; A key to use in the generated JWT - this is for the other service to locate the verification key in their JWK sign-token.outbound.*.jwt-audience &#160; Audience this key is generated for (e.g. http://www.example.org/api/myService ) - validated by the other service sign-token.outbound.*.jwt-not-before-seconds 5 Makes this key valid this amount of seconds into the past. Allows a certain time-skew for the generated token to be valid before current time (e.g. when we expect a certain misalignment of clocks) sign-token.outbound.*.jwt-validity-seconds 1 day Token validity in seconds ",
            "title": "Configuration options"
        },
        {
            "location": "/se/security/02_providers",
            "text": " JSON Web Token (JWT) provider has support for authentication and outbound security. Authentication is based on validating the token (signature, valid before etc.) and on asserting the subject of the JWT subject claim. For outbound, we support either token propagation (e.g. the token from request is propagated further) or support for generating a brand new token based on configuration of this provider. ",
            "title": "How does it work?"
        },
        {
            "location": "/se/security/02_providers",
            "text": " JWT token authentication and outbound security provider. Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-jwt&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"text\" title=\"Provider class name\" >io.helidon.security.providers.jwt.JwtProvider <markup lang=\"text\" title=\"Provider configuration key\" >jwt Example code https://github.com/oracle/helidon/tree/master/examples/security/outbound-override <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - provider: atn-token: jwk.resource.resource-path: \"verifying-jwk.json\" jwt-audience: \"http://my.service\" sign-token: jwk.resource.resource-path: \"signing-jwk.json\" jwt-issuer: \"http://my.server/identity\" outbound: - name: \"propagate-token\" hosts: [\"*.internal.org\"] - name: \"generate-token\" hosts: [\"1.partner-service\"] jwk-kid: \"partner-1\" jwt-kid: \"helidon\" jwt-audience: \"http://1.partner-service\" Configuration options The following table shows all configuration options of the provider and their default values key default value description optional false If set to true , failure to authenticate will return ABSTAIN result instead of FAILURE . This is an important distinction when more than one provider is used authenticate true Whether to attempt authentication propagate true Whether to attempt identity propagation/JWT creation principal-type USER Whether we authenticate a user or a service (other option is SERVICE) atn-token A group for configuring authentication of the request atn-token.verify-signature true Whether to verify signature in incoming JWT. If disabled, ANY JWT will be accepted atn-token.jwt-audience &#160; Expected audience of the JWT. If not defined, any audience is accepted (and we may accept JWT not inteded for us) atn-token.jwk.resource.* &#160; Configuration of the JWK to obtain key(s) to validate signatures of inbound token. The JWK should contain public keys. This may be: jwk.resource.path, jwk.resource.resource-path, jwk.resource.url, jwk.resource.content-plain (actual JSON string), jwk.resource.content (base64) atn-token.handler Authorization header with `bearer ` prefix A handler configuration for inbound token - e.g. how to extract it atn-token.handler.header &#160; Name of a header the token is expected in atn-token.handler.prefix &#160; Prefix before the token value (optional) atn-token.handler.regexp &#160; Regular expression to obtain the token, first matching group is used (optional) sign-token &#160; A group for configuring outbound security sign-token.jwk.resource.* &#160; Configuration of the JWK to use when generating tokens (follows same rules as atn-token.jwk above), this JWK must contain private keys when using asymmetric ciphers sign-token.jwt-issuer &#160; When we issue a new token, this is the issuer to be placed into it (validated by target service) sign-token.outbound &#160; A group for configuring outbound rules (based on transport, host and.or path) sign-token.outbound.*.name &#160; A short descriptive name for configured target service(s) sign-token.outbound.*.transports any An array of transports this outbound matches (e.g. https) sign-token.outbound.*.hosts any An array of hosts this outbound matches, may use * as a wild-card (e.g. *.oracle.com) sign-token.outbound.*.paths any An array of paths on the host this outbound matches, may use * as a wild-card (e.g. /some/path/*) sign-token.outbound.*.outbound-token Authorization header with `bearer ` prefix Configuration of outbound token handler (same as atn-token.handler) sign-token.outbound.*.outbound-token.format &#160; Java text format for generating the value of outbound token header (e.g. \"bearer %1$s\") sign-token.outbound.*.jwk-kid &#160; If this key is defined, we are generating a new token, otherwise we propagate existing. Defines the key id of a key definition in the JWK file to use for signing the outbound token sign-token.outbound.*.jwt-kid &#160; A key to use in the generated JWT - this is for the other service to locate the verification key in their JWK sign-token.outbound.*.jwt-audience &#160; Audience this key is generated for (e.g. http://www.example.org/api/myService ) - validated by the other service sign-token.outbound.*.jwt-not-before-seconds 5 Makes this key valid this amount of seconds into the past. Allows a certain time-skew for the generated token to be valid before current time (e.g. when we expect a certain misalignment of clocks) sign-token.outbound.*.jwt-validity-seconds 1 day Token validity in seconds How does it work? JSON Web Token (JWT) provider has support for authentication and outbound security. Authentication is based on validating the token (signature, valid before etc.) and on asserting the subject of the JWT subject claim. For outbound, we support either token propagation (e.g. the token from request is propagated further) or support for generating a brand new token based on configuration of this provider. ",
            "title": "JWT Provider"
        },
        {
            "location": "/se/security/02_providers",
            "text": " Helidon provides the following security providers for endpoint protection: Provider Type Outbound supported Description OIDC Provider Authentication ✅ Open ID Connect supporting JWT, Scopes, Groups and OIDC code flow HTTP Basic Authentication Authentication ✅ HTTP Basic Authentication support HTTP Digest Authentication Authentication 🚫 HTTP Digest Authentication support Header Assertion Authentication ✅ Asserting a user based on a header value HTTP Signatures Authentication ✅ Protecting service to service communication through signatures IDCS Roles Role Mapping 🚫 Retrieves roles from IDCS provider for authenticated user ABAC Authorization Authorization 🚫 Attribute based access control authorization policies The following providers are no longer evolved: Provider Type Outbound supported Description Google Login Authentication ✅ Authenticates a token from request against Google servers JWT Provider Authentication ✅ JWT tokens passed from frontend OIDC Provider Open ID Connect security provider. Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-oidc&lt;/artifactId&gt; &lt;/dependency&gt; In Helidon SE, we need to register the redirection support with routing (in addition to WebSecurity that integrates with WebServer ). This is not required when redirect is set to false. <markup lang=\"java\" title=\"Adding support for OIDC redirects\" >Routing routing = Routing.builder() .register(WebSecurity.create(config.get(\"security\"))) .register(OidcSupport.create(config)) ... .build(); <markup lang=\"text\" title=\"Provider class name\" >io.helidon.security.providers.oidc.OidcProvider <markup lang=\"text\" title=\"Provider configuration key\" >oidc Example code https://github.com/oracle/helidon/tree/master/examples/security/idcs-login <markup lang=\"yaml\" title=\"Configuration example\" >security: config.require-encryption: false security: providers: - oidc: client-id: \"client-id-of-this-service\" client-secret: \"${CLEAR=client-secret-of-this-service}\" identity-uri: \"http://your-tenant.identity-server.com\" frontend-uri: \"http://my-service:8080\" audience: \"http://my-service\" cors: allow-origins: [\"http://foo.com\", \"http://there.com\"] allow-methods: [\"PUT\", \"DELETE\"] outbound: - name: \"internal-services\" hosts: [\"*.example.org\"] outbound-token: header: \"X-Internal-Auth\" Configuration options The following table shows all configuration options of the provider and their default values key default value description optional false If set to true , failure to authenticate will return ABSTAIN result instead of FAILURE . This is an important distinction when more than one provider is used client-id &#160; Client ID as generated by identity server client-secret &#160; Client secret as generated by identity server identity-uri &#160; URI of the identity server, base used to retrieve OIDC metadata frontend-uri &#160; Full URI of this service for redirects back from OIDC server issuer issuer from OIDC metadata Issuer of token - each JWT is validated to check the issuer audience &#160; Audience of a token - each JWT is validated to check the audience cors &#160; Cross-origin resource sharing settings (see below) proxy-protocol http Proxy protocol to use when proxy is used proxy-host null Proxy host to use. When defined, triggers usage of proxy for HTTP requests proxy-port 80 Port of the proxy server to use redirect-uri /oidc/redirect URI to register web server component on, used by the OIDC server to redirect authorization requests to after a user logs in or approves scopes. Note that usually the redirect URI configured here must be the same one as configured on OIDC server. scope-audience empty string Audience of the scope required by this application. This is prefixed to the scope name when requesting scopes from the identity server. cookie-use true Whether to use cookie to store JWT. If used, redirects happen only in case the user is not authenticated or has insufficient scopes cookie-name JSESSIONID Name of the cookie cookie-domain &#160; Domain the cookie is valid for. Not used by default cookie-path / Path the cookie is valid for. cookie-max-age-seconds {nsbp} When using cookie, used to set MaxAge attribute of the cookie, defining how long the cookie is valid. cookie-http-only true When using cookie, if set to true, the HttpOnly attribute will be configured. cookie-secure false When using cookie, if set to true, the Secure attribute will be configured. cookie-same-site Lax When using cookie, used to set the SameSite cookie value. Can be \"Strict\" or \"Lax\". Setting this to \"Strict\" will result in infinite redirects when calling OIDC on a different host. query-param-use false Whether to expect JWT in a query parameter query-param-name accessToken Name of a query parameter that contains the JWT token when parameter is used. header-use false Whether to expect JWT in a header field. header-token Authorization header with prefix bearer A TokenHandler configuration to process header containing a JWT oidc-metadata-well-known true If set to true, metadata will be loaded from default (well known) location, unless it is explicitly defined using oidc-metadata-resource. If set to false, it would not be loaded even if oidc-metadata-resource is not defined. In such a case all URIs must be explicitly defined (e.g. token-endpoint-uri). oidc-metadata.resource identity-uri/.well-known/openid-configuration Resource configuration for OIDC Metadata containing endpoints to various identity services, as well as information about the identity server. See Resource.create(io.helidon.config.Config) token-endpoint-uri token_endpoint in OIDC metadata, or identity-url/oauth2/v1/token if not available URI of a token endpoint used to obtain a JWT based on the authentication code. authorization-endpoint-uri \"authorization_endpoint\" in OIDC metadata, or identity-uri/oauth2/v1/authorize if not available URI of an authorization endpoint used to redirect users to for logging-in. validate-with-jwk true When true - validate against jwk defined by \"sign-jwk\", when false validate JWT through OIDC Server endpoint \"validation-endpoint-uri\" sign-jwk.resource \"jwks-uri\" in OIDC metadata, or identity-uri/admin/v1/SigningCert/jwk if not available, only needed when jwt validation is done by us A resource pointing to JWK with public keys of signing certificates used to validate JWT. See Resource.create(io.helidon.config.Config) introspect-endpoint-uri \"introspection_endpoint\" in OIDC metadata, or identity-uri/oauth2/v1/introspect When validate-with-jwk is set to \"false\", this is the endpoint used base-scopes openid Configure scopes to be requested by default. If the scope has a qualifier, it must be included here redirect true Whether to redirect to identity server when authentication failed. realm helidon Realm returned in HTTP response if redirect is not enabled or possible. redirect-attempt-param h_ra Query parameter holding the number of times we redirected to an identity server. Customizable to prevent conflicts with application parameters max-redirects 5 Maximal number of times we can redirect to an identity server. When the number is reached, no further redirects happen and the request finishes with an error (status 401) server-type &#160; Type of identity server. Currently supported is idcs or not configured (for default). propagate &#160; Whether to propagate the token we have. Defaults to false unless an outbound configuration is defined outbound &#160; A list of outbound configurations outbound.*.name &#160; Required name of outbound configuration outbound.*.transports any transport An array of transports this outbound configuration should be used for outbound.*.hosts any host An array of hosts this outbound configuration should be used for, can be a regular expression outbound.*.paths any path An array of paths this outbound configuration should be used for (such as /greet ), can be a regular expression outbound.*.methods any method An array of HTTP methods this outbound configuration should be used for outbound.*.outbound-token Authorization header with bearer prefix Configuration of outbound header used to propagate outbound.*.outbound-token.header &#160; Name of the header used to propagate the token outbound.*.outbound-token.prefix &#160; Prefix for the header value, such as \"bearer\" (only one of prefix , regexp and format should be defined, regexp wins over prefix , format wins over regexp ) outbound.*.outbound-token.format &#160; String format with a single parameter to create the header value, such as \"bearer %1s\" outbound.*.outbound-token.regexp &#160; Regular expression to create the header value, such as \"bearer (.*)\" How does it work? At Helidon startup, if OIDC provider is configured, the following will happen: client-id , client-secret , and identityUri are validated - these must provide values Unless all resources are configured as local resources, the provider attempts to contact the oidc-metadata.resource endpoint to retrieve all endpoints At runtime, depending on configuration&#8230;&#8203; If a request comes without a token or with insufficient scopes: If redirect is set to true (default), request is redirected to the authorization endpoint of the identity server. If set to false, 401 is returned User authenticates against the identity server The identity server redirects back to Helidon service with a code Helidon service contacts the identity server&#8217;s token endpoint, to exchange the code for a JWT The JWT is stored in a cookie (if cookie support is enabled, which it is by default) Helidon service redirects to original endpoint (on itself) Helidon obtains a token from request (from cookie, header, or query parameter): Token is parsed as a singed JWT We validate the JWT signature either against local JWK or against the identity server&#8217;s introspection endpoint depending on configuration We validate the issuer and audience of the token if it matches the configured values A subject is created from the JWT, including scopes from the token We validate that we have sufficient scopes to proceed, and return 403 if not Handling is returned to security to process other security providers CORS Settings As an experimental feature, you can set up cross-origin handling for the redirect and logout endpoints in an optional cors block inside the oidc configuration. The table below lists the configuration keys that identify the CORS characteristics. Configuration Key Default CORS Header Name allow-credentials false Access-Control-Allow-Credentials allow-headers [\"*\"] Access-Control-Allow-Headers allow-methods [\"*\"] Access-Control-Allow-Methods allow-origins [\"*\"] Access-Control-Allow-Origins expose-headers none Access-Control-Expose-Headers max-age 3600 Access-Control-Max-Age enabled true n/a If the cross-origin configuration is disabled ( enabled = false), then the Helidon CORS implementation ignores the cross-origin configuration entry. The following example of basic cross-origin configuration limits cross-origin resource sharing for PUT and DELETE operations to only foo.com and there.com : <markup lang=\"hocon\" >... allow-origins: [\"http://foo.com\", \"http://there.com\"] allow-methods: [\"PUT\", \"DELETE\"] ... HTTP Basic Authentication Provider HTTP Basic authentication support Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-http-auth&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"text\" title=\"Provider class name\" >io.helidon.security.providers.httpauth.HttpBasicAuthProvider <markup lang=\"text\" title=\"Provider configuration key\" >http-basic-auth Example code https://github.com/oracle/helidon/tree/master/examples/security/outbound-override <markup lang=\"yaml\" title=\"Configuration example\" >security: config.require-encryption: false security: providers: - http-basic-auth: realm: \"helidon\" users: - login: \"john\" password: \"${CLEAR=password}\" roles: [\"admin\"] - login: \"jack\" password: \"password\" roles: [\"user\", \"admin\"] outbound: - name: \"internal-services\" hosts: [\"*.example.org\"] # Propagates current user's identity or identity from request property outbound-token: header: \"X-Internal-Auth\" - name: \"partner-service\" hosts: [\"*.partner.org\"] # Uses this username and password username: \"partner-user-1\" password: \"${CLEAR=password}\" Configuration options The following table shows all configuration options of the provider and their default values key default value description optional false If set to true , failure to authenticate will return ABSTAIN result instead of FAILURE . This is an important distinction when more than one provider is used realm helidon The realm shown in challenge when user accesses a service without authentication principal-type USER Type of authenticated entity - either USER or SERVICE , can be used in combination with other authentication mechanism to authenticate both the user (as in person sitting in front of a computer) and a service (as in the application requesting this service on user&#8217;s behalf) users &#160; List of users when using configuration based approach. As an alternative, you can implement a java service (see below). outbound &#160; A list of outbound configurations outbound.*.name &#160; Required name of outbound configuration outbound.*.username &#160; Optional username used for outbound security; if not provided, current identity is propagated outbound.*.password &#160; Optional password used for outbound security outbound.*.transports any transport An array of transports this outbound configuration should be used for outbound.*.hosts any host An array of hosts this outbound configuration should be used for, can be a regular expression outbound.*.paths any path An array of paths this outbound configuration should be used for (such as /greet ), can be a regular expression outbound.*.methods any method An array of HTTP methods this outbound configuration should be used for outbound.*.outbound-token Authorization header with basic prefix Configuration of outbound header used to propagate outbound.*.outbound-token.header &#160; Name of the header used to propagate the token outbound.*.outbound-token.prefix &#160; Prefix for the header value, such as \"basic \" (only one of prefix , regexp and format should be defined, regexp wins over prefix , format wins over regexp ) outbound.*.outbound-token.format &#160; String format with a single parameter to create the header value, such as \"basic %1s\" outbound.*.outbound-token.regexp &#160; Regular expression to create the header value, such as \"basic (.*)\" How does it work? See https://tools.ietf.org/html/rfc7617 . Authentication of request When a request is received without the Authorization: basic &#8230;&#8203;. header, a challenge is returned to provide such authentication. When a request is received with the Authorization: basic &#8230;&#8203;. header, the username and password is validated against configured users (and users obtained from custom service if any provided). Subject is created based on the username and roles provided by the user store. Identity propagation When identity propagation is configured, there are several options for identifying username and password to propagate: We propagate the current username and password (inbound request must be authenticated using basic authentication). We use username and password from an explicitly configured property (See HttpBasicAuthProvider.EP_PROPERTY_OUTBOUND_USER and HttpBasicAuthProvider.EP_PROPERTY_OUTBOUND_PASSWORD ) We use username and password associated with an outbound target (see example configuration above) Identity is propagated only if: There is an outbound target configured for the endpoint Or there is an explicitly configured username/password for the current request (through request property) Custom user store Java service loader service io.helidon.security.providers.httpauth.spi.UserStoreService can be implemented to provide users to the provider, such as when validated against an internal database or LDAP server. The user store is defined so you never need the clear text password of the user. Warning on security of HTTP Basic Authenticaton (or lack thereof) Basic authentication uses base64 encoded username and password and passes it over the network. Base64 is only encoding, not encryption - so anybody that gets hold of the header value can learn the actual username and password of the user. This is a security risk and an attack vector that everybody should be aware of before using HTTP Basic Authentication. We recommend using this approach only for testing and demo purposes. HTTP Digest Authentication Provider HTTP Digest authentication support Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-http-auth&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"text\" title=\"Provider class name\" >io.helidon.security.providers.httpauth.HttpDigestAuthProvider <markup lang=\"text\" title=\"Provider configuration key\" >http-digest-auth Example code <markup lang=\"yaml\" title=\"Configuration example\" >security: config.require-encryption: false security: providers: - http-digest-auth: realm: \"helidon\" server-secret: \"${CLEAR=service-wide-secret-not-known-outside}\" users: - login: \"john\" password: \"${CLEAR=password}\" roles: [\"admin\"] - login: \"jack\" password: \"password\" roles: [\"user\", \"admin\"] Configuration options The following table shows all configuration options of the provider and their default values key default value description optional false If set to true , failure to authenticate will return ABSTAIN result instead of FAILURE . This is an important distinction when more than one provider is used realm helidon The realm shown in challenge when user accesses a service without authentication principal-type USER Type of authenticated entity - either USER or SERVICE , can be used in combination with other authentication mechanism to authenticate both the user (as in person sitting in front of a computer) and a service (as in the application requesting this service on user&#8217;s behalf) users &#160; List of users when using configuration based approach. As an alternative, you can implement a java service (see below). algorithm MD5 Only MD5 supported nonce-timeout-millis 1 day Number of milliseconds for the nonce timeout server-secret random A string to use as a server secret - this is to use digest auth between multiple servers (e.g. when in a cluster). Used to encrypt nonce. This must not be known outside of this app, as others may create digest requests we would trust. qop NONE only AUTH supported. If left empty, uses the legacy approach (older RFC version). AUTH-INT is not supported. How does it work? See https://tools.ietf.org/html/rfc7616 . Authentication of request When a request is received without the Authorization: digest &#8230;&#8203;. header, a challenge is returned to provide such authentication using WWW-Authenticate header. When a request is received with the Authorization: digest &#8230;&#8203;. header, the request is validated against configured users (and users obtained from custom service if any provided). Subject is created based on the username and roles provided by the user store. Custom user store Java service loader service io.helidon.security.providers.httpauth.spi.UserStoreService can be implemented to provide users to the provider, such as when validated against an internal database or LDAP server. The user store is defined so you never need the clear text password of the user. Note on security of HTTP Digest Authenticaton These authentication schemes should be obsolete , though they provide a very easy way to test a protected resource. Header Authentication Provider Asserts user or service identity based on a value of a header. Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-header&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"text\" title=\"Provider class name\" >io.helidon.security.providers.header.HeaderAtnProvider <markup lang=\"text\" title=\"Provider configuration key\" >header-atn Example code <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: header-atn: atn-token: header: \"X-AUTH-USER\" outbound: - name: \"internal-services\" hosts: [\"*.example.org\"] # propagates the current user or service id using the same header as authentication - name: \"partner-service\" hosts: [\"*.partner.org\"] # propagates an explicit username in a custom header username: \"service-27\" outbound-token: header: \"X-Service-Auth\" Configuration options The following table shows all configuration options of the provider and their default values key default value description optional false If set to true , failure to authenticate will return ABSTAIN result instead of FAILURE . This is an important distinction when more than one provider is used authenticate true If set to false , authentication will not be attempted (outbound security can still be used) propagate false If explicitly set to false , identity propagation will not be done. Otherwise it is done if an outbound section is configured principal-type USER Can be USER or SERVICE atn-token none Token extraction and propagation, you can define which header to use and how to extract it outbound &#160; A list of outbound configurations outbound.*.name &#160; Required name of outbound configuration outbound.*.username &#160; Optional username used for outbound security; if not provided, current identity is propagated outbound.*.transports any transport An array of transports this outbound configuration should be used for outbound.*.hosts any host An array of hosts this outbound configuration should be used for, can be a regular expression outbound.*.paths any path An array of paths this outbound configuration should be used for (such as /greet ), can be a regular expression outbound.*.methods any method An array of HTTP methods this outbound configuration should be used for outbound.*.outbound-token same as atn-token Configuration of outbound header used to propagate outbound.*.outbound-token.header &#160; Name of the header used to propagate the token outbound.*.outbound-token.prefix &#160; Prefix for the header value, such as \"username \" (only one of prefix , regexp and format should be defined, regexp wins over prefix , format wins over regexp ) outbound.*.outbound-token.format &#160; String format with a single parameter to create the header value, such as \"username %1s\" outbound.*.outbound-token.regexp &#160; Regular expression to create the header value, such as \"username (.*)\" How does it work? This provider inspects a specified request header and extracts the username/service name from it and asserts it as current subject&#8217;s principal. This can be used when we use perimeter authentication (e.g. there is a gateway that takes care of authentication and propagates the user in a header). Identity propagation Identity is propagated only if an outbound target matches the target service. The following options exist when propagating identity: 1. We propagate the current username using the configured header 2. We use username associated with an outbound target (see example configuration above) Caution When using this provider, you must be sure the header cannot be explicitly configured by a user or another service. All requests should go through a gateway that removes this header from inbound traffic, and only configures it for authenticated users/services. Another option is to use this with fully trusted parties (such as services within a single company, on a single protected network not accessible to any users), and of course for testing and demo purposes. HTTP Signatures Provider Support for HTTP Signatures. Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-http-sign&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"text\" title=\"Provider class name\" >io.helidon.security.providers.httpsign.HttpSignProvider <markup lang=\"text\" title=\"Provider configuration key\" >http-signatures Example code https://github.com/oracle/helidon/tree/master/examples/security/webserver-signatures <markup lang=\"yaml\" title=\"Configuration example\" >security: config.require-encryption: false security: providers: - http-signatures: inbound: keys: - key-id: \"service1-hmac\" principal-name: \"Service1 - HMAC signature\" hmac.secret: \"${CLEAR=somePasswordForHmacShouldBeEncrypted}\" - key-id: \"service1-rsa\" principal-name: \"Service1 - RSA signature\" public-key: keystore: resource.path: \"src/main/resources/keystore.p12\" passphrase: \"password\" cert.alias: \"service_cert\" outbound: - name: \"service2-hmac\" hosts: [\"localhost\"] paths: [\"/service2\"] signature: key-id: \"service1-hmac\" hmac.secret: \"${CLEAR=somePasswordForHmacShouldBeEncrypted}\" - name: \"service2-rsa\" hosts: [\"localhost\"] paths: [\"/service2-rsa.*\"] signature: key-id: \"service1-rsa\" private-key: keystore: resource.path: \"src/main/resources/keystore.p12\" passphrase: \"password\" key.alias: \"myPrivateKey\" Configuration options The following table shows all configuration options of the provider and their default values key default value description optional false If set to true , failure to authenticate will return ABSTAIN result instead of FAILURE . This is an important distinction when more than one provider is used realm helidon Realm used for challenge when request does not have a signature headers [SIGNATURE,AUTHORIZATION,CUSTOM] Headers to look for inbound signatures and to store outbound signatures. CUSTOM is provided using io.helidon.security.util.TokenHandler sign-headers always = [\"date\"] Headers to be signed sign-headers.*.method default for all methods Method this configuration is valid for sign-headers.*.always &#160; Array of headers to be always required in the request signature sign-headers.*.if-present &#160; Array of headers to be part of the signatures if present in the request inbound &#160; Configuration of inbound traffic for authenticating incoming requests inbound.keys &#160; Configuration of signature keys to verify incoming requests inbound.keys.*.key-id &#160; Key id as used in inbound signature to find the correct certificate/hmac configuration to verify the signature inbound.keys.*.principal-name &#160; The principal name (or user name) asserted when the signature is valid inbound.keys.*.principal-type SERVICE The type of principal to assert (can be USER ) inbound.keys.*.algorithm according to other configuration hmac-sha256 or rsa-sha256 is assumed if other configuration options for that type are set inbound.keys.*.hmac.secret &#160; Secret shared by the service that signed the request and this service for hmac-sha256 algorithm inbound.keys.*.public-key &#160; Public key configuration, implies rsa-sha256 algorithm inbound.keys.*.public-key.keystore &#160; Keystore configuration for public key - full configuration as defined by KeyStore class outbound &#160; A list of outbound configurations outbound.*.name &#160; Required name of outbound configuration outbound.*.username &#160; Optional username used for outbound security; if not provided, current identity is propagated outbound.*.password &#160; Optional password used for outbound security outbound.*.transports any transport An array of transports this outbound configuration should be used for outbound.*.hosts any host An array of hosts this outbound configuration should be used for, can be a regular expression outbound.*.paths any path An array of paths this outbound configuration should be used for (such as /greet ), can be a regular expression outbound.*.methods any method An array of HTTP methods this outbound configuration should be used for outbound.*.signature &#160; Configuration related to outbound signature configuration outbound.*.signature.key-id &#160; Key id to use in the outbound signature (to map to appropriate public key in target service&#8217;s configuration) outbound.*.signature.header [SIGNATURE,AUTHORIZATION,CUSTOM] Headers supported by HTTP Signature. CUSTOM is provided using io.helidon.security.util.TokenHandler outbound.*.signature.hmac.secret &#160; Shared secret for hmac outbound.*.signature.private-key &#160; Private key configuration for rsa based signatures outbound.*.signature.private-key.keystore &#160; Keystore configuration for private key - full configuration as defined by KeyStore class Signature basics standard: based on https://tools.ietf.org/html/draft-cavage-http-signatures-03 key-id: an arbitrary string used to locate signature configuration - when a request is received the provider locates validation configuration based on this id (e.g. HMAC shared secret or RSA public key). Commonly used meanings are: key fingerprint (RSA); API Key How does it work? Inbound Signatures We act as a server and another party is calling us with a signed HTTP request. We validate the signature and assume identity of the caller. Outbound Signatures We act as a client and we sign our outgoing requests. If there is a matching outbound target specified in configuration, its configuration will be applied for signing the outgoing request, otherwise there is no signature added IDCS Role Mapper A role mapper to retrieve roles from Oracle IDCS. Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-idcs-mapper&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"text\" title=\"Provider class name\" >io.helidon.security.providers.idcs.mapper.IdcsRoleMapperProvider <markup lang=\"text\" title=\"Provider configuration key\" >idcs-role-mapper Example code https://github.com/oracle/helidon/tree/master/examples/security/idcs-login/ <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - idcs-role-mapper: multitenant: false oidc-config: client-id: \"client-id\" client-secret: \"client-secret\" identity-uri: \"IDCS identity server address\" Configuration options The following table shows all configuration options of the provider and their default values key default value description multitenant true Whether to support multi-tenancy with this provider idcs-tenant-handler Header X-USER-IDENTITY-SERVICE-GUID Multi-tenant specific TokenHandler configuration to retrieve the tenant id idcs-app-name-handler Header X-RESOURCE-SERVICE-INSTANCE-IDENTITY-APPNAME Multi-tenant specific TokenHandler configuration to retrieve the application name cache-config &#160; Configuration of cache of roles for subjects cache-config.cache-enabled true Possibility to disable the cache altogether cache-config.max-size 100_000 Maximal number of records in the cache cache-config.cache-timeout-millis 1 hour Cache timeout in milliseconds cache-config.cache-evict-delay-millis 1 minute How long to wait before starting the first eviction process cache-config.cache-evict-period-millis 5 minutes Period of running the eviction process cache-config.parallelism-threshold 10_000 Threshold as used by ConcurrentHashMap.forEachKey cache-config.evictor-class &#160; Implementation of BiFunction that receives key and value, and returns true for records that should be removed from the cache. Eviction mechanism should be fast, as it is called within methods of ConcurrentHashMap subject-types USER Can use USER and/or SERVICE default-idcs-subject-type user Default subject type to use when requesting roles, can be user or client oidc-config &#160; OidcConfig configuration, except validate-with-jwk is set to false , and server-type is set to idcs How does it work? The provider asks the IDCS server to provide list of roles for the currently authenticated user. The result is cached for a certain period of time (see cache-config above). ABAC Provider Attribute based access control authorization provider. Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-abac&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"text\" title=\"Provider class name\" >io.helidon.security.providers.abac.AbacProvider <markup lang=\"text\" title=\"Provider configuration key\" >abac Example code https://github.com/oracle/helidon/tree/master/examples/security/attribute-based-access-control <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - abac: Configuration options The following table shows all configuration options of the provider and their default values key default value description fail-on-unvalidated true \"Unvalidated\" means: an attribute is defined, but there is no validator available for it fail-if-none-validated true \"None validated\" means: there was not a single attribute that was validated How does it work? ABAC uses available validators and validates them against attributes of the authenticated user. Combinations of fail-on-unvalidated and fail-if-none-validated : true &amp; true : Will fail if any attribute is not validated and if any has failed validation false &amp; true : Will fail if there is one or more attributes present and NONE of them is validated or if any has failed validation, Will NOT fail if there is at least one validated attribute and any number of not validated attributes (and NONE failed) false &amp; false : Will fail if there is any attribute that failed validation, Will NOT fail if there are no failed validation or if there are NONE validated Any attribute of the following objects can be used: environment (such as time of request) - e.g. env.time.year subject (user) - e.g. subject.principal.id subject (service) - e.g. service.principal.id object (must be explicitly invoked by developer in code, as object cannot be automatically added to security context) - e.g. object.owner This provider checks that all defined ABAC validators are validated. If there is a definition for a validator that is not checked, the request is denied (depending on configuration as mentioned above). ABAC provider also allows an object to be used in authorization process, such as when evaluating if an object&#8217;s owner is the current user. The following example uses the Expression language validator to demonstrate the point in a JAX-RS resource: <markup lang=\"java\" title=\"Example of using an object\" >@Authenticated @Path(\"/abac\") public class AbacResource { @GET @Authorized(explicit = true) @PolicyStatement(\"${env.time.year &gt;= 2017 &amp;&amp; object.owner == subject.principal.id}\") public Response process(@Context SecurityContext context) { // probably looked up from a database SomeResource res = new SomeResource(\"user\"); AuthorizationResponse atzResponse = context.authorize(res); if (atzResponse.isPermitted()) { //do the update return Response.ok().entity(\"fine, sir\").build(); } else { return Response.status(Response.Status.FORBIDDEN) .entity(atzResponse.getDescription().orElse(\"Access not granted\")) .build(); } } } The following validators are implemented: Roles Scopes EL Policy Role Validator Checks whether user/service is in either of the required role(s). Configuration Key: role-validator Annotations: @RolesAllowed , @RoleValidator.Roles <markup lang=\"yaml\" title=\"Configuration example for WebServer \" >security: web-server.paths: - path: \"/user[/{*}]\" roles-allowed: [\"user\"] <markup lang=\"java\" title=\"JAX-RS example\" >@RolesAllowed(\"user\") @RoleValidator.Roles(value = \"service_role\", subjectType = SubjectType.SERVICE) @Authenticated @Path(\"/abac\") public class AbacResource { } Interaction with JAX-RS sub-resource locators When using sub-resource locators in JAX-RS, the roles allowed are collected from each \"level\" of execution: - Application class annotations - Resource class annotations + resource method annotations - Sub-resource class annotations + sub-resource method annotations - Sub-resource class annotations + sub-resource method annotations (for every sub-resource on the path) The RolesAllowed or Roles annotation to be used is the last one in the path as defined above. Example 1: There is a RolesAllowed(\"admin\") defined on a sub-resource locator resource class. In this case the required role is admin . Example 2: There is a RolesAllowed(\"admin\") defined on a sub-resource locator resource class and a RolesAllowed(\"user\") defined on the method of the sub-resource that provides the response. In this case the required role is user . Scope Validator Checks whether user has all the required scopes. Configuration Key: scope-validator Annotations: @Scope <markup lang=\"yaml\" title=\"Configuration example for WebServer \" >security: web-server.paths: - path: \"/user[/{*}]\" abac.scopes: [\"calendar_read\", \"calendar_edit\"] <markup lang=\"java\" title=\"JAX-RS example\" >@Scope(\"calendar_read\") @Scope(\"calendar_edit\") @Authenticated @Path(\"/abac\") public class AbacResource { } Expression Language Policy Validator Policy executor using Java EE policy expression language (EL) Configuration Key: policy-javax-el Annotations: @PolicyStatement Example of a policy statement: ${env.time.year &gt;= 2017} <markup lang=\"yaml\" title=\"Configuration example for WebServer \" >security: web-server.paths: - path: \"/user[/{*}]\" policy: statement: \"hasScopes('calendar_read','calendar_edit') AND timeOfDayBetween('8:15', '17:30')\" <markup lang=\"java\" title=\"JAX-RS example\" >@PolicyStatement(\"${env.time.year &gt;= 2017}\") @Authenticated @Path(\"/abac\") public class AbacResource { } Google Login Provider Authenticates a token from request against Google identity provider Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-google-login&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"text\" title=\"Provider class name\" >io.helidon.security.providers.google.login.GoogleTokenProvider <markup lang=\"text\" title=\"Provider configuration key\" >google-login Example code https://github.com/oracle/helidon/tree/master/examples/security/google-login <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - provider: client-id: \"Google client id\" Configuration options The following table shows all configuration options of the provider and their default values key default value description client-id &#160; Client id of an application. To create an application, use the Google developer console ( https://developers.google.com/identity/sign-in/web/sign-in ) optional false If set to true , failure to authenticate will return ABSTAIN result instead of FAILURE . This is an important distinction when more than one provider is used realm helidon Realm used in the challenge when authentication is not provided and it is required proxy-host none Configuration of a proxy host to use when authenticating the user proxy-port 80 Proxy port token Authorization header with bearer prefix Configuration of the location of the token (see TokenHandler ) outbound &#160; A list of outbound configurations outbound.*.name &#160; Required name of outbound configuration outbound.*.username &#160; Optional username used for outbound security; if not provided, current identity is propagated outbound.*.password &#160; Optional password used for outbound security outbound.*.transports any transport An array of transports this outbound configuration should be used for outbound.*.hosts any host An array of hosts this outbound configuration should be used for, can be a regular expression outbound.*.paths any path An array of paths this outbound configuration should be used for (such as /greet ), can be a regular expression outbound.*.methods any method An array of HTTP methods this outbound configuration should be used for How does it work? We expect to receive a token (with sufficient scopes) from the inbound request, such as when using the Google login button on a page. The page has access to the token in javascript and can send it to backend with every request in a header field ( Authorization with `bearer ` prefix is assumed by default). Once we receive the token in Helidon, we parse it and: Validate if it timed out locally Return a cached response (see EvictableCache with default values) Otherwise verify using Google API - GoogleIdTokenVerifier We build a subject from the Google token with the following attributes filled (if in token): userId email name emailVerified locale family_name given_name picture (URL) Outbound security The token will be propagated to outbound calls if an outbound target exists that matches the invoked endpoint (see outbound configuration above). JWT Provider JWT token authentication and outbound security provider. Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-jwt&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"text\" title=\"Provider class name\" >io.helidon.security.providers.jwt.JwtProvider <markup lang=\"text\" title=\"Provider configuration key\" >jwt Example code https://github.com/oracle/helidon/tree/master/examples/security/outbound-override <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - provider: atn-token: jwk.resource.resource-path: \"verifying-jwk.json\" jwt-audience: \"http://my.service\" sign-token: jwk.resource.resource-path: \"signing-jwk.json\" jwt-issuer: \"http://my.server/identity\" outbound: - name: \"propagate-token\" hosts: [\"*.internal.org\"] - name: \"generate-token\" hosts: [\"1.partner-service\"] jwk-kid: \"partner-1\" jwt-kid: \"helidon\" jwt-audience: \"http://1.partner-service\" Configuration options The following table shows all configuration options of the provider and their default values key default value description optional false If set to true , failure to authenticate will return ABSTAIN result instead of FAILURE . This is an important distinction when more than one provider is used authenticate true Whether to attempt authentication propagate true Whether to attempt identity propagation/JWT creation principal-type USER Whether we authenticate a user or a service (other option is SERVICE) atn-token A group for configuring authentication of the request atn-token.verify-signature true Whether to verify signature in incoming JWT. If disabled, ANY JWT will be accepted atn-token.jwt-audience &#160; Expected audience of the JWT. If not defined, any audience is accepted (and we may accept JWT not inteded for us) atn-token.jwk.resource.* &#160; Configuration of the JWK to obtain key(s) to validate signatures of inbound token. The JWK should contain public keys. This may be: jwk.resource.path, jwk.resource.resource-path, jwk.resource.url, jwk.resource.content-plain (actual JSON string), jwk.resource.content (base64) atn-token.handler Authorization header with `bearer ` prefix A handler configuration for inbound token - e.g. how to extract it atn-token.handler.header &#160; Name of a header the token is expected in atn-token.handler.prefix &#160; Prefix before the token value (optional) atn-token.handler.regexp &#160; Regular expression to obtain the token, first matching group is used (optional) sign-token &#160; A group for configuring outbound security sign-token.jwk.resource.* &#160; Configuration of the JWK to use when generating tokens (follows same rules as atn-token.jwk above), this JWK must contain private keys when using asymmetric ciphers sign-token.jwt-issuer &#160; When we issue a new token, this is the issuer to be placed into it (validated by target service) sign-token.outbound &#160; A group for configuring outbound rules (based on transport, host and.or path) sign-token.outbound.*.name &#160; A short descriptive name for configured target service(s) sign-token.outbound.*.transports any An array of transports this outbound matches (e.g. https) sign-token.outbound.*.hosts any An array of hosts this outbound matches, may use * as a wild-card (e.g. *.oracle.com) sign-token.outbound.*.paths any An array of paths on the host this outbound matches, may use * as a wild-card (e.g. /some/path/*) sign-token.outbound.*.outbound-token Authorization header with `bearer ` prefix Configuration of outbound token handler (same as atn-token.handler) sign-token.outbound.*.outbound-token.format &#160; Java text format for generating the value of outbound token header (e.g. \"bearer %1$s\") sign-token.outbound.*.jwk-kid &#160; If this key is defined, we are generating a new token, otherwise we propagate existing. Defines the key id of a key definition in the JWK file to use for signing the outbound token sign-token.outbound.*.jwt-kid &#160; A key to use in the generated JWT - this is for the other service to locate the verification key in their JWK sign-token.outbound.*.jwt-audience &#160; Audience this key is generated for (e.g. http://www.example.org/api/myService ) - validated by the other service sign-token.outbound.*.jwt-not-before-seconds 5 Makes this key valid this amount of seconds into the past. Allows a certain time-skew for the generated token to be valid before current time (e.g. when we expect a certain misalignment of clocks) sign-token.outbound.*.jwt-validity-seconds 1 day Token validity in seconds How does it work? JSON Web Token (JWT) provider has support for authentication and outbound security. Authentication is based on validating the token (signature, valid before etc.) and on asserting the subject of the JWT subject claim. For outbound, we support either token propagation (e.g. the token from request is propagated further) or support for generating a brand new token based on configuration of this provider. ",
            "title": "Implemented Security Providers"
        },
        {
            "location": "/se/cors/01_introduction",
            "text": " Cross-origin resource sharing (CORS) support in Helidon SE provides a flexible mechanism that allows a Helidon SE application to control how another web application can access its resources, even if that web application is served from a different domain. ",
            "title": "preambule"
        },
        {
            "location": "/se/cors/01_introduction",
            "text": " The CORS protocol helps developers control if and how REST resources served by their applications can be shared across origins. Helidon SE includes an implementation of CORS that you can use to add CORS behavior to the services you develop. You can define your application&#8217;s CORS behavior programmatically using the Helidon CORS API alone, or together with configuration. Helidon also provides three built-in services that add their own endpoints to your application - health, metrics, and OpenAPI - that have integrated CORS support. By adding very little code to your application, you control how all the resources in your application&#8201;&#8212;&#8201;the ones you write and the ones provided by the Helidon built-in services&#8201;&#8212;&#8201;can be shared across origins. ",
            "title": "Overview"
        },
        {
            "location": "/se/cors/01_introduction",
            "text": " Before you revise your application to add CORS support, you need to decide what type of cross-origin sharing you want to allow for each resource your application exposes. For example, suppose for a given resource you want to allow unrestricted sharing for GET, HEAD, and POST requests (what CORS refers to as \"simple\" requests), but permit other types of requests only from the two origins foo.com and there.com . Your application would implement two types of CORS sharing: more relaxed for the simple requests and stricter for others. Once you know the type of sharing you want to allow for each of your resources&#8201;&#8212;&#8201;including any from built-in services&#8201;&#8212;&#8201;you can change your application accordingly. ",
            "title": "Before You Begin"
        },
        {
            "location": "/se/cors/01_introduction",
            "text": " To introduce CORS into your Helidon SE application, do any or all of the following: Modify your code using the Helidon SE CORS API. Learn more. Use configuration in combination with the Helidon SE CORS API to add CORS to your application. Learn more. Update your application to include any of the built-in Helidon services that automatically support CORS. Learn more. ",
            "title": "Next Steps"
        },
        {
            "location": "/se/guides/04_health",
            "text": " This guide describes how to create a sample Helidon SE project that can be used to run some basic examples using both built-in and custom health-checks. ",
            "title": "preambule"
        },
        {
            "location": "/se/guides/04_health",
            "text": " Generate the project sources using the Helidon SE Maven archetype. The result is a simple project that can be used for the examples in this guide. <markup lang=\"bash\" title=\"Run the Maven archetype:\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-se \\ -DarchetypeVersion=2.5.4 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-se \\ -Dpackage=io.helidon.examples.quickstart.se ",
            "title": "Create a Sample SE Project"
        },
        {
            "location": "/se/guides/04_health",
            "text": " Helidon has a set of built-in health checks that can be optionally enabled to report various health-check statuses that are commonly used: deadlock detection available disk space available heap memory The following example will demonstrate how to use the built-in health-checks. These examples are all executed from the root directory of your project (helidon-quickstart-se). <markup lang=\"xml\" title=\"Notice that the built-in health-check dependency is already in the project&#8217;s pom.xml file:\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.health&lt;/groupId&gt; &lt;artifactId&gt;helidon-health-checks&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"java\" title=\"Have a look at Main.java , and the createRouting method:\" >private static Routing createRouting(Config config) { HealthSupport health = HealthSupport.builder() .addLiveness(HealthChecks.healthChecks()) .build(); return Routing.builder() .register(health) .build(); } Add built-in health-checks (requires the helidon-health-checks dependency). Register the created health support with web server routing (adds the /health endpoint). <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-se.jar <markup lang=\"bash\" title=\"Verify the health endpoint in a new terminal window:\" >curl http://localhost:8080/health <markup lang=\"json\" title=\"JSON response:\" >{ \"outcome\": \"UP\", \"status\": \"UP\", \"checks\": [ { \"name\": \"deadlock\", \"state\": \"UP\", \"status\": \"UP\" }, { \"name\": \"diskSpace\", \"state\": \"UP\", \"status\": \"UP\", \"data\": { \"free\": \"319.58 GB\", \"freeBytes\": 343144304640, \"percentFree\": \"68.63%\", \"total\": \"465.63 GB\", \"totalBytes\": 499963174912 } }, { \"name\": \"heapMemory\", \"state\": \"UP\", \"status\": \"UP\", \"data\": { \"free\": \"196.84 MB\", \"freeBytes\": 206404016, \"max\": \"3.56 GB\", \"maxBytes\": 3817865216, \"percentFree\": \"98.66%\", \"total\": \"245.50 MB\", \"totalBytes\": 257425408 } } ] } In MicroProfile Health 2.0 outcome and state were replaced by status in the JSON response wire format. Helidon currently provides both fields for backwards compatibility, but use of outcome and state is deprecated and will be removed in a future release. You should rely on status instead. ",
            "title": "Using the Built-In Health Checks"
        },
        {
            "location": "/se/guides/04_health",
            "text": " You can create application specific custom health checks and integrate them with Helidon using the HealthSupport class, which is a WebServer service that contains a collection of registered HealthCheck instances. When queried, it invokes the registered health check and returns a response with a status code representing the overall state of the application. <markup lang=\"xml\" title=\"Notice the custom health-checks dependency is already in the project&#8217;s pom.xml file:\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.health&lt;/groupId&gt; &lt;artifactId&gt;helidon-health&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"java\" title=\"Replace the HealthSupport builder in the Main.createRouting method:\" >HealthSupport health = HealthSupport.builder() .addLiveness(() -&gt; HealthCheckResponse.named(\"LivenessCheck\") .up() .withData(\"time\", System.currentTimeMillis()) .build()) .build(); Add a custom liveness health check. This example returns UP and current time. <markup lang=\"bash\" title=\"Build and run the application, then verify the custom health endpoint:\" >curl http://localhost:8080/health <markup lang=\"json\" title=\"JSON response:\" >{ \"outcome\": \"UP\", \"checks\": [ { \"name\": \"LivenessCheck\", \"state\": \"UP\", \"data\": { \"time\": 1546958376613 } } ] } ",
            "title": "Custom Liveness Health Checks"
        },
        {
            "location": "/se/guides/04_health",
            "text": " You can add a readiness check to indicate that the application is ready to be used. In this example, the server will wait five seconds before it becomes ready. <markup lang=\"java\" title=\"Add a readyTime variable to the Main class, then set it five seconds after the application starts:\" >import java.util.concurrent.atomic.AtomicLong; public final class Main { private static AtomicLong readyTime = new AtomicLong(0); ... static WebServer startServer() throws IOException { ... server.start() ... // Server threads are not daemon. No need to block. Just react. try { Thread.sleep(5000); } catch (InterruptedException e) { throw new RuntimeException(e); } readyTime.set(System.currentTimeMillis()); return server; Import AtomicLong. Declare the readyTime variable. Sleep five seconds. Set the readyTime to the time when the server became ready. <markup lang=\"java\" title=\"Add a readiness check to the HealhSupport builder in the Main.createRouting method:\" >HealthSupport health = HealthSupport.builder() .addLiveness(() -&gt; HealthCheckResponse.named(\"LivenessCheck\") .up() .withData(\"time\", System.currentTimeMillis()) .build()) .addReadiness(() -&gt; HealthCheckResponse.named(\"ReadinessCheck\") .state (readyTime.get() != 0 ) .withData( \"time\", readyTime.get()) .build()) .build(); Add the readiness check. <markup lang=\"bash\" title=\"Build and run the application. Issue the curl command with -v within five seconds and you see the application is not ready:\" >curl -v http://localhost:8080/health/ready <markup lang=\"json\" title=\"HTTP response:\" >... &lt; HTTP/1.1 503 Service Unavailable ... { \"outcome\": \"DOWN\", \"status\": \"DOWN\", \"checks\": [ { \"name\": \"ReadinessCheck\", \"state\": \"DOWN\", \"status\": \"DOWN\", \"data\": { \"time,\": 0 } } ] } The HTTP status is 503 since the application is not ready. <markup lang=\"bash\" title=\"After five seconds you will see the application is ready:\" >curl -v http://localhost:8080/health/ready <markup lang=\"json\" title=\"JSON response:\" >... &lt; HTTP/1.1 200 OK ... { \"outcome\": \"UP\", \"status\": \"UP\", \"checks\": [ { \"name\": \"ReadinessCheck\", \"state\": \"UP\", \"status\": \"UP\", \"data\": { \"time,\": 1566243562097 } } ] } The HTTP status is 200 indicating that the application is ready. When using the health-check URLs, you can get the following health-check data liveness only - http://localhost:8080/health/live readiness only - http://localhost:8080/health/ready both - http://localhost:8080/health <markup lang=\"bash\" title=\"Get both liveness and readiness data from a single query:\" >curl http://localhost:8080/health <markup lang=\"json\" title=\"JSON response:\" >{ \"outcome\": \"UP\", \"status\": \"UP\", \"checks\": [ { \"name\": \"LivenessCheck\", \"state\": \"UP\", \"status\": \"UP\", \"data\": { \"time\": 1566244094548 } }, { \"name\": \"ReadinessCheck\", \"state\": \"UP\", \"status\": \"UP\", \"data\": { \"time,\": 1566244093012 } } ] } ",
            "title": "Custom Readiness Health Check"
        },
        {
            "location": "/se/guides/04_health",
            "text": " You can combine built-in and custom health-checks using the same HealthSupport builder. <markup lang=\"java\" title=\"Register a custom health-check in the Main.createRouting method:\" >HealthSupport health = HealthSupport.builder() .addLiveness(HealthChecks.healthChecks()) .addLiveness(() -&gt; HealthCheckResponse.named(\"LivenessCheck\") .up() .withData(\"time\", System.currentTimeMillis()) .build()) .addReadiness(() -&gt; HealthCheckResponse.named(\"ReadinessCheck\") .state (readyTime.get() != 0 ) .withData( \"time\", readyTime.get()) .build()) .build(); Add the built-in health-checks back to HealthSupport builder. <markup lang=\"bash\" title=\"Build and run the application, then verify the health endpoint. You will see both the built-in and custom health-check data:\" >curl http://localhost:8080/health <markup lang=\"json\" title=\"JSON response:\" >{ \"outcome\": \"UP\", \"status\": \"UP\", \"checks\": [ { \"name\": \"LivenessCheck\", \"state\": \"UP\", \"status\": \"UP\", \"data\": { \"time\": 1566245527673 } }, { \"name\": \"ReadinessCheck\", \"state\": \"UP\", \"status\": \"UP\", \"data\": { \"time,\": 1566245527620 } }, { \"name\": \"deadlock\", \"state\": \"UP\", \"status\": \"UP\" }, { \"name\": \"diskSpace\", \"state\": \"UP\", \"status\": \"UP\", \"data\": { \"free\": \"326.17 GB\", \"freeBytes\": 350224424960, \"percentFree\": \"70.05%\", \"total\": \"465.63 GB\", \"totalBytes\": 499963174912 } }, { \"name\": \"heapMemory\", \"state\": \"UP\", \"status\": \"UP\", \"data\": { \"free\": \"247.76 MB\", \"freeBytes\": 259791680, \"max\": \"4.00 GB\", \"maxBytes\": 4294967296, \"percentFree\": \"99.80%\", \"total\": \"256.00 MB\", \"totalBytes\": 268435456 } } ] } ",
            "title": "Combine Built-In and Custom Health Checks"
        },
        {
            "location": "/se/guides/04_health",
            "text": " You can use a custom URL path for heath checks by setting the WebContext . In the following example, only the liveness URL is changed, but you can do the same for the readiness and default health-checks. <markup lang=\"java\" title=\"Register a custom URL path with the custom health-check in the Main.createRouting method:\" >HealthSupport health = HealthSupport.builder() .webContext(\"/probe/live\") .addLiveness(() -&gt; HealthCheckResponse.named(\"livenessProbe\") .up() .withData(\"time\", System.currentTimeMillis()) .build()) .build(); Change the liveness URL path using a WebContext . <markup lang=\"bash\" title=\"Build and run the application, then verify that the liveness endpoint is using the /probe/live :\" >curl http://localhost:8080/probe/live <markup lang=\"json\" title=\"JSON response:\" >{ \"outcome\": \"UP\", \"checks\": [ { \"name\": \"livenessProbe\", \"state\": \"UP\", \"data\": { \"time\": 1546958376613 } } ] } ",
            "title": "Custom Health Check URL Path"
        },
        {
            "location": "/se/guides/04_health",
            "text": " The following example shows how to integrate the Helidon health API in an application that implements health endpoints for the Kubernetes liveness and readiness probes. <markup lang=\"java\" title=\"Change the HealthSupport builder in the Main.createRouting method to use the built-in liveness checks, a custom liveness check, and a readiness check:\" >HealthSupport health = HealthSupport.builder() .addLiveness(HealthChecks.healthChecks()) .addLiveness(() -&gt; HealthCheckResponse.named(\"LivenessCheck\") .up() .withData(\"time\", System.currentTimeMillis()) .build()) .addReadiness(() -&gt; HealthCheckResponse.named(\"ReadinessCheck\") .state (readyTime.get() != 0 ) .withData( \"time\", readyTime.get()) .build()) .build(); Add built-in health-checks. Add a custom liveness check. Add a custom readiness check. <markup lang=\"bash\" title=\"Build and run the application, then verify the liveness and readiness endpoints:\" >curl http://localhost:8080/health/live curl http://localhost:8080/health/ready <markup lang=\"bash\" title=\"Stop the application and build the docker image:\" >docker build -t helidon-quickstart-se . <markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named health.yaml , with the following content:\" >kind: Service apiVersion: v1 metadata: name: helidon-health labels: app: helidon-health spec: type: NodePort selector: app: helidon-health ports: - port: 8080 targetPort: 8080 name: http --- kind: Deployment apiVersion: apps/v1 metadata: name: helidon-health spec: replicas: 1 selector: matchLabels: app: helidon-health template: metadata: labels: app: helidon-health version: v1 spec: containers: - name: helidon-health image: helidon-quickstart-se imagePullPolicy: IfNotPresent ports: - containerPort: 8080 livenessProbe: httpGet: path: /health/live port: 8080 initialDelaySeconds: 5 periodSeconds: 10 timeoutSeconds: 3 failureThreshold: 3 readinessProbe: httpGet: path: /health/ready port: 8080 initialDelaySeconds: 5 periodSeconds: 2 timeoutSeconds: 3 --- A service of type NodePort that serves the default routes on port 8080 . A deployment with one replica of a pod. The HTTP endpoint for the liveness probe. The liveness probe configuration. The HTTP endpoint for the readiness probe. The readiness probe configuration. <markup lang=\"bash\" title=\"Create and deploy the application into Kubernetes:\" >kubectl apply -f ./health.yaml <markup lang=\"bash\" title=\"Get the service information:\" >kubectl get service/helidon-health <markup lang=\"bash\" >NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE helidon-health NodePort 10.107.226.62 &lt;none&gt; 8080:30116/TCP 4s A service of type NodePort that serves the default routes on port 30116 . <markup lang=\"bash\" title=\"Verify the health endpoints using port '30116', your port may be different:\" >curl http://localhost:30116/health <markup lang=\"bash\" title=\"Delete the application, cleaning up Kubernetes resources:\" >kubectl delete -f ./health.yaml ",
            "title": "Using Liveness and Readiness Health Checks with Kubernetes"
        },
        {
            "location": "/se/guides/04_health",
            "text": " This guide demonstrated how to use health checks in a Helidon SE application as follows: Access the default health-check Create and use custom readiness and liveness checks Customize the health-check root path Integrate Helidon health-check with Kubernetes Refer to the following reference for additional information: Helidon Javadoc at https://helidon.io/docs/latest/apidocs/index.html?overview-summary.html ",
            "title": "Summary"
        },
        {
            "location": "/se/guides/04_health",
            "text": " For this 15 minute tutorial, you will need the following: <div class=\"table__overflow elevation-1 flex sm7 \"> A Helidon {upper-case-flavor} Application You can use your own application or use the Helidon {upper-case-flavor} Quickstart to create a sample application. Java&#160;SE&#160;11 ( Open&#160;JDK&#160;11 ) Helidon requires Java 11+. Maven 3.6.1+ Helidon requires Maven 3.6.1+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop ). <markup lang=\"bash\" title=\"Verify Prerequisites\" >java -version mvn --version docker --version kubectl version --short <markup lang=\"bash\" title=\"Setting JAVA_HOME\" ># On Mac export JAVA_HOME=`/usr/libexec/java_home -v 11` # On Linux # Use the appropriate path to your JDK export JAVA_HOME=/usr/lib/jvm/jdk-11 Create a Sample SE Project Generate the project sources using the Helidon SE Maven archetype. The result is a simple project that can be used for the examples in this guide. <markup lang=\"bash\" title=\"Run the Maven archetype:\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-se \\ -DarchetypeVersion=2.5.4 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-se \\ -Dpackage=io.helidon.examples.quickstart.se Using the Built-In Health Checks Helidon has a set of built-in health checks that can be optionally enabled to report various health-check statuses that are commonly used: deadlock detection available disk space available heap memory The following example will demonstrate how to use the built-in health-checks. These examples are all executed from the root directory of your project (helidon-quickstart-se). <markup lang=\"xml\" title=\"Notice that the built-in health-check dependency is already in the project&#8217;s pom.xml file:\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.health&lt;/groupId&gt; &lt;artifactId&gt;helidon-health-checks&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"java\" title=\"Have a look at Main.java , and the createRouting method:\" >private static Routing createRouting(Config config) { HealthSupport health = HealthSupport.builder() .addLiveness(HealthChecks.healthChecks()) .build(); return Routing.builder() .register(health) .build(); } Add built-in health-checks (requires the helidon-health-checks dependency). Register the created health support with web server routing (adds the /health endpoint). <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-se.jar <markup lang=\"bash\" title=\"Verify the health endpoint in a new terminal window:\" >curl http://localhost:8080/health <markup lang=\"json\" title=\"JSON response:\" >{ \"outcome\": \"UP\", \"status\": \"UP\", \"checks\": [ { \"name\": \"deadlock\", \"state\": \"UP\", \"status\": \"UP\" }, { \"name\": \"diskSpace\", \"state\": \"UP\", \"status\": \"UP\", \"data\": { \"free\": \"319.58 GB\", \"freeBytes\": 343144304640, \"percentFree\": \"68.63%\", \"total\": \"465.63 GB\", \"totalBytes\": 499963174912 } }, { \"name\": \"heapMemory\", \"state\": \"UP\", \"status\": \"UP\", \"data\": { \"free\": \"196.84 MB\", \"freeBytes\": 206404016, \"max\": \"3.56 GB\", \"maxBytes\": 3817865216, \"percentFree\": \"98.66%\", \"total\": \"245.50 MB\", \"totalBytes\": 257425408 } } ] } In MicroProfile Health 2.0 outcome and state were replaced by status in the JSON response wire format. Helidon currently provides both fields for backwards compatibility, but use of outcome and state is deprecated and will be removed in a future release. You should rely on status instead. Custom Liveness Health Checks You can create application specific custom health checks and integrate them with Helidon using the HealthSupport class, which is a WebServer service that contains a collection of registered HealthCheck instances. When queried, it invokes the registered health check and returns a response with a status code representing the overall state of the application. <markup lang=\"xml\" title=\"Notice the custom health-checks dependency is already in the project&#8217;s pom.xml file:\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.health&lt;/groupId&gt; &lt;artifactId&gt;helidon-health&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"java\" title=\"Replace the HealthSupport builder in the Main.createRouting method:\" >HealthSupport health = HealthSupport.builder() .addLiveness(() -&gt; HealthCheckResponse.named(\"LivenessCheck\") .up() .withData(\"time\", System.currentTimeMillis()) .build()) .build(); Add a custom liveness health check. This example returns UP and current time. <markup lang=\"bash\" title=\"Build and run the application, then verify the custom health endpoint:\" >curl http://localhost:8080/health <markup lang=\"json\" title=\"JSON response:\" >{ \"outcome\": \"UP\", \"checks\": [ { \"name\": \"LivenessCheck\", \"state\": \"UP\", \"data\": { \"time\": 1546958376613 } } ] } Custom Readiness Health Check You can add a readiness check to indicate that the application is ready to be used. In this example, the server will wait five seconds before it becomes ready. <markup lang=\"java\" title=\"Add a readyTime variable to the Main class, then set it five seconds after the application starts:\" >import java.util.concurrent.atomic.AtomicLong; public final class Main { private static AtomicLong readyTime = new AtomicLong(0); ... static WebServer startServer() throws IOException { ... server.start() ... // Server threads are not daemon. No need to block. Just react. try { Thread.sleep(5000); } catch (InterruptedException e) { throw new RuntimeException(e); } readyTime.set(System.currentTimeMillis()); return server; Import AtomicLong. Declare the readyTime variable. Sleep five seconds. Set the readyTime to the time when the server became ready. <markup lang=\"java\" title=\"Add a readiness check to the HealhSupport builder in the Main.createRouting method:\" >HealthSupport health = HealthSupport.builder() .addLiveness(() -&gt; HealthCheckResponse.named(\"LivenessCheck\") .up() .withData(\"time\", System.currentTimeMillis()) .build()) .addReadiness(() -&gt; HealthCheckResponse.named(\"ReadinessCheck\") .state (readyTime.get() != 0 ) .withData( \"time\", readyTime.get()) .build()) .build(); Add the readiness check. <markup lang=\"bash\" title=\"Build and run the application. Issue the curl command with -v within five seconds and you see the application is not ready:\" >curl -v http://localhost:8080/health/ready <markup lang=\"json\" title=\"HTTP response:\" >... &lt; HTTP/1.1 503 Service Unavailable ... { \"outcome\": \"DOWN\", \"status\": \"DOWN\", \"checks\": [ { \"name\": \"ReadinessCheck\", \"state\": \"DOWN\", \"status\": \"DOWN\", \"data\": { \"time,\": 0 } } ] } The HTTP status is 503 since the application is not ready. <markup lang=\"bash\" title=\"After five seconds you will see the application is ready:\" >curl -v http://localhost:8080/health/ready <markup lang=\"json\" title=\"JSON response:\" >... &lt; HTTP/1.1 200 OK ... { \"outcome\": \"UP\", \"status\": \"UP\", \"checks\": [ { \"name\": \"ReadinessCheck\", \"state\": \"UP\", \"status\": \"UP\", \"data\": { \"time,\": 1566243562097 } } ] } The HTTP status is 200 indicating that the application is ready. When using the health-check URLs, you can get the following health-check data liveness only - http://localhost:8080/health/live readiness only - http://localhost:8080/health/ready both - http://localhost:8080/health <markup lang=\"bash\" title=\"Get both liveness and readiness data from a single query:\" >curl http://localhost:8080/health <markup lang=\"json\" title=\"JSON response:\" >{ \"outcome\": \"UP\", \"status\": \"UP\", \"checks\": [ { \"name\": \"LivenessCheck\", \"state\": \"UP\", \"status\": \"UP\", \"data\": { \"time\": 1566244094548 } }, { \"name\": \"ReadinessCheck\", \"state\": \"UP\", \"status\": \"UP\", \"data\": { \"time,\": 1566244093012 } } ] } Combine Built-In and Custom Health Checks You can combine built-in and custom health-checks using the same HealthSupport builder. <markup lang=\"java\" title=\"Register a custom health-check in the Main.createRouting method:\" >HealthSupport health = HealthSupport.builder() .addLiveness(HealthChecks.healthChecks()) .addLiveness(() -&gt; HealthCheckResponse.named(\"LivenessCheck\") .up() .withData(\"time\", System.currentTimeMillis()) .build()) .addReadiness(() -&gt; HealthCheckResponse.named(\"ReadinessCheck\") .state (readyTime.get() != 0 ) .withData( \"time\", readyTime.get()) .build()) .build(); Add the built-in health-checks back to HealthSupport builder. <markup lang=\"bash\" title=\"Build and run the application, then verify the health endpoint. You will see both the built-in and custom health-check data:\" >curl http://localhost:8080/health <markup lang=\"json\" title=\"JSON response:\" >{ \"outcome\": \"UP\", \"status\": \"UP\", \"checks\": [ { \"name\": \"LivenessCheck\", \"state\": \"UP\", \"status\": \"UP\", \"data\": { \"time\": 1566245527673 } }, { \"name\": \"ReadinessCheck\", \"state\": \"UP\", \"status\": \"UP\", \"data\": { \"time,\": 1566245527620 } }, { \"name\": \"deadlock\", \"state\": \"UP\", \"status\": \"UP\" }, { \"name\": \"diskSpace\", \"state\": \"UP\", \"status\": \"UP\", \"data\": { \"free\": \"326.17 GB\", \"freeBytes\": 350224424960, \"percentFree\": \"70.05%\", \"total\": \"465.63 GB\", \"totalBytes\": 499963174912 } }, { \"name\": \"heapMemory\", \"state\": \"UP\", \"status\": \"UP\", \"data\": { \"free\": \"247.76 MB\", \"freeBytes\": 259791680, \"max\": \"4.00 GB\", \"maxBytes\": 4294967296, \"percentFree\": \"99.80%\", \"total\": \"256.00 MB\", \"totalBytes\": 268435456 } } ] } Custom Health Check URL Path You can use a custom URL path for heath checks by setting the WebContext . In the following example, only the liveness URL is changed, but you can do the same for the readiness and default health-checks. <markup lang=\"java\" title=\"Register a custom URL path with the custom health-check in the Main.createRouting method:\" >HealthSupport health = HealthSupport.builder() .webContext(\"/probe/live\") .addLiveness(() -&gt; HealthCheckResponse.named(\"livenessProbe\") .up() .withData(\"time\", System.currentTimeMillis()) .build()) .build(); Change the liveness URL path using a WebContext . <markup lang=\"bash\" title=\"Build and run the application, then verify that the liveness endpoint is using the /probe/live :\" >curl http://localhost:8080/probe/live <markup lang=\"json\" title=\"JSON response:\" >{ \"outcome\": \"UP\", \"checks\": [ { \"name\": \"livenessProbe\", \"state\": \"UP\", \"data\": { \"time\": 1546958376613 } } ] } Using Liveness and Readiness Health Checks with Kubernetes The following example shows how to integrate the Helidon health API in an application that implements health endpoints for the Kubernetes liveness and readiness probes. <markup lang=\"java\" title=\"Change the HealthSupport builder in the Main.createRouting method to use the built-in liveness checks, a custom liveness check, and a readiness check:\" >HealthSupport health = HealthSupport.builder() .addLiveness(HealthChecks.healthChecks()) .addLiveness(() -&gt; HealthCheckResponse.named(\"LivenessCheck\") .up() .withData(\"time\", System.currentTimeMillis()) .build()) .addReadiness(() -&gt; HealthCheckResponse.named(\"ReadinessCheck\") .state (readyTime.get() != 0 ) .withData( \"time\", readyTime.get()) .build()) .build(); Add built-in health-checks. Add a custom liveness check. Add a custom readiness check. <markup lang=\"bash\" title=\"Build and run the application, then verify the liveness and readiness endpoints:\" >curl http://localhost:8080/health/live curl http://localhost:8080/health/ready <markup lang=\"bash\" title=\"Stop the application and build the docker image:\" >docker build -t helidon-quickstart-se . <markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named health.yaml , with the following content:\" >kind: Service apiVersion: v1 metadata: name: helidon-health labels: app: helidon-health spec: type: NodePort selector: app: helidon-health ports: - port: 8080 targetPort: 8080 name: http --- kind: Deployment apiVersion: apps/v1 metadata: name: helidon-health spec: replicas: 1 selector: matchLabels: app: helidon-health template: metadata: labels: app: helidon-health version: v1 spec: containers: - name: helidon-health image: helidon-quickstart-se imagePullPolicy: IfNotPresent ports: - containerPort: 8080 livenessProbe: httpGet: path: /health/live port: 8080 initialDelaySeconds: 5 periodSeconds: 10 timeoutSeconds: 3 failureThreshold: 3 readinessProbe: httpGet: path: /health/ready port: 8080 initialDelaySeconds: 5 periodSeconds: 2 timeoutSeconds: 3 --- A service of type NodePort that serves the default routes on port 8080 . A deployment with one replica of a pod. The HTTP endpoint for the liveness probe. The liveness probe configuration. The HTTP endpoint for the readiness probe. The readiness probe configuration. <markup lang=\"bash\" title=\"Create and deploy the application into Kubernetes:\" >kubectl apply -f ./health.yaml <markup lang=\"bash\" title=\"Get the service information:\" >kubectl get service/helidon-health <markup lang=\"bash\" >NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE helidon-health NodePort 10.107.226.62 &lt;none&gt; 8080:30116/TCP 4s A service of type NodePort that serves the default routes on port 30116 . <markup lang=\"bash\" title=\"Verify the health endpoints using port '30116', your port may be different:\" >curl http://localhost:30116/health <markup lang=\"bash\" title=\"Delete the application, cleaning up Kubernetes resources:\" >kubectl delete -f ./health.yaml Summary This guide demonstrated how to use health checks in a Helidon SE application as follows: Access the default health-check Create and use custom readiness and liveness checks Customize the health-check root path Integrate Helidon health-check with Kubernetes Refer to the following reference for additional information: Helidon Javadoc at https://helidon.io/docs/latest/apidocs/index.html?overview-summary.html ",
            "title": "What You Need"
        },
        {
            "location": "/se/grpc/02_configuration",
            "text": " Configure the gRPC Server using the Helidon configuration framework, either programmatically or via a configuration file. ",
            "title": "preambule"
        },
        {
            "location": "/se/grpc/02_configuration",
            "text": " The easiest way to configure the gRPC Server is in your application code. <markup lang=\"java\" >GrpcServerConfiguration configuration = GrpcServerConfiguration.builder() .port(8080) .build(); GrpcServer grpcServer = GrpcServer.create(configuration, routing); ",
            "title": "Configuring the gRPC Server in your code"
        },
        {
            "location": "/se/grpc/02_configuration",
            "text": " You can also define the configuration in a file. <markup lang=\"hocon\" title=\"GrpcServer configuration file application.yaml \" >grpcserver: port: 3333 Then, in your application code, load the configuration from that file. <markup lang=\"java\" title=\"GrpcServer initialization using the application.conf file located on the classpath\" >GrpcServerConfiguration configuration = GrpcServerConfiguration.create( Config.builder() .sources(classpath(\"application.conf\")) .build()); GrpcServer grpcServer = GrpcServer.create(configuration, routing); ",
            "title": "Configuring the gRPC Server in a configuration file"
        },
        {
            "location": "/se/grpc/02_configuration",
            "text": " See all configuration options here . ",
            "title": "Configuration options"
        },
        {
            "location": "/se/security/01_introduction",
            "text": " Helidon Security provides authentication, authroization and auditing for your Helidon application. ",
            "title": "preambule"
        },
        {
            "location": "/se/security/01_introduction",
            "text": " To enable Security add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security&lt;/groupId&gt; &lt;artifactId&gt;helidon-security&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/security/01_introduction",
            "text": " Helidon Security provides the following features Authentication - support for authenticating incoming requests, creating a security Subject with Principal and Grants. Principal represents current user/service. Grant may represent a Role, Scope etc. Responsibility to create Principals and Grants lies with with AuthenticationProvider SPI. The following Principals are expected and supported out of the box: UserPrincipal - the party is an end-user (e.g. a person) - there can be zero to one user principals in a subject ServicePrincipal - the party is a service (e.g. a computer program) - there can be zero to one service principals in a subject Authorization - support for authorizing incoming requests. Out-of-the-box the security module supports ABAC and RBAC (Attribute based access control and Role based access control). RBAC is handled through RolesAllowed annotation (for integrations that support injection). Outbound security - support for propagating identity or (in general) securing outbound requests. Modification of a request to include outbound security is responsibility of OutboundSecurityProvider SPI Audit - security module audits most important events through its own API (e.g. Authentication events, Authorization events, outbound security events). A default AuditProvider is provided as well, logging to Java util logging (JUL) logger called \"AUDIT\" (may be overridden through configuration). AuditProvider SPI may be implemented to support other auditing options. Security module is quite HTTP centric (as most common use cases are related to HTTP REST), though it is not HTTP specific (the security module may be used to secure even other transports, such as JMS, Kafka messages etc. if an appropriate integration module is developed, as all APIs can be mapped to a non-HTTP protocol). Nevertheless there may be security providers that only make sense with HTTP (such as HTTP digest authentication). ",
            "title": "Overview"
        },
        {
            "location": "/se/security/01_introduction",
            "text": "<markup lang=\"java\" title=\"Security through a builder\" >Security security = Security.builder() // create a provider instance based on the provider documentation .addProvider(...) .build(); ",
            "title": "Builder pattern"
        },
        {
            "location": "/se/security/01_introduction",
            "text": " When a configuration needs to be overridden, we may have problems with the list type of the providers configuration. To simplify overrides using properties, you can explicitly setup a type of provider using a type key. Example: <markup lang=\"properties\" >security.providers.1.type=header-atn security.providers.1.header-atn.authenticate=false Would explicitly override the second provider ( http-basic-auth in example above) with header-atn provider. Note that the type and the key of the provider must match. ",
            "title": "Overriding configuration"
        },
        {
            "location": "/se/security/01_introduction",
            "text": " See Secure config for details about encrypting passwords in configuration files. <markup lang=\"java\" title=\"Security from configuration\" >// uses io.helidon.Config Security security = Security.create(config); <markup lang=\"yaml\" title=\"Security from configuration - application.yaml\" ># Uses config encryption filter to encrypt passwords security: providers: - abac: - http-basic-auth: realm: \"helidon\" users: - login: \"jack\" password: \"${CLEAR=password}\" roles: [\"user\", \"admin\"] - login: \"jill\" password: \"${CLEAR=password}\" roles: [\"user\"] Overriding configuration When a configuration needs to be overridden, we may have problems with the list type of the providers configuration. To simplify overrides using properties, you can explicitly setup a type of provider using a type key. Example: <markup lang=\"properties\" >security.providers.1.type=header-atn security.providers.1.header-atn.authenticate=false Would explicitly override the second provider ( http-basic-auth in example above) with header-atn provider. Note that the type and the key of the provider must match. ",
            "title": "Configuration pattern"
        },
        {
            "location": "/se/security/01_introduction",
            "text": "<markup lang=\"java\" title=\"Security from configuration and builder\" >// uses io.helidon.Config Security security = Security.builder(config) .addProvider(...) .build(); // or reverse order: Security security = Security.builder() .addProvider() .config(config) .build(); ",
            "title": "Hybrid pattern (Builder &amp; Configuration)"
        },
        {
            "location": "/se/security/01_introduction",
            "text": " To integrate with a container, or to use Security standalone, we must create an instance of security. In general, Security supports three approaches a fluent-API builder pattern - you configure everything \"by hand\" a configuration based pattern - you configure everything in a configuration file hybrid - you load a builder from configuration and update it in a program Once a security instance is built, it can be used to initialize an integration with a container , or to use security from a program directly: <markup lang=\"java\" title=\"Security direct usage\" >// create a security context SecurityContext context = security.contextBuilder(UUID.randomUUID().toString()) .env(SecurityEnvironment.builder() .method(\"get\") .path(\"/test\") .transport(\"http\") .header(\"Authorization\", \"Bearer abcdefgh\") .build()) .build(); // use the context to authenticate a request context.atnClientBuilder() .submit() .whenComplete((response, exception) -&gt; { // this is to show the features, not a real-world production code... if (null == exception) { if (response.getStatus().isSuccess()) { System.out.println(response.getUser()); System.out.println(response.getService()); } else { System.out.println(\"Authentication failed: \" + response.getDescription()); } } else { exception.printStackTrace(); } }); Builder pattern <markup lang=\"java\" title=\"Security through a builder\" >Security security = Security.builder() // create a provider instance based on the provider documentation .addProvider(...) .build(); Configuration pattern See Secure config for details about encrypting passwords in configuration files. <markup lang=\"java\" title=\"Security from configuration\" >// uses io.helidon.Config Security security = Security.create(config); <markup lang=\"yaml\" title=\"Security from configuration - application.yaml\" ># Uses config encryption filter to encrypt passwords security: providers: - abac: - http-basic-auth: realm: \"helidon\" users: - login: \"jack\" password: \"${CLEAR=password}\" roles: [\"user\", \"admin\"] - login: \"jill\" password: \"${CLEAR=password}\" roles: [\"user\"] Overriding configuration When a configuration needs to be overridden, we may have problems with the list type of the providers configuration. To simplify overrides using properties, you can explicitly setup a type of provider using a type key. Example: <markup lang=\"properties\" >security.providers.1.type=header-atn security.providers.1.header-atn.authenticate=false Would explicitly override the second provider ( http-basic-auth in example above) with header-atn provider. Note that the type and the key of the provider must match. Hybrid pattern (Builder &amp; Configuration) <markup lang=\"java\" title=\"Security from configuration and builder\" >// uses io.helidon.Config Security security = Security.builder(config) .addProvider(...) .build(); // or reverse order: Security security = Security.builder() .addProvider() .config(config) .build(); ",
            "title": "How to use"
        },
        {
            "location": "/se/guides/05_metrics",
            "text": " This guide describes how to create a sample Helidon SE project that can be used to run some basic examples using both built-in and custom metrics with Helidon. ",
            "title": "preambule"
        },
        {
            "location": "/se/guides/05_metrics",
            "text": " Use the Helidon SE Maven archetype to create a simple project that can be used for the examples in this guide. <markup lang=\"bash\" title=\"Run the Maven archetype\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-se \\ -DarchetypeVersion=2.5.4 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-se \\ -Dpackage=io.helidon.examples.quickstart.se ",
            "title": "Create a Sample Helidon SE Project"
        },
        {
            "location": "/se/guides/05_metrics",
            "text": " Helidon provides three scopes of metrics: base, vendor, and application. Here are the metric endpoints: /metrics/base - Base metrics data as specified by the MicroProfile Metrics specification. /metrics/vendor - Helidon-specific metrics data. /metrics/application - Application-specific metrics data. The /metrics endpoint will return data for all scopes. The built-in metrics fall into three categories: JVM behavior (in the base registry), basic key performance indicators for request handling (in the vendor registry), and thread pool utilization (also in the vendor registry). A later section describes the key performance indicator metrics in detail. The following example demonstrates how to use the other built-in metrics. All examples are executed from the root directory of your project (helidon-quickstart-se). The generated source code is already configured for both metrics and health checks, but the following example removes health checks. <markup lang=\"xml\" title=\"Notice that the metrics dependency is already in the project&#8217;s pom.xml file:\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"java\" title=\"Replace the Main.createRouting method with the following code:\" > private static Routing createRouting(Config config) { GreetService greetService = new GreetService(config); return Routing.builder() .register(MetricsSupport.create()) .register(\"/greet\", greetService) .build(); } Register the built-in base and vendor metrics. <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-se.jar Metrics can be returned in either text format (the default), or JSON. The text format uses OpenMetrics (Prometheus) Text Format, see https://prometheus.io/docs/instrumenting/exposition_formats/#text-format-details . <markup lang=\"bash\" title=\"Verify the metrics endpoint in a new terminal window:\" >curl http://localhost:8080/metrics <markup lang=\"text\" title=\"Text response:\" ># TYPE base:classloader_current_loaded_class_count counter # HELP base:classloader_current_loaded_class_count Displays the number of classes that are currently loaded in the Java virtual machine. base:classloader_current_loaded_class_count 7511 # TYPE base:classloader_total_loaded_class_count counter # HELP base:classloader_total_loaded_class_count Displays the total number of classes that have been loaded since the Java virtual machine has started execution. base:classloader_total_loaded_class_count 7512 ... You can get the same data in JSON format. <markup lang=\"bash\" title=\"Verify the metrics endpoint with an HTTP accept header:\" >curl -H \"Accept: application/json\" http://localhost:8080/metrics <markup lang=\"json\" title=\"JSON response:\" >{ \"base\": { \"classloader.currentLoadedClass.count\": 7534, \"classloader.totalLoadedClass.count\": 7538, \"classloader.totalUnloadedClass.count\": 1, \"cpu.availableProcessors\": 4, \"cpu.systemLoadAverage\": 2.83349609375, \"gc.PS MarkSweep.count\": 2, \"gc.PS MarkSweep.time\": 77, \"gc.PS Scavenge.count\": 5, \"gc.PS Scavenge.time\": 37, \"jvm.uptime\": 727588, \"memory.committedHeap\": 284164096, \"memory.maxHeap\": 3817865216, \"memory.usedHeap\": 53283088, \"thread.count\": 44, \"thread.daemon.count\": 35, \"thread.max.count\": 44 }, \"vendor\": { \"executor-service.active-count;poolIndex=0;supplierCategory=helidon-thread-pool-2;supplierIndex=0\": 0, \"executor-service.completed-task-count;poolIndex=0;supplierCategory=helidon-thread-pool-2;supplierIndex=0\": 0, \"executor-service.largest-pool-size;poolIndex=0;supplierCategory=helidon-thread-pool-2;supplierIndex=0\": 5, \"executor-service.pool-size;poolIndex=0;supplierCategory=helidon-thread-pool-2;supplierIndex=0\": 5, \"executor-service.queue.remaining-capacity;poolIndex=0;supplierCategory=helidon-thread-pool-2;supplierIndex=0\": 10000, \"executor-service.queue.size;poolIndex=0;supplierCategory=helidon-thread-pool-2;supplierIndex=0\": 0, \"executor-service.task-count;poolIndex=0;supplierCategory=helidon-thread-pool-2;supplierIndex=0\": 0, \"requests.count\": 6, \"requests.meter\": { \"count\": 6, \"meanRate\": 0.008275992296704147, \"oneMinRate\": 0.01576418632772332, \"fiveMinRate\": 0.006695060022357365, \"fifteenMinRate\": 0.0036382699664488415 } } } You can get a single metric by specifying the name in the URL path. <markup lang=\"bash\" title=\"Get the Helidon requests.meter metric:\" >curl -H \"Accept: application/json\" http://localhost:8080/metrics/vendor/requests.meter <markup lang=\"json\" title=\"JSON response:\" >{ \"requests.meter\": { \"count\": 6, \"meanRate\": 0.008275992296704147, \"oneMinRate\": 0.01576418632772332, \"fiveMinRate\": 0.006695060022357365, \"fifteenMinRate\": 0.0036382699664488415 } } You cannot get the individual fields of a metric. For example, you cannot target http://localhost:8080/metrics/vendor/requests.meter.count . The base metrics illustrated above provide some insight into the behavior of the JVM in which the server runs. The vendor metrics shown above appear in two groups: Helidon thread pools Helidon uses these thread pools for its own internal work, and your application can also use Helidon-managed thread pools if it needs to do work asynchronously. (See this example .) The metrics in this group show information about the thread pools which can help you assess how efficiently they are utilized. Helidon uses tags to distinguish the metrics which describe different thread pools. In some cases the specific metrics exposed depend on the particular type of thread pool. basic key performance indicators These metrics give an idea of the request traffic the server is handling. See the later section for more information on the basic and extended key performance indicator metrics. ",
            "title": "Using the Built-In Metrics"
        },
        {
            "location": "/se/guides/05_metrics",
            "text": " By default, if your application depends on the helidon-metrics Maven module then full-featured metrics are enabled. You can disable the metrics subsystem entirely using configuration: <markup lang=\"properties\" title=\"Configuration properties file disabling metrics\" >metrics.enabled=false A Helidon SE application can disable metrics processing programmatically. <markup lang=\"java\" title=\"Disable all metrics behavior\" >import io.helidon.metrics.api.MetricsSettings; import io.helidon.metrics.serviceapi.MetricsSupport; import io.helidon.metrics.api.RegistryFactory; ... MetricsSettings metricsSettings = MetricsSettings.builder() .enabled(false) .build(); MetricsSupport metricsSupport = MetricsSupport.create(metricsSettings); RegistryFactory registryFactory = RegistryFactory.getInstance(metricsSettings); Create a MetricsSettings instance (via its Builder ) with the metrics subsystem disabled. Get a MetricsSupport service (usable in setting routing rules) that responds to the /metrics endpoint with 404 and an explanatory message. Get a RegistryFactory instance that provides MetricRegistry instances which register no-op metric objects (counters, timers, etc.). These builders and interfaces also have methods which accept Config objects representing the metrics node from the application configuration. With metrics processing disabled, Helidon never updates any metrics and the /metrics endpoints respond with 404 plus a message that the metrics subsystem is disabled. ",
            "title": "Disabling Metrics Subsystem Entirely"
        },
        {
            "location": "/se/guides/05_metrics",
            "text": " Helidon contains several components and integrations which register and update metrics. Depending on how the component is written, you might be able to disable just that component&#8217;s use of metrics: <markup lang=\"properties\" title=\"Configuration properties file disabling a component&#8217;s use of metrics\" >some-component.metrics.enabled=false Check the documentation for a specific component to find out whether that component uses metrics and whether it allows you to disable that use. Your Helidon SE application can disable a metrics-capable component&#8217;s use of metrics programmatically. <markup lang=\"java\" title=\"Disable metrics use in a metrics-capable component\" >import io.helidon.metrics.api.ComponentMetricsSettings; ... ComponentMetricsSettings.Builder componentMetricsSettingsBuilder = ComponentMetricsSettings.builder() .enabled(false); SomeService someService = SomeService.builder() ... .componentMetricsSettings(componentMetricsSettingsBuilder) ... .build(); Create a ComponentMetricsSettings instance (via its Builder ) indicating that metrics usage should be disabled. Create an instance of the service with its metrics usage disabled. If you disable a component&#8217;s use of metrics, Helidon does not register the component&#8217;s metrics in the visible metrics registries nor do those metrics ever update their values. The response from the /metrics endpoint excludes that component&#8217;s metrics. Note that if you disable metrics processing entirely, no component updates its metrics regardless of any component-level metrics settings. ",
            "title": "Enabling and Disabling Metrics Usage by a Component"
        },
        {
            "location": "/se/guides/05_metrics",
            "text": " To disable all metrics in a given registry type (application, vendor, or base), add one or more groups to the configuration: <markup lang=\"properties\" title=\"Disabling base and vendor metrics (properties format)\" >metrics.registries.0.type = base metrics.registries.0.enabled = false metrics.registries.1.type = vendor metrics.registries.1.enabled = false <markup lang=\"yaml\" title=\"Disabling base and vendor metrics (YAML format)\" >metrics: registries: - type: base enabled: false - type: vendor enables: false ",
            "title": "Disabling All Metrics of a Given Registry Type"
        },
        {
            "location": "/se/guides/05_metrics",
            "text": " You can be even more selective. Within a registry type you can configure up to two regular expression patterns: one matching metric names to exclude , and one matching metric names to include . Helidon updates and reports a metric only if two conditions hold: the metric name does not match the exclude regex pattern (if you define one), and either there is no include regex pattern, or the metric name matches the include pattern. Caution Make sure any include regex pattern you specify matches all the metric names you want to capture. Suppose your application creates and updates a group of metrics with names such as myapp.xxx.queries , myapp.xxx.creates , myapp.xxx.updates , and myapp.xxx.deletes where xxx can be either supplier or customer . The following example gathers all metrics except those from your application regarding suppliers: <markup lang=\"properties\" title=\"Disabling metrics by name (properties format)\" >metrics.registries.0.type = application metrics.registries.0.filter.exclude = myapp\\.supplier\\..* The following settings select the particular subset of the metrics created in your application code representing updates of customers and suppliers: <markup lang=\"properties\" title=\"Enabling metrics by name (properties format)\" >metrics.registries.0.type = application metrics.registries.0.filter.include = myapp\\..*\\.updates If you use the YAML configuration format, enclose the regex patterns in single-quote marks: <markup lang=\"yaml\" title=\"Enabling metrics by name (YAML format)\" >metrics: registries: - type: application filter: include: 'myapp\\..*\\.updates' The next example selects only your application&#8217;s metrics while excluding those which refer to deletions: <markup lang=\"properties\" title=\"Combining include and exclude \" >metrics.registries.0.type = application metrics.registries.0.filter.include = myapp\\..* metrics.registries.0.filter.exclude = myapp\\..*/deletes Helidon would not update or report the metric myapp.supplier.queries , for example. To include metrics from your application for both updates and queries (but not for other operations), you could change the settings in the previous example to this: <markup >metrics.registries.0.type = application metrics.registries.0.filter.include = myapp\\..*\\.updates|myapp\\..*\\.queries metrics.registries.0.filter.exclude = myapp\\..*/deletes Your Helidon SE application can control the collection and reporting of metrics programmatically as well by preparing these settings objects: RegistryFilterSettings RegistrySettings MetricsSettings and using the resulting MetricsSettings to retrieve a suitable RegistryFactory . <markup lang=\"java\" title=\"Control metrics by registry type and name\" >import io.helidon.metrics.api.RegistryFilterSettings; import org.eclipse.microprofile.metrics.MetricRegistry; ... RegistryFilterSettings appFilterSettings = RegistryFilterSettings.builder() .include(\"myapp\\..*\\.updates\") .build(); RegistrySettings registrySettings = RegistrySettings.builder() .filterSettings(appFilterSettings) .build(); MetricsSettings metricsSettings = MetricsSettings.builder() .registrySettings(MetricRegistry.Type.APPLICATION, appFilterSettings) .build(); RegistryFactory rf = RegistryFactory.getInstance(metricsSettings); MetricRegistry registry = rf.getRegistry(MetricRegistry.Type.APPLICATION); Create the registry filter settings to include only those metrics with names indicating updates. Create the registry settings with that filter. Create the metrics settings, associating the registry settings with the APPLICATION metric registry. Set the overall metrics settings and retrieve a registry factory suitably initialized. Obtain a reference to the APPLICATION registry which is set up to create and report on only metrics with names starting with myapp.updates. . ",
            "title": "Controlling Metrics by Metric Name"
        },
        {
            "location": "/se/guides/05_metrics",
            "text": " You can control the collection and reporting of metrics by registry type and metric name within registry type. Disabling All Metrics of a Given Registry Type To disable all metrics in a given registry type (application, vendor, or base), add one or more groups to the configuration: <markup lang=\"properties\" title=\"Disabling base and vendor metrics (properties format)\" >metrics.registries.0.type = base metrics.registries.0.enabled = false metrics.registries.1.type = vendor metrics.registries.1.enabled = false <markup lang=\"yaml\" title=\"Disabling base and vendor metrics (YAML format)\" >metrics: registries: - type: base enabled: false - type: vendor enables: false Controlling Metrics by Metric Name You can be even more selective. Within a registry type you can configure up to two regular expression patterns: one matching metric names to exclude , and one matching metric names to include . Helidon updates and reports a metric only if two conditions hold: the metric name does not match the exclude regex pattern (if you define one), and either there is no include regex pattern, or the metric name matches the include pattern. Caution Make sure any include regex pattern you specify matches all the metric names you want to capture. Suppose your application creates and updates a group of metrics with names such as myapp.xxx.queries , myapp.xxx.creates , myapp.xxx.updates , and myapp.xxx.deletes where xxx can be either supplier or customer . The following example gathers all metrics except those from your application regarding suppliers: <markup lang=\"properties\" title=\"Disabling metrics by name (properties format)\" >metrics.registries.0.type = application metrics.registries.0.filter.exclude = myapp\\.supplier\\..* The following settings select the particular subset of the metrics created in your application code representing updates of customers and suppliers: <markup lang=\"properties\" title=\"Enabling metrics by name (properties format)\" >metrics.registries.0.type = application metrics.registries.0.filter.include = myapp\\..*\\.updates If you use the YAML configuration format, enclose the regex patterns in single-quote marks: <markup lang=\"yaml\" title=\"Enabling metrics by name (YAML format)\" >metrics: registries: - type: application filter: include: 'myapp\\..*\\.updates' The next example selects only your application&#8217;s metrics while excluding those which refer to deletions: <markup lang=\"properties\" title=\"Combining include and exclude \" >metrics.registries.0.type = application metrics.registries.0.filter.include = myapp\\..* metrics.registries.0.filter.exclude = myapp\\..*/deletes Helidon would not update or report the metric myapp.supplier.queries , for example. To include metrics from your application for both updates and queries (but not for other operations), you could change the settings in the previous example to this: <markup >metrics.registries.0.type = application metrics.registries.0.filter.include = myapp\\..*\\.updates|myapp\\..*\\.queries metrics.registries.0.filter.exclude = myapp\\..*/deletes Your Helidon SE application can control the collection and reporting of metrics programmatically as well by preparing these settings objects: RegistryFilterSettings RegistrySettings MetricsSettings and using the resulting MetricsSettings to retrieve a suitable RegistryFactory . <markup lang=\"java\" title=\"Control metrics by registry type and name\" >import io.helidon.metrics.api.RegistryFilterSettings; import org.eclipse.microprofile.metrics.MetricRegistry; ... RegistryFilterSettings appFilterSettings = RegistryFilterSettings.builder() .include(\"myapp\\..*\\.updates\") .build(); RegistrySettings registrySettings = RegistrySettings.builder() .filterSettings(appFilterSettings) .build(); MetricsSettings metricsSettings = MetricsSettings.builder() .registrySettings(MetricRegistry.Type.APPLICATION, appFilterSettings) .build(); RegistryFactory rf = RegistryFactory.getInstance(metricsSettings); MetricRegistry registry = rf.getRegistry(MetricRegistry.Type.APPLICATION); Create the registry filter settings to include only those metrics with names indicating updates. Create the registry settings with that filter. Create the metrics settings, associating the registry settings with the APPLICATION metric registry. Set the overall metrics settings and retrieve a registry factory suitably initialized. Obtain a reference to the APPLICATION registry which is set up to create and report on only metrics with names starting with myapp.updates. . ",
            "title": "Controlling Metrics By Registry Type and Metric Name"
        },
        {
            "location": "/se/guides/05_metrics",
            "text": " Any time you include the Helidon metrics module in your application, Helidon tracks two basic performance indicator metrics: a Counter of all requests received ( requests.count ), and a Meter of all requests received ( requests.meter ). Helidon SE also includes additional, extended KPI metrics which are disabled by default: current number of requests in-flight - a ConcurrentGauge ( requests.inFlight ) of requests currently being processed long-running requests - a Meter ( requests.longRunning ) measuring the rate at which Helidon processes requests which take at least a given amount of time to complete; configurable, defaults to 10000 milliseconds (10 seconds) load - a Meter ( requests.load ) measuring the rate at which requests are worked on (as opposed to received) deferred - a Meter ( requests.deferred ) measuring the rate at which a request&#8217;s processing is delayed after Helidon receives the request You can enable and control these metrics using configuration: <markup lang=\"properties\" title=\"Configuration properties file controlling extended KPI metrics\" >metrics.key-performance-indicators.extended = true metrics.key-performance-indicators.long-running.threshold-ms = 2000 Your Helidon SE application can also control the KPI settings programmatically. <markup lang=\"java\" title=\"Assign KPI metrics behavior from code\" >import io.helidon.metrics.api.KeyPerformanceIndicatorMetricsSettings; import io.helidon.metrics.api.MetricsSettings; import io.helidon.metrics.serviceapi.MetricsSupport; import io.helidon.metrics.api.RegistryFactory; ... KeyPerformanceIndicatorMetricsSettings.Builder kpiSettingsBuilder = KeyPerformanceIndicatorMetricsSettings.builder() .extended(true) .longRunningThresholdMs(2000); MetricsSettings metricsSettings = MetricsSettings.builder() .keyPerformanceIndicatorSettings(kpiSettingsBuilder) .build(); Create a KeyPerformanceIndicatorMetricsSettings instance (via its Builder ) with non-default values. Create a MetricsSettings instance reflecting the KPI settings. ",
            "title": "Collecting Basic and Extended Key Performance Indicator (KPI) Metrics"
        },
        {
            "location": "/se/guides/05_metrics",
            "text": " By adding a metrics section to your application configuration you can control how the Helidon metrics subsystem behaves in any of several ways. Disable metrics subsystem entirely . Identify groups of metrics to control: registered by a particular component , and by metric registry (application, vendor, and base) and within a registry by metric names which match patterns you provide. Select whether to collect extended key performance indicator metrics . Your Helidon SE application can also control metrics processing programmatically as described in the following sections. Disabling Metrics Subsystem Entirely By default, if your application depends on the helidon-metrics Maven module then full-featured metrics are enabled. You can disable the metrics subsystem entirely using configuration: <markup lang=\"properties\" title=\"Configuration properties file disabling metrics\" >metrics.enabled=false A Helidon SE application can disable metrics processing programmatically. <markup lang=\"java\" title=\"Disable all metrics behavior\" >import io.helidon.metrics.api.MetricsSettings; import io.helidon.metrics.serviceapi.MetricsSupport; import io.helidon.metrics.api.RegistryFactory; ... MetricsSettings metricsSettings = MetricsSettings.builder() .enabled(false) .build(); MetricsSupport metricsSupport = MetricsSupport.create(metricsSettings); RegistryFactory registryFactory = RegistryFactory.getInstance(metricsSettings); Create a MetricsSettings instance (via its Builder ) with the metrics subsystem disabled. Get a MetricsSupport service (usable in setting routing rules) that responds to the /metrics endpoint with 404 and an explanatory message. Get a RegistryFactory instance that provides MetricRegistry instances which register no-op metric objects (counters, timers, etc.). These builders and interfaces also have methods which accept Config objects representing the metrics node from the application configuration. With metrics processing disabled, Helidon never updates any metrics and the /metrics endpoints respond with 404 plus a message that the metrics subsystem is disabled. Enabling and Disabling Metrics Usage by a Component Helidon contains several components and integrations which register and update metrics. Depending on how the component is written, you might be able to disable just that component&#8217;s use of metrics: <markup lang=\"properties\" title=\"Configuration properties file disabling a component&#8217;s use of metrics\" >some-component.metrics.enabled=false Check the documentation for a specific component to find out whether that component uses metrics and whether it allows you to disable that use. Your Helidon SE application can disable a metrics-capable component&#8217;s use of metrics programmatically. <markup lang=\"java\" title=\"Disable metrics use in a metrics-capable component\" >import io.helidon.metrics.api.ComponentMetricsSettings; ... ComponentMetricsSettings.Builder componentMetricsSettingsBuilder = ComponentMetricsSettings.builder() .enabled(false); SomeService someService = SomeService.builder() ... .componentMetricsSettings(componentMetricsSettingsBuilder) ... .build(); Create a ComponentMetricsSettings instance (via its Builder ) indicating that metrics usage should be disabled. Create an instance of the service with its metrics usage disabled. If you disable a component&#8217;s use of metrics, Helidon does not register the component&#8217;s metrics in the visible metrics registries nor do those metrics ever update their values. The response from the /metrics endpoint excludes that component&#8217;s metrics. Note that if you disable metrics processing entirely, no component updates its metrics regardless of any component-level metrics settings. Controlling Metrics By Registry Type and Metric Name You can control the collection and reporting of metrics by registry type and metric name within registry type. Disabling All Metrics of a Given Registry Type To disable all metrics in a given registry type (application, vendor, or base), add one or more groups to the configuration: <markup lang=\"properties\" title=\"Disabling base and vendor metrics (properties format)\" >metrics.registries.0.type = base metrics.registries.0.enabled = false metrics.registries.1.type = vendor metrics.registries.1.enabled = false <markup lang=\"yaml\" title=\"Disabling base and vendor metrics (YAML format)\" >metrics: registries: - type: base enabled: false - type: vendor enables: false Controlling Metrics by Metric Name You can be even more selective. Within a registry type you can configure up to two regular expression patterns: one matching metric names to exclude , and one matching metric names to include . Helidon updates and reports a metric only if two conditions hold: the metric name does not match the exclude regex pattern (if you define one), and either there is no include regex pattern, or the metric name matches the include pattern. Caution Make sure any include regex pattern you specify matches all the metric names you want to capture. Suppose your application creates and updates a group of metrics with names such as myapp.xxx.queries , myapp.xxx.creates , myapp.xxx.updates , and myapp.xxx.deletes where xxx can be either supplier or customer . The following example gathers all metrics except those from your application regarding suppliers: <markup lang=\"properties\" title=\"Disabling metrics by name (properties format)\" >metrics.registries.0.type = application metrics.registries.0.filter.exclude = myapp\\.supplier\\..* The following settings select the particular subset of the metrics created in your application code representing updates of customers and suppliers: <markup lang=\"properties\" title=\"Enabling metrics by name (properties format)\" >metrics.registries.0.type = application metrics.registries.0.filter.include = myapp\\..*\\.updates If you use the YAML configuration format, enclose the regex patterns in single-quote marks: <markup lang=\"yaml\" title=\"Enabling metrics by name (YAML format)\" >metrics: registries: - type: application filter: include: 'myapp\\..*\\.updates' The next example selects only your application&#8217;s metrics while excluding those which refer to deletions: <markup lang=\"properties\" title=\"Combining include and exclude \" >metrics.registries.0.type = application metrics.registries.0.filter.include = myapp\\..* metrics.registries.0.filter.exclude = myapp\\..*/deletes Helidon would not update or report the metric myapp.supplier.queries , for example. To include metrics from your application for both updates and queries (but not for other operations), you could change the settings in the previous example to this: <markup >metrics.registries.0.type = application metrics.registries.0.filter.include = myapp\\..*\\.updates|myapp\\..*\\.queries metrics.registries.0.filter.exclude = myapp\\..*/deletes Your Helidon SE application can control the collection and reporting of metrics programmatically as well by preparing these settings objects: RegistryFilterSettings RegistrySettings MetricsSettings and using the resulting MetricsSettings to retrieve a suitable RegistryFactory . <markup lang=\"java\" title=\"Control metrics by registry type and name\" >import io.helidon.metrics.api.RegistryFilterSettings; import org.eclipse.microprofile.metrics.MetricRegistry; ... RegistryFilterSettings appFilterSettings = RegistryFilterSettings.builder() .include(\"myapp\\..*\\.updates\") .build(); RegistrySettings registrySettings = RegistrySettings.builder() .filterSettings(appFilterSettings) .build(); MetricsSettings metricsSettings = MetricsSettings.builder() .registrySettings(MetricRegistry.Type.APPLICATION, appFilterSettings) .build(); RegistryFactory rf = RegistryFactory.getInstance(metricsSettings); MetricRegistry registry = rf.getRegistry(MetricRegistry.Type.APPLICATION); Create the registry filter settings to include only those metrics with names indicating updates. Create the registry settings with that filter. Create the metrics settings, associating the registry settings with the APPLICATION metric registry. Set the overall metrics settings and retrieve a registry factory suitably initialized. Obtain a reference to the APPLICATION registry which is set up to create and report on only metrics with names starting with myapp.updates. . Collecting Basic and Extended Key Performance Indicator (KPI) Metrics Any time you include the Helidon metrics module in your application, Helidon tracks two basic performance indicator metrics: a Counter of all requests received ( requests.count ), and a Meter of all requests received ( requests.meter ). Helidon SE also includes additional, extended KPI metrics which are disabled by default: current number of requests in-flight - a ConcurrentGauge ( requests.inFlight ) of requests currently being processed long-running requests - a Meter ( requests.longRunning ) measuring the rate at which Helidon processes requests which take at least a given amount of time to complete; configurable, defaults to 10000 milliseconds (10 seconds) load - a Meter ( requests.load ) measuring the rate at which requests are worked on (as opposed to received) deferred - a Meter ( requests.deferred ) measuring the rate at which a request&#8217;s processing is delayed after Helidon receives the request You can enable and control these metrics using configuration: <markup lang=\"properties\" title=\"Configuration properties file controlling extended KPI metrics\" >metrics.key-performance-indicators.extended = true metrics.key-performance-indicators.long-running.threshold-ms = 2000 Your Helidon SE application can also control the KPI settings programmatically. <markup lang=\"java\" title=\"Assign KPI metrics behavior from code\" >import io.helidon.metrics.api.KeyPerformanceIndicatorMetricsSettings; import io.helidon.metrics.api.MetricsSettings; import io.helidon.metrics.serviceapi.MetricsSupport; import io.helidon.metrics.api.RegistryFactory; ... KeyPerformanceIndicatorMetricsSettings.Builder kpiSettingsBuilder = KeyPerformanceIndicatorMetricsSettings.builder() .extended(true) .longRunningThresholdMs(2000); MetricsSettings metricsSettings = MetricsSettings.builder() .keyPerformanceIndicatorSettings(kpiSettingsBuilder) .build(); Create a KeyPerformanceIndicatorMetricsSettings instance (via its Builder ) with non-default values. Create a MetricsSettings instance reflecting the KPI settings. ",
            "title": "Controlling Metrics Behavior"
        },
        {
            "location": "/se/guides/05_metrics",
            "text": " Each metric has associated metadata that describes: name: The name of the metric. units: The unit of the metric such as time (seconds, millisecond), size (bytes, megabytes), etc. type: The type of metric: Counter , Timer , Meter , Histogram , SimpleTimer , or Gauge . You can get the metadata for any scope, such as /metrics/base , as shown below: <markup lang=\"bash\" title=\"Get the metrics metadata using HTTP OPTIONS method:\" > curl -X OPTIONS -H \"Accept: application/json\" http://localhost:8080/metrics/base <markup lang=\"json\" title=\"JSON response (truncated):\" >{ \"classloader.currentLoadedClass.count\": { \"unit\": \"none\", \"type\": \"counter\", \"description\": \"Displays the number of classes that are currently loaded in the Java virtual machine.\", \"displayName\": \"Current Loaded Class Count\" }, ... \"jvm.uptime\": { \"unit\": \"milliseconds\", \"type\": \"gauge\", \"description\": \"Displays the start time of the Java virtual machine in milliseconds. This attribute displays the approximate time when the Java virtual machine started.\", \"displayName\": \"JVM Uptime\" }, ... \"memory.usedHeap\": { \"unit\": \"bytes\", \"type\": \"gauge\", \"description\": \"Displays the amount of used heap memory in bytes.\", \"displayName\": \"Used Heap Memory\" } } ",
            "title": "Metrics Metadata"
        },
        {
            "location": "/se/guides/05_metrics",
            "text": " The Counter metric is a monotonically increasing or decreasing number. The following example will demonstrate how to use a Counter to track the number of times the /cards endpoint is called. <markup lang=\"java\" title=\"Create a new class named GreetingCards with the following code:\" >package io.helidon.examples.quickstart.se; import io.helidon.metrics.RegistryFactory; import io.helidon.webserver.Routing; import io.helidon.webserver.ServerRequest; import io.helidon.webserver.ServerResponse; import io.helidon.webserver.Service; import java.util.Collections; import javax.json.Json; import javax.json.JsonBuilderFactory; import javax.json.JsonObject; import org.eclipse.microprofile.metrics.Counter; import org.eclipse.microprofile.metrics.MetricRegistry; public class GreetingCards implements Service { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); private final Counter cardCounter; GreetingCards() { RegistryFactory metricsRegistry = RegistryFactory.getInstance(); MetricRegistry appRegistry = metricsRegistry.getRegistry(MetricRegistry.Type.APPLICATION); cardCounter = appRegistry.counter(\"cardCount\"); } @Override public void update(Routing.Rules rules) { rules.get(\"/\", this::getDefaultMessageHandler); } private void getDefaultMessageHandler(ServerRequest request, ServerResponse response) { cardCounter.inc(); sendResponse(response, \"Here are some cards ...\"); } private void sendResponse(ServerResponse response, String msg) { JsonObject returnObject = JSON.createObjectBuilder().add(\"message\", msg).build(); response.send(returnObject); } } Import metrics classes. Declare a Counter member variable. Create and register the Counter metric in the MetricRegistry . This Counter will exist for the lifetime of the application. Increment the count. <markup lang=\"java\" title=\"Update the Main.createRouting method as follows:\" > private static Routing createRouting(Config config) { MetricsSupport metrics = MetricsSupport.create(); GreetService greetService = new GreetService(config); return Routing.builder() .register(JsonSupport.create()) .register(metrics) .register(\"/greet\", greetService) .register(\"/cards\", new GreetingCards()) .build(); } Add the GreetingCards service to the Routing.builder . Helidon will route any REST requests with the /cards root path to the GreetingCards service. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints below:\" >curl http://localhost:8080/cards curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response:\" >{ \"cardCount\": 1 } The count value is one since the method was called once. ",
            "title": "Counter Metric"
        },
        {
            "location": "/se/guides/05_metrics",
            "text": " The Meter metric is used to measure throughput, the number of times an event occurs within a certain time period. When a Meter object is created, its internal clock starts running. That clock is used to calculate the various rates stored this metric. The Meter also includes the count field from the Counter metric. When you mark an event, the count is incremented. The following example marks an event each time the /cards endpoint is called. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.se; import io.helidon.metrics.RegistryFactory; import io.helidon.webserver.Routing; import io.helidon.webserver.ServerRequest; import io.helidon.webserver.ServerResponse; import io.helidon.webserver.Service; import java.util.Collections; import javax.json.Json; import javax.json.JsonBuilderFactory; import javax.json.JsonObject; import org.eclipse.microprofile.metrics.Meter; import org.eclipse.microprofile.metrics.MetricRegistry; public class GreetingCards implements Service { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); private final Meter cardMeter; GreetingCards() { RegistryFactory metricsRegistry = RegistryFactory.getInstance(); MetricRegistry appRegistry = metricsRegistry.getRegistry(MetricRegistry.Type.APPLICATION); cardMeter = appRegistry.meter(\"cardMeter\"); } @Override public void update(Routing.Rules rules) { rules.get(\"/\", this::getDefaultMessageHandler); } private void getDefaultMessageHandler(ServerRequest request, ServerResponse response) { cardMeter.mark(); sendResponse(response, \"Here are some cards ...\"); } private void sendResponse(ServerResponse response, String msg) { JsonObject returnObject = JSON.createObjectBuilder().add(\"message\", msg).build(); response.send(returnObject); } } Import metrics classes. Declare a Meter member variable. Create and register the Meter metric in the MetricRegistry . Mark the occurrence of an event. Note: you can specify a count parameter such as mark(100) to mark multiple events. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints below:\" >curl http://localhost:8080/cards curl http://localhost:8080/cards curl http://localhost:8080/cards curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response:\" >{ \"cardMeter\": { \"count\": 3, \"meanRate\": 0.17566568722974535, \"oneMinRate\": 0.04413761384322548, \"fiveMinRate\": 0.009753212003766951, \"fifteenMinRate\": 0.0033056752265846544 } } The Meter metric has a set of fields to show various rates, along with the count. The /cards endpoint was called three times. ",
            "title": "Meter Metric"
        },
        {
            "location": "/se/guides/05_metrics",
            "text": " (See also Simple timer metric .) The Timer metric aggregates durations, provides timing statistics, and includes throughput statistics using an internal Meter metric. The Timer measures duration in nanoseconds. In the following example, a Timer metric is used to measure the duration of a method&#8217;s execution. Whenever the REST /cards endpoint is called, the Timer will be updated with additional timing information. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.se; import io.helidon.metrics.RegistryFactory; import io.helidon.webserver.Routing; import io.helidon.webserver.ServerRequest; import io.helidon.webserver.ServerResponse; import io.helidon.webserver.Service; import java.util.Collections; import javax.json.Json; import javax.json.JsonBuilderFactory; import javax.json.JsonObject; import org.eclipse.microprofile.metrics.MetricRegistry; import org.eclipse.microprofile.metrics.Timer; public class GreetingCards implements Service { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); private final Timer cardTimer; GreetingCards() { RegistryFactory metricsRegistry = RegistryFactory.getInstance(); MetricRegistry appRegistry = metricsRegistry.getRegistry(MetricRegistry.Type.APPLICATION); cardTimer = appRegistry.timer(\"cardTimer\"); } @Override public void update(Routing.Rules rules) { rules.get(\"/\", this::getDefaultMessageHandler); } private void getDefaultMessageHandler(ServerRequest request, ServerResponse response) { Timer.Context timerContext = cardTimer.time(); sendResponse(response, \"Here are some cards ...\"); response.whenSent().thenAccept(res -&gt; timerContext.stop()); } private void sendResponse(ServerResponse response, String msg) { JsonObject returnObject = JSON.createObjectBuilder().add(\"message\", msg).build(); response.send(returnObject); } } Import metrics classes. Declare a Timer member variable. Create and register the Timer metric in the MetricRegistry . Start the timer. Stop the timer. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints below:\" >curl http://localhost:8080/cards curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response:\" >{ \"cardTimer\": { \"count\": 1, \"meanRate\": 0.03843465264149663, \"oneMinRate\": 0.014712537947741825, \"fiveMinRate\": 0.0032510706679223173, \"fifteenMinRate\": 0.0011018917421948848, \"min\": 40876527, \"max\": 40876527, \"mean\": 40876527, \"stddev\": 0.0, \"p50\": 40876527, \"p75\": 40876527, \"p95\": 40876527, \"p98\": 40876527, \"p99\": 40876527, \"p999\": 40876527 } } These are the same fields used by Meter . These are the Timer fields that measure the duration of the getDefaultMessageHandler method. Some of these values will change each time you invoke the /cards endpoint. ",
            "title": "Timer Metric"
        },
        {
            "location": "/se/guides/05_metrics",
            "text": " The Histogram metric calculates the distribution of a set of values within ranges. This metric does not relate to time at all. The following example will record a set of random numbers in a Histogram metric when the /cards endpoint is invoked. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.se; import io.helidon.metrics.RegistryFactory; import io.helidon.webserver.Routing; import io.helidon.webserver.ServerRequest; import io.helidon.webserver.ServerResponse; import io.helidon.webserver.Service; import java.util.Collections; import java.util.Random; import javax.json.Json; import javax.json.JsonBuilderFactory; import javax.json.JsonObject; import org.eclipse.microprofile.metrics.Histogram; import org.eclipse.microprofile.metrics.MetricRegistry; public class GreetingCards implements Service { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); private final Histogram cardHistogram; GreetingCards() { RegistryFactory metricsRegistry = RegistryFactory.getInstance(); MetricRegistry appRegistry = metricsRegistry.getRegistry(MetricRegistry.Type.APPLICATION); cardHistogram = appRegistry.histogram(\"cardHistogram\"); } @Override public void update(Routing.Rules rules) { rules.get(\"/\", this::getDefaultMessageHandler); } private void getDefaultMessageHandler(ServerRequest request, ServerResponse response) { Random r = new Random(); for (int i = 0; i &lt; 1000; i++) { cardHistogram.update(1 + r.nextInt(25)); } sendResponse(response, \"Here are some cards ...\"); } private void sendResponse(ServerResponse response, String msg) { JsonObject returnObject = JSON.createObjectBuilder().add(\"message\", msg).build(); response.send(returnObject); } } Import metrics classes. Declare a Histogram member variable. Create and register the Histogram metric in the MetricRegistry . Update the Histogram metric with a random number. Loop, loading the histogram with numbers. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints below:\" >curl http://localhost:8080/cards curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response:\" >{ \"cardHistogram\": { \"count\": 1000, \"min\": 1, \"max\": 25, \"mean\": 12.743999999999915, \"stddev\": 7.308793607702962, \"p50\": 13.0, \"p75\": 19.0, \"p95\": 24.0, \"p98\": 25.0, \"p99\": 25.0, \"p999\": 25.0 } } This is the histogram data. Some of these values will change each time you invoke the /cards endpoint. ",
            "title": "Histogram Metric"
        },
        {
            "location": "/se/guides/05_metrics",
            "text": " The Gauge metric measures a discreet value at a point in time, such as a temperature. The metric is not normally tied to a REST endpoint, rather it should be registered during application startup. When the /metrics/application endpoint is invoked, Helidon will call the getValue method of each registered Gauge . The following example demonstrates how a Gauge is used to get the current temperature. <markup lang=\"java\" title=\"Add new imports to Main.java and replace the Main.createRouting method with the following code:\" >import io.helidon.metrics.RegistryFactory; import java.util.Random; import org.eclipse.microprofile.metrics.Gauge; import org.eclipse.microprofile.metrics.MetricRegistry; ... private static Routing createRouting(Config config) { MetricsSupport metrics = MetricsSupport.create(); RegistryFactory metricsRegistry = RegistryFactory.getInstance(); MetricRegistry appRegistry = metricsRegistry.getRegistry(MetricRegistry.Type.APPLICATION); appRegistry.register(\"temperature\", (Gauge&lt;Integer&gt;)() -&gt; new Random().nextInt(100)); GreetService greetService = new GreetService(config); return Routing.builder() .register(JsonSupport.create()) .register(metrics) // Metrics at \"/metrics\" .register(\"/greet\", greetService) .register(\"/cards\", new GreetingCards()) .build(); } Register the Gauge , providing a lambda function that will return a random temperature. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code to use the Counter metric which will simplify the JSON output:\" >package io.helidon.examples.quickstart.se; import io.helidon.metrics.RegistryFactory; import io.helidon.webserver.Routing; import io.helidon.webserver.ServerRequest; import io.helidon.webserver.ServerResponse; import io.helidon.webserver.Service; import java.util.Collections; import javax.json.Json; import javax.json.JsonBuilderFactory; import javax.json.JsonObject; import org.eclipse.microprofile.metrics.Counter; import org.eclipse.microprofile.metrics.MetricRegistry; public class GreetingCards implements Service { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); private final Counter cardCounter; GreetingCards() { RegistryFactory metricsRegistry = RegistryFactory.getInstance(); MetricRegistry appRegistry = metricsRegistry.getRegistry(MetricRegistry.Type.APPLICATION); cardCounter = appRegistry.counter(\"cardCount\"); } @Override public void update(Routing.Rules rules) { rules.get(\"/\", this::getDefaultMessageHandler); } private void getDefaultMessageHandler(ServerRequest request, ServerResponse response) { cardCounter.inc(); sendResponse(response, \"Here are some cards ...\"); } private void sendResponse(ServerResponse response, String msg) { JsonObject returnObject = JSON.createObjectBuilder().add(\"message\", msg).build(); response.send(returnObject); } } <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints below:\" >curl http://localhost:8080/cards curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response from /metrics/application :\" >{ \"cardCount\": 1, \"temperature\": 11 } The current temperature is returned. Invoke the /metrics/application endpoint again and you should get a different value. ",
            "title": "Gauge Metric"
        },
        {
            "location": "/se/guides/05_metrics",
            "text": " The SimpleTimer metric counts invocations and accumulates duration (in seconds). In the following example, a SimpleTimer metric is used to count and measure the duration of a method&#8217;s execution. Whenever the REST /cards endpoint is called, the SimpleTimer updates its count and total elapsed time. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.se; import io.helidon.metrics.RegistryFactory; import io.helidon.webserver.Routing; import io.helidon.webserver.ServerRequest; import io.helidon.webserver.ServerResponse; import io.helidon.webserver.Service; import java.util.Collections; import javax.json.Json; import javax.json.JsonBuilderFactory; import javax.json.JsonObject; import org.eclipse.microprofile.metrics.MetricRegistry; import org.eclipse.microprofile.metrics.SimpleTimer; public class GreetingCards implements Service { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); private final SimpleTimer cardTimer; GreetingCards() { RegistryFactory metricsRegistry = RegistryFactory.getInstance(); MetricRegistry appRegistry = metricsRegistry.getRegistry(MetricRegistry.Type.APPLICATION); cardTimer = appRegistry.simpleTimer(\"cardSimpleTimer\"); } @Override public void update(Routing.Rules rules) { rules.get(\"/\", this::getDefaultMessageHandler); } private void getDefaultMessageHandler(ServerRequest request, ServerResponse response) { cardTimer.time(() -&gt; sendResponse(response, \"Here are some cards ...\")); } private void sendResponse(ServerResponse response, String msg) { JsonObject returnObject = JSON.createObjectBuilder().add(\"message\", msg).build(); response.send(returnObject); } } Import metrics classes, particularly the SimpleTimer interface for this example. Declare a SimpleTimer member variable. Create and register the SimpleTimer metric in the MetricRegistry . Wrap the business logic in the simple timer&#8217;s time method which updates the count and the total elapsed time. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints below:\" >curl http://localhost:8080/cards curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response:\" >{ \"cardSimpleTimer\": { \"count\":1, \"elapsedTime\":0.034274025 } } How many times the getDefaultMessageHandler method ran. Cumulative time spent in the getDefaultMessageHandler method during its executions. ",
            "title": "Simple Timer Metric"
        },
        {
            "location": "/se/guides/05_metrics",
            "text": " This section demonstrates how to use application-specific metrics and integrate them with Helidon. It is the application&#8217;s responsibility to create and update the metrics at runtime. The application has complete control over when and how each metric is used. For example, an application may use the same counter for multiple methods, or one counter per method. Helidon maintains an application MetricRegistry which is used to manage all of the application metrics. Helidon returns these metrics in response to a /metrics/application REST request. In all of these examples, the scope and lifetime of the metric is at the application-level. Each metric, except Gauge , is updated in response to a REST request and the contents of the metric is cumulative. Counter Metric The Counter metric is a monotonically increasing or decreasing number. The following example will demonstrate how to use a Counter to track the number of times the /cards endpoint is called. <markup lang=\"java\" title=\"Create a new class named GreetingCards with the following code:\" >package io.helidon.examples.quickstart.se; import io.helidon.metrics.RegistryFactory; import io.helidon.webserver.Routing; import io.helidon.webserver.ServerRequest; import io.helidon.webserver.ServerResponse; import io.helidon.webserver.Service; import java.util.Collections; import javax.json.Json; import javax.json.JsonBuilderFactory; import javax.json.JsonObject; import org.eclipse.microprofile.metrics.Counter; import org.eclipse.microprofile.metrics.MetricRegistry; public class GreetingCards implements Service { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); private final Counter cardCounter; GreetingCards() { RegistryFactory metricsRegistry = RegistryFactory.getInstance(); MetricRegistry appRegistry = metricsRegistry.getRegistry(MetricRegistry.Type.APPLICATION); cardCounter = appRegistry.counter(\"cardCount\"); } @Override public void update(Routing.Rules rules) { rules.get(\"/\", this::getDefaultMessageHandler); } private void getDefaultMessageHandler(ServerRequest request, ServerResponse response) { cardCounter.inc(); sendResponse(response, \"Here are some cards ...\"); } private void sendResponse(ServerResponse response, String msg) { JsonObject returnObject = JSON.createObjectBuilder().add(\"message\", msg).build(); response.send(returnObject); } } Import metrics classes. Declare a Counter member variable. Create and register the Counter metric in the MetricRegistry . This Counter will exist for the lifetime of the application. Increment the count. <markup lang=\"java\" title=\"Update the Main.createRouting method as follows:\" > private static Routing createRouting(Config config) { MetricsSupport metrics = MetricsSupport.create(); GreetService greetService = new GreetService(config); return Routing.builder() .register(JsonSupport.create()) .register(metrics) .register(\"/greet\", greetService) .register(\"/cards\", new GreetingCards()) .build(); } Add the GreetingCards service to the Routing.builder . Helidon will route any REST requests with the /cards root path to the GreetingCards service. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints below:\" >curl http://localhost:8080/cards curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response:\" >{ \"cardCount\": 1 } The count value is one since the method was called once. Meter Metric The Meter metric is used to measure throughput, the number of times an event occurs within a certain time period. When a Meter object is created, its internal clock starts running. That clock is used to calculate the various rates stored this metric. The Meter also includes the count field from the Counter metric. When you mark an event, the count is incremented. The following example marks an event each time the /cards endpoint is called. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.se; import io.helidon.metrics.RegistryFactory; import io.helidon.webserver.Routing; import io.helidon.webserver.ServerRequest; import io.helidon.webserver.ServerResponse; import io.helidon.webserver.Service; import java.util.Collections; import javax.json.Json; import javax.json.JsonBuilderFactory; import javax.json.JsonObject; import org.eclipse.microprofile.metrics.Meter; import org.eclipse.microprofile.metrics.MetricRegistry; public class GreetingCards implements Service { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); private final Meter cardMeter; GreetingCards() { RegistryFactory metricsRegistry = RegistryFactory.getInstance(); MetricRegistry appRegistry = metricsRegistry.getRegistry(MetricRegistry.Type.APPLICATION); cardMeter = appRegistry.meter(\"cardMeter\"); } @Override public void update(Routing.Rules rules) { rules.get(\"/\", this::getDefaultMessageHandler); } private void getDefaultMessageHandler(ServerRequest request, ServerResponse response) { cardMeter.mark(); sendResponse(response, \"Here are some cards ...\"); } private void sendResponse(ServerResponse response, String msg) { JsonObject returnObject = JSON.createObjectBuilder().add(\"message\", msg).build(); response.send(returnObject); } } Import metrics classes. Declare a Meter member variable. Create and register the Meter metric in the MetricRegistry . Mark the occurrence of an event. Note: you can specify a count parameter such as mark(100) to mark multiple events. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints below:\" >curl http://localhost:8080/cards curl http://localhost:8080/cards curl http://localhost:8080/cards curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response:\" >{ \"cardMeter\": { \"count\": 3, \"meanRate\": 0.17566568722974535, \"oneMinRate\": 0.04413761384322548, \"fiveMinRate\": 0.009753212003766951, \"fifteenMinRate\": 0.0033056752265846544 } } The Meter metric has a set of fields to show various rates, along with the count. The /cards endpoint was called three times. Timer Metric (See also Simple timer metric .) The Timer metric aggregates durations, provides timing statistics, and includes throughput statistics using an internal Meter metric. The Timer measures duration in nanoseconds. In the following example, a Timer metric is used to measure the duration of a method&#8217;s execution. Whenever the REST /cards endpoint is called, the Timer will be updated with additional timing information. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.se; import io.helidon.metrics.RegistryFactory; import io.helidon.webserver.Routing; import io.helidon.webserver.ServerRequest; import io.helidon.webserver.ServerResponse; import io.helidon.webserver.Service; import java.util.Collections; import javax.json.Json; import javax.json.JsonBuilderFactory; import javax.json.JsonObject; import org.eclipse.microprofile.metrics.MetricRegistry; import org.eclipse.microprofile.metrics.Timer; public class GreetingCards implements Service { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); private final Timer cardTimer; GreetingCards() { RegistryFactory metricsRegistry = RegistryFactory.getInstance(); MetricRegistry appRegistry = metricsRegistry.getRegistry(MetricRegistry.Type.APPLICATION); cardTimer = appRegistry.timer(\"cardTimer\"); } @Override public void update(Routing.Rules rules) { rules.get(\"/\", this::getDefaultMessageHandler); } private void getDefaultMessageHandler(ServerRequest request, ServerResponse response) { Timer.Context timerContext = cardTimer.time(); sendResponse(response, \"Here are some cards ...\"); response.whenSent().thenAccept(res -&gt; timerContext.stop()); } private void sendResponse(ServerResponse response, String msg) { JsonObject returnObject = JSON.createObjectBuilder().add(\"message\", msg).build(); response.send(returnObject); } } Import metrics classes. Declare a Timer member variable. Create and register the Timer metric in the MetricRegistry . Start the timer. Stop the timer. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints below:\" >curl http://localhost:8080/cards curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response:\" >{ \"cardTimer\": { \"count\": 1, \"meanRate\": 0.03843465264149663, \"oneMinRate\": 0.014712537947741825, \"fiveMinRate\": 0.0032510706679223173, \"fifteenMinRate\": 0.0011018917421948848, \"min\": 40876527, \"max\": 40876527, \"mean\": 40876527, \"stddev\": 0.0, \"p50\": 40876527, \"p75\": 40876527, \"p95\": 40876527, \"p98\": 40876527, \"p99\": 40876527, \"p999\": 40876527 } } These are the same fields used by Meter . These are the Timer fields that measure the duration of the getDefaultMessageHandler method. Some of these values will change each time you invoke the /cards endpoint. Histogram Metric The Histogram metric calculates the distribution of a set of values within ranges. This metric does not relate to time at all. The following example will record a set of random numbers in a Histogram metric when the /cards endpoint is invoked. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.se; import io.helidon.metrics.RegistryFactory; import io.helidon.webserver.Routing; import io.helidon.webserver.ServerRequest; import io.helidon.webserver.ServerResponse; import io.helidon.webserver.Service; import java.util.Collections; import java.util.Random; import javax.json.Json; import javax.json.JsonBuilderFactory; import javax.json.JsonObject; import org.eclipse.microprofile.metrics.Histogram; import org.eclipse.microprofile.metrics.MetricRegistry; public class GreetingCards implements Service { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); private final Histogram cardHistogram; GreetingCards() { RegistryFactory metricsRegistry = RegistryFactory.getInstance(); MetricRegistry appRegistry = metricsRegistry.getRegistry(MetricRegistry.Type.APPLICATION); cardHistogram = appRegistry.histogram(\"cardHistogram\"); } @Override public void update(Routing.Rules rules) { rules.get(\"/\", this::getDefaultMessageHandler); } private void getDefaultMessageHandler(ServerRequest request, ServerResponse response) { Random r = new Random(); for (int i = 0; i &lt; 1000; i++) { cardHistogram.update(1 + r.nextInt(25)); } sendResponse(response, \"Here are some cards ...\"); } private void sendResponse(ServerResponse response, String msg) { JsonObject returnObject = JSON.createObjectBuilder().add(\"message\", msg).build(); response.send(returnObject); } } Import metrics classes. Declare a Histogram member variable. Create and register the Histogram metric in the MetricRegistry . Update the Histogram metric with a random number. Loop, loading the histogram with numbers. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints below:\" >curl http://localhost:8080/cards curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response:\" >{ \"cardHistogram\": { \"count\": 1000, \"min\": 1, \"max\": 25, \"mean\": 12.743999999999915, \"stddev\": 7.308793607702962, \"p50\": 13.0, \"p75\": 19.0, \"p95\": 24.0, \"p98\": 25.0, \"p99\": 25.0, \"p999\": 25.0 } } This is the histogram data. Some of these values will change each time you invoke the /cards endpoint. Gauge Metric The Gauge metric measures a discreet value at a point in time, such as a temperature. The metric is not normally tied to a REST endpoint, rather it should be registered during application startup. When the /metrics/application endpoint is invoked, Helidon will call the getValue method of each registered Gauge . The following example demonstrates how a Gauge is used to get the current temperature. <markup lang=\"java\" title=\"Add new imports to Main.java and replace the Main.createRouting method with the following code:\" >import io.helidon.metrics.RegistryFactory; import java.util.Random; import org.eclipse.microprofile.metrics.Gauge; import org.eclipse.microprofile.metrics.MetricRegistry; ... private static Routing createRouting(Config config) { MetricsSupport metrics = MetricsSupport.create(); RegistryFactory metricsRegistry = RegistryFactory.getInstance(); MetricRegistry appRegistry = metricsRegistry.getRegistry(MetricRegistry.Type.APPLICATION); appRegistry.register(\"temperature\", (Gauge&lt;Integer&gt;)() -&gt; new Random().nextInt(100)); GreetService greetService = new GreetService(config); return Routing.builder() .register(JsonSupport.create()) .register(metrics) // Metrics at \"/metrics\" .register(\"/greet\", greetService) .register(\"/cards\", new GreetingCards()) .build(); } Register the Gauge , providing a lambda function that will return a random temperature. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code to use the Counter metric which will simplify the JSON output:\" >package io.helidon.examples.quickstart.se; import io.helidon.metrics.RegistryFactory; import io.helidon.webserver.Routing; import io.helidon.webserver.ServerRequest; import io.helidon.webserver.ServerResponse; import io.helidon.webserver.Service; import java.util.Collections; import javax.json.Json; import javax.json.JsonBuilderFactory; import javax.json.JsonObject; import org.eclipse.microprofile.metrics.Counter; import org.eclipse.microprofile.metrics.MetricRegistry; public class GreetingCards implements Service { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); private final Counter cardCounter; GreetingCards() { RegistryFactory metricsRegistry = RegistryFactory.getInstance(); MetricRegistry appRegistry = metricsRegistry.getRegistry(MetricRegistry.Type.APPLICATION); cardCounter = appRegistry.counter(\"cardCount\"); } @Override public void update(Routing.Rules rules) { rules.get(\"/\", this::getDefaultMessageHandler); } private void getDefaultMessageHandler(ServerRequest request, ServerResponse response) { cardCounter.inc(); sendResponse(response, \"Here are some cards ...\"); } private void sendResponse(ServerResponse response, String msg) { JsonObject returnObject = JSON.createObjectBuilder().add(\"message\", msg).build(); response.send(returnObject); } } <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints below:\" >curl http://localhost:8080/cards curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response from /metrics/application :\" >{ \"cardCount\": 1, \"temperature\": 11 } The current temperature is returned. Invoke the /metrics/application endpoint again and you should get a different value. Simple Timer Metric The SimpleTimer metric counts invocations and accumulates duration (in seconds). In the following example, a SimpleTimer metric is used to count and measure the duration of a method&#8217;s execution. Whenever the REST /cards endpoint is called, the SimpleTimer updates its count and total elapsed time. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.se; import io.helidon.metrics.RegistryFactory; import io.helidon.webserver.Routing; import io.helidon.webserver.ServerRequest; import io.helidon.webserver.ServerResponse; import io.helidon.webserver.Service; import java.util.Collections; import javax.json.Json; import javax.json.JsonBuilderFactory; import javax.json.JsonObject; import org.eclipse.microprofile.metrics.MetricRegistry; import org.eclipse.microprofile.metrics.SimpleTimer; public class GreetingCards implements Service { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); private final SimpleTimer cardTimer; GreetingCards() { RegistryFactory metricsRegistry = RegistryFactory.getInstance(); MetricRegistry appRegistry = metricsRegistry.getRegistry(MetricRegistry.Type.APPLICATION); cardTimer = appRegistry.simpleTimer(\"cardSimpleTimer\"); } @Override public void update(Routing.Rules rules) { rules.get(\"/\", this::getDefaultMessageHandler); } private void getDefaultMessageHandler(ServerRequest request, ServerResponse response) { cardTimer.time(() -&gt; sendResponse(response, \"Here are some cards ...\")); } private void sendResponse(ServerResponse response, String msg) { JsonObject returnObject = JSON.createObjectBuilder().add(\"message\", msg).build(); response.send(returnObject); } } Import metrics classes, particularly the SimpleTimer interface for this example. Declare a SimpleTimer member variable. Create and register the SimpleTimer metric in the MetricRegistry . Wrap the business logic in the simple timer&#8217;s time method which updates the count and the total elapsed time. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints below:\" >curl http://localhost:8080/cards curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response:\" >{ \"cardSimpleTimer\": { \"count\":1, \"elapsedTime\":0.034274025 } } How many times the getDefaultMessageHandler method ran. Cumulative time spent in the getDefaultMessageHandler method during its executions. ",
            "title": "Application-Specific Metrics Data"
        },
        {
            "location": "/se/guides/05_metrics",
            "text": " The following example shows how to integrate the Helidon SE application with Kubernetes. <markup lang=\"bash\" title=\"Stop the application and build the docker image:\" >docker build -t helidon-metrics-se . <markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named metrics.yaml , with the following content:\" >kind: Service apiVersion: v1 metadata: name: helidon-metrics labels: app: helidon-metrics annotations: prometheus.io/scrape: 'true' spec: type: NodePort selector: app: helidon-metrics ports: - port: 8080 targetPort: 8080 name: http --- kind: Deployment apiVersion: apps/v1 metadata: name: helidon-metrics spec: replicas: 1 selector: matchLabels: app: helidon-metrics template: metadata: labels: app: helidon-metrics version: v1 spec: containers: - name: helidon-metrics image: helidon-metrics-se imagePullPolicy: IfNotPresent ports: - containerPort: 8080 A service of type NodePort that serves the default routes on port 8080 . An annotation that will allow Prometheus to discover and scrape the application pod. A deployment with one replica of a pod. <markup lang=\"bash\" title=\"Create and deploy the application into Kubernetes:\" >kubectl apply -f ./metrics.yaml <markup lang=\"bash\" title=\"Get the service information:\" >kubectl get service/helidon-metrics <markup lang=\"bash\" >NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE helidon-metrics NodePort 10.99.159.2 &lt;none&gt; 8080:31143/TCP 8s A service of type NodePort that serves the default routes on port 31143 . <markup lang=\"bash\" title=\"Verify the metrics endpoint using port 30116 , your port will likely be different:\" >curl http://localhost:31143/metrics Leave the application running in Kubernetes since it will be used for Prometheus integration. ",
            "title": "Kubernetes Integration"
        },
        {
            "location": "/se/guides/05_metrics",
            "text": " The metrics service that you just deployed into Kubernetes is already annotated with prometheus.io/scrape: . This will allow Prometheus to discover the service and scrape the metrics. In this exercise, you will install Prometheus into Kubernetes, then verify that it discovered the Helidon metrics in your application. <markup lang=\"bash\" title=\"Install Prometheus and wait until the pod is ready:\" >helm install stable/prometheus --name metrics export POD_NAME=$(kubectl get pods --namespace default -l \"app=prometheus,component=server\" -o jsonpath=\"{.items[0].metadata.name}\") kubectl get pod $POD_NAME You will see output similar to the following. Repeat the kubectl get pod command until you see 2/2 and Running . This may take up to one minute. <markup lang=\"bash\" >metrics-prometheus-server-5fc5dc86cb-79lk4 2/2 Running 0 46s <markup lang=\"bash\" title=\"Create a port-forward so you can access the server URL:\" >kubectl --namespace default port-forward $POD_NAME 7090:9090 Now open your browser and navigate to http://localhost:7090/targets . Search for helidon on the page and you will see your Helidon application as one of the Prometheus targets. ",
            "title": "Prometheus Integration"
        },
        {
            "location": "/se/guides/05_metrics",
            "text": " You can now delete the Kubernetes resources that were just created during this example. <markup lang=\"bash\" title=\"Delete the Prometheus Kubernetes resources:\" >helm delete --purge metrics <markup lang=\"bash\" title=\"Delete the application Kubernetes resources:\" >kubectl delete -f ./metrics.yaml ",
            "title": "Final Cleanup"
        },
        {
            "location": "/se/guides/05_metrics",
            "text": " Kubernetes Integration The following example shows how to integrate the Helidon SE application with Kubernetes. <markup lang=\"bash\" title=\"Stop the application and build the docker image:\" >docker build -t helidon-metrics-se . <markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named metrics.yaml , with the following content:\" >kind: Service apiVersion: v1 metadata: name: helidon-metrics labels: app: helidon-metrics annotations: prometheus.io/scrape: 'true' spec: type: NodePort selector: app: helidon-metrics ports: - port: 8080 targetPort: 8080 name: http --- kind: Deployment apiVersion: apps/v1 metadata: name: helidon-metrics spec: replicas: 1 selector: matchLabels: app: helidon-metrics template: metadata: labels: app: helidon-metrics version: v1 spec: containers: - name: helidon-metrics image: helidon-metrics-se imagePullPolicy: IfNotPresent ports: - containerPort: 8080 A service of type NodePort that serves the default routes on port 8080 . An annotation that will allow Prometheus to discover and scrape the application pod. A deployment with one replica of a pod. <markup lang=\"bash\" title=\"Create and deploy the application into Kubernetes:\" >kubectl apply -f ./metrics.yaml <markup lang=\"bash\" title=\"Get the service information:\" >kubectl get service/helidon-metrics <markup lang=\"bash\" >NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE helidon-metrics NodePort 10.99.159.2 &lt;none&gt; 8080:31143/TCP 8s A service of type NodePort that serves the default routes on port 31143 . <markup lang=\"bash\" title=\"Verify the metrics endpoint using port 30116 , your port will likely be different:\" >curl http://localhost:31143/metrics Leave the application running in Kubernetes since it will be used for Prometheus integration. Prometheus Integration The metrics service that you just deployed into Kubernetes is already annotated with prometheus.io/scrape: . This will allow Prometheus to discover the service and scrape the metrics. In this exercise, you will install Prometheus into Kubernetes, then verify that it discovered the Helidon metrics in your application. <markup lang=\"bash\" title=\"Install Prometheus and wait until the pod is ready:\" >helm install stable/prometheus --name metrics export POD_NAME=$(kubectl get pods --namespace default -l \"app=prometheus,component=server\" -o jsonpath=\"{.items[0].metadata.name}\") kubectl get pod $POD_NAME You will see output similar to the following. Repeat the kubectl get pod command until you see 2/2 and Running . This may take up to one minute. <markup lang=\"bash\" >metrics-prometheus-server-5fc5dc86cb-79lk4 2/2 Running 0 46s <markup lang=\"bash\" title=\"Create a port-forward so you can access the server URL:\" >kubectl --namespace default port-forward $POD_NAME 7090:9090 Now open your browser and navigate to http://localhost:7090/targets . Search for helidon on the page and you will see your Helidon application as one of the Prometheus targets. Final Cleanup You can now delete the Kubernetes resources that were just created during this example. <markup lang=\"bash\" title=\"Delete the Prometheus Kubernetes resources:\" >helm delete --purge metrics <markup lang=\"bash\" title=\"Delete the application Kubernetes resources:\" >kubectl delete -f ./metrics.yaml ",
            "title": "Integration with Kubernetes and Prometheus"
        },
        {
            "location": "/se/guides/05_metrics",
            "text": " This guide demonstrated how to use metrics in a Helidon SE application using various combinations of metrics and scopes. Access metrics for all three scopes: base, vendor, and application Configure metrics that are updated by the application when an application REST endpoint is invoked Configure a Gauge metric Integrate Helidon metrics with Kubernetes and Prometheus Refer to the following references for additional information: MicroProfile Metrics specification at https://github.com/eclipse/microprofile-metrics/releases/tag/1.1 MicroProfile Metrics Javadoc at https://javadoc.io/doc/org.eclipse.microprofile.metrics/microprofile-metrics-api/1.1.1 Helidon Javadoc at https://helidon.io/docs/latest/apidocs/index.html?overview-summary.html ",
            "title": "Summary"
        },
        {
            "location": "/se/guides/05_metrics",
            "text": " For this 30 minute tutorial, you will need the following: <div class=\"table__overflow elevation-1 flex sm7 \"> A Helidon SE Application You can use your own application or use the Helidon SE Quickstart to create a sample application. Java&#160;SE&#160;11 ( Open&#160;JDK&#160;11 ) Helidon requires Java 11+. Maven 3.6.1+ Helidon requires Maven 3.6.1+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop ). Helm To manage Kubernetes applications. <markup lang=\"bash\" title=\"Verify Prerequisites\" >java -version mvn --version docker --version kubectl version --short <markup lang=\"bash\" title=\"Setting JAVA_HOME\" ># On Mac export JAVA_HOME=`/usr/libexec/java_home -v 11` # On Linux # Use the appropriate path to your JDK export JAVA_HOME=/usr/lib/jvm/jdk-11 Create a Sample Helidon SE Project Use the Helidon SE Maven archetype to create a simple project that can be used for the examples in this guide. <markup lang=\"bash\" title=\"Run the Maven archetype\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-se \\ -DarchetypeVersion=2.5.4 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-se \\ -Dpackage=io.helidon.examples.quickstart.se Using the Built-In Metrics Helidon provides three scopes of metrics: base, vendor, and application. Here are the metric endpoints: /metrics/base - Base metrics data as specified by the MicroProfile Metrics specification. /metrics/vendor - Helidon-specific metrics data. /metrics/application - Application-specific metrics data. The /metrics endpoint will return data for all scopes. The built-in metrics fall into three categories: JVM behavior (in the base registry), basic key performance indicators for request handling (in the vendor registry), and thread pool utilization (also in the vendor registry). A later section describes the key performance indicator metrics in detail. The following example demonstrates how to use the other built-in metrics. All examples are executed from the root directory of your project (helidon-quickstart-se). The generated source code is already configured for both metrics and health checks, but the following example removes health checks. <markup lang=\"xml\" title=\"Notice that the metrics dependency is already in the project&#8217;s pom.xml file:\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"java\" title=\"Replace the Main.createRouting method with the following code:\" > private static Routing createRouting(Config config) { GreetService greetService = new GreetService(config); return Routing.builder() .register(MetricsSupport.create()) .register(\"/greet\", greetService) .build(); } Register the built-in base and vendor metrics. <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-se.jar Metrics can be returned in either text format (the default), or JSON. The text format uses OpenMetrics (Prometheus) Text Format, see https://prometheus.io/docs/instrumenting/exposition_formats/#text-format-details . <markup lang=\"bash\" title=\"Verify the metrics endpoint in a new terminal window:\" >curl http://localhost:8080/metrics <markup lang=\"text\" title=\"Text response:\" ># TYPE base:classloader_current_loaded_class_count counter # HELP base:classloader_current_loaded_class_count Displays the number of classes that are currently loaded in the Java virtual machine. base:classloader_current_loaded_class_count 7511 # TYPE base:classloader_total_loaded_class_count counter # HELP base:classloader_total_loaded_class_count Displays the total number of classes that have been loaded since the Java virtual machine has started execution. base:classloader_total_loaded_class_count 7512 ... You can get the same data in JSON format. <markup lang=\"bash\" title=\"Verify the metrics endpoint with an HTTP accept header:\" >curl -H \"Accept: application/json\" http://localhost:8080/metrics <markup lang=\"json\" title=\"JSON response:\" >{ \"base\": { \"classloader.currentLoadedClass.count\": 7534, \"classloader.totalLoadedClass.count\": 7538, \"classloader.totalUnloadedClass.count\": 1, \"cpu.availableProcessors\": 4, \"cpu.systemLoadAverage\": 2.83349609375, \"gc.PS MarkSweep.count\": 2, \"gc.PS MarkSweep.time\": 77, \"gc.PS Scavenge.count\": 5, \"gc.PS Scavenge.time\": 37, \"jvm.uptime\": 727588, \"memory.committedHeap\": 284164096, \"memory.maxHeap\": 3817865216, \"memory.usedHeap\": 53283088, \"thread.count\": 44, \"thread.daemon.count\": 35, \"thread.max.count\": 44 }, \"vendor\": { \"executor-service.active-count;poolIndex=0;supplierCategory=helidon-thread-pool-2;supplierIndex=0\": 0, \"executor-service.completed-task-count;poolIndex=0;supplierCategory=helidon-thread-pool-2;supplierIndex=0\": 0, \"executor-service.largest-pool-size;poolIndex=0;supplierCategory=helidon-thread-pool-2;supplierIndex=0\": 5, \"executor-service.pool-size;poolIndex=0;supplierCategory=helidon-thread-pool-2;supplierIndex=0\": 5, \"executor-service.queue.remaining-capacity;poolIndex=0;supplierCategory=helidon-thread-pool-2;supplierIndex=0\": 10000, \"executor-service.queue.size;poolIndex=0;supplierCategory=helidon-thread-pool-2;supplierIndex=0\": 0, \"executor-service.task-count;poolIndex=0;supplierCategory=helidon-thread-pool-2;supplierIndex=0\": 0, \"requests.count\": 6, \"requests.meter\": { \"count\": 6, \"meanRate\": 0.008275992296704147, \"oneMinRate\": 0.01576418632772332, \"fiveMinRate\": 0.006695060022357365, \"fifteenMinRate\": 0.0036382699664488415 } } } You can get a single metric by specifying the name in the URL path. <markup lang=\"bash\" title=\"Get the Helidon requests.meter metric:\" >curl -H \"Accept: application/json\" http://localhost:8080/metrics/vendor/requests.meter <markup lang=\"json\" title=\"JSON response:\" >{ \"requests.meter\": { \"count\": 6, \"meanRate\": 0.008275992296704147, \"oneMinRate\": 0.01576418632772332, \"fiveMinRate\": 0.006695060022357365, \"fifteenMinRate\": 0.0036382699664488415 } } You cannot get the individual fields of a metric. For example, you cannot target http://localhost:8080/metrics/vendor/requests.meter.count . The base metrics illustrated above provide some insight into the behavior of the JVM in which the server runs. The vendor metrics shown above appear in two groups: Helidon thread pools Helidon uses these thread pools for its own internal work, and your application can also use Helidon-managed thread pools if it needs to do work asynchronously. (See this example .) The metrics in this group show information about the thread pools which can help you assess how efficiently they are utilized. Helidon uses tags to distinguish the metrics which describe different thread pools. In some cases the specific metrics exposed depend on the particular type of thread pool. basic key performance indicators These metrics give an idea of the request traffic the server is handling. See the later section for more information on the basic and extended key performance indicator metrics. Controlling Metrics Behavior By adding a metrics section to your application configuration you can control how the Helidon metrics subsystem behaves in any of several ways. Disable metrics subsystem entirely . Identify groups of metrics to control: registered by a particular component , and by metric registry (application, vendor, and base) and within a registry by metric names which match patterns you provide. Select whether to collect extended key performance indicator metrics . Your Helidon SE application can also control metrics processing programmatically as described in the following sections. Disabling Metrics Subsystem Entirely By default, if your application depends on the helidon-metrics Maven module then full-featured metrics are enabled. You can disable the metrics subsystem entirely using configuration: <markup lang=\"properties\" title=\"Configuration properties file disabling metrics\" >metrics.enabled=false A Helidon SE application can disable metrics processing programmatically. <markup lang=\"java\" title=\"Disable all metrics behavior\" >import io.helidon.metrics.api.MetricsSettings; import io.helidon.metrics.serviceapi.MetricsSupport; import io.helidon.metrics.api.RegistryFactory; ... MetricsSettings metricsSettings = MetricsSettings.builder() .enabled(false) .build(); MetricsSupport metricsSupport = MetricsSupport.create(metricsSettings); RegistryFactory registryFactory = RegistryFactory.getInstance(metricsSettings); Create a MetricsSettings instance (via its Builder ) with the metrics subsystem disabled. Get a MetricsSupport service (usable in setting routing rules) that responds to the /metrics endpoint with 404 and an explanatory message. Get a RegistryFactory instance that provides MetricRegistry instances which register no-op metric objects (counters, timers, etc.). These builders and interfaces also have methods which accept Config objects representing the metrics node from the application configuration. With metrics processing disabled, Helidon never updates any metrics and the /metrics endpoints respond with 404 plus a message that the metrics subsystem is disabled. Enabling and Disabling Metrics Usage by a Component Helidon contains several components and integrations which register and update metrics. Depending on how the component is written, you might be able to disable just that component&#8217;s use of metrics: <markup lang=\"properties\" title=\"Configuration properties file disabling a component&#8217;s use of metrics\" >some-component.metrics.enabled=false Check the documentation for a specific component to find out whether that component uses metrics and whether it allows you to disable that use. Your Helidon SE application can disable a metrics-capable component&#8217;s use of metrics programmatically. <markup lang=\"java\" title=\"Disable metrics use in a metrics-capable component\" >import io.helidon.metrics.api.ComponentMetricsSettings; ... ComponentMetricsSettings.Builder componentMetricsSettingsBuilder = ComponentMetricsSettings.builder() .enabled(false); SomeService someService = SomeService.builder() ... .componentMetricsSettings(componentMetricsSettingsBuilder) ... .build(); Create a ComponentMetricsSettings instance (via its Builder ) indicating that metrics usage should be disabled. Create an instance of the service with its metrics usage disabled. If you disable a component&#8217;s use of metrics, Helidon does not register the component&#8217;s metrics in the visible metrics registries nor do those metrics ever update their values. The response from the /metrics endpoint excludes that component&#8217;s metrics. Note that if you disable metrics processing entirely, no component updates its metrics regardless of any component-level metrics settings. Controlling Metrics By Registry Type and Metric Name You can control the collection and reporting of metrics by registry type and metric name within registry type. Disabling All Metrics of a Given Registry Type To disable all metrics in a given registry type (application, vendor, or base), add one or more groups to the configuration: <markup lang=\"properties\" title=\"Disabling base and vendor metrics (properties format)\" >metrics.registries.0.type = base metrics.registries.0.enabled = false metrics.registries.1.type = vendor metrics.registries.1.enabled = false <markup lang=\"yaml\" title=\"Disabling base and vendor metrics (YAML format)\" >metrics: registries: - type: base enabled: false - type: vendor enables: false Controlling Metrics by Metric Name You can be even more selective. Within a registry type you can configure up to two regular expression patterns: one matching metric names to exclude , and one matching metric names to include . Helidon updates and reports a metric only if two conditions hold: the metric name does not match the exclude regex pattern (if you define one), and either there is no include regex pattern, or the metric name matches the include pattern. Caution Make sure any include regex pattern you specify matches all the metric names you want to capture. Suppose your application creates and updates a group of metrics with names such as myapp.xxx.queries , myapp.xxx.creates , myapp.xxx.updates , and myapp.xxx.deletes where xxx can be either supplier or customer . The following example gathers all metrics except those from your application regarding suppliers: <markup lang=\"properties\" title=\"Disabling metrics by name (properties format)\" >metrics.registries.0.type = application metrics.registries.0.filter.exclude = myapp\\.supplier\\..* The following settings select the particular subset of the metrics created in your application code representing updates of customers and suppliers: <markup lang=\"properties\" title=\"Enabling metrics by name (properties format)\" >metrics.registries.0.type = application metrics.registries.0.filter.include = myapp\\..*\\.updates If you use the YAML configuration format, enclose the regex patterns in single-quote marks: <markup lang=\"yaml\" title=\"Enabling metrics by name (YAML format)\" >metrics: registries: - type: application filter: include: 'myapp\\..*\\.updates' The next example selects only your application&#8217;s metrics while excluding those which refer to deletions: <markup lang=\"properties\" title=\"Combining include and exclude \" >metrics.registries.0.type = application metrics.registries.0.filter.include = myapp\\..* metrics.registries.0.filter.exclude = myapp\\..*/deletes Helidon would not update or report the metric myapp.supplier.queries , for example. To include metrics from your application for both updates and queries (but not for other operations), you could change the settings in the previous example to this: <markup >metrics.registries.0.type = application metrics.registries.0.filter.include = myapp\\..*\\.updates|myapp\\..*\\.queries metrics.registries.0.filter.exclude = myapp\\..*/deletes Your Helidon SE application can control the collection and reporting of metrics programmatically as well by preparing these settings objects: RegistryFilterSettings RegistrySettings MetricsSettings and using the resulting MetricsSettings to retrieve a suitable RegistryFactory . <markup lang=\"java\" title=\"Control metrics by registry type and name\" >import io.helidon.metrics.api.RegistryFilterSettings; import org.eclipse.microprofile.metrics.MetricRegistry; ... RegistryFilterSettings appFilterSettings = RegistryFilterSettings.builder() .include(\"myapp\\..*\\.updates\") .build(); RegistrySettings registrySettings = RegistrySettings.builder() .filterSettings(appFilterSettings) .build(); MetricsSettings metricsSettings = MetricsSettings.builder() .registrySettings(MetricRegistry.Type.APPLICATION, appFilterSettings) .build(); RegistryFactory rf = RegistryFactory.getInstance(metricsSettings); MetricRegistry registry = rf.getRegistry(MetricRegistry.Type.APPLICATION); Create the registry filter settings to include only those metrics with names indicating updates. Create the registry settings with that filter. Create the metrics settings, associating the registry settings with the APPLICATION metric registry. Set the overall metrics settings and retrieve a registry factory suitably initialized. Obtain a reference to the APPLICATION registry which is set up to create and report on only metrics with names starting with myapp.updates. . Collecting Basic and Extended Key Performance Indicator (KPI) Metrics Any time you include the Helidon metrics module in your application, Helidon tracks two basic performance indicator metrics: a Counter of all requests received ( requests.count ), and a Meter of all requests received ( requests.meter ). Helidon SE also includes additional, extended KPI metrics which are disabled by default: current number of requests in-flight - a ConcurrentGauge ( requests.inFlight ) of requests currently being processed long-running requests - a Meter ( requests.longRunning ) measuring the rate at which Helidon processes requests which take at least a given amount of time to complete; configurable, defaults to 10000 milliseconds (10 seconds) load - a Meter ( requests.load ) measuring the rate at which requests are worked on (as opposed to received) deferred - a Meter ( requests.deferred ) measuring the rate at which a request&#8217;s processing is delayed after Helidon receives the request You can enable and control these metrics using configuration: <markup lang=\"properties\" title=\"Configuration properties file controlling extended KPI metrics\" >metrics.key-performance-indicators.extended = true metrics.key-performance-indicators.long-running.threshold-ms = 2000 Your Helidon SE application can also control the KPI settings programmatically. <markup lang=\"java\" title=\"Assign KPI metrics behavior from code\" >import io.helidon.metrics.api.KeyPerformanceIndicatorMetricsSettings; import io.helidon.metrics.api.MetricsSettings; import io.helidon.metrics.serviceapi.MetricsSupport; import io.helidon.metrics.api.RegistryFactory; ... KeyPerformanceIndicatorMetricsSettings.Builder kpiSettingsBuilder = KeyPerformanceIndicatorMetricsSettings.builder() .extended(true) .longRunningThresholdMs(2000); MetricsSettings metricsSettings = MetricsSettings.builder() .keyPerformanceIndicatorSettings(kpiSettingsBuilder) .build(); Create a KeyPerformanceIndicatorMetricsSettings instance (via its Builder ) with non-default values. Create a MetricsSettings instance reflecting the KPI settings. Metrics Metadata Each metric has associated metadata that describes: name: The name of the metric. units: The unit of the metric such as time (seconds, millisecond), size (bytes, megabytes), etc. type: The type of metric: Counter , Timer , Meter , Histogram , SimpleTimer , or Gauge . You can get the metadata for any scope, such as /metrics/base , as shown below: <markup lang=\"bash\" title=\"Get the metrics metadata using HTTP OPTIONS method:\" > curl -X OPTIONS -H \"Accept: application/json\" http://localhost:8080/metrics/base <markup lang=\"json\" title=\"JSON response (truncated):\" >{ \"classloader.currentLoadedClass.count\": { \"unit\": \"none\", \"type\": \"counter\", \"description\": \"Displays the number of classes that are currently loaded in the Java virtual machine.\", \"displayName\": \"Current Loaded Class Count\" }, ... \"jvm.uptime\": { \"unit\": \"milliseconds\", \"type\": \"gauge\", \"description\": \"Displays the start time of the Java virtual machine in milliseconds. This attribute displays the approximate time when the Java virtual machine started.\", \"displayName\": \"JVM Uptime\" }, ... \"memory.usedHeap\": { \"unit\": \"bytes\", \"type\": \"gauge\", \"description\": \"Displays the amount of used heap memory in bytes.\", \"displayName\": \"Used Heap Memory\" } } Application-Specific Metrics Data This section demonstrates how to use application-specific metrics and integrate them with Helidon. It is the application&#8217;s responsibility to create and update the metrics at runtime. The application has complete control over when and how each metric is used. For example, an application may use the same counter for multiple methods, or one counter per method. Helidon maintains an application MetricRegistry which is used to manage all of the application metrics. Helidon returns these metrics in response to a /metrics/application REST request. In all of these examples, the scope and lifetime of the metric is at the application-level. Each metric, except Gauge , is updated in response to a REST request and the contents of the metric is cumulative. Counter Metric The Counter metric is a monotonically increasing or decreasing number. The following example will demonstrate how to use a Counter to track the number of times the /cards endpoint is called. <markup lang=\"java\" title=\"Create a new class named GreetingCards with the following code:\" >package io.helidon.examples.quickstart.se; import io.helidon.metrics.RegistryFactory; import io.helidon.webserver.Routing; import io.helidon.webserver.ServerRequest; import io.helidon.webserver.ServerResponse; import io.helidon.webserver.Service; import java.util.Collections; import javax.json.Json; import javax.json.JsonBuilderFactory; import javax.json.JsonObject; import org.eclipse.microprofile.metrics.Counter; import org.eclipse.microprofile.metrics.MetricRegistry; public class GreetingCards implements Service { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); private final Counter cardCounter; GreetingCards() { RegistryFactory metricsRegistry = RegistryFactory.getInstance(); MetricRegistry appRegistry = metricsRegistry.getRegistry(MetricRegistry.Type.APPLICATION); cardCounter = appRegistry.counter(\"cardCount\"); } @Override public void update(Routing.Rules rules) { rules.get(\"/\", this::getDefaultMessageHandler); } private void getDefaultMessageHandler(ServerRequest request, ServerResponse response) { cardCounter.inc(); sendResponse(response, \"Here are some cards ...\"); } private void sendResponse(ServerResponse response, String msg) { JsonObject returnObject = JSON.createObjectBuilder().add(\"message\", msg).build(); response.send(returnObject); } } Import metrics classes. Declare a Counter member variable. Create and register the Counter metric in the MetricRegistry . This Counter will exist for the lifetime of the application. Increment the count. <markup lang=\"java\" title=\"Update the Main.createRouting method as follows:\" > private static Routing createRouting(Config config) { MetricsSupport metrics = MetricsSupport.create(); GreetService greetService = new GreetService(config); return Routing.builder() .register(JsonSupport.create()) .register(metrics) .register(\"/greet\", greetService) .register(\"/cards\", new GreetingCards()) .build(); } Add the GreetingCards service to the Routing.builder . Helidon will route any REST requests with the /cards root path to the GreetingCards service. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints below:\" >curl http://localhost:8080/cards curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response:\" >{ \"cardCount\": 1 } The count value is one since the method was called once. Meter Metric The Meter metric is used to measure throughput, the number of times an event occurs within a certain time period. When a Meter object is created, its internal clock starts running. That clock is used to calculate the various rates stored this metric. The Meter also includes the count field from the Counter metric. When you mark an event, the count is incremented. The following example marks an event each time the /cards endpoint is called. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.se; import io.helidon.metrics.RegistryFactory; import io.helidon.webserver.Routing; import io.helidon.webserver.ServerRequest; import io.helidon.webserver.ServerResponse; import io.helidon.webserver.Service; import java.util.Collections; import javax.json.Json; import javax.json.JsonBuilderFactory; import javax.json.JsonObject; import org.eclipse.microprofile.metrics.Meter; import org.eclipse.microprofile.metrics.MetricRegistry; public class GreetingCards implements Service { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); private final Meter cardMeter; GreetingCards() { RegistryFactory metricsRegistry = RegistryFactory.getInstance(); MetricRegistry appRegistry = metricsRegistry.getRegistry(MetricRegistry.Type.APPLICATION); cardMeter = appRegistry.meter(\"cardMeter\"); } @Override public void update(Routing.Rules rules) { rules.get(\"/\", this::getDefaultMessageHandler); } private void getDefaultMessageHandler(ServerRequest request, ServerResponse response) { cardMeter.mark(); sendResponse(response, \"Here are some cards ...\"); } private void sendResponse(ServerResponse response, String msg) { JsonObject returnObject = JSON.createObjectBuilder().add(\"message\", msg).build(); response.send(returnObject); } } Import metrics classes. Declare a Meter member variable. Create and register the Meter metric in the MetricRegistry . Mark the occurrence of an event. Note: you can specify a count parameter such as mark(100) to mark multiple events. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints below:\" >curl http://localhost:8080/cards curl http://localhost:8080/cards curl http://localhost:8080/cards curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response:\" >{ \"cardMeter\": { \"count\": 3, \"meanRate\": 0.17566568722974535, \"oneMinRate\": 0.04413761384322548, \"fiveMinRate\": 0.009753212003766951, \"fifteenMinRate\": 0.0033056752265846544 } } The Meter metric has a set of fields to show various rates, along with the count. The /cards endpoint was called three times. Timer Metric (See also Simple timer metric .) The Timer metric aggregates durations, provides timing statistics, and includes throughput statistics using an internal Meter metric. The Timer measures duration in nanoseconds. In the following example, a Timer metric is used to measure the duration of a method&#8217;s execution. Whenever the REST /cards endpoint is called, the Timer will be updated with additional timing information. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.se; import io.helidon.metrics.RegistryFactory; import io.helidon.webserver.Routing; import io.helidon.webserver.ServerRequest; import io.helidon.webserver.ServerResponse; import io.helidon.webserver.Service; import java.util.Collections; import javax.json.Json; import javax.json.JsonBuilderFactory; import javax.json.JsonObject; import org.eclipse.microprofile.metrics.MetricRegistry; import org.eclipse.microprofile.metrics.Timer; public class GreetingCards implements Service { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); private final Timer cardTimer; GreetingCards() { RegistryFactory metricsRegistry = RegistryFactory.getInstance(); MetricRegistry appRegistry = metricsRegistry.getRegistry(MetricRegistry.Type.APPLICATION); cardTimer = appRegistry.timer(\"cardTimer\"); } @Override public void update(Routing.Rules rules) { rules.get(\"/\", this::getDefaultMessageHandler); } private void getDefaultMessageHandler(ServerRequest request, ServerResponse response) { Timer.Context timerContext = cardTimer.time(); sendResponse(response, \"Here are some cards ...\"); response.whenSent().thenAccept(res -&gt; timerContext.stop()); } private void sendResponse(ServerResponse response, String msg) { JsonObject returnObject = JSON.createObjectBuilder().add(\"message\", msg).build(); response.send(returnObject); } } Import metrics classes. Declare a Timer member variable. Create and register the Timer metric in the MetricRegistry . Start the timer. Stop the timer. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints below:\" >curl http://localhost:8080/cards curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response:\" >{ \"cardTimer\": { \"count\": 1, \"meanRate\": 0.03843465264149663, \"oneMinRate\": 0.014712537947741825, \"fiveMinRate\": 0.0032510706679223173, \"fifteenMinRate\": 0.0011018917421948848, \"min\": 40876527, \"max\": 40876527, \"mean\": 40876527, \"stddev\": 0.0, \"p50\": 40876527, \"p75\": 40876527, \"p95\": 40876527, \"p98\": 40876527, \"p99\": 40876527, \"p999\": 40876527 } } These are the same fields used by Meter . These are the Timer fields that measure the duration of the getDefaultMessageHandler method. Some of these values will change each time you invoke the /cards endpoint. Histogram Metric The Histogram metric calculates the distribution of a set of values within ranges. This metric does not relate to time at all. The following example will record a set of random numbers in a Histogram metric when the /cards endpoint is invoked. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.se; import io.helidon.metrics.RegistryFactory; import io.helidon.webserver.Routing; import io.helidon.webserver.ServerRequest; import io.helidon.webserver.ServerResponse; import io.helidon.webserver.Service; import java.util.Collections; import java.util.Random; import javax.json.Json; import javax.json.JsonBuilderFactory; import javax.json.JsonObject; import org.eclipse.microprofile.metrics.Histogram; import org.eclipse.microprofile.metrics.MetricRegistry; public class GreetingCards implements Service { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); private final Histogram cardHistogram; GreetingCards() { RegistryFactory metricsRegistry = RegistryFactory.getInstance(); MetricRegistry appRegistry = metricsRegistry.getRegistry(MetricRegistry.Type.APPLICATION); cardHistogram = appRegistry.histogram(\"cardHistogram\"); } @Override public void update(Routing.Rules rules) { rules.get(\"/\", this::getDefaultMessageHandler); } private void getDefaultMessageHandler(ServerRequest request, ServerResponse response) { Random r = new Random(); for (int i = 0; i &lt; 1000; i++) { cardHistogram.update(1 + r.nextInt(25)); } sendResponse(response, \"Here are some cards ...\"); } private void sendResponse(ServerResponse response, String msg) { JsonObject returnObject = JSON.createObjectBuilder().add(\"message\", msg).build(); response.send(returnObject); } } Import metrics classes. Declare a Histogram member variable. Create and register the Histogram metric in the MetricRegistry . Update the Histogram metric with a random number. Loop, loading the histogram with numbers. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints below:\" >curl http://localhost:8080/cards curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response:\" >{ \"cardHistogram\": { \"count\": 1000, \"min\": 1, \"max\": 25, \"mean\": 12.743999999999915, \"stddev\": 7.308793607702962, \"p50\": 13.0, \"p75\": 19.0, \"p95\": 24.0, \"p98\": 25.0, \"p99\": 25.0, \"p999\": 25.0 } } This is the histogram data. Some of these values will change each time you invoke the /cards endpoint. Gauge Metric The Gauge metric measures a discreet value at a point in time, such as a temperature. The metric is not normally tied to a REST endpoint, rather it should be registered during application startup. When the /metrics/application endpoint is invoked, Helidon will call the getValue method of each registered Gauge . The following example demonstrates how a Gauge is used to get the current temperature. <markup lang=\"java\" title=\"Add new imports to Main.java and replace the Main.createRouting method with the following code:\" >import io.helidon.metrics.RegistryFactory; import java.util.Random; import org.eclipse.microprofile.metrics.Gauge; import org.eclipse.microprofile.metrics.MetricRegistry; ... private static Routing createRouting(Config config) { MetricsSupport metrics = MetricsSupport.create(); RegistryFactory metricsRegistry = RegistryFactory.getInstance(); MetricRegistry appRegistry = metricsRegistry.getRegistry(MetricRegistry.Type.APPLICATION); appRegistry.register(\"temperature\", (Gauge&lt;Integer&gt;)() -&gt; new Random().nextInt(100)); GreetService greetService = new GreetService(config); return Routing.builder() .register(JsonSupport.create()) .register(metrics) // Metrics at \"/metrics\" .register(\"/greet\", greetService) .register(\"/cards\", new GreetingCards()) .build(); } Register the Gauge , providing a lambda function that will return a random temperature. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code to use the Counter metric which will simplify the JSON output:\" >package io.helidon.examples.quickstart.se; import io.helidon.metrics.RegistryFactory; import io.helidon.webserver.Routing; import io.helidon.webserver.ServerRequest; import io.helidon.webserver.ServerResponse; import io.helidon.webserver.Service; import java.util.Collections; import javax.json.Json; import javax.json.JsonBuilderFactory; import javax.json.JsonObject; import org.eclipse.microprofile.metrics.Counter; import org.eclipse.microprofile.metrics.MetricRegistry; public class GreetingCards implements Service { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); private final Counter cardCounter; GreetingCards() { RegistryFactory metricsRegistry = RegistryFactory.getInstance(); MetricRegistry appRegistry = metricsRegistry.getRegistry(MetricRegistry.Type.APPLICATION); cardCounter = appRegistry.counter(\"cardCount\"); } @Override public void update(Routing.Rules rules) { rules.get(\"/\", this::getDefaultMessageHandler); } private void getDefaultMessageHandler(ServerRequest request, ServerResponse response) { cardCounter.inc(); sendResponse(response, \"Here are some cards ...\"); } private void sendResponse(ServerResponse response, String msg) { JsonObject returnObject = JSON.createObjectBuilder().add(\"message\", msg).build(); response.send(returnObject); } } <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints below:\" >curl http://localhost:8080/cards curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response from /metrics/application :\" >{ \"cardCount\": 1, \"temperature\": 11 } The current temperature is returned. Invoke the /metrics/application endpoint again and you should get a different value. Simple Timer Metric The SimpleTimer metric counts invocations and accumulates duration (in seconds). In the following example, a SimpleTimer metric is used to count and measure the duration of a method&#8217;s execution. Whenever the REST /cards endpoint is called, the SimpleTimer updates its count and total elapsed time. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.se; import io.helidon.metrics.RegistryFactory; import io.helidon.webserver.Routing; import io.helidon.webserver.ServerRequest; import io.helidon.webserver.ServerResponse; import io.helidon.webserver.Service; import java.util.Collections; import javax.json.Json; import javax.json.JsonBuilderFactory; import javax.json.JsonObject; import org.eclipse.microprofile.metrics.MetricRegistry; import org.eclipse.microprofile.metrics.SimpleTimer; public class GreetingCards implements Service { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); private final SimpleTimer cardTimer; GreetingCards() { RegistryFactory metricsRegistry = RegistryFactory.getInstance(); MetricRegistry appRegistry = metricsRegistry.getRegistry(MetricRegistry.Type.APPLICATION); cardTimer = appRegistry.simpleTimer(\"cardSimpleTimer\"); } @Override public void update(Routing.Rules rules) { rules.get(\"/\", this::getDefaultMessageHandler); } private void getDefaultMessageHandler(ServerRequest request, ServerResponse response) { cardTimer.time(() -&gt; sendResponse(response, \"Here are some cards ...\")); } private void sendResponse(ServerResponse response, String msg) { JsonObject returnObject = JSON.createObjectBuilder().add(\"message\", msg).build(); response.send(returnObject); } } Import metrics classes, particularly the SimpleTimer interface for this example. Declare a SimpleTimer member variable. Create and register the SimpleTimer metric in the MetricRegistry . Wrap the business logic in the simple timer&#8217;s time method which updates the count and the total elapsed time. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints below:\" >curl http://localhost:8080/cards curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response:\" >{ \"cardSimpleTimer\": { \"count\":1, \"elapsedTime\":0.034274025 } } How many times the getDefaultMessageHandler method ran. Cumulative time spent in the getDefaultMessageHandler method during its executions. Integration with Kubernetes and Prometheus Kubernetes Integration The following example shows how to integrate the Helidon SE application with Kubernetes. <markup lang=\"bash\" title=\"Stop the application and build the docker image:\" >docker build -t helidon-metrics-se . <markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named metrics.yaml , with the following content:\" >kind: Service apiVersion: v1 metadata: name: helidon-metrics labels: app: helidon-metrics annotations: prometheus.io/scrape: 'true' spec: type: NodePort selector: app: helidon-metrics ports: - port: 8080 targetPort: 8080 name: http --- kind: Deployment apiVersion: apps/v1 metadata: name: helidon-metrics spec: replicas: 1 selector: matchLabels: app: helidon-metrics template: metadata: labels: app: helidon-metrics version: v1 spec: containers: - name: helidon-metrics image: helidon-metrics-se imagePullPolicy: IfNotPresent ports: - containerPort: 8080 A service of type NodePort that serves the default routes on port 8080 . An annotation that will allow Prometheus to discover and scrape the application pod. A deployment with one replica of a pod. <markup lang=\"bash\" title=\"Create and deploy the application into Kubernetes:\" >kubectl apply -f ./metrics.yaml <markup lang=\"bash\" title=\"Get the service information:\" >kubectl get service/helidon-metrics <markup lang=\"bash\" >NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE helidon-metrics NodePort 10.99.159.2 &lt;none&gt; 8080:31143/TCP 8s A service of type NodePort that serves the default routes on port 31143 . <markup lang=\"bash\" title=\"Verify the metrics endpoint using port 30116 , your port will likely be different:\" >curl http://localhost:31143/metrics Leave the application running in Kubernetes since it will be used for Prometheus integration. Prometheus Integration The metrics service that you just deployed into Kubernetes is already annotated with prometheus.io/scrape: . This will allow Prometheus to discover the service and scrape the metrics. In this exercise, you will install Prometheus into Kubernetes, then verify that it discovered the Helidon metrics in your application. <markup lang=\"bash\" title=\"Install Prometheus and wait until the pod is ready:\" >helm install stable/prometheus --name metrics export POD_NAME=$(kubectl get pods --namespace default -l \"app=prometheus,component=server\" -o jsonpath=\"{.items[0].metadata.name}\") kubectl get pod $POD_NAME You will see output similar to the following. Repeat the kubectl get pod command until you see 2/2 and Running . This may take up to one minute. <markup lang=\"bash\" >metrics-prometheus-server-5fc5dc86cb-79lk4 2/2 Running 0 46s <markup lang=\"bash\" title=\"Create a port-forward so you can access the server URL:\" >kubectl --namespace default port-forward $POD_NAME 7090:9090 Now open your browser and navigate to http://localhost:7090/targets . Search for helidon on the page and you will see your Helidon application as one of the Prometheus targets. Final Cleanup You can now delete the Kubernetes resources that were just created during this example. <markup lang=\"bash\" title=\"Delete the Prometheus Kubernetes resources:\" >helm delete --purge metrics <markup lang=\"bash\" title=\"Delete the application Kubernetes resources:\" >kubectl delete -f ./metrics.yaml Summary This guide demonstrated how to use metrics in a Helidon SE application using various combinations of metrics and scopes. Access metrics for all three scopes: base, vendor, and application Configure metrics that are updated by the application when an application REST endpoint is invoked Configure a Gauge metric Integrate Helidon metrics with Kubernetes and Prometheus Refer to the following references for additional information: MicroProfile Metrics specification at https://github.com/eclipse/microprofile-metrics/releases/tag/1.1 MicroProfile Metrics Javadoc at https://javadoc.io/doc/org.eclipse.microprofile.metrics/microprofile-metrics-api/1.1.1 Helidon Javadoc at https://helidon.io/docs/latest/apidocs/index.html?overview-summary.html ",
            "title": "What You Need"
        },
        {
            "location": "/se/vault/01_vault",
            "text": " HashiCorp Vault is a commonly used Vault in many microservices. The APIs are REST-based and Helidon implements them using reactive client. Vault integration supports the following: Secret Engines : Key/Value version 2, Key/Value version 1, Cubbyhole, PKI, Transit, Database Authentication Methods : Token, Kubernetes (k8s), AppRole Other Sys Operations and Configurations ",
            "title": "preambule"
        },
        {
            "location": "/se/vault/01_vault",
            "text": " Helidon Vault support is still experimental and not intended for production use. APIs and features have not yet been fully tested and are subject to change. ",
            "title": "Experimental"
        },
        {
            "location": "/se/vault/01_vault",
            "text": " Each of these features is implemented as a separate module, with the Vault class binding them together. In Helidon MP, with injection, this binding is done automatically, and you can simply inject your favorite secret engine. In addition to these features, Vault itself can be authenticated as follows: Token authentication - token is configured when connecting to Vault AppRole authentication - AppRole ID and secret ID are configured, integration exchanges these for a temporary token that is used to connect to Vault K8s authentication - the k8s JWT token is discovered on current node and used to obtain a temporary token that is used to connect to Vault ",
            "title": "Sys Operations"
        },
        {
            "location": "/se/vault/01_vault",
            "text": " New secret engines and authentication methods can be implemented quite easily, as the integration is based on service providers (using ServiceLoader). This gives us (or you, as the users) the option to add new secret engines and/or authentication methods without adding a plethora of methods to the Vault class. See the following SPIs: <markup lang=\"properties\" >io.helidon.integrations.vault.spi.AuthMethodProvider io.helidon.integrations.vault.spi.SecretsEngineProvider io.helidon.integrations.vault.spi.SysProvider io.helidon.integrations.vault.spi.VaultAuth io.helidon.integrations.vault.spi.InjectionProvider ",
            "title": "Extensibility"
        },
        {
            "location": "/se/vault/01_vault",
            "text": " The following is a list of maven coordinates of all Vault modules available: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.vault&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-vault&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.vault.auths&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-vault-auths-token&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.vault.auths&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-vault-auths-approle&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.vault.auths&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-vault-auths-k8s&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.vault.secrets&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-vault-secrets-kv1&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.vault.secrets&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-vault-secrets-kv2&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.vault.secrets&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-vault-secrets-cubbyhole&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.vault.secrets&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-vault-secrets-transit&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.vault.secrets&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-vault-secrets-database&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.vault.sys&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-vault-sys&lt;/artifactId&gt; &lt;/dependency&gt; Configuration to connect to Vault. Authenticating using Token: vault: address: \"http://localhost:8200\" token: \"my-token\" Authenticating using AppRole: vault: auth: app-role: role-id: \"app-role-id\" secret-id: app-role-secret-id Authenticating using Kubernetes: vault: auth: k8s: token-role: \"my-role\" The token role must be configured in Vault Minimal configuration to connect to Vault: <markup lang=\"yaml\" >vault: token: \"my-token\" address: \"http://localhost:8200\" Code to set up Vault and obtain a specific secret engine: <markup lang=\"java\" >Vault vault = Vault.builder() .config(config.get(\"vault\")) .build(); Kv2SecretsRx secrets = vault.secrets(Kv2SecretsRx.ENGINE); Similar code can be used for any secret engine available: Kv2SecretsRx - Key/Value Version 2 Secrets (versioned secrets, default) Kv1SecretsRx - Key/Value Version 1 Secrets (unversioned secrets, legacy) CubbyholeSecretsRx - Cubbyhole secrets (token bound secrets) DbSecretsRx - Database secrets (for generating temporary DB credentials) PkiSecretsRx - PKI secrets (for generating keys and X.509 certificates) TransitSecretsRx - Transit operations (encryption, signatures, HMAC) Code to obtain a specific authentication method: <markup lang=\"java\" >K8sAuthRx auth = vault.auth(K8sAuthRx.AUTH_METHOD) Similar code can be used for any authentication method available: AppRoleAuthRx - AppRole authentication method (management operations) K8sAuthRx - Kubernetes authentication method (management operations) TokenAuthRx - Token authentication method (management operations) Code to get the Sys operations of Vault: <markup lang=\"java\" >SysRx sys = vault.sys(SysRx.API); ",
            "title": "Modules"
        },
        {
            "location": "/se/vault/01_vault",
            "text": " Cubbyhole secrets engine operations: <markup lang=\"java\" >@Override public void update(Routing.Rules rules) { rules.get(\"/create\", this::createSecrets) .get(\"/secrets/{path:.*}\", this::getSecret); } private void createSecrets(ServerRequest req, ServerResponse res) { secrets.create(\"first/secret\", Map.of(\"key\", \"secretValue\")) .thenAccept(ignored -&gt; res.send(\"Created secret on path /first/secret\")) .exceptionally(res::send); } private void getSecret(ServerRequest req, ServerResponse res) { String path = req.path().param(\"path\"); secrets.get(path) .thenAccept(secret -&gt; { if (secret.isPresent()) { // using toString so we do not need to depend on JSON-B res.send(secret.get().values().toString()); } else { res.status(Http.Status.NOT_FOUND_404); res.send(); } }) .exceptionally(res::send); } Create a secret from request entity. Get the secret on a specified path. ",
            "title": "Cubbyhole secrets"
        },
        {
            "location": "/se/vault/01_vault",
            "text": " Key/Value version 1 secrets engine operations: <markup lang=\"java\" >@Override public void update(Routing.Rules rules) { rules.get(\"/enable\", this::enableEngine) .get(\"/create\", this::createSecrets) .get(\"/secrets/{path:.*}\", this::getSecret) .delete(\"/secrets/{path:.*}\", this::deleteSecret) .get(\"/disable\", this::disableEngine); } private void disableEngine(ServerRequest req, ServerResponse res) { sys.disableEngine(Kv1SecretsRx.ENGINE) .thenAccept(ignored -&gt; res.send(\"KV1 Secret engine disabled\")) .exceptionally(res::send); } private void enableEngine(ServerRequest req, ServerResponse res) { sys.enableEngine(Kv1SecretsRx.ENGINE) .thenAccept(ignored -&gt; res.send(\"KV1 Secret engine enabled\")) .exceptionally(res::send); } private void createSecrets(ServerRequest req, ServerResponse res) { secrets.create(\"first/secret\", Map.of(\"key\", \"secretValue\")) .thenAccept(ignored -&gt; res.send(\"Created secret on path /first/secret\")) .exceptionally(res::send); } private void deleteSecret(ServerRequest req, ServerResponse res) { String path = req.path().param(\"path\"); secrets.delete(path) .thenAccept(ignored -&gt; res.send(\"Deleted secret on path \" + path)); } private void getSecret(ServerRequest req, ServerResponse res) { String path = req.path().param(\"path\"); secrets.get(path) .thenAccept(secret -&gt; { if (secret.isPresent()) { // using toString so we do not need to depend on JSON-B res.send(secret.get().values().toString()); } else { res.status(Http.Status.NOT_FOUND_404); res.send(); } }) .exceptionally(res::send); } Disable the secrets engine on the default path. Enable the secrets engine on the default path. Create a secret from request entity. Delete the secret on a specified path. Get the secret on a specified path. ",
            "title": "KV1 Secrets"
        },
        {
            "location": "/se/vault/01_vault",
            "text": " Key/Value version 2 secrets engine operations: <markup lang=\"java\" >@Override public void update(Routing.Rules rules) { rules.get(\"/create\", this::createSecrets) .get(\"/secrets/{path:.*}\", this::getSecret) .delete(\"/secrets/{path:.*}\", this::deleteSecret); } private void createSecrets(ServerRequest req, ServerResponse res) { secrets.create(\"first/secret\", Map.of(\"key\", \"secretValue\")) .thenAccept(ignored -&gt; res.send(\"Created secret on path /first/secret\")) .exceptionally(res::send); } private void deleteSecret(ServerRequest req, ServerResponse res) { String path = req.path().param(\"path\"); secrets.deleteAll(path) .thenAccept(ignored -&gt; res.send(\"Deleted secret on path \" + path)); } private void getSecret(ServerRequest req, ServerResponse res) { String path = req.path().param(\"path\"); secrets.get(path) .thenAccept(secret -&gt; { if (secret.isPresent()) { // using toString so we do not need to depend on JSON-B Kv2Secret kv2Secret = secret.get(); res.send(\"Version \" + kv2Secret.metadata().version() + \", secret: \" + kv2Secret.values().toString()); } else { res.status(Http.Status.NOT_FOUND_404); res.send(); } }) .exceptionally(res::send); } Create a secret from request entity. Delete the secret on a specified path. Get the secret on a specified path. ",
            "title": "KV2 Secrets"
        },
        {
            "location": "/se/vault/01_vault",
            "text": " Transit secrets engine operations: <markup lang=\"bash\" >@Override public void update(Routing.Rules rules) { rules.get(\"/enable\", this::enableEngine) .get(\"/keys\", this::createKeys) .delete(\"/keys\", this::deleteKeys) .get(\"/batch\", this::batch) .get(\"/encrypt/{text:.*}\", this::encryptSecret) .get(\"/decrypt/{text:.*}\", this::decryptSecret) .get(\"/sign\", this::sign) .get(\"/hmac\", this::hmac) .get(\"/verify/sign/{text:.*}\", this::verify) .get(\"/verify/hmac/{text:.*}\", this::verifyHmac) .get(\"/disable\", this::disableEngine); } private void enableEngine(ServerRequest req, ServerResponse res) { sys.enableEngine(TransitSecretsRx.ENGINE) .thenAccept(ignored -&gt; res.send(\"Transit Secret engine enabled\")) .exceptionally(res::send); } private void disableEngine(ServerRequest req, ServerResponse res) { sys.disableEngine(TransitSecretsRx.ENGINE) .thenAccept(ignored -&gt; res.send(\"Transit Secret engine disabled\")) .exceptionally(res::send); } private void createKeys(ServerRequest req, ServerResponse res) { CreateKey.Request request = CreateKey.Request.builder() .name(ENCRYPTION_KEY); secrets.createKey(request) .flatMapSingle(ignored -&gt; secrets.createKey(CreateKey.Request.builder() .name(SIGNATURE_KEY) .type(\"rsa-2048\"))) .forSingle(ignored -&gt; res.send(\"Created keys\")) .exceptionally(res::send); } private void deleteKeys(ServerRequest req, ServerResponse res) { secrets.updateKeyConfig(UpdateKeyConfig.Request.builder() .name(ENCRYPTION_KEY) .allowDeletion(true)) .peek(ignored -&gt; System.out.println(\"Updated key config\")) .flatMapSingle(ignored -&gt; secrets.deleteKey(DeleteKey.Request.create(ENCRYPTION_KEY))) .forSingle(ignored -&gt; res.send(\"Deleted key.\")) .exceptionally(res::send); } private void encryptSecret(ServerRequest req, ServerResponse res) { String secret = req.path().param(\"text\"); secrets.encrypt(Encrypt.Request.builder() .encryptionKeyName(ENCRYPTION_KEY) .data(Base64Value.create(secret))) .forSingle(response -&gt; res.send(response.encrypted().cipherText())) .exceptionally(res::send); } private void decryptSecret(ServerRequest req, ServerResponse res) { String encrypted = req.path().param(\"text\"); secrets.decrypt(Decrypt.Request.builder() .encryptionKeyName(ENCRYPTION_KEY) .cipherText(encrypted)) .forSingle(response -&gt; res.send(String.valueOf(response.decrypted().toDecodedString()))) .exceptionally(res::send); } private void hmac(ServerRequest req, ServerResponse res) { secrets.hmac(Hmac.Request.builder() .hmacKeyName(ENCRYPTION_KEY) .data(SECRET_STRING)) .forSingle(response -&gt; res.send(response.hmac())) .exceptionally(res::send); } private void sign(ServerRequest req, ServerResponse res) { secrets.sign(Sign.Request.builder() .signatureKeyName(SIGNATURE_KEY) .data(SECRET_STRING)) .forSingle(response -&gt; res.send(response.signature())) .exceptionally(res::send); } private void verifyHmac(ServerRequest req, ServerResponse res) { String hmac = req.path().param(\"text\"); secrets.verify(Verify.Request.builder() .digestKeyName(ENCRYPTION_KEY) .data(SECRET_STRING) .hmac(hmac)) .forSingle(response -&gt; res.send(\"Valid: \" + response.isValid())) .exceptionally(res::send); } private void verify(ServerRequest req, ServerResponse res) { String signature = req.path().param(\"text\"); secrets.verify(Verify.Request.builder() .digestKeyName(SIGNATURE_KEY) .data(SECRET_STRING) .signature(signature)) .forSingle(response -&gt; res.send(\"Valid: \" + response.isValid())) .exceptionally(res::send); } Enable the secrets engine on the default path. Disable the secrets engine on the default path. Create the encryption and signature keys. Delete the encryption and signature keys. Encrypt a secret. Decrypt a secret. Create an HMAC for text. Create a signature for text. Verify HMAC. Verify signature. ",
            "title": "Transit secrets"
        },
        {
            "location": "/se/vault/01_vault",
            "text": " In order to use Kubernetes authentication: <markup lang=\"java\" >class K8sExample { private static final String SECRET_PATH = \"k8s/example/secret\"; private static final String POLICY_NAME = \"k8s_policy\"; private final Vault tokenVault; private final String k8sAddress; private final Config config; private final SysRx sys; private Vault k8sVault; K8sExample(Vault tokenVault, Config config) { this.tokenVault = tokenVault; this.sys = tokenVault.sys(SysRx.API); this.k8sAddress = config.get(\"cluster-address\").asString().get(); this.config = config; } public Single&lt;String&gt; run() { /* The following tasks must be run before we authenticate */ return enableK8sAuth() // Now we can login using k8s - must run within a k8s cluster (or you need the k8s configuration files locally) .flatMapSingle(ignored -&gt; workWithSecrets()) // Now back to token based Vault, as we will clean up .flatMapSingle(ignored -&gt; disableK8sAuth()) .map(ignored -&gt; \"k8s example finished successfully.\"); } private Single&lt;ApiResponse&gt; workWithSecrets() { Kv2SecretsRx secrets = k8sVault.secrets(Kv2SecretsRx.ENGINE); return secrets.create(SECRET_PATH, Map.of(\"secret-key\", \"secretValue\", \"secret-user\", \"username\")) .flatMapSingle(ignored -&gt; secrets.get(SECRET_PATH)) .peek(secret -&gt; { if (secret.isPresent()) { Kv2Secret kv2Secret = secret.get(); System.out.println(\"k8s first secret: \" + kv2Secret.value(\"secret-key\")); System.out.println(\"k8s second secret: \" + kv2Secret.value(\"secret-user\")); } else { System.out.println(\"k8s secret not found\"); } }).flatMapSingle(ignored -&gt; secrets.deleteAll(SECRET_PATH)); } private Single&lt;ApiResponse&gt; disableK8sAuth() { return sys.deletePolicy(POLICY_NAME) .flatMapSingle(ignored -&gt; sys.disableAuth(K8sAuthRx.AUTH_METHOD.defaultPath())); } private Single&lt;ApiResponse&gt; enableK8sAuth() { // enable the method return sys.enableAuth(K8sAuthRx.AUTH_METHOD) // add policy .flatMapSingle(ignored -&gt; sys.createPolicy(POLICY_NAME, VaultPolicy.POLICY)) .flatMapSingle(ignored -&gt; tokenVault.auth(K8sAuthRx.AUTH_METHOD) .configure(ConfigureK8s.Request.builder() .address(k8sAddress))) .flatMapSingle(ignored -&gt; tokenVault.auth(K8sAuthRx.AUTH_METHOD) // this must be the same role name as is defined in application.yaml .createRole(CreateRole.Request.builder() .roleName(\"my-role\") .addBoundServiceAccountName(\"*\") .addBoundServiceAccountNamespace(\"default\") .addTokenPolicy(POLICY_NAME))) .peek(ignored -&gt; k8sVault = Vault.create(config)) .map(Function.identity()); } } Run the Kubernetes Authentication by enabling it. Create Kubernetes secrets. Disable Kubernetes authentication if needed. Function used to enable Kubernetes authentication. ",
            "title": "Authentication with Kubernetes"
        },
        {
            "location": "/se/vault/01_vault",
            "text": " Configure the Vault object using token base configuration: <markup lang=\"java\" >Config config = buildConfig(); Vault tokenVault = Vault.builder() .config(config.get(\"vault.token\")) .updateWebClient(it -&gt; it.connectTimeout(5, TimeUnit.SECONDS) .readTimeout(5, TimeUnit.SECONDS)) .build(); Then WebService has to be configured with endpoints routing registered: <markup lang=\"java\" >SysRx sys = tokenVault.sys(SysRx.API); WebServer webServer = WebServer.builder() .config(config.get(\"server\")) .routing(Routing.builder() .register(\"/cubbyhole\", new CubbyholeService(sys, tokenVault.secrets(CubbyholeSecretsRx.ENGINE))) .register(\"/kv1\", new Kv1Service(sys, tokenVault.secrets(Kv1SecretsRx.ENGINE))) .register(\"/kv2\", new Kv2Service(sys, tokenVault.secrets(Kv2SecretsRx.ENGINE))) .register(\"/transit\", new TransitService(sys, tokenVault.secrets(TransitSecretsRx.ENGINE)))) .build() .start() .await(); AppRole-based and Kubernetes authentications are available. Cubbyhole secrets Cubbyhole secrets engine operations: <markup lang=\"java\" >@Override public void update(Routing.Rules rules) { rules.get(\"/create\", this::createSecrets) .get(\"/secrets/{path:.*}\", this::getSecret); } private void createSecrets(ServerRequest req, ServerResponse res) { secrets.create(\"first/secret\", Map.of(\"key\", \"secretValue\")) .thenAccept(ignored -&gt; res.send(\"Created secret on path /first/secret\")) .exceptionally(res::send); } private void getSecret(ServerRequest req, ServerResponse res) { String path = req.path().param(\"path\"); secrets.get(path) .thenAccept(secret -&gt; { if (secret.isPresent()) { // using toString so we do not need to depend on JSON-B res.send(secret.get().values().toString()); } else { res.status(Http.Status.NOT_FOUND_404); res.send(); } }) .exceptionally(res::send); } Create a secret from request entity. Get the secret on a specified path. KV1 Secrets Key/Value version 1 secrets engine operations: <markup lang=\"java\" >@Override public void update(Routing.Rules rules) { rules.get(\"/enable\", this::enableEngine) .get(\"/create\", this::createSecrets) .get(\"/secrets/{path:.*}\", this::getSecret) .delete(\"/secrets/{path:.*}\", this::deleteSecret) .get(\"/disable\", this::disableEngine); } private void disableEngine(ServerRequest req, ServerResponse res) { sys.disableEngine(Kv1SecretsRx.ENGINE) .thenAccept(ignored -&gt; res.send(\"KV1 Secret engine disabled\")) .exceptionally(res::send); } private void enableEngine(ServerRequest req, ServerResponse res) { sys.enableEngine(Kv1SecretsRx.ENGINE) .thenAccept(ignored -&gt; res.send(\"KV1 Secret engine enabled\")) .exceptionally(res::send); } private void createSecrets(ServerRequest req, ServerResponse res) { secrets.create(\"first/secret\", Map.of(\"key\", \"secretValue\")) .thenAccept(ignored -&gt; res.send(\"Created secret on path /first/secret\")) .exceptionally(res::send); } private void deleteSecret(ServerRequest req, ServerResponse res) { String path = req.path().param(\"path\"); secrets.delete(path) .thenAccept(ignored -&gt; res.send(\"Deleted secret on path \" + path)); } private void getSecret(ServerRequest req, ServerResponse res) { String path = req.path().param(\"path\"); secrets.get(path) .thenAccept(secret -&gt; { if (secret.isPresent()) { // using toString so we do not need to depend on JSON-B res.send(secret.get().values().toString()); } else { res.status(Http.Status.NOT_FOUND_404); res.send(); } }) .exceptionally(res::send); } Disable the secrets engine on the default path. Enable the secrets engine on the default path. Create a secret from request entity. Delete the secret on a specified path. Get the secret on a specified path. KV2 Secrets Key/Value version 2 secrets engine operations: <markup lang=\"java\" >@Override public void update(Routing.Rules rules) { rules.get(\"/create\", this::createSecrets) .get(\"/secrets/{path:.*}\", this::getSecret) .delete(\"/secrets/{path:.*}\", this::deleteSecret); } private void createSecrets(ServerRequest req, ServerResponse res) { secrets.create(\"first/secret\", Map.of(\"key\", \"secretValue\")) .thenAccept(ignored -&gt; res.send(\"Created secret on path /first/secret\")) .exceptionally(res::send); } private void deleteSecret(ServerRequest req, ServerResponse res) { String path = req.path().param(\"path\"); secrets.deleteAll(path) .thenAccept(ignored -&gt; res.send(\"Deleted secret on path \" + path)); } private void getSecret(ServerRequest req, ServerResponse res) { String path = req.path().param(\"path\"); secrets.get(path) .thenAccept(secret -&gt; { if (secret.isPresent()) { // using toString so we do not need to depend on JSON-B Kv2Secret kv2Secret = secret.get(); res.send(\"Version \" + kv2Secret.metadata().version() + \", secret: \" + kv2Secret.values().toString()); } else { res.status(Http.Status.NOT_FOUND_404); res.send(); } }) .exceptionally(res::send); } Create a secret from request entity. Delete the secret on a specified path. Get the secret on a specified path. Transit secrets Transit secrets engine operations: <markup lang=\"bash\" >@Override public void update(Routing.Rules rules) { rules.get(\"/enable\", this::enableEngine) .get(\"/keys\", this::createKeys) .delete(\"/keys\", this::deleteKeys) .get(\"/batch\", this::batch) .get(\"/encrypt/{text:.*}\", this::encryptSecret) .get(\"/decrypt/{text:.*}\", this::decryptSecret) .get(\"/sign\", this::sign) .get(\"/hmac\", this::hmac) .get(\"/verify/sign/{text:.*}\", this::verify) .get(\"/verify/hmac/{text:.*}\", this::verifyHmac) .get(\"/disable\", this::disableEngine); } private void enableEngine(ServerRequest req, ServerResponse res) { sys.enableEngine(TransitSecretsRx.ENGINE) .thenAccept(ignored -&gt; res.send(\"Transit Secret engine enabled\")) .exceptionally(res::send); } private void disableEngine(ServerRequest req, ServerResponse res) { sys.disableEngine(TransitSecretsRx.ENGINE) .thenAccept(ignored -&gt; res.send(\"Transit Secret engine disabled\")) .exceptionally(res::send); } private void createKeys(ServerRequest req, ServerResponse res) { CreateKey.Request request = CreateKey.Request.builder() .name(ENCRYPTION_KEY); secrets.createKey(request) .flatMapSingle(ignored -&gt; secrets.createKey(CreateKey.Request.builder() .name(SIGNATURE_KEY) .type(\"rsa-2048\"))) .forSingle(ignored -&gt; res.send(\"Created keys\")) .exceptionally(res::send); } private void deleteKeys(ServerRequest req, ServerResponse res) { secrets.updateKeyConfig(UpdateKeyConfig.Request.builder() .name(ENCRYPTION_KEY) .allowDeletion(true)) .peek(ignored -&gt; System.out.println(\"Updated key config\")) .flatMapSingle(ignored -&gt; secrets.deleteKey(DeleteKey.Request.create(ENCRYPTION_KEY))) .forSingle(ignored -&gt; res.send(\"Deleted key.\")) .exceptionally(res::send); } private void encryptSecret(ServerRequest req, ServerResponse res) { String secret = req.path().param(\"text\"); secrets.encrypt(Encrypt.Request.builder() .encryptionKeyName(ENCRYPTION_KEY) .data(Base64Value.create(secret))) .forSingle(response -&gt; res.send(response.encrypted().cipherText())) .exceptionally(res::send); } private void decryptSecret(ServerRequest req, ServerResponse res) { String encrypted = req.path().param(\"text\"); secrets.decrypt(Decrypt.Request.builder() .encryptionKeyName(ENCRYPTION_KEY) .cipherText(encrypted)) .forSingle(response -&gt; res.send(String.valueOf(response.decrypted().toDecodedString()))) .exceptionally(res::send); } private void hmac(ServerRequest req, ServerResponse res) { secrets.hmac(Hmac.Request.builder() .hmacKeyName(ENCRYPTION_KEY) .data(SECRET_STRING)) .forSingle(response -&gt; res.send(response.hmac())) .exceptionally(res::send); } private void sign(ServerRequest req, ServerResponse res) { secrets.sign(Sign.Request.builder() .signatureKeyName(SIGNATURE_KEY) .data(SECRET_STRING)) .forSingle(response -&gt; res.send(response.signature())) .exceptionally(res::send); } private void verifyHmac(ServerRequest req, ServerResponse res) { String hmac = req.path().param(\"text\"); secrets.verify(Verify.Request.builder() .digestKeyName(ENCRYPTION_KEY) .data(SECRET_STRING) .hmac(hmac)) .forSingle(response -&gt; res.send(\"Valid: \" + response.isValid())) .exceptionally(res::send); } private void verify(ServerRequest req, ServerResponse res) { String signature = req.path().param(\"text\"); secrets.verify(Verify.Request.builder() .digestKeyName(SIGNATURE_KEY) .data(SECRET_STRING) .signature(signature)) .forSingle(response -&gt; res.send(\"Valid: \" + response.isValid())) .exceptionally(res::send); } Enable the secrets engine on the default path. Disable the secrets engine on the default path. Create the encryption and signature keys. Delete the encryption and signature keys. Encrypt a secret. Decrypt a secret. Create an HMAC for text. Create a signature for text. Verify HMAC. Verify signature. Authentication with Kubernetes In order to use Kubernetes authentication: <markup lang=\"java\" >class K8sExample { private static final String SECRET_PATH = \"k8s/example/secret\"; private static final String POLICY_NAME = \"k8s_policy\"; private final Vault tokenVault; private final String k8sAddress; private final Config config; private final SysRx sys; private Vault k8sVault; K8sExample(Vault tokenVault, Config config) { this.tokenVault = tokenVault; this.sys = tokenVault.sys(SysRx.API); this.k8sAddress = config.get(\"cluster-address\").asString().get(); this.config = config; } public Single&lt;String&gt; run() { /* The following tasks must be run before we authenticate */ return enableK8sAuth() // Now we can login using k8s - must run within a k8s cluster (or you need the k8s configuration files locally) .flatMapSingle(ignored -&gt; workWithSecrets()) // Now back to token based Vault, as we will clean up .flatMapSingle(ignored -&gt; disableK8sAuth()) .map(ignored -&gt; \"k8s example finished successfully.\"); } private Single&lt;ApiResponse&gt; workWithSecrets() { Kv2SecretsRx secrets = k8sVault.secrets(Kv2SecretsRx.ENGINE); return secrets.create(SECRET_PATH, Map.of(\"secret-key\", \"secretValue\", \"secret-user\", \"username\")) .flatMapSingle(ignored -&gt; secrets.get(SECRET_PATH)) .peek(secret -&gt; { if (secret.isPresent()) { Kv2Secret kv2Secret = secret.get(); System.out.println(\"k8s first secret: \" + kv2Secret.value(\"secret-key\")); System.out.println(\"k8s second secret: \" + kv2Secret.value(\"secret-user\")); } else { System.out.println(\"k8s secret not found\"); } }).flatMapSingle(ignored -&gt; secrets.deleteAll(SECRET_PATH)); } private Single&lt;ApiResponse&gt; disableK8sAuth() { return sys.deletePolicy(POLICY_NAME) .flatMapSingle(ignored -&gt; sys.disableAuth(K8sAuthRx.AUTH_METHOD.defaultPath())); } private Single&lt;ApiResponse&gt; enableK8sAuth() { // enable the method return sys.enableAuth(K8sAuthRx.AUTH_METHOD) // add policy .flatMapSingle(ignored -&gt; sys.createPolicy(POLICY_NAME, VaultPolicy.POLICY)) .flatMapSingle(ignored -&gt; tokenVault.auth(K8sAuthRx.AUTH_METHOD) .configure(ConfigureK8s.Request.builder() .address(k8sAddress))) .flatMapSingle(ignored -&gt; tokenVault.auth(K8sAuthRx.AUTH_METHOD) // this must be the same role name as is defined in application.yaml .createRole(CreateRole.Request.builder() .roleName(\"my-role\") .addBoundServiceAccountName(\"*\") .addBoundServiceAccountNamespace(\"default\") .addTokenPolicy(POLICY_NAME))) .peek(ignored -&gt; k8sVault = Vault.create(config)) .map(Function.identity()); } } Run the Kubernetes Authentication by enabling it. Create Kubernetes secrets. Disable Kubernetes authentication if needed. Function used to enable Kubernetes authentication. ",
            "title": "Usage with WebServer"
        },
        {
            "location": "/se/vault/01_vault",
            "text": " Vault is available as a docker image, so to test locally, you can simply: <markup lang=\"bash\" >docker run -e VAULT_DEV_ROOT_TOKEN_ID=my-token -d --name=vault -p8200:8200 vault This will create a Vault docker image, run it in background and open it on localhost:8200 with a custom root token my-token, using name vault. This is of course only suitable for local testing, as the root token has too many rights, but it can be easily used with the examples below. ",
            "title": "Local testing"
        },
        {
            "location": "/se/aot/01_introduction",
            "text": " Helidon applications can be compiled into a native executable using GraalVM native image. When using applications created using the CLI, or when you configure Helidon application pom as a parent of your module, you can use the following steps to build a native image from your application: Create an environment variable GRAALVM_HOME pointing to your installation of GraalVM with native-image installed Run Maven command mvn clean package -Pnative-image Execute the native executable created in target directory of your project ",
            "title": "preambule"
        },
        {
            "location": "/se/aot/01_introduction",
            "text": " Some Helidon components are not (yet) supported in native image, some have restrictions. The following table lists all Helidon features and their support for native image. Helidon SE features in AOT Feature Component AOT note ✅ Config Config &#160; ✅ &#160; Encryption &#160; ✅ &#160; HOCON &#160; ✅ &#160; Object Mapping &#160; ✅ &#160; YAML &#160; ❓ &#160; etcd Not yet tested. ✅ &#160; git &#160; ✅ Db Client Db Client &#160; ✅ &#160; Health Check &#160; 🔶 &#160; JDBC Tested with Helidon modules for Oracle and H2 driver (see examples) ✅ &#160; Metrics &#160; ✅ &#160; Tracing &#160; ✅ &#160; mongo &#160; ✅ Health Health &#160; ✅ &#160; Built-ins &#160; ✅ Messaging Messaging &#160; ✅ Metrics Metrics &#160; ✅ OpenAPI OpenAPI &#160; ✅ Security Security &#160; ✅ &#160; Integration: Jersey &#160; ✅ &#160; Integration: WebServer &#160; ✅ &#160; Integration: gRPC &#160; ✅ &#160; OIDC &#160; ✅ &#160; Provider: ABAC &#160; ✅ &#160; Provider/ABAC/Policy: EL Requires reflection configuration for used classes. ✅ &#160; Provider/ABAC: Role &#160; ✅ &#160; Provider/ABAC: Scope &#160; ✅ &#160; Provider/ABAC: Time &#160; ❓ &#160; Provider: Google Login Not yet tested. ✅ &#160; Provider: Header &#160; ✅ &#160; Provider: HTTP Basic &#160; ✅ &#160; Provider: HTTP Digest &#160; ✅ &#160; Provider: HTTP Signatures &#160; ❓ &#160; Provider: IDCS Role Mapper Not yet tested. ✅ &#160; Provider: JWT &#160; ✅ Tracing Tracing &#160; ✅ &#160; Integration: Jersey Server &#160; ✅ &#160; Integration: Jersey Client &#160; ✅ &#160; Jaeger &#160; ✅ &#160; Zipkin &#160; ✅ WebClient WebClient &#160; ✅ &#160; Web Client &#160; ✅ &#160; Jackson &#160; ✅ &#160; JSON-B &#160; ✅ &#160; JSON-P &#160; ✅ &#160; Metrics &#160; ✅ &#160; Multi-part &#160; ✅ &#160; Security &#160; ✅ &#160; Tracing &#160; ✅ WebServer WebServer &#160; ✅ &#160; Access Log &#160; ✅ &#160; CORS &#160; ✅ &#160; Jackson &#160; ✅ &#160; Jersey &#160; ✅ &#160; JSON-B &#160; ✅ &#160; JSON-P &#160; ✅ &#160; Multi-part &#160; ❓ &#160; Prometheus Not yet tested. ✅ &#160; Websocket Server only. ✅ gRPC Server gRPC Server Since GraalVM 21.0.0 ✅ &#160; Metrics &#160; ✅ gRPC Client gRPC Client Since GraalVM 21.0.0 ✅ &#160; Metrics &#160; ✅ Scheduling Scheduling &#160; ✅ OCI OCI Integration Modules with group id io.helidon.integrations.oci ✅ Vault Hashicorp Vault Integration &#160; ",
            "title": "AOT supported modules"
        },
        {
            "location": "/se/grpc/08_security",
            "text": " Security integration of the gRPC server ",
            "title": "preambule"
        },
        {
            "location": "/se/grpc/08_security",
            "text": " To enable gRPC Server Security add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.integration&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-integration-grpc&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/grpc/08_security",
            "text": " When using the Helidon SE gRPC client API security can be configured for a gRPC service or at the individual method level. The client API has a custom CallCredentials implementation that integrates with the Helidon security APIs. <markup lang=\"java\" title=\"Example configuring client security for a service\" >Security security = Security.builder() .addProvider(HttpBasicAuthProvider.create(config.get(\"http-basic-auth\"))) .build(); GrpcClientSecurity clientSecurity = GrpcClientSecurity.builder(security.createContext(\"test.client\")) .property(HttpBasicAuthProvider.EP_PROPERTY_OUTBOUND_USER, user) .property(HttpBasicAuthProvider.EP_PROPERTY_OUTBOUND_PASSWORD, password) .build(); ClientServiceDescriptor descriptor = ClientServiceDescriptor .builder(StringService.class) .unary(\"Lower\") .callCredentials(clientSecurity) .build(); GrpcServiceClient client = GrpcServiceClient.create(channel, descriptor); String response = client.blockingUnary(\"Lower\", \"ABCD\"); Create the Helidon Security instance (in this case using the basic auth provider) Create the GrpcClientSecurity gRPC CallCredentials adding the user and password property expected by the basic auth provider. Create the gRPC ClientServiceDescriptor for the StringService gRPC service. Set the GrpcClientSecurity instance as the call credentials for all methods of the service Create a GrpcServiceClient that will allow methods to be called on the service Call the \"Lower\" method which will use the configured basic auth credentials <markup lang=\"java\" title=\"Example configuring client security for a specific method\" >GrpcClientSecurity clientSecurity = GrpcClientSecurity.builder(security.createContext(\"test.client\")) .property(HttpBasicAuthProvider.EP_PROPERTY_OUTBOUND_USER, user) .property(HttpBasicAuthProvider.EP_PROPERTY_OUTBOUND_PASSWORD, password) .build(); ClientServiceDescriptor descriptor = ClientServiceDescriptor .builder(StringService.class) .unary(\"Lower\") .unary(\"Upper\", rules -&gt; rules.callCredentials(clientSecurity)) .build(); Create the GrpcClientSecurity call credentials in the same way as above. Create the ClientServiceDescriptor , this time with two unary methods, \"Lower\" and \"Upper\". The \"Upper\" method is configured to use the GrpcClientSecurity call credentials, the \"Lower\" method will be called without any credentials. ",
            "title": "Client security"
        },
        {
            "location": "/se/grpc/08_security",
            "text": " Outbound security covers three scenarios: Calling a secure gRPC service from inside a gRPC service method handler Calling a secure gRPC service from inside a web server method handler Calling a secure web endpoint from inside a gRPC service method handler Within each scenario credentials can be propagated if the gRPC/http method handler is executing within a security context or credentials can be overridden to provide a different set of credentials to use to call the outbound endpoint. <markup lang=\"java\" title=\"Example calling a secure gRPC service from inside a gRPC service method handler\" >// Obtain the SecurityContext from the current gRPC call Context SecurityContext securityContext = GrpcSecurity.SECURITY_CONTEXT.get(); // Create a gRPC CallCredentials that will use the current request's // security context to configure outbound credentials GrpcClientSecurity clientSecurity = GrpcClientSecurity.create(securityContext); // Create the gRPC stub using the CallCredentials EchoServiceGrpc.EchoServiceBlockingStub stub = noCredsEchoStub.withCallCredentials(clientSecurity); <markup lang=\"java\" title=\"Example calling a secure gRPC service from inside a web server method handler\" >private static void propagateCredentialsWebRequest(ServerRequest req, ServerResponse res) { try { // Create a gRPC CallCredentials that will use the current request's // security context to configure outbound credentials GrpcClientSecurity clientSecurity = GrpcClientSecurity.create(req); // Create the gRPC stub using the CallCredentials EchoServiceGrpc.EchoServiceBlockingStub stub = noCredsEchoStub.withCallCredentials(clientSecurity); String message = req.queryParams().first(\"message\").orElse(null); Echo.EchoResponse echoResponse = stub.echo(Echo.EchoRequest.newBuilder().setMessage(message).build()); res.send(echoResponse.getMessage()); } catch (StatusRuntimeException e) { res.status(GrpcHelper.toHttpResponseStatus(e)).send(); } catch (Throwable thrown) { res.status(Http.ResponseStatus.create(500, thrown.getMessage())).send(); } } <markup lang=\"java\" title=\"Example calling a secure web endpoint from inside a gRPC service method handler\" >// Obtain the SecurityContext from the gRPC call Context SecurityContext securityContext = GrpcSecurity.SECURITY_CONTEXT.get(); // Use the SecurityContext as normal to make a http request Response webResponse = client.target(url) .path(\"/test\") .request() .property(ClientSecurity.PROPERTY_CONTEXT, securityContext) .get(); ",
            "title": "Outbound security"
        },
        {
            "location": "/se/grpc/08_security",
            "text": " There are two steps to configure security with gRPC server: Create security instance and register it with server Protect gRPC services of server with various security features <markup lang=\"java\" title=\"Example using builders\" >// gRPC server's routing GrpcRouting.builder() // This is step 1 - register security instance with gRPC server processing // security - instance of security either from config or from a builder // securityDefaults - default enforcement for each service that has a security definition .intercept(GrpcSecurity.create(security).securityDefaults(GrpcSecurity.authenticate())) // this is step 2 - protect a service // register and protect this service with authentication (from defaults) and role \"user\" .register(greetService, GrpcSecurity.rolesAllowed(\"user\")) .build(); <markup lang=\"java\" title=\"Example using builders for more fine grained method level security\" >// create the service descriptor ServiceDescriptor greetService = ServiceDescriptor.builder(new GreetService()) // Add an instance of gRPC security that will apply to all methods of // the service - in this case require the \"user\" role .intercept(GrpcSecurity.rolesAllowed(\"user\")) // Add an instance of gRPC security that will apply to the \"SetGreeting\" // method of the service - in this case require the \"admin\" role .intercept(\"SetGreeting\", GrpcSecurity.rolesAllowed(\"admin\")) .build(); // Create the gRPC server's routing GrpcRouting.builder() // This is step 1 - register security instance with gRPC server processing // security - instance of security either from config or from a builder // securityDefaults - default enforcement for each service that has a security definition .intercept(GrpcSecurity.create(security).securityDefaults(GrpcSecurity.authenticate())) // this is step 2 - add the service descriptor .register(greetService) .build(); <markup lang=\"java\" title=\"Example using configuration\" >GrpcRouting.builder() // helper method to load both security and gRPC server security from configuration .intercept(GrpcSecurity.create(config)) // continue with gRPC server route configuration... .register(new GreetService()) .build(); <markup lang=\"conf\" title=\"Example using configuration - configuration (HOCON)\" ># This may change in the future - to align with gRPC server configuration, # once it is supported security grpc-server: # Configuration of integration with gRPC server defaults: authenticate: true # Configuration security for individual services services: - name: \"GreetService\" defaults: roles-allowed: [\"user\"] # Configuration security for individual methods of the service methods: - name: \"SetGreeting\" roles-allowed: [\"admin\"] Client security When using the Helidon SE gRPC client API security can be configured for a gRPC service or at the individual method level. The client API has a custom CallCredentials implementation that integrates with the Helidon security APIs. <markup lang=\"java\" title=\"Example configuring client security for a service\" >Security security = Security.builder() .addProvider(HttpBasicAuthProvider.create(config.get(\"http-basic-auth\"))) .build(); GrpcClientSecurity clientSecurity = GrpcClientSecurity.builder(security.createContext(\"test.client\")) .property(HttpBasicAuthProvider.EP_PROPERTY_OUTBOUND_USER, user) .property(HttpBasicAuthProvider.EP_PROPERTY_OUTBOUND_PASSWORD, password) .build(); ClientServiceDescriptor descriptor = ClientServiceDescriptor .builder(StringService.class) .unary(\"Lower\") .callCredentials(clientSecurity) .build(); GrpcServiceClient client = GrpcServiceClient.create(channel, descriptor); String response = client.blockingUnary(\"Lower\", \"ABCD\"); Create the Helidon Security instance (in this case using the basic auth provider) Create the GrpcClientSecurity gRPC CallCredentials adding the user and password property expected by the basic auth provider. Create the gRPC ClientServiceDescriptor for the StringService gRPC service. Set the GrpcClientSecurity instance as the call credentials for all methods of the service Create a GrpcServiceClient that will allow methods to be called on the service Call the \"Lower\" method which will use the configured basic auth credentials <markup lang=\"java\" title=\"Example configuring client security for a specific method\" >GrpcClientSecurity clientSecurity = GrpcClientSecurity.builder(security.createContext(\"test.client\")) .property(HttpBasicAuthProvider.EP_PROPERTY_OUTBOUND_USER, user) .property(HttpBasicAuthProvider.EP_PROPERTY_OUTBOUND_PASSWORD, password) .build(); ClientServiceDescriptor descriptor = ClientServiceDescriptor .builder(StringService.class) .unary(\"Lower\") .unary(\"Upper\", rules -&gt; rules.callCredentials(clientSecurity)) .build(); Create the GrpcClientSecurity call credentials in the same way as above. Create the ClientServiceDescriptor , this time with two unary methods, \"Lower\" and \"Upper\". The \"Upper\" method is configured to use the GrpcClientSecurity call credentials, the \"Lower\" method will be called without any credentials. Outbound security Outbound security covers three scenarios: Calling a secure gRPC service from inside a gRPC service method handler Calling a secure gRPC service from inside a web server method handler Calling a secure web endpoint from inside a gRPC service method handler Within each scenario credentials can be propagated if the gRPC/http method handler is executing within a security context or credentials can be overridden to provide a different set of credentials to use to call the outbound endpoint. <markup lang=\"java\" title=\"Example calling a secure gRPC service from inside a gRPC service method handler\" >// Obtain the SecurityContext from the current gRPC call Context SecurityContext securityContext = GrpcSecurity.SECURITY_CONTEXT.get(); // Create a gRPC CallCredentials that will use the current request's // security context to configure outbound credentials GrpcClientSecurity clientSecurity = GrpcClientSecurity.create(securityContext); // Create the gRPC stub using the CallCredentials EchoServiceGrpc.EchoServiceBlockingStub stub = noCredsEchoStub.withCallCredentials(clientSecurity); <markup lang=\"java\" title=\"Example calling a secure gRPC service from inside a web server method handler\" >private static void propagateCredentialsWebRequest(ServerRequest req, ServerResponse res) { try { // Create a gRPC CallCredentials that will use the current request's // security context to configure outbound credentials GrpcClientSecurity clientSecurity = GrpcClientSecurity.create(req); // Create the gRPC stub using the CallCredentials EchoServiceGrpc.EchoServiceBlockingStub stub = noCredsEchoStub.withCallCredentials(clientSecurity); String message = req.queryParams().first(\"message\").orElse(null); Echo.EchoResponse echoResponse = stub.echo(Echo.EchoRequest.newBuilder().setMessage(message).build()); res.send(echoResponse.getMessage()); } catch (StatusRuntimeException e) { res.status(GrpcHelper.toHttpResponseStatus(e)).send(); } catch (Throwable thrown) { res.status(Http.ResponseStatus.create(500, thrown.getMessage())).send(); } } <markup lang=\"java\" title=\"Example calling a secure web endpoint from inside a gRPC service method handler\" >// Obtain the SecurityContext from the gRPC call Context SecurityContext securityContext = GrpcSecurity.SECURITY_CONTEXT.get(); // Use the SecurityContext as normal to make a http request Response webResponse = client.target(url) .path(\"/test\") .request() .property(ClientSecurity.PROPERTY_CONTEXT, securityContext) .get(); ",
            "title": "Bootstrapping"
        },
        {
            "location": "/mp/oci/01_oci",
            "text": " Helidon MP OCI Integration provides easy access to Oracle Cloud Infrastructure using the OCI Java SDK. ",
            "title": "preambule"
        },
        {
            "location": "/mp/oci/01_oci",
            "text": " To enable OCI Integration add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.oci.sdk&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-oci-sdk-cdi&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/oci/01_oci",
            "text": " When added to your application this CDI portable extension provides support for injecting Oracle Cloud Infrastructure SDK Clients in your Helidon MicroProfile application. The extension also handles authenticating with OCI by automatically picking up OCI credentials from your environment. ",
            "title": "The Helidon OCI SDK Extension"
        },
        {
            "location": "/mp/oci/01_oci",
            "text": " When you inject an OCI SDK Client object, the Helidon OCI SDK extension configures and constructs the object for you. The configuration primarily consists of initializing an OCI AuthenticationDetailsProvider . By default the extension will examine your environment and select the best AuthenticationDetailsProvider and configure it for you. This means if your environment is already set up to work with the OCI SDK or the OCI command line, then it is very likely you do not need to do any additional configuration of the extension. Just add it as a dependency and it will self-configure. If for some reason you require full control over the OCI configuration you have that as well. For more information concerning the extension and its configuration and authentication options see the OciExtension javadocs. In particular the oci.auth-strategies property lets you control which AuthenticationDetailsProvider will be used. ",
            "title": "Configuring the Helidon OCI SDK Extension"
        },
        {
            "location": "/mp/oci/01_oci",
            "text": " Since the Helidon OCI SDK extension supports injecting any OCI client from the OCI SDK, you can use it to access any OCI service supported by the OCI SDK. In addition to adding the Helidon OCI SDK Extension dependency (as described above) you will need to add dependencies for the specific ODI SDK clients you will use. You will also need to configure your environment to authenticate with OCI. It is recommended that you do this first, and verify your configuration by using the OCI CLI to access the service. The following documentation will help you get started with some common OCI Services: OCI Object Storage OCI Vault OCI ATP ",
            "title": "Accessing OCI Services"
        },
        {
            "location": "/mp/reactivemessaging/04_kafka",
            "text": " To enable Reactive Kafka Connector add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.messaging.kafka&lt;/groupId&gt; &lt;artifactId&gt;helidon-messaging-kafka&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/reactivemessaging/04_kafka",
            "text": " Connecting streams to Kafka with Reactive Messaging couldn&#8217;t be easier. <markup lang=\"yaml\" title=\"Example of connector config:\" >mp.messaging: incoming.from-kafka: connector: helidon-kafka topic: messaging-test-topic-1 auto.offset.reset: latest enable.auto.commit: true group.id: example-group-id outgoing.to-kafka: connector: helidon-kafka topic: messaging-test-topic-1 connector: helidon-kafka: bootstrap.servers: localhost:9092 key.serializer: org.apache.kafka.common.serialization.StringSerializer value.serializer: org.apache.kafka.common.serialization.StringSerializer key.deserializer: org.apache.kafka.common.serialization.StringDeserializer value.deserializer: org.apache.kafka.common.serialization.StringDeserializer <markup lang=\"java\" title=\"Example of consuming from Kafka:\" >@Incoming(\"from-kafka\") public void consumeKafka(String msg) { System.out.println(\"Kafka says: \" + msg); } <markup lang=\"java\" title=\"Example of producing to Kafka:\" >@Outgoing(\"to-kafka\") public PublisherBuilder&lt;String&gt; produceToKafka() { return ReactiveStreams.of(\"test1\", \"test2\"); } Don&#8217;t forget to check out the examples with pre-configured Kafka docker image, for easy testing: https://github.com/oracle/helidon/tree/master/examples/messaging ",
            "title": "Reactive Kafka Connector"
        },
        {
            "location": "/mp/testing/01_testing",
            "text": " Helidon provides built-in test support for CDI testing in JUnit5. ",
            "title": "preambule"
        },
        {
            "location": "/mp/testing/01_testing",
            "text": " To enable Testing add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.tests&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-tests-junit5&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/testing/01_testing",
            "text": " A test can be annotated with io.helidon.microprofile.tests.junit5.HelidonTest annotation to mark it as a CDI test. This annotation will start the CDI container before any test method is invoked, and stop it after the last method is invoked. This annotation also enables injection into the test class itself. The annotations described in this section are inherited (for the non-repeatable ones), and additive (for repeatable). So if you declare @DisableDiscovery on abstract class, all implementations will have discovery disabled, unless you annotate the implementation class with @DisableDiscovery(false) . If you declare @AddBean on both abstract class and implementation class, both beans will be added. In addition to this simplification, the following annotations are supported: io.helidon.microprofile.tests.junit5.AddBean - to add one or more beans to the container (if not part of a bean archive, or when discovery is disabled) io.helidon.microprofile.tests.junit5.AddExtension - to add one or more CDI extensions to the container (if not added through service loader, or when discovery is disabled) io.helidon.microprofile.tests.junit5.AddConfig - to add one or more configuration properties to MicroProfile config without the need of creating a microprofile-config.properties file io.helidon.microprofile.tests.junit5.DisableDiscovery - to disable automated discovery of beans and extensions <markup lang=\"java\" title=\"Code sample\" >@HelidonTest @DisableDiscovery @AddBean(MyBean.class) @AddExtension(ConfigCdiExtension.class) @AddConfig(key = \"app.greeting\", value = \"TestHello\") class TestNoDiscovery { @Inject private MyBean myBean; @Test void testGreeting() { assertThat(myBean, notNullValue()); assertThat(myBean.greeting(), is(\"TestHello\")); } } ",
            "title": "Usage - default"
        },
        {
            "location": "/mp/testing/01_testing",
            "text": " A test can be annotated as follows: @HelidonTest(resetPerTest = true) This will change the behavior as follows: A new CDI container is created for each test method invocation annotations to add config, beans and extension can be added for each method in addition to the class you cannot inject fields or constructor parameters of the test class itself (as a single instance is shared by more containers) you can add SeContainer as a method parameter of any test method and you will get the current container ",
            "title": "Usage - per method CDI container"
        },
        {
            "location": "/mp/testing/01_testing",
            "text": " In addition to the @AddConfig annotation, you can also use @Configuration to configure additional classpath properties config sources using configSources , and to mark that a custom configuration is desired. If @Configuration(useExisting=true) , the existing (or default) MicroProfile configuration would be used. In this case it is important to set property mp.initializer.allow=true in order CDI container to start, when used with @HelidonTest . You can set up config in @BeforeAll method and register it with ConfigProviderResolver using MP Config APIs, and declare @Configuration(useExisting=true) . Note that this is not compatible with repeatable tests that use method sources that access CDI, as we must delay the CDI startup to the test class instantiation (which is too late, as the method sources are already invoked by this time). If you want to use method sources that use CDI with repeatable tests, please do not use @Configuration(useExisting=true) ",
            "title": "Usage - configuration"
        },
        {
            "location": "/mp/testing/01_testing",
            "text": " The following types are available for injection (when a single CDI container is used per test class): WebTarget - a JAX-RS client&#8217;s target configured for the current hostname and port when helidon-micorprofile-server is on the classpath The following types are available as method parameters (in any type of Helidon tests): WebTarget - a JAX-RS client&#8217;s target configured for the current hostname and port when helidon-micorprofile-server is on the classpath SeContainer - the current container instance ",
            "title": "Usage - added parameters and injection types"
        },
        {
            "location": "/mp/health/01_introduction",
            "text": " To enable MicroProfile Health either add a dependency on the helidon-microprofile bundle or add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.health&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-health&lt;/artifactId&gt; &lt;/dependency&gt; To enable built-in health checks add the following dependency (or use the helidon-microprofile bundle ) <markup lang=\"xml\" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.health&lt;/groupId&gt; &lt;artifactId&gt;helidon-health-checks&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/health/01_introduction",
            "text": " Microservices expose their health status primarily so external tools (for example, an orchestrator such as Kubernetes) can monitor each service and take action, such as restarting a service instance if it has failed or temporarily shunting traffic away from the instance if the service is unable to process incoming requests normally. ",
            "title": "Overview"
        },
        {
            "location": "/mp/health/01_introduction",
            "text": " Helidon MP implements the MicroProfile Health spec . The spec prescribes how external tools probe a service&#8217;s health checks and how you implement health checks as part of your microservice that are specific to your service&#8217;s needs. ",
            "title": "About the MicroProfile Health Specification"
        },
        {
            "location": "/mp/health/01_introduction",
            "text": " MicroProfile Health supports two types of health checks: Liveness checks report whether the runtime environment in which the service is running is sufficient to support the work the service performs. The environment is beyond the control of the service itself and typically cannot improve without outside intervention. If a microservice instance reports a DOWN liveness check, it should never report UP later. It will need to be stopped and a replacement instance created. Readiness checks report whether the service is currently capable of performing its work. A service that reports DOWN for its readiness cannot at the moment do its job, but at some future point it might become able to do so without requiring a restart. The following table describes more about these two types of health checks, including how an orchestrator such as Kubernetes might react. ",
            "title": "Liveness and Readiness Checks"
        },
        {
            "location": "/mp/health/01_introduction",
            "text": " A MicroProfile-compliant service reports its health via known REST endpoints. Helidon MP provides these endpoints automatically as part of every MP microservice. External management tools (or curl or browsers) retrieve liveness via /health/live and readiness via /health/ready . Responses from the health endpoints report 200 (OK), 204 (no content), or 503 (service unavailable) depending on the outcome of running the health checks. HTTP GET responses include JSON content showing the detailed results of all the health checks which the server executed after receiving the request. HTTP HEAD requests return only the status with no payload. The following table summarizes the two types of health checks in MicroProfile Health. Types of Health Checks Type Meaning REST endpoint Kubernetes response on failure liveness whether the runtime environment is suitable /health/live Restarts container. readiness whether the microservice is currently capable of doing its work /health/ready Diverts requests away from the instance; periodically rechecks readiness and resumes traffic once the microservice reports itself as ready. ",
            "title": "Known Health Check Endpoints"
        },
        {
            "location": "/mp/health/01_introduction",
            "text": " Helidon provides built-in, default checks for each endpoint. The built-in liveness checks include various environmental values, such as whether the JVM has detected deadlocks or whether there is sufficient heap space. The built-in readiness check always reports UP . You can see all the defaults by accessing any Helidon MP microservice&#8217;s /health/live endpoint and viewing the response. ",
            "title": "Built-in Health Checks"
        },
        {
            "location": "/mp/health/01_introduction",
            "text": " Add your own liveness or readiness checks by adding a Java class for each check. Each custom check must implement the HealthCheck interface, and you add either the @Liveness or the @Readiness annotation to the class. ",
            "title": "Custom Health Checks"
        },
        {
            "location": "/mp/health/01_introduction",
            "text": " Built-in Health Checks Helidon provides built-in, default checks for each endpoint. The built-in liveness checks include various environmental values, such as whether the JVM has detected deadlocks or whether there is sufficient heap space. The built-in readiness check always reports UP . You can see all the defaults by accessing any Helidon MP microservice&#8217;s /health/live endpoint and viewing the response. Custom Health Checks Add your own liveness or readiness checks by adding a Java class for each check. Each custom check must implement the HealthCheck interface, and you add either the @Liveness or the @Readiness annotation to the class. ",
            "title": "Built-in and Custom Health Checks"
        },
        {
            "location": "/mp/health/01_introduction",
            "text": " Add custom health checks to your own microservices. The Helidon MP Health Check Guide shows how to create a sample project and add custom liveness and readiness health checks. ",
            "title": "Next Steps"
        },
        {
            "location": "/mp/health/01_introduction",
            "text": " Liveness and Readiness Checks MicroProfile Health supports two types of health checks: Liveness checks report whether the runtime environment in which the service is running is sufficient to support the work the service performs. The environment is beyond the control of the service itself and typically cannot improve without outside intervention. If a microservice instance reports a DOWN liveness check, it should never report UP later. It will need to be stopped and a replacement instance created. Readiness checks report whether the service is currently capable of performing its work. A service that reports DOWN for its readiness cannot at the moment do its job, but at some future point it might become able to do so without requiring a restart. The following table describes more about these two types of health checks, including how an orchestrator such as Kubernetes might react. Known Health Check Endpoints A MicroProfile-compliant service reports its health via known REST endpoints. Helidon MP provides these endpoints automatically as part of every MP microservice. External management tools (or curl or browsers) retrieve liveness via /health/live and readiness via /health/ready . Responses from the health endpoints report 200 (OK), 204 (no content), or 503 (service unavailable) depending on the outcome of running the health checks. HTTP GET responses include JSON content showing the detailed results of all the health checks which the server executed after receiving the request. HTTP HEAD requests return only the status with no payload. The following table summarizes the two types of health checks in MicroProfile Health. Types of Health Checks Type Meaning REST endpoint Kubernetes response on failure liveness whether the runtime environment is suitable /health/live Restarts container. readiness whether the microservice is currently capable of doing its work /health/ready Diverts requests away from the instance; periodically rechecks readiness and resumes traffic once the microservice reports itself as ready. Built-in and Custom Health Checks Built-in Health Checks Helidon provides built-in, default checks for each endpoint. The built-in liveness checks include various environmental values, such as whether the JVM has detected deadlocks or whether there is sufficient heap space. The built-in readiness check always reports UP . You can see all the defaults by accessing any Helidon MP microservice&#8217;s /health/live endpoint and viewing the response. Custom Health Checks Add your own liveness or readiness checks by adding a Java class for each check. Each custom check must implement the HealthCheck interface, and you add either the @Liveness or the @Readiness annotation to the class. Next Steps Add custom health checks to your own microservices. The Helidon MP Health Check Guide shows how to create a sample project and add custom liveness and readiness health checks. ",
            "title": "Concepts"
        },
        {
            "location": "/se/dbclient/01_introduction",
            "text": " The Helidon SE DB Client provides a unified, reactive API for working with databases in non-blocking way. ",
            "title": "preambule"
        },
        {
            "location": "/se/dbclient/01_introduction",
            "text": " To enable DB Client add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.dbclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-dbclient&lt;/artifactId&gt; &lt;/dependency&gt; To use with a JDBC client also add the following dependency: <markup lang=\"xml\" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.dbclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-dbclient-jdbc&lt;/artifactId&gt; &lt;/dependency&gt; Or to use with MongoDB client add the following dependency: <markup lang=\"xml\" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.dbclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-dbclient-mongodb&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/dbclient/01_introduction",
            "text": " The DB Client simplifies how you work with databases by abstracting the type of the database. The API can be used both for relational and non-relational databases. The API provides: Database configuration abstraction Using Helidon configuration allows database implementation specific configuration options without the need to use database implementation specific APIs. This allows for seamless switching between databases based on configuration. Statement configuration abstraction Using Helidon configuration allows use of database specific statements. This allows usage of different databases on different environments without changing code. Unified API for data access and query Thanks to the statement configuration abstraction, we can invoke a statement against a relational or non-relations databases (such as MySQL and MongoDB) withough modifying source code Reactive database access with backpressure Current we support natively reactive driver for MongoDB, and an executor service wrapped support for any JDBC driver. This allows for seamless use of JDBC drivers in a reactive non-blocking environment, including support for backpressure (result set is processed as requested by the query subscriber) Observability The API offers support for health checks, metrics and tracing. ",
            "title": "Helidon DB Client Features Overview"
        },
        {
            "location": "/se/dbclient/01_introduction",
            "text": " For the DB Client using JDBC implementation and H2 database, you must include the following dependencies in your project: <markup lang=\"xml\" >&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.dbclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-dbclient&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.dbclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-dbclient-jdbc&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.h2database&lt;/groupId&gt; &lt;artifactId&gt;h2&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; Add the Helidon DB Client Specify JDBC or MongoDB Add the database JDBC driver (only for JDBC) ",
            "title": "Add the DB Client dependencies to the Maven pom.xml file."
        },
        {
            "location": "/se/dbclient/01_introduction",
            "text": " The DB Client must be configured before you begin. In the example below we&#8217;ll use Helidon Config to set up JDBC-based client: <markup lang=\"yaml\" >db: source: \"jdbc\" connection: url: \"jdbc:mysql://127.0.0.1:3306/pokemon?useSSL=false\" username: \"user\" password: \"password\" statements: ping: \"DO 0\" select-all-pokemons: \"SELECT id, name FROM Pokemons\" Source: jdbc or mongoDb Connection: database connection parameters Statements: named statements to be used in application A ping statement used by health check ",
            "title": "Use Helidon Config to configure the client."
        },
        {
            "location": "/se/dbclient/01_introduction",
            "text": " Before you begin you must add the DB Client dependencies and configure the client. Add the DB Client dependencies to the Maven pom.xml file. For the DB Client using JDBC implementation and H2 database, you must include the following dependencies in your project: <markup lang=\"xml\" >&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.dbclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-dbclient&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.dbclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-dbclient-jdbc&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.h2database&lt;/groupId&gt; &lt;artifactId&gt;h2&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; Add the Helidon DB Client Specify JDBC or MongoDB Add the database JDBC driver (only for JDBC) Use Helidon Config to configure the client. The DB Client must be configured before you begin. In the example below we&#8217;ll use Helidon Config to set up JDBC-based client: <markup lang=\"yaml\" >db: source: \"jdbc\" connection: url: \"jdbc:mysql://127.0.0.1:3306/pokemon?useSSL=false\" username: \"user\" password: \"password\" statements: ping: \"DO 0\" select-all-pokemons: \"SELECT id, name FROM Pokemons\" Source: jdbc or mongoDb Connection: database connection parameters Statements: named statements to be used in application A ping statement used by health check ",
            "title": "Getting Started"
        },
        {
            "location": "/se/dbclient/01_introduction",
            "text": " DBClient class has two methods to select whether statements will be executed in transaction or not: execute(Function&lt;DbExecute, T&gt; executor) inTransaction(Function&lt;DbTransaction, T&gt; executor) Both methods provide an executor (either DbExecute or DbTransaction ) and expect either Single or a Multi result, usually returned by one of their methods. ",
            "title": "Executor Selection"
        },
        {
            "location": "/se/dbclient/01_introduction",
            "text": " DbExecute class offers many methods for various statements builders: DML statements: createDmlStatement , createNamedDmlStatement insert statements: createInsert , createNamedInsert update statements: createUpdate , createNamedUpdate delete statements: createDelete , createNamedDelete query statements: createQuery , createNamedQuery get statements: createGet , createNamedGet Methods with \"Named\" in their name ( create Named DmlStatement ) expect statement name from statements section of Config, or a named statement configured when the DbClient was created using a Builder . All statement builders offer methods to set statement parameters. Those parameters can be ordered parameters or named parameters. Ordered and named parameters can’t be mixed in a single statement. Note that get statements are query statements that allow zero to one results. ",
            "title": "Statement Building and Execution"
        },
        {
            "location": "/se/dbclient/01_introduction",
            "text": " Ordered parameters are written down as ? in the statement text: <markup lang=\"sql\" >SELECT name FROM Pokemons WHERE id = ? The ordered parameters are equivalent to JDBC PreparedStatement parameters. Methods to set ordered parameters are: params(List&lt;?&gt; parameters) with all parameters as List params(Object… parameters) with all parameters as array indexedParam(Object parameters) POJO used with registered mapper addParam(Object parameter) with single parameter, can be called repeatedly ",
            "title": "Ordered Parameters"
        },
        {
            "location": "/se/dbclient/01_introduction",
            "text": " Named parameters are written down as :&lt;name&gt; in the JDBC statements <markup lang=\"sql\" >SELECT name FROM Pokemons WHERE id = :id or as $&lt;name&gt; in the MongoDB statement: <markup lang=\"json\" >{ \"collection\": \"pokemons\", \"operation\": \"update\", \"value\":{ $set: { \"name\": $name } }, \"query\": { id: $id } } Methods to set named parameters are: params(Map&lt;String, ?&gt; parameters) with all parameters as Map namedParam(Object parameters) POJO used with registered mapper addParam(String name, Object parameter) with single parameter, can be called repeatedly ",
            "title": "Named Parameters"
        },
        {
            "location": "/se/dbclient/01_introduction",
            "text": " Execution of DML statements will always return Single&lt;Long&gt; with the number of modified records in the database. In following example, the number of modified records is printed to standard output: <markup lang=\"java\" >dbClient.execute(exec -&gt; exec .insert(\"INSERT INTO Pokemons (id, name) VALUES(?, ?)\", 1, \"Pikachu\")) .thenAccept(count -&gt; System.out.printf(\"Inserted %d records\", count)); ",
            "title": "DML Statement Result"
        },
        {
            "location": "/se/dbclient/01_introduction",
            "text": " Execution of a query statement will always return Multi&lt;DbRow&gt;&gt; . Multi has several useful properties: It is an implementation of Flow.Publisher to process individual result rows using Flow.Subscriber&lt;DbRow&gt; Single&lt;List&lt;DbRow&gt;&gt; collectList() to collect all rows and return them as a promise of List&lt;DbRow&gt; &lt;U&gt; Multi&lt;U&gt; map(…) to map returned result using provided mapper ",
            "title": "Query Statement Result"
        },
        {
            "location": "/se/dbclient/01_introduction",
            "text": " Statements are executed by calling execute() method after statement parameters are set. This method returns either a Single or Multi depending on statement type. The type returned also depends on statement type. JDBC query with ordered parameters and query that does not run in the transaction: <markup lang=\"java\" >dbClient.execute(exec -&gt; exec .createQuery(\"SELECT name FROM Pokemons WHERE id = ?\") .params(1) .execute() ); JDBC query with named parameters and the query runs in transaction: <markup lang=\"java\" >dbClient.inTransaction(tx -&gt; tx .createQuery(\"SELECT name FROM Pokemons WHERE id = :id\") .addParam(\"id\", 1) .execute() ); Both examples will return Multi&lt;DbRow&gt; with rows returned by the query. This example shows a MongoDB update statement with named parameters and the query does not run in transaction: <markup lang=\"java\" >dbClient.execute(exec -&gt; exec .createUpdate(\"{\\\"collection\\\": \\\"pokemons\\\",\" + \"\\\"value\\\":{$set:{\\\"name\\\":$name}},\" + \"\\\"query\\\":{id:$id}}\") .addParam(\"id\", 1) .addParam(\"name\", \"Pikachu\") .execute() ); This update statement will return Single&lt;Long&gt; with the number of modified records in the database. DML Statement Result Execution of DML statements will always return Single&lt;Long&gt; with the number of modified records in the database. In following example, the number of modified records is printed to standard output: <markup lang=\"java\" >dbClient.execute(exec -&gt; exec .insert(\"INSERT INTO Pokemons (id, name) VALUES(?, ?)\", 1, \"Pikachu\")) .thenAccept(count -&gt; System.out.printf(\"Inserted %d records\", count)); Query Statement Result Execution of a query statement will always return Multi&lt;DbRow&gt;&gt; . Multi has several useful properties: It is an implementation of Flow.Publisher to process individual result rows using Flow.Subscriber&lt;DbRow&gt; Single&lt;List&lt;DbRow&gt;&gt; collectList() to collect all rows and return them as a promise of List&lt;DbRow&gt; &lt;U&gt; Multi&lt;U&gt; map(…) to map returned result using provided mapper ",
            "title": "Statement Execution"
        },
        {
            "location": "/se/dbclient/01_introduction",
            "text": " The Helidon DB Client API contains many methods to run various statements with parameters and to retrieve statement execution results. The following sections describe the options you can use to build and execute your statements. Executor Selection DBClient class has two methods to select whether statements will be executed in transaction or not: execute(Function&lt;DbExecute, T&gt; executor) inTransaction(Function&lt;DbTransaction, T&gt; executor) Both methods provide an executor (either DbExecute or DbTransaction ) and expect either Single or a Multi result, usually returned by one of their methods. Statement Building and Execution DbExecute class offers many methods for various statements builders: DML statements: createDmlStatement , createNamedDmlStatement insert statements: createInsert , createNamedInsert update statements: createUpdate , createNamedUpdate delete statements: createDelete , createNamedDelete query statements: createQuery , createNamedQuery get statements: createGet , createNamedGet Methods with \"Named\" in their name ( create Named DmlStatement ) expect statement name from statements section of Config, or a named statement configured when the DbClient was created using a Builder . All statement builders offer methods to set statement parameters. Those parameters can be ordered parameters or named parameters. Ordered and named parameters can’t be mixed in a single statement. Note that get statements are query statements that allow zero to one results. Ordered Parameters Ordered parameters are written down as ? in the statement text: <markup lang=\"sql\" >SELECT name FROM Pokemons WHERE id = ? The ordered parameters are equivalent to JDBC PreparedStatement parameters. Methods to set ordered parameters are: params(List&lt;?&gt; parameters) with all parameters as List params(Object… parameters) with all parameters as array indexedParam(Object parameters) POJO used with registered mapper addParam(Object parameter) with single parameter, can be called repeatedly Named Parameters Named parameters are written down as :&lt;name&gt; in the JDBC statements <markup lang=\"sql\" >SELECT name FROM Pokemons WHERE id = :id or as $&lt;name&gt; in the MongoDB statement: <markup lang=\"json\" >{ \"collection\": \"pokemons\", \"operation\": \"update\", \"value\":{ $set: { \"name\": $name } }, \"query\": { id: $id } } Methods to set named parameters are: params(Map&lt;String, ?&gt; parameters) with all parameters as Map namedParam(Object parameters) POJO used with registered mapper addParam(String name, Object parameter) with single parameter, can be called repeatedly Statement Execution Statements are executed by calling execute() method after statement parameters are set. This method returns either a Single or Multi depending on statement type. The type returned also depends on statement type. JDBC query with ordered parameters and query that does not run in the transaction: <markup lang=\"java\" >dbClient.execute(exec -&gt; exec .createQuery(\"SELECT name FROM Pokemons WHERE id = ?\") .params(1) .execute() ); JDBC query with named parameters and the query runs in transaction: <markup lang=\"java\" >dbClient.inTransaction(tx -&gt; tx .createQuery(\"SELECT name FROM Pokemons WHERE id = :id\") .addParam(\"id\", 1) .execute() ); Both examples will return Multi&lt;DbRow&gt; with rows returned by the query. This example shows a MongoDB update statement with named parameters and the query does not run in transaction: <markup lang=\"java\" >dbClient.execute(exec -&gt; exec .createUpdate(\"{\\\"collection\\\": \\\"pokemons\\\",\" + \"\\\"value\\\":{$set:{\\\"name\\\":$name}},\" + \"\\\"query\\\":{id:$id}}\") .addParam(\"id\", 1) .addParam(\"name\", \"Pikachu\") .execute() ); This update statement will return Single&lt;Long&gt; with the number of modified records in the database. DML Statement Result Execution of DML statements will always return Single&lt;Long&gt; with the number of modified records in the database. In following example, the number of modified records is printed to standard output: <markup lang=\"java\" >dbClient.execute(exec -&gt; exec .insert(\"INSERT INTO Pokemons (id, name) VALUES(?, ?)\", 1, \"Pikachu\")) .thenAccept(count -&gt; System.out.printf(\"Inserted %d records\", count)); Query Statement Result Execution of a query statement will always return Multi&lt;DbRow&gt;&gt; . Multi has several useful properties: It is an implementation of Flow.Publisher to process individual result rows using Flow.Subscriber&lt;DbRow&gt; Single&lt;List&lt;DbRow&gt;&gt; collectList() to collect all rows and return them as a promise of List&lt;DbRow&gt; &lt;U&gt; Multi&lt;U&gt; map(…) to map returned result using provided mapper ",
            "title": "Using DB Client API Methods"
        },
        {
            "location": "/se/dbclient/01_introduction",
            "text": " Now that you understand how to build and execute statements, try it for yourself. DB Client Examples . ",
            "title": "Next Steps"
        },
        {
            "location": "/mp/security/02_providers",
            "text": "<markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-oidc&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"text\" title=\"Provider class name\" >io.helidon.security.providers.oidc.OidcProvider <markup lang=\"text\" title=\"Provider configuration key\" >oidc ",
            "title": "Setup"
        },
        {
            "location": "/mp/security/02_providers",
            "text": " https://github.com/oracle/helidon/tree/master/examples/security/idcs-login <markup lang=\"yaml\" title=\"Configuration example\" >security: config.require-encryption: false security: providers: - oidc: client-id: \"client-id-of-this-service\" client-secret: \"${CLEAR=client-secret-of-this-service}\" identity-uri: \"http://your-tenant.identity-server.com\" frontend-uri: \"http://my-service:8080\" audience: \"http://my-service\" cors: allow-origins: [\"http://foo.com\", \"http://there.com\"] allow-methods: [\"PUT\", \"DELETE\"] outbound: - name: \"internal-services\" hosts: [\"*.example.org\"] outbound-token: header: \"X-Internal-Auth\" ",
            "title": "Example code"
        },
        {
            "location": "/mp/security/02_providers",
            "text": " The following table shows all configuration options of the provider and their default values key default value description optional false If set to true , failure to authenticate will return ABSTAIN result instead of FAILURE . This is an important distinction when more than one provider is used client-id &#160; Client ID as generated by identity server client-secret &#160; Client secret as generated by identity server identity-uri &#160; URI of the identity server, base used to retrieve OIDC metadata frontend-uri &#160; Full URI of this service for redirects back from OIDC server issuer issuer from OIDC metadata Issuer of token - each JWT is validated to check the issuer audience &#160; Audience of a token - each JWT is validated to check the audience cors &#160; Cross-origin resource sharing settings (see below) proxy-protocol http Proxy protocol to use when proxy is used proxy-host null Proxy host to use. When defined, triggers usage of proxy for HTTP requests proxy-port 80 Port of the proxy server to use redirect-uri /oidc/redirect URI to register web server component on, used by the OIDC server to redirect authorization requests to after a user logs in or approves scopes. Note that usually the redirect URI configured here must be the same one as configured on OIDC server. scope-audience empty string Audience of the scope required by this application. This is prefixed to the scope name when requesting scopes from the identity server. cookie-use true Whether to use cookie to store JWT. If used, redirects happen only in case the user is not authenticated or has insufficient scopes cookie-name JSESSIONID Name of the cookie cookie-domain &#160; Domain the cookie is valid for. Not used by default cookie-path / Path the cookie is valid for. cookie-max-age-seconds {nsbp} When using cookie, used to set MaxAge attribute of the cookie, defining how long the cookie is valid. cookie-http-only true When using cookie, if set to true, the HttpOnly attribute will be configured. cookie-secure false When using cookie, if set to true, the Secure attribute will be configured. cookie-same-site Lax When using cookie, used to set the SameSite cookie value. Can be \"Strict\" or \"Lax\". Setting this to \"Strict\" will result in infinite redirects when calling OIDC on a different host. query-param-use false Whether to expect JWT in a query parameter query-param-name accessToken Name of a query parameter that contains the JWT token when parameter is used. header-use false Whether to expect JWT in a header field. header-token Authorization header with prefix bearer A TokenHandler configuration to process header containing a JWT oidc-metadata-well-known true If set to true, metadata will be loaded from default (well known) location, unless it is explicitly defined using oidc-metadata-resource. If set to false, it would not be loaded even if oidc-metadata-resource is not defined. In such a case all URIs must be explicitly defined (e.g. token-endpoint-uri). oidc-metadata.resource identity-uri/.well-known/openid-configuration Resource configuration for OIDC Metadata containing endpoints to various identity services, as well as information about the identity server. See Resource.create(io.helidon.config.Config) token-endpoint-uri token_endpoint in OIDC metadata, or identity-url/oauth2/v1/token if not available URI of a token endpoint used to obtain a JWT based on the authentication code. authorization-endpoint-uri \"authorization_endpoint\" in OIDC metadata, or identity-uri/oauth2/v1/authorize if not available URI of an authorization endpoint used to redirect users to for logging-in. validate-with-jwk true When true - validate against jwk defined by \"sign-jwk\", when false validate JWT through OIDC Server endpoint \"validation-endpoint-uri\" sign-jwk.resource \"jwks-uri\" in OIDC metadata, or identity-uri/admin/v1/SigningCert/jwk if not available, only needed when jwt validation is done by us A resource pointing to JWK with public keys of signing certificates used to validate JWT. See Resource.create(io.helidon.config.Config) introspect-endpoint-uri \"introspection_endpoint\" in OIDC metadata, or identity-uri/oauth2/v1/introspect When validate-with-jwk is set to \"false\", this is the endpoint used base-scopes openid Configure scopes to be requested by default. If the scope has a qualifier, it must be included here redirect true Whether to redirect to identity server when authentication failed. realm helidon Realm returned in HTTP response if redirect is not enabled or possible. redirect-attempt-param h_ra Query parameter holding the number of times we redirected to an identity server. Customizable to prevent conflicts with application parameters max-redirects 5 Maximal number of times we can redirect to an identity server. When the number is reached, no further redirects happen and the request finishes with an error (status 401) server-type &#160; Type of identity server. Currently supported is idcs or not configured (for default). propagate &#160; Whether to propagate the token we have. Defaults to false unless an outbound configuration is defined outbound &#160; A list of outbound configurations outbound.*.name &#160; Required name of outbound configuration outbound.*.transports any transport An array of transports this outbound configuration should be used for outbound.*.hosts any host An array of hosts this outbound configuration should be used for, can be a regular expression outbound.*.paths any path An array of paths this outbound configuration should be used for (such as /greet ), can be a regular expression outbound.*.methods any method An array of HTTP methods this outbound configuration should be used for outbound.*.outbound-token Authorization header with bearer prefix Configuration of outbound header used to propagate outbound.*.outbound-token.header &#160; Name of the header used to propagate the token outbound.*.outbound-token.prefix &#160; Prefix for the header value, such as \"bearer\" (only one of prefix , regexp and format should be defined, regexp wins over prefix , format wins over regexp ) outbound.*.outbound-token.format &#160; String format with a single parameter to create the header value, such as \"bearer %1s\" outbound.*.outbound-token.regexp &#160; Regular expression to create the header value, such as \"bearer (.*)\" ",
            "title": "Configuration options"
        },
        {
            "location": "/mp/security/02_providers",
            "text": " As an experimental feature, you can set up cross-origin handling for the redirect and logout endpoints in an optional cors block inside the oidc configuration. The table below lists the configuration keys that identify the CORS characteristics. Configuration Key Default CORS Header Name allow-credentials false Access-Control-Allow-Credentials allow-headers [\"*\"] Access-Control-Allow-Headers allow-methods [\"*\"] Access-Control-Allow-Methods allow-origins [\"*\"] Access-Control-Allow-Origins expose-headers none Access-Control-Expose-Headers max-age 3600 Access-Control-Max-Age enabled true n/a If the cross-origin configuration is disabled ( enabled = false), then the Helidon CORS implementation ignores the cross-origin configuration entry. The following example of basic cross-origin configuration limits cross-origin resource sharing for PUT and DELETE operations to only foo.com and there.com : <markup lang=\"hocon\" >... allow-origins: [\"http://foo.com\", \"http://there.com\"] allow-methods: [\"PUT\", \"DELETE\"] ... ",
            "title": "CORS Settings"
        },
        {
            "location": "/mp/security/02_providers",
            "text": " At Helidon startup, if OIDC provider is configured, the following will happen: client-id , client-secret , and identityUri are validated - these must provide values Unless all resources are configured as local resources, the provider attempts to contact the oidc-metadata.resource endpoint to retrieve all endpoints At runtime, depending on configuration&#8230;&#8203; If a request comes without a token or with insufficient scopes: If redirect is set to true (default), request is redirected to the authorization endpoint of the identity server. If set to false, 401 is returned User authenticates against the identity server The identity server redirects back to Helidon service with a code Helidon service contacts the identity server&#8217;s token endpoint, to exchange the code for a JWT The JWT is stored in a cookie (if cookie support is enabled, which it is by default) Helidon service redirects to original endpoint (on itself) Helidon obtains a token from request (from cookie, header, or query parameter): Token is parsed as a singed JWT We validate the JWT signature either against local JWK or against the identity server&#8217;s introspection endpoint depending on configuration We validate the issuer and audience of the token if it matches the configured values A subject is created from the JWT, including scopes from the token We validate that we have sufficient scopes to proceed, and return 403 if not Handling is returned to security to process other security providers CORS Settings As an experimental feature, you can set up cross-origin handling for the redirect and logout endpoints in an optional cors block inside the oidc configuration. The table below lists the configuration keys that identify the CORS characteristics. Configuration Key Default CORS Header Name allow-credentials false Access-Control-Allow-Credentials allow-headers [\"*\"] Access-Control-Allow-Headers allow-methods [\"*\"] Access-Control-Allow-Methods allow-origins [\"*\"] Access-Control-Allow-Origins expose-headers none Access-Control-Expose-Headers max-age 3600 Access-Control-Max-Age enabled true n/a If the cross-origin configuration is disabled ( enabled = false), then the Helidon CORS implementation ignores the cross-origin configuration entry. The following example of basic cross-origin configuration limits cross-origin resource sharing for PUT and DELETE operations to only foo.com and there.com : <markup lang=\"hocon\" >... allow-origins: [\"http://foo.com\", \"http://there.com\"] allow-methods: [\"PUT\", \"DELETE\"] ... ",
            "title": "How does it work?"
        },
        {
            "location": "/mp/security/02_providers",
            "text": " Open ID Connect security provider. Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-oidc&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"text\" title=\"Provider class name\" >io.helidon.security.providers.oidc.OidcProvider <markup lang=\"text\" title=\"Provider configuration key\" >oidc Example code https://github.com/oracle/helidon/tree/master/examples/security/idcs-login <markup lang=\"yaml\" title=\"Configuration example\" >security: config.require-encryption: false security: providers: - oidc: client-id: \"client-id-of-this-service\" client-secret: \"${CLEAR=client-secret-of-this-service}\" identity-uri: \"http://your-tenant.identity-server.com\" frontend-uri: \"http://my-service:8080\" audience: \"http://my-service\" cors: allow-origins: [\"http://foo.com\", \"http://there.com\"] allow-methods: [\"PUT\", \"DELETE\"] outbound: - name: \"internal-services\" hosts: [\"*.example.org\"] outbound-token: header: \"X-Internal-Auth\" Configuration options The following table shows all configuration options of the provider and their default values key default value description optional false If set to true , failure to authenticate will return ABSTAIN result instead of FAILURE . This is an important distinction when more than one provider is used client-id &#160; Client ID as generated by identity server client-secret &#160; Client secret as generated by identity server identity-uri &#160; URI of the identity server, base used to retrieve OIDC metadata frontend-uri &#160; Full URI of this service for redirects back from OIDC server issuer issuer from OIDC metadata Issuer of token - each JWT is validated to check the issuer audience &#160; Audience of a token - each JWT is validated to check the audience cors &#160; Cross-origin resource sharing settings (see below) proxy-protocol http Proxy protocol to use when proxy is used proxy-host null Proxy host to use. When defined, triggers usage of proxy for HTTP requests proxy-port 80 Port of the proxy server to use redirect-uri /oidc/redirect URI to register web server component on, used by the OIDC server to redirect authorization requests to after a user logs in or approves scopes. Note that usually the redirect URI configured here must be the same one as configured on OIDC server. scope-audience empty string Audience of the scope required by this application. This is prefixed to the scope name when requesting scopes from the identity server. cookie-use true Whether to use cookie to store JWT. If used, redirects happen only in case the user is not authenticated or has insufficient scopes cookie-name JSESSIONID Name of the cookie cookie-domain &#160; Domain the cookie is valid for. Not used by default cookie-path / Path the cookie is valid for. cookie-max-age-seconds {nsbp} When using cookie, used to set MaxAge attribute of the cookie, defining how long the cookie is valid. cookie-http-only true When using cookie, if set to true, the HttpOnly attribute will be configured. cookie-secure false When using cookie, if set to true, the Secure attribute will be configured. cookie-same-site Lax When using cookie, used to set the SameSite cookie value. Can be \"Strict\" or \"Lax\". Setting this to \"Strict\" will result in infinite redirects when calling OIDC on a different host. query-param-use false Whether to expect JWT in a query parameter query-param-name accessToken Name of a query parameter that contains the JWT token when parameter is used. header-use false Whether to expect JWT in a header field. header-token Authorization header with prefix bearer A TokenHandler configuration to process header containing a JWT oidc-metadata-well-known true If set to true, metadata will be loaded from default (well known) location, unless it is explicitly defined using oidc-metadata-resource. If set to false, it would not be loaded even if oidc-metadata-resource is not defined. In such a case all URIs must be explicitly defined (e.g. token-endpoint-uri). oidc-metadata.resource identity-uri/.well-known/openid-configuration Resource configuration for OIDC Metadata containing endpoints to various identity services, as well as information about the identity server. See Resource.create(io.helidon.config.Config) token-endpoint-uri token_endpoint in OIDC metadata, or identity-url/oauth2/v1/token if not available URI of a token endpoint used to obtain a JWT based on the authentication code. authorization-endpoint-uri \"authorization_endpoint\" in OIDC metadata, or identity-uri/oauth2/v1/authorize if not available URI of an authorization endpoint used to redirect users to for logging-in. validate-with-jwk true When true - validate against jwk defined by \"sign-jwk\", when false validate JWT through OIDC Server endpoint \"validation-endpoint-uri\" sign-jwk.resource \"jwks-uri\" in OIDC metadata, or identity-uri/admin/v1/SigningCert/jwk if not available, only needed when jwt validation is done by us A resource pointing to JWK with public keys of signing certificates used to validate JWT. See Resource.create(io.helidon.config.Config) introspect-endpoint-uri \"introspection_endpoint\" in OIDC metadata, or identity-uri/oauth2/v1/introspect When validate-with-jwk is set to \"false\", this is the endpoint used base-scopes openid Configure scopes to be requested by default. If the scope has a qualifier, it must be included here redirect true Whether to redirect to identity server when authentication failed. realm helidon Realm returned in HTTP response if redirect is not enabled or possible. redirect-attempt-param h_ra Query parameter holding the number of times we redirected to an identity server. Customizable to prevent conflicts with application parameters max-redirects 5 Maximal number of times we can redirect to an identity server. When the number is reached, no further redirects happen and the request finishes with an error (status 401) server-type &#160; Type of identity server. Currently supported is idcs or not configured (for default). propagate &#160; Whether to propagate the token we have. Defaults to false unless an outbound configuration is defined outbound &#160; A list of outbound configurations outbound.*.name &#160; Required name of outbound configuration outbound.*.transports any transport An array of transports this outbound configuration should be used for outbound.*.hosts any host An array of hosts this outbound configuration should be used for, can be a regular expression outbound.*.paths any path An array of paths this outbound configuration should be used for (such as /greet ), can be a regular expression outbound.*.methods any method An array of HTTP methods this outbound configuration should be used for outbound.*.outbound-token Authorization header with bearer prefix Configuration of outbound header used to propagate outbound.*.outbound-token.header &#160; Name of the header used to propagate the token outbound.*.outbound-token.prefix &#160; Prefix for the header value, such as \"bearer\" (only one of prefix , regexp and format should be defined, regexp wins over prefix , format wins over regexp ) outbound.*.outbound-token.format &#160; String format with a single parameter to create the header value, such as \"bearer %1s\" outbound.*.outbound-token.regexp &#160; Regular expression to create the header value, such as \"bearer (.*)\" How does it work? At Helidon startup, if OIDC provider is configured, the following will happen: client-id , client-secret , and identityUri are validated - these must provide values Unless all resources are configured as local resources, the provider attempts to contact the oidc-metadata.resource endpoint to retrieve all endpoints At runtime, depending on configuration&#8230;&#8203; If a request comes without a token or with insufficient scopes: If redirect is set to true (default), request is redirected to the authorization endpoint of the identity server. If set to false, 401 is returned User authenticates against the identity server The identity server redirects back to Helidon service with a code Helidon service contacts the identity server&#8217;s token endpoint, to exchange the code for a JWT The JWT is stored in a cookie (if cookie support is enabled, which it is by default) Helidon service redirects to original endpoint (on itself) Helidon obtains a token from request (from cookie, header, or query parameter): Token is parsed as a singed JWT We validate the JWT signature either against local JWK or against the identity server&#8217;s introspection endpoint depending on configuration We validate the issuer and audience of the token if it matches the configured values A subject is created from the JWT, including scopes from the token We validate that we have sufficient scopes to proceed, and return 403 if not Handling is returned to security to process other security providers CORS Settings As an experimental feature, you can set up cross-origin handling for the redirect and logout endpoints in an optional cors block inside the oidc configuration. The table below lists the configuration keys that identify the CORS characteristics. Configuration Key Default CORS Header Name allow-credentials false Access-Control-Allow-Credentials allow-headers [\"*\"] Access-Control-Allow-Headers allow-methods [\"*\"] Access-Control-Allow-Methods allow-origins [\"*\"] Access-Control-Allow-Origins expose-headers none Access-Control-Expose-Headers max-age 3600 Access-Control-Max-Age enabled true n/a If the cross-origin configuration is disabled ( enabled = false), then the Helidon CORS implementation ignores the cross-origin configuration entry. The following example of basic cross-origin configuration limits cross-origin resource sharing for PUT and DELETE operations to only foo.com and there.com : <markup lang=\"hocon\" >... allow-origins: [\"http://foo.com\", \"http://there.com\"] allow-methods: [\"PUT\", \"DELETE\"] ... ",
            "title": "OIDC Provider"
        },
        {
            "location": "/mp/security/02_providers",
            "text": "<markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-http-auth&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"text\" title=\"Provider class name\" >io.helidon.security.providers.httpauth.HttpBasicAuthProvider <markup lang=\"text\" title=\"Provider configuration key\" >http-basic-auth ",
            "title": "Setup"
        },
        {
            "location": "/mp/security/02_providers",
            "text": " https://github.com/oracle/helidon/tree/master/examples/security/outbound-override <markup lang=\"yaml\" title=\"Configuration example\" >security: config.require-encryption: false security: providers: - http-basic-auth: realm: \"helidon\" users: - login: \"john\" password: \"${CLEAR=password}\" roles: [\"admin\"] - login: \"jack\" password: \"password\" roles: [\"user\", \"admin\"] outbound: - name: \"internal-services\" hosts: [\"*.example.org\"] # Propagates current user's identity or identity from request property outbound-token: header: \"X-Internal-Auth\" - name: \"partner-service\" hosts: [\"*.partner.org\"] # Uses this username and password username: \"partner-user-1\" password: \"${CLEAR=password}\" ",
            "title": "Example code"
        },
        {
            "location": "/mp/security/02_providers",
            "text": " The following table shows all configuration options of the provider and their default values key default value description optional false If set to true , failure to authenticate will return ABSTAIN result instead of FAILURE . This is an important distinction when more than one provider is used realm helidon The realm shown in challenge when user accesses a service without authentication principal-type USER Type of authenticated entity - either USER or SERVICE , can be used in combination with other authentication mechanism to authenticate both the user (as in person sitting in front of a computer) and a service (as in the application requesting this service on user&#8217;s behalf) users &#160; List of users when using configuration based approach. As an alternative, you can implement a java service (see below). outbound &#160; A list of outbound configurations outbound.*.name &#160; Required name of outbound configuration outbound.*.username &#160; Optional username used for outbound security; if not provided, current identity is propagated outbound.*.password &#160; Optional password used for outbound security outbound.*.transports any transport An array of transports this outbound configuration should be used for outbound.*.hosts any host An array of hosts this outbound configuration should be used for, can be a regular expression outbound.*.paths any path An array of paths this outbound configuration should be used for (such as /greet ), can be a regular expression outbound.*.methods any method An array of HTTP methods this outbound configuration should be used for outbound.*.outbound-token Authorization header with basic prefix Configuration of outbound header used to propagate outbound.*.outbound-token.header &#160; Name of the header used to propagate the token outbound.*.outbound-token.prefix &#160; Prefix for the header value, such as \"basic \" (only one of prefix , regexp and format should be defined, regexp wins over prefix , format wins over regexp ) outbound.*.outbound-token.format &#160; String format with a single parameter to create the header value, such as \"basic %1s\" outbound.*.outbound-token.regexp &#160; Regular expression to create the header value, such as \"basic (.*)\" ",
            "title": "Configuration options"
        },
        {
            "location": "/mp/security/02_providers",
            "text": " See https://tools.ietf.org/html/rfc7617 . Authentication of request When a request is received without the Authorization: basic &#8230;&#8203;. header, a challenge is returned to provide such authentication. When a request is received with the Authorization: basic &#8230;&#8203;. header, the username and password is validated against configured users (and users obtained from custom service if any provided). Subject is created based on the username and roles provided by the user store. Identity propagation When identity propagation is configured, there are several options for identifying username and password to propagate: We propagate the current username and password (inbound request must be authenticated using basic authentication). We use username and password from an explicitly configured property (See HttpBasicAuthProvider.EP_PROPERTY_OUTBOUND_USER and HttpBasicAuthProvider.EP_PROPERTY_OUTBOUND_PASSWORD ) We use username and password associated with an outbound target (see example configuration above) Identity is propagated only if: There is an outbound target configured for the endpoint Or there is an explicitly configured username/password for the current request (through request property) Custom user store Java service loader service io.helidon.security.providers.httpauth.spi.UserStoreService can be implemented to provide users to the provider, such as when validated against an internal database or LDAP server. The user store is defined so you never need the clear text password of the user. Warning on security of HTTP Basic Authenticaton (or lack thereof) Basic authentication uses base64 encoded username and password and passes it over the network. Base64 is only encoding, not encryption - so anybody that gets hold of the header value can learn the actual username and password of the user. This is a security risk and an attack vector that everybody should be aware of before using HTTP Basic Authentication. We recommend using this approach only for testing and demo purposes. ",
            "title": "How does it work?"
        },
        {
            "location": "/mp/security/02_providers",
            "text": " HTTP Basic authentication support Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-http-auth&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"text\" title=\"Provider class name\" >io.helidon.security.providers.httpauth.HttpBasicAuthProvider <markup lang=\"text\" title=\"Provider configuration key\" >http-basic-auth Example code https://github.com/oracle/helidon/tree/master/examples/security/outbound-override <markup lang=\"yaml\" title=\"Configuration example\" >security: config.require-encryption: false security: providers: - http-basic-auth: realm: \"helidon\" users: - login: \"john\" password: \"${CLEAR=password}\" roles: [\"admin\"] - login: \"jack\" password: \"password\" roles: [\"user\", \"admin\"] outbound: - name: \"internal-services\" hosts: [\"*.example.org\"] # Propagates current user's identity or identity from request property outbound-token: header: \"X-Internal-Auth\" - name: \"partner-service\" hosts: [\"*.partner.org\"] # Uses this username and password username: \"partner-user-1\" password: \"${CLEAR=password}\" Configuration options The following table shows all configuration options of the provider and their default values key default value description optional false If set to true , failure to authenticate will return ABSTAIN result instead of FAILURE . This is an important distinction when more than one provider is used realm helidon The realm shown in challenge when user accesses a service without authentication principal-type USER Type of authenticated entity - either USER or SERVICE , can be used in combination with other authentication mechanism to authenticate both the user (as in person sitting in front of a computer) and a service (as in the application requesting this service on user&#8217;s behalf) users &#160; List of users when using configuration based approach. As an alternative, you can implement a java service (see below). outbound &#160; A list of outbound configurations outbound.*.name &#160; Required name of outbound configuration outbound.*.username &#160; Optional username used for outbound security; if not provided, current identity is propagated outbound.*.password &#160; Optional password used for outbound security outbound.*.transports any transport An array of transports this outbound configuration should be used for outbound.*.hosts any host An array of hosts this outbound configuration should be used for, can be a regular expression outbound.*.paths any path An array of paths this outbound configuration should be used for (such as /greet ), can be a regular expression outbound.*.methods any method An array of HTTP methods this outbound configuration should be used for outbound.*.outbound-token Authorization header with basic prefix Configuration of outbound header used to propagate outbound.*.outbound-token.header &#160; Name of the header used to propagate the token outbound.*.outbound-token.prefix &#160; Prefix for the header value, such as \"basic \" (only one of prefix , regexp and format should be defined, regexp wins over prefix , format wins over regexp ) outbound.*.outbound-token.format &#160; String format with a single parameter to create the header value, such as \"basic %1s\" outbound.*.outbound-token.regexp &#160; Regular expression to create the header value, such as \"basic (.*)\" How does it work? See https://tools.ietf.org/html/rfc7617 . Authentication of request When a request is received without the Authorization: basic &#8230;&#8203;. header, a challenge is returned to provide such authentication. When a request is received with the Authorization: basic &#8230;&#8203;. header, the username and password is validated against configured users (and users obtained from custom service if any provided). Subject is created based on the username and roles provided by the user store. Identity propagation When identity propagation is configured, there are several options for identifying username and password to propagate: We propagate the current username and password (inbound request must be authenticated using basic authentication). We use username and password from an explicitly configured property (See HttpBasicAuthProvider.EP_PROPERTY_OUTBOUND_USER and HttpBasicAuthProvider.EP_PROPERTY_OUTBOUND_PASSWORD ) We use username and password associated with an outbound target (see example configuration above) Identity is propagated only if: There is an outbound target configured for the endpoint Or there is an explicitly configured username/password for the current request (through request property) Custom user store Java service loader service io.helidon.security.providers.httpauth.spi.UserStoreService can be implemented to provide users to the provider, such as when validated against an internal database or LDAP server. The user store is defined so you never need the clear text password of the user. Warning on security of HTTP Basic Authenticaton (or lack thereof) Basic authentication uses base64 encoded username and password and passes it over the network. Base64 is only encoding, not encryption - so anybody that gets hold of the header value can learn the actual username and password of the user. This is a security risk and an attack vector that everybody should be aware of before using HTTP Basic Authentication. We recommend using this approach only for testing and demo purposes. ",
            "title": "HTTP Basic Authentication Provider"
        },
        {
            "location": "/mp/security/02_providers",
            "text": "<markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-http-auth&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"text\" title=\"Provider class name\" >io.helidon.security.providers.httpauth.HttpDigestAuthProvider <markup lang=\"text\" title=\"Provider configuration key\" >http-digest-auth ",
            "title": "Setup"
        },
        {
            "location": "/mp/security/02_providers",
            "text": "<markup lang=\"yaml\" title=\"Configuration example\" >security: config.require-encryption: false security: providers: - http-digest-auth: realm: \"helidon\" server-secret: \"${CLEAR=service-wide-secret-not-known-outside}\" users: - login: \"john\" password: \"${CLEAR=password}\" roles: [\"admin\"] - login: \"jack\" password: \"password\" roles: [\"user\", \"admin\"] ",
            "title": "Example code"
        },
        {
            "location": "/mp/security/02_providers",
            "text": " The following table shows all configuration options of the provider and their default values key default value description optional false If set to true , failure to authenticate will return ABSTAIN result instead of FAILURE . This is an important distinction when more than one provider is used realm helidon The realm shown in challenge when user accesses a service without authentication principal-type USER Type of authenticated entity - either USER or SERVICE , can be used in combination with other authentication mechanism to authenticate both the user (as in person sitting in front of a computer) and a service (as in the application requesting this service on user&#8217;s behalf) users &#160; List of users when using configuration based approach. As an alternative, you can implement a java service (see below). algorithm MD5 Only MD5 supported nonce-timeout-millis 1 day Number of milliseconds for the nonce timeout server-secret random A string to use as a server secret - this is to use digest auth between multiple servers (e.g. when in a cluster). Used to encrypt nonce. This must not be known outside of this app, as others may create digest requests we would trust. qop NONE only AUTH supported. If left empty, uses the legacy approach (older RFC version). AUTH-INT is not supported. ",
            "title": "Configuration options"
        },
        {
            "location": "/mp/security/02_providers",
            "text": " See https://tools.ietf.org/html/rfc7616 . Authentication of request When a request is received without the Authorization: digest &#8230;&#8203;. header, a challenge is returned to provide such authentication using WWW-Authenticate header. When a request is received with the Authorization: digest &#8230;&#8203;. header, the request is validated against configured users (and users obtained from custom service if any provided). Subject is created based on the username and roles provided by the user store. Custom user store Java service loader service io.helidon.security.providers.httpauth.spi.UserStoreService can be implemented to provide users to the provider, such as when validated against an internal database or LDAP server. The user store is defined so you never need the clear text password of the user. Note on security of HTTP Digest Authenticaton These authentication schemes should be obsolete , though they provide a very easy way to test a protected resource. ",
            "title": "How does it work?"
        },
        {
            "location": "/mp/security/02_providers",
            "text": " HTTP Digest authentication support Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-http-auth&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"text\" title=\"Provider class name\" >io.helidon.security.providers.httpauth.HttpDigestAuthProvider <markup lang=\"text\" title=\"Provider configuration key\" >http-digest-auth Example code <markup lang=\"yaml\" title=\"Configuration example\" >security: config.require-encryption: false security: providers: - http-digest-auth: realm: \"helidon\" server-secret: \"${CLEAR=service-wide-secret-not-known-outside}\" users: - login: \"john\" password: \"${CLEAR=password}\" roles: [\"admin\"] - login: \"jack\" password: \"password\" roles: [\"user\", \"admin\"] Configuration options The following table shows all configuration options of the provider and their default values key default value description optional false If set to true , failure to authenticate will return ABSTAIN result instead of FAILURE . This is an important distinction when more than one provider is used realm helidon The realm shown in challenge when user accesses a service without authentication principal-type USER Type of authenticated entity - either USER or SERVICE , can be used in combination with other authentication mechanism to authenticate both the user (as in person sitting in front of a computer) and a service (as in the application requesting this service on user&#8217;s behalf) users &#160; List of users when using configuration based approach. As an alternative, you can implement a java service (see below). algorithm MD5 Only MD5 supported nonce-timeout-millis 1 day Number of milliseconds for the nonce timeout server-secret random A string to use as a server secret - this is to use digest auth between multiple servers (e.g. when in a cluster). Used to encrypt nonce. This must not be known outside of this app, as others may create digest requests we would trust. qop NONE only AUTH supported. If left empty, uses the legacy approach (older RFC version). AUTH-INT is not supported. How does it work? See https://tools.ietf.org/html/rfc7616 . Authentication of request When a request is received without the Authorization: digest &#8230;&#8203;. header, a challenge is returned to provide such authentication using WWW-Authenticate header. When a request is received with the Authorization: digest &#8230;&#8203;. header, the request is validated against configured users (and users obtained from custom service if any provided). Subject is created based on the username and roles provided by the user store. Custom user store Java service loader service io.helidon.security.providers.httpauth.spi.UserStoreService can be implemented to provide users to the provider, such as when validated against an internal database or LDAP server. The user store is defined so you never need the clear text password of the user. Note on security of HTTP Digest Authenticaton These authentication schemes should be obsolete , though they provide a very easy way to test a protected resource. ",
            "title": "HTTP Digest Authentication Provider"
        },
        {
            "location": "/mp/security/02_providers",
            "text": "<markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-header&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"text\" title=\"Provider class name\" >io.helidon.security.providers.header.HeaderAtnProvider <markup lang=\"text\" title=\"Provider configuration key\" >header-atn ",
            "title": "Setup"
        },
        {
            "location": "/mp/security/02_providers",
            "text": "<markup lang=\"yaml\" title=\"Configuration example\" >security: providers: header-atn: atn-token: header: \"X-AUTH-USER\" outbound: - name: \"internal-services\" hosts: [\"*.example.org\"] # propagates the current user or service id using the same header as authentication - name: \"partner-service\" hosts: [\"*.partner.org\"] # propagates an explicit username in a custom header username: \"service-27\" outbound-token: header: \"X-Service-Auth\" ",
            "title": "Example code"
        },
        {
            "location": "/mp/security/02_providers",
            "text": " The following table shows all configuration options of the provider and their default values key default value description optional false If set to true , failure to authenticate will return ABSTAIN result instead of FAILURE . This is an important distinction when more than one provider is used authenticate true If set to false , authentication will not be attempted (outbound security can still be used) propagate false If explicitly set to false , identity propagation will not be done. Otherwise it is done if an outbound section is configured principal-type USER Can be USER or SERVICE atn-token none Token extraction and propagation, you can define which header to use and how to extract it outbound &#160; A list of outbound configurations outbound.*.name &#160; Required name of outbound configuration outbound.*.username &#160; Optional username used for outbound security; if not provided, current identity is propagated outbound.*.transports any transport An array of transports this outbound configuration should be used for outbound.*.hosts any host An array of hosts this outbound configuration should be used for, can be a regular expression outbound.*.paths any path An array of paths this outbound configuration should be used for (such as /greet ), can be a regular expression outbound.*.methods any method An array of HTTP methods this outbound configuration should be used for outbound.*.outbound-token same as atn-token Configuration of outbound header used to propagate outbound.*.outbound-token.header &#160; Name of the header used to propagate the token outbound.*.outbound-token.prefix &#160; Prefix for the header value, such as \"username \" (only one of prefix , regexp and format should be defined, regexp wins over prefix , format wins over regexp ) outbound.*.outbound-token.format &#160; String format with a single parameter to create the header value, such as \"username %1s\" outbound.*.outbound-token.regexp &#160; Regular expression to create the header value, such as \"username (.*)\" ",
            "title": "Configuration options"
        },
        {
            "location": "/mp/security/02_providers",
            "text": " This provider inspects a specified request header and extracts the username/service name from it and asserts it as current subject&#8217;s principal. This can be used when we use perimeter authentication (e.g. there is a gateway that takes care of authentication and propagates the user in a header). Identity propagation Identity is propagated only if an outbound target matches the target service. The following options exist when propagating identity: 1. We propagate the current username using the configured header 2. We use username associated with an outbound target (see example configuration above) Caution When using this provider, you must be sure the header cannot be explicitly configured by a user or another service. All requests should go through a gateway that removes this header from inbound traffic, and only configures it for authenticated users/services. Another option is to use this with fully trusted parties (such as services within a single company, on a single protected network not accessible to any users), and of course for testing and demo purposes. ",
            "title": "How does it work?"
        },
        {
            "location": "/mp/security/02_providers",
            "text": " Asserts user or service identity based on a value of a header. Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-header&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"text\" title=\"Provider class name\" >io.helidon.security.providers.header.HeaderAtnProvider <markup lang=\"text\" title=\"Provider configuration key\" >header-atn Example code <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: header-atn: atn-token: header: \"X-AUTH-USER\" outbound: - name: \"internal-services\" hosts: [\"*.example.org\"] # propagates the current user or service id using the same header as authentication - name: \"partner-service\" hosts: [\"*.partner.org\"] # propagates an explicit username in a custom header username: \"service-27\" outbound-token: header: \"X-Service-Auth\" Configuration options The following table shows all configuration options of the provider and their default values key default value description optional false If set to true , failure to authenticate will return ABSTAIN result instead of FAILURE . This is an important distinction when more than one provider is used authenticate true If set to false , authentication will not be attempted (outbound security can still be used) propagate false If explicitly set to false , identity propagation will not be done. Otherwise it is done if an outbound section is configured principal-type USER Can be USER or SERVICE atn-token none Token extraction and propagation, you can define which header to use and how to extract it outbound &#160; A list of outbound configurations outbound.*.name &#160; Required name of outbound configuration outbound.*.username &#160; Optional username used for outbound security; if not provided, current identity is propagated outbound.*.transports any transport An array of transports this outbound configuration should be used for outbound.*.hosts any host An array of hosts this outbound configuration should be used for, can be a regular expression outbound.*.paths any path An array of paths this outbound configuration should be used for (such as /greet ), can be a regular expression outbound.*.methods any method An array of HTTP methods this outbound configuration should be used for outbound.*.outbound-token same as atn-token Configuration of outbound header used to propagate outbound.*.outbound-token.header &#160; Name of the header used to propagate the token outbound.*.outbound-token.prefix &#160; Prefix for the header value, such as \"username \" (only one of prefix , regexp and format should be defined, regexp wins over prefix , format wins over regexp ) outbound.*.outbound-token.format &#160; String format with a single parameter to create the header value, such as \"username %1s\" outbound.*.outbound-token.regexp &#160; Regular expression to create the header value, such as \"username (.*)\" How does it work? This provider inspects a specified request header and extracts the username/service name from it and asserts it as current subject&#8217;s principal. This can be used when we use perimeter authentication (e.g. there is a gateway that takes care of authentication and propagates the user in a header). Identity propagation Identity is propagated only if an outbound target matches the target service. The following options exist when propagating identity: 1. We propagate the current username using the configured header 2. We use username associated with an outbound target (see example configuration above) Caution When using this provider, you must be sure the header cannot be explicitly configured by a user or another service. All requests should go through a gateway that removes this header from inbound traffic, and only configures it for authenticated users/services. Another option is to use this with fully trusted parties (such as services within a single company, on a single protected network not accessible to any users), and of course for testing and demo purposes. ",
            "title": "Header Authentication Provider"
        },
        {
            "location": "/mp/security/02_providers",
            "text": "<markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-http-sign&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"text\" title=\"Provider class name\" >io.helidon.security.providers.httpsign.HttpSignProvider <markup lang=\"text\" title=\"Provider configuration key\" >http-signatures ",
            "title": "Setup"
        },
        {
            "location": "/mp/security/02_providers",
            "text": " https://github.com/oracle/helidon/tree/master/examples/security/webserver-signatures <markup lang=\"yaml\" title=\"Configuration example\" >security: config.require-encryption: false security: providers: - http-signatures: inbound: keys: - key-id: \"service1-hmac\" principal-name: \"Service1 - HMAC signature\" hmac.secret: \"${CLEAR=somePasswordForHmacShouldBeEncrypted}\" - key-id: \"service1-rsa\" principal-name: \"Service1 - RSA signature\" public-key: keystore: resource.path: \"src/main/resources/keystore.p12\" passphrase: \"password\" cert.alias: \"service_cert\" outbound: - name: \"service2-hmac\" hosts: [\"localhost\"] paths: [\"/service2\"] signature: key-id: \"service1-hmac\" hmac.secret: \"${CLEAR=somePasswordForHmacShouldBeEncrypted}\" - name: \"service2-rsa\" hosts: [\"localhost\"] paths: [\"/service2-rsa.*\"] signature: key-id: \"service1-rsa\" private-key: keystore: resource.path: \"src/main/resources/keystore.p12\" passphrase: \"password\" key.alias: \"myPrivateKey\" ",
            "title": "Example code"
        },
        {
            "location": "/mp/security/02_providers",
            "text": " The following table shows all configuration options of the provider and their default values key default value description optional false If set to true , failure to authenticate will return ABSTAIN result instead of FAILURE . This is an important distinction when more than one provider is used realm helidon Realm used for challenge when request does not have a signature headers [SIGNATURE,AUTHORIZATION,CUSTOM] Headers to look for inbound signatures and to store outbound signatures. CUSTOM is provided using io.helidon.security.util.TokenHandler sign-headers always = [\"date\"] Headers to be signed sign-headers.*.method default for all methods Method this configuration is valid for sign-headers.*.always &#160; Array of headers to be always required in the request signature sign-headers.*.if-present &#160; Array of headers to be part of the signatures if present in the request inbound &#160; Configuration of inbound traffic for authenticating incoming requests inbound.keys &#160; Configuration of signature keys to verify incoming requests inbound.keys.*.key-id &#160; Key id as used in inbound signature to find the correct certificate/hmac configuration to verify the signature inbound.keys.*.principal-name &#160; The principal name (or user name) asserted when the signature is valid inbound.keys.*.principal-type SERVICE The type of principal to assert (can be USER ) inbound.keys.*.algorithm according to other configuration hmac-sha256 or rsa-sha256 is assumed if other configuration options for that type are set inbound.keys.*.hmac.secret &#160; Secret shared by the service that signed the request and this service for hmac-sha256 algorithm inbound.keys.*.public-key &#160; Public key configuration, implies rsa-sha256 algorithm inbound.keys.*.public-key.keystore &#160; Keystore configuration for public key - full configuration as defined by KeyStore class outbound &#160; A list of outbound configurations outbound.*.name &#160; Required name of outbound configuration outbound.*.username &#160; Optional username used for outbound security; if not provided, current identity is propagated outbound.*.password &#160; Optional password used for outbound security outbound.*.transports any transport An array of transports this outbound configuration should be used for outbound.*.hosts any host An array of hosts this outbound configuration should be used for, can be a regular expression outbound.*.paths any path An array of paths this outbound configuration should be used for (such as /greet ), can be a regular expression outbound.*.methods any method An array of HTTP methods this outbound configuration should be used for outbound.*.signature &#160; Configuration related to outbound signature configuration outbound.*.signature.key-id &#160; Key id to use in the outbound signature (to map to appropriate public key in target service&#8217;s configuration) outbound.*.signature.header [SIGNATURE,AUTHORIZATION,CUSTOM] Headers supported by HTTP Signature. CUSTOM is provided using io.helidon.security.util.TokenHandler outbound.*.signature.hmac.secret &#160; Shared secret for hmac outbound.*.signature.private-key &#160; Private key configuration for rsa based signatures outbound.*.signature.private-key.keystore &#160; Keystore configuration for private key - full configuration as defined by KeyStore class ",
            "title": "Configuration options"
        },
        {
            "location": "/mp/security/02_providers",
            "text": " standard: based on https://tools.ietf.org/html/draft-cavage-http-signatures-03 key-id: an arbitrary string used to locate signature configuration - when a request is received the provider locates validation configuration based on this id (e.g. HMAC shared secret or RSA public key). Commonly used meanings are: key fingerprint (RSA); API Key ",
            "title": "Signature basics"
        },
        {
            "location": "/mp/security/02_providers",
            "text": " Inbound Signatures We act as a server and another party is calling us with a signed HTTP request. We validate the signature and assume identity of the caller. Outbound Signatures We act as a client and we sign our outgoing requests. If there is a matching outbound target specified in configuration, its configuration will be applied for signing the outgoing request, otherwise there is no signature added ",
            "title": "How does it work?"
        },
        {
            "location": "/mp/security/02_providers",
            "text": " Support for HTTP Signatures. Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-http-sign&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"text\" title=\"Provider class name\" >io.helidon.security.providers.httpsign.HttpSignProvider <markup lang=\"text\" title=\"Provider configuration key\" >http-signatures Example code https://github.com/oracle/helidon/tree/master/examples/security/webserver-signatures <markup lang=\"yaml\" title=\"Configuration example\" >security: config.require-encryption: false security: providers: - http-signatures: inbound: keys: - key-id: \"service1-hmac\" principal-name: \"Service1 - HMAC signature\" hmac.secret: \"${CLEAR=somePasswordForHmacShouldBeEncrypted}\" - key-id: \"service1-rsa\" principal-name: \"Service1 - RSA signature\" public-key: keystore: resource.path: \"src/main/resources/keystore.p12\" passphrase: \"password\" cert.alias: \"service_cert\" outbound: - name: \"service2-hmac\" hosts: [\"localhost\"] paths: [\"/service2\"] signature: key-id: \"service1-hmac\" hmac.secret: \"${CLEAR=somePasswordForHmacShouldBeEncrypted}\" - name: \"service2-rsa\" hosts: [\"localhost\"] paths: [\"/service2-rsa.*\"] signature: key-id: \"service1-rsa\" private-key: keystore: resource.path: \"src/main/resources/keystore.p12\" passphrase: \"password\" key.alias: \"myPrivateKey\" Configuration options The following table shows all configuration options of the provider and their default values key default value description optional false If set to true , failure to authenticate will return ABSTAIN result instead of FAILURE . This is an important distinction when more than one provider is used realm helidon Realm used for challenge when request does not have a signature headers [SIGNATURE,AUTHORIZATION,CUSTOM] Headers to look for inbound signatures and to store outbound signatures. CUSTOM is provided using io.helidon.security.util.TokenHandler sign-headers always = [\"date\"] Headers to be signed sign-headers.*.method default for all methods Method this configuration is valid for sign-headers.*.always &#160; Array of headers to be always required in the request signature sign-headers.*.if-present &#160; Array of headers to be part of the signatures if present in the request inbound &#160; Configuration of inbound traffic for authenticating incoming requests inbound.keys &#160; Configuration of signature keys to verify incoming requests inbound.keys.*.key-id &#160; Key id as used in inbound signature to find the correct certificate/hmac configuration to verify the signature inbound.keys.*.principal-name &#160; The principal name (or user name) asserted when the signature is valid inbound.keys.*.principal-type SERVICE The type of principal to assert (can be USER ) inbound.keys.*.algorithm according to other configuration hmac-sha256 or rsa-sha256 is assumed if other configuration options for that type are set inbound.keys.*.hmac.secret &#160; Secret shared by the service that signed the request and this service for hmac-sha256 algorithm inbound.keys.*.public-key &#160; Public key configuration, implies rsa-sha256 algorithm inbound.keys.*.public-key.keystore &#160; Keystore configuration for public key - full configuration as defined by KeyStore class outbound &#160; A list of outbound configurations outbound.*.name &#160; Required name of outbound configuration outbound.*.username &#160; Optional username used for outbound security; if not provided, current identity is propagated outbound.*.password &#160; Optional password used for outbound security outbound.*.transports any transport An array of transports this outbound configuration should be used for outbound.*.hosts any host An array of hosts this outbound configuration should be used for, can be a regular expression outbound.*.paths any path An array of paths this outbound configuration should be used for (such as /greet ), can be a regular expression outbound.*.methods any method An array of HTTP methods this outbound configuration should be used for outbound.*.signature &#160; Configuration related to outbound signature configuration outbound.*.signature.key-id &#160; Key id to use in the outbound signature (to map to appropriate public key in target service&#8217;s configuration) outbound.*.signature.header [SIGNATURE,AUTHORIZATION,CUSTOM] Headers supported by HTTP Signature. CUSTOM is provided using io.helidon.security.util.TokenHandler outbound.*.signature.hmac.secret &#160; Shared secret for hmac outbound.*.signature.private-key &#160; Private key configuration for rsa based signatures outbound.*.signature.private-key.keystore &#160; Keystore configuration for private key - full configuration as defined by KeyStore class Signature basics standard: based on https://tools.ietf.org/html/draft-cavage-http-signatures-03 key-id: an arbitrary string used to locate signature configuration - when a request is received the provider locates validation configuration based on this id (e.g. HMAC shared secret or RSA public key). Commonly used meanings are: key fingerprint (RSA); API Key How does it work? Inbound Signatures We act as a server and another party is calling us with a signed HTTP request. We validate the signature and assume identity of the caller. Outbound Signatures We act as a client and we sign our outgoing requests. If there is a matching outbound target specified in configuration, its configuration will be applied for signing the outgoing request, otherwise there is no signature added ",
            "title": "HTTP Signatures Provider"
        },
        {
            "location": "/mp/security/02_providers",
            "text": "<markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-idcs-mapper&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"text\" title=\"Provider class name\" >io.helidon.security.providers.idcs.mapper.IdcsRoleMapperProvider <markup lang=\"text\" title=\"Provider configuration key\" >idcs-role-mapper ",
            "title": "Setup"
        },
        {
            "location": "/mp/security/02_providers",
            "text": " https://github.com/oracle/helidon/tree/master/examples/security/idcs-login/ <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - idcs-role-mapper: multitenant: false oidc-config: client-id: \"client-id\" client-secret: \"client-secret\" identity-uri: \"IDCS identity server address\" ",
            "title": "Example code"
        },
        {
            "location": "/mp/security/02_providers",
            "text": " The following table shows all configuration options of the provider and their default values key default value description multitenant true Whether to support multi-tenancy with this provider idcs-tenant-handler Header X-USER-IDENTITY-SERVICE-GUID Multi-tenant specific TokenHandler configuration to retrieve the tenant id idcs-app-name-handler Header X-RESOURCE-SERVICE-INSTANCE-IDENTITY-APPNAME Multi-tenant specific TokenHandler configuration to retrieve the application name cache-config &#160; Configuration of cache of roles for subjects cache-config.cache-enabled true Possibility to disable the cache altogether cache-config.max-size 100_000 Maximal number of records in the cache cache-config.cache-timeout-millis 1 hour Cache timeout in milliseconds cache-config.cache-evict-delay-millis 1 minute How long to wait before starting the first eviction process cache-config.cache-evict-period-millis 5 minutes Period of running the eviction process cache-config.parallelism-threshold 10_000 Threshold as used by ConcurrentHashMap.forEachKey cache-config.evictor-class &#160; Implementation of BiFunction that receives key and value, and returns true for records that should be removed from the cache. Eviction mechanism should be fast, as it is called within methods of ConcurrentHashMap subject-types USER Can use USER and/or SERVICE default-idcs-subject-type user Default subject type to use when requesting roles, can be user or client oidc-config &#160; OidcConfig configuration, except validate-with-jwk is set to false , and server-type is set to idcs ",
            "title": "Configuration options"
        },
        {
            "location": "/mp/security/02_providers",
            "text": " The provider asks the IDCS server to provide list of roles for the currently authenticated user. The result is cached for a certain period of time (see cache-config above). ",
            "title": "How does it work?"
        },
        {
            "location": "/mp/security/02_providers",
            "text": " A role mapper to retrieve roles from Oracle IDCS. Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-idcs-mapper&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"text\" title=\"Provider class name\" >io.helidon.security.providers.idcs.mapper.IdcsRoleMapperProvider <markup lang=\"text\" title=\"Provider configuration key\" >idcs-role-mapper Example code https://github.com/oracle/helidon/tree/master/examples/security/idcs-login/ <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - idcs-role-mapper: multitenant: false oidc-config: client-id: \"client-id\" client-secret: \"client-secret\" identity-uri: \"IDCS identity server address\" Configuration options The following table shows all configuration options of the provider and their default values key default value description multitenant true Whether to support multi-tenancy with this provider idcs-tenant-handler Header X-USER-IDENTITY-SERVICE-GUID Multi-tenant specific TokenHandler configuration to retrieve the tenant id idcs-app-name-handler Header X-RESOURCE-SERVICE-INSTANCE-IDENTITY-APPNAME Multi-tenant specific TokenHandler configuration to retrieve the application name cache-config &#160; Configuration of cache of roles for subjects cache-config.cache-enabled true Possibility to disable the cache altogether cache-config.max-size 100_000 Maximal number of records in the cache cache-config.cache-timeout-millis 1 hour Cache timeout in milliseconds cache-config.cache-evict-delay-millis 1 minute How long to wait before starting the first eviction process cache-config.cache-evict-period-millis 5 minutes Period of running the eviction process cache-config.parallelism-threshold 10_000 Threshold as used by ConcurrentHashMap.forEachKey cache-config.evictor-class &#160; Implementation of BiFunction that receives key and value, and returns true for records that should be removed from the cache. Eviction mechanism should be fast, as it is called within methods of ConcurrentHashMap subject-types USER Can use USER and/or SERVICE default-idcs-subject-type user Default subject type to use when requesting roles, can be user or client oidc-config &#160; OidcConfig configuration, except validate-with-jwk is set to false , and server-type is set to idcs How does it work? The provider asks the IDCS server to provide list of roles for the currently authenticated user. The result is cached for a certain period of time (see cache-config above). ",
            "title": "IDCS Role Mapper"
        },
        {
            "location": "/mp/security/02_providers",
            "text": "<markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-abac&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"text\" title=\"Provider class name\" >io.helidon.security.providers.abac.AbacProvider <markup lang=\"text\" title=\"Provider configuration key\" >abac ",
            "title": "Setup"
        },
        {
            "location": "/mp/security/02_providers",
            "text": " https://github.com/oracle/helidon/tree/master/examples/security/attribute-based-access-control <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - abac: ",
            "title": "Example code"
        },
        {
            "location": "/mp/security/02_providers",
            "text": " The following table shows all configuration options of the provider and their default values key default value description fail-on-unvalidated true \"Unvalidated\" means: an attribute is defined, but there is no validator available for it fail-if-none-validated true \"None validated\" means: there was not a single attribute that was validated ",
            "title": "Configuration options"
        },
        {
            "location": "/mp/security/02_providers",
            "text": " ABAC uses available validators and validates them against attributes of the authenticated user. Combinations of fail-on-unvalidated and fail-if-none-validated : true &amp; true : Will fail if any attribute is not validated and if any has failed validation false &amp; true : Will fail if there is one or more attributes present and NONE of them is validated or if any has failed validation, Will NOT fail if there is at least one validated attribute and any number of not validated attributes (and NONE failed) false &amp; false : Will fail if there is any attribute that failed validation, Will NOT fail if there are no failed validation or if there are NONE validated Any attribute of the following objects can be used: environment (such as time of request) - e.g. env.time.year subject (user) - e.g. subject.principal.id subject (service) - e.g. service.principal.id object (must be explicitly invoked by developer in code, as object cannot be automatically added to security context) - e.g. object.owner This provider checks that all defined ABAC validators are validated. If there is a definition for a validator that is not checked, the request is denied (depending on configuration as mentioned above). ABAC provider also allows an object to be used in authorization process, such as when evaluating if an object&#8217;s owner is the current user. The following example uses the Expression language validator to demonstrate the point in a JAX-RS resource: <markup lang=\"java\" title=\"Example of using an object\" >@Authenticated @Path(\"/abac\") public class AbacResource { @GET @Authorized(explicit = true) @PolicyStatement(\"${env.time.year &gt;= 2017 &amp;&amp; object.owner == subject.principal.id}\") public Response process(@Context SecurityContext context) { // probably looked up from a database SomeResource res = new SomeResource(\"user\"); AuthorizationResponse atzResponse = context.authorize(res); if (atzResponse.isPermitted()) { //do the update return Response.ok().entity(\"fine, sir\").build(); } else { return Response.status(Response.Status.FORBIDDEN) .entity(atzResponse.getDescription().orElse(\"Access not granted\")) .build(); } } } The following validators are implemented: Roles Scopes EL Policy ",
            "title": "How does it work?"
        },
        {
            "location": "/mp/security/02_providers",
            "text": " When using sub-resource locators in JAX-RS, the roles allowed are collected from each \"level\" of execution: - Application class annotations - Resource class annotations + resource method annotations - Sub-resource class annotations + sub-resource method annotations - Sub-resource class annotations + sub-resource method annotations (for every sub-resource on the path) The RolesAllowed or Roles annotation to be used is the last one in the path as defined above. Example 1: There is a RolesAllowed(\"admin\") defined on a sub-resource locator resource class. In this case the required role is admin . Example 2: There is a RolesAllowed(\"admin\") defined on a sub-resource locator resource class and a RolesAllowed(\"user\") defined on the method of the sub-resource that provides the response. In this case the required role is user . ",
            "title": "Interaction with JAX-RS sub-resource locators"
        },
        {
            "location": "/mp/security/02_providers",
            "text": " Checks whether user/service is in either of the required role(s). Configuration Key: role-validator Annotations: @RolesAllowed , @RoleValidator.Roles <markup lang=\"yaml\" title=\"Configuration example for WebServer \" >security: web-server.paths: - path: \"/user[/{*}]\" roles-allowed: [\"user\"] <markup lang=\"java\" title=\"JAX-RS example\" >@RolesAllowed(\"user\") @RoleValidator.Roles(value = \"service_role\", subjectType = SubjectType.SERVICE) @Authenticated @Path(\"/abac\") public class AbacResource { } Interaction with JAX-RS sub-resource locators When using sub-resource locators in JAX-RS, the roles allowed are collected from each \"level\" of execution: - Application class annotations - Resource class annotations + resource method annotations - Sub-resource class annotations + sub-resource method annotations - Sub-resource class annotations + sub-resource method annotations (for every sub-resource on the path) The RolesAllowed or Roles annotation to be used is the last one in the path as defined above. Example 1: There is a RolesAllowed(\"admin\") defined on a sub-resource locator resource class. In this case the required role is admin . Example 2: There is a RolesAllowed(\"admin\") defined on a sub-resource locator resource class and a RolesAllowed(\"user\") defined on the method of the sub-resource that provides the response. In this case the required role is user . ",
            "title": "Role Validator"
        },
        {
            "location": "/mp/security/02_providers",
            "text": " Checks whether user has all the required scopes. Configuration Key: scope-validator Annotations: @Scope <markup lang=\"yaml\" title=\"Configuration example for WebServer \" >security: web-server.paths: - path: \"/user[/{*}]\" abac.scopes: [\"calendar_read\", \"calendar_edit\"] <markup lang=\"java\" title=\"JAX-RS example\" >@Scope(\"calendar_read\") @Scope(\"calendar_edit\") @Authenticated @Path(\"/abac\") public class AbacResource { } ",
            "title": "Scope Validator"
        },
        {
            "location": "/mp/security/02_providers",
            "text": " Policy executor using Java EE policy expression language (EL) Configuration Key: policy-javax-el Annotations: @PolicyStatement Example of a policy statement: ${env.time.year &gt;= 2017} <markup lang=\"yaml\" title=\"Configuration example for WebServer \" >security: web-server.paths: - path: \"/user[/{*}]\" policy: statement: \"hasScopes('calendar_read','calendar_edit') AND timeOfDayBetween('8:15', '17:30')\" <markup lang=\"java\" title=\"JAX-RS example\" >@PolicyStatement(\"${env.time.year &gt;= 2017}\") @Authenticated @Path(\"/abac\") public class AbacResource { } ",
            "title": "Expression Language Policy Validator"
        },
        {
            "location": "/mp/security/02_providers",
            "text": " Attribute based access control authorization provider. Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-abac&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"text\" title=\"Provider class name\" >io.helidon.security.providers.abac.AbacProvider <markup lang=\"text\" title=\"Provider configuration key\" >abac Example code https://github.com/oracle/helidon/tree/master/examples/security/attribute-based-access-control <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - abac: Configuration options The following table shows all configuration options of the provider and their default values key default value description fail-on-unvalidated true \"Unvalidated\" means: an attribute is defined, but there is no validator available for it fail-if-none-validated true \"None validated\" means: there was not a single attribute that was validated How does it work? ABAC uses available validators and validates them against attributes of the authenticated user. Combinations of fail-on-unvalidated and fail-if-none-validated : true &amp; true : Will fail if any attribute is not validated and if any has failed validation false &amp; true : Will fail if there is one or more attributes present and NONE of them is validated or if any has failed validation, Will NOT fail if there is at least one validated attribute and any number of not validated attributes (and NONE failed) false &amp; false : Will fail if there is any attribute that failed validation, Will NOT fail if there are no failed validation or if there are NONE validated Any attribute of the following objects can be used: environment (such as time of request) - e.g. env.time.year subject (user) - e.g. subject.principal.id subject (service) - e.g. service.principal.id object (must be explicitly invoked by developer in code, as object cannot be automatically added to security context) - e.g. object.owner This provider checks that all defined ABAC validators are validated. If there is a definition for a validator that is not checked, the request is denied (depending on configuration as mentioned above). ABAC provider also allows an object to be used in authorization process, such as when evaluating if an object&#8217;s owner is the current user. The following example uses the Expression language validator to demonstrate the point in a JAX-RS resource: <markup lang=\"java\" title=\"Example of using an object\" >@Authenticated @Path(\"/abac\") public class AbacResource { @GET @Authorized(explicit = true) @PolicyStatement(\"${env.time.year &gt;= 2017 &amp;&amp; object.owner == subject.principal.id}\") public Response process(@Context SecurityContext context) { // probably looked up from a database SomeResource res = new SomeResource(\"user\"); AuthorizationResponse atzResponse = context.authorize(res); if (atzResponse.isPermitted()) { //do the update return Response.ok().entity(\"fine, sir\").build(); } else { return Response.status(Response.Status.FORBIDDEN) .entity(atzResponse.getDescription().orElse(\"Access not granted\")) .build(); } } } The following validators are implemented: Roles Scopes EL Policy Role Validator Checks whether user/service is in either of the required role(s). Configuration Key: role-validator Annotations: @RolesAllowed , @RoleValidator.Roles <markup lang=\"yaml\" title=\"Configuration example for WebServer \" >security: web-server.paths: - path: \"/user[/{*}]\" roles-allowed: [\"user\"] <markup lang=\"java\" title=\"JAX-RS example\" >@RolesAllowed(\"user\") @RoleValidator.Roles(value = \"service_role\", subjectType = SubjectType.SERVICE) @Authenticated @Path(\"/abac\") public class AbacResource { } Interaction with JAX-RS sub-resource locators When using sub-resource locators in JAX-RS, the roles allowed are collected from each \"level\" of execution: - Application class annotations - Resource class annotations + resource method annotations - Sub-resource class annotations + sub-resource method annotations - Sub-resource class annotations + sub-resource method annotations (for every sub-resource on the path) The RolesAllowed or Roles annotation to be used is the last one in the path as defined above. Example 1: There is a RolesAllowed(\"admin\") defined on a sub-resource locator resource class. In this case the required role is admin . Example 2: There is a RolesAllowed(\"admin\") defined on a sub-resource locator resource class and a RolesAllowed(\"user\") defined on the method of the sub-resource that provides the response. In this case the required role is user . Scope Validator Checks whether user has all the required scopes. Configuration Key: scope-validator Annotations: @Scope <markup lang=\"yaml\" title=\"Configuration example for WebServer \" >security: web-server.paths: - path: \"/user[/{*}]\" abac.scopes: [\"calendar_read\", \"calendar_edit\"] <markup lang=\"java\" title=\"JAX-RS example\" >@Scope(\"calendar_read\") @Scope(\"calendar_edit\") @Authenticated @Path(\"/abac\") public class AbacResource { } Expression Language Policy Validator Policy executor using Java EE policy expression language (EL) Configuration Key: policy-javax-el Annotations: @PolicyStatement Example of a policy statement: ${env.time.year &gt;= 2017} <markup lang=\"yaml\" title=\"Configuration example for WebServer \" >security: web-server.paths: - path: \"/user[/{*}]\" policy: statement: \"hasScopes('calendar_read','calendar_edit') AND timeOfDayBetween('8:15', '17:30')\" <markup lang=\"java\" title=\"JAX-RS example\" >@PolicyStatement(\"${env.time.year &gt;= 2017}\") @Authenticated @Path(\"/abac\") public class AbacResource { } ",
            "title": "ABAC Provider"
        },
        {
            "location": "/mp/security/02_providers",
            "text": "<markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-google-login&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"text\" title=\"Provider class name\" >io.helidon.security.providers.google.login.GoogleTokenProvider <markup lang=\"text\" title=\"Provider configuration key\" >google-login ",
            "title": "Setup"
        },
        {
            "location": "/mp/security/02_providers",
            "text": " https://github.com/oracle/helidon/tree/master/examples/security/google-login <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - provider: client-id: \"Google client id\" ",
            "title": "Example code"
        },
        {
            "location": "/mp/security/02_providers",
            "text": " The following table shows all configuration options of the provider and their default values key default value description client-id &#160; Client id of an application. To create an application, use the Google developer console ( https://developers.google.com/identity/sign-in/web/sign-in ) optional false If set to true , failure to authenticate will return ABSTAIN result instead of FAILURE . This is an important distinction when more than one provider is used realm helidon Realm used in the challenge when authentication is not provided and it is required proxy-host none Configuration of a proxy host to use when authenticating the user proxy-port 80 Proxy port token Authorization header with bearer prefix Configuration of the location of the token (see TokenHandler ) outbound &#160; A list of outbound configurations outbound.*.name &#160; Required name of outbound configuration outbound.*.username &#160; Optional username used for outbound security; if not provided, current identity is propagated outbound.*.password &#160; Optional password used for outbound security outbound.*.transports any transport An array of transports this outbound configuration should be used for outbound.*.hosts any host An array of hosts this outbound configuration should be used for, can be a regular expression outbound.*.paths any path An array of paths this outbound configuration should be used for (such as /greet ), can be a regular expression outbound.*.methods any method An array of HTTP methods this outbound configuration should be used for ",
            "title": "Configuration options"
        },
        {
            "location": "/mp/security/02_providers",
            "text": " We expect to receive a token (with sufficient scopes) from the inbound request, such as when using the Google login button on a page. The page has access to the token in javascript and can send it to backend with every request in a header field ( Authorization with `bearer ` prefix is assumed by default). Once we receive the token in Helidon, we parse it and: Validate if it timed out locally Return a cached response (see EvictableCache with default values) Otherwise verify using Google API - GoogleIdTokenVerifier We build a subject from the Google token with the following attributes filled (if in token): userId email name emailVerified locale family_name given_name picture (URL) Outbound security The token will be propagated to outbound calls if an outbound target exists that matches the invoked endpoint (see outbound configuration above). ",
            "title": "How does it work?"
        },
        {
            "location": "/mp/security/02_providers",
            "text": " Authenticates a token from request against Google identity provider Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-google-login&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"text\" title=\"Provider class name\" >io.helidon.security.providers.google.login.GoogleTokenProvider <markup lang=\"text\" title=\"Provider configuration key\" >google-login Example code https://github.com/oracle/helidon/tree/master/examples/security/google-login <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - provider: client-id: \"Google client id\" Configuration options The following table shows all configuration options of the provider and their default values key default value description client-id &#160; Client id of an application. To create an application, use the Google developer console ( https://developers.google.com/identity/sign-in/web/sign-in ) optional false If set to true , failure to authenticate will return ABSTAIN result instead of FAILURE . This is an important distinction when more than one provider is used realm helidon Realm used in the challenge when authentication is not provided and it is required proxy-host none Configuration of a proxy host to use when authenticating the user proxy-port 80 Proxy port token Authorization header with bearer prefix Configuration of the location of the token (see TokenHandler ) outbound &#160; A list of outbound configurations outbound.*.name &#160; Required name of outbound configuration outbound.*.username &#160; Optional username used for outbound security; if not provided, current identity is propagated outbound.*.password &#160; Optional password used for outbound security outbound.*.transports any transport An array of transports this outbound configuration should be used for outbound.*.hosts any host An array of hosts this outbound configuration should be used for, can be a regular expression outbound.*.paths any path An array of paths this outbound configuration should be used for (such as /greet ), can be a regular expression outbound.*.methods any method An array of HTTP methods this outbound configuration should be used for How does it work? We expect to receive a token (with sufficient scopes) from the inbound request, such as when using the Google login button on a page. The page has access to the token in javascript and can send it to backend with every request in a header field ( Authorization with `bearer ` prefix is assumed by default). Once we receive the token in Helidon, we parse it and: Validate if it timed out locally Return a cached response (see EvictableCache with default values) Otherwise verify using Google API - GoogleIdTokenVerifier We build a subject from the Google token with the following attributes filled (if in token): userId email name emailVerified locale family_name given_name picture (URL) Outbound security The token will be propagated to outbound calls if an outbound target exists that matches the invoked endpoint (see outbound configuration above). ",
            "title": "Google Login Provider"
        },
        {
            "location": "/mp/security/02_providers",
            "text": "<markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-jwt&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"text\" title=\"Provider class name\" >io.helidon.security.providers.jwt.JwtProvider <markup lang=\"text\" title=\"Provider configuration key\" >jwt ",
            "title": "Setup"
        },
        {
            "location": "/mp/security/02_providers",
            "text": " https://github.com/oracle/helidon/tree/master/examples/security/outbound-override <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - provider: atn-token: jwk.resource.resource-path: \"verifying-jwk.json\" jwt-audience: \"http://my.service\" sign-token: jwk.resource.resource-path: \"signing-jwk.json\" jwt-issuer: \"http://my.server/identity\" outbound: - name: \"propagate-token\" hosts: [\"*.internal.org\"] - name: \"generate-token\" hosts: [\"1.partner-service\"] jwk-kid: \"partner-1\" jwt-kid: \"helidon\" jwt-audience: \"http://1.partner-service\" ",
            "title": "Example code"
        },
        {
            "location": "/mp/security/02_providers",
            "text": " The following table shows all configuration options of the provider and their default values key default value description optional false If set to true , failure to authenticate will return ABSTAIN result instead of FAILURE . This is an important distinction when more than one provider is used authenticate true Whether to attempt authentication propagate true Whether to attempt identity propagation/JWT creation principal-type USER Whether we authenticate a user or a service (other option is SERVICE) atn-token A group for configuring authentication of the request atn-token.verify-signature true Whether to verify signature in incoming JWT. If disabled, ANY JWT will be accepted atn-token.jwt-audience &#160; Expected audience of the JWT. If not defined, any audience is accepted (and we may accept JWT not inteded for us) atn-token.jwk.resource.* &#160; Configuration of the JWK to obtain key(s) to validate signatures of inbound token. The JWK should contain public keys. This may be: jwk.resource.path, jwk.resource.resource-path, jwk.resource.url, jwk.resource.content-plain (actual JSON string), jwk.resource.content (base64) atn-token.handler Authorization header with `bearer ` prefix A handler configuration for inbound token - e.g. how to extract it atn-token.handler.header &#160; Name of a header the token is expected in atn-token.handler.prefix &#160; Prefix before the token value (optional) atn-token.handler.regexp &#160; Regular expression to obtain the token, first matching group is used (optional) sign-token &#160; A group for configuring outbound security sign-token.jwk.resource.* &#160; Configuration of the JWK to use when generating tokens (follows same rules as atn-token.jwk above), this JWK must contain private keys when using asymmetric ciphers sign-token.jwt-issuer &#160; When we issue a new token, this is the issuer to be placed into it (validated by target service) sign-token.outbound &#160; A group for configuring outbound rules (based on transport, host and.or path) sign-token.outbound.*.name &#160; A short descriptive name for configured target service(s) sign-token.outbound.*.transports any An array of transports this outbound matches (e.g. https) sign-token.outbound.*.hosts any An array of hosts this outbound matches, may use * as a wild-card (e.g. *.oracle.com) sign-token.outbound.*.paths any An array of paths on the host this outbound matches, may use * as a wild-card (e.g. /some/path/*) sign-token.outbound.*.outbound-token Authorization header with `bearer ` prefix Configuration of outbound token handler (same as atn-token.handler) sign-token.outbound.*.outbound-token.format &#160; Java text format for generating the value of outbound token header (e.g. \"bearer %1$s\") sign-token.outbound.*.jwk-kid &#160; If this key is defined, we are generating a new token, otherwise we propagate existing. Defines the key id of a key definition in the JWK file to use for signing the outbound token sign-token.outbound.*.jwt-kid &#160; A key to use in the generated JWT - this is for the other service to locate the verification key in their JWK sign-token.outbound.*.jwt-audience &#160; Audience this key is generated for (e.g. http://www.example.org/api/myService ) - validated by the other service sign-token.outbound.*.jwt-not-before-seconds 5 Makes this key valid this amount of seconds into the past. Allows a certain time-skew for the generated token to be valid before current time (e.g. when we expect a certain misalignment of clocks) sign-token.outbound.*.jwt-validity-seconds 1 day Token validity in seconds ",
            "title": "Configuration options"
        },
        {
            "location": "/mp/security/02_providers",
            "text": " JSON Web Token (JWT) provider has support for authentication and outbound security. Authentication is based on validating the token (signature, valid before etc.) and on asserting the subject of the JWT subject claim. For outbound, we support either token propagation (e.g. the token from request is propagated further) or support for generating a brand new token based on configuration of this provider. ",
            "title": "How does it work?"
        },
        {
            "location": "/mp/security/02_providers",
            "text": " JWT token authentication and outbound security provider. Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-jwt&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"text\" title=\"Provider class name\" >io.helidon.security.providers.jwt.JwtProvider <markup lang=\"text\" title=\"Provider configuration key\" >jwt Example code https://github.com/oracle/helidon/tree/master/examples/security/outbound-override <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - provider: atn-token: jwk.resource.resource-path: \"verifying-jwk.json\" jwt-audience: \"http://my.service\" sign-token: jwk.resource.resource-path: \"signing-jwk.json\" jwt-issuer: \"http://my.server/identity\" outbound: - name: \"propagate-token\" hosts: [\"*.internal.org\"] - name: \"generate-token\" hosts: [\"1.partner-service\"] jwk-kid: \"partner-1\" jwt-kid: \"helidon\" jwt-audience: \"http://1.partner-service\" Configuration options The following table shows all configuration options of the provider and their default values key default value description optional false If set to true , failure to authenticate will return ABSTAIN result instead of FAILURE . This is an important distinction when more than one provider is used authenticate true Whether to attempt authentication propagate true Whether to attempt identity propagation/JWT creation principal-type USER Whether we authenticate a user or a service (other option is SERVICE) atn-token A group for configuring authentication of the request atn-token.verify-signature true Whether to verify signature in incoming JWT. If disabled, ANY JWT will be accepted atn-token.jwt-audience &#160; Expected audience of the JWT. If not defined, any audience is accepted (and we may accept JWT not inteded for us) atn-token.jwk.resource.* &#160; Configuration of the JWK to obtain key(s) to validate signatures of inbound token. The JWK should contain public keys. This may be: jwk.resource.path, jwk.resource.resource-path, jwk.resource.url, jwk.resource.content-plain (actual JSON string), jwk.resource.content (base64) atn-token.handler Authorization header with `bearer ` prefix A handler configuration for inbound token - e.g. how to extract it atn-token.handler.header &#160; Name of a header the token is expected in atn-token.handler.prefix &#160; Prefix before the token value (optional) atn-token.handler.regexp &#160; Regular expression to obtain the token, first matching group is used (optional) sign-token &#160; A group for configuring outbound security sign-token.jwk.resource.* &#160; Configuration of the JWK to use when generating tokens (follows same rules as atn-token.jwk above), this JWK must contain private keys when using asymmetric ciphers sign-token.jwt-issuer &#160; When we issue a new token, this is the issuer to be placed into it (validated by target service) sign-token.outbound &#160; A group for configuring outbound rules (based on transport, host and.or path) sign-token.outbound.*.name &#160; A short descriptive name for configured target service(s) sign-token.outbound.*.transports any An array of transports this outbound matches (e.g. https) sign-token.outbound.*.hosts any An array of hosts this outbound matches, may use * as a wild-card (e.g. *.oracle.com) sign-token.outbound.*.paths any An array of paths on the host this outbound matches, may use * as a wild-card (e.g. /some/path/*) sign-token.outbound.*.outbound-token Authorization header with `bearer ` prefix Configuration of outbound token handler (same as atn-token.handler) sign-token.outbound.*.outbound-token.format &#160; Java text format for generating the value of outbound token header (e.g. \"bearer %1$s\") sign-token.outbound.*.jwk-kid &#160; If this key is defined, we are generating a new token, otherwise we propagate existing. Defines the key id of a key definition in the JWK file to use for signing the outbound token sign-token.outbound.*.jwt-kid &#160; A key to use in the generated JWT - this is for the other service to locate the verification key in their JWK sign-token.outbound.*.jwt-audience &#160; Audience this key is generated for (e.g. http://www.example.org/api/myService ) - validated by the other service sign-token.outbound.*.jwt-not-before-seconds 5 Makes this key valid this amount of seconds into the past. Allows a certain time-skew for the generated token to be valid before current time (e.g. when we expect a certain misalignment of clocks) sign-token.outbound.*.jwt-validity-seconds 1 day Token validity in seconds How does it work? JSON Web Token (JWT) provider has support for authentication and outbound security. Authentication is based on validating the token (signature, valid before etc.) and on asserting the subject of the JWT subject claim. For outbound, we support either token propagation (e.g. the token from request is propagated further) or support for generating a brand new token based on configuration of this provider. ",
            "title": "JWT Provider"
        },
        {
            "location": "/mp/security/02_providers",
            "text": " Helidon provides the following security providers for endpoint protection: Provider Type Outbound supported Description OIDC Provider Authentication ✅ Open ID Connect supporting JWT, Scopes, Groups and OIDC code flow HTTP Basic Authentication Authentication ✅ HTTP Basic Authentication support HTTP Digest Authentication Authentication 🚫 HTTP Digest Authentication support Header Assertion Authentication ✅ Asserting a user based on a header value HTTP Signatures Authentication ✅ Protecting service to service communication through signatures IDCS Roles Role Mapping 🚫 Retrieves roles from IDCS provider for authenticated user ABAC Authorization Authorization 🚫 Attribute based access control authorization policies The following providers are no longer evolved: Provider Type Outbound supported Description Google Login Authentication ✅ Authenticates a token from request against Google servers JWT Provider Authentication ✅ JWT tokens passed from frontend Note : If the example code uses clear-text passwords in configuration, ensure that you add the following to the code snippet: security: config.require-encryption: false If set to true , an exception is thrown. However, in a production environment you would set this value to true so that any attempt to pass a clear-text password throws an exception. OIDC Provider Open ID Connect security provider. Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-oidc&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"text\" title=\"Provider class name\" >io.helidon.security.providers.oidc.OidcProvider <markup lang=\"text\" title=\"Provider configuration key\" >oidc Example code https://github.com/oracle/helidon/tree/master/examples/security/idcs-login <markup lang=\"yaml\" title=\"Configuration example\" >security: config.require-encryption: false security: providers: - oidc: client-id: \"client-id-of-this-service\" client-secret: \"${CLEAR=client-secret-of-this-service}\" identity-uri: \"http://your-tenant.identity-server.com\" frontend-uri: \"http://my-service:8080\" audience: \"http://my-service\" cors: allow-origins: [\"http://foo.com\", \"http://there.com\"] allow-methods: [\"PUT\", \"DELETE\"] outbound: - name: \"internal-services\" hosts: [\"*.example.org\"] outbound-token: header: \"X-Internal-Auth\" Configuration options The following table shows all configuration options of the provider and their default values key default value description optional false If set to true , failure to authenticate will return ABSTAIN result instead of FAILURE . This is an important distinction when more than one provider is used client-id &#160; Client ID as generated by identity server client-secret &#160; Client secret as generated by identity server identity-uri &#160; URI of the identity server, base used to retrieve OIDC metadata frontend-uri &#160; Full URI of this service for redirects back from OIDC server issuer issuer from OIDC metadata Issuer of token - each JWT is validated to check the issuer audience &#160; Audience of a token - each JWT is validated to check the audience cors &#160; Cross-origin resource sharing settings (see below) proxy-protocol http Proxy protocol to use when proxy is used proxy-host null Proxy host to use. When defined, triggers usage of proxy for HTTP requests proxy-port 80 Port of the proxy server to use redirect-uri /oidc/redirect URI to register web server component on, used by the OIDC server to redirect authorization requests to after a user logs in or approves scopes. Note that usually the redirect URI configured here must be the same one as configured on OIDC server. scope-audience empty string Audience of the scope required by this application. This is prefixed to the scope name when requesting scopes from the identity server. cookie-use true Whether to use cookie to store JWT. If used, redirects happen only in case the user is not authenticated or has insufficient scopes cookie-name JSESSIONID Name of the cookie cookie-domain &#160; Domain the cookie is valid for. Not used by default cookie-path / Path the cookie is valid for. cookie-max-age-seconds {nsbp} When using cookie, used to set MaxAge attribute of the cookie, defining how long the cookie is valid. cookie-http-only true When using cookie, if set to true, the HttpOnly attribute will be configured. cookie-secure false When using cookie, if set to true, the Secure attribute will be configured. cookie-same-site Lax When using cookie, used to set the SameSite cookie value. Can be \"Strict\" or \"Lax\". Setting this to \"Strict\" will result in infinite redirects when calling OIDC on a different host. query-param-use false Whether to expect JWT in a query parameter query-param-name accessToken Name of a query parameter that contains the JWT token when parameter is used. header-use false Whether to expect JWT in a header field. header-token Authorization header with prefix bearer A TokenHandler configuration to process header containing a JWT oidc-metadata-well-known true If set to true, metadata will be loaded from default (well known) location, unless it is explicitly defined using oidc-metadata-resource. If set to false, it would not be loaded even if oidc-metadata-resource is not defined. In such a case all URIs must be explicitly defined (e.g. token-endpoint-uri). oidc-metadata.resource identity-uri/.well-known/openid-configuration Resource configuration for OIDC Metadata containing endpoints to various identity services, as well as information about the identity server. See Resource.create(io.helidon.config.Config) token-endpoint-uri token_endpoint in OIDC metadata, or identity-url/oauth2/v1/token if not available URI of a token endpoint used to obtain a JWT based on the authentication code. authorization-endpoint-uri \"authorization_endpoint\" in OIDC metadata, or identity-uri/oauth2/v1/authorize if not available URI of an authorization endpoint used to redirect users to for logging-in. validate-with-jwk true When true - validate against jwk defined by \"sign-jwk\", when false validate JWT through OIDC Server endpoint \"validation-endpoint-uri\" sign-jwk.resource \"jwks-uri\" in OIDC metadata, or identity-uri/admin/v1/SigningCert/jwk if not available, only needed when jwt validation is done by us A resource pointing to JWK with public keys of signing certificates used to validate JWT. See Resource.create(io.helidon.config.Config) introspect-endpoint-uri \"introspection_endpoint\" in OIDC metadata, or identity-uri/oauth2/v1/introspect When validate-with-jwk is set to \"false\", this is the endpoint used base-scopes openid Configure scopes to be requested by default. If the scope has a qualifier, it must be included here redirect true Whether to redirect to identity server when authentication failed. realm helidon Realm returned in HTTP response if redirect is not enabled or possible. redirect-attempt-param h_ra Query parameter holding the number of times we redirected to an identity server. Customizable to prevent conflicts with application parameters max-redirects 5 Maximal number of times we can redirect to an identity server. When the number is reached, no further redirects happen and the request finishes with an error (status 401) server-type &#160; Type of identity server. Currently supported is idcs or not configured (for default). propagate &#160; Whether to propagate the token we have. Defaults to false unless an outbound configuration is defined outbound &#160; A list of outbound configurations outbound.*.name &#160; Required name of outbound configuration outbound.*.transports any transport An array of transports this outbound configuration should be used for outbound.*.hosts any host An array of hosts this outbound configuration should be used for, can be a regular expression outbound.*.paths any path An array of paths this outbound configuration should be used for (such as /greet ), can be a regular expression outbound.*.methods any method An array of HTTP methods this outbound configuration should be used for outbound.*.outbound-token Authorization header with bearer prefix Configuration of outbound header used to propagate outbound.*.outbound-token.header &#160; Name of the header used to propagate the token outbound.*.outbound-token.prefix &#160; Prefix for the header value, such as \"bearer\" (only one of prefix , regexp and format should be defined, regexp wins over prefix , format wins over regexp ) outbound.*.outbound-token.format &#160; String format with a single parameter to create the header value, such as \"bearer %1s\" outbound.*.outbound-token.regexp &#160; Regular expression to create the header value, such as \"bearer (.*)\" How does it work? At Helidon startup, if OIDC provider is configured, the following will happen: client-id , client-secret , and identityUri are validated - these must provide values Unless all resources are configured as local resources, the provider attempts to contact the oidc-metadata.resource endpoint to retrieve all endpoints At runtime, depending on configuration&#8230;&#8203; If a request comes without a token or with insufficient scopes: If redirect is set to true (default), request is redirected to the authorization endpoint of the identity server. If set to false, 401 is returned User authenticates against the identity server The identity server redirects back to Helidon service with a code Helidon service contacts the identity server&#8217;s token endpoint, to exchange the code for a JWT The JWT is stored in a cookie (if cookie support is enabled, which it is by default) Helidon service redirects to original endpoint (on itself) Helidon obtains a token from request (from cookie, header, or query parameter): Token is parsed as a singed JWT We validate the JWT signature either against local JWK or against the identity server&#8217;s introspection endpoint depending on configuration We validate the issuer and audience of the token if it matches the configured values A subject is created from the JWT, including scopes from the token We validate that we have sufficient scopes to proceed, and return 403 if not Handling is returned to security to process other security providers CORS Settings As an experimental feature, you can set up cross-origin handling for the redirect and logout endpoints in an optional cors block inside the oidc configuration. The table below lists the configuration keys that identify the CORS characteristics. Configuration Key Default CORS Header Name allow-credentials false Access-Control-Allow-Credentials allow-headers [\"*\"] Access-Control-Allow-Headers allow-methods [\"*\"] Access-Control-Allow-Methods allow-origins [\"*\"] Access-Control-Allow-Origins expose-headers none Access-Control-Expose-Headers max-age 3600 Access-Control-Max-Age enabled true n/a If the cross-origin configuration is disabled ( enabled = false), then the Helidon CORS implementation ignores the cross-origin configuration entry. The following example of basic cross-origin configuration limits cross-origin resource sharing for PUT and DELETE operations to only foo.com and there.com : <markup lang=\"hocon\" >... allow-origins: [\"http://foo.com\", \"http://there.com\"] allow-methods: [\"PUT\", \"DELETE\"] ... HTTP Basic Authentication Provider HTTP Basic authentication support Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-http-auth&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"text\" title=\"Provider class name\" >io.helidon.security.providers.httpauth.HttpBasicAuthProvider <markup lang=\"text\" title=\"Provider configuration key\" >http-basic-auth Example code https://github.com/oracle/helidon/tree/master/examples/security/outbound-override <markup lang=\"yaml\" title=\"Configuration example\" >security: config.require-encryption: false security: providers: - http-basic-auth: realm: \"helidon\" users: - login: \"john\" password: \"${CLEAR=password}\" roles: [\"admin\"] - login: \"jack\" password: \"password\" roles: [\"user\", \"admin\"] outbound: - name: \"internal-services\" hosts: [\"*.example.org\"] # Propagates current user's identity or identity from request property outbound-token: header: \"X-Internal-Auth\" - name: \"partner-service\" hosts: [\"*.partner.org\"] # Uses this username and password username: \"partner-user-1\" password: \"${CLEAR=password}\" Configuration options The following table shows all configuration options of the provider and their default values key default value description optional false If set to true , failure to authenticate will return ABSTAIN result instead of FAILURE . This is an important distinction when more than one provider is used realm helidon The realm shown in challenge when user accesses a service without authentication principal-type USER Type of authenticated entity - either USER or SERVICE , can be used in combination with other authentication mechanism to authenticate both the user (as in person sitting in front of a computer) and a service (as in the application requesting this service on user&#8217;s behalf) users &#160; List of users when using configuration based approach. As an alternative, you can implement a java service (see below). outbound &#160; A list of outbound configurations outbound.*.name &#160; Required name of outbound configuration outbound.*.username &#160; Optional username used for outbound security; if not provided, current identity is propagated outbound.*.password &#160; Optional password used for outbound security outbound.*.transports any transport An array of transports this outbound configuration should be used for outbound.*.hosts any host An array of hosts this outbound configuration should be used for, can be a regular expression outbound.*.paths any path An array of paths this outbound configuration should be used for (such as /greet ), can be a regular expression outbound.*.methods any method An array of HTTP methods this outbound configuration should be used for outbound.*.outbound-token Authorization header with basic prefix Configuration of outbound header used to propagate outbound.*.outbound-token.header &#160; Name of the header used to propagate the token outbound.*.outbound-token.prefix &#160; Prefix for the header value, such as \"basic \" (only one of prefix , regexp and format should be defined, regexp wins over prefix , format wins over regexp ) outbound.*.outbound-token.format &#160; String format with a single parameter to create the header value, such as \"basic %1s\" outbound.*.outbound-token.regexp &#160; Regular expression to create the header value, such as \"basic (.*)\" How does it work? See https://tools.ietf.org/html/rfc7617 . Authentication of request When a request is received without the Authorization: basic &#8230;&#8203;. header, a challenge is returned to provide such authentication. When a request is received with the Authorization: basic &#8230;&#8203;. header, the username and password is validated against configured users (and users obtained from custom service if any provided). Subject is created based on the username and roles provided by the user store. Identity propagation When identity propagation is configured, there are several options for identifying username and password to propagate: We propagate the current username and password (inbound request must be authenticated using basic authentication). We use username and password from an explicitly configured property (See HttpBasicAuthProvider.EP_PROPERTY_OUTBOUND_USER and HttpBasicAuthProvider.EP_PROPERTY_OUTBOUND_PASSWORD ) We use username and password associated with an outbound target (see example configuration above) Identity is propagated only if: There is an outbound target configured for the endpoint Or there is an explicitly configured username/password for the current request (through request property) Custom user store Java service loader service io.helidon.security.providers.httpauth.spi.UserStoreService can be implemented to provide users to the provider, such as when validated against an internal database or LDAP server. The user store is defined so you never need the clear text password of the user. Warning on security of HTTP Basic Authenticaton (or lack thereof) Basic authentication uses base64 encoded username and password and passes it over the network. Base64 is only encoding, not encryption - so anybody that gets hold of the header value can learn the actual username and password of the user. This is a security risk and an attack vector that everybody should be aware of before using HTTP Basic Authentication. We recommend using this approach only for testing and demo purposes. HTTP Digest Authentication Provider HTTP Digest authentication support Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-http-auth&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"text\" title=\"Provider class name\" >io.helidon.security.providers.httpauth.HttpDigestAuthProvider <markup lang=\"text\" title=\"Provider configuration key\" >http-digest-auth Example code <markup lang=\"yaml\" title=\"Configuration example\" >security: config.require-encryption: false security: providers: - http-digest-auth: realm: \"helidon\" server-secret: \"${CLEAR=service-wide-secret-not-known-outside}\" users: - login: \"john\" password: \"${CLEAR=password}\" roles: [\"admin\"] - login: \"jack\" password: \"password\" roles: [\"user\", \"admin\"] Configuration options The following table shows all configuration options of the provider and their default values key default value description optional false If set to true , failure to authenticate will return ABSTAIN result instead of FAILURE . This is an important distinction when more than one provider is used realm helidon The realm shown in challenge when user accesses a service without authentication principal-type USER Type of authenticated entity - either USER or SERVICE , can be used in combination with other authentication mechanism to authenticate both the user (as in person sitting in front of a computer) and a service (as in the application requesting this service on user&#8217;s behalf) users &#160; List of users when using configuration based approach. As an alternative, you can implement a java service (see below). algorithm MD5 Only MD5 supported nonce-timeout-millis 1 day Number of milliseconds for the nonce timeout server-secret random A string to use as a server secret - this is to use digest auth between multiple servers (e.g. when in a cluster). Used to encrypt nonce. This must not be known outside of this app, as others may create digest requests we would trust. qop NONE only AUTH supported. If left empty, uses the legacy approach (older RFC version). AUTH-INT is not supported. How does it work? See https://tools.ietf.org/html/rfc7616 . Authentication of request When a request is received without the Authorization: digest &#8230;&#8203;. header, a challenge is returned to provide such authentication using WWW-Authenticate header. When a request is received with the Authorization: digest &#8230;&#8203;. header, the request is validated against configured users (and users obtained from custom service if any provided). Subject is created based on the username and roles provided by the user store. Custom user store Java service loader service io.helidon.security.providers.httpauth.spi.UserStoreService can be implemented to provide users to the provider, such as when validated against an internal database or LDAP server. The user store is defined so you never need the clear text password of the user. Note on security of HTTP Digest Authenticaton These authentication schemes should be obsolete , though they provide a very easy way to test a protected resource. Header Authentication Provider Asserts user or service identity based on a value of a header. Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-header&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"text\" title=\"Provider class name\" >io.helidon.security.providers.header.HeaderAtnProvider <markup lang=\"text\" title=\"Provider configuration key\" >header-atn Example code <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: header-atn: atn-token: header: \"X-AUTH-USER\" outbound: - name: \"internal-services\" hosts: [\"*.example.org\"] # propagates the current user or service id using the same header as authentication - name: \"partner-service\" hosts: [\"*.partner.org\"] # propagates an explicit username in a custom header username: \"service-27\" outbound-token: header: \"X-Service-Auth\" Configuration options The following table shows all configuration options of the provider and their default values key default value description optional false If set to true , failure to authenticate will return ABSTAIN result instead of FAILURE . This is an important distinction when more than one provider is used authenticate true If set to false , authentication will not be attempted (outbound security can still be used) propagate false If explicitly set to false , identity propagation will not be done. Otherwise it is done if an outbound section is configured principal-type USER Can be USER or SERVICE atn-token none Token extraction and propagation, you can define which header to use and how to extract it outbound &#160; A list of outbound configurations outbound.*.name &#160; Required name of outbound configuration outbound.*.username &#160; Optional username used for outbound security; if not provided, current identity is propagated outbound.*.transports any transport An array of transports this outbound configuration should be used for outbound.*.hosts any host An array of hosts this outbound configuration should be used for, can be a regular expression outbound.*.paths any path An array of paths this outbound configuration should be used for (such as /greet ), can be a regular expression outbound.*.methods any method An array of HTTP methods this outbound configuration should be used for outbound.*.outbound-token same as atn-token Configuration of outbound header used to propagate outbound.*.outbound-token.header &#160; Name of the header used to propagate the token outbound.*.outbound-token.prefix &#160; Prefix for the header value, such as \"username \" (only one of prefix , regexp and format should be defined, regexp wins over prefix , format wins over regexp ) outbound.*.outbound-token.format &#160; String format with a single parameter to create the header value, such as \"username %1s\" outbound.*.outbound-token.regexp &#160; Regular expression to create the header value, such as \"username (.*)\" How does it work? This provider inspects a specified request header and extracts the username/service name from it and asserts it as current subject&#8217;s principal. This can be used when we use perimeter authentication (e.g. there is a gateway that takes care of authentication and propagates the user in a header). Identity propagation Identity is propagated only if an outbound target matches the target service. The following options exist when propagating identity: 1. We propagate the current username using the configured header 2. We use username associated with an outbound target (see example configuration above) Caution When using this provider, you must be sure the header cannot be explicitly configured by a user or another service. All requests should go through a gateway that removes this header from inbound traffic, and only configures it for authenticated users/services. Another option is to use this with fully trusted parties (such as services within a single company, on a single protected network not accessible to any users), and of course for testing and demo purposes. HTTP Signatures Provider Support for HTTP Signatures. Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-http-sign&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"text\" title=\"Provider class name\" >io.helidon.security.providers.httpsign.HttpSignProvider <markup lang=\"text\" title=\"Provider configuration key\" >http-signatures Example code https://github.com/oracle/helidon/tree/master/examples/security/webserver-signatures <markup lang=\"yaml\" title=\"Configuration example\" >security: config.require-encryption: false security: providers: - http-signatures: inbound: keys: - key-id: \"service1-hmac\" principal-name: \"Service1 - HMAC signature\" hmac.secret: \"${CLEAR=somePasswordForHmacShouldBeEncrypted}\" - key-id: \"service1-rsa\" principal-name: \"Service1 - RSA signature\" public-key: keystore: resource.path: \"src/main/resources/keystore.p12\" passphrase: \"password\" cert.alias: \"service_cert\" outbound: - name: \"service2-hmac\" hosts: [\"localhost\"] paths: [\"/service2\"] signature: key-id: \"service1-hmac\" hmac.secret: \"${CLEAR=somePasswordForHmacShouldBeEncrypted}\" - name: \"service2-rsa\" hosts: [\"localhost\"] paths: [\"/service2-rsa.*\"] signature: key-id: \"service1-rsa\" private-key: keystore: resource.path: \"src/main/resources/keystore.p12\" passphrase: \"password\" key.alias: \"myPrivateKey\" Configuration options The following table shows all configuration options of the provider and their default values key default value description optional false If set to true , failure to authenticate will return ABSTAIN result instead of FAILURE . This is an important distinction when more than one provider is used realm helidon Realm used for challenge when request does not have a signature headers [SIGNATURE,AUTHORIZATION,CUSTOM] Headers to look for inbound signatures and to store outbound signatures. CUSTOM is provided using io.helidon.security.util.TokenHandler sign-headers always = [\"date\"] Headers to be signed sign-headers.*.method default for all methods Method this configuration is valid for sign-headers.*.always &#160; Array of headers to be always required in the request signature sign-headers.*.if-present &#160; Array of headers to be part of the signatures if present in the request inbound &#160; Configuration of inbound traffic for authenticating incoming requests inbound.keys &#160; Configuration of signature keys to verify incoming requests inbound.keys.*.key-id &#160; Key id as used in inbound signature to find the correct certificate/hmac configuration to verify the signature inbound.keys.*.principal-name &#160; The principal name (or user name) asserted when the signature is valid inbound.keys.*.principal-type SERVICE The type of principal to assert (can be USER ) inbound.keys.*.algorithm according to other configuration hmac-sha256 or rsa-sha256 is assumed if other configuration options for that type are set inbound.keys.*.hmac.secret &#160; Secret shared by the service that signed the request and this service for hmac-sha256 algorithm inbound.keys.*.public-key &#160; Public key configuration, implies rsa-sha256 algorithm inbound.keys.*.public-key.keystore &#160; Keystore configuration for public key - full configuration as defined by KeyStore class outbound &#160; A list of outbound configurations outbound.*.name &#160; Required name of outbound configuration outbound.*.username &#160; Optional username used for outbound security; if not provided, current identity is propagated outbound.*.password &#160; Optional password used for outbound security outbound.*.transports any transport An array of transports this outbound configuration should be used for outbound.*.hosts any host An array of hosts this outbound configuration should be used for, can be a regular expression outbound.*.paths any path An array of paths this outbound configuration should be used for (such as /greet ), can be a regular expression outbound.*.methods any method An array of HTTP methods this outbound configuration should be used for outbound.*.signature &#160; Configuration related to outbound signature configuration outbound.*.signature.key-id &#160; Key id to use in the outbound signature (to map to appropriate public key in target service&#8217;s configuration) outbound.*.signature.header [SIGNATURE,AUTHORIZATION,CUSTOM] Headers supported by HTTP Signature. CUSTOM is provided using io.helidon.security.util.TokenHandler outbound.*.signature.hmac.secret &#160; Shared secret for hmac outbound.*.signature.private-key &#160; Private key configuration for rsa based signatures outbound.*.signature.private-key.keystore &#160; Keystore configuration for private key - full configuration as defined by KeyStore class Signature basics standard: based on https://tools.ietf.org/html/draft-cavage-http-signatures-03 key-id: an arbitrary string used to locate signature configuration - when a request is received the provider locates validation configuration based on this id (e.g. HMAC shared secret or RSA public key). Commonly used meanings are: key fingerprint (RSA); API Key How does it work? Inbound Signatures We act as a server and another party is calling us with a signed HTTP request. We validate the signature and assume identity of the caller. Outbound Signatures We act as a client and we sign our outgoing requests. If there is a matching outbound target specified in configuration, its configuration will be applied for signing the outgoing request, otherwise there is no signature added IDCS Role Mapper A role mapper to retrieve roles from Oracle IDCS. Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-idcs-mapper&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"text\" title=\"Provider class name\" >io.helidon.security.providers.idcs.mapper.IdcsRoleMapperProvider <markup lang=\"text\" title=\"Provider configuration key\" >idcs-role-mapper Example code https://github.com/oracle/helidon/tree/master/examples/security/idcs-login/ <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - idcs-role-mapper: multitenant: false oidc-config: client-id: \"client-id\" client-secret: \"client-secret\" identity-uri: \"IDCS identity server address\" Configuration options The following table shows all configuration options of the provider and their default values key default value description multitenant true Whether to support multi-tenancy with this provider idcs-tenant-handler Header X-USER-IDENTITY-SERVICE-GUID Multi-tenant specific TokenHandler configuration to retrieve the tenant id idcs-app-name-handler Header X-RESOURCE-SERVICE-INSTANCE-IDENTITY-APPNAME Multi-tenant specific TokenHandler configuration to retrieve the application name cache-config &#160; Configuration of cache of roles for subjects cache-config.cache-enabled true Possibility to disable the cache altogether cache-config.max-size 100_000 Maximal number of records in the cache cache-config.cache-timeout-millis 1 hour Cache timeout in milliseconds cache-config.cache-evict-delay-millis 1 minute How long to wait before starting the first eviction process cache-config.cache-evict-period-millis 5 minutes Period of running the eviction process cache-config.parallelism-threshold 10_000 Threshold as used by ConcurrentHashMap.forEachKey cache-config.evictor-class &#160; Implementation of BiFunction that receives key and value, and returns true for records that should be removed from the cache. Eviction mechanism should be fast, as it is called within methods of ConcurrentHashMap subject-types USER Can use USER and/or SERVICE default-idcs-subject-type user Default subject type to use when requesting roles, can be user or client oidc-config &#160; OidcConfig configuration, except validate-with-jwk is set to false , and server-type is set to idcs How does it work? The provider asks the IDCS server to provide list of roles for the currently authenticated user. The result is cached for a certain period of time (see cache-config above). ABAC Provider Attribute based access control authorization provider. Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-abac&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"text\" title=\"Provider class name\" >io.helidon.security.providers.abac.AbacProvider <markup lang=\"text\" title=\"Provider configuration key\" >abac Example code https://github.com/oracle/helidon/tree/master/examples/security/attribute-based-access-control <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - abac: Configuration options The following table shows all configuration options of the provider and their default values key default value description fail-on-unvalidated true \"Unvalidated\" means: an attribute is defined, but there is no validator available for it fail-if-none-validated true \"None validated\" means: there was not a single attribute that was validated How does it work? ABAC uses available validators and validates them against attributes of the authenticated user. Combinations of fail-on-unvalidated and fail-if-none-validated : true &amp; true : Will fail if any attribute is not validated and if any has failed validation false &amp; true : Will fail if there is one or more attributes present and NONE of them is validated or if any has failed validation, Will NOT fail if there is at least one validated attribute and any number of not validated attributes (and NONE failed) false &amp; false : Will fail if there is any attribute that failed validation, Will NOT fail if there are no failed validation or if there are NONE validated Any attribute of the following objects can be used: environment (such as time of request) - e.g. env.time.year subject (user) - e.g. subject.principal.id subject (service) - e.g. service.principal.id object (must be explicitly invoked by developer in code, as object cannot be automatically added to security context) - e.g. object.owner This provider checks that all defined ABAC validators are validated. If there is a definition for a validator that is not checked, the request is denied (depending on configuration as mentioned above). ABAC provider also allows an object to be used in authorization process, such as when evaluating if an object&#8217;s owner is the current user. The following example uses the Expression language validator to demonstrate the point in a JAX-RS resource: <markup lang=\"java\" title=\"Example of using an object\" >@Authenticated @Path(\"/abac\") public class AbacResource { @GET @Authorized(explicit = true) @PolicyStatement(\"${env.time.year &gt;= 2017 &amp;&amp; object.owner == subject.principal.id}\") public Response process(@Context SecurityContext context) { // probably looked up from a database SomeResource res = new SomeResource(\"user\"); AuthorizationResponse atzResponse = context.authorize(res); if (atzResponse.isPermitted()) { //do the update return Response.ok().entity(\"fine, sir\").build(); } else { return Response.status(Response.Status.FORBIDDEN) .entity(atzResponse.getDescription().orElse(\"Access not granted\")) .build(); } } } The following validators are implemented: Roles Scopes EL Policy Role Validator Checks whether user/service is in either of the required role(s). Configuration Key: role-validator Annotations: @RolesAllowed , @RoleValidator.Roles <markup lang=\"yaml\" title=\"Configuration example for WebServer \" >security: web-server.paths: - path: \"/user[/{*}]\" roles-allowed: [\"user\"] <markup lang=\"java\" title=\"JAX-RS example\" >@RolesAllowed(\"user\") @RoleValidator.Roles(value = \"service_role\", subjectType = SubjectType.SERVICE) @Authenticated @Path(\"/abac\") public class AbacResource { } Interaction with JAX-RS sub-resource locators When using sub-resource locators in JAX-RS, the roles allowed are collected from each \"level\" of execution: - Application class annotations - Resource class annotations + resource method annotations - Sub-resource class annotations + sub-resource method annotations - Sub-resource class annotations + sub-resource method annotations (for every sub-resource on the path) The RolesAllowed or Roles annotation to be used is the last one in the path as defined above. Example 1: There is a RolesAllowed(\"admin\") defined on a sub-resource locator resource class. In this case the required role is admin . Example 2: There is a RolesAllowed(\"admin\") defined on a sub-resource locator resource class and a RolesAllowed(\"user\") defined on the method of the sub-resource that provides the response. In this case the required role is user . Scope Validator Checks whether user has all the required scopes. Configuration Key: scope-validator Annotations: @Scope <markup lang=\"yaml\" title=\"Configuration example for WebServer \" >security: web-server.paths: - path: \"/user[/{*}]\" abac.scopes: [\"calendar_read\", \"calendar_edit\"] <markup lang=\"java\" title=\"JAX-RS example\" >@Scope(\"calendar_read\") @Scope(\"calendar_edit\") @Authenticated @Path(\"/abac\") public class AbacResource { } Expression Language Policy Validator Policy executor using Java EE policy expression language (EL) Configuration Key: policy-javax-el Annotations: @PolicyStatement Example of a policy statement: ${env.time.year &gt;= 2017} <markup lang=\"yaml\" title=\"Configuration example for WebServer \" >security: web-server.paths: - path: \"/user[/{*}]\" policy: statement: \"hasScopes('calendar_read','calendar_edit') AND timeOfDayBetween('8:15', '17:30')\" <markup lang=\"java\" title=\"JAX-RS example\" >@PolicyStatement(\"${env.time.year &gt;= 2017}\") @Authenticated @Path(\"/abac\") public class AbacResource { } Google Login Provider Authenticates a token from request against Google identity provider Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-google-login&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"text\" title=\"Provider class name\" >io.helidon.security.providers.google.login.GoogleTokenProvider <markup lang=\"text\" title=\"Provider configuration key\" >google-login Example code https://github.com/oracle/helidon/tree/master/examples/security/google-login <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - provider: client-id: \"Google client id\" Configuration options The following table shows all configuration options of the provider and their default values key default value description client-id &#160; Client id of an application. To create an application, use the Google developer console ( https://developers.google.com/identity/sign-in/web/sign-in ) optional false If set to true , failure to authenticate will return ABSTAIN result instead of FAILURE . This is an important distinction when more than one provider is used realm helidon Realm used in the challenge when authentication is not provided and it is required proxy-host none Configuration of a proxy host to use when authenticating the user proxy-port 80 Proxy port token Authorization header with bearer prefix Configuration of the location of the token (see TokenHandler ) outbound &#160; A list of outbound configurations outbound.*.name &#160; Required name of outbound configuration outbound.*.username &#160; Optional username used for outbound security; if not provided, current identity is propagated outbound.*.password &#160; Optional password used for outbound security outbound.*.transports any transport An array of transports this outbound configuration should be used for outbound.*.hosts any host An array of hosts this outbound configuration should be used for, can be a regular expression outbound.*.paths any path An array of paths this outbound configuration should be used for (such as /greet ), can be a regular expression outbound.*.methods any method An array of HTTP methods this outbound configuration should be used for How does it work? We expect to receive a token (with sufficient scopes) from the inbound request, such as when using the Google login button on a page. The page has access to the token in javascript and can send it to backend with every request in a header field ( Authorization with `bearer ` prefix is assumed by default). Once we receive the token in Helidon, we parse it and: Validate if it timed out locally Return a cached response (see EvictableCache with default values) Otherwise verify using Google API - GoogleIdTokenVerifier We build a subject from the Google token with the following attributes filled (if in token): userId email name emailVerified locale family_name given_name picture (URL) Outbound security The token will be propagated to outbound calls if an outbound target exists that matches the invoked endpoint (see outbound configuration above). JWT Provider JWT token authentication and outbound security provider. Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-jwt&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"text\" title=\"Provider class name\" >io.helidon.security.providers.jwt.JwtProvider <markup lang=\"text\" title=\"Provider configuration key\" >jwt Example code https://github.com/oracle/helidon/tree/master/examples/security/outbound-override <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - provider: atn-token: jwk.resource.resource-path: \"verifying-jwk.json\" jwt-audience: \"http://my.service\" sign-token: jwk.resource.resource-path: \"signing-jwk.json\" jwt-issuer: \"http://my.server/identity\" outbound: - name: \"propagate-token\" hosts: [\"*.internal.org\"] - name: \"generate-token\" hosts: [\"1.partner-service\"] jwk-kid: \"partner-1\" jwt-kid: \"helidon\" jwt-audience: \"http://1.partner-service\" Configuration options The following table shows all configuration options of the provider and their default values key default value description optional false If set to true , failure to authenticate will return ABSTAIN result instead of FAILURE . This is an important distinction when more than one provider is used authenticate true Whether to attempt authentication propagate true Whether to attempt identity propagation/JWT creation principal-type USER Whether we authenticate a user or a service (other option is SERVICE) atn-token A group for configuring authentication of the request atn-token.verify-signature true Whether to verify signature in incoming JWT. If disabled, ANY JWT will be accepted atn-token.jwt-audience &#160; Expected audience of the JWT. If not defined, any audience is accepted (and we may accept JWT not inteded for us) atn-token.jwk.resource.* &#160; Configuration of the JWK to obtain key(s) to validate signatures of inbound token. The JWK should contain public keys. This may be: jwk.resource.path, jwk.resource.resource-path, jwk.resource.url, jwk.resource.content-plain (actual JSON string), jwk.resource.content (base64) atn-token.handler Authorization header with `bearer ` prefix A handler configuration for inbound token - e.g. how to extract it atn-token.handler.header &#160; Name of a header the token is expected in atn-token.handler.prefix &#160; Prefix before the token value (optional) atn-token.handler.regexp &#160; Regular expression to obtain the token, first matching group is used (optional) sign-token &#160; A group for configuring outbound security sign-token.jwk.resource.* &#160; Configuration of the JWK to use when generating tokens (follows same rules as atn-token.jwk above), this JWK must contain private keys when using asymmetric ciphers sign-token.jwt-issuer &#160; When we issue a new token, this is the issuer to be placed into it (validated by target service) sign-token.outbound &#160; A group for configuring outbound rules (based on transport, host and.or path) sign-token.outbound.*.name &#160; A short descriptive name for configured target service(s) sign-token.outbound.*.transports any An array of transports this outbound matches (e.g. https) sign-token.outbound.*.hosts any An array of hosts this outbound matches, may use * as a wild-card (e.g. *.oracle.com) sign-token.outbound.*.paths any An array of paths on the host this outbound matches, may use * as a wild-card (e.g. /some/path/*) sign-token.outbound.*.outbound-token Authorization header with `bearer ` prefix Configuration of outbound token handler (same as atn-token.handler) sign-token.outbound.*.outbound-token.format &#160; Java text format for generating the value of outbound token header (e.g. \"bearer %1$s\") sign-token.outbound.*.jwk-kid &#160; If this key is defined, we are generating a new token, otherwise we propagate existing. Defines the key id of a key definition in the JWK file to use for signing the outbound token sign-token.outbound.*.jwt-kid &#160; A key to use in the generated JWT - this is for the other service to locate the verification key in their JWK sign-token.outbound.*.jwt-audience &#160; Audience this key is generated for (e.g. http://www.example.org/api/myService ) - validated by the other service sign-token.outbound.*.jwt-not-before-seconds 5 Makes this key valid this amount of seconds into the past. Allows a certain time-skew for the generated token to be valid before current time (e.g. when we expect a certain misalignment of clocks) sign-token.outbound.*.jwt-validity-seconds 1 day Token validity in seconds How does it work? JSON Web Token (JWT) provider has support for authentication and outbound security. Authentication is based on validating the token (signature, valid before etc.) and on asserting the subject of the JWT subject claim. For outbound, we support either token propagation (e.g. the token from request is propagated further) or support for generating a brand new token based on configuration of this provider. ",
            "title": "Implemented Security Providers"
        },
        {
            "location": "/se/webclient/02_tls-configuration",
            "text": " Configure TLS either programmatically or by the Helidon configuration framework. ",
            "title": "preambule"
        },
        {
            "location": "/se/webclient/02_tls-configuration",
            "text": " The one way to configure TLS in WebClient is in your application code. <markup lang=\"java\" >KeyConfig keyConfig = KeyConfig.keystoreBuilder() //Whether this keystore is also trust store .trustStore() //Keystore location/name .keystore(Resource.create(\"client.p12\")) //Password to the keystore .keystorePassphrase(\"password\") .build(); WebClient.builder() .tls(WebClientTls.builder() .certificateTrustStore(keyConfig) .clientKeyStore(keyConfig) .build()) .build(); ",
            "title": "Configuring TLS in your code"
        },
        {
            "location": "/se/webclient/02_tls-configuration",
            "text": " It is also possible to configure TLS via the config file. <markup lang=\"yaml\" title=\"WebClient TLS configuration file application.yaml \" >webclient: tls: #Server part defines settings for server certificate validation and truststore server: keystore: passphrase: \"password\" trust-store: true resource: resource-path: \"keystore.p12\" #Client part defines access to the keystore with client private key or certificate client: keystore: passphrase: \"password\" resource: resource-path: \"keystore.p12\" Then, in your application code, load the configuration from that file. <markup lang=\"java\" title=\"WebClient initialization using the application.yaml file located on the classpath\" >Config config = Config.create(); WebClient webClient = WebClient.create(config.get(\"webclient\")); Or you can only create WebClientTls instance based on the config file. <markup lang=\"java\" title=\"WebClientTls instance based on application.yaml file located on the classpath\" >Config config = Config.create(); WebClientTls.builder() .config(config.get(\"webclient.tls\")) .build(); ",
            "title": "Configuring TLS in the config file"
        },
        {
            "location": "/se/webclient/02_tls-configuration",
            "text": " See all configuration options here . Available server certificate configuration options: Configuration key Default value Java type Description disable-hostname-verification false boolean Whether hostname verification should be performed trust-all false boolean Whether all of the server certificates should be trusted keystore &#160; Object Keystore configuration, please follow the example above Available client configuration options: Configuration key Default value Java type Description keystore &#160; Object Keystore configuration, please follow the example above ",
            "title": "Configuration options"
        },
        {
            "location": "/mp/jaxrs/10_reactive-routing",
            "text": " Since Helidon 1.4 ",
            "title": "preambule"
        },
        {
            "location": "/mp/jaxrs/10_reactive-routing",
            "text": " You can annotate a service bean with this annotation to assign it to a specific named routing, that is (most likely) going to be bound to a specific port. The annotation has two attributes: - value that defines the routing name - required to mark that the routing name MUST be configured in Helidon server <markup lang=\"java\" title=\" @RoutingName example\" >@ApplicationScoped @RoutingName(value=\"admin\", required=\"true\") @RoutingPath(\"/admin\") public class AdminService implements Service { //.... } The example above will be bound to admin routing (and port) and will fail if such a port is not configured. ",
            "title": "Annotation @RoutingName "
        },
        {
            "location": "/mp/jaxrs/10_reactive-routing",
            "text": " For each service bean you can define the routing name and its required flag by specifying a configuration option bean-class-name.routing-name.name and bean-class-name.routing-name.required . For service beans produced with producer method replace bean-class-name with class-name.producer-method-name . Example (YAML) configuration for a service bean io.helidon.examples.AdminService that changes the routing name to management and its required flag to false : <markup lang=\"yaml\" >io.helidon.examples.AdminService: routing-name: name: \"management\" required: false ",
            "title": "Configuration override of routing name"
        },
        {
            "location": "/mp/jaxrs/10_reactive-routing",
            "text": " Helidon has the concept of named routings. These correspond to the named ports configured with WebServer. You can assign a reactive service to a named routing (and as a result to a named port) using either an annotation or configuration (or both to override the value from annotation). Annotation @RoutingName You can annotate a service bean with this annotation to assign it to a specific named routing, that is (most likely) going to be bound to a specific port. The annotation has two attributes: - value that defines the routing name - required to mark that the routing name MUST be configured in Helidon server <markup lang=\"java\" title=\" @RoutingName example\" >@ApplicationScoped @RoutingName(value=\"admin\", required=\"true\") @RoutingPath(\"/admin\") public class AdminService implements Service { //.... } The example above will be bound to admin routing (and port) and will fail if such a port is not configured. Configuration override of routing name For each service bean you can define the routing name and its required flag by specifying a configuration option bean-class-name.routing-name.name and bean-class-name.routing-name.required . For service beans produced with producer method replace bean-class-name with class-name.producer-method-name . Example (YAML) configuration for a service bean io.helidon.examples.AdminService that changes the routing name to management and its required flag to false : <markup lang=\"yaml\" >io.helidon.examples.AdminService: routing-name: name: \"management\" required: false ",
            "title": "Assigning a reactive service to named ports"
        },
        {
            "location": "/mp/jaxrs/10_reactive-routing",
            "text": " You can configure @RoutingPath to define the path a service is registered on. ",
            "title": "Annotation @RoutingPath "
        },
        {
            "location": "/mp/jaxrs/10_reactive-routing",
            "text": " For each reactive service class you can define the routing path by specifying a configuration option class-name.routing-path.path . Example (YAML) configuration for a class io.helidon.example.AdminService that changes the routing path to /management : <markup lang=\"yaml\" >io.helidon.examples.AdminService: routing-path: path: \"/management\" ",
            "title": "Configuration override of routing path"
        },
        {
            "location": "/mp/jaxrs/10_reactive-routing",
            "text": " Each service is registered on a path. If none is configured, then the service would be configured on the root path. You can configure service path using an annotation or configuration (or both to override value from annotation) Annotation @RoutingPath You can configure @RoutingPath to define the path a service is registered on. Configuration override of routing path For each reactive service class you can define the routing path by specifying a configuration option class-name.routing-path.path . Example (YAML) configuration for a class io.helidon.example.AdminService that changes the routing path to /management : <markup lang=\"yaml\" >io.helidon.examples.AdminService: routing-path: path: \"/management\" ",
            "title": "Configuring a reactive service path"
        },
        {
            "location": "/mp/jaxrs/10_reactive-routing",
            "text": " The service can be customized using annotations and/or configuration to be registered on a specific path registered with a named routing Assigning a reactive service to named ports Helidon has the concept of named routings. These correspond to the named ports configured with WebServer. You can assign a reactive service to a named routing (and as a result to a named port) using either an annotation or configuration (or both to override the value from annotation). Annotation @RoutingName You can annotate a service bean with this annotation to assign it to a specific named routing, that is (most likely) going to be bound to a specific port. The annotation has two attributes: - value that defines the routing name - required to mark that the routing name MUST be configured in Helidon server <markup lang=\"java\" title=\" @RoutingName example\" >@ApplicationScoped @RoutingName(value=\"admin\", required=\"true\") @RoutingPath(\"/admin\") public class AdminService implements Service { //.... } The example above will be bound to admin routing (and port) and will fail if such a port is not configured. Configuration override of routing name For each service bean you can define the routing name and its required flag by specifying a configuration option bean-class-name.routing-name.name and bean-class-name.routing-name.required . For service beans produced with producer method replace bean-class-name with class-name.producer-method-name . Example (YAML) configuration for a service bean io.helidon.examples.AdminService that changes the routing name to management and its required flag to false : <markup lang=\"yaml\" >io.helidon.examples.AdminService: routing-name: name: \"management\" required: false Configuring a reactive service path Each service is registered on a path. If none is configured, then the service would be configured on the root path. You can configure service path using an annotation or configuration (or both to override value from annotation) Annotation @RoutingPath You can configure @RoutingPath to define the path a service is registered on. Configuration override of routing path For each reactive service class you can define the routing path by specifying a configuration option class-name.routing-path.path . Example (YAML) configuration for a class io.helidon.example.AdminService that changes the routing path to /management : <markup lang=\"yaml\" >io.helidon.examples.AdminService: routing-path: path: \"/management\" ",
            "title": "Customizing the reactive service"
        },
        {
            "location": "/mp/jaxrs/10_reactive-routing",
            "text": " A full configuration example (YAML): <markup lang=\"yaml\" >server: port: 8080 sockets: management: port: 8090 io.helidon.examples.AdminService: routing-name: name: \"management\" required: true routing-path: path: \"/management\" ",
            "title": "Example configuration of reactive service"
        },
        {
            "location": "/mp/jaxrs/10_reactive-routing",
            "text": " Helidon MP Server will pick up CDI beans that implement the io.helidon.webserver.Service interface and configure them with the underlying WebServer. This allows configuration of reactive routes to run alongside a JAX-RS application. The bean is expected to be either ApplicationScoped or Dependent and will be requested only once during the boot of the Server . The bean will support injection of ApplicationScoped and Dependent scoped beans. You cannot inject RequestScoped beans. Please use WebServer features to handle request related objects. Customizing the reactive service The service can be customized using annotations and/or configuration to be registered on a specific path registered with a named routing Assigning a reactive service to named ports Helidon has the concept of named routings. These correspond to the named ports configured with WebServer. You can assign a reactive service to a named routing (and as a result to a named port) using either an annotation or configuration (or both to override the value from annotation). Annotation @RoutingName You can annotate a service bean with this annotation to assign it to a specific named routing, that is (most likely) going to be bound to a specific port. The annotation has two attributes: - value that defines the routing name - required to mark that the routing name MUST be configured in Helidon server <markup lang=\"java\" title=\" @RoutingName example\" >@ApplicationScoped @RoutingName(value=\"admin\", required=\"true\") @RoutingPath(\"/admin\") public class AdminService implements Service { //.... } The example above will be bound to admin routing (and port) and will fail if such a port is not configured. Configuration override of routing name For each service bean you can define the routing name and its required flag by specifying a configuration option bean-class-name.routing-name.name and bean-class-name.routing-name.required . For service beans produced with producer method replace bean-class-name with class-name.producer-method-name . Example (YAML) configuration for a service bean io.helidon.examples.AdminService that changes the routing name to management and its required flag to false : <markup lang=\"yaml\" >io.helidon.examples.AdminService: routing-name: name: \"management\" required: false Configuring a reactive service path Each service is registered on a path. If none is configured, then the service would be configured on the root path. You can configure service path using an annotation or configuration (or both to override value from annotation) Annotation @RoutingPath You can configure @RoutingPath to define the path a service is registered on. Configuration override of routing path For each reactive service class you can define the routing path by specifying a configuration option class-name.routing-path.path . Example (YAML) configuration for a class io.helidon.example.AdminService that changes the routing path to /management : <markup lang=\"yaml\" >io.helidon.examples.AdminService: routing-path: path: \"/management\" Example configuration of reactive service A full configuration example (YAML): <markup lang=\"yaml\" >server: port: 8080 sockets: management: port: 8090 io.helidon.examples.AdminService: routing-name: name: \"management\" required: true routing-path: path: \"/management\" ",
            "title": "Configuring a reactive route in Helidon MP"
        },
        {
            "location": "/about/05_cli",
            "text": " The Helidon CLI lets you easily create a Helidon project by picking from a set of archetypes. It also supports a developer loop that performs continuous compilation and application restart, so you can easily iterate over source code changes. The CLI is distributed as a standalone executable (compiled using GraalVM) for ease of installation. It is currently available as a download for Linux, Mac and Windows. Simply download the binary, install it at a location accessible from your PATH and you’re ready to go. ",
            "title": "Introduction"
        },
        {
            "location": "/about/05_cli",
            "text": " Helidon requires Java 11 (or newer) and Maven. <div class=\"table__overflow elevation-1 flex sm7 \"> Java&#160;SE&#160;11 ( Open&#160;JDK&#160;11 ) or newer Maven 3.6.1+ You should make sure java and mvn are in your path. <markup lang=\"bash\" >java -version mvn --version ",
            "title": "Prerequisites"
        },
        {
            "location": "/about/05_cli",
            "text": "<markup lang=\"bash\" title=\"MacOS\" >curl -L -O https://helidon.io/cli/latest/darwin/helidon chmod +x ./helidon sudo mv ./helidon /usr/local/bin/ If you get a warning that \"the developer cannot be verified\" when running the CLI this is due to the Helidon CLI not being signed and notarized yet. You can disable this check by running: xattr -d com.apple.quarantine helidon <markup lang=\"bash\" title=\"Linux\" >curl -L -O https://helidon.io/cli/latest/linux/helidon chmod +x ./helidon sudo mv ./helidon /usr/local/bin/ <markup lang=\"powershell\" title=\"Windows\" >PowerShell -Command Invoke-WebRequest -Uri \"https://helidon.io/cli/latest/windows/helidon.exe\" -OutFile \"C:\\Windows\\system32\\helidon.exe\" For Windows you will also need the Visual C++ Redistributable Runtime. See Helidon on Windows for more information. ",
            "title": "Installation"
        },
        {
            "location": "/about/05_cli",
            "text": "<markup lang=\"bash\" >helidon init Then answer the questions. ",
            "title": "Create a New Project"
        },
        {
            "location": "/about/05_cli",
            "text": "<markup lang=\"bash\" >cd myproject helidon dev As you make source code changes the project will automatically recompile and restart your application. ",
            "title": "Developer Loop"
        },
        {
            "location": "/about/05_cli",
            "text": " ",
            "title": "Demo"
        },
        {
            "location": "/se/security/05_extensibility",
            "text": " This guide describes how you can extend the Security component. The component has the following extension points: Security providers Provider selection policy Integration with a framework ",
            "title": "preambule"
        },
        {
            "location": "/se/security/05_extensibility",
            "text": " To create a custom authentication provider, create a class that implements io.helidon.security.spi.AuthenticationProvider . Implementation is responsible for taking a request and asserting a subject based on that request. In case the protocol is multi-request (e.g. challenge for basic authentication), you have the possibility to return specific headers and a response code. The default semantics of these is HTTP, though providers may exist that are not HTTP specific. ",
            "title": "Authentication provider"
        },
        {
            "location": "/se/security/05_extensibility",
            "text": " To create a custom authorization provider, create a class that implements io.helidon.security.spi.AuthorizationProvider . Implementation is responsible for taking a request and checking whether the request can continue processing (e.g. if the current user and/or service subject has a right to execute it). If authentication is configured, the Security component guarantees it resolved before authorization. ",
            "title": "Authorization provider"
        },
        {
            "location": "/se/security/05_extensibility",
            "text": " To create a custom outbound security provider, create a class that implements io.helidon.security.spi.OutboundSecurityProvider . Implementation can update outgoing message headers to handle security for an outgoing request (e.g. identity propagation, mapping etc.). ",
            "title": "Outbound security provider"
        },
        {
            "location": "/se/security/05_extensibility",
            "text": " To create a custom audit provider, create a class that implements io.helidon.security.spi.AuditProvider . Security component feeds each audit provider all messages from all components that invoke audit method on \"Security\" class, including internal audit events pre-configured in the component itself (e.g. authentication, authorization events). Implementation may do whatever desired with these messages, e.g.: filter them log them store them to a database forward them to an audit component discard them ",
            "title": "Audit provider"
        },
        {
            "location": "/se/security/05_extensibility",
            "text": " You can build a custom provider for each type of security concept supported. By default, each provider is asynchronous. For simple cases, a class exists in \"spi\" package to help implement a synchronous approach: SynchronousProvider . You have two options: Implement a provider interface and reference it in configuration (or from builder) by class Implement a provider interface and provide a Java ServiceLoader service implementing io.helidon.security.spi.SecurityProviderService The second option allows for easier configuration, as the configuration key can be used without a class definition and creates a default name of a provider. Authentication provider To create a custom authentication provider, create a class that implements io.helidon.security.spi.AuthenticationProvider . Implementation is responsible for taking a request and asserting a subject based on that request. In case the protocol is multi-request (e.g. challenge for basic authentication), you have the possibility to return specific headers and a response code. The default semantics of these is HTTP, though providers may exist that are not HTTP specific. Authorization provider To create a custom authorization provider, create a class that implements io.helidon.security.spi.AuthorizationProvider . Implementation is responsible for taking a request and checking whether the request can continue processing (e.g. if the current user and/or service subject has a right to execute it). If authentication is configured, the Security component guarantees it resolved before authorization. Outbound security provider To create a custom outbound security provider, create a class that implements io.helidon.security.spi.OutboundSecurityProvider . Implementation can update outgoing message headers to handle security for an outgoing request (e.g. identity propagation, mapping etc.). Audit provider To create a custom audit provider, create a class that implements io.helidon.security.spi.AuditProvider . Security component feeds each audit provider all messages from all components that invoke audit method on \"Security\" class, including internal audit events pre-configured in the component itself (e.g. authentication, authorization events). Implementation may do whatever desired with these messages, e.g.: filter them log them store them to a database forward them to an audit component discard them ",
            "title": "Security providers"
        },
        {
            "location": "/se/security/05_extensibility",
            "text": " Each request is processed by a single authentication and/or authorization provider. The selection policy provides the security component information about which provider to use. Out of the box, there are three policies: \"First\" policy - first configured provider (or explicitly defined default provider) is used by default, if a named provider is requested, it would be used \"Composite\" policy - this policy allows for a sequence of providers to be executed (e.g. one request may have more than one provider) - used for example to resolve service and user authentication \"Class\" policy - this allows usage of a custom policy defined by fully qualified class name To create a custom provider selection policy, create a class that implements \"io.helidon.security.spi.ProviderSelectionPolicy\". ",
            "title": "Provider selection policy"
        },
        {
            "location": "/se/security/05_extensibility",
            "text": " The Security component supports integration with Helidon WebServer ( helidon-security-integration-webserver ) and with Jersey ( helidon-security-integration-jersey ). Existing integrations (WebServer and Jersey) use Helidon Security APIs that are available to integrate any framework/application (for example we could integrate security with messaging, such as JMS). To create a new integration, an instance of Security class is needed, as it handles all configured providers. Usually a single Security instance is used for an application. Security is then used to create an instance of SecurityContext , which is used for interaction with a single user. A single SecurityContext is created for each HTTP request in Jersey and WebServer integration. SecurityContext is used to invoke authentication, authorization, and outbound security requests. Helidon Security also defines a set of annotations: @Authenticated - access to resources must follow authentication rules defined by the annotation @Authorized - access to resources must follow authorization rules defined by the annotation @Audited - to configure auditing If the protected resources (in Helidon MP, these are JAX-RS resource classes and methods) can be annotated, the integration component must use these annotations when deciding how to secure the endpoint. For example, the Jersey integration checks whether the @Authenticated annotation exists. If it does, then the integration component attempts to authenticate the request. Because other components of Helidon Security (such as ABAC validators) query the request for annotations, the integration component should also collect all annotations from the resource and correctly configure them when creating the security request. ",
            "title": "Framework integration"
        },
        {
            "location": "/mp/jaxrs/03_application-configuration",
            "text": " Your application can use the MicroProfile Config or Helidon Config (or both). MicroProfile Config offers portability to other MicroProfile servers. Helidon Config supports a full tree structure, including repeating elements. ",
            "title": "preambule"
        },
        {
            "location": "/mp/jaxrs/03_application-configuration",
            "text": " You can inject values that the application can access from both MicroProfile Config and from Helidon Config. <markup lang=\"java\" title=\"JAX-RS - inject a single config property\" >@Inject public MyResource(@ConfigProperty(name=\"app.name\") String appName) { this.applicationName = appName; } You can also inject the whole configuration instance, either io.helidon.config.Config or org.eclipse.microprofile.config.Config . <markup lang=\"java\" title=\"JAX-RS - inject config\" >@Inject public MyResource(Config config) { this.config = config; } ",
            "title": "Configuring the Application"
        },
        {
            "location": "/se/oci/01_oci",
            "text": " Helidon SE OCI Integration provides easy access to Oracle Cloud Infrastructure. ",
            "title": "preambule"
        },
        {
            "location": "/se/oci/01_oci",
            "text": " The custom Helidon SE OCI clients documented here are deprecated. It is recommended that you use the OCI Java SDK directly, in particular the Async clients. For more information see: OCI Documentation Helidon SE OCI ATP Example Helidon SE OCI Object Storage Example Helidon SE OCI Metrics Example Helidon SE OCI Vault Example ",
            "title": "Deprecated"
        },
        {
            "location": "/se/oci/01_oci",
            "text": " Helidon integration with Oracle Cloud Infrastructure is still experimental and not intended for production use. APIs and features have not yet been fully tested and are subject to change. ",
            "title": "Experimental"
        },
        {
            "location": "/se/oci/01_oci",
            "text": " The first option to configure connection to OCI is to directly specify properties in application.yaml file: <markup lang=\"yaml\" >oci: config: oci-profile: user: ocid1.user.... fingerprint: 1c:6c:.... tenancy: ocid1.tenancy.oc1.. region: us-... key-pem: &lt;pem content&gt; ",
            "title": "Using Helidon SE Properties Configuration"
        },
        {
            "location": "/se/oci/01_oci",
            "text": " The second option is via OCI configuration file. For authentication in OCI a special configuration file should be set up. The file is usually located at ~/.oci/config <markup lang=\"properties\" >[DEFAULT] user=ocid1.user.... fingerprint=1c:6c:.... tenancy=ocid1.tenancy.oc1.. region=us-... key_file=&lt;path to key file&gt; More information how to set up on your environment: Official website ",
            "title": "Using OCI Configuration"
        },
        {
            "location": "/se/oci/01_oci",
            "text": " If you follow these instructions on how to Generate an API Signing Key , be advised that Helidon does not currently support passphrase-protected private keys in PKCS#1 format. If generating a private key using those instructions, use the no passphrase option. Using Helidon SE Properties Configuration The first option to configure connection to OCI is to directly specify properties in application.yaml file: <markup lang=\"yaml\" >oci: config: oci-profile: user: ocid1.user.... fingerprint: 1c:6c:.... tenancy: ocid1.tenancy.oc1.. region: us-... key-pem: &lt;pem content&gt; Using OCI Configuration The second option is via OCI configuration file. For authentication in OCI a special configuration file should be set up. The file is usually located at ~/.oci/config <markup lang=\"properties\" >[DEFAULT] user=ocid1.user.... fingerprint=1c:6c:.... tenancy=ocid1.tenancy.oc1.. region=us-... key_file=&lt;path to key file&gt; More information how to set up on your environment: Official website ",
            "title": "General Configuration"
        },
        {
            "location": "/se/cors/04_support-in-builtin-services",
            "text": " Several built-in Helidon services&#8201;&#8212;&#8201;health, metrics, and OpenAPI&#8201;&#8212;&#8201;have integrated CORS support. You can include these services in your application and control their CORS behavior. ",
            "title": "preambule"
        },
        {
            "location": "/se/cors/04_support-in-builtin-services",
            "text": " Helidon lets you easily include health , metrics , and OpenAPI services in your Helidon application. These services add endpoints to your application so that clients can retrieve information about it. As with the application endpoints you write, these endpoints represent resources that can be shared across origins. For example, several websites related to OpenAPI run a web application in your browser. You provide the URL for your application to the browser application. The browser application uses the URL to retrieve the OpenAPI document that describes the application&#8217;s endpoints directly from your application. The browser application then displays a user interface that you use to \"drive\" your application. That is, you provide input, have the web application send requests to your application endpoints, and then view the responses. This scenario is exactly the situation CORS addresses: an application in the browser from one origin&#8201;&#8212;&#8201;the user interface downloaded from the website&#8201;&#8212;&#8201;requests a resource from another origin&#8201;&#8212;&#8201;the /openapi endpoint which Helidon&#8217;s OpenAPI built-in service automatically adds to your application. Integrating CORS support into these built-in services allows such third-party web sites and their browser applications&#8201;&#8212;&#8201;or more generally, apps from any other origin&#8201;&#8212;&#8201;to work with your Helidon application. Because all three of these built-in Helidon services serve only GET endpoints, by default the integrated CORS support in all three services permits any origin to share their resources using GET , HEAD , and OPTIONS HTTP requests. You can customize the CORS set-up for these built-in services independently from each other using either the Helidon API, configuration, or both. You can use this override feature to control the CORS behavior of the built-in services even if you do not add CORS behavior to your own endpoints. ",
            "title": "Understanding CORS Support in Helidon Services"
        },
        {
            "location": "/se/cors/04_support-in-builtin-services",
            "text": " To use built-in services with CORS support and customize the CORS behavior: Add the built-in service or services to your application. The health, metrics, and OpenAPI services automatically include default CORS support. Add a dependency on the Helidon SE CORS artifact to your Maven pom.xml file. If you want the built-in services to support CORS, then you need to add the CORS dependency even if your own endpoints do not use CORS. The Managing Dependencies page describes how you should declare dependency management for Helidon applications. For CORS support in Helidon SE, you must include the following dependency in your project: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webserver&lt;/groupId&gt; &lt;artifactId&gt;helidon-webserver-cors&lt;/artifactId&gt; &lt;/dependency&gt; Use the Helidon API or configuration to customize the CORS behavior as needed. The documentation for the individual built-in services describes how to add each service to your application, including adding a Maven dependency and including the service in your application&#8217;s routing rules. In your application&#8217;s configuration file, the configuration for each service appears under its own key. Helidon Service Documentation Configuration Key health health metrics metrics OpenAPI openapi The Helidon SE QuickStart example uses these services, so you can use that as a template for your own application, or use the example project itself to experiment with customizing the CORS behavior in the built-in services. ",
            "title": "Getting Started"
        },
        {
            "location": "/se/cors/04_support-in-builtin-services",
            "text": " Although services such as health, metrics, and OpenAPI are built into Helidon, to use them your application must create instances of the services and then use those instances in building your application&#8217;s routing rules. Recall that each service type has a Builder class. To control the CORS behavior of a built-in service using the API, follow these steps: Create a Builder for the type of service of interest. Build an instance of CrossOriginConfig with the settings you want. Invoke the builder.crossOriginConfig method, passing that CrossOriginConfig instance. Invoke the builder&#8217;s build method to initialize the service instance. Use the service instance in preparing the routing rules. The following excerpt shows changes to the Helidon SE QuickStart example which limit sharing of the /metrics endpoint to http://foo.com . <markup lang=\"java\" >private static Routing createRouting(Config config) { CrossOriginConfig.Builder metricsCrossOriginConfigBuilder = CrossOriginConfig.builder() .allowOrigins(\"http://foo.com\"); RestServiceSettings.Builder restServiceSettingsBuilder = RestServiceSettings.builder() .crossOriginConfig(metricsCrossOriginConfigBuilder); MetricsSupport metrics = MetricsSupport.builder() .restServiceSettings(restServiceSettingsBuilder) .build(); GreetService greetService = new GreetService(config); HealthSupport health = HealthSupport.builder() .addLiveness(HealthChecks.healthChecks()) // Adds a convenient set of checks .build(); return Routing.builder() .register(health) // Health at \"/health\" .register(metrics) // Metrics at \"/metrics\" .register(\"/greet\", greetService) .build(); } Create the CrossOriginConfig.Builder for metrics, limiting sharing to http://foo.com . Use the CrossOriginConfig.Builder instance in constructing the RestServiceSetting.Builder (which assigns common settings such as the CORS configuration and the web context for the service endpoint). Use the RestServiceSetting.Builder in preparing the MetricsSupport service. Use the MetricsSupport object in creating the routing rules. ",
            "title": "Controlling CORS for Built-in Services Using the API"
        },
        {
            "location": "/se/cors/04_support-in-builtin-services",
            "text": " You can also use configuration to control whether and how each of the built-in services works with CORS. Your application can pass configuration to the builder for each built-in service. For the health, metrics, and OpenAPI services, your configuration can include a section for CORS. The following example restricts sharing of the /health resource, provided by the health built-in service, to only the origin http://there.com . <markup lang=\"hocon\" >... health: cors: allow-origins: [http://there.com] ... Modify your application to load the health config node and use it to construct the HealthSupport service. The following code shows this change in the the QuickStart SE example. <markup lang=\"java\" >HealthSupport health = HealthSupport.builder() .config(config.get(\"health\")) .addLiveness(HealthChecks.healthChecks()) // Adds a convenient set of checks .build(); Use the health config section (if present) to configure the health service. You have full control over the CORS configuration for a built-in Helidon service. Use a basic CORS config section as described in Using Configuration for CORS . ",
            "title": "Configuring CORS for Built-in Services"
        },
        {
            "location": "/se/cors/04_support-in-builtin-services",
            "text": " Build and run the QuickStart application as usual. <markup lang=\"bash\" >mvn package java -jar target/helidon-quickstart-se.jar ... WEB server is up! http://localhost:8080/greet ",
            "title": "Build and Run the Application"
        },
        {
            "location": "/se/cors/04_support-in-builtin-services",
            "text": " The metrics service rejects attempts to access metrics on behalf of a disallowed origin. <markup lang=\"bash\" >curl -i -H \"Origin: http://other.com\" http://localhost:8080/metrics HTTP/1.1 403 Forbidden Date: Mon, 11 May 2020 11:08:09 -0500 transfer-encoding: chunked connection: keep-alive But accesses from foo.com succeed. <markup lang=\"bash\" >curl -i -H \"Origin: http://foo.com\" http://localhost:8080/metrics HTTP/1.1 200 OK Access-Control-Allow-Origin: http://foo.com Content-Type: text/plain Date: Mon, 11 May 2020 11:08:16 -0500 Vary: Origin connection: keep-alive content-length: 6065 # TYPE base_classloader_loadedClasses_count gauge # HELP base_classloader_loadedClasses_count Displays the number of classes that are currently loaded in the Java virtual machine. base_classloader_loadedClasses_count 3568 ... ",
            "title": "Retrieve Metrics"
        },
        {
            "location": "/se/cors/04_support-in-builtin-services",
            "text": " The health service rejects requests from origins not specifically approved. <markup lang=\"bash\" >curl -i -H \"Origin: http://foo.com\" http://localhost:8080/health HTTP/1.1 403 Forbidden Date: Mon, 11 May 2020 12:06:55 -0500 transfer-encoding: chunked connection: keep-alive And responds successfully only to cross-origin requests from http://there.com . <markup lang=\"bash\" >curl -i -H \"Origin: http://there.com\" http://localhost:8080/health HTTP/1.1 200 OK Access-Control-Allow-Origin: http://there.com Content-Type: application/json Date: Mon, 11 May 2020 12:07:32 -0500 Vary: Origin connection: keep-alive content-length: 461 {\"outcome\":\"UP\",...} ",
            "title": "Retrieve Health"
        },
        {
            "location": "/se/cors/04_support-in-builtin-services",
            "text": " If you have edited the Helidon SE QuickStart application as described in the previous topics and saved your changes, you can build and run the application. Once you do so you can execute curl commands to demonstrate the behavior changes in the metric and health services with the addition of the CORS functionality. Note the addition of the Origin header value in the curl commands, and the Access-Control-Allow-Origin in the successful responses. Build and Run the Application Build and run the QuickStart application as usual. <markup lang=\"bash\" >mvn package java -jar target/helidon-quickstart-se.jar ... WEB server is up! http://localhost:8080/greet Retrieve Metrics The metrics service rejects attempts to access metrics on behalf of a disallowed origin. <markup lang=\"bash\" >curl -i -H \"Origin: http://other.com\" http://localhost:8080/metrics HTTP/1.1 403 Forbidden Date: Mon, 11 May 2020 11:08:09 -0500 transfer-encoding: chunked connection: keep-alive But accesses from foo.com succeed. <markup lang=\"bash\" >curl -i -H \"Origin: http://foo.com\" http://localhost:8080/metrics HTTP/1.1 200 OK Access-Control-Allow-Origin: http://foo.com Content-Type: text/plain Date: Mon, 11 May 2020 11:08:16 -0500 Vary: Origin connection: keep-alive content-length: 6065 # TYPE base_classloader_loadedClasses_count gauge # HELP base_classloader_loadedClasses_count Displays the number of classes that are currently loaded in the Java virtual machine. base_classloader_loadedClasses_count 3568 ... Retrieve Health The health service rejects requests from origins not specifically approved. <markup lang=\"bash\" >curl -i -H \"Origin: http://foo.com\" http://localhost:8080/health HTTP/1.1 403 Forbidden Date: Mon, 11 May 2020 12:06:55 -0500 transfer-encoding: chunked connection: keep-alive And responds successfully only to cross-origin requests from http://there.com . <markup lang=\"bash\" >curl -i -H \"Origin: http://there.com\" http://localhost:8080/health HTTP/1.1 200 OK Access-Control-Allow-Origin: http://there.com Content-Type: application/json Date: Mon, 11 May 2020 12:07:32 -0500 Vary: Origin connection: keep-alive content-length: 461 {\"outcome\":\"UP\",...} ",
            "title": "Accessing the Shared Resources"
        },
        {
            "location": "/mp/aot/01_introduction",
            "text": " Helidon applications can be compiled into a native executable using GraalVM native image. When using applications created using the CLI, or when you configure Helidon application pom as a parent of your module, you can use the following steps to build a native image from your application: Create an environment variable GRAALVM_HOME pointing to your installation of GraalVM with native-image installed Run Maven command mvn clean package -Pnative-image Execute the native executable created in target directory of your project ",
            "title": "preambule"
        },
        {
            "location": "/mp/aot/01_introduction",
            "text": " Some Helidon components are not (yet) supported in native image, some have restrictions. The following table lists all Helidon features and their support for native image. Helidon MP features in AOT &#160; Feature Component AOT note ✅ CDI CDI &#160; ✅ Config Config &#160; ✅ &#160; Encryption &#160; ✅ &#160; YAML &#160; ✅ Fault Tolerance Fault Tolerance &#160; ✅ Health Health &#160; ✅ &#160; Built-ins &#160; ✅ JAX-RS JAX-RS &#160; ✅ JPA JPA &#160; ❓ &#160; EclipseLink Not yet tested. 🔶 &#160; Hibernate Experimental support, tested on limited use cases with Helidon Oracle and H2 JDBC modules 🔶 JTA JTA Experimental support, tested on limited use cases ✅ Messaging Messaging &#160; ✅ Metrics Metrics &#160; ✅ Open API Open API &#160; 🔶 REST Client REST Client Does not support execution of default methods on interfaces. ✅ Security Security &#160; ✅ &#160; Integration: Jersey &#160; ✅ &#160; Integration: WebServer &#160; ✅ &#160; Integration: gRPC &#160; ✅ &#160; JWT Auth &#160; ✅ &#160; OIDC &#160; ✅ &#160; Provider: ABAC &#160; ✅ &#160; Provider/ABAC/Policy: EL Requires reflection configuration for used classes. ✅ &#160; Provider/ABAC: Role &#160; ✅ &#160; Provider/ABAC: Scope &#160; ✅ &#160; Provider/ABAC: Time &#160; ❓ &#160; Provider: Google Login Not yet tested. ✅ &#160; Provider: Header &#160; ✅ &#160; Provider: HTTP Basic &#160; ✅ &#160; Provider: HTTP Digest &#160; ✅ &#160; Provider: HTTP Signatures &#160; ❓ &#160; Provider: IDCS Role Mapper Not yet tested. ✅ &#160; Provider: JWT &#160; ✅ Server Server &#160; ✅ &#160; Access Log &#160; ✅ &#160; CORS &#160; ✅ Tracing Tracing &#160; ✅ &#160; Integration: Jersey Server &#160; ✅ &#160; Integration: Jersey Client &#160; ✅ &#160; Jaeger &#160; ✅ &#160; Zipkin &#160; ✅ Web Client Web Client &#160; ✅ &#160; Metrics &#160; ✅ &#160; Security &#160; ✅ &#160; Tracing &#160; ✅ &#160; Websocket Server only. ✅ gRPC Server gRPC Server Since GraalVM 21.0.0 ✅ &#160; Metrics &#160; ✅ gRPC Client gRPC Client Since GraalVM 21.0.0 ✅ &#160; Metrics &#160; ✅ Scheduling Scheduling &#160; ✅ OCI OCI Integration Modules with group id io.helidon.integrations.oci ✅ Vault Hashicorp Vault Integration &#160; ✅ Long Running Actions Client &#160; ✅ &#160; Coordinator Only with external database ",
            "title": "AOT supported modules"
        },
        {
            "location": "/mp/jaxrs/05_jaxrs-applications",
            "text": " In this section we shall distinguish the notion of a JAX-RS Application subclass from a Helidon application. As we shall learn shortly, the latter may include zero or more of the former. The JAX-RS specification defines the notion of an Application subclass whose methods return resource and provider classes, singletons and properties. This is the mechanism developers can use to define what comprises a JAX-RS application. Unless otherwise stated by the runtime environment in which the JAX-RS application runs, every JAX-RS application must include exactly one Application subclass. Helidon provides an extension to JAX-RS in which 0 or more Application subclasses are allowed. If no Application subclasses are provided, then a so-called synthetic subclass will be created automatically. This synthetic subclass shall include all resource and provider classes discovered by Helidon. Most Helidon applications should simply rely on this mechanism in accordance to convention over configuration practices. ",
            "title": "preambule"
        },
        {
            "location": "/mp/jaxrs/05_jaxrs-applications",
            "text": " CDI scanning is controlled by the bean-discovery-mode attribute in beans.xml files &mdash; the default value for this attribute is annotated . In the default mode, CDI scans for beans decorated by bean-defining annotations such as @ApplicationScoped , @RequestScoped , etc. With the help of CDI, Helidon looks for JAX-RS Application subclasses in your Helidon application. If none are found, a synthetic application will be created by gathering all resources and providers found during the discovery phase. Note that if your Application subclass has no bean-defining annotations, and bean discovery is set to the default annotated value, it will be ignored. The discovery phase is carried out as follows (in no particular order): Collect all beans that extend Application Collect all beans annotated with @Path Collect all beans annotated with @Provider If no Application subclasses are found, create a synthetic Application subclass that includes all beans gathered in steps (2) and (3) and set the application path to be \"/\" &mdash;this is the path normally defined using the @ApplicationPath annotation. If one or more Application subclasses are found, call the getClasses and getSingletons methods in each subclass using the collections in steps (2) and (3) only as defaults, i.e. if these methods both return empty sets. Helidon treats @Path and @Provided as bean-definining annotations but, as stated above, Application subclasses may require additional annotations depending on the discovery mode. ",
            "title": "Discovery of JAX-RS Beans"
        },
        {
            "location": "/mp/jaxrs/05_jaxrs-applications",
            "text": " JAX-RS provides access to the Application subclass instance via injection using @Context . This form of access is still supported in Helidon but is insufficient if two or more subclasses are present. Given that support for two or more Application subclasses is a Helidon extension, a new mechanism is provided via the ServerRequest 's context object as shown next. <markup lang=\"java\" >import io.helidon.webserver.ServerRequest; @Path(\"myresource\") public class MyResource { @GET public void get(@Context ServerRequest serverRequest) { Application app = serverRequest.context().get(Application.class).get(); // ... } } This approach effectively moves the scope of Application subclass instances to request scope in order to access the correct subclass for the resource method being executed. ",
            "title": "Access to Application Instances"
        },
        {
            "location": "/mp/jaxrs/05_jaxrs-applications",
            "text": " Jersey does not currently provide support for multiple Application subclasses. As a result, it creates a single internal injection manager for your entire application, but this is insufficient when multiple Application subclasses are present. Helidon creates a separate injection manager for each Application subclass, and a single parent injection manager for your application. Each Application subclass injection manager delegates to the parent injection manager. Due to an implementation strategy in Jersey, ParamConverterProvider 's must be registered in the parent manager for proper registration and initialization. Thus, providers of this type will be shared and accessible by all Application subclasses, even if your code tries to limit their access. This is likely to change in future versions of Jersey/Helidon and does not typically impact how your application runs. ",
            "title": "Injection Managers in Helidon"
        },
        {
            "location": "/mp/vault/01_vault",
            "text": " HashiCorp Vault is a commonly used Vault in many microservices. The APIs are REST-based and Helidon implements them using reactive client. Vault integration supports the following: Secret Engines : Key/Value version 2, Key/Value version 1, Cubbyhole, PKI, Transit, Database Authentication Methods : Token, Kubernetes (k8s), AppRole Other Sys Operations and Configurations ",
            "title": "preambule"
        },
        {
            "location": "/mp/vault/01_vault",
            "text": " Helidon Vault support is still experimental and not intended for production use. APIs and features have not yet been fully tested and are subject to change. ",
            "title": "Experimental"
        },
        {
            "location": "/mp/vault/01_vault",
            "text": " Each of these features is implemented as a separate module, with the Vault class binding them together. In Helidon MP, with injection, this binding is done automatically, and you can simply inject your favorite secret engine. In addition to these features, Vault itself can be authenticated as follows: Token authentication - token is configured when connecting to Vault AppRole authentication - AppRole ID and secret ID are configured, integration exchanges these for a temporary token that is used to connect to Vault K8s authentication - the k8s JWT token is discovered on current node and used to obtain a temporary token that is used to connect to Vault ",
            "title": "Sys Operations"
        },
        {
            "location": "/mp/vault/01_vault",
            "text": " New secret engines and authentication methods can be implemented quite easily, as the integration is based on service providers (using ServiceLoader). This gives us (or you, as the users) the option to add new secret engines and/or authentication methods without adding a plethora of methods to the Vault class. See the following SPIs: <markup lang=\"properties\" >io.helidon.integrations.vault.spi.AuthMethodProvider io.helidon.integrations.vault.spi.SecretsEngineProvider io.helidon.integrations.vault.spi.SysProvider io.helidon.integrations.vault.spi.VaultAuth io.helidon.integrations.vault.spi.InjectionProvider ",
            "title": "Extensibility"
        },
        {
            "location": "/mp/vault/01_vault",
            "text": " The following is a list of maven coordinates of all Vault modules available: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.vault&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-vault&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.vault.auths&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-vault-auths-token&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.vault.auths&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-vault-auths-approle&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.vault.auths&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-vault-auths-k8s&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.vault.secrets&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-vault-secrets-kv1&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.vault.secrets&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-vault-secrets-kv2&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.vault.secrets&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-vault-secrets-cubbyhole&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.vault.secrets&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-vault-secrets-transit&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.vault.secrets&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-vault-secrets-database&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.vault.sys&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-vault-sys&lt;/artifactId&gt; &lt;/dependency&gt; To use Vault integration in MP, the following module must be added, as it enables injection of all features: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.vault&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-vault-cdi&lt;/artifactId&gt; &lt;/dependency&gt; Configuration to connect to Vault. Authenticating using Token: vault.address=http://localhost:8200 vault.token=my-token Authenticating using AppRole: vault.auth.app-role.role-id=app-role-id vault.auth.app-role.secret-id=app-role-secret-id Authenticating using Kubernetes: vault.auth.k8s.token-role=my-role The token role must be configured in Vault The following classes can be injected into any CDI bean (if appropriate module is on the classpath): Kv2Secrets - Key/Value Version 2 Secrets (versioned secrets, default) Kv1Secrets - Key/Value Version 1 Secrets (unversioned secrets, legacy) CubbyholeSecrets - Cubbyhole secrets (token bound secrets) DbSecrets - Database secrets (for generating temporary DB credentials) PkiSecrets - PKI secrets (for generating keys and X.509 certificates) TransitSecrets - Transit operations (encryption, signatures, HMAC) AppRoleAuth - AppRole authentication method (management operations) K8sAuth - Kubernetes authentication method (management operations) TokenAuth - Token authentication method (management operations) Sys - System operations (management of Vault - enabling/disabling secret engines and authentication methods) *Rx - reactive counterparts to the classes defined above, usually not recommended in CDI, as it is a blocking environment ",
            "title": "Modules"
        },
        {
            "location": "/mp/vault/01_vault",
            "text": " Cubbyhole example: <markup lang=\"java\" >@Path(\"/cubbyhole\") public class CubbyholeResource { private final CubbyholeSecrets secrets; @Inject CubbyholeResource(CubbyholeSecrets secrets) { this.secrets = secrets; } @POST @Path(\"/secrets/{path: .*}\") public Response createSecret(@PathParam(\"path\") String path, String secret) { CreateCubbyhole.Response response = secrets.create(path, Map.of(\"secret\", secret)); return Response.ok() .entity(\"Created secret on path: \" + path + \", key is \\\"secret\\\", original status: \" + response.status().code()) .build(); } @DELETE @Path(\"/secrets/{path: .*}\") public Response deleteSecret(@PathParam(\"path\") String path) { DeleteCubbyhole.Response response = secrets.delete(path); return Response.ok() .entity(\"Deleted secret on path: \" + path + \". Original status: \" + response.status().code()) .build(); } @GET @Path(\"/secrets/{path: .*}\") public Response getSecret(@PathParam(\"path\") String path) { Optional&lt;Secret&gt; secret = secrets.get(path); if (secret.isPresent()) { Secret kv1Secret = secret.get(); return Response.ok() .entity(\"Secret: \" + secret.get().values().toString()) .build(); } else { return Response.status(Response.Status.NOT_FOUND).build(); } } } Create a secret from request entity, the name of the value is {@code secret}. Delete the secret on a specified path. Get the secret on a specified path. ",
            "title": "Cubbyhole secrets"
        },
        {
            "location": "/mp/vault/01_vault",
            "text": " Key/Value version 1 secrets engine operations: <markup lang=\"java\" >@Path(\"/kv1\") public class Kv1Resource { private final Sys sys; private final Kv1Secrets secrets; @Inject Kv1Resource(Sys sys, Kv1Secrets secrets) { this.sys = sys; this.secrets = secrets; } @Path(\"/engine\") @GET public Response enableEngine() { EnableEngine.Response response = sys.enableEngine(Kv1SecretsRx.ENGINE); return Response.ok() .entity(\"Key/value version 1 secret engine is now enabled. Original status: \" + response.status().code()) .build(); } @Path(\"/engine\") @DELETE public Response disableEngine() { DisableEngine.Response response = sys.disableEngine(Kv1SecretsRx.ENGINE); return Response.ok() .entity(\"Key/value version 1 secret engine is now disabled. Original status: \" + response.status().code()) .build(); } @POST @Path(\"/secrets/{path: .*}\") public Response createSecret(@PathParam(\"path\") String path, String secret) { CreateKv&lt;1&gt;Response response = secrets.create(path, Map.of(\"secret\", secret)); return Response.ok() .entity(\"Created secret on path: \" + path + \", key is \\\"secret\\\", original status: \" + response.status().code()) .build(); } @DELETE @Path(\"/secrets/{path: .*}\") public Response deleteSecret(@PathParam(\"path\") String path) { DeleteKv&lt;1&gt;Response response = secrets.delete(path); return Response.ok() .entity(\"Deleted secret on path: \" + path + \". Original status: \" + response.status().code()) .build(); } @GET @Path(\"/secrets/{path: .*}\") public Response getSecret(@PathParam(\"path\") String path) { Optional&lt;Secret&gt; secret = secrets.get(path); if (secret.isPresent()) { Secret kv1Secret = secret.get(); return Response.ok() .entity(\"Secret: \" + secret.get().values().toString()) .build(); } else { return Response.status(Response.Status.NOT_FOUND).build(); } } } Enable the secrets engine on the default path. Disable the secrets engine on the default path. Create a secret from request entity, the name of the value is secret . Delete the secret on a specified path. Get the secret on a specified path. ",
            "title": "KV1 secrets"
        },
        {
            "location": "/mp/vault/01_vault",
            "text": " Key/Value version 2 secrets engine operations: <markup lang=\"java\" >@Path(\"/kv2\") public class Kv2Resource { private final Kv2Secrets secrets; @Inject Kv2Resource(@VaultName(\"app-role\") @VaultPath(\"custom\") Kv2Secrets secrets) { this.secrets = secrets; } @POST @Path(\"/secrets/{path: .*}\") public Response createSecret(@PathParam(\"path\") String path, String secret) { CreateKv&lt;2&gt;Response response = secrets.create(path, Map.of(\"secret\", secret)); return Response.ok() .entity(\"Created secret on path: \" + path + \", key is \\\"secret\\\", original status: \" + response.status().code()) .build(); } @DELETE @Path(\"/secrets/{path: .*}\") public Response deleteSecret(@PathParam(\"path\") String path) { DeleteAllKv&lt;2&gt;Response response = secrets.deleteAll(path); return Response.ok() .entity(\"Deleted secret on path: \" + path + \". Original status: \" + response.status().code()) .build(); } @GET @Path(\"/secrets/{path: .*}\") public Response getSecret(@PathParam(\"path\") String path) { Optional&lt;Kv2Secret&gt; secret = secrets.get(path); if (secret.isPresent()) { Kv2Secret kv2Secret = secret.get(); return Response.ok() .entity(\"Version \" + kv2Secret.metadata().version() + \", secret: \" + kv2Secret.values().toString()) .build(); } else { return Response.status(Response.Status.NOT_FOUND).build(); } } } Create a secret from request entity, the name of the value is secret . Delete the secret on a specified path. Get the secret on a specified path. ",
            "title": "KV2 secrets"
        },
        {
            "location": "/mp/vault/01_vault",
            "text": " Transit secrets engine operations: <markup lang=\"java\" >@Path(\"/transit\") public class TransitResource { private static final String ENCRYPTION_KEY = \"encryption-key\"; private static final String SIGNATURE_KEY = \"signature-key\"; private final Sys sys; private final TransitSecrets secrets; @Inject TransitResource(Sys sys, TransitSecrets secrets) { this.sys = sys; this.secrets = secrets; } @Path(\"/engine\") @GET public Response enableEngine() { EnableEngine.Response response = sys.enableEngine(TransitSecretsRx.ENGINE); return Response.ok() .entity(\"Transit secret engine is now enabled. Original status: \" + response.status().code()) .build(); } @Path(\"/engine\") @DELETE public Response disableEngine() { DisableEngine.Response response = sys.disableEngine(TransitSecretsRx.ENGINE); return Response.ok() .entity(\"Transit secret engine is now disabled. Original status: \" + response.status()) .build(); } @Path(\"/keys\") @GET public Response createKeys() { secrets.createKey(CreateKey.Request.builder() .name(ENCRYPTION_KEY)); secrets.createKey(CreateKey.Request.builder() .name(SIGNATURE_KEY) .type(\"rsa-2048\")); return Response.ok() .entity(\"Created encryption (and HMAC), and signature keys\") .build(); } @Path(\"/keys\") @DELETE public Response deleteKeys() { // we must first enable deletion of the key (by default it cannot be deleted) secrets.updateKeyConfig(UpdateKeyConfig.Request.builder() .name(ENCRYPTION_KEY) .allowDeletion(true)); secrets.updateKeyConfig(UpdateKeyConfig.Request.builder() .name(SIGNATURE_KEY) .allowDeletion(true)); secrets.deleteKey(DeleteKey.Request.create(ENCRYPTION_KEY)); secrets.deleteKey(DeleteKey.Request.create(SIGNATURE_KEY)); return Response.ok() .entity(\"Deleted encryption (and HMAC), and signature keys\") .build(); } @Path(\"/encrypt/{secret: .*}\") @GET public String encryptSecret(@PathParam(\"secret\") String secret) { return secrets.encrypt(Encrypt.Request.builder() .encryptionKeyName(ENCRYPTION_KEY) .data(Base64Value.create(secret))) .encrypted() .cipherText(); } @Path(\"/decrypt/{cipherText: .*}\") @GET public String decryptSecret(@PathParam(\"cipherText\") String cipherText) { return secrets.decrypt(Decrypt.Request.builder() .encryptionKeyName(ENCRYPTION_KEY) .cipherText(cipherText)) .decrypted() .toDecodedString(); } @Path(\"/hmac/{text}\") @GET public String hmac(@PathParam(\"text\") String text) { return secrets.hmac(Hmac.Request.builder() .hmacKeyName(ENCRYPTION_KEY) .data(Base64Value.create(text))) .hmac(); } @Path(\"/sign/{text}\") @GET public String sign(@PathParam(\"text\") String text) { return secrets.sign(Sign.Request.builder() .signatureKeyName(SIGNATURE_KEY) .data(Base64Value.create(text))) .signature(); } @Path(\"/verify/hmac/{secret}/{hmac: .*}\") @GET public String verifyHmac(@PathParam(\"secret\") String secret, @PathParam(\"hmac\") String hmac) { boolean isValid = secrets.verify(Verify.Request.builder() .digestKeyName(ENCRYPTION_KEY) .data(Base64Value.create(secret)) .hmac(hmac)) .isValid(); return (isValid ? \"HMAC Valid\" : \"HMAC Invalid\"); } @Path(\"/verify/sign/{secret}/{signature: .*}\") @GET public String verifySignature(@PathParam(\"secret\") String secret, @PathParam(\"signature\") String signature) { boolean isValid = secrets.verify(Verify.Request.builder() .digestKeyName(SIGNATURE_KEY) .data(Base64Value.create(secret)) .signature(signature)) .isValid(); return (isValid ? \"Signature Valid\" : \"Signature Invalid\"); } } Enable the secrets engine on the default path. Disable the secrets engine on the default path. Create the encrypting and signature keys. Delete the encryption and signature keys. Encrypt a secret. Decrypt a secret. Create an HMAC for text. Create a signature for text. Verify HMAC. Verify signature. ",
            "title": "Transit secrets"
        },
        {
            "location": "/mp/vault/01_vault",
            "text": " The following example shows usage of Vault to encrypt a secret using the default Vault configuration (in a JAX-RS resource): <markup lang=\"java\" >private final TransitSecrets secrets; @Inject TransitResource(TransitSecrets secrets) { this.secrets = secrets; } //... @Path(\"/encrypt/{secret: .*}\") @GET public String encrypt(@PathParam(\"secret\") String secret) { return secrets.encrypt(Encrypt.Request.builder() .encryptionKeyName(ENCRYPTION_KEY) .data(Base64Value.create(secret))) .encrypted() .cipherText(); } Cubbyhole secrets Cubbyhole example: <markup lang=\"java\" >@Path(\"/cubbyhole\") public class CubbyholeResource { private final CubbyholeSecrets secrets; @Inject CubbyholeResource(CubbyholeSecrets secrets) { this.secrets = secrets; } @POST @Path(\"/secrets/{path: .*}\") public Response createSecret(@PathParam(\"path\") String path, String secret) { CreateCubbyhole.Response response = secrets.create(path, Map.of(\"secret\", secret)); return Response.ok() .entity(\"Created secret on path: \" + path + \", key is \\\"secret\\\", original status: \" + response.status().code()) .build(); } @DELETE @Path(\"/secrets/{path: .*}\") public Response deleteSecret(@PathParam(\"path\") String path) { DeleteCubbyhole.Response response = secrets.delete(path); return Response.ok() .entity(\"Deleted secret on path: \" + path + \". Original status: \" + response.status().code()) .build(); } @GET @Path(\"/secrets/{path: .*}\") public Response getSecret(@PathParam(\"path\") String path) { Optional&lt;Secret&gt; secret = secrets.get(path); if (secret.isPresent()) { Secret kv1Secret = secret.get(); return Response.ok() .entity(\"Secret: \" + secret.get().values().toString()) .build(); } else { return Response.status(Response.Status.NOT_FOUND).build(); } } } Create a secret from request entity, the name of the value is {@code secret}. Delete the secret on a specified path. Get the secret on a specified path. KV1 secrets Key/Value version 1 secrets engine operations: <markup lang=\"java\" >@Path(\"/kv1\") public class Kv1Resource { private final Sys sys; private final Kv1Secrets secrets; @Inject Kv1Resource(Sys sys, Kv1Secrets secrets) { this.sys = sys; this.secrets = secrets; } @Path(\"/engine\") @GET public Response enableEngine() { EnableEngine.Response response = sys.enableEngine(Kv1SecretsRx.ENGINE); return Response.ok() .entity(\"Key/value version 1 secret engine is now enabled. Original status: \" + response.status().code()) .build(); } @Path(\"/engine\") @DELETE public Response disableEngine() { DisableEngine.Response response = sys.disableEngine(Kv1SecretsRx.ENGINE); return Response.ok() .entity(\"Key/value version 1 secret engine is now disabled. Original status: \" + response.status().code()) .build(); } @POST @Path(\"/secrets/{path: .*}\") public Response createSecret(@PathParam(\"path\") String path, String secret) { CreateKv&lt;1&gt;Response response = secrets.create(path, Map.of(\"secret\", secret)); return Response.ok() .entity(\"Created secret on path: \" + path + \", key is \\\"secret\\\", original status: \" + response.status().code()) .build(); } @DELETE @Path(\"/secrets/{path: .*}\") public Response deleteSecret(@PathParam(\"path\") String path) { DeleteKv&lt;1&gt;Response response = secrets.delete(path); return Response.ok() .entity(\"Deleted secret on path: \" + path + \". Original status: \" + response.status().code()) .build(); } @GET @Path(\"/secrets/{path: .*}\") public Response getSecret(@PathParam(\"path\") String path) { Optional&lt;Secret&gt; secret = secrets.get(path); if (secret.isPresent()) { Secret kv1Secret = secret.get(); return Response.ok() .entity(\"Secret: \" + secret.get().values().toString()) .build(); } else { return Response.status(Response.Status.NOT_FOUND).build(); } } } Enable the secrets engine on the default path. Disable the secrets engine on the default path. Create a secret from request entity, the name of the value is secret . Delete the secret on a specified path. Get the secret on a specified path. KV2 secrets Key/Value version 2 secrets engine operations: <markup lang=\"java\" >@Path(\"/kv2\") public class Kv2Resource { private final Kv2Secrets secrets; @Inject Kv2Resource(@VaultName(\"app-role\") @VaultPath(\"custom\") Kv2Secrets secrets) { this.secrets = secrets; } @POST @Path(\"/secrets/{path: .*}\") public Response createSecret(@PathParam(\"path\") String path, String secret) { CreateKv&lt;2&gt;Response response = secrets.create(path, Map.of(\"secret\", secret)); return Response.ok() .entity(\"Created secret on path: \" + path + \", key is \\\"secret\\\", original status: \" + response.status().code()) .build(); } @DELETE @Path(\"/secrets/{path: .*}\") public Response deleteSecret(@PathParam(\"path\") String path) { DeleteAllKv&lt;2&gt;Response response = secrets.deleteAll(path); return Response.ok() .entity(\"Deleted secret on path: \" + path + \". Original status: \" + response.status().code()) .build(); } @GET @Path(\"/secrets/{path: .*}\") public Response getSecret(@PathParam(\"path\") String path) { Optional&lt;Kv2Secret&gt; secret = secrets.get(path); if (secret.isPresent()) { Kv2Secret kv2Secret = secret.get(); return Response.ok() .entity(\"Version \" + kv2Secret.metadata().version() + \", secret: \" + kv2Secret.values().toString()) .build(); } else { return Response.status(Response.Status.NOT_FOUND).build(); } } } Create a secret from request entity, the name of the value is secret . Delete the secret on a specified path. Get the secret on a specified path. Transit secrets Transit secrets engine operations: <markup lang=\"java\" >@Path(\"/transit\") public class TransitResource { private static final String ENCRYPTION_KEY = \"encryption-key\"; private static final String SIGNATURE_KEY = \"signature-key\"; private final Sys sys; private final TransitSecrets secrets; @Inject TransitResource(Sys sys, TransitSecrets secrets) { this.sys = sys; this.secrets = secrets; } @Path(\"/engine\") @GET public Response enableEngine() { EnableEngine.Response response = sys.enableEngine(TransitSecretsRx.ENGINE); return Response.ok() .entity(\"Transit secret engine is now enabled. Original status: \" + response.status().code()) .build(); } @Path(\"/engine\") @DELETE public Response disableEngine() { DisableEngine.Response response = sys.disableEngine(TransitSecretsRx.ENGINE); return Response.ok() .entity(\"Transit secret engine is now disabled. Original status: \" + response.status()) .build(); } @Path(\"/keys\") @GET public Response createKeys() { secrets.createKey(CreateKey.Request.builder() .name(ENCRYPTION_KEY)); secrets.createKey(CreateKey.Request.builder() .name(SIGNATURE_KEY) .type(\"rsa-2048\")); return Response.ok() .entity(\"Created encryption (and HMAC), and signature keys\") .build(); } @Path(\"/keys\") @DELETE public Response deleteKeys() { // we must first enable deletion of the key (by default it cannot be deleted) secrets.updateKeyConfig(UpdateKeyConfig.Request.builder() .name(ENCRYPTION_KEY) .allowDeletion(true)); secrets.updateKeyConfig(UpdateKeyConfig.Request.builder() .name(SIGNATURE_KEY) .allowDeletion(true)); secrets.deleteKey(DeleteKey.Request.create(ENCRYPTION_KEY)); secrets.deleteKey(DeleteKey.Request.create(SIGNATURE_KEY)); return Response.ok() .entity(\"Deleted encryption (and HMAC), and signature keys\") .build(); } @Path(\"/encrypt/{secret: .*}\") @GET public String encryptSecret(@PathParam(\"secret\") String secret) { return secrets.encrypt(Encrypt.Request.builder() .encryptionKeyName(ENCRYPTION_KEY) .data(Base64Value.create(secret))) .encrypted() .cipherText(); } @Path(\"/decrypt/{cipherText: .*}\") @GET public String decryptSecret(@PathParam(\"cipherText\") String cipherText) { return secrets.decrypt(Decrypt.Request.builder() .encryptionKeyName(ENCRYPTION_KEY) .cipherText(cipherText)) .decrypted() .toDecodedString(); } @Path(\"/hmac/{text}\") @GET public String hmac(@PathParam(\"text\") String text) { return secrets.hmac(Hmac.Request.builder() .hmacKeyName(ENCRYPTION_KEY) .data(Base64Value.create(text))) .hmac(); } @Path(\"/sign/{text}\") @GET public String sign(@PathParam(\"text\") String text) { return secrets.sign(Sign.Request.builder() .signatureKeyName(SIGNATURE_KEY) .data(Base64Value.create(text))) .signature(); } @Path(\"/verify/hmac/{secret}/{hmac: .*}\") @GET public String verifyHmac(@PathParam(\"secret\") String secret, @PathParam(\"hmac\") String hmac) { boolean isValid = secrets.verify(Verify.Request.builder() .digestKeyName(ENCRYPTION_KEY) .data(Base64Value.create(secret)) .hmac(hmac)) .isValid(); return (isValid ? \"HMAC Valid\" : \"HMAC Invalid\"); } @Path(\"/verify/sign/{secret}/{signature: .*}\") @GET public String verifySignature(@PathParam(\"secret\") String secret, @PathParam(\"signature\") String signature) { boolean isValid = secrets.verify(Verify.Request.builder() .digestKeyName(SIGNATURE_KEY) .data(Base64Value.create(secret)) .signature(signature)) .isValid(); return (isValid ? \"Signature Valid\" : \"Signature Invalid\"); } } Enable the secrets engine on the default path. Disable the secrets engine on the default path. Create the encrypting and signature keys. Delete the encryption and signature keys. Encrypt a secret. Decrypt a secret. Create an HMAC for text. Create a signature for text. Verify HMAC. Verify signature. ",
            "title": "Usage"
        },
        {
            "location": "/mp/vault/01_vault",
            "text": " Vault is available as a docker image, so to test locally, you can simply: <markup lang=\"bash\" >docker run -e VAULT_DEV_ROOT_TOKEN_ID=my-token -d --name=vault -p8200:8200 vault This will create a Vault docker image, run it in background and open it on localhost:8200 with a custom root token my-token, using name vault. This is of course only suitable for local testing, as the root token has too many rights, but it can be easily used with the examples below. ",
            "title": "Local testing"
        },
        {
            "location": "/se/reactivestreams/02_engine",
            "text": " To enable Reactive Engine add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.common&lt;/groupId&gt; &lt;artifactId&gt;helidon-common-reactive&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/reactivestreams/02_engine",
            "text": " In the situations when part of the operator chain needs to be prepared in advance, compose and to operators are at hand. <markup lang=\"java\" title=\"Combining operator chains:\" > // Assembly of stream, nothing is streamed yet Multi&lt;String&gt; publisherStage = Multi.just(\"foo\", \"bar\") .map(String::trim); Function&lt;Multi&lt;T&gt;, Multi&lt;T&gt;&gt; processorStage = upstream -&gt; upstream.map(String::toUpperCase); // Execution of pre-prepared stream publisherStage .compose(processorStage) .map(s -&gt; \"Item received: \" + s) .forEach(System.out::println); &gt; Item received: FOO &gt; Item received: BAR ",
            "title": "Operator chains composition"
        },
        {
            "location": "/se/reactivestreams/02_engine",
            "text": " Helidon has its own set of reactive operators that have no dependencies outside of the Helidon ecosystem. These operators can be used with java.util.concurrent.Flow based reactive streams. Stream processing operator chain can be easily constructed by io.helidon.common.reactive.Multi , or io.helidon.common.reactive.Single for streams with single value. <markup lang=\"java\" title=\"Example of Multi usage:\" >AtomicInteger sum = new AtomicInteger(); Multi.just(\"1\", \"2\", \"3\", \"4\", \"5\") .limit(3) .map(Integer::parseInt) .forEach(sum::addAndGet); System.out.println(\"Sum: \" + sum.get()); &gt; Sum: 6 <markup lang=\"java\" title=\"Example of Single usage:\" >Single.just(\"1\") .map(Integer::parseInt) .map(i -&gt; i + 5) .toStage() .whenComplete((i, t) -&gt; System.out.println(\"Result: \" + i)); &gt; Result: 6 Operators defer Call the given supplier function for each individual downstream Subscriber to return a Flow.Publisher to subscribe to. map Map this Multi instance to a new Multi of another type using the given Mapper . defaultIfEmpty Signals the default item if the upstream is empty. switchIfEmpty Switch to the other publisher if the upstream is empty. peek Invoke provided consumer for every item in stream. distinct Filter out all duplicates. filter Filter stream items with provided predicate. takeWhile Take the longest prefix of elements from this stream that satisfy the given predicate. As long as predicate returns true, items from upstream are sent to downstream, when predicate returns false stream is completed. dropWhile Drop the longest prefix of elements from this stream that satisfy the given predicate. As long as predicate returns true, items from upstream are NOT sent to downstream but being dropped, predicate is never called again after it returns false for the first time. limit Limit stream to allow only specified number of items to pass. skip Skip first n items, all the others are emitted. flatMap Transform each upstream item with the supplied function into a Flow.Publisher , subscribe to them and then flatten their items into a single sequence of items emitted to the downstream. flatMap Transform each upstream item with the supplied function and flatten the resulting Flow.Publisher to downstream while limiting the maximum number of concurrent inner `Flow.Publisher`s and their in-flight item count, optionally aggregating and delaying all errors until all sources terminate. flatMapCompletionStage Transform each upstream item with the supplied function and flatten the resulting CompletionStage results to downstream. flatMapIterable Transform each upstream item with the supplied function and flatten the resulting Iterable to the downstream. flatMapOptional Transform each upstream item with the supplied function and flatten the resulting Optional to the downstream as item if present. observeOn Re-emit the upstream&#8217;s signals to the downstream on the given executor&#8217;s thread using a default buffer size of 32 and errors skipping ahead of items. observeOn Re-emit the upstream&#8217;s signals to the downstream on the given executor&#8217;s thread. forEach Terminal stage, invokes provided consumer for every item in the stream. collectList Collect the items of this Multi instance into a Single of List . collect Collect the items of this Multi instance into a Single . collect Collect the items of this Multi into a collection provided via a Supplier and mutated by a BiConsumer callback. collectStream Collects up upstream items with the help of the callbacks of a java.util.stream.Collector . reduce Combine subsequent items via a callback function and emit the final value result as a Single. reduce Combine every upstream item with an accumulator value to produce a new accumulator value and emit the final accumulator value as a Single. first Get the first item of this Multi instance as a Single . from Wrap a CompletionStage into a Multi and signal its outcome non-blockingly. from Wrap a CompletionStage into a Multi and signal its outcome non-blockingly. from Create a Multi instance wrapped around the given publisher. from Create a Multi instance that publishes the given iterable. from Create a Multi instance that publishes the given Stream . just Create a Multi instance that publishes the given items to a single subscriber. just Create a Multi instance that publishes the given items to a single subscriber. singleton Create a Multi that emits a pre-existing item and then completes. error Create a Multi instance that reports the given exception to its subscriber(s). The exception is reported by invoking Subscriber#onError(java.lang.Throwable) when Publisher#subscribe(Subscriber) is called. empty Get a Multi instance that completes immediately. never Get a Multi instance that never completes. concat Concat streams to one. onTerminate Executes given java.lang.Runnable when any of signals onComplete, onCancel or onError is received. ifEmpty Executes given java.lang.Runnable when stream is finished without value(empty stream). onComplete Executes given java.lang.Runnable when onComplete signal is received. onError Executes the given java.util.function.Consumer when an onError signal is received. onCancel Executes given java.lang.Runnable when a cancel signal is received. takeUntil Relay upstream items until the other source signals an item or completes. range Emits a range of ever increasing integers. rangeLong Emits a range of ever increasing longs. timer Signal 0L and complete the sequence after the given time elapsed. interval Signal 0L, 1L and so on periodically to the downstream. interval Signal 0L after an initial delay, then 1L, 2L and so on periodically to the downstream. timeout Signals a TimeoutException if the upstream doesn&#8217;t signal the next item, error or completion within the specified time. timeout Switches to a fallback source if the upstream doesn&#8217;t signal the next item, error or completion within the specified time. onErrorResume java.util.function.Function providing one item to be submitted as onNext in case of onError signal is received. onErrorResumeWith Resume stream from supplied publisher if onError signal is intercepted. retry Retry a failing upstream at most the given number of times before giving up. retry Retry a failing upstream if the predicate returns true. retryWhen Retry a failing upstream when the given function returns a publisher that signals an item. Operator chains composition In the situations when part of the operator chain needs to be prepared in advance, compose and to operators are at hand. <markup lang=\"java\" title=\"Combining operator chains:\" > // Assembly of stream, nothing is streamed yet Multi&lt;String&gt; publisherStage = Multi.just(\"foo\", \"bar\") .map(String::trim); Function&lt;Multi&lt;T&gt;, Multi&lt;T&gt;&gt; processorStage = upstream -&gt; upstream.map(String::toUpperCase); // Execution of pre-prepared stream publisherStage .compose(processorStage) .map(s -&gt; \"Item received: \" + s) .forEach(System.out::println); &gt; Item received: FOO &gt; Item received: BAR ",
            "title": "Reactive Engine"
        },
        {
            "location": "/mp/guides/02_quickstart",
            "text": " This guide describes a basic example of an Helidon MP application using Docker and Kubernetes. ",
            "title": "preambule"
        },
        {
            "location": "/mp/guides/02_quickstart",
            "text": " For this 5 minute tutorial, you will need the following: <div class=\"table__overflow elevation-1 flex sm7 \"> A Helidon {upper-case-flavor} Application You can use your own application or use the Helidon {upper-case-flavor} Quickstart to create a sample application. Java&#160;SE&#160;11 ( Open&#160;JDK&#160;11 ) Helidon requires Java 11+. Maven 3.6.1+ Helidon requires Maven 3.6.1+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop ). <markup lang=\"bash\" title=\"Verify Prerequisites\" >java -version mvn --version docker --version kubectl version --short <markup lang=\"bash\" title=\"Setting JAVA_HOME\" ># On Mac export JAVA_HOME=`/usr/libexec/java_home -v 11` # On Linux # Use the appropriate path to your JDK export JAVA_HOME=/usr/lib/jvm/jdk-11 ",
            "title": "What You Need"
        },
        {
            "location": "/mp/guides/02_quickstart",
            "text": " Generate the project sources using one (or both) of the Helidon Maven archetypes. The result is a simple project that shows the basics of configuring the WebServer and implementing basic routing rules. <markup lang=\"bash\" title=\"Run the Maven archetype\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-mp \\ -DarchetypeVersion=2.5.4 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-mp \\ -Dpackage=io.helidon.examples.quickstart.mp The archetype generates a Maven project in your current directory (for example, helidon-quickstart-mp ). Change into this directory. <markup lang=\"bash\" >cd helidon-quickstart-mp If you want to use the generated project as a starter for your own application, then you can replace groupId, artifactId and package with values appropriate for your application. <markup lang=\"bash\" title=\"Build the Application\" >mvn package The project builds an application jar for the example and saves all runtime dependencies in the target/libs directory. This means you can easily start the application by running the application jar file: <markup lang=\"bash\" title=\"Run the application\" >java -jar target/helidon-quickstart-mp.jar The example is a very simple \"Hello World\" greeting service. It supports GET requests for generating a greeting message, and a PUT request for changing the greeting itself. The response is encoded using JSON. For example: <markup lang=\"bash\" title=\"Try the Application\" >curl -X GET http://localhost:8080/greet {\"message\":\"Hello World!\"} curl -X GET http://localhost:8080/greet/Joe {\"message\":\"Hello Joe!\"} curl -X PUT -H \"Content-Type: application/json\" -d '{\"greeting\" : \"Hola\"}' http://localhost:8080/greet/greeting curl -X GET http://localhost:8080/greet/Jose {\"message\":\"Hola Jose!\"} ",
            "title": "Generate the Project"
        },
        {
            "location": "/mp/guides/02_quickstart",
            "text": " Helidon provides built-in support for health and metrics endpoints. <markup lang=\"bash\" title=\"Health\" >curl -s -X GET http://localhost:8080/health <markup lang=\"bash\" title=\"Metrics in Prometheus Format\" >curl -s -X GET http://localhost:8080/metrics <markup lang=\"bash\" title=\"Metrics in JSON Format\" >curl -H 'Accept: application/json' -X GET http://localhost:8080/metrics ",
            "title": "Health and Metrics"
        },
        {
            "location": "/mp/guides/02_quickstart",
            "text": " The project also contains a Dockerfile so that you can easily build and run a Docker image. To build the Docker image, you need to have Docker installed and running on your system. <markup lang=\"bash\" title=\"Docker build\" >docker build -t helidon-quickstart-mp . <markup lang=\"bash\" title=\"Run Docker Image\" >docker run --rm -p 8080:8080 helidon-quickstart-mp:latest Then you can try the application as you did before. ",
            "title": "Build a Docker Image"
        },
        {
            "location": "/mp/guides/02_quickstart",
            "text": " If you don&#8217;t have access to a Kubernetes cluster, you can install one on your desktop . Then deploy the example: <markup lang=\"bash\" title=\"Verify connectivity to cluster\" >kubectl cluster-info kubectl get nodes <markup lang=\"bash\" title=\"Deploy the application to Kubernetes\" >kubectl create -f app.yaml kubectl get pods # Wait for quickstart pod to be RUNNING The step above created a service that is exposed into any node port. Lookup the service to find the port. <markup lang=\"bash\" title=\"Lookup the service\" >kubectl get service helidon-quickstart-mp Note the PORTs. You can now exercise the application as you did before but use the second port number (the NodePort) instead of 8080. For example: <markup lang=\"bash\" >curl -X GET http://localhost:31431/greet After you&#8217;re done, cleanup. <markup lang=\"bash\" title=\"Remove the application from Kubernetes\" >kubectl delete -f app.yaml ",
            "title": "Deploy the Application to Kubernetes"
        },
        {
            "location": "/mp/guides/02_quickstart",
            "text": " Helidon also includes support for GraalVM Native Images and Java Custom Runtime Images. For more information see: GraalVM Native Images Custom Runtime Images using jlink ",
            "title": "Building Native and Custom Runtime Images"
        },
        {
            "location": "/mp/guides/02_quickstart",
            "text": " With the Helidon CLI you can create additional types of Helidon applications and use the \"dev loop\" to do fast, iterative development. Try it now . ",
            "title": "The Helidon CLI"
        },
        {
            "location": "/se/metrics/02_micrometer",
            "text": " Helidon SE simplifies how you can use Micrometer for application-specific metrics: The endpoint /micrometer : A configurable endpoint that exposes metrics according to which Micrometer meter registry responds to the HTTP request. The MicrometerSupport class: A convenience class for enrolling Micrometer meter registries your application creates explicitly or for selecting which built-in Micrometer meter registries to use. Configuration to tailor the Prometheus and other Micrometer meter registries. In Helidon 2.5.4, Micrometer support is separate from the Helidon SE metrics API and the built-in Helidon metrics. ",
            "title": "preambule"
        },
        {
            "location": "/se/metrics/02_micrometer",
            "text": " Declare the following dependency in your project: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.micrometer&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-micrometer&lt;/artifactId&gt; &lt;/dependency&gt; Micrometer supports different types of meter registries which have different output styles and formats. Helidon provides built-in support for the Prometheus meter registry. To use other meter registry types, you will need to add dependencies for them to your pom.xml and, optionally, add code to your application or add configuration to set them up as you wish. ",
            "title": "Prerequisites"
        },
        {
            "location": "/se/metrics/02_micrometer",
            "text": "<markup lang=\"java\" title=\"Initialize Micrometer support\" >import io.helidon.integrations.micrometer.MicrometerSupport; //... MicrometerSupport micrometerSupport = MicrometerSupport.create(); Routing.builder() .register(micrometerSupport) .register(\"/myapp\", new MyService(micrometerSupport.registry())) .build(); Create the MicrometerSupport instance, using the default built-in Prometheus meter registry. Register the support instance as a service; by default, MicrometerSupport exposes the endpoint as /micrometer . Pass the MicrometerSupport object&#8217;s meter registry to your service for use in creating and updating meters. ",
            "title": "Register an Instance of MicrometerSupport with the Web Server"
        },
        {
            "location": "/se/metrics/02_micrometer",
            "text": "<markup lang=\"java\" title=\"Define and use a Counter \" >import io.micrometer.core.instrument.Counter; public class MyService implements Service { private final Counter requestCounter; public MyService(MicrometerMeterRegistry registry) { requestCounter = registry.counter(\"allRequests\"); // ... } @Override public void update(Routing.Rules rules) { rules .any(this::countRequests) .get(\"/\", this::myGet); } private void countRequests(ServerRequest request, ServerResponse response) { requestCounter.increment(); request.next(); } } Use the Micrometer meter registry to create the request counter. Add routing for any request to invoke the method which counts requests by updating the counter. Update the counter and delegate the rest of the request processing to the next handler in the chain. The example above enrolls the built-in Prometheus meter registry with the default Prometheus registry configuration. You can change the default setup for built-in registries, and you can enroll other meter registries your application creates itself. ",
            "title": "Create and Update Meters in your Application Service"
        },
        {
            "location": "/se/metrics/02_micrometer",
            "text": " Use the MicrometerSupport.Builder class to set up Micrometer support however your application needs. The builder lets you: Provide your own Micrometer meter registry configuration that MicrometerSupport uses to create a built-in meter registry, or Instantiate a Micrometer meter registry yourself, configured however you want, and add it to the MicrometerSupport object&#8217;s collection of meter registries <markup lang=\"java\" title=\"Overriding defaults for built-in meter registries using MicrometerSupport.Builder \" >PrometheusConfig myPrometheusConfig = ...; MicrometerSupport support = MicrometerSupport.builder() .enrollBuiltInRegistry( MicrometerSupport.BuiltInRegistryType.PROMETHEUS, myPrometheusConfig) .build(); Create the meter registry configuration however you need. Enroll the PROMETHEUS built-in registry type with your custom configuration. ",
            "title": "Using MicrometerSupport.Builder "
        },
        {
            "location": "/se/metrics/02_micrometer",
            "text": " To use configuration to control the selection and behavior of Helidon&#8217;s built-in Micrometer meter registries, include in your configuration (such as application.yaml ) a micrometer.builtin-registries section. <markup lang=\"yaml\" title=\"Enroll Prometheus built-in meter registry using default configuration\" >micrometer: builtin-registries: - type: prometheus <markup lang=\"yaml\" title=\"Enroll Prometheus built-in meter registry with non-default configuration\" >micrometer: builtin-registries: - type: prometheus prefix: myPrefix Note that the first config example is equivalent to the default Helidon Micrometer behavior; Helidon by default supports the Prometheus meter registry. The configuration keys that are valid for the builtin-registries child entries depend on the type of Micrometer meter registry. For example, the Prometheus meter registry supports the prefix configuration setting but other meter registries might not and might support other settings. Refer to the documentation for the meter registry you want to configure to find out what items apply to that registry type. Helidon does not validate the configuration keys you specify for meter registries. ",
            "title": "Using Configuration"
        },
        {
            "location": "/se/metrics/02_micrometer",
            "text": " Unless you specify otherwise, Helidon uses defaults for any built-in Micrometer meter registry. For example, Helidon configures the built-in Prometheus registry using PrometheusConfig.DEFAULT . You can override these defaults in either of two ways: Using the MicrometerSupport.Builder class Using configuration Using MicrometerSupport.Builder Use the MicrometerSupport.Builder class to set up Micrometer support however your application needs. The builder lets you: Provide your own Micrometer meter registry configuration that MicrometerSupport uses to create a built-in meter registry, or Instantiate a Micrometer meter registry yourself, configured however you want, and add it to the MicrometerSupport object&#8217;s collection of meter registries <markup lang=\"java\" title=\"Overriding defaults for built-in meter registries using MicrometerSupport.Builder \" >PrometheusConfig myPrometheusConfig = ...; MicrometerSupport support = MicrometerSupport.builder() .enrollBuiltInRegistry( MicrometerSupport.BuiltInRegistryType.PROMETHEUS, myPrometheusConfig) .build(); Create the meter registry configuration however you need. Enroll the PROMETHEUS built-in registry type with your custom configuration. Using Configuration To use configuration to control the selection and behavior of Helidon&#8217;s built-in Micrometer meter registries, include in your configuration (such as application.yaml ) a micrometer.builtin-registries section. <markup lang=\"yaml\" title=\"Enroll Prometheus built-in meter registry using default configuration\" >micrometer: builtin-registries: - type: prometheus <markup lang=\"yaml\" title=\"Enroll Prometheus built-in meter registry with non-default configuration\" >micrometer: builtin-registries: - type: prometheus prefix: myPrefix Note that the first config example is equivalent to the default Helidon Micrometer behavior; Helidon by default supports the Prometheus meter registry. The configuration keys that are valid for the builtin-registries child entries depend on the type of Micrometer meter registry. For example, the Prometheus meter registry supports the prefix configuration setting but other meter registries might not and might support other settings. Refer to the documentation for the meter registry you want to configure to find out what items apply to that registry type. Helidon does not validate the configuration keys you specify for meter registries. ",
            "title": "Overriding Defaults for Built-in Meter Registry Types"
        },
        {
            "location": "/se/metrics/02_micrometer",
            "text": " To create additional types of registries and enroll them with MicrometerSupport , you need to: Write a Handler Each meter registry has its own way of producing output. Write your handler so that it has a reference to the meter registry it should use and so that its accept method sets the payload in the HTTP response using the registry&#8217;s mechanism for creating output. Write a Function which accepts a ServerRequest and returns an Optional&lt;Handler&gt; In general, your function looks at the request&#8212;&#8203;the Content-Type , query parameters, etc.--to decide whether your handler should respond to the request. If so, your function should instantiate your Handler and return an Optional.of(theHandlerInstance) ; otherwise, your function should return Optional.empty() . When MicrometerSupport receives a request, it invokes the functions of all the enrolled registries, stopping as soon as one function provides a handler. MicrometerSupport then delegates to that handler to create and send the response. Pass the Handler and Function to the MicrometerSupport.enrollRegistry method to enroll them <markup lang=\"java\" title=\"Creating and enrolling your own Micrometer meter registry\" >MeterRegistry myRegistry = new PrometheusMeterRegistry(myPrometheusConfig); MicrometerSupport support = MicrometerSupport.builder() .enrollRegistry(myRegistry, request -&gt; request .headers() .bestAccepted(MediaType.TEXT_PLAIN).isPresent() ? Optional.of((req, resp) -&gt; resp.send(myRegistry.scrape())) : Optional.empty()) .build(); Create the meter registry. This example uses a Prometheus registry but it can be any extension of MeterRegistry . Provide the function that checks if the ServerRequest accepts content that your meter registry can produce (e.g., either text/plain or unspecified is normally an indication for Prometheus-style output) and returns the appropriate Optional&lt; Handler &gt; . A very simple in-line Handler that sets the response entity from the Prometheus registry&#8217;s scrape() method. ",
            "title": "Enrolling other Micrometer meter registries"
        },
        {
            "location": "/se/metrics/02_micrometer",
            "text": " You need to make two types of changes to your application to use Helidon SE integration with Micrometer: Register an instance of MicrometerSupport with the web server. Create meters using the meter registry which MicrometerSupport manages and update those meters. Register an Instance of MicrometerSupport with the Web Server <markup lang=\"java\" title=\"Initialize Micrometer support\" >import io.helidon.integrations.micrometer.MicrometerSupport; //... MicrometerSupport micrometerSupport = MicrometerSupport.create(); Routing.builder() .register(micrometerSupport) .register(\"/myapp\", new MyService(micrometerSupport.registry())) .build(); Create the MicrometerSupport instance, using the default built-in Prometheus meter registry. Register the support instance as a service; by default, MicrometerSupport exposes the endpoint as /micrometer . Pass the MicrometerSupport object&#8217;s meter registry to your service for use in creating and updating meters. Create and Update Meters in your Application Service <markup lang=\"java\" title=\"Define and use a Counter \" >import io.micrometer.core.instrument.Counter; public class MyService implements Service { private final Counter requestCounter; public MyService(MicrometerMeterRegistry registry) { requestCounter = registry.counter(\"allRequests\"); // ... } @Override public void update(Routing.Rules rules) { rules .any(this::countRequests) .get(\"/\", this::myGet); } private void countRequests(ServerRequest request, ServerResponse response) { requestCounter.increment(); request.next(); } } Use the Micrometer meter registry to create the request counter. Add routing for any request to invoke the method which counts requests by updating the counter. Update the counter and delegate the rest of the request processing to the next handler in the chain. The example above enrolls the built-in Prometheus meter registry with the default Prometheus registry configuration. You can change the default setup for built-in registries, and you can enroll other meter registries your application creates itself. Overriding Defaults for Built-in Meter Registry Types Unless you specify otherwise, Helidon uses defaults for any built-in Micrometer meter registry. For example, Helidon configures the built-in Prometheus registry using PrometheusConfig.DEFAULT . You can override these defaults in either of two ways: Using the MicrometerSupport.Builder class Using configuration Using MicrometerSupport.Builder Use the MicrometerSupport.Builder class to set up Micrometer support however your application needs. The builder lets you: Provide your own Micrometer meter registry configuration that MicrometerSupport uses to create a built-in meter registry, or Instantiate a Micrometer meter registry yourself, configured however you want, and add it to the MicrometerSupport object&#8217;s collection of meter registries <markup lang=\"java\" title=\"Overriding defaults for built-in meter registries using MicrometerSupport.Builder \" >PrometheusConfig myPrometheusConfig = ...; MicrometerSupport support = MicrometerSupport.builder() .enrollBuiltInRegistry( MicrometerSupport.BuiltInRegistryType.PROMETHEUS, myPrometheusConfig) .build(); Create the meter registry configuration however you need. Enroll the PROMETHEUS built-in registry type with your custom configuration. Using Configuration To use configuration to control the selection and behavior of Helidon&#8217;s built-in Micrometer meter registries, include in your configuration (such as application.yaml ) a micrometer.builtin-registries section. <markup lang=\"yaml\" title=\"Enroll Prometheus built-in meter registry using default configuration\" >micrometer: builtin-registries: - type: prometheus <markup lang=\"yaml\" title=\"Enroll Prometheus built-in meter registry with non-default configuration\" >micrometer: builtin-registries: - type: prometheus prefix: myPrefix Note that the first config example is equivalent to the default Helidon Micrometer behavior; Helidon by default supports the Prometheus meter registry. The configuration keys that are valid for the builtin-registries child entries depend on the type of Micrometer meter registry. For example, the Prometheus meter registry supports the prefix configuration setting but other meter registries might not and might support other settings. Refer to the documentation for the meter registry you want to configure to find out what items apply to that registry type. Helidon does not validate the configuration keys you specify for meter registries. Enrolling other Micrometer meter registries To create additional types of registries and enroll them with MicrometerSupport , you need to: Write a Handler Each meter registry has its own way of producing output. Write your handler so that it has a reference to the meter registry it should use and so that its accept method sets the payload in the HTTP response using the registry&#8217;s mechanism for creating output. Write a Function which accepts a ServerRequest and returns an Optional&lt;Handler&gt; In general, your function looks at the request&#8212;&#8203;the Content-Type , query parameters, etc.--to decide whether your handler should respond to the request. If so, your function should instantiate your Handler and return an Optional.of(theHandlerInstance) ; otherwise, your function should return Optional.empty() . When MicrometerSupport receives a request, it invokes the functions of all the enrolled registries, stopping as soon as one function provides a handler. MicrometerSupport then delegates to that handler to create and send the response. Pass the Handler and Function to the MicrometerSupport.enrollRegistry method to enroll them <markup lang=\"java\" title=\"Creating and enrolling your own Micrometer meter registry\" >MeterRegistry myRegistry = new PrometheusMeterRegistry(myPrometheusConfig); MicrometerSupport support = MicrometerSupport.builder() .enrollRegistry(myRegistry, request -&gt; request .headers() .bestAccepted(MediaType.TEXT_PLAIN).isPresent() ? Optional.of((req, resp) -&gt; resp.send(myRegistry.scrape())) : Optional.empty()) .build(); Create the meter registry. This example uses a Prometheus registry but it can be any extension of MeterRegistry . Provide the function that checks if the ServerRequest accepts content that your meter registry can produce (e.g., either text/plain or unspecified is normally an indication for Prometheus-style output) and returns the appropriate Optional&lt; Handler &gt; . A very simple in-line Handler that sets the response entity from the Prometheus registry&#8217;s scrape() method. ",
            "title": "Using Micrometer in Your Application"
        },
        {
            "location": "/se/metrics/02_micrometer",
            "text": " By default, Helidon Micrometer integration exposes the /micrometer endpoint. You can override this using the Builder or the micrometer.web-context configuration key. When MicrometerSupport receives a request at the endpoint, it looks for the first enrolled meter registry for which the corresponding Function&lt;ServerRequest, Optional&lt;Handler&gt;&gt; returns a non-empty Handler . Helidon invokes that Handler which must retrieve the metrics output from its meter registry and set and send the response. Note that the Handler which your function returns typically has a reference to the meter registry it will use in preparing the response. ",
            "title": "Accessing the Helidon Micrometer Endpoint"
        },
        {
            "location": "/se/tracing/01_tracing",
            "text": " To enable Tracing add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/tracing/01_tracing",
            "text": " Helidon includes support for tracing through the OpenTracing APIs. Tracing is integrated with WebServer, gRPC Server, and Security. Support for specific tracers is abstracted. Your application can depend on the abstraction layer and provide a specific tracer implementation as a Java ServiceLoader service. ",
            "title": "Tracing Support"
        },
        {
            "location": "/se/tracing/01_tracing",
            "text": " To configure tracer with WebServer: <markup lang=\"java\" title=\"Configuring OpenTracing Tracer \" >ServerConfiguration.builder() .tracer(TracerBuilder.create(\"my-application\") .collectorUri(URI.create(\"http://10.0.0.18:9411\")) .build()) .build() The name of the application (service) to associate with the tracing events The endpoint for tracing events, specific to the tracer used, usually loaded from Config ",
            "title": "Configuring Tracing with WebServer"
        },
        {
            "location": "/se/tracing/01_tracing",
            "text": "<markup lang=\"java\" title=\"Configuring OpenTracing Tracer \" >Tracer tracer = (Tracer) TracerBuilder.create(\"Server\") .collectorUri(URI.create(\"http://10.0.0.18:9411\")) .build(); If using zipkin tracing system, the endpoint would be: http://10.0.0.18:9411/api/v2/spans <markup lang=\"java\" title=\"Configuring Tracing Attributes\" >GrpcTracingConfig tracingConfig = new GrpcTracingConfig.Builder() .withStreaming() .withVerbosity() .withTracedAttributes(ServerRequestAttribute.CALL_ATTRIBUTES, ServerRequestAttribute.HEADERS, ServerRequestAttribute.METHOD_NAME) .build(); <markup lang=\"java\" title=\"Configuring gRPC Server\" >GrpcServerConfiguration serverConfig = GrpcServerConfiguration.builder().port(0) .tracer(tracer) .tracingConfig(tracingConfig) .build(); ",
            "title": "Configuring Tracing with gRPC Server"
        },
        {
            "location": "/se/tracing/01_tracing",
            "text": " There is a set of common configuration options that this section describes. In addition each tracer implementation may have additional configuration options - please see the documentation of each of them. Each implementation may provide defaults for these options. All common configuration options: key description service Name of the service sending the tracing information. This is usually visible in the trace data to distinguish actors in a conversation (e.g. when multiple microservices are connected together) protocol Protocol of the tracing collector (e.g. http , https ) host Host of the tracing collector (e.g. localhost ) port Port of the tracing collector (e.g. 9411 ) path Path of the tracing collector service that is used to send spans to enabled If set to false, tracing would be disabled tags String tags that are to be added to each span reported (object node of string-string pairs) boolean-tags Boolean tags that are to be added to each span reported (object node of string-boolean pairs) int-tags Int tags that are to be added to each span reported (object node of string-int pairs) ",
            "title": "Configuration using Helidon Config"
        },
        {
            "location": "/se/tracing/01_tracing",
            "text": " Configuring Tracing with WebServer To configure tracer with WebServer: <markup lang=\"java\" title=\"Configuring OpenTracing Tracer \" >ServerConfiguration.builder() .tracer(TracerBuilder.create(\"my-application\") .collectorUri(URI.create(\"http://10.0.0.18:9411\")) .build()) .build() The name of the application (service) to associate with the tracing events The endpoint for tracing events, specific to the tracer used, usually loaded from Config Configuring Tracing with gRPC Server <markup lang=\"java\" title=\"Configuring OpenTracing Tracer \" >Tracer tracer = (Tracer) TracerBuilder.create(\"Server\") .collectorUri(URI.create(\"http://10.0.0.18:9411\")) .build(); If using zipkin tracing system, the endpoint would be: http://10.0.0.18:9411/api/v2/spans <markup lang=\"java\" title=\"Configuring Tracing Attributes\" >GrpcTracingConfig tracingConfig = new GrpcTracingConfig.Builder() .withStreaming() .withVerbosity() .withTracedAttributes(ServerRequestAttribute.CALL_ATTRIBUTES, ServerRequestAttribute.HEADERS, ServerRequestAttribute.METHOD_NAME) .build(); <markup lang=\"java\" title=\"Configuring gRPC Server\" >GrpcServerConfiguration serverConfig = GrpcServerConfiguration.builder().port(0) .tracer(tracer) .tracingConfig(tracingConfig) .build(); Configuration using Helidon Config There is a set of common configuration options that this section describes. In addition each tracer implementation may have additional configuration options - please see the documentation of each of them. Each implementation may provide defaults for these options. All common configuration options: key description service Name of the service sending the tracing information. This is usually visible in the trace data to distinguish actors in a conversation (e.g. when multiple microservices are connected together) protocol Protocol of the tracing collector (e.g. http , https ) host Host of the tracing collector (e.g. localhost ) port Port of the tracing collector (e.g. 9411 ) path Path of the tracing collector service that is used to send spans to enabled If set to false, tracing would be disabled tags String tags that are to be added to each span reported (object node of string-string pairs) boolean-tags Boolean tags that are to be added to each span reported (object node of string-boolean pairs) int-tags Int tags that are to be added to each span reported (object node of string-int pairs) ",
            "title": "Configuring Tracing with Helidon SE"
        },
        {
            "location": "/se/tracing/01_tracing",
            "text": " To create a custom span that is a child of the WebServer request: <markup lang=\"java\" >Span span = request.tracer() .buildSpan(\"my-operation\") .asChildOf(request.spanContext()) .start(); ",
            "title": "Creating custom spans"
        },
        {
            "location": "/se/tracing/01_tracing",
            "text": " Automated trace propagation is supported currently only with Jersey client. <markup lang=\"java\" title=\"Tracing propagation with Jersey client\" >Response response = client.target(serviceEndpoint) .request() .get(); ",
            "title": "Trace propagation across services"
        },
        {
            "location": "/se/tracing/01_tracing",
            "text": " Builder approach, example that disables a single span log event: <markup lang=\"java\" title=\"Configure tracing using a builder\" >TracingConfig.builder() .addComponent(ComponentTracingConfig.builder(\"web-server\") .addSpan(SpanTracingConfig.builder(\"HTTP Request\") .addSpanLog(SpanLogTracingConfig.builder(\"content-write\").enabled(false).build()) .build()) .build()) .build() ",
            "title": "Configuration using builder"
        },
        {
            "location": "/se/tracing/01_tracing",
            "text": " Tracing configuration can be defined in a config file. <markup lang=\"yaml\" title=\"Tracing configuration\" >tracing: components: web-server: spans: - name: \"HTTP Request\" logs: - name: \"content-write\" enabled: false <markup lang=\"java\" title=\"Use the configuration in web server\" >routing.register(WebTracingConfig.create(config.get(\"tracing\"))); ",
            "title": "Configuration using Helidon Config"
        },
        {
            "location": "/se/tracing/01_tracing",
            "text": " For Web Server we have a path based support for configuring tracing, in addition to the configuration described above. Configuration of path can use any path string supported by the Web Server. The configuration itself has the same possibilities as traced configuration described above. The path specific configuration will be merged with global configuration (path is the \"newer\" configuration, global is the \"older\") <markup lang=\"yaml\" title=\"Configuration in YAML\" >tracing: paths: - path: \"/favicon.ico\" enabled: false - path: \"/metrics\" enabled: false - path: \"/health\" enabled: false - path: \"/greet\" components: web-server: spans: - name: \"content-read\" new-name: \"read\" enabled: false <markup lang=\"java\" title=\"Configuration with Web Server\" >routingBuilder.register(WebTracingConfig.create(config.get(\"tracing\")); <markup lang=\"java\" title=\"Configuration with Web Server using a builder\" >routingBuilder.register(WebTracingConfig.builder() .addPathConfig(PathTracingConfig.builder() .path(\"/metrics\") .tracingConfig(TracingConfig.DISABLED) .build(); .build()); ",
            "title": "Path based configuration in Helidon Web Server"
        },
        {
            "location": "/se/tracing/01_tracing",
            "text": " To have a nicer overview in search pane of a tracer, you can customize the top-level span name using configuration. Example: <markup lang=\"yaml\" title=\"Configuration in YAML\" >tracing: components: web-server: spans: - name: \"HTTP Request\" new-name: \"HTTP %1$s %2$s\" This is supported ONLY for the span named \"HTTP Request\" on component \"web-server\". Parameters provided: Method - HTTP method Path - path of the request (such as '/greet') Query - query of the request (may be null) ",
            "title": "Renaming top level span using request properties"
        },
        {
            "location": "/se/tracing/01_tracing",
            "text": " Each component and its spans can be configured using Config. The traced configuration has the following layers: TracingConfig - the overall configuration of traced components of Helidon ComponentTracingConfig - a component of Helidon that traces spans (such as web-server , security , jax-rs ) SpanTracingConfig - a single traced span within a component (such as security:atn ) SpanLogTracingConfig - a single log event on a span (such as security.user in span security:atn ) The components using tracing configuration use the TracingConfigUtil . This uses the io.helidon.common.Context to retrieve current configuration. Configuration using builder Builder approach, example that disables a single span log event: <markup lang=\"java\" title=\"Configure tracing using a builder\" >TracingConfig.builder() .addComponent(ComponentTracingConfig.builder(\"web-server\") .addSpan(SpanTracingConfig.builder(\"HTTP Request\") .addSpanLog(SpanLogTracingConfig.builder(\"content-write\").enabled(false).build()) .build()) .build()) .build() Configuration using Helidon Config Tracing configuration can be defined in a config file. <markup lang=\"yaml\" title=\"Tracing configuration\" >tracing: components: web-server: spans: - name: \"HTTP Request\" logs: - name: \"content-write\" enabled: false <markup lang=\"java\" title=\"Use the configuration in web server\" >routing.register(WebTracingConfig.create(config.get(\"tracing\"))); Path based configuration in Helidon Web Server For Web Server we have a path based support for configuring tracing, in addition to the configuration described above. Configuration of path can use any path string supported by the Web Server. The configuration itself has the same possibilities as traced configuration described above. The path specific configuration will be merged with global configuration (path is the \"newer\" configuration, global is the \"older\") <markup lang=\"yaml\" title=\"Configuration in YAML\" >tracing: paths: - path: \"/favicon.ico\" enabled: false - path: \"/metrics\" enabled: false - path: \"/health\" enabled: false - path: \"/greet\" components: web-server: spans: - name: \"content-read\" new-name: \"read\" enabled: false <markup lang=\"java\" title=\"Configuration with Web Server\" >routingBuilder.register(WebTracingConfig.create(config.get(\"tracing\")); <markup lang=\"java\" title=\"Configuration with Web Server using a builder\" >routingBuilder.register(WebTracingConfig.builder() .addPathConfig(PathTracingConfig.builder() .path(\"/metrics\") .tracingConfig(TracingConfig.DISABLED) .build(); .build()); Renaming top level span using request properties To have a nicer overview in search pane of a tracer, you can customize the top-level span name using configuration. Example: <markup lang=\"yaml\" title=\"Configuration in YAML\" >tracing: components: web-server: spans: - name: \"HTTP Request\" new-name: \"HTTP %1$s %2$s\" This is supported ONLY for the span named \"HTTP Request\" on component \"web-server\". Parameters provided: Method - HTTP method Path - path of the request (such as '/greet') Query - query of the request (may be null) ",
            "title": "Traced spans configuration"
        },
        {
            "location": "/se/tracing/01_tracing",
            "text": " The following table lists all spans traced by Helidon components: component span name description web-server HTTP Request The overall span of the Web Server from request intitiation until response Note that in Zipkin the name is replaced with jax-rs span name if jax-rs tracing is used. web-server content-read Span for reading the request entity web-server content-write Span for writing the response entity security security Processing of request security security security:atn Span for request authentication security security:atz Span for request authorization security security:response Processing of response security security security:outbound Processing of outbound security jax-rs A generated name Span for the resource method invocation, name is generated from class and method name jax-rs jersey-client-call Span for outbound client call Some of these spans log to the span. These log events can be (in most cases) configured: span name log name configurable enabled by default description HTTP Request handler.class YES YES Each handler has its class and event logged security status YES YES Logs either \"status: PROCEED\" or \"status: DENY\" security:atn security.user YES NO The username of the user if logged in security:atn security.service YES NO The name of the service if logged in security:atn status YES YES Logs the status of security response (such as SUCCESS ) security:atz status YES YES Logs the status of security response (such as SUCCESS ) security:outbound status YES YES Logs the status of security response (such as SUCCESS ) There are also tags that are set by Helidon components. These are not configurable. span name tag name description HTTP Request component name of the component - helidon-webserver , or jaxrs when using MP HTTP Request http.method HTTP method of the request, such as GET , POST HTTP Request http.status_code HTTP status code of the response HTTP Request http.url The path of the request (for SE without protocol, host and port) HTTP Request error If the request ends in error, this tag is set to true , usually accompanied by logs with details content-read requested.type Type (class) of the requested entity (if entity is read) content-write response.type Type (class) of the entity being sent (if enitty is sent) security security.id ID of the security context created for this request (if security is used) jersey-client-call http.method HTTP method of the client request jersey-client-call http.status_code HTTP status code of client response jersey-client-call http.url Full URL of the request (such as http://localhost:8080/greet ) Traced spans configuration Each component and its spans can be configured using Config. The traced configuration has the following layers: TracingConfig - the overall configuration of traced components of Helidon ComponentTracingConfig - a component of Helidon that traces spans (such as web-server , security , jax-rs ) SpanTracingConfig - a single traced span within a component (such as security:atn ) SpanLogTracingConfig - a single log event on a span (such as security.user in span security:atn ) The components using tracing configuration use the TracingConfigUtil . This uses the io.helidon.common.Context to retrieve current configuration. Configuration using builder Builder approach, example that disables a single span log event: <markup lang=\"java\" title=\"Configure tracing using a builder\" >TracingConfig.builder() .addComponent(ComponentTracingConfig.builder(\"web-server\") .addSpan(SpanTracingConfig.builder(\"HTTP Request\") .addSpanLog(SpanLogTracingConfig.builder(\"content-write\").enabled(false).build()) .build()) .build()) .build() Configuration using Helidon Config Tracing configuration can be defined in a config file. <markup lang=\"yaml\" title=\"Tracing configuration\" >tracing: components: web-server: spans: - name: \"HTTP Request\" logs: - name: \"content-write\" enabled: false <markup lang=\"java\" title=\"Use the configuration in web server\" >routing.register(WebTracingConfig.create(config.get(\"tracing\"))); Path based configuration in Helidon Web Server For Web Server we have a path based support for configuring tracing, in addition to the configuration described above. Configuration of path can use any path string supported by the Web Server. The configuration itself has the same possibilities as traced configuration described above. The path specific configuration will be merged with global configuration (path is the \"newer\" configuration, global is the \"older\") <markup lang=\"yaml\" title=\"Configuration in YAML\" >tracing: paths: - path: \"/favicon.ico\" enabled: false - path: \"/metrics\" enabled: false - path: \"/health\" enabled: false - path: \"/greet\" components: web-server: spans: - name: \"content-read\" new-name: \"read\" enabled: false <markup lang=\"java\" title=\"Configuration with Web Server\" >routingBuilder.register(WebTracingConfig.create(config.get(\"tracing\")); <markup lang=\"java\" title=\"Configuration with Web Server using a builder\" >routingBuilder.register(WebTracingConfig.builder() .addPathConfig(PathTracingConfig.builder() .path(\"/metrics\") .tracingConfig(TracingConfig.DISABLED) .build(); .build()); Renaming top level span using request properties To have a nicer overview in search pane of a tracer, you can customize the top-level span name using configuration. Example: <markup lang=\"yaml\" title=\"Configuration in YAML\" >tracing: components: web-server: spans: - name: \"HTTP Request\" new-name: \"HTTP %1$s %2$s\" This is supported ONLY for the span named \"HTTP Request\" on component \"web-server\". Parameters provided: Method - HTTP method Path - path of the request (such as '/greet') Query - query of the request (may be null) ",
            "title": "Traced spans"
        },
        {
            "location": "/guides/32_jib",
            "text": " This guide describes how to build container images for Helidon applications using Jib and Maven. ",
            "title": "preambule"
        },
        {
            "location": "/guides/32_jib",
            "text": " About 10 minutes Helidon Prerequisites ",
            "title": "What You Need"
        },
        {
            "location": "/guides/32_jib",
            "text": " Jib is a java tool chain for building Docker images for Java applications. It is integrated with Maven and Gradle and uses a distroless base image to produce small images. Jib does not require the docker command or the Docker daemon, there is no need to solve the Docker-in-Docker problem in order to build Docker images as part of your continuous integration. The docker command is only required for local usage when registering images in your local Docker registry. The example below shows how to build an image and register it in the local registry using the jib-maven-plugin . Add the following plugin declaration to your pom.xml: <markup lang=\"xml\" >&lt;plugin&gt; &lt;groupId&gt;com.google.cloud.tools&lt;/groupId&gt; &lt;artifactId&gt;jib-maven-plugin&lt;/artifactId&gt; &lt;version&gt;0.10.1&lt;/version&gt; &lt;configuration&gt; &lt;to&gt; &lt;image&gt;jib-${project.artifactId}&lt;/image&gt; &lt;tags&gt; &lt;tag&gt;${project.version}&lt;/tag&gt; &lt;tag&gt;latest&lt;/tag&gt; &lt;/tags&gt; &lt;/to&gt; &lt;container&gt; &lt;!-- good defaults intended for containers --&gt; &lt;jvmFlags&gt; &lt;jmxFlag&gt;-server&lt;/jmxFlag&gt; &lt;jmxFlag&gt;-Djava.awt.headless=true&lt;/jmxFlag&gt; &lt;jmxFlag&gt;-XX:+UnlockExperimentalVMOptions&lt;/jmxFlag&gt; &lt;jmxFlag&gt;-XX:+UseCGroupMemoryLimitForHeap&lt;/jmxFlag&gt; &lt;jmxFlag&gt;-XX:InitialRAMFraction=2&lt;/jmxFlag&gt; &lt;jmxFlag&gt;-XX:MinRAMFraction=2&lt;/jmxFlag&gt; &lt;jmxFlag&gt;-XX:MaxRAMFraction=2&lt;/jmxFlag&gt; &lt;jmxFlag&gt;-XX:+UseG1GC&lt;/jmxFlag&gt; &lt;/jvmFlags&gt; &lt;mainClass&gt;${mainClass}&lt;/mainClass&gt; &lt;ports&gt; &lt;port&gt;8080&lt;/port&gt; &lt;/ports&gt; &lt;/container&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;dockerBuild&lt;/goal&gt; &lt;/goals&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; By default, Jib uses distroless/java as the base image. You can override the default with configuration see the documentation <markup lang=\"bash\" title=\"Package the updated application\" >mvn package <markup lang=\"bash\" title=\"Run the image\" >docker run --rm -p 8080:8080 jib-helidon-quickstart-se <markup lang=\"bash\" title=\"Ping the application\" >curl -X GET http://localhost:8080/greet <markup lang=\"bash\" title=\"Take a look at the image size\" >docker images jib-quickstart-se:latest <markup lang=\"bash\" >REPOSITORY TAG IMAGE ID CREATED SIZE jib-quickstart-se latest 384aebda5594 48 years ago 124MB Ignore the fact that it says the image was created 48 years ago. Refer to the Jib FAQ for explanations. the Jib image is smaller because of the use of a distroless base image. ",
            "title": "Creating a Docker Image Using Jib"
        },
        {
            "location": "/mp/reactivestreams/01_overview",
            "text": " fa-cogs Helidon Reactive Engine A set of reactive operators. fa-book MicroProfile Reactive Streams Operators Microprofile implementation. There are two handy apis for working with reactive streams available in Helidon, one for working with java.util.concurrent.Flow and another for org.reactivestreams based reactive components. ",
            "title": "Reactive Streams"
        },
        {
            "location": "/se/metrics/03_prometheus",
            "text": " Helidon WebServer can serve Prometheus metrics. This document describes how to register Prometheus support with WebServer and how to customize the configuration. For information about using Prometheus, see the Prometheus documentation: https://prometheus.io/docs/introduction/overview/ . Note that Helidon has an in-built metrics implementation. See Helidon Metrics . ",
            "title": "preambule"
        },
        {
            "location": "/se/metrics/03_prometheus",
            "text": " To enable Prometheus Metrics add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics-prometheus&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/metrics/03_prometheus",
            "text": " To enable Prometheus metrics, register it with the web server. <markup lang=\"java\" >import io.helidon.metrics.prometheus.PrometheusSupport; //... Routing.builder() .register(PrometheusSupport.create()) .register(\"/myapp\", new MyService()) .build(); This example uses the default CollectorRegistry and exposes an endpoint /metrics . You can use fluent API builder obtained by PrometheusSupport.builder() to configure a different CollectorRegistry or a different path. ",
            "title": "Using Prometheus metrics in your application"
        },
        {
            "location": "/mp/faulttolerance/01_overview",
            "text": " Fault Tolerance is part of the MicroProfile set of specifications . This API defines mostly annotations that improve application robustness by providing support to conveniently handle error conditions (faults) that may occur in real-world applications. Examples include service restarts, network delays, temporal infrastructure instabilities, etc. ",
            "title": "preambule"
        },
        {
            "location": "/mp/faulttolerance/01_overview",
            "text": " To enable MicroProfile Fault Tolerance either add a dependency on the helidon-microprofile bundle or add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-fault-tolerance&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/faulttolerance/01_overview",
            "text": " Helidon&#8217;s implementation uses two types of thread pools: normal and scheduled. The default core size of these executors is 16; however, that can be configured using an application.yaml file as follows: <markup lang=\"yaml\" >executor: core-pool-size: 32 scheduled-executor: core-pool-size: 32 There is currently no support to configure these executor properties via a microprofile-config.properties file. For a complete set of properties available to configure these executors, see ServerThreadPoolSupplier and ScheduledThreadPoolSupplier . ",
            "title": "Configuration"
        },
        {
            "location": "/mp/faulttolerance/01_overview",
            "text": " The latest implementation of MP Fault Tolerance is built on top of Helidon&#8217;s SE Fault Tolerance. Thus, some configuration for Helidon SE Fault Tolerance also applies to MP. The next section describes configuration properties that are of particular interest to MP applications. Configuration Helidon&#8217;s implementation uses two types of thread pools: normal and scheduled. The default core size of these executors is 16; however, that can be configured using an application.yaml file as follows: <markup lang=\"yaml\" >executor: core-pool-size: 32 scheduled-executor: core-pool-size: 32 There is currently no support to configure these executor properties via a microprofile-config.properties file. For a complete set of properties available to configure these executors, see ServerThreadPoolSupplier and ScheduledThreadPoolSupplier . ",
            "title": "Fault Tolerance in Helidon"
        },
        {
            "location": "/mp/guides/08_jta",
            "text": " This guide shows how to configure and use Java Transaction API (JTA) -compliant transactions in your Helidon MP application. ",
            "title": "preambule"
        },
        {
            "location": "/mp/guides/08_jta",
            "text": " For this 10 minute tutorial, you will need the following: <div class=\"table__overflow elevation-1 flex sm7 \"> A Helidon {upper-case-flavor} Application You can use your own application or use the Helidon {upper-case-flavor} Quickstart to create a sample application. Java&#160;SE&#160;11 ( Open&#160;JDK&#160;11 ) Helidon requires Java 11+. Maven 3.6.1+ Helidon requires Maven 3.6.1+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop ). <markup lang=\"bash\" title=\"Verify Prerequisites\" >java -version mvn --version docker --version kubectl version --short <markup lang=\"bash\" title=\"Setting JAVA_HOME\" ># On Mac export JAVA_HOME=`/usr/libexec/java_home -v 11` # On Linux # Use the appropriate path to your JDK export JAVA_HOME=/usr/lib/jvm/jdk-11 ",
            "title": "What You Need"
        },
        {
            "location": "/mp/guides/08_jta",
            "text": " To bring JTA transactions to your Helidon MP application, you&#8217;ll need to add the relevant extension. Specifically, you&#8217;ll need to add an appropriate &lt;dependency&gt; element as a child element of the &lt;dependencies&gt; element in your pom.xml , referencing the Helidon JTA extension: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.cdi&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-cdi-jta-weld&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; Note the scope is runtime . ",
            "title": "Add the Helidon JTA Integration to Your Application&#8217;s Runtime Classpath"
        },
        {
            "location": "/mp/guides/08_jta",
            "text": " To actually use the Java Transaction API in your code, you&#8217;ll need to ensure a library defining the classes and interfaces mandated by the specification is present on your compilation classpath. (Note that this library is separate from any given vendor&#8217;s actual implementation of the specification by way of these classes and interfaces.) <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;jakarta.transaction&lt;/groupId&gt; &lt;artifactId&gt;jakarta.transaction-api&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; The scope is provided to allow the JTA implementation runtime to provide its own implementation of the API jar if necessary. ",
            "title": "Add JTA to Your Application&#8217;s Compilation Classpath"
        },
        {
            "location": "/mp/guides/08_jta",
            "text": " Choose a method that you wish to have a certain kind of transactional behavior, and annotate it with the @Transactional annotation. The method in question will need to be a business method of some kind: a method that is invoked by the Helidon MP server machinery, not directly by the user. This is because normally the behavior that @Transactional requests is provided by interceptor functionality. More concretely, in Helidon MP you can annotate a JAX-RS resource method , or a method on a CDI bean that itself is injected in your application somewhere. For example, a method on a hypothetical PersonDAO class that saves a hypothetical Person object to a database, starting a new JTA transaction if necessary, might look like this: <markup lang=\"java\" title=\" PersonDAO.java \" >import javax.transaction.Transactional; import javax.transaction.Transactional.TxType; @Transactional(TxType.REQUIRED) public void savePerson(Person person) { // Use JPA or another JTA-aware framework to save the Person object } The Transactional annotation indicates the kind of transactional behavior you would like this method to have. In this example, we explicitly set the kind of behavior to be REQUIRED (which also happens to be the default if you do not specify an explicit TxType ). Annotating a method with @Transactional demarcates a JTA transaction, but it is up to individual JTA-aware frameworks and libraries to actually do something when the transaction is implicitly started. JPA is an example of a framework that is JTA aware. ",
            "title": "Annotate a Method With @Transactional "
        },
        {
            "location": "/mp/beanvalidation/02_general_beanvalidation",
            "text": " If bean validation is required outside JAX-RS/Jersey use cases, it is also available in Helidon. It follows the standard Jakarta Bean Validation specification which defines an API to validate Java beans. ",
            "title": "preambule"
        },
        {
            "location": "/mp/beanvalidation/02_general_beanvalidation",
            "text": " To enable General Bean Validation add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.bean-validation&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-bean-validation&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/beanvalidation/02_general_beanvalidation",
            "text": " The following example shows a simple application with one field declared as not null using @NotNull annotation: <markup lang=\"java\" >public class GreetingHolder { @NotNull private String greeting; //... } If the bean contains a method parameter annotated with @Valid, and GreetingHolder with null_greeting is passed, then a _ValidationException will be thrown: <markup lang=\"java\" >@ApplicationScoped public class GreetingProvider { private GreetingHolder greetingHolder; //.. void setGreeting(@Valid GreetingHolder greetingHolder) { this.greetingHolder = greetingHolder; } } beans.xml is required to identify beans and for bean validation to work properly. For more information about the supported validations, see Jakarta Bean Validation specification . ",
            "title": "Validation Example in Helidon MP"
        },
        {
            "location": "/mp/restclient/09_rest-client",
            "text": " To enable MicroProfile Rest Client either add a dependency on the helidon-microprofile bundle or add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.rest-client&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-rest-client&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/restclient/09_rest-client",
            "text": " MicroProfile Rest Client adds the capability to invoke remote microservices using a JAX-RS like interface to declare the operations. ",
            "title": "Configuring Rest Client with Helidon MP"
        },
        {
            "location": "/mp/restclient/09_rest-client",
            "text": " MicroProfile Rest Client can be created using a builder obtained from RestClientBuilder.newBuilder() . The builder provides methods to configure details for the client and to define the desired rest client interface. Example: <markup lang=\"java\" >SomeResource someResource = RestClientBuilder.newBuilder() .baseUri(URI.create(\"http://localhost:8080/baseUri\")) .build(SomeResource.class); someResource.someMethod(apiModel); ",
            "title": "Creating a new client using a builder"
        },
        {
            "location": "/mp/restclient/09_rest-client",
            "text": " A rest client interface can be annotated with @RegisterRestClient to automatically register it with CDI. The RegisterRestClient annotation has a property baseUri that can be used to define the base endpoint of this client. This value can be overridden using configuration. Example: <markup lang=\"java\" >@RegisterRestClient(baseUri=\"http://localhost:8080/baseUri\") public interface SomeResource { // ... } Once a rest client interface is annotated, it can be injected into any CDI bean. Example: <markup lang=\"java\" >@Inject @RestClient SomeResource client; // ... client.sampleMethod(); ",
            "title": "Creating new client - CDI"
        },
        {
            "location": "/mp/restclient/09_rest-client",
            "text": " Rest client implementation allows you to configure its parameters by builder, annotations, and configuration. You can configure new providers, base URI/URL and other options of the client. See specification for full details: https://download.eclipse.org/microprofile/microprofile-rest-client-1.2.1/microprofile-rest-client-1.2.1.html ",
            "title": "Rest client configuration"
        },
        {
            "location": "/mp/restclient/09_rest-client",
            "text": " To be able to run and test this example, please head to the Helidon examples/quickstarts and start the helidon-quickstart-mp. Then create project with the dependency on the Helidon rest client implementation and create the following rest client interface: Rest client interface <markup lang=\"java\" >@Path(\"/greet\") interface GreetRestClient { @GET JsonObject getDefaultMessage(); @Path(\"/{name}\") @GET JsonObject getMessage(@PathParam(\"name\") String name); } Then create runnable method the same way as it is described in Creating new client - Interface ,but with baseUri http://localhost:8080/greet and the above interface. By calling GreetRestClient.getDefaultMessage() you reach the endpoint of Helidon quickstart. ",
            "title": "Quickstart example"
        },
        {
            "location": "/mp/guides/06_tracing",
            "text": " This guide describes how to create a sample MicroProfile (MP) project that can be used to run some basic examples using tracing with Helidon MP. ",
            "title": "preambule"
        },
        {
            "location": "/mp/guides/06_tracing",
            "text": " For this 30 minute tutorial, you will need the following: <div class=\"table__overflow elevation-1 flex sm7 \"> A Helidon {upper-case-flavor} Application You can use your own application or use the Helidon {upper-case-flavor} Quickstart to create a sample application. Java&#160;SE&#160;11 ( Open&#160;JDK&#160;11 ) Helidon requires Java 11+. Maven 3.6.1+ Helidon requires Maven 3.6.1+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop ). <markup lang=\"bash\" title=\"Verify Prerequisites\" >java -version mvn --version docker --version kubectl version --short <markup lang=\"bash\" title=\"Setting JAVA_HOME\" ># On Mac export JAVA_HOME=`/usr/libexec/java_home -v 11` # On Linux # Use the appropriate path to your JDK export JAVA_HOME=/usr/lib/jvm/jdk-11 ",
            "title": "What You Need"
        },
        {
            "location": "/mp/guides/06_tracing",
            "text": " This section explains a few concepts that you need to understand before you get started with tracing. In the context of this document, a service is synonymous with an application. A span is the basic unit of work done within a single service, on a single host. Every span has a name, starting timestamp, and duration. For example, the work done by a REST endpoint is a span. A span is associated to a single service, but its descendants can belong to different services and hosts. A trace contains a collection of spans from one or more services, running on one or more hosts. For example, if you trace a service endpoint that calls another service, then the trace would contain spans from both services. Within a trace, spans are organized as a directed acyclic graph (DAG) and can belong to multiple services, running on multiple hosts. The OpenTracing Data Model describes the details at The OpenTracing Semantic Specification . Spans are automatically created by Helidon as needed during execution of the REST request. ",
            "title": "Tracing Concepts"
        },
        {
            "location": "/mp/guides/06_tracing",
            "text": " Distributed tracing is a critical feature of micro-service based applications, since it traces workflow both within a service and across multiple services. This provides insight to sequence and timing data for specific blocks of work, which helps you identify performance and operational issues. Helidon MP includes support for distributed tracing through the OpenTracing API . Tracing is integrated with WebServer, gRPC Server, and Security using either the Zipkin or Jaeger tracers. Tracing Concepts This section explains a few concepts that you need to understand before you get started with tracing. In the context of this document, a service is synonymous with an application. A span is the basic unit of work done within a single service, on a single host. Every span has a name, starting timestamp, and duration. For example, the work done by a REST endpoint is a span. A span is associated to a single service, but its descendants can belong to different services and hosts. A trace contains a collection of spans from one or more services, running on one or more hosts. For example, if you trace a service endpoint that calls another service, then the trace would contain spans from both services. Within a trace, spans are organized as a directed acyclic graph (DAG) and can belong to multiple services, running on multiple hosts. The OpenTracing Data Model describes the details at The OpenTracing Semantic Specification . Spans are automatically created by Helidon as needed during execution of the REST request. ",
            "title": "Introduction"
        },
        {
            "location": "/mp/guides/06_tracing",
            "text": " Use the Helidon MP Maven archetype to create a simple project that can be used for the examples in this guide. <markup lang=\"bash\" title=\"Run the Maven archetype:\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-mp \\ -DarchetypeVersion=2.5.4 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-mp \\ -Dpackage=io.helidon.examples.quickstart.mp <markup lang=\"bash\" title=\"The project will be built and run from the helidon-quickstart-mp directory:\" >cd helidon-quickstart-mp ",
            "title": "Create a Sample Helidon MP project"
        },
        {
            "location": "/mp/guides/06_tracing",
            "text": " First, you need to run the Zipkin tracer. Helidon will communicate with this tracer at runtime. <markup lang=\"bash\" title=\"Run Zipkin within a docker container, then check the Zipkin server health:\" >docker run -d --name zipkin -p 9411:9411 openzipkin/zipkin Run the Zipkin docker image named openzipkin/zipkin . <markup lang=\"bash\" title=\"Check the Zipkin server health:\" >curl http://localhost:9411/health ... { \"status\": \"UP\", \"zipkin\": { \"status\": \"UP\", \"details\": { \"InMemoryStorage{}\": { \"status\": \"UP\" } } } } Invoke the Zipkin REST API to check the Zipkin server health. All status fields should be UP . ",
            "title": "Set up Zipkin"
        },
        {
            "location": "/mp/guides/06_tracing",
            "text": " Update the pom.xml file and add the following Zipkin dependency to the &lt;dependencies&gt; section ( not &lt;dependencyManagement&gt; ). This will enable Helidon to use Zipkin at the default host and port, localhost:9411 . <markup lang=\"xml\" title=\"Add the following dependency to pom.xml :\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-zipkin&lt;/artifactId&gt; &lt;/dependency&gt; All spans sent by Helidon to Zipkin need to be associated with a service. Specify the service name below. <markup lang=\"bash\" title=\"Add the following line to META-INF/microprofile-config.properties :\" >tracing.service=helidon-mp-1 <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-mp.jar <markup lang=\"bash\" title=\"Run the curl command in a new terminal window and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"Hello World!\" } ",
            "title": "Enable Tracing in the Helidon Application"
        },
        {
            "location": "/mp/guides/06_tracing",
            "text": " Because tracing is now enabled, the previous /greet endpoint invocation resulted in a new trace being created. Let&#8217;s get the trace data that was generated using the Zipkin API. First, get the service information. Helidon automatically enables tracing for JAX-RS resources methods so you don&#8217;t need to use annotations with JAX-RS. See MicroProfile OpenTracing for more details. <markup lang=\"bash\" title=\"Run the curl command and check the response:\" >curl http://localhost:9411/api/v2/services ... [\"helidon-mp-1\"] This is the tracing service name specified in META-INF/microprofile-config.properties . Each span used by a service has a name, which is unique within a trace. If you invoke the /greet endpoint multiple times, you will still get the same set of names. <markup lang=\"bash\" title=\"Invoke the endpoint below and check the response:\" > curl -X GET \"http://localhost:9411/api/v2/spans?serviceName=helidon-mp-1\" -H \"accept: application/json\" ... [ \"content-read\", \"content-write\", \"get:io.helidon.examples.quickstart.mp.greetresource.getdefaultmessage\", \"security\", \"security:atn\", \"security:atz\", \"security:response\" ] Get the span names for the helidon-mp-1 service. These are the span names. If you invoke the /greet endpoint again, then invoke the /spans endpoint, you will get the same response. Next, get the contents of the trace as shown below. Notice that each span has a parentId field, except the get:io.helidon.examples.quickstart.mp.greetresource.getdefaultmessage span, which is the root. <markup lang=\"bash\" title=\"Invoke the endpoint below and check the response:\" > curl -X GET \"http://localhost:9411/api/v2/traces?serviceName=helidon-mp-1&amp;limit=1\" -H \"accept: application/json\" ... [ [ { \"traceId\": \"2e0af8866efdef35\", \"parentId\": \"2e0af8866efdef35\", \"id\": \"b5d61690f230fde4\", \"kind\": \"SERVER\", \"name\": \"content-read\", \"timestamp\": 1568077339998659, \"duration\": 41, \"localEndpoint\": { \"serviceName\": \"helidon-mp-1\", \"ipv4\": \"192.168.1.115\" }, \"tags\": { \"requested.type\": \"java.io.InputStream\" } }, ... (truncated) ] Get the newest trace only, using the limit=1 query param. There are other query params that let you restrict results to a specific time window. The request will return seven spans, one for each name, along with an unnamed JSON node, which has the status. ",
            "title": "View Tracing Using Zipkin REST API"
        },
        {
            "location": "/mp/guides/06_tracing",
            "text": " The tracing output data is verbose and can be difficult to interpret using the REST API, especially since it represents a structure of spans. Zipkin provides a web-based UI at http://localhost:9411/zipkin , where you can see a visual representation of the same data and the relationship between spans within a trace. If you see a Lens UI button at the top center then click on it and it will take you to the specific UI used by this guide. Click on the UI refresh button (the search icon) as shown in the image below. Notice that you can change the look-back time to restrict the trace list. Trace refresh The image below shows the trace summary, including start time and duration of each trace. There are two traces, each one generated in response to a curl http://localhost:8080/greet invocation. The oldest trace will have a much longer duration since there is one-time initialization that occurs. Tracing list view Click on a trace and you will see the trace detail page where the spans are listed. You can clearly see the root span and the relationship among all the spans in the trace, along with timing information. Trace detail page A parent span might not depend on the result of the child. This is called a FollowsFrom reference, see Open Tracing Semantic Spec . Note that the last span that writes the response after the root span ends falls into this category. You can examine span details by clicking on the span row. Refer to the image below, which shows the security span details, including timing information. You can see times for each space relative to the root span. These rows are annotated with Server Start and Server Finish , as shown in the third column. Span detail page ",
            "title": "View Tracing Using Zipkin UI"
        },
        {
            "location": "/mp/guides/06_tracing",
            "text": " To trace at the method level, you just annotate a method with @Traced. <markup lang=\"java\" title=\"Update the GreetingProvider class; 1) Add a new import and 2) Add the @Traced annotation to the getMessage method:\" >import org.eclipse.microprofile.opentracing.Traced; ... @Traced String getMessage() { return message.get(); } ... Import the Traced annotation. Enable tracing for getMessage. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints and check the response:\" >curl http://localhost:8080/greet curl -X GET \"http://localhost:9411/api/v2/spans?serviceName=helidon-mp-1\" -H \"accept: application/json\" ... [ \"content-read\", \"content-write\", \"dosomework\", \"get:io.helidon.examples.quickstart.mp.greetresource.getdefaultmessage\", \"io.helidon.examples.quickstart.mp.greetingprovider.getmessage\", \"security\", \"security:atn\", \"security:atz\", \"security:response\" ] There is new span name for the getmessage method, since your code called that method during the invocation of /greet . Click the back button on your browser, then click on the UI refresh button to see the new trace. Select the newest trace in the list to see the trace detail page like the one below. Notice the new span named io.helidon.examples.quickstart.mp.greetingprovider.getmessage . Trace detail page with new span getmessage ",
            "title": "Tracing at the Method Level"
        },
        {
            "location": "/mp/guides/06_tracing",
            "text": " To trace at the class level, annotate the class with @Traced. This will enable tracing for all class methods, except for the constructor and private methods. <markup lang=\"java\" title=\"Update the GreetingProvider class; 1) Add @Traced to the GreetingProvider class and 2) Remove @Traced from the getMessage method:\" >@Traced @ApplicationScoped public class GreetingProvider { ... String getMessage() { return message.get(); } This will enable tracing for all class methods, except for the constructor and methods that are private. Remove @Traced for the getMessage method. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints and check the response:\" >curl http://localhost:8080/greet curl -X GET \"http://localhost:9411/api/v2/spans?serviceName=helidon-mp-1\" -H \"accept: application/json\" [ ... \"io.helidon.examples.quickstart.mp.greetingprovider.getmessage\", ... ] The service has the same set of span names as above, since getmessage was the only method called in this bean. Next, invoke HTTP PUT to change the greeting, which will cause setMessage to be called. <markup lang=\"bash\" >Invoke the endpoints and check the response: ---- curl -i -X PUT -H \"Content-Type: application/json\" -d '{\"greeting\": \"Hi\"}' http://localhost:8080/greet/greeting curl -X GET \"http://localhost:9411/api/v2/spans?serviceName=helidon-mp-1\" -H \"accept: application/json\" ... [ \"content-read\", \"content-write\", \"get:io.helidon.examples.quickstart.mp.greetresource.getdefaultmessage\", \"io.helidon.examples.quickstart.mp.greetingprovider.getmessage\", \"io.helidon.examples.quickstart.mp.greetingprovider.setmessage\", \"put:io.helidon.examples.quickstart.mp.greetresource.updategreeting\", \"security\", \"security:atn\", \"security:atz\", \"security:response\" ] ---- &lt;1&gt; Invoke the endpoint to change the greeting. &lt;2&gt; The `GreetingProvider.setmessage` method was traced since you enabled class level tracing. &lt;3&gt; The JAX-RS method `GreetResource.updategreeting` was traced automatically by Helidon. You can refresh the UI view and drill down the trace to see the new spans. Methods invoked directly by your code are not enabled for tracing, even if you explicitly annotate them with @Traced. Tracing only works for methods invoked on CDI beans. See the example below. <markup lang=\"java\" title=\"Update the GreetingProvider class with the following code:\" >@ApplicationScoped public class GreetingProvider { private final AtomicReference&lt;String&gt; message = new AtomicReference&lt;&gt;(); @Inject public GreetingProvider(@ConfigProperty(name = \"app.greeting\") String message) { this.message.set(message); } @Traced String getMessage() { return getMessage2(); } @Traced String getMessage2() { return message.get(); } void setMessage(String message) { this.message.set(message); } } The getMessage method will be traced since it is externally invoked by GreetResource . The getMessage2 method will not be traced, even with the @Traced annotation, since it is called internally by getMessage . <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints and check the response:\" >curl http://localhost:8080/greet curl -X GET \"http://localhost:9411/api/v2/spans?serviceName=helidon-mp-1\" -H \"accept: application/json\" ... [ ... \"io.helidon.examples.quickstart.mp.greetingprovider.getmessage\", ... ] The getMessage method is traced, but getMessage2 is not. ",
            "title": "Tracing at the Class Level"
        },
        {
            "location": "/mp/guides/06_tracing",
            "text": " So far in this tutorial you have used tracing with JAX-RS without needing to annotate. You can enable tracing on other CDI beans, either at the class level or at the method level, as shown by the following examples. Tracing at the Method Level To trace at the method level, you just annotate a method with @Traced. <markup lang=\"java\" title=\"Update the GreetingProvider class; 1) Add a new import and 2) Add the @Traced annotation to the getMessage method:\" >import org.eclipse.microprofile.opentracing.Traced; ... @Traced String getMessage() { return message.get(); } ... Import the Traced annotation. Enable tracing for getMessage. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints and check the response:\" >curl http://localhost:8080/greet curl -X GET \"http://localhost:9411/api/v2/spans?serviceName=helidon-mp-1\" -H \"accept: application/json\" ... [ \"content-read\", \"content-write\", \"dosomework\", \"get:io.helidon.examples.quickstart.mp.greetresource.getdefaultmessage\", \"io.helidon.examples.quickstart.mp.greetingprovider.getmessage\", \"security\", \"security:atn\", \"security:atz\", \"security:response\" ] There is new span name for the getmessage method, since your code called that method during the invocation of /greet . Click the back button on your browser, then click on the UI refresh button to see the new trace. Select the newest trace in the list to see the trace detail page like the one below. Notice the new span named io.helidon.examples.quickstart.mp.greetingprovider.getmessage . Trace detail page with new span getmessage Tracing at the Class Level To trace at the class level, annotate the class with @Traced. This will enable tracing for all class methods, except for the constructor and private methods. <markup lang=\"java\" title=\"Update the GreetingProvider class; 1) Add @Traced to the GreetingProvider class and 2) Remove @Traced from the getMessage method:\" >@Traced @ApplicationScoped public class GreetingProvider { ... String getMessage() { return message.get(); } This will enable tracing for all class methods, except for the constructor and methods that are private. Remove @Traced for the getMessage method. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints and check the response:\" >curl http://localhost:8080/greet curl -X GET \"http://localhost:9411/api/v2/spans?serviceName=helidon-mp-1\" -H \"accept: application/json\" [ ... \"io.helidon.examples.quickstart.mp.greetingprovider.getmessage\", ... ] The service has the same set of span names as above, since getmessage was the only method called in this bean. Next, invoke HTTP PUT to change the greeting, which will cause setMessage to be called. <markup lang=\"bash\" >Invoke the endpoints and check the response: ---- curl -i -X PUT -H \"Content-Type: application/json\" -d '{\"greeting\": \"Hi\"}' http://localhost:8080/greet/greeting curl -X GET \"http://localhost:9411/api/v2/spans?serviceName=helidon-mp-1\" -H \"accept: application/json\" ... [ \"content-read\", \"content-write\", \"get:io.helidon.examples.quickstart.mp.greetresource.getdefaultmessage\", \"io.helidon.examples.quickstart.mp.greetingprovider.getmessage\", \"io.helidon.examples.quickstart.mp.greetingprovider.setmessage\", \"put:io.helidon.examples.quickstart.mp.greetresource.updategreeting\", \"security\", \"security:atn\", \"security:atz\", \"security:response\" ] ---- &lt;1&gt; Invoke the endpoint to change the greeting. &lt;2&gt; The `GreetingProvider.setmessage` method was traced since you enabled class level tracing. &lt;3&gt; The JAX-RS method `GreetResource.updategreeting` was traced automatically by Helidon. You can refresh the UI view and drill down the trace to see the new spans. Methods invoked directly by your code are not enabled for tracing, even if you explicitly annotate them with @Traced. Tracing only works for methods invoked on CDI beans. See the example below. <markup lang=\"java\" title=\"Update the GreetingProvider class with the following code:\" >@ApplicationScoped public class GreetingProvider { private final AtomicReference&lt;String&gt; message = new AtomicReference&lt;&gt;(); @Inject public GreetingProvider(@ConfigProperty(name = \"app.greeting\") String message) { this.message.set(message); } @Traced String getMessage() { return getMessage2(); } @Traced String getMessage2() { return message.get(); } void setMessage(String message) { this.message.set(message); } } The getMessage method will be traced since it is externally invoked by GreetResource . The getMessage2 method will not be traced, even with the @Traced annotation, since it is called internally by getMessage . <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints and check the response:\" >curl http://localhost:8080/greet curl -X GET \"http://localhost:9411/api/v2/spans?serviceName=helidon-mp-1\" -H \"accept: application/json\" ... [ ... \"io.helidon.examples.quickstart.mp.greetingprovider.getmessage\", ... ] The getMessage method is traced, but getMessage2 is not. ",
            "title": "Enable Tracing on CDI Beans"
        },
        {
            "location": "/mp/guides/06_tracing",
            "text": "<markup lang=\"bash\" title=\"Run the Maven archetype:\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-mp \\ -DarchetypeVersion=2.5.4 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-mp-2 \\ -Dpackage=io.helidon.examples.quickstart.mp <markup lang=\"bash\" title=\"The project will be built and run from the helidon-quickstart-mp directory:\" >cd helidon-quickstart-mp-2 <markup lang=\"xml\" title=\"Add the following dependency to pom.xml :\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-zipkin&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"bash\" title=\"Replace META-INF/microprofile-config.properties with the following:\" >app.greeting=Hello From MP-2 tracing.service=helidon-mp-2 # Microprofile server properties server.port=8081 server.host=0.0.0.0 <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-mp-2.jar <markup lang=\"bash\" title=\"Run the curl command in a new terminal window and check the response ( notice the port is 8081 ) :\" >curl http://localhost:8081/greet ... { \"message\": \"Hello From MP-2 World!\" } ",
            "title": "Create a second service"
        },
        {
            "location": "/mp/guides/06_tracing",
            "text": " Once you have validated that the second service is running correctly, you need to modify the original application to call it. <markup lang=\"java\" title=\"Replace the GreetResource class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import javax.enterprise.context.RequestScoped; import javax.inject.Inject; import javax.json.Json; import javax.json.JsonBuilderFactory; import javax.json.JsonObject; import javax.ws.rs.GET; import javax.ws.rs.Path; import javax.ws.rs.Produces; import javax.ws.rs.client.WebTarget; import javax.ws.rs.core.MediaType; import org.glassfish.jersey.server.Uri; @Path(\"/greet\") @RequestScoped public class GreetResource { @Uri(\"http://localhost:8081/greet\") private WebTarget target; private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); private final GreetingProvider greetingProvider; @Inject public GreetResource(GreetingProvider greetingConfig) { this.greetingProvider = greetingConfig; } @SuppressWarnings(\"checkstyle:designforextension\") @GET @Produces(MediaType.APPLICATION_JSON) public JsonObject getDefaultMessage() { return createResponse(\"World\"); } @GET @Path(\"/outbound\") public JsonObject outbound() { return target.request().accept(MediaType.APPLICATION_JSON_TYPE).get(JsonObject.class); } private JsonObject createResponse(String who) { String msg = String.format(\"%s %s!\", greetingProvider.getMessage(), who); return JSON.createObjectBuilder().add(\"message\", msg).build(); } } This is the WebTarget needed to send a request to the second service at port 8081 . This is the new endpoint that will call the second service. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl -i http://localhost:8080/greet/outbound ... { \"message\": \"Hello From MP-2 World!\" } The request went to the service on 8080 , which then invoked the service at 8081 to get the greeting. Notice the greeting came from the second service. Refresh the Zipkin UI trace listing page and notice that there is a trace across two services. Tracing multiple service list view Click on the trace with two services to see the detail view. Tracing across multiple services detail view In the image above, you can see that the trace includes spans from two services. You will notice there is a gap before the sixth span, which is a get operation. This is a one-time client initialization delay. Run the /outbound curl command again and look at the new trace to see that the delay no longer exists. You can now stop your second service, it is no longer used in this guide. ",
            "title": "Modify the first service"
        },
        {
            "location": "/mp/guides/06_tracing",
            "text": " Helidon automatically traces across services as long as the services use the same tracer, for example, the same instance of Zipkin. This means a single trace can include spans from multiple services and hosts. OpenTracing uses a SpanContext to propagate tracing information across process boundaries. When you make client API calls, Helidon will internally call OpenTracing APIs to propagate the SpanContext . There is nothing you need to do in your application to make this work. To demonstrate distributed tracing, you will need to create a second project, where the server listens on port 8081. Create a new root directory to hold this new project, then do the following steps, similar to what you did at the start of this guide: Create a second service <markup lang=\"bash\" title=\"Run the Maven archetype:\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-mp \\ -DarchetypeVersion=2.5.4 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-mp-2 \\ -Dpackage=io.helidon.examples.quickstart.mp <markup lang=\"bash\" title=\"The project will be built and run from the helidon-quickstart-mp directory:\" >cd helidon-quickstart-mp-2 <markup lang=\"xml\" title=\"Add the following dependency to pom.xml :\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-zipkin&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"bash\" title=\"Replace META-INF/microprofile-config.properties with the following:\" >app.greeting=Hello From MP-2 tracing.service=helidon-mp-2 # Microprofile server properties server.port=8081 server.host=0.0.0.0 <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-mp-2.jar <markup lang=\"bash\" title=\"Run the curl command in a new terminal window and check the response ( notice the port is 8081 ) :\" >curl http://localhost:8081/greet ... { \"message\": \"Hello From MP-2 World!\" } Modify the first service Once you have validated that the second service is running correctly, you need to modify the original application to call it. <markup lang=\"java\" title=\"Replace the GreetResource class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import javax.enterprise.context.RequestScoped; import javax.inject.Inject; import javax.json.Json; import javax.json.JsonBuilderFactory; import javax.json.JsonObject; import javax.ws.rs.GET; import javax.ws.rs.Path; import javax.ws.rs.Produces; import javax.ws.rs.client.WebTarget; import javax.ws.rs.core.MediaType; import org.glassfish.jersey.server.Uri; @Path(\"/greet\") @RequestScoped public class GreetResource { @Uri(\"http://localhost:8081/greet\") private WebTarget target; private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); private final GreetingProvider greetingProvider; @Inject public GreetResource(GreetingProvider greetingConfig) { this.greetingProvider = greetingConfig; } @SuppressWarnings(\"checkstyle:designforextension\") @GET @Produces(MediaType.APPLICATION_JSON) public JsonObject getDefaultMessage() { return createResponse(\"World\"); } @GET @Path(\"/outbound\") public JsonObject outbound() { return target.request().accept(MediaType.APPLICATION_JSON_TYPE).get(JsonObject.class); } private JsonObject createResponse(String who) { String msg = String.format(\"%s %s!\", greetingProvider.getMessage(), who); return JSON.createObjectBuilder().add(\"message\", msg).build(); } } This is the WebTarget needed to send a request to the second service at port 8081 . This is the new endpoint that will call the second service. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl -i http://localhost:8080/greet/outbound ... { \"message\": \"Hello From MP-2 World!\" } The request went to the service on 8080 , which then invoked the service at 8081 to get the greeting. Notice the greeting came from the second service. Refresh the Zipkin UI trace listing page and notice that there is a trace across two services. Tracing multiple service list view Click on the trace with two services to see the detail view. Tracing across multiple services detail view In the image above, you can see that the trace includes spans from two services. You will notice there is a gap before the sixth span, which is a get operation. This is a one-time client initialization delay. Run the /outbound curl command again and look at the new trace to see that the delay no longer exists. You can now stop your second service, it is no longer used in this guide. ",
            "title": "Trace Across Services"
        },
        {
            "location": "/mp/guides/06_tracing",
            "text": " The examples in this guide demonstrate how to integrate tracing with Helidon, how to view traces, how to trace across multiple services, and how to integrate tracing with Kubernetes. All examples use Zipkin and traces will be viewed using both the Zipkin API and UI. Create a Sample Helidon MP project Use the Helidon MP Maven archetype to create a simple project that can be used for the examples in this guide. <markup lang=\"bash\" title=\"Run the Maven archetype:\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-mp \\ -DarchetypeVersion=2.5.4 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-mp \\ -Dpackage=io.helidon.examples.quickstart.mp <markup lang=\"bash\" title=\"The project will be built and run from the helidon-quickstart-mp directory:\" >cd helidon-quickstart-mp Set up Zipkin First, you need to run the Zipkin tracer. Helidon will communicate with this tracer at runtime. <markup lang=\"bash\" title=\"Run Zipkin within a docker container, then check the Zipkin server health:\" >docker run -d --name zipkin -p 9411:9411 openzipkin/zipkin Run the Zipkin docker image named openzipkin/zipkin . <markup lang=\"bash\" title=\"Check the Zipkin server health:\" >curl http://localhost:9411/health ... { \"status\": \"UP\", \"zipkin\": { \"status\": \"UP\", \"details\": { \"InMemoryStorage{}\": { \"status\": \"UP\" } } } } Invoke the Zipkin REST API to check the Zipkin server health. All status fields should be UP . Enable Tracing in the Helidon Application Update the pom.xml file and add the following Zipkin dependency to the &lt;dependencies&gt; section ( not &lt;dependencyManagement&gt; ). This will enable Helidon to use Zipkin at the default host and port, localhost:9411 . <markup lang=\"xml\" title=\"Add the following dependency to pom.xml :\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-zipkin&lt;/artifactId&gt; &lt;/dependency&gt; All spans sent by Helidon to Zipkin need to be associated with a service. Specify the service name below. <markup lang=\"bash\" title=\"Add the following line to META-INF/microprofile-config.properties :\" >tracing.service=helidon-mp-1 <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-mp.jar <markup lang=\"bash\" title=\"Run the curl command in a new terminal window and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"Hello World!\" } View Tracing Using Zipkin REST API Because tracing is now enabled, the previous /greet endpoint invocation resulted in a new trace being created. Let&#8217;s get the trace data that was generated using the Zipkin API. First, get the service information. Helidon automatically enables tracing for JAX-RS resources methods so you don&#8217;t need to use annotations with JAX-RS. See MicroProfile OpenTracing for more details. <markup lang=\"bash\" title=\"Run the curl command and check the response:\" >curl http://localhost:9411/api/v2/services ... [\"helidon-mp-1\"] This is the tracing service name specified in META-INF/microprofile-config.properties . Each span used by a service has a name, which is unique within a trace. If you invoke the /greet endpoint multiple times, you will still get the same set of names. <markup lang=\"bash\" title=\"Invoke the endpoint below and check the response:\" > curl -X GET \"http://localhost:9411/api/v2/spans?serviceName=helidon-mp-1\" -H \"accept: application/json\" ... [ \"content-read\", \"content-write\", \"get:io.helidon.examples.quickstart.mp.greetresource.getdefaultmessage\", \"security\", \"security:atn\", \"security:atz\", \"security:response\" ] Get the span names for the helidon-mp-1 service. These are the span names. If you invoke the /greet endpoint again, then invoke the /spans endpoint, you will get the same response. Next, get the contents of the trace as shown below. Notice that each span has a parentId field, except the get:io.helidon.examples.quickstart.mp.greetresource.getdefaultmessage span, which is the root. <markup lang=\"bash\" title=\"Invoke the endpoint below and check the response:\" > curl -X GET \"http://localhost:9411/api/v2/traces?serviceName=helidon-mp-1&amp;limit=1\" -H \"accept: application/json\" ... [ [ { \"traceId\": \"2e0af8866efdef35\", \"parentId\": \"2e0af8866efdef35\", \"id\": \"b5d61690f230fde4\", \"kind\": \"SERVER\", \"name\": \"content-read\", \"timestamp\": 1568077339998659, \"duration\": 41, \"localEndpoint\": { \"serviceName\": \"helidon-mp-1\", \"ipv4\": \"192.168.1.115\" }, \"tags\": { \"requested.type\": \"java.io.InputStream\" } }, ... (truncated) ] Get the newest trace only, using the limit=1 query param. There are other query params that let you restrict results to a specific time window. The request will return seven spans, one for each name, along with an unnamed JSON node, which has the status. View Tracing Using Zipkin UI The tracing output data is verbose and can be difficult to interpret using the REST API, especially since it represents a structure of spans. Zipkin provides a web-based UI at http://localhost:9411/zipkin , where you can see a visual representation of the same data and the relationship between spans within a trace. If you see a Lens UI button at the top center then click on it and it will take you to the specific UI used by this guide. Click on the UI refresh button (the search icon) as shown in the image below. Notice that you can change the look-back time to restrict the trace list. Trace refresh The image below shows the trace summary, including start time and duration of each trace. There are two traces, each one generated in response to a curl http://localhost:8080/greet invocation. The oldest trace will have a much longer duration since there is one-time initialization that occurs. Tracing list view Click on a trace and you will see the trace detail page where the spans are listed. You can clearly see the root span and the relationship among all the spans in the trace, along with timing information. Trace detail page A parent span might not depend on the result of the child. This is called a FollowsFrom reference, see Open Tracing Semantic Spec . Note that the last span that writes the response after the root span ends falls into this category. You can examine span details by clicking on the span row. Refer to the image below, which shows the security span details, including timing information. You can see times for each space relative to the root span. These rows are annotated with Server Start and Server Finish , as shown in the third column. Span detail page Enable Tracing on CDI Beans So far in this tutorial you have used tracing with JAX-RS without needing to annotate. You can enable tracing on other CDI beans, either at the class level or at the method level, as shown by the following examples. Tracing at the Method Level To trace at the method level, you just annotate a method with @Traced. <markup lang=\"java\" title=\"Update the GreetingProvider class; 1) Add a new import and 2) Add the @Traced annotation to the getMessage method:\" >import org.eclipse.microprofile.opentracing.Traced; ... @Traced String getMessage() { return message.get(); } ... Import the Traced annotation. Enable tracing for getMessage. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints and check the response:\" >curl http://localhost:8080/greet curl -X GET \"http://localhost:9411/api/v2/spans?serviceName=helidon-mp-1\" -H \"accept: application/json\" ... [ \"content-read\", \"content-write\", \"dosomework\", \"get:io.helidon.examples.quickstart.mp.greetresource.getdefaultmessage\", \"io.helidon.examples.quickstart.mp.greetingprovider.getmessage\", \"security\", \"security:atn\", \"security:atz\", \"security:response\" ] There is new span name for the getmessage method, since your code called that method during the invocation of /greet . Click the back button on your browser, then click on the UI refresh button to see the new trace. Select the newest trace in the list to see the trace detail page like the one below. Notice the new span named io.helidon.examples.quickstart.mp.greetingprovider.getmessage . Trace detail page with new span getmessage Tracing at the Class Level To trace at the class level, annotate the class with @Traced. This will enable tracing for all class methods, except for the constructor and private methods. <markup lang=\"java\" title=\"Update the GreetingProvider class; 1) Add @Traced to the GreetingProvider class and 2) Remove @Traced from the getMessage method:\" >@Traced @ApplicationScoped public class GreetingProvider { ... String getMessage() { return message.get(); } This will enable tracing for all class methods, except for the constructor and methods that are private. Remove @Traced for the getMessage method. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints and check the response:\" >curl http://localhost:8080/greet curl -X GET \"http://localhost:9411/api/v2/spans?serviceName=helidon-mp-1\" -H \"accept: application/json\" [ ... \"io.helidon.examples.quickstart.mp.greetingprovider.getmessage\", ... ] The service has the same set of span names as above, since getmessage was the only method called in this bean. Next, invoke HTTP PUT to change the greeting, which will cause setMessage to be called. <markup lang=\"bash\" >Invoke the endpoints and check the response: ---- curl -i -X PUT -H \"Content-Type: application/json\" -d '{\"greeting\": \"Hi\"}' http://localhost:8080/greet/greeting curl -X GET \"http://localhost:9411/api/v2/spans?serviceName=helidon-mp-1\" -H \"accept: application/json\" ... [ \"content-read\", \"content-write\", \"get:io.helidon.examples.quickstart.mp.greetresource.getdefaultmessage\", \"io.helidon.examples.quickstart.mp.greetingprovider.getmessage\", \"io.helidon.examples.quickstart.mp.greetingprovider.setmessage\", \"put:io.helidon.examples.quickstart.mp.greetresource.updategreeting\", \"security\", \"security:atn\", \"security:atz\", \"security:response\" ] ---- &lt;1&gt; Invoke the endpoint to change the greeting. &lt;2&gt; The `GreetingProvider.setmessage` method was traced since you enabled class level tracing. &lt;3&gt; The JAX-RS method `GreetResource.updategreeting` was traced automatically by Helidon. You can refresh the UI view and drill down the trace to see the new spans. Methods invoked directly by your code are not enabled for tracing, even if you explicitly annotate them with @Traced. Tracing only works for methods invoked on CDI beans. See the example below. <markup lang=\"java\" title=\"Update the GreetingProvider class with the following code:\" >@ApplicationScoped public class GreetingProvider { private final AtomicReference&lt;String&gt; message = new AtomicReference&lt;&gt;(); @Inject public GreetingProvider(@ConfigProperty(name = \"app.greeting\") String message) { this.message.set(message); } @Traced String getMessage() { return getMessage2(); } @Traced String getMessage2() { return message.get(); } void setMessage(String message) { this.message.set(message); } } The getMessage method will be traced since it is externally invoked by GreetResource . The getMessage2 method will not be traced, even with the @Traced annotation, since it is called internally by getMessage . <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints and check the response:\" >curl http://localhost:8080/greet curl -X GET \"http://localhost:9411/api/v2/spans?serviceName=helidon-mp-1\" -H \"accept: application/json\" ... [ ... \"io.helidon.examples.quickstart.mp.greetingprovider.getmessage\", ... ] The getMessage method is traced, but getMessage2 is not. Trace Across Services Helidon automatically traces across services as long as the services use the same tracer, for example, the same instance of Zipkin. This means a single trace can include spans from multiple services and hosts. OpenTracing uses a SpanContext to propagate tracing information across process boundaries. When you make client API calls, Helidon will internally call OpenTracing APIs to propagate the SpanContext . There is nothing you need to do in your application to make this work. To demonstrate distributed tracing, you will need to create a second project, where the server listens on port 8081. Create a new root directory to hold this new project, then do the following steps, similar to what you did at the start of this guide: Create a second service <markup lang=\"bash\" title=\"Run the Maven archetype:\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-mp \\ -DarchetypeVersion=2.5.4 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-mp-2 \\ -Dpackage=io.helidon.examples.quickstart.mp <markup lang=\"bash\" title=\"The project will be built and run from the helidon-quickstart-mp directory:\" >cd helidon-quickstart-mp-2 <markup lang=\"xml\" title=\"Add the following dependency to pom.xml :\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-zipkin&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"bash\" title=\"Replace META-INF/microprofile-config.properties with the following:\" >app.greeting=Hello From MP-2 tracing.service=helidon-mp-2 # Microprofile server properties server.port=8081 server.host=0.0.0.0 <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-mp-2.jar <markup lang=\"bash\" title=\"Run the curl command in a new terminal window and check the response ( notice the port is 8081 ) :\" >curl http://localhost:8081/greet ... { \"message\": \"Hello From MP-2 World!\" } Modify the first service Once you have validated that the second service is running correctly, you need to modify the original application to call it. <markup lang=\"java\" title=\"Replace the GreetResource class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import javax.enterprise.context.RequestScoped; import javax.inject.Inject; import javax.json.Json; import javax.json.JsonBuilderFactory; import javax.json.JsonObject; import javax.ws.rs.GET; import javax.ws.rs.Path; import javax.ws.rs.Produces; import javax.ws.rs.client.WebTarget; import javax.ws.rs.core.MediaType; import org.glassfish.jersey.server.Uri; @Path(\"/greet\") @RequestScoped public class GreetResource { @Uri(\"http://localhost:8081/greet\") private WebTarget target; private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); private final GreetingProvider greetingProvider; @Inject public GreetResource(GreetingProvider greetingConfig) { this.greetingProvider = greetingConfig; } @SuppressWarnings(\"checkstyle:designforextension\") @GET @Produces(MediaType.APPLICATION_JSON) public JsonObject getDefaultMessage() { return createResponse(\"World\"); } @GET @Path(\"/outbound\") public JsonObject outbound() { return target.request().accept(MediaType.APPLICATION_JSON_TYPE).get(JsonObject.class); } private JsonObject createResponse(String who) { String msg = String.format(\"%s %s!\", greetingProvider.getMessage(), who); return JSON.createObjectBuilder().add(\"message\", msg).build(); } } This is the WebTarget needed to send a request to the second service at port 8081 . This is the new endpoint that will call the second service. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl -i http://localhost:8080/greet/outbound ... { \"message\": \"Hello From MP-2 World!\" } The request went to the service on 8080 , which then invoked the service at 8081 to get the greeting. Notice the greeting came from the second service. Refresh the Zipkin UI trace listing page and notice that there is a trace across two services. Tracing multiple service list view Click on the trace with two services to see the detail view. Tracing across multiple services detail view In the image above, you can see that the trace includes spans from two services. You will notice there is a gap before the sixth span, which is a get operation. This is a one-time client initialization delay. Run the /outbound curl command again and look at the new trace to see that the delay no longer exists. You can now stop your second service, it is no longer used in this guide. ",
            "title": "Getting Started with Tracing"
        },
        {
            "location": "/mp/guides/06_tracing",
            "text": "<markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named zipkin.yaml , with the following contents:\" >apiVersion: v1 kind: Service metadata: name: zipkin spec: ports: - port: 9411 protocol: TCP selector: app: zipkin --- kind: Pod apiVersion: v1 metadata: name: zipkin labels: app: zipkin spec: containers: - name: zipkin image: openzipkin/zipkin imagePullPolicy: IfNotPresent ports: - containerPort: 9411 <markup lang=\"bash\" title=\"Create the Zipkin pod and ClusterIP service:\" >kubectl apply -f ./zipkin.yaml <markup lang=\"bash\" title=\"Create a Zipkin external server and expose it on port 9142:\" >kubectl expose pod zipkin --name=zipkin-external --port=9412 --target-port=9411 --type=LoadBalancer Create a service so that you can access the Zipkin UI. Navigate to http://localhost:9412/zipkin to validate that you can access Zipkin running in Kubernetes. It may take a few seconds before it is ready. ",
            "title": "Deploy Zipkin into Kubernetes"
        },
        {
            "location": "/mp/guides/06_tracing",
            "text": "<markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named tracing.yaml , with the following contents:\" >kind: Service apiVersion: v1 metadata: name: helidon-tracing labels: app: helidon-tracing spec: type: NodePort selector: app: helidon-tracing ports: - port: 8080 targetPort: 8080 name: http --- kind: Deployment apiVersion: apps/v1 metadata: name: helidon-tracing spec: replicas: 1 selector: matchLabels: app: helidon-tracing template: metadata: labels: app: helidon-tracing version: v1 spec: containers: - name: helidon-tracing image: helidon-tracing-mp imagePullPolicy: IfNotPresent ports: - containerPort: 8080 A service of type NodePort that serves the default routes on port 8080 . A deployment with one replica of a pod. <markup lang=\"bash\" title=\"Create and deploy the application into Kubernetes:\" >kubectl apply -f ./tracing.yaml ",
            "title": "Deploy Your Helidon Application into Kubernetes"
        },
        {
            "location": "/mp/guides/06_tracing",
            "text": "<markup lang=\"bash\" title=\"Get the application service information:\" >kubectl get service/helidon-tracing <markup lang=\"bash\" >NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE helidon-tracing NodePort 10.99.159.2 &lt;none&gt; 8080:31143/TCP 8s A service of type NodePort that serves the default routes on port 31143 . <markup lang=\"bash\" title=\"Verify the tracing endpoint using port 31143 , your port will likely be different:\" >curl http://localhost:31143/greet ... { \"message\": \"Hello World!\" } Access the Zipkin UI at http://localhost:9412/zipkin and click on the refresh icon to see the trace that was just created. ",
            "title": "Access Your Application and the Zipkin Trace"
        },
        {
            "location": "/mp/guides/06_tracing",
            "text": " You can now delete the Kubernetes resources that were just created during this example. <markup lang=\"bash\" title=\"Delete the Kubernetes resources:\" >kubectl delete -f ./zipkin.yaml kubectl delete -f ./tracing.yaml kubectl delete service zipkin-external docker rm -f zipkin ",
            "title": "Cleanup"
        },
        {
            "location": "/mp/guides/06_tracing",
            "text": " The following example demonstrate how to use Zipkin from a Helidon application running in Kubernetes. <markup lang=\"bash\" title=\"Add the following line to META-INF/microprofile-config.properties :\" >tracing.host=zipkin <markup lang=\"bash\" title=\"Stop the application and build the docker image for your application:\" >docker build -t helidon-tracing-mp . Deploy Zipkin into Kubernetes <markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named zipkin.yaml , with the following contents:\" >apiVersion: v1 kind: Service metadata: name: zipkin spec: ports: - port: 9411 protocol: TCP selector: app: zipkin --- kind: Pod apiVersion: v1 metadata: name: zipkin labels: app: zipkin spec: containers: - name: zipkin image: openzipkin/zipkin imagePullPolicy: IfNotPresent ports: - containerPort: 9411 <markup lang=\"bash\" title=\"Create the Zipkin pod and ClusterIP service:\" >kubectl apply -f ./zipkin.yaml <markup lang=\"bash\" title=\"Create a Zipkin external server and expose it on port 9142:\" >kubectl expose pod zipkin --name=zipkin-external --port=9412 --target-port=9411 --type=LoadBalancer Create a service so that you can access the Zipkin UI. Navigate to http://localhost:9412/zipkin to validate that you can access Zipkin running in Kubernetes. It may take a few seconds before it is ready. Deploy Your Helidon Application into Kubernetes <markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named tracing.yaml , with the following contents:\" >kind: Service apiVersion: v1 metadata: name: helidon-tracing labels: app: helidon-tracing spec: type: NodePort selector: app: helidon-tracing ports: - port: 8080 targetPort: 8080 name: http --- kind: Deployment apiVersion: apps/v1 metadata: name: helidon-tracing spec: replicas: 1 selector: matchLabels: app: helidon-tracing template: metadata: labels: app: helidon-tracing version: v1 spec: containers: - name: helidon-tracing image: helidon-tracing-mp imagePullPolicy: IfNotPresent ports: - containerPort: 8080 A service of type NodePort that serves the default routes on port 8080 . A deployment with one replica of a pod. <markup lang=\"bash\" title=\"Create and deploy the application into Kubernetes:\" >kubectl apply -f ./tracing.yaml Access Your Application and the Zipkin Trace <markup lang=\"bash\" title=\"Get the application service information:\" >kubectl get service/helidon-tracing <markup lang=\"bash\" >NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE helidon-tracing NodePort 10.99.159.2 &lt;none&gt; 8080:31143/TCP 8s A service of type NodePort that serves the default routes on port 31143 . <markup lang=\"bash\" title=\"Verify the tracing endpoint using port 31143 , your port will likely be different:\" >curl http://localhost:31143/greet ... { \"message\": \"Hello World!\" } Access the Zipkin UI at http://localhost:9412/zipkin and click on the refresh icon to see the trace that was just created. Cleanup You can now delete the Kubernetes resources that were just created during this example. <markup lang=\"bash\" title=\"Delete the Kubernetes resources:\" >kubectl delete -f ./zipkin.yaml kubectl delete -f ./tracing.yaml kubectl delete service zipkin-external docker rm -f zipkin ",
            "title": "Integration with Kubernetes"
        },
        {
            "location": "/mp/guides/06_tracing",
            "text": " This guide has demonstrated how to use the Helidon MP tracing feature with Zipkin. You have learned to do the following: Enable tracing within a service Use tracing with JAX-RS and CDI beans Use the Zipkin REST API and UI Use tracing across multiple services Integrate tracing with Kubernetes Refer to the following references for additional information: MicroProfile OpenTracing specification at https://github.com/eclipse/microprofile-opentracing/releases/tag/1.3 MicroProfile OpenTracing Javadoc at https://javadoc.io/doc/org.eclipse.microprofile.opentracing/microprofile-opentracing-api/1.3 Helidon Javadoc at https://helidon.io/docs/latest/apidocs/index.html?overview-summary.html ",
            "title": "Summary"
        },
        {
            "location": "/se/config/09_config-profiles",
            "text": " Configuration profiles provide a capability to prepare structure of configuration for each environment in advance, and then simply switch between these structures using a system property or an environment variable. ",
            "title": "preambule"
        },
        {
            "location": "/se/config/09_config-profiles",
            "text": " To choose a configuration profile to use at runtime, you can use: A system property config.profile An environment variable HELIDON_CONFIG_PROFILE There are two ways to define a profile configuration: Use a config source with a profile specific name Use a profile file defining all configuration sources Configuration profiles can only be used when config is created using the Config.create() method without parameters. If you explicitly configure sources, profiles are ignored. ",
            "title": "Profile options"
        },
        {
            "location": "/se/config/09_config-profiles",
            "text": " If a profile is specified, config will load the profile-specific default configuration source before the \"main\" source. Let&#8217;s consider the selected profile is dev , and we have yaml configuration support on classpath; config will look for the following sources (in this order): application-dev.yaml on file system application-dev.properties on file system application-dev.yaml on classpath application-dev.properties on classpath application.yaml on file system application.properties on file system application.yaml on classpath application.properties on classpath ",
            "title": "Profile Config Sources"
        },
        {
            "location": "/se/config/09_config-profiles",
            "text": " The config system supports these built-in types: Built-in Types Type Use Related ConfigSources Method Required Properties system-properties System properties are a config source ConfigSources.systemProperties() n/a environment-variables Environment variables are a config source ConfigSources.environmentVariables() n/a classpath Specified resource is used as a config source ConfigSources.classpath(String) resource - path to the resource to load file Specified file is used as a config source ConfigSources.file(Path) path - path to the file to load directory Each file in directory used as config entry, with key = file name and value = file contents ConfigSources.directory(String) path - path to the directory to use url Specified URL is read as a config source ConfigSources.url(URL) url - URL from which to load the config inlined The whole configuration tree under properties is added as a configuration source (excluding the properties node) n/a n/a prefixed Associated config source is loaded with the specified prefix ConfigSources.prefixed(String,Supplier) key - key of config element in associated source to load type - associated config source specification properties - as needed to further qualify the associated config source Except for the system-properties and environment-variables types, the profile properties section for a source can also specify any optional settings for the corresponding config source type. The JavaDoc for the related config source type builders lists the supported properties for each type. (For example, FileConfigSource.FileBuilder .) Here is an example profile in YAML format. Note how the properties sections are at the same level as the type or class within a sources array entry. <markup lang=\"yaml\" title=\"Profile config-profile.yaml illustrating all built-in sources available on the classpath\" >caching.enabled: false sources: - type: \"system-properties\" - type: \"environment-variables\" - type: \"directory\" properties: path: \"conf/secrets\" media-type-mapping: yaml: \"application/x-yaml\" password: \"application/base64\" polling-strategy: type: \"regular\" properties: interval: \"PT15S\" - type: \"url\" properties: url: \"http://config-service/my-config\" media-type: \"application/hocon\" optional: true retry-policy: type: \"repeat\" properties: retries: 3 - type: \"file\" properties: optional: true path: \"conf/env.yaml\" change-watcher: type: \"file\" properties: delay-millis: 5000 - type: \"prefixed\" properties: key: \"app\" type: \"classpath\" properties: resource: \"app.conf\" - type: \"classpath\" properties: resource: \"application.conf\" Note that the example shows how your profile can configure optional features such as polling strategies and retry policies for config sources. ",
            "title": "Built-in Types"
        },
        {
            "location": "/se/config/09_config-profiles",
            "text": " Profiles can be used to set up custom config sources as well as the built-in ones described above. Implement the ConfigSourceProvider <markup lang=\"java\" >public class MyConfigSourceProvider implements ConfigSourceProvider { private static final String TYPE = \"my-type\"; @Override public boolean supports(String type) { return TYPE.equals(type); } @Override public ConfigSource create(String type, Config metaConfig) { // as we only support one in this implementation, we can just return it return MyConfigSource.create(metaConfig); } @Override public Set&lt;String&gt; supported() { return Collections.singleton(TYPE); } } Register it as a java service loader service <markup title=\"File META-INF/services/io.helidon.config.spi.ConfigSourceProvider \" >io.helidon.examples.MyConfigSourceProvider And in module-info.java if using JPMS: <markup lang=\"java\" title=\"File module-info.java \" >provides io.helidon.config.spi.ConfigSourceProvider with io.helidon.examples.MyConfigSourceProvider Now you can use the following profile: <markup lang=\"yaml\" >sources: - type: \"system-properties\" - type: \"environment-variables\" - type: \"my-type\" properties: my-property: \"some-value\" Note that it is the io.helidon.config.AbstractConfigSource class that provides support for polling strategies, change watchers, and retry policies. If you create custom config sources that should also offer this support be sure they extend AbstractConfigSource and implement appropriate SPI interfaces (such as io.helidon.config.spi.WatchableSource ) to support such features. ",
            "title": "Support for Custom Sources"
        },
        {
            "location": "/se/config/09_config-profiles",
            "text": " Your config profile can include the set-up for polling strategies, change watchers, and retry policies if the config source supports them. Declare them in a way similar to how you declare the config sources themselves: by type and with accompanying properties . Config Profile Support for Built-in Polling Strategies Strategy Type Usage Properties regular Periodic polling - See PollingStrategies.regular method interval ( Duration ) - indicating how often to poll; e.g., PT15S represents 15 seconds Config Profile Support for Built-in Change Watchers Type Usage Properties file Filesystem monitoring - See PollingStrategies.watch method initial-delay-millis - delay between the start of the watcher and first check for changes Config Profile Support for Built-in Retry Policies Policy Type Usage Properties repeat Regularly-scheduled - see RetryPolicies.repeat . retries ( int ) - number of retries to perform Optional: delay ( Duration ) - initial delay between retries delay-factor ( double ) - delay is repeatedly multiplied by this each retry to compute the delay for each successive retry call-timeout ( Duration ) - timeout for a single invocation to load the source overall-timeout ( Duration ) - total timeout for all retry calls and delays To specify a custom polling strategy or custom retry policy, implement the interface ( io.helidon.config.spi.PollingStrategy , io.helidon.config.spi.ChangeWatcher , or io.helidon.config.spi.RetryPolicy ), and then implement the provider interface ( io.helidon.config.spi.PollingStrategyProvider , io.helidon.config.spi.ChangeWatcherProvider , or io.helidon.config.spi.RetryPolicyProvider ) to enable your custom implementations for profiles. You can then use any custom properties - these are provided as a Config instance to the create method of the Provider implementation. See RetryPolicy , ChangeWatcher , and PollingStrategy JavaDoc sections. ",
            "title": "Support for Custom Polling Strategies, Change Watchers, and Retry Policies"
        },
        {
            "location": "/se/config/09_config-profiles",
            "text": " Configuration profile provides similar options to the configuration builder. The profile file must contain at least the list of sources from which configuration can be loaded. The root sources property contains an array (ordered) of objects defining each config source to be used. Each element of the array must contain at least the type property, determining the config source type (such as system-properties , file ). It may also contain a properties property with additional configuration of the config source. An example development profile using \"inlined\" configuration: <markup lang=\"yaml\" title=\"Config profile config-profile-dev.yaml \" >sources: - type: \"inlined\" properties: app.greeting: \"Hello World\" An example of a profile using environment variables, system properties, classpath, and file configuration: <markup lang=\"yaml\" title=\"Config profile config-profile-prod.yaml \" >sources: - type: \"environment-variables\" - type: \"system-properties\" - type: \"file\" properties: path: \"config/config-prod.yaml\" - type: \"classpath\" properties: resource: \"application.yaml\" Built-in Types The config system supports these built-in types: Built-in Types Type Use Related ConfigSources Method Required Properties system-properties System properties are a config source ConfigSources.systemProperties() n/a environment-variables Environment variables are a config source ConfigSources.environmentVariables() n/a classpath Specified resource is used as a config source ConfigSources.classpath(String) resource - path to the resource to load file Specified file is used as a config source ConfigSources.file(Path) path - path to the file to load directory Each file in directory used as config entry, with key = file name and value = file contents ConfigSources.directory(String) path - path to the directory to use url Specified URL is read as a config source ConfigSources.url(URL) url - URL from which to load the config inlined The whole configuration tree under properties is added as a configuration source (excluding the properties node) n/a n/a prefixed Associated config source is loaded with the specified prefix ConfigSources.prefixed(String,Supplier) key - key of config element in associated source to load type - associated config source specification properties - as needed to further qualify the associated config source Except for the system-properties and environment-variables types, the profile properties section for a source can also specify any optional settings for the corresponding config source type. The JavaDoc for the related config source type builders lists the supported properties for each type. (For example, FileConfigSource.FileBuilder .) Here is an example profile in YAML format. Note how the properties sections are at the same level as the type or class within a sources array entry. <markup lang=\"yaml\" title=\"Profile config-profile.yaml illustrating all built-in sources available on the classpath\" >caching.enabled: false sources: - type: \"system-properties\" - type: \"environment-variables\" - type: \"directory\" properties: path: \"conf/secrets\" media-type-mapping: yaml: \"application/x-yaml\" password: \"application/base64\" polling-strategy: type: \"regular\" properties: interval: \"PT15S\" - type: \"url\" properties: url: \"http://config-service/my-config\" media-type: \"application/hocon\" optional: true retry-policy: type: \"repeat\" properties: retries: 3 - type: \"file\" properties: optional: true path: \"conf/env.yaml\" change-watcher: type: \"file\" properties: delay-millis: 5000 - type: \"prefixed\" properties: key: \"app\" type: \"classpath\" properties: resource: \"app.conf\" - type: \"classpath\" properties: resource: \"application.conf\" Note that the example shows how your profile can configure optional features such as polling strategies and retry policies for config sources. Support for Custom Sources Profiles can be used to set up custom config sources as well as the built-in ones described above. Implement the ConfigSourceProvider <markup lang=\"java\" >public class MyConfigSourceProvider implements ConfigSourceProvider { private static final String TYPE = \"my-type\"; @Override public boolean supports(String type) { return TYPE.equals(type); } @Override public ConfigSource create(String type, Config metaConfig) { // as we only support one in this implementation, we can just return it return MyConfigSource.create(metaConfig); } @Override public Set&lt;String&gt; supported() { return Collections.singleton(TYPE); } } Register it as a java service loader service <markup title=\"File META-INF/services/io.helidon.config.spi.ConfigSourceProvider \" >io.helidon.examples.MyConfigSourceProvider And in module-info.java if using JPMS: <markup lang=\"java\" title=\"File module-info.java \" >provides io.helidon.config.spi.ConfigSourceProvider with io.helidon.examples.MyConfigSourceProvider Now you can use the following profile: <markup lang=\"yaml\" >sources: - type: \"system-properties\" - type: \"environment-variables\" - type: \"my-type\" properties: my-property: \"some-value\" Note that it is the io.helidon.config.AbstractConfigSource class that provides support for polling strategies, change watchers, and retry policies. If you create custom config sources that should also offer this support be sure they extend AbstractConfigSource and implement appropriate SPI interfaces (such as io.helidon.config.spi.WatchableSource ) to support such features. Support for Custom Polling Strategies, Change Watchers, and Retry Policies Your config profile can include the set-up for polling strategies, change watchers, and retry policies if the config source supports them. Declare them in a way similar to how you declare the config sources themselves: by type and with accompanying properties . Config Profile Support for Built-in Polling Strategies Strategy Type Usage Properties regular Periodic polling - See PollingStrategies.regular method interval ( Duration ) - indicating how often to poll; e.g., PT15S represents 15 seconds Config Profile Support for Built-in Change Watchers Type Usage Properties file Filesystem monitoring - See PollingStrategies.watch method initial-delay-millis - delay between the start of the watcher and first check for changes Config Profile Support for Built-in Retry Policies Policy Type Usage Properties repeat Regularly-scheduled - see RetryPolicies.repeat . retries ( int ) - number of retries to perform Optional: delay ( Duration ) - initial delay between retries delay-factor ( double ) - delay is repeatedly multiplied by this each retry to compute the delay for each successive retry call-timeout ( Duration ) - timeout for a single invocation to load the source overall-timeout ( Duration ) - total timeout for all retry calls and delays To specify a custom polling strategy or custom retry policy, implement the interface ( io.helidon.config.spi.PollingStrategy , io.helidon.config.spi.ChangeWatcher , or io.helidon.config.spi.RetryPolicy ), and then implement the provider interface ( io.helidon.config.spi.PollingStrategyProvider , io.helidon.config.spi.ChangeWatcherProvider , or io.helidon.config.spi.RetryPolicyProvider ) to enable your custom implementations for profiles. You can then use any custom properties - these are provided as a Config instance to the create method of the Provider implementation. See RetryPolicy , ChangeWatcher , and PollingStrategy JavaDoc sections. ",
            "title": "Profile File Format"
        },
        {
            "location": "/se/config/09_config-profiles",
            "text": " If a profile is specified, config will look for a profile-specific \"meta configuration\". Let&#8217;s consider the selected profile is dev , and we have yaml configuration support on classpath; config will look for the following profiles (in this order): config-profile-dev.yaml on file system config-profile-dev.properties on file system config-profile-dev.yaml on classpath config-profile-dev.properties on classpath If any of these files is discovered, it would be used to set up the configuration. In case none is found, the config falls back to profile specific config sources . The structure of the file is described below in profile file format . In case you need to customize the location of the profile file, you can use the system property io.helidon.config.meta-config . For example if it is configured to config/profile.yaml , config looks for file config/profile-dev.yaml when dev profile is configured. Profile File Format Configuration profile provides similar options to the configuration builder. The profile file must contain at least the list of sources from which configuration can be loaded. The root sources property contains an array (ordered) of objects defining each config source to be used. Each element of the array must contain at least the type property, determining the config source type (such as system-properties , file ). It may also contain a properties property with additional configuration of the config source. An example development profile using \"inlined\" configuration: <markup lang=\"yaml\" title=\"Config profile config-profile-dev.yaml \" >sources: - type: \"inlined\" properties: app.greeting: \"Hello World\" An example of a profile using environment variables, system properties, classpath, and file configuration: <markup lang=\"yaml\" title=\"Config profile config-profile-prod.yaml \" >sources: - type: \"environment-variables\" - type: \"system-properties\" - type: \"file\" properties: path: \"config/config-prod.yaml\" - type: \"classpath\" properties: resource: \"application.yaml\" Built-in Types The config system supports these built-in types: Built-in Types Type Use Related ConfigSources Method Required Properties system-properties System properties are a config source ConfigSources.systemProperties() n/a environment-variables Environment variables are a config source ConfigSources.environmentVariables() n/a classpath Specified resource is used as a config source ConfigSources.classpath(String) resource - path to the resource to load file Specified file is used as a config source ConfigSources.file(Path) path - path to the file to load directory Each file in directory used as config entry, with key = file name and value = file contents ConfigSources.directory(String) path - path to the directory to use url Specified URL is read as a config source ConfigSources.url(URL) url - URL from which to load the config inlined The whole configuration tree under properties is added as a configuration source (excluding the properties node) n/a n/a prefixed Associated config source is loaded with the specified prefix ConfigSources.prefixed(String,Supplier) key - key of config element in associated source to load type - associated config source specification properties - as needed to further qualify the associated config source Except for the system-properties and environment-variables types, the profile properties section for a source can also specify any optional settings for the corresponding config source type. The JavaDoc for the related config source type builders lists the supported properties for each type. (For example, FileConfigSource.FileBuilder .) Here is an example profile in YAML format. Note how the properties sections are at the same level as the type or class within a sources array entry. <markup lang=\"yaml\" title=\"Profile config-profile.yaml illustrating all built-in sources available on the classpath\" >caching.enabled: false sources: - type: \"system-properties\" - type: \"environment-variables\" - type: \"directory\" properties: path: \"conf/secrets\" media-type-mapping: yaml: \"application/x-yaml\" password: \"application/base64\" polling-strategy: type: \"regular\" properties: interval: \"PT15S\" - type: \"url\" properties: url: \"http://config-service/my-config\" media-type: \"application/hocon\" optional: true retry-policy: type: \"repeat\" properties: retries: 3 - type: \"file\" properties: optional: true path: \"conf/env.yaml\" change-watcher: type: \"file\" properties: delay-millis: 5000 - type: \"prefixed\" properties: key: \"app\" type: \"classpath\" properties: resource: \"app.conf\" - type: \"classpath\" properties: resource: \"application.conf\" Note that the example shows how your profile can configure optional features such as polling strategies and retry policies for config sources. Support for Custom Sources Profiles can be used to set up custom config sources as well as the built-in ones described above. Implement the ConfigSourceProvider <markup lang=\"java\" >public class MyConfigSourceProvider implements ConfigSourceProvider { private static final String TYPE = \"my-type\"; @Override public boolean supports(String type) { return TYPE.equals(type); } @Override public ConfigSource create(String type, Config metaConfig) { // as we only support one in this implementation, we can just return it return MyConfigSource.create(metaConfig); } @Override public Set&lt;String&gt; supported() { return Collections.singleton(TYPE); } } Register it as a java service loader service <markup title=\"File META-INF/services/io.helidon.config.spi.ConfigSourceProvider \" >io.helidon.examples.MyConfigSourceProvider And in module-info.java if using JPMS: <markup lang=\"java\" title=\"File module-info.java \" >provides io.helidon.config.spi.ConfigSourceProvider with io.helidon.examples.MyConfigSourceProvider Now you can use the following profile: <markup lang=\"yaml\" >sources: - type: \"system-properties\" - type: \"environment-variables\" - type: \"my-type\" properties: my-property: \"some-value\" Note that it is the io.helidon.config.AbstractConfigSource class that provides support for polling strategies, change watchers, and retry policies. If you create custom config sources that should also offer this support be sure they extend AbstractConfigSource and implement appropriate SPI interfaces (such as io.helidon.config.spi.WatchableSource ) to support such features. Support for Custom Polling Strategies, Change Watchers, and Retry Policies Your config profile can include the set-up for polling strategies, change watchers, and retry policies if the config source supports them. Declare them in a way similar to how you declare the config sources themselves: by type and with accompanying properties . Config Profile Support for Built-in Polling Strategies Strategy Type Usage Properties regular Periodic polling - See PollingStrategies.regular method interval ( Duration ) - indicating how often to poll; e.g., PT15S represents 15 seconds Config Profile Support for Built-in Change Watchers Type Usage Properties file Filesystem monitoring - See PollingStrategies.watch method initial-delay-millis - delay between the start of the watcher and first check for changes Config Profile Support for Built-in Retry Policies Policy Type Usage Properties repeat Regularly-scheduled - see RetryPolicies.repeat . retries ( int ) - number of retries to perform Optional: delay ( Duration ) - initial delay between retries delay-factor ( double ) - delay is repeatedly multiplied by this each retry to compute the delay for each successive retry call-timeout ( Duration ) - timeout for a single invocation to load the source overall-timeout ( Duration ) - total timeout for all retry calls and delays To specify a custom polling strategy or custom retry policy, implement the interface ( io.helidon.config.spi.PollingStrategy , io.helidon.config.spi.ChangeWatcher , or io.helidon.config.spi.RetryPolicy ), and then implement the provider interface ( io.helidon.config.spi.PollingStrategyProvider , io.helidon.config.spi.ChangeWatcherProvider , or io.helidon.config.spi.RetryPolicyProvider ) to enable your custom implementations for profiles. You can then use any custom properties - these are provided as a Config instance to the create method of the Provider implementation. See RetryPolicy , ChangeWatcher , and PollingStrategy JavaDoc sections. ",
            "title": "Profile Files"
        },
        {
            "location": "/se/oci/02_object-storage",
            "text": " The Helidon SE OCI Object Storage integration provides a reactive API to files stored in Oracle cloud. ",
            "title": "preambule"
        },
        {
            "location": "/se/oci/02_object-storage",
            "text": " The custom Helidon SE OCI clients documented here are deprecated. It is recommended that you use the OCI Java SDK directly, in particular the Async clients. For more information see: OCI Object Storage Documentation OCI Object Storage Javadoc Helidon SE OCI Object Storage Example ",
            "title": "Deprecated"
        },
        {
            "location": "/se/oci/02_object-storage",
            "text": " Helidon integration with Oracle Cloud Infrastructure is still experimental and not intended for production use. APIs and features have not yet been fully tested and are subject to change. ",
            "title": "Experimental"
        },
        {
            "location": "/se/oci/02_object-storage",
            "text": " To enable OCI Object Storage add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.oci&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-oci-objectstorage&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/oci/02_object-storage",
            "text": " In order to use the OCI Object Storage integration, the following setup should be made: <markup lang=\"java\" >Config ociConfig = config.get(\"oci\"); OciObjectStorageRx ociObjectStorage = OciObjectStorageRx.create(ociConfig); Current configuration requires ~/.oci/config to be available in the home folder. This configuration file can be downloaded from OCI. Routing should be added to the WebServer , in our case pointing to /file : <markup lang=\"java\" >String bucketName = ociConfig.get(\"objectstorage\").get(\"bucket\").asString().get(); WebServer.builder() .config(config.get(\"server\")) .routing(Routing.builder() .register(\"/files\", new ObjectStorageService(ociObjectStorage, bucketName))) .build() .start() .await() Additionally, in application.yaml OCI properties should be specified: <markup lang=\"yaml\" >oci: properties: compartment-ocid: \"ocid&lt;1&gt;tenancy.oc&lt;1&gt;.&lt;..&gt;\" objectstorage-namespace: \"&lt;...&gt;\" objectstorage-bucket: \"&lt;...&gt;\" The exact values are available in OCI object storage and bucket properties. ",
            "title": "Setting up the Object Storage"
        },
        {
            "location": "/se/oci/02_object-storage",
            "text": " To upload a file to OCI Object Storage using the PUT method: <markup lang=\"java\" >private void upload(ServerRequest req, ServerResponse res) { OptionalLong contentLength = req.headers().contentLength(); if (contentLength.isEmpty()) { req.content().forEach(DataChunk::release); res.status(Http.Status.BAD_REQUEST_400).send(\"Content length must be defined\"); return; } String objectName = req.path().param(\"file-name\"); PutObject.Request request = PutObject.Request.builder() .objectName(objectName) .bucket(bucketName) .contentLength(contentLength.getAsLong()); req.headers().contentType().ifPresent(request::requestMediaType); objectStorage.putObject(request, req.content()) .forSingle(response -&gt; res.send(response.requestId())) .exceptionally(res::send); } Create the Request using PutObject.Request.builder() Define MediaType Execute the request to OCI in asynchronous way and put the result in response object ",
            "title": "Upload file"
        },
        {
            "location": "/se/oci/02_object-storage",
            "text": " To download a file from OCI Object Storage using the GET method: <markup lang=\"java\" >private void download(ServerRequest req, ServerResponse res) { String objectName = req.path().param(\"file-name\"); objectStorage.getObject(GetObject.Request.builder() .bucket(bucketName) .objectName(objectName)) .forSingle(apiResponse -&gt; { Optional&lt;GetObjectRx.Response&gt; entity = apiResponse.entity(); if (entity.isEmpty()) { res.status(Http.Status.NOT_FOUND_404).send(); } else { GetObjectRx.Response response = entity.get(); // copy the content length header to response apiResponse.headers() .first(Http.Header.CONTENT_LENGTH) .ifPresent(res.headers()::add); res.send(response.publisher()); } }) .exceptionally(res::send); } Use getObject function to make asynchronous request to OCI Object Storage The result is of type Optional Whenever the result is empty, return status 404 Get the response, set headers and return the result as a Publisher ",
            "title": "Download file"
        },
        {
            "location": "/se/oci/02_object-storage",
            "text": " To rename an existing file in the OCI bucket, submit a GET method with two parameters: <markup lang=\"java\" >private void rename(ServerRequest req, ServerResponse res) { String oldName = req.path().param(\"old-name\"); String newName = req.path().param(\"new-name\"); objectStorage.renameObject(RenameObject.Request.builder() .bucket(bucketName) .objectName(oldName) .newObjectName(newName)) .forSingle(it -&gt; res.send(\"Renamed to \" + newName)) .exceptionally(res::send); } Use renameObject function and configure a RenameObject.Request.builder() to submit the rename request The request is made in asynchronous way; a Single is returned ",
            "title": "Rename file"
        },
        {
            "location": "/se/oci/02_object-storage",
            "text": " Finally, to delete a file, DELETE request should be used: <markup lang=\"java\" >private void delete(ServerRequest req, ServerResponse res) { String objectName = req.path().param(\"file-name\"); objectStorage.deleteObject(DeleteObject.Request.builder() .bucket(bucketName) .objectName(objectName)) .forSingle(response -&gt; res.status(response.status()).send()) .exceptionally(res::send); } Use deleteObject function and configure a DeleteObject.Request.builder() to submit the delete request The request is made in asynchronous way; a Single is returned ",
            "title": "Delete file"
        },
        {
            "location": "/se/oci/02_object-storage",
            "text": " In the Service we must specify the mapping for CRUD operations with the files and their handlers: <markup lang=\"java\" >@Override public void update(Routing.Rules rules) { rules.get(\"/file/{file-name}\", this::download) .post(\"/file/{file-name}\", this::upload) .delete(\"/file/{file-name}\", this::delete) .get(\"/rename/{old-name}/{new-name}\", this::rename); } Upload file To upload a file to OCI Object Storage using the PUT method: <markup lang=\"java\" >private void upload(ServerRequest req, ServerResponse res) { OptionalLong contentLength = req.headers().contentLength(); if (contentLength.isEmpty()) { req.content().forEach(DataChunk::release); res.status(Http.Status.BAD_REQUEST_400).send(\"Content length must be defined\"); return; } String objectName = req.path().param(\"file-name\"); PutObject.Request request = PutObject.Request.builder() .objectName(objectName) .bucket(bucketName) .contentLength(contentLength.getAsLong()); req.headers().contentType().ifPresent(request::requestMediaType); objectStorage.putObject(request, req.content()) .forSingle(response -&gt; res.send(response.requestId())) .exceptionally(res::send); } Create the Request using PutObject.Request.builder() Define MediaType Execute the request to OCI in asynchronous way and put the result in response object Download file To download a file from OCI Object Storage using the GET method: <markup lang=\"java\" >private void download(ServerRequest req, ServerResponse res) { String objectName = req.path().param(\"file-name\"); objectStorage.getObject(GetObject.Request.builder() .bucket(bucketName) .objectName(objectName)) .forSingle(apiResponse -&gt; { Optional&lt;GetObjectRx.Response&gt; entity = apiResponse.entity(); if (entity.isEmpty()) { res.status(Http.Status.NOT_FOUND_404).send(); } else { GetObjectRx.Response response = entity.get(); // copy the content length header to response apiResponse.headers() .first(Http.Header.CONTENT_LENGTH) .ifPresent(res.headers()::add); res.send(response.publisher()); } }) .exceptionally(res::send); } Use getObject function to make asynchronous request to OCI Object Storage The result is of type Optional Whenever the result is empty, return status 404 Get the response, set headers and return the result as a Publisher Rename file To rename an existing file in the OCI bucket, submit a GET method with two parameters: <markup lang=\"java\" >private void rename(ServerRequest req, ServerResponse res) { String oldName = req.path().param(\"old-name\"); String newName = req.path().param(\"new-name\"); objectStorage.renameObject(RenameObject.Request.builder() .bucket(bucketName) .objectName(oldName) .newObjectName(newName)) .forSingle(it -&gt; res.send(\"Renamed to \" + newName)) .exceptionally(res::send); } Use renameObject function and configure a RenameObject.Request.builder() to submit the rename request The request is made in asynchronous way; a Single is returned Delete file Finally, to delete a file, DELETE request should be used: <markup lang=\"java\" >private void delete(ServerRequest req, ServerResponse res) { String objectName = req.path().param(\"file-name\"); objectStorage.deleteObject(DeleteObject.Request.builder() .bucket(bucketName) .objectName(objectName)) .forSingle(response -&gt; res.status(response.status()).send()) .exceptionally(res::send); } Use deleteObject function and configure a DeleteObject.Request.builder() to submit the delete request The request is made in asynchronous way; a Single is returned ",
            "title": "Using the Object Storage"
        },
        {
            "location": "/se/oci/02_object-storage",
            "text": " If your Helidon application depends on Object Storage accessibility, you may consider setting up a health check to verify connectivity with an OCI bucket. To do so, first add the following dependency in your pom file: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.oci&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-oci-objectstorage-health&lt;/artifactId&gt; &lt;/dependency&gt; In order to register the new health check in Helidon SE, create an instance of HealthSupport and configure it as shown next: <markup lang=\"java\" >HealthSupport health = HealthSupport.builder() .addLiveness(OciObjectStorageHealthCheck.builder() .ociObjectStorage(ociObjectStorage) .bucket(bucketName) .namespace(namespace) .build()) .build(); where ociObjectStorage , bucketName and namespace are as required for any other Object Storage access. Finally, include your newly created HealthSupport object as part of your application&#8217;s routing: <markup lang=\"java\" >Routing routing = Routing.builder() .register(health) // other routes here .build(); When executed, this health check will ping the bucket to make sure it is accessible in your environment. For more information about health checks see Health Checks . ",
            "title": "Object Storage Health Check"
        },
        {
            "location": "/mp/extensions/02_cdi_datasource-ucp",
            "text": " This CDI portable extension provides support for injecting Oracle Universal Connection Pool data sources in your Helidon MicroProfile applications. ",
            "title": "preambule"
        },
        {
            "location": "/mp/extensions/02_cdi_datasource-ucp",
            "text": " To enable Oracle UCP Support add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.cdi&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-cdi-datasource-ucp&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/extensions/02_cdi_datasource-ucp",
            "text": " The following examples show how to create a DataSource named orders in your application. <markup lang=\"java\" title=\"Field-injection example\" > @Inject @Named(\"orders\") private DataSource ordersDataSource; <markup lang=\"java\" title=\"Constructor-injection example\" > private final DataSource ds; @Inject public YourConstructor(@Named(\"orders\") DataSource ds) { super(); this.ds = ds; } The extension implements this injection point by creating a PoolDataSource object in the application scope . You can configure the object using MicroProfile config . For example, the data source created above can be configured as follows: <markup lang=\"properties\" title=\"META-INF/microprofile-config.properties\" >javax.sql.DataSource.orders.connectionFactoryClassName = oracle.jdbc.pool.OracleDataSource javax.sql.DataSource.orders.URL = jdbc:oracle:thin:@localhost:1521:ORCL javax.sql.DataSource.orders.user = sys as sysoper javax.sql.DataSource.orders.password = Oracle Property names that start with javax.sql.DataSource.dataSourceName. are parsed, and the remaining portion of each name is treated as a Java Bean property of the oracle.ucp.jdbc.PoolDataSource class. ",
            "title": "Injecting an Oracle Universal Connection Pool data source"
        },
        {
            "location": "/mp/guides/01_overview",
            "text": " Quickstart MP Create your first Helidon MP application in under 5 minutes. ",
            "title": "Getting Started"
        },
        {
            "location": "/mp/guides/01_overview",
            "text": " MP Config Guide Learn how to configure a Helidon MP application. MP Health Check Guide Learn how to use Helidon MP built-in and custom health checks. MP Metrics Guide Learn how to use Helidon MP built-in and application metrics. MP Tracing Guide Learn how to trace a Helidon MP application. Using DataSources Learn how to configure and use DataSources in your Helidon MP application. Using Transactions Learn how to configure and use Java Transaction API (JTA)-compliant transactions in your Helidon MP application. Using JPA Learn how to configure and use the Java Persistence API (JPA) in your Helidon MP application. Helidon MP Tutorial Learn how to build a Helidon MicroProfile (MP) application from scratch. ",
            "title": "Helidon MP Guides"
        },
        {
            "location": "/mp/guides/01_overview",
            "text": " Maven Guide Using Helidon in your Maven project. Gradle Guide Using Helidon in your Gradle project. GraalVM Native Images Learn how to build a GraalVM native image for your Helidon application both on your desktop and as part of a Docker image. Custom Runtime Images using jlink Learn how to build a custom runtime Java image for your Helidon application both on your desktop and as part of a Docker image. Building Container Images with Jib Learn how to use Jib to create a container image without Docker. Deploying to OKE Learn how to deploy your application to Oracle Cloud Infrastructure Container Engine for Kubernetes (OKE). ",
            "title": "Build and Deploy"
        },
        {
            "location": "/se/grpc/03_routing",
            "text": " Unlike Webserver, which allows you to route requests based on path expression and the HTTP verb, gRPC server always routes requests based on the service and method name. This makes routing configuration somewhat simpler&#8201;&#8212;&#8201;all you need to do is register your services: <markup lang=\"java\" > private static GrpcRouting createRouting(Config config) { return GrpcRouting.builder() .register(new GreetService(config)) .register(new EchoService()) .register(new MathService()) .build(); } Register GreetService instance. Register EchoService instance. Register MathService instance. Both \"standard\" gRPC services that implement io.grpc.BindableService interface (typically implemented by extending generated server-side stub and overriding its methods), and Helidon gRPC services that implement io.helidon.grpc.server.GrpcService interface can be registered. The difference is that Helidon gRPC services allow you to customize behavior down to the method level, and provide a number of useful helper methods that make service implementation easier, as we&#8217;ll see in a moment. ",
            "title": "gRPC Server Routing"
        },
        {
            "location": "/se/grpc/03_routing",
            "text": " When registering a service, regardless of its type, you can customize its descriptor by providing configuration consumer as a second argument to the register method. This is particularly useful when registering standard BindableService instances, as it allows you to add certain Helidon-specific behaviors, such as health checks and metrics to them: <markup lang=\"java\" > private static GrpcRouting createRouting(Config config) { return GrpcRouting.builder() .register(new GreetService(config)) .register(new EchoService(), service -&gt; { service.healthCheck(CustomHealthChecks::echoHealthCheck) .metered(); }) .build(); } Add custom health check to the service. Specify that all the calls to service methods should be metered. ",
            "title": "Customizing Service Definitions"
        },
        {
            "location": "/se/grpc/03_routing",
            "text": " GrpcRouting also allows you to specify custom interceptors that will be applied to all registered services. This is useful to configure features such as tracing, security and metrics collection, and we provide built-in interceptors for those purposes that you can simply register with the routing definition: <markup lang=\"java\" > private static GrpcRouting createRouting(Config config) { return GrpcRouting.builder() .intercept(GrpcMetrics.timed()) .register(new GreetService(config)) .register(new EchoService()) .register(new MathService()) .build(); } Register GrpcMetrics interceptor that will collect timers for all methods of all services (but can be overridden at the individual service or even method level). ",
            "title": "Specifying Global Interceptors"
        },
        {
            "location": "/se/webserver/13_http-compression",
            "text": " HTTP compression can improve bandwidth utilization and transfer speeds in certain scenarios. It requires a few extra CPU cycles for compressing and uncompressing, but these can be offset if data is transferred over low-bandwidth network links. A client advertises the compression encodings it supports at request time, and the WebServer responds by selecting an encoding it supports and setting it in a header, effectively negotiating the content encoding of the response. If none of the advertised encodings is supported by the WebServer, the response is returned uncompressed. ",
            "title": "preambule"
        },
        {
            "location": "/se/webserver/13_http-compression",
            "text": " HTTP compression in the Helidon WebServer is disabled by default. It can sometimes interfere with certain applications that use streaming, even if a compression encoding has not been negotiated with the client. It can be enabled either programmatically or via configuration, and it can also be enabled on a per-socket basis. When configured at the server level, it applies only to the default socket. Programmatically, simply use the enableCompression method during server creation: <markup lang=\"java\" > WebServer.builder() .port(8080) .routing(...) .enableCompression(true) // compression enabled .build() Or use a config file as follows and make sure the WebServer is created using it: <markup lang=\"yaml\" title=\"WebServer HTTP Compression configuration file application.yaml \" >server: port: 8080 enable-compression: true ",
            "title": "Configuring HTTP Compression"
        },
        {
            "location": "/se/webserver/13_http-compression",
            "text": " HTTP compression negotiation is controlled by clients using the Accept-Encoding header. The value of this header is a comma-separated list of encodings. The WebServer will select one of these encodings for compression purposes; it currently supports gzip and deflate . For example, if the request includes Accept-Encoding: gzip, deflate , and HTTP compression has been enabled as shown above, the response shall include the header Content-Encoding: gzip and a compressed payload. ",
            "title": "HTTP Compression Negotiation"
        },
        {
            "location": "/se/tracing/03_jaeger",
            "text": " Helidon is integrated with the Jaeger tracer. The Jaeger builder is loaded through ServiceLoader and configured. You could also use the Jaeger builder directly, though this would create a source-code dependency on the Jaeger tracer. ",
            "title": "preambule"
        },
        {
            "location": "/se/tracing/03_jaeger",
            "text": " To enable Jaeger Tracing add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-jaeger&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/tracing/03_jaeger",
            "text": " The Jaeger tracer supports the following configuration options: Key Default value Builder method Description service N/A serviceName Name of the service, to distinguish traces crossing service boundaries; Jaeger is using lower-case only, name will be automatically lower-cased protocol http collectorProtocol Protocol of the Jaeger trace collector ( udp , http or https ), to switch to agent mode, use udp host localhost collectorHost Host of the Jaeger trace collector (IP Address, hostname, or FQDN) port 14268 collectorPort Port of the Jaeger trace collector path /api/traces collectorPath Path of the Jaeger trace collector token N/A token Authentication token to use (token authentication) username N/A username User to authenticate (basic authentication) password N/A password Password of the user to authenticate (basic authentication) propagation library default addPropagation Propagation type ( jaeger or b3 ) log-spans library default logSpans Whether to log spans (boolean) max-queue-size library default maxQueueSize Maximal queue size of the reporter (int) flush-interval-ms library default flushInterval Reporter flush interval in milliseconds sampler-type library default samplerType Sampler type ( probabilistic , ratelimiting , remote ) sampler-param library default samplerParam Numeric parameter specifying details for the sampler type sampler-manager library default samplerManager Host and port of the sampler manager for remote type enabled true enabled If set to false, tracing would be disabled tags N/A addTracerTag(String, String) String tags to add to each span boolean-tags N/A addTracerTag(String, boolean) boolean tags to add to each span int-tags N/A addTracerTag(String, int) int tags to add to each span The following is an example of a Jaeger configuration, specified in the YAML format. <markup lang=\"yaml\" >tracing: service: \"helidon-full-http\" protocol: \"https\" # JAEGER_ENDPOINT (if not udp, http is expected and endpoint is filled) host: \"192.168.1.3\" # JAEGER_ENDPOINT port: 14240 # JAEGER_ENDPOINT path: \"/api/traces/mine\" # JAEGER_ENDPOINT token: \"token\" # JAEGER_AUTH_TOKEN # Either token or username/password #username: \"user\" # JAEGER_USER #password: \"pass\" # JAEGER_PASSWORD propagation: \"jaeger\" # JAEGER_PROPAGATION either \"jaeger\" or \"b3\" log-spans: false # JAEGER_REPORTER_LOG_SPANS max-queue-size: 42 # JAEGER_REPORTER_MAX_QUEUE_SIZE flush-interval-ms: 10001 # JAEGER_REPORTER_FLUSH_INTERVAL sampler-type: \"remote\"# JAEGER_SAMPLER_TYPE (https://www.jaegertracing.io/docs/latest/sampling/#client-sampling-configuration) sampler-param: 0.5 # JAEGER_SAMPLER_PARAM (number) sampler-manager: \"localhost:47877\" # JAEGER_SAMPLER_MANAGER_HOST_PORT tags: tag1: \"tag1-value\" # JAEGER_TAGS tag2: \"tag2-value\" # JAEGER_TAGS boolean-tags: tag3: true # JAEGER_TAGS tag4: false # JAEGER_TAGS int-tags: tag5: 145 # JAEGER_TAGS tag6: 741 # JAEGER_TAGS ",
            "title": "Configuring Jaeger"
        },
        {
            "location": "/se/tracing/03_jaeger",
            "text": " Jaeger tracks its own behavior using metrics. See Metrics Support for Jaeger to read how to integrate Jaeger metrics with Helidon. ",
            "title": "Integrating with Jaeger Tracing"
        },
        {
            "location": "/se/grpc/06_health_checks",
            "text": " Helidon gRPC services provide a built-in support for Helidon Health Checks. Unless a custom health check is implemented by the service developer, each service deployed to the gRPC server will be provisioned with a default health check, which always returns status of UP . This allows all services, including the ones that don&#8217;t have a meaningful health check, to show up in the health report (or to be queried for health) without service developer having to do anything. However, services that do need custom health checks can easily define one, directly within GrpcService implementation: <markup lang=\"java\" >public class MyService implements GrpcService { @Override public void update(ServiceDescriptor.Rules rules) { rules.unary(\"MyMethod\", this::myMethod) .healthCheck(this::healthCheck); } private HealthCheckResponse healthCheck() { boolean fUp = isMyServiceUp(); return HealthCheckResponse .named(name()) .state(fUp) .withData(\"ts\", System.currentTimeMillis()) .build(); } private &lt;ReqT, ResT&gt; void myMethod(ReqT request, StreamObserver&lt;ResT&gt; observer) { // do something } } Configure a custom health check for the service Determine service status Use service name as a health check name for consistency Use determined service status Optionally, provide additional metadata You can also define custom health check for an existing service, including plain io.grpc.BindableService implementations, using service configurer inside the GrpcRouting deefinition: <markup lang=\"java\" >private static GrpcRouting createRouting() { return GrpcRouting.builder() .register(new EchoService(), cfg -&gt; cfg.healthCheck(MyCustomHealthChecks::echoHealthCheck)) .build(); } Configure custom health check for an existing or legacy service ",
            "title": "Service Health Checks"
        },
        {
            "location": "/se/grpc/06_health_checks",
            "text": " All gRPC service health checks are managed by the Helidon gRPC Server, and are automatically exposed to the gRPC clients using custom implementation of the standard gRPC HealthService API. However, they can also be exposed to REST clients via standard Helidon/Microprofile /health endpoint: <markup lang=\"java\" > GrpcServer grpcServer = GrpcServer.create(grpcServerConfig(), createRouting(config)); grpcServer.start(); HealthSupport health = HealthSupport.builder() .add(grpcServer.healthChecks()) .build(); Routing routing = Routing.builder() .register(health) .build(); WebServer.create(webServerConfig(), routing).start(); Create GrpcServer instance Start gRPC server, which will deploy all services and register default and custom health checks Add gRPC server managed health checks to HealthSupport instance Add HealthSupport to the web server routing definition Create and start web server All gRPC health checks will now be available via /health REST endpoint, in addition to the standard gRPC HealthService ",
            "title": "Exposing Health Checks"
        },
        {
            "location": "/mp/guides/09_jpa",
            "text": " This guide shows how to configure and use the Java Persistence API (JPA) from within a Helidon MP application. ",
            "title": "preambule"
        },
        {
            "location": "/mp/guides/09_jpa",
            "text": " For this 30 minute tutrial, you&#8217;ll need the following: <div class=\"table__overflow elevation-1 flex sm7 \"> A Helidon {upper-case-flavor} Application You can use your own application or use the Helidon {upper-case-flavor} Quickstart to create a sample application. Java&#160;SE&#160;11 ( Open&#160;JDK&#160;11 ) Helidon requires Java 11+. Maven 3.6.1+ Helidon requires Maven 3.6.1+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop ). curl (Optional) for testing <markup lang=\"bash\" title=\"Verify Prerequisites\" >java -version mvn --version docker --version kubectl version --short <markup lang=\"bash\" title=\"Setting JAVA_HOME\" ># On Mac export JAVA_HOME=`/usr/libexec/java_home -v 11` # On Linux # Use the appropriate path to your JDK export JAVA_HOME=/usr/lib/jvm/jdk-11 ",
            "title": "What You Need"
        },
        {
            "location": "/mp/guides/09_jpa",
            "text": " By following this guide, you’ll enhance a bare-bones Helidon MP application to use JPA, with automatic transaction support, backed by EclipseLink , to access an in-memory H2 database . You’ll see how to install the relevant dependencies and add JPA-related code to your application. This guide assumes that you have read the following: An understanding of named data source support in Helidon MP and An understanding of transaction support in Helidon MP . ",
            "title": "Overview"
        },
        {
            "location": "/mp/guides/09_jpa",
            "text": " Add the following dependency in your pom.xml : <markup lang=\"xml\" title=\" pom.xml \" >&lt;dependency&gt; &lt;groupId&gt;com.h2database&lt;/groupId&gt; &lt;artifactId&gt;h2&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; In a production application, you may use a different database, so in that case you may add a different database driver dependency here instead. ",
            "title": "Add the H2 Database Driver to the Runtime Classpath"
        },
        {
            "location": "/mp/guides/09_jpa",
            "text": " Add the following dependency in your pom.xml : <markup lang=\"xml\" title=\" pom.xml \" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.cdi&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-cdi-datasource-hikaricp&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; ",
            "title": "Add the Hikari Connection Pool Extension to the Runtime Classpath"
        },
        {
            "location": "/mp/guides/09_jpa",
            "text": " Add the following dependency in your pom.xml : <markup lang=\"xml\" title=\" pom.xml \" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.cdi&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-cdi-jta-weld&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; ",
            "title": "Add the JTA Extension to the Runtime Classpath"
        },
        {
            "location": "/mp/guides/09_jpa",
            "text": " Add the following dependency in your pom.xml : <markup lang=\"xml\" title=\" pom.xml \" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.cdi&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-cdi-jpa&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; ",
            "title": "Add the Provider-Independent Helidon JPA Extension to the Runtime Classpath"
        },
        {
            "location": "/mp/guides/09_jpa",
            "text": " Add the following dependency in your pom.xml : <markup lang=\"xml\" title=\" pom.xml \" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.cdi&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-cdi-eclipselink&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; ",
            "title": "Add the EclipseLink JPA Extension to the Runtime Classpath"
        },
        {
            "location": "/mp/guides/09_jpa",
            "text": " Add the following dependencies in your pom.xml : <markup lang=\"xml\" title=\" pom.xml \" >&lt;dependency&gt; &lt;groupId&gt;jakarta.persistence&lt;/groupId&gt; &lt;artifactId&gt;jakarta.persistence-api&lt;/artifactId&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;jakarta.transaction&lt;/groupId&gt; &lt;artifactId&gt;jakarta.transaction-api&lt;/artifactId&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; ",
            "title": "Add the JTA and JPA Dependencies to the Provided Classpath"
        },
        {
            "location": "/mp/guides/09_jpa",
            "text": " Add the following file under src/main/resources : <markup lang=\"sql\" title=\" src/main/resources/greeting.ddl \" >CREATE TABLE IF NOT EXISTS GREETING ( SALUTATION VARCHAR(64) NOT NULL PRIMARY KEY, RESPONSE VARCHAR(64) NOT NULL ); MERGE INTO GREETING (SALUTATION, RESPONSE) VALUES ('Marco', 'Polo'); ",
            "title": "Add DDL to Create the Relevant Database Tables"
        },
        {
            "location": "/mp/guides/09_jpa",
            "text": " Replace the contents of the following file under src/main/resources : <markup lang=\"yaml\" title=\" src/main/resources/application.yaml \" >server: port: 8080 javax: sql: DataSource: greetingDataSource: dataSourceClassName: org.h2.jdbcx.JdbcDataSource dataSource: url: jdbc:h2:mem:greeting;INIT=RUNSCRIPT FROM 'classpath:greeting.ddl' user: sa password: \"\" The H2 INIT property tells H2 what command to run upon starting up. In this case, it is going to load and run the DDL mentioned above. ",
            "title": "Add an application.yaml File With Database Connectivity Information"
        },
        {
            "location": "/mp/guides/09_jpa",
            "text": " Add the following Java class under src/main/java/io/helidon/example/jpa : <markup lang=\"java\" title=\" src/main/java/io/helidon/example/jpa/Greeting.java \" >package io.helidon.example.jpa; import java.io.Serializable; import java.util.Objects; import javax.persistence.Access; import javax.persistence.AccessType; import javax.persistence.Basic; import javax.persistence.Column; import javax.persistence.Entity; import javax.persistence.Id; import javax.persistence.Table; @Access(value = AccessType.FIELD) @Entity(name = \"Greeting\") @Table(name = \"GREETING\") public class Greeting implements Serializable { @Column( insertable = true, name = \"SALUTATION\", nullable = false, updatable = false ) @Id private String salutation; @Basic(optional = false) @Column( insertable = true, name = \"RESPONSE\", nullable = false, updatable = true ) private String response; @Deprecated protected Greeting() { super(); } public Greeting(String salutation, String response) { super(); this.salutation = Objects.requireNonNull(salutation); this.setResponse(response); } public String getSalutation() { return this.salutation; } public String getResponse() { return this.response; } public void setResponse(String response) { this.response = Objects.requireNonNull(response); } @Override public String toString() { return this.getSalutation() + \" \" + this.getResponse(); } } (Some of the annotations in this example, like this one, have sensible defaults, but the example specifies them explicitly for clarity.) This Access annotation says that JPA will access this class' fields directly, rather than via getter and setter methods. The Entity annotation identifies this class as a JPA entity. The name element value can be used in JPQL queries. The Table annotation identifies the database table to which this class will be mapped. JPA entities should be Serializable . The Column annotation specifies what column in the database the annotated field maps to. The elements of the Column annotation further describe the column. The Id annotation indicates this field will be mapped to the primary key of the database table. The Basic annotation indicates this field will be mapped to an ordinary (\"basic\") column. All JPA entities need a zero-argument constructor, but it doesn&#8217;t have to be public . This constructor satisfies this requirement. It is marked Deprecated and is non- public so that normal users have to supply data for the salutation and response fields via the other constructor. This is the constructor normal users will use. ",
            "title": "Add a Java Class to Represent a Greeting JPA Entity"
        },
        {
            "location": "/mp/guides/09_jpa",
            "text": " Add the following file under src/main/resources/META-INF : <markup lang=\"xml\" title=\" src/main/resources/META-INF/persistence.xml \" >&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;persistence version=\"2.2\" xmlns=\"http://xmlns.jcp.org/xml/ns/persistence\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://xmlns.jcp.org/xml/ns/persistence http://xmlns.jcp.org/xml/ns/persistence/persistence_2_2.xsd\"&gt; &lt;persistence-unit name=\"greeting\" transaction-type=\"JTA\"&gt; &lt;description&gt;A persistence unit for the greeting example.&lt;/description&gt; &lt;jta-data-source&gt;greetingDataSource&lt;/jta-data-source&gt; &lt;class&gt;io.helidon.example.jpa.Greeting&lt;/class&gt; &lt;properties&gt; &lt;property name=\"eclipselink.deploy-on-startup\" value=\"true\"/&gt; &lt;property name=\"eclipselink.jdbc.native-sql\" value=\"true\"/&gt; &lt;property name=\"eclipselink.logging.logger\" value=\"JavaLogger\"/&gt; &lt;property name=\"eclipselink.logging.parameters\" value=\"true\"/&gt; &lt;property name=\"eclipselink.target-database\" value=\"org.eclipse.persistence.platform.database.H2Platform\"/&gt; &lt;property name=\"eclipselink.target-server\" value=\"io.helidon.integrations.cdi.eclipselink.CDISEPlatform\"/&gt; &lt;property name=\"eclipselink.weaving\" value=\"false\"/&gt; &lt;/properties&gt; &lt;/persistence-unit&gt; &lt;/persistence&gt; Helidon MP&#8217;s JPA extension supports JPA 2.2. Note that JTA is the transaction type. JTA transactions are fully supported. Note that the name of the data source is the one configured in the application.yaml file described earlier. The Greeting class you created is listed here. The properties listed here are in general EclipseLink properties . Many are optional, but a few (detailed below) are required. This property is required when EclipseLink is the JPA provider. It is set to org.eclipse.persistence.platform.database.H2Platform because this example uses the H2 database. This property is required, and when EclipseLink is the JPA provider must have the value io.helidon.integrations.cdi.eclipselink.CDISEPlatform . This property is required when EclipseLink is the JPA provider and must be set to false . ",
            "title": "Add a META-INF/persistence.xml Descriptor"
        },
        {
            "location": "/mp/guides/09_jpa",
            "text": " Weaving is the term that describes the bytecode manipulation that JPA providers perform upon your simple Java entity classes (like the Greeting class you created above). In Helidon MicroProfile&#8217;s JPA extension, weaving must be performed statically (at build time). Here we modify the pom.xml to make that happen. Add the following plugin configuration in your pom.xml : <markup lang=\"xml\" title=\" pom.xml \" >&lt;plugin&gt; &lt;groupId&gt;com.ethlo.persistence.tools&lt;/groupId&gt; &lt;artifactId&gt;eclipselink-maven-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;weave&lt;/id&gt; &lt;phase&gt;process-classes&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;weave&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;execution&gt; &lt;id&gt;modelgen&lt;/id&gt; &lt;phase&gt;generate-sources&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;modelgen&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; Static weaving is performed on compiled classes in place. The JPA static metamodel is generated by this goal. ",
            "title": "Modify the pom.xml File To Support Static Weaving"
        },
        {
            "location": "/mp/guides/09_jpa",
            "text": " In a shell, cd into an empty directory and run this: <markup lang=\"bash\" >mvn -U archetype:generate \\ -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-bare-mp \\ -DarchetypeVersion=2.5.4 \\ -DgroupId=io.helidon.example \\ -DartifactId=helidon-jpa \\ -Dpackage=io.helidon.example.jpa Now cd into helidon-jpa . The rest of this guide will assume all relative paths are relative to this directory. Add the H2 Database Driver to the Runtime Classpath Add the following dependency in your pom.xml : <markup lang=\"xml\" title=\" pom.xml \" >&lt;dependency&gt; &lt;groupId&gt;com.h2database&lt;/groupId&gt; &lt;artifactId&gt;h2&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; In a production application, you may use a different database, so in that case you may add a different database driver dependency here instead. Add the Hikari Connection Pool Extension to the Runtime Classpath Add the following dependency in your pom.xml : <markup lang=\"xml\" title=\" pom.xml \" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.cdi&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-cdi-datasource-hikaricp&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; Add the JTA Extension to the Runtime Classpath Add the following dependency in your pom.xml : <markup lang=\"xml\" title=\" pom.xml \" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.cdi&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-cdi-jta-weld&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; Add the Provider-Independent Helidon JPA Extension to the Runtime Classpath Add the following dependency in your pom.xml : <markup lang=\"xml\" title=\" pom.xml \" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.cdi&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-cdi-jpa&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; Add the EclipseLink JPA Extension to the Runtime Classpath Add the following dependency in your pom.xml : <markup lang=\"xml\" title=\" pom.xml \" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.cdi&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-cdi-eclipselink&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; Add the JTA and JPA Dependencies to the Provided Classpath Add the following dependencies in your pom.xml : <markup lang=\"xml\" title=\" pom.xml \" >&lt;dependency&gt; &lt;groupId&gt;jakarta.persistence&lt;/groupId&gt; &lt;artifactId&gt;jakarta.persistence-api&lt;/artifactId&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;jakarta.transaction&lt;/groupId&gt; &lt;artifactId&gt;jakarta.transaction-api&lt;/artifactId&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; Add DDL to Create the Relevant Database Tables Add the following file under src/main/resources : <markup lang=\"sql\" title=\" src/main/resources/greeting.ddl \" >CREATE TABLE IF NOT EXISTS GREETING ( SALUTATION VARCHAR(64) NOT NULL PRIMARY KEY, RESPONSE VARCHAR(64) NOT NULL ); MERGE INTO GREETING (SALUTATION, RESPONSE) VALUES ('Marco', 'Polo'); Add an application.yaml File With Database Connectivity Information Replace the contents of the following file under src/main/resources : <markup lang=\"yaml\" title=\" src/main/resources/application.yaml \" >server: port: 8080 javax: sql: DataSource: greetingDataSource: dataSourceClassName: org.h2.jdbcx.JdbcDataSource dataSource: url: jdbc:h2:mem:greeting;INIT=RUNSCRIPT FROM 'classpath:greeting.ddl' user: sa password: \"\" The H2 INIT property tells H2 what command to run upon starting up. In this case, it is going to load and run the DDL mentioned above. Add a Java Class to Represent a Greeting JPA Entity Add the following Java class under src/main/java/io/helidon/example/jpa : <markup lang=\"java\" title=\" src/main/java/io/helidon/example/jpa/Greeting.java \" >package io.helidon.example.jpa; import java.io.Serializable; import java.util.Objects; import javax.persistence.Access; import javax.persistence.AccessType; import javax.persistence.Basic; import javax.persistence.Column; import javax.persistence.Entity; import javax.persistence.Id; import javax.persistence.Table; @Access(value = AccessType.FIELD) @Entity(name = \"Greeting\") @Table(name = \"GREETING\") public class Greeting implements Serializable { @Column( insertable = true, name = \"SALUTATION\", nullable = false, updatable = false ) @Id private String salutation; @Basic(optional = false) @Column( insertable = true, name = \"RESPONSE\", nullable = false, updatable = true ) private String response; @Deprecated protected Greeting() { super(); } public Greeting(String salutation, String response) { super(); this.salutation = Objects.requireNonNull(salutation); this.setResponse(response); } public String getSalutation() { return this.salutation; } public String getResponse() { return this.response; } public void setResponse(String response) { this.response = Objects.requireNonNull(response); } @Override public String toString() { return this.getSalutation() + \" \" + this.getResponse(); } } (Some of the annotations in this example, like this one, have sensible defaults, but the example specifies them explicitly for clarity.) This Access annotation says that JPA will access this class' fields directly, rather than via getter and setter methods. The Entity annotation identifies this class as a JPA entity. The name element value can be used in JPQL queries. The Table annotation identifies the database table to which this class will be mapped. JPA entities should be Serializable . The Column annotation specifies what column in the database the annotated field maps to. The elements of the Column annotation further describe the column. The Id annotation indicates this field will be mapped to the primary key of the database table. The Basic annotation indicates this field will be mapped to an ordinary (\"basic\") column. All JPA entities need a zero-argument constructor, but it doesn&#8217;t have to be public . This constructor satisfies this requirement. It is marked Deprecated and is non- public so that normal users have to supply data for the salutation and response fields via the other constructor. This is the constructor normal users will use. Add a META-INF/persistence.xml Descriptor Add the following file under src/main/resources/META-INF : <markup lang=\"xml\" title=\" src/main/resources/META-INF/persistence.xml \" >&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;persistence version=\"2.2\" xmlns=\"http://xmlns.jcp.org/xml/ns/persistence\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://xmlns.jcp.org/xml/ns/persistence http://xmlns.jcp.org/xml/ns/persistence/persistence_2_2.xsd\"&gt; &lt;persistence-unit name=\"greeting\" transaction-type=\"JTA\"&gt; &lt;description&gt;A persistence unit for the greeting example.&lt;/description&gt; &lt;jta-data-source&gt;greetingDataSource&lt;/jta-data-source&gt; &lt;class&gt;io.helidon.example.jpa.Greeting&lt;/class&gt; &lt;properties&gt; &lt;property name=\"eclipselink.deploy-on-startup\" value=\"true\"/&gt; &lt;property name=\"eclipselink.jdbc.native-sql\" value=\"true\"/&gt; &lt;property name=\"eclipselink.logging.logger\" value=\"JavaLogger\"/&gt; &lt;property name=\"eclipselink.logging.parameters\" value=\"true\"/&gt; &lt;property name=\"eclipselink.target-database\" value=\"org.eclipse.persistence.platform.database.H2Platform\"/&gt; &lt;property name=\"eclipselink.target-server\" value=\"io.helidon.integrations.cdi.eclipselink.CDISEPlatform\"/&gt; &lt;property name=\"eclipselink.weaving\" value=\"false\"/&gt; &lt;/properties&gt; &lt;/persistence-unit&gt; &lt;/persistence&gt; Helidon MP&#8217;s JPA extension supports JPA 2.2. Note that JTA is the transaction type. JTA transactions are fully supported. Note that the name of the data source is the one configured in the application.yaml file described earlier. The Greeting class you created is listed here. The properties listed here are in general EclipseLink properties . Many are optional, but a few (detailed below) are required. This property is required when EclipseLink is the JPA provider. It is set to org.eclipse.persistence.platform.database.H2Platform because this example uses the H2 database. This property is required, and when EclipseLink is the JPA provider must have the value io.helidon.integrations.cdi.eclipselink.CDISEPlatform . This property is required when EclipseLink is the JPA provider and must be set to false . Modify the pom.xml File To Support Static Weaving Weaving is the term that describes the bytecode manipulation that JPA providers perform upon your simple Java entity classes (like the Greeting class you created above). In Helidon MicroProfile&#8217;s JPA extension, weaving must be performed statically (at build time). Here we modify the pom.xml to make that happen. Add the following plugin configuration in your pom.xml : <markup lang=\"xml\" title=\" pom.xml \" >&lt;plugin&gt; &lt;groupId&gt;com.ethlo.persistence.tools&lt;/groupId&gt; &lt;artifactId&gt;eclipselink-maven-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;weave&lt;/id&gt; &lt;phase&gt;process-classes&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;weave&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;execution&gt; &lt;id&gt;modelgen&lt;/id&gt; &lt;phase&gt;generate-sources&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;modelgen&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; Static weaving is performed on compiled classes in place. The JPA static metamodel is generated by this goal. ",
            "title": "Use the Maven Archetype to Generate a Helidon MP Application"
        },
        {
            "location": "/mp/guides/09_jpa",
            "text": " In the src/main/java/io/helidon/example/jpa/GreetResource.java file, add the following imports: <markup lang=\"java\" title=\" src/main/java/io/helidon/example/jpa/GreetResource.java \" >import javax.enterprise.context.Dependent; import javax.persistence.EntityManager; import javax.persistence.PersistenceContext; Annotate the resource class declaration with @Dependent : <markup lang=\"java\" title=\" src/main/java/io/helidon/example/jpa/GreetResource.java \" >@Dependent public class GreetResource { This ensures that io.helidon.example.jpa.GreetResource is a discoverable CDI bean, because it is an example of a bean-defining annotation . Then add the following annotated field declaration: <markup lang=\"java\" title=\" src/main/java/io/helidon/example/jpa/GreetResource.java \" >@PersistenceContext private EntityManager em; The @PersistenceContext annotation indicates that you want an EntityManager injected here. ",
            "title": "Inject a Container-Managed EntityManager "
        },
        {
            "location": "/mp/guides/09_jpa",
            "text": " In the src/main/java/io/helidon/example/jpa/GreetResource.java file, add the following import: <markup lang=\"java\" title=\" src/main/java/io/helidon/example/jpa/GreetResource.java \" >import javax.transaction.Transactional; import javax.ws.rs.PathParam; Add the following resource method to the GreetResource class: <markup lang=\"java\" title=\" src/main/java/io/helidon/example/jpa/GreetResource.java \" >@GET @Path(\"response/{salutation}\") @Produces(\"text/plain\") @Transactional public String getResponse(@PathParam(\"salutation\") String salutation) { final Greeting greeting = this.em.find(Greeting.class, salutation); final String returnValue; if (greeting == null) { returnValue = null; } else { returnValue = greeting.getResponse(); } return returnValue; } A JTA transaction will be automatically started at the beginning of this method when it is invoked as a result of an incoming HTTP request, and committed or rolled back when the method terminates normally or exceptionally. The injected EntityManager will join the transaction automatically. ",
            "title": "Use the Injected EntityManager "
        },
        {
            "location": "/mp/guides/09_jpa",
            "text": " Add the following content to the logging.properties file under src/main/resources : <markup lang=\"properties\" title=\" src/main/resources/logging.properties \" >com.zaxxer.hikari.level=INFO h2database.level=WARNING io.netty.level=INFO org.eclipse.persistence.level=FINE org.glassfish.jersey.server.level=CONFIG ",
            "title": "Add Logging"
        },
        {
            "location": "/mp/guides/09_jpa",
            "text": " Execute the following from the root directory of your application: <markup lang=\"bash\" >mvn package ",
            "title": "Build the Application"
        },
        {
            "location": "/mp/guides/09_jpa",
            "text": " Execute the following from the root directory of your application: <markup lang=\"bash\" >java -jar target/helidon-jpa.jar ",
            "title": "Run the Application"
        },
        {
            "location": "/mp/guides/09_jpa",
            "text": " Execute the following: <markup lang=\"bash\" >curl http://localhost:8080/greet/response/Marco Observe that Polo is returned. ",
            "title": "Test the Application"
        },
        {
            "location": "/se/graphql/01_introduction",
            "text": " Helidon GraphQL Server provides a framework for creating GraphQL applications. ",
            "title": "preambule"
        },
        {
            "location": "/se/graphql/01_introduction",
            "text": " The Helidon GraphQL feature is currently experimental and the APIs are subject to changes until GraphQL support is stabilized. ",
            "title": "Experimental"
        },
        {
            "location": "/se/graphql/01_introduction",
            "text": " To enable GraphQL add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.graphql&lt;/groupId&gt; &lt;artifactId&gt;helidon-graphql-server&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/graphql/01_introduction",
            "text": " Here is the code for a minimalist GraphQL application that exposes 2 queries. <markup lang=\"java\" > public static void main(String[] args) { WebServer server = WebServer.builder() .routing(Routing.builder() .register(GraphQlSupport.create(buildSchema())) .build()) .build(); server.start() .thenApply(webServer -&gt; { String endpoint = \"http://localhost:\" + webServer.port(); System.out.println(\"GraphQL started on \" + endpoint + \"/graphql\"); System.out.println(\"GraphQL schema availanle on \" + endpoint + \"/graphql/schema.graphql\"); return null; }); } private static GraphQLSchema buildSchema() { String schema = \"type Query{\" + \"hello: String \" + \"helloInDifferentLanguages: [String] \" + \"}\"; SchemaParser schemaParser = new SchemaParser(); TypeDefinitionRegistry typeDefinitionRegistry = schemaParser.parse(schema); // DataFetcher to return various hello's in difference languages DataFetcher&lt;List&lt;String&gt;&gt; hellosDataFetcher = (DataFetcher&lt;List&lt;String&gt;&gt;) environment -&gt; List.of(\"Bonjour\", \"Hola\", \"Zdravstvuyte\", \"Nǐn hǎo\", \"Salve\", \"Gudday\", \"Konnichiwa\", \"Guten Tag\"); RuntimeWiring runtimeWiring = RuntimeWiring.newRuntimeWiring() .type(\"Query\", builder -&gt; builder.dataFetcher(\"hello\", new StaticDataFetcher(\"world\"))) .type(\"Query\", builder -&gt; builder.dataFetcher(\"helloInDifferentLanguages\", hellosDataFetcher)) .build(); SchemaGenerator schemaGenerator = new SchemaGenerator(); return schemaGenerator.makeExecutableSchema(typeDefinitionRegistry, runtimeWiring); } Register GraphQL support. Start the server. Define the GraphQL schema. Create a DataFetcher to return a List of Hellos in different languages. Wire up the DataFetchers. Generate the GraphQL schema. The example above deploys a very simple service exposing the /graphql endpoint. You can then probe the endpoints: Hello word endpoint <markup lang=\"bash\" >curl -X POST http://127.0.0.1:PORT/graphql -d '{\"query\":\"query { hello }\"}' \"data\":{\"hello\":\"world\"}} Hello in different languages <markup lang=\"bash\" >curl -X POST http://127.0.0.1:PORT/graphql -d '{\"query\":\"query { helloInDifferentLanguages }\"}' {\"data\":{\"helloInDifferentLanguages\":[\"Bonjour\",\"Hola\",\"Zdravstvuyte\",\"Nǐn hǎo\",\"Salve\",\"Gudday\",\"Konnichiwa\",\"Guten Tag\"]}} ",
            "title": "Quick Start"
        },
        {
            "location": "/about/01_overview",
            "text": " explore Helidon SE A set of reactive, non-blocking libraries. explore Helidon MP Microprofile implementation. ",
            "title": "Components"
        },
        {
            "location": "/about/01_overview",
            "text": " arrow_circle_up Get Started Get started with Helidon. library_books Javadocs Browse the Helidon Javadocs. ",
            "title": "Get Going"
        },
        {
            "location": "/mp/guides/25_maven_build",
            "text": " This guide describes Helidon&#8217;s support for Maven projects. ",
            "title": "preambule"
        },
        {
            "location": "/mp/guides/25_maven_build",
            "text": " Helidon supports Maven by providing the following: The Helidon Application parent POM Dependency management via the Helidon BOM and Dependencies POMs The helidon-maven-plugin ",
            "title": "Introduction"
        },
        {
            "location": "/mp/guides/25_maven_build",
            "text": " Helidon examples and projects generated using the Helidon Quickstart use a Helidon application POM as their parent. This parent POM provides the following: Helidon dependency management. Maven plugin configurations to help in the building and packaging of your Helidon application. If you want to use your own parent POM, then take a look at the standalone quickstart example . This example has a stand-alone POM that you can pattern your own application POM after. For more details on Helidon application POMs see the Helidon&#8217;s Application POMS ",
            "title": "The Helidon Application POM"
        },
        {
            "location": "/mp/guides/25_maven_build",
            "text": " In Maven you use Dependency Management to manage the versions of the dependencies used by your project so that you do not need to specify versions when declaring project dependencies. Helidon provides two POMs that are used together for dependency management: The Helidon Bill of Materials (BOM) POM ( io.helidon:helidon-bom ): manages the version of Helidon artifacts (to align with the Helidon version). The Helidon Dependencies POM ( io.helidon:helidon-dependencies ): manages the versions of third party dependencies to ensure consistency across Helidon and your Helidon application. Inherits the Helidon BOM POM. When you use a Helidon Application POM as your project&#8217;s parent pom, you inherit Helidon&#8217;s dependency management. If you have your own parent, then you can import Helidon dependency management like this: <markup lang=\"xml\" title=\"Import Helidon Dependency Management\" >&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon&lt;/groupId&gt; &lt;artifactId&gt;helidon-dependencies&lt;/artifactId&gt; &lt;version&gt;2.5.4&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; You then declare dependencies on Helidon (and other) components without specifying a version. <markup lang=\"xml\" title=\"Component dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webserver&lt;/groupId&gt; &lt;artifactId&gt;helidon-webserver&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Dependency Management"
        },
        {
            "location": "/mp/guides/25_maven_build",
            "text": " You can override many of the plugin attributes by passing a system property to the mvn command: <markup >mvn -Djlink.image.addClassDataSharingArchive=false ... ",
            "title": "Pass Property on Command Line"
        },
        {
            "location": "/mp/guides/25_maven_build",
            "text": " Or you can set the properties in your project&#8217;s pom.xml: <markup >&lt;properties&gt; &lt;jlink.image.addClassDataSharingArchive&gt;false&lt;/jlink.image.addClassDataSharingArchive&gt; &lt;native.image.reportExceptionStackTraces&gt;true&lt;/native.image.reportExceptionStackTraces&gt; &lt;/properties&gt; ",
            "title": "Set Property in pom.xml"
        },
        {
            "location": "/mp/guides/25_maven_build",
            "text": " For full control you can override the plugin&#8217;s configuration using pluginManagement : <markup lang=\"xml\" title=\"Turn off generation of the CDS Archive when generating a custom Java runtime image\" > &lt;build&gt; &lt;pluginManagement&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;io.helidon.build-tools&lt;/groupId&gt; &lt;artifactId&gt;helidon-maven-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;jlink-image&lt;/id&gt; &lt;configuration&gt; &lt;addClassDataSharingArchive&gt;false&lt;/addClassDataSharingArchive&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;/build&gt; <markup lang=\"xml\" title=\"Override final name of native image binary\" > &lt;build&gt; &lt;pluginManagement&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;io.helidon.build-tools&lt;/groupId&gt; &lt;artifactId&gt;helidon-maven-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;native-image&lt;/id&gt; &lt;configuration&gt; &lt;finalName&gt;my-fantastic-service&lt;/finalName&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;/build&gt; ",
            "title": "Override Plugin Configuration using pluginManagement "
        },
        {
            "location": "/mp/guides/25_maven_build",
            "text": " Helidon provides a Maven plugin that, among other things, provides the following goals: native-image: Build a GraalVM native image . jlink-image: Build a custom runtime Java image . For full documentation of the plugin please see the Helidon Maven Plugin README . If you use the Helidon application parent POM you will have this plugin configured for you. If you need to customize the helidon-maven-plugin you can do so in a few ways: Passing system properties to Maven on the command line. Setting system properties in your project&#8217;s pom.xml Overriding the plugin configuration by using pluginManagment Pass Property on Command Line You can override many of the plugin attributes by passing a system property to the mvn command: <markup >mvn -Djlink.image.addClassDataSharingArchive=false ... Set Property in pom.xml Or you can set the properties in your project&#8217;s pom.xml: <markup >&lt;properties&gt; &lt;jlink.image.addClassDataSharingArchive&gt;false&lt;/jlink.image.addClassDataSharingArchive&gt; &lt;native.image.reportExceptionStackTraces&gt;true&lt;/native.image.reportExceptionStackTraces&gt; &lt;/properties&gt; Override Plugin Configuration using pluginManagement For full control you can override the plugin&#8217;s configuration using pluginManagement : <markup lang=\"xml\" title=\"Turn off generation of the CDS Archive when generating a custom Java runtime image\" > &lt;build&gt; &lt;pluginManagement&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;io.helidon.build-tools&lt;/groupId&gt; &lt;artifactId&gt;helidon-maven-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;jlink-image&lt;/id&gt; &lt;configuration&gt; &lt;addClassDataSharingArchive&gt;false&lt;/addClassDataSharingArchive&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;/build&gt; <markup lang=\"xml\" title=\"Override final name of native image binary\" > &lt;build&gt; &lt;pluginManagement&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;io.helidon.build-tools&lt;/groupId&gt; &lt;artifactId&gt;helidon-maven-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;native-image&lt;/id&gt; &lt;configuration&gt; &lt;finalName&gt;my-fantastic-service&lt;/finalName&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;/build&gt; ",
            "title": "The helidon-maven-plugin "
        },
        {
            "location": "/se/security/04_tools",
            "text": " Support for encrypting secrets in configuration files. <markup lang=\"xml\" title=\"Maven Dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.config&lt;/groupId&gt; &lt;artifactId&gt;helidon-config-encryption&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Secure configuration"
        },
        {
            "location": "/se/security/04_tools",
            "text": " Configuration support for accessing private keys, public keys, certificates and certificate chains including runtime access to instances of such. <markup lang=\"xml\" title=\"Maven Dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.common&lt;/groupId&gt; &lt;artifactId&gt;helidon-common-key-util&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Key and certificate configuration"
        },
        {
            "location": "/se/security/04_tools",
            "text": " Secure configuration Support for encrypting secrets in configuration files. <markup lang=\"xml\" title=\"Maven Dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.config&lt;/groupId&gt; &lt;artifactId&gt;helidon-config-encryption&lt;/artifactId&gt; &lt;/dependency&gt; Key and certificate configuration Configuration support for accessing private keys, public keys, certificates and certificate chains including runtime access to instances of such. <markup lang=\"xml\" title=\"Maven Dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.common&lt;/groupId&gt; &lt;artifactId&gt;helidon-common-key-util&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Tools"
        },
        {
            "location": "/mp/config/02_MP_config_sources",
            "text": " A Config Source provides configuration values from different sources such as property files and user classes that are registered by the application. Helidon configuration sources can use different formats for the configuration data. You can specify the format on a per-source bases, mixing and matching formats as required. The following configuration sources can be used to retrieve the configuration: Source Description System properties A mutable source that uses System.getProperties() to obtain configuration values. Environment variables An immutable source that uses System.env() to obtain configuration values and resolves aliases as defined by the MicroProfile Config specification. META-INF/microprofile-config.properties The properties config source as defined by MicroProfile Config specification. File Creates the source from a properties file on the file system with MpConfigSources.create(Path) . URL Creates the source from properties from an URL with MpConfigSources.create(URL) . Map&lt;String, String&gt; Creates the source from a Map with MpConfigSources.create(Map) . Properties Creates the source directly from Properties with MpConfigSources.create(Properties) . File on classpath Creates the source from a properties file on classpath with MpConfigSources.classpath(String) . YAML Creates the source from YAML using YamlMpConfigSource.create(Path) or YamlMpConfigSource.create(URL) . ",
            "title": "preambule"
        },
        {
            "location": "/mp/config/02_MP_config_sources",
            "text": " The default MicroProfile Config Sources are: System properties (ordinal=400) Environment variables (ordinal=300) /META-INF/microprofile-config.properties (ordinal=100) Each Config Source has an ordinal that determines the priority of the Config Source. A Config Source with higher ordinal has higher priority as compared to the Config Source with lower ordinal. The values taken from the high-priority Config Source overrides the values from low-priority Config Source. This helps to customize the configuration of Config Sources using external Config Source if an external Config Source has higher ordinal values than the built-in Config Sources of the application. ",
            "title": "Understanding the Ordering of Default Config Sources"
        },
        {
            "location": "/mp/config/02_MP_config_sources",
            "text": "<markup lang=\"java\" >public class CustomConfigSource implements ConfigSource { private static final String NAME = \"MyConfigSource\"; private static final int ORDINAL = 200; // Default for MP is 100 private static final Map&lt;String, String&gt; PROPERTIES = mapOf(\"app.greeting\", \"Hi\"); @Override public String getName() { return NAME; } @Override public Map&lt;String, String&gt; getProperties() { return PROPERTIES; } @Override public String getValue(String key) { return PROPERTIES.get(key); } @Override public int getOrdinal() { return ORDINAL; } } Returns the name of the Config Source to use for logging or analysis of configured values. Returns the properties in this Config Source as a map. Returns the value of the requested key, or null if the key is not available Returns the ordinal of this Config Source. ",
            "title": "Example of a Custom Config Source"
        },
        {
            "location": "/mp/config/02_MP_config_sources",
            "text": " Custom Config Sources are loaded using the Java Service Loader pattern, by implementing either org.eclipse.microprofile.config.spi.ConfigSource , or org.eclipse.microprofile.config.spi.ConfigSourceProvider SPI and registering it as a service (Using META-INF/services/${class-name} file when using classpath, or using the provides statement in module-info.java when using module path). The interface org.eclipse.microprofile.config.spi.ConfigSource requires implementation of the following methods: String getName() Map&lt;String, String&gt; getProperties() String getValue(String key) getOrdinal() Example of a Custom Config Source <markup lang=\"java\" >public class CustomConfigSource implements ConfigSource { private static final String NAME = \"MyConfigSource\"; private static final int ORDINAL = 200; // Default for MP is 100 private static final Map&lt;String, String&gt; PROPERTIES = mapOf(\"app.greeting\", \"Hi\"); @Override public String getName() { return NAME; } @Override public Map&lt;String, String&gt; getProperties() { return PROPERTIES; } @Override public String getValue(String key) { return PROPERTIES.get(key); } @Override public int getOrdinal() { return ORDINAL; } } Returns the name of the Config Source to use for logging or analysis of configured values. Returns the properties in this Config Source as a map. Returns the value of the requested key, or null if the key is not available Returns the ordinal of this Config Source. ",
            "title": "Creating Custom Config Sources"
        },
        {
            "location": "/mp/config/02_MP_config_sources",
            "text": " You can create Microprofile Config Source from a map. <markup lang=\"java\" title=\"Create MicroProfile Config Source based on Environment Variables and Custom Map\" >ConfigProviderResolver resolver = ConfigProviderResolver.instance(); org.eclipse.microprofile.config.Config config = resolver.getBuilder() .withSources(MpConfigSources.environmentVariables()) .withSources(MpConfigSources.create(Map.of(\"key\",\"value\"))) .build(); resolver.registerConfig(config, null); Creates MicroProfile Config Source builder. Adds environment variables. Adds a custom map. Builds the MicroProfile Config Source. Registers the config, so it can be used by other components ",
            "title": "Create Custom Map MicroProfile Config Source"
        },
        {
            "location": "/mp/config/02_MP_config_sources",
            "text": " You can create Yaml Microprofile Config Source from a path or a URL. When you create a MicroProfile instance from the builder, the YamlMpConfigSource allows you to create a custom Config Source and register it with the builder. <markup lang=\"java\" title=\"Create YamlMPConfigSource from a path\" >ConfigProviderResolver.instance().newBuilder() .withSources(YamlMpConfigSource.create(path)) .build(); ",
            "title": "Create Yaml MicroProfile Config Source"
        },
        {
            "location": "/mp/config/02_MP_config_sources",
            "text": " You can use the following methods to create MicroProfile Config Sources to manually set up the Config from org.eclipse.microprofile.config.spi.ConfigProviderResolver#getBuilder() on io.helidon.config.mp.MpConfigSources class: Method Description systemProperties() System properties config source. environmentVariables() Environment variables config source. create(java.nio.file.Path) Loads a properties file from file system. To load the properties file from file system with custom name, use create(String, java.nio.file.Path) . create(java.util.Map) Creates an in-memory source from map. To create an in-memory source from map with custom name, use create(String, java.util.Map) . create(java.util.Properties) Creates an in-memory source from properties. To create an in-memory source from properties with custom name, use create(String, java.util.Properties) . Create Custom Map MicroProfile Config Source You can create Microprofile Config Source from a map. <markup lang=\"java\" title=\"Create MicroProfile Config Source based on Environment Variables and Custom Map\" >ConfigProviderResolver resolver = ConfigProviderResolver.instance(); org.eclipse.microprofile.config.Config config = resolver.getBuilder() .withSources(MpConfigSources.environmentVariables()) .withSources(MpConfigSources.create(Map.of(\"key\",\"value\"))) .build(); resolver.registerConfig(config, null); Creates MicroProfile Config Source builder. Adds environment variables. Adds a custom map. Builds the MicroProfile Config Source. Registers the config, so it can be used by other components Create Yaml MicroProfile Config Source You can create Yaml Microprofile Config Source from a path or a URL. When you create a MicroProfile instance from the builder, the YamlMpConfigSource allows you to create a custom Config Source and register it with the builder. <markup lang=\"java\" title=\"Create YamlMPConfigSource from a path\" >ConfigProviderResolver.instance().newBuilder() .withSources(YamlMpConfigSource.create(path)) .build(); ",
            "title": "Creating MicroProfile Config Sources for Manual Setup of Config"
        },
        {
            "location": "/mp/config/02_MP_config_sources",
            "text": " Instead of directly specifying the configuration sources in your code, you can use meta-configuration in a file that declares the configuration sources, and their attributes as mentioned in Microprofile Config When used, the Microprofile Config uses configuration sources and flags configured in the meta configuration file. If a file named mp-meta-config.yaml , or mp-meta-config.properties is in the current directory or on the classpath, and there is no explicit setup of configuration in the code, the configuration will be loaded from the meta-config file. The location of the file can be overridden using system property io.helidon.config.mp.meta-config , or environment variable HELIDON_MP_META_CONFIG <markup lang=\"yaml\" title=\"Example of a YAML meta configuration file:\" >add-discovered-sources: true add-discovered-converters: false add-default-sources: false sources: - type: \"environment-variables\" - type: \"system-properties\" - type: \"properties\" path: \"/conf/prod.properties\" ordinal: 50 optional: true - type: \"yaml\" classpath: \"META-INF/database.yaml\" - type: \"hocon\" classpath: \"custom-application.conf\" - type: \"json\" path: \"path: conf/custom-application.json\" If configured to true , config sources discovered through service loader will be added If configured to true , converters discovered through service loader will be added If configured to true , default config sources (system properties, environment variables, and `META-INF/microprofile-config.properties) will be added Loads the environment variables config source. Loads the system properties config source. Loads a properties file Location of the file: /conf/prod.properties on the file system Custom ordinal, if not defined, the value defined in the file, or default value is used. The source precedence order is the order of appearance in the file. The file is optional (if not optional and no file is found, the bootstrap fails) Loads a YAML file Location of the file: META-INF/database.yaml on the classpath Loads a HOCON file Location of the file: custom-application.conf on the classpath Loads a JSON file Location of the file: conf/custom-application.json relative to the directory of where the app was executed on the file system. Important Note: To enable support for HOCON and JSON types, add the following dependency to your project’s pom.xml. <markup lang=\"xml\" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.config&lt;/groupId&gt; &lt;artifactId&gt;helidon-config-hocon-mp&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Creating MicroProfile Config Sources from meta-config"
        },
        {
            "location": "/mp/config/02_MP_config_sources",
            "text": "<markup lang=\"java\" >public class CustomMpMetaConfigProvider implements MpMetaConfigProvider { @Override public Set&lt;String&gt; supportedTypes() { return Set.of(\"custom\"); } @Override public List&lt;? extends ConfigSource&gt; create(String type, Config metaConfig, String profile) { ConfigValue&lt;Path&gt; pathConfig = metaConfig.get(\"path\").as(Path.class); if (pathConfig.isPresent()) { Path path = pathConfig.get(); List&lt;ConfigSource&gt; sources = sourceFromPath(path, profile); if (sources != null &amp;&amp; !sources.isEmpty()) { return result; } location = \"path \" + path.toAbsolutePath(); } else { ConfigValue&lt;String&gt; classpathConfig = metaConfig.get(\"classpath\").as(String.class); if (classpathConfig.isPresent()) { String classpath = classpathConfig.get(); List&lt;ConfigSource&gt; sources = sourceFromClasspath(classpath, profile); if (sources != null &amp;&amp; !sources.isEmpty()) { return sources; } location = \"classpath \" + classpath; } else { ConfigValue&lt;URL&gt; urlConfig = metaConfig.get(\"url\").as(URL.class); if (urlConfig.isPresent()) { URL url = urlConfig.get(); List&lt;ConfigSource&gt; sources = sourceFromUrlMeta(url, profile); if (sources != null &amp;&amp; !sources.isEmpty()) { return sources; } location = \"url \" + url; } else { throw new ConfigException(\"No config source location for \" + config.key()); } } } } if (metaConfig.get(\"optional\").asBoolean().orElse(false);) { return List.of(); } throw new ConfigException(\"Meta configuration could not find non-optional config source on \" + location); } Returns the names of the types that will be supported in this meta-config. Processes config source from file system if path is provided. Method to parse config source from a specified path Processes config source from classpath location if classpath is provided. Method to parse config source from a specified classpath Processes config source from url location if location is provided. Method to parse config source from a specified url Returns an empty result if set to optional and config source is not found. Throws a ConfigException if not set to optional and config source is not found. ",
            "title": "Example of a Meta-Config Custom Type"
        },
        {
            "location": "/mp/config/02_MP_config_sources",
            "text": " Helidon meta-config by default supports the following types: environment-variables, system-properties, properties, yaml, hocon and json. Users can also extend meta-config to create a custom config source type by loading it using the Java Service Loader pattern. This is achieved by implementing io.helidon.config.mp.spi.MpMetaConfigProvider SPI and registering it as a service (Using META-INF/services/${class-name} file when using classpath, or using the provides statement in module-info.java when using module path). The interface io.helidon.config.mp.spi.MpMetaConfigProvider requires implementation of the following methods: Set&lt;String&gt; supportedTypes() List&lt;? extends ConfigSource&gt; create(String type, Config metaConfig, String profile); Example of a Meta-Config Custom Type <markup lang=\"java\" >public class CustomMpMetaConfigProvider implements MpMetaConfigProvider { @Override public Set&lt;String&gt; supportedTypes() { return Set.of(\"custom\"); } @Override public List&lt;? extends ConfigSource&gt; create(String type, Config metaConfig, String profile) { ConfigValue&lt;Path&gt; pathConfig = metaConfig.get(\"path\").as(Path.class); if (pathConfig.isPresent()) { Path path = pathConfig.get(); List&lt;ConfigSource&gt; sources = sourceFromPath(path, profile); if (sources != null &amp;&amp; !sources.isEmpty()) { return result; } location = \"path \" + path.toAbsolutePath(); } else { ConfigValue&lt;String&gt; classpathConfig = metaConfig.get(\"classpath\").as(String.class); if (classpathConfig.isPresent()) { String classpath = classpathConfig.get(); List&lt;ConfigSource&gt; sources = sourceFromClasspath(classpath, profile); if (sources != null &amp;&amp; !sources.isEmpty()) { return sources; } location = \"classpath \" + classpath; } else { ConfigValue&lt;URL&gt; urlConfig = metaConfig.get(\"url\").as(URL.class); if (urlConfig.isPresent()) { URL url = urlConfig.get(); List&lt;ConfigSource&gt; sources = sourceFromUrlMeta(url, profile); if (sources != null &amp;&amp; !sources.isEmpty()) { return sources; } location = \"url \" + url; } else { throw new ConfigException(\"No config source location for \" + config.key()); } } } } if (metaConfig.get(\"optional\").asBoolean().orElse(false);) { return List.of(); } throw new ConfigException(\"Meta configuration could not find non-optional config source on \" + location); } Returns the names of the types that will be supported in this meta-config. Processes config source from file system if path is provided. Method to parse config source from a specified path Processes config source from classpath location if classpath is provided. Method to parse config source from a specified classpath Processes config source from url location if location is provided. Method to parse config source from a specified url Returns an empty result if set to optional and config source is not found. Throws a ConfigException if not set to optional and config source is not found. ",
            "title": "Extending meta-config to create a custom config source type"
        },
        {
            "location": "/mp/config/02_MP_config_sources",
            "text": " To use the Helidon SE features in Helidon MP, create MicroProfile Config Source from Helidon SE Config Source. The Config Source is immutable regardless of configured polling strategy or change watchers. Config config = ConfigProviderResolver.instance() .getBuilder() .withSources(MpConfigSources.create(helidonConfigSource) .build(); Creates a MicroProfile config instance using Helidon Config Source. ",
            "title": "Creating MicroProfile Config Source from Helidon SE Config Source"
        },
        {
            "location": "/mp/config/02_MP_config_sources",
            "text": " To use advanced Helidon SE features in Helidon MP, create MicroProfile Config Source from Helidon SE Config. The Config Source is mutable if the config uses either polling strategy and change watchers, or polling strategy or change watchers. The latest config version is queried each time org.eclipse.microprofile.config.spi.ConfigSource#getValue(String) is called. io.helidon.config.Config helidonConfig = io.helidon.config.Config.builder() .addSource(ConfigSources.create(Map.of(\"key\", \"value\"))) .build(); ConfigProviderResolver.instance(); Config config = ConfigProviderResolver.instance() .getBuilder() .withSources(MpConfigSources.create(helidonConfig)) .build(); Creates a config source from Helidon Config. Creates a MicroProfile config instance using Helidon Config. ",
            "title": "Creating MicroProfile Config Source from Helidon SE Config Instance"
        },
        {
            "location": "/se/config/02_config-sources",
            "text": " Configuration can be loaded from different types of locations and expressed in different formats. This section describes how your application can use config sources and config parsers together to load configuration data. ",
            "title": "preambule"
        },
        {
            "location": "/se/config/02_config-sources",
            "text": " Each config source reads data from a location of a specific type, without regard to the format of the config data there. Each config parser converts data expressed in a particular format into the in-memory config data structure that the rest of the config system uses, without any concern for where that data resides or how it is physically retrieved. These two work together to prepare data in a given format at a given location for the config system. When your application prepares a Config.Builder it sets what ConfigSource s and ConfigParser s the builder should use in constructing the resulting Config object. ",
            "title": "Overview"
        },
        {
            "location": "/se/config/02_config-sources",
            "text": " If your application uses the default configuration, then the config system automatically sets up the config sources for you, as described in the config introduction . If instead your application uses a Config.Builder , then it can invoke one of the sources methods on that builder to set which config sources it should use. The config system includes support for several types of config sources, for example: a resource on the runtime classpath, environment variables, a file, Java system properties, a URL, a variety of in-memory data structures ( String , Map , Properties ) See the JavaDoc for the ConfigSources class for a complete list of the built-in config source types and how to use them. You can also extend the config system to handle other types of sources by implementing the ConfigSource interface. See the extensions documentation for complete information. See the advanced topics page for further information on some more involved aspects of config sources. ",
            "title": "Config Sources"
        },
        {
            "location": "/se/config/02_config-sources",
            "text": " When it reads configuration text from sources, the config system uses config parsers to translate that text into the in-memory data structures representing that configuration. The config system includes several built-in parsers, such as for the Java properties, YAML, JSON, and HOCON formats. See this section in the introduction for how to change your pom.xml to make parsers for those formats available to your application. Then your application can invoke the config builder&#8217;s addParser method so that builder will use the parsers you choose. You can extend the system with custom parsers of your own. Implement the ConfigParser interface, then construct a Config.Builder using the addParser method, passing an instance of your customer parser. Invoke one of the sources methods to include a source that uses the custom format and then build the Config object. ",
            "title": "Config Parsers"
        },
        {
            "location": "/se/config/02_config-sources",
            "text": " Each Config object which the config system returns to your application is immutable; even if the information in one of the underlying config sources changes, an in-memory data structure built from the earlier content remains unchanged. Even so, the config system allows your application to learn when such underlying changes in the data occur and respond accordingly. The mutability section explains this in detail, and the PollingStrategies JavaDoc describes the built-in implementations. You can, of course, write your own by implementing the PollingStrategy interface. On a config source builder invoke pollingStrategy with an instance of your custom strategy and then invoke build to create the ConfigSource . ",
            "title": "Detecting and Responding to Changes in Config Data"
        },
        {
            "location": "/se/config/02_config-sources",
            "text": " Config sources, especially those that depend on fallible mechanisms such as the network or a shared file system, might fail to load during momentary outages. The config system allows you to build resiliency into your application&#8217;s use of configuration that relies on such technologies. When your application builds a ConfigSource it can specify a retry policy . When the config system needs to load data from that source it delegates the load operation to that retry policy. That policy is responsible not only for loading the data but also for detecting errors during loading and implementing the algorithm for deciding when and how many times to retry a failed load before reporting a failure back to your application. The config system includes two predefined retry policies: Predefined Retry Policies Policy Summary \"just call\" (default) asks the config source to load the data with no retry \"repeat\" performs a settable number of time-based retries, reporting failure only after all available retries have failed See the RetryPolicies JavaDoc for complete details on these built-in retry policies. You can devise your own policy. Implement the RetryPolicy interface. Then pass an instance of your policy implementation to the config source builder&#8217;s retryPolicy method. ",
            "title": "Dealing with Loading Errors: Retry Policies"
        },
        {
            "location": "/se/guides/37_jlink_image",
            "text": " This guide describes how to build a custom runtime image for your Helidon application using Helidon&#8217;s support for the JDK&#8217;s jlink tool. ",
            "title": "preambule"
        },
        {
            "location": "/se/guides/37_jlink_image",
            "text": " JDK 9 introduced the jlink command that supports assembling a set of modules and their dependencies into a custom runtime image. The helidon-maven-plugin has support for easily creating a custom runtime image for your Helidon application resulting in a smaller, better performing runtime. In this guide you will learn how to build a custom runtime image locally on your machine, as well as how to build it in a Docker image. ",
            "title": "Introduction"
        },
        {
            "location": "/se/guides/37_jlink_image",
            "text": " For this 10 minute tutorial, you will need the following: <div class=\"table__overflow elevation-1 flex sm7 \"> A Helidon {upper-case-flavor} Application You can use your own application or use the Helidon {upper-case-flavor} Quickstart to create a sample application. Java&#160;SE&#160;11 ( Open&#160;JDK&#160;11 ) Helidon requires Java 11+. Maven 3.6.1+ Helidon requires Maven 3.6.1+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop ). <markup lang=\"bash\" title=\"Verify Prerequisites\" >java -version mvn --version docker --version kubectl version --short <markup lang=\"bash\" title=\"Setting JAVA_HOME\" ># On Mac export JAVA_HOME=`/usr/libexec/java_home -v 11` # On Linux # Use the appropriate path to your JDK export JAVA_HOME=/usr/lib/jvm/jdk-11 ",
            "title": "What You Need"
        },
        {
            "location": "/se/guides/37_jlink_image",
            "text": " As noted in the prerequisites above, JDK 11 or newer is required. <markup lang=\"bash\" >$JAVA_HOME/bin/java --version Creating a custom runtime image requires that the JDK modules are present as *.jmod files, and some distributions do not provide them by default. Check the jmods directory to ensure they are present: <markup lang=\"bash\" >ls $JAVA_HOME/jmods OpenJDK on Linux RPM based distributions provide *.jmod files in separate java-*-openjdk-jmods packages. Debian based distributions provide *.jmod files only in the openjdk-*-jdk-headless packages. ",
            "title": "Verify JDK"
        },
        {
            "location": "/se/guides/37_jlink_image",
            "text": " Generate the project using the Helidon SE Quickstart Maven archetype. <markup lang=\"bash\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-se \\ -DarchetypeVersion=2.5.4 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-se \\ -Dpackage=io.helidon.examples.quickstart.se The archetype generates a Maven project in your current directory (for example, helidon-quickstart-se ). Change into this directory and build. <markup lang=\"bash\" >cd helidon-quickstart-se mvn package At this point you can run the application using the JVM: <markup lang=\"bash\" >java -jar target/helidon-quickstart-se.jar In another shell test an endpoint: <markup lang=\"bash\" >curl -X GET http://localhost:8080/greet The application should respond with {\"message\":\"Hello World!\"} Now stop the running application (by pressing Ctrl+C). For more information about the Quickstart application and other enpoints it supports see the Helidon SE quickstart Guide . ",
            "title": "Generate the Project"
        },
        {
            "location": "/se/guides/37_jlink_image",
            "text": " Build the custom runtime image using the jlink image profile: <markup lang=\"bash\" >mvn package -Pjlink-image Tip This uses the helidon-maven-plugin to perform the custom image generation. After the build completes it will report some statistics about the build including the reduction in image size. The target/helidon-quickstart-se-jri directory is a self contained custom image of your application. It contains your application, its runtime dependencies and the JDK modules it depends on. You can start your application using the provide start script: <markup lang=\"bash\" >./target/helidon-quickstart-se-jri/bin/start ",
            "title": "Local Build"
        },
        {
            "location": "/se/guides/37_jlink_image",
            "text": " Also included in the custom image is a Class Data Sharing (CDS) archive that improves your application&#8217;s startup performance and in-memory footprint. You can learn more about Class Data Sharing in the JDK documentation . The CDS archive increases your image size to get these performance optimizations. It can be of significant size (tens of MB). The size of the CDS archive is reported at the end of the build output. If you&#8217;d rather have a smaller image size (with a slightly increased startup time) you can skip the creation of the CDS archive by executing your build like this: <markup lang=\"bash\" >mvn package -Pjlink-image -Djlink.image.addClassDataSharingArchive=false For more information on available configuration options see the helidon-maven-plugin documentation . ",
            "title": "Class Data Sharing (CDS) Archive"
        },
        {
            "location": "/se/guides/37_jlink_image",
            "text": " To build a Docker image with a custom Java runtime image use the jlink Dockerfile included with the quickstart. <markup lang=\"bash\" >docker build -t helidon-quickstart-se-jri -f Dockerfile.jlink . Tip This does a full build inside the Docker container. The first time you run it, it will take a while because it is downloading all of the Maven dependencies and caching them in a Docker layer. Subsequent builds will be much faster as long as you don&#8217;t change the pom.xml file. If the pom is modified then the dependencies will be re-downloaded. Start the application: <markup lang=\"bash\" >docker run --rm -p 8080:8080 helidon-quickstart-se-jri:latest You can exercise the application&#8217;s endpoints as before. ",
            "title": "Multi-Stage Docker Build"
        },
        {
            "location": "/se/guides/37_jlink_image",
            "text": " You can build a custom runtime image in 2 different ways: Locally, on your desktop Using Docker Local Build Build the custom runtime image using the jlink image profile: <markup lang=\"bash\" >mvn package -Pjlink-image Tip This uses the helidon-maven-plugin to perform the custom image generation. After the build completes it will report some statistics about the build including the reduction in image size. The target/helidon-quickstart-se-jri directory is a self contained custom image of your application. It contains your application, its runtime dependencies and the JDK modules it depends on. You can start your application using the provide start script: <markup lang=\"bash\" >./target/helidon-quickstart-se-jri/bin/start Class Data Sharing (CDS) Archive Also included in the custom image is a Class Data Sharing (CDS) archive that improves your application&#8217;s startup performance and in-memory footprint. You can learn more about Class Data Sharing in the JDK documentation . The CDS archive increases your image size to get these performance optimizations. It can be of significant size (tens of MB). The size of the CDS archive is reported at the end of the build output. If you&#8217;d rather have a smaller image size (with a slightly increased startup time) you can skip the creation of the CDS archive by executing your build like this: <markup lang=\"bash\" >mvn package -Pjlink-image -Djlink.image.addClassDataSharingArchive=false For more information on available configuration options see the helidon-maven-plugin documentation . Multi-Stage Docker Build To build a Docker image with a custom Java runtime image use the jlink Dockerfile included with the quickstart. <markup lang=\"bash\" >docker build -t helidon-quickstart-se-jri -f Dockerfile.jlink . Tip This does a full build inside the Docker container. The first time you run it, it will take a while because it is downloading all of the Maven dependencies and caching them in a Docker layer. Subsequent builds will be much faster as long as you don&#8217;t change the pom.xml file. If the pom is modified then the dependencies will be re-downloaded. Start the application: <markup lang=\"bash\" >docker run --rm -p 8080:8080 helidon-quickstart-se-jri:latest You can exercise the application&#8217;s endpoints as before. ",
            "title": "Building a Custom Runtime Image"
        },
        {
            "location": "/se/guides/37_jlink_image",
            "text": " Custom runtime images are ideal for use when you want all of the runtime performance of the JDK JVM in a reasonably compact form. For cases where absolute minimal startup time and image size are required, then consider using GraalVM Native Images . ",
            "title": "Using Custom Runtime Images"
        },
        {
            "location": "/mp/guides/37_jlink_image",
            "text": " This guide describes how to build a custom runtime image for your Helidon application using Helidon&#8217;s support for the JDK&#8217;s jlink tool. ",
            "title": "preambule"
        },
        {
            "location": "/mp/guides/37_jlink_image",
            "text": " JDK 9 introduced the jlink command that supports assembling a set of modules and their dependencies into a custom runtime image. The helidon-maven-plugin has support for easily creating a custom runtime image for your Helidon application resulting in a smaller, better performing runtime. In this guide you will learn how to build a custom runtime image locally on your machine, as well as how to build it in a Docker image. ",
            "title": "Introduction"
        },
        {
            "location": "/mp/guides/37_jlink_image",
            "text": " For this 10 minute tutorial, you will need the following: <div class=\"table__overflow elevation-1 flex sm7 \"> A Helidon {upper-case-flavor} Application You can use your own application or use the Helidon {upper-case-flavor} Quickstart to create a sample application. Java&#160;SE&#160;11 ( Open&#160;JDK&#160;11 ) Helidon requires Java 11+. Maven 3.6.1+ Helidon requires Maven 3.6.1+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop ). <markup lang=\"bash\" title=\"Verify Prerequisites\" >java -version mvn --version docker --version kubectl version --short <markup lang=\"bash\" title=\"Setting JAVA_HOME\" ># On Mac export JAVA_HOME=`/usr/libexec/java_home -v 11` # On Linux # Use the appropriate path to your JDK export JAVA_HOME=/usr/lib/jvm/jdk-11 ",
            "title": "What You Need"
        },
        {
            "location": "/mp/guides/37_jlink_image",
            "text": " As noted in the prerequisites above, JDK 11 or newer is required. <markup lang=\"bash\" >$JAVA_HOME/bin/java --version Creating a custom runtime image requires that the JDK modules are present as *.jmod files, and some distributions do not provide them by default. Check the jmods directory to ensure they are present: <markup lang=\"bash\" >ls $JAVA_HOME/jmods OpenJDK on Linux RPM based distributions provide *.jmod files in separate java-*-openjdk-jmods packages. Debian based distributions provide *.jmod files only in the openjdk-*-jdk-headless packages. ",
            "title": "Verify JDK"
        },
        {
            "location": "/mp/guides/37_jlink_image",
            "text": " Generate the project using the Helidon MP Quickstart Maven archetype. <markup lang=\"bash\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-mp \\ -DarchetypeVersion=2.5.4 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-mp \\ -Dpackage=io.helidon.examples.quickstart.mp The archetype generates a Maven project in your current directory (for example, helidon-quickstart-mp ). Change into this directory and build. <markup lang=\"bash\" >cd helidon-quickstart-mp mvn package At this point you can run the application using the JVM: <markup lang=\"bash\" >java -jar target/helidon-quickstart-mp.jar In another shell test an endpoint: <markup lang=\"bash\" >curl -X GET http://localhost:8080/greet The application should respond with {\"message\":\"Hello World!\"} Now stop the running application (by pressing Ctrl+C). For more information about the Quickstart application and other enpoints it supports see the Helidon MP quickstart Guide . ",
            "title": "Generate the Project"
        },
        {
            "location": "/mp/guides/37_jlink_image",
            "text": " Build the custom runtime image using the jlink image profile: <markup lang=\"bash\" >mvn package -Pjlink-image Tip This uses the helidon-maven-plugin to perform the custom image generation. After the build completes it will report some statistics about the build including the reduction in image size. The target/helidon-quickstart-mp-jri directory is a self contained custom image of your application. It contains your application, its runtime dependencies and the JDK modules it depends on. You can start your application using the provide start script: <markup lang=\"bash\" >./target/helidon-quickstart-mp-jri/bin/start ",
            "title": "Local Build"
        },
        {
            "location": "/mp/guides/37_jlink_image",
            "text": " Also included in the custom image is a Class Data Sharing (CDS) archive that improves your application&#8217;s startup performance and in-memory footprint. You can learn more about Class Data Sharing in the JDK documentation . The CDS archive increases your image size to get these performance optimizations. It can be of significant size (tens of MB). The size of the CDS archive is reported at the end of the build output. If you&#8217;d rather have a smaller image size (with a slightly increased startup time) you can skip the creation of the CDS archive by executing your build like this: <markup lang=\"bash\" >mvn package -Pjlink-image -Djlink.image.addClassDataSharingArchive=false For more information on available configuration options see the helidon-maven-plugin documentation . ",
            "title": "Class Data Sharing (CDS) Archive"
        },
        {
            "location": "/mp/guides/37_jlink_image",
            "text": " To build a Docker image with a custom Java runtime image use the jlink Dockerfile included with the quickstart. <markup lang=\"bash\" >docker build -t helidon-quickstart-mp-jri -f Dockerfile.jlink . Tip This does a full build inside the Docker container. The first time you run it, it will take a while because it is downloading all of the Maven dependencies and caching them in a Docker layer. Subsequent builds will be much faster as long as you don&#8217;t change the pom.xml file. If the pom is modified then the dependencies will be re-downloaded. Start the application: <markup lang=\"bash\" >docker run --rm -p 8080:8080 helidon-quickstart-mp-jri:latest You can exercise the application&#8217;s endpoints as before. ",
            "title": "Multi-Stage Docker Build"
        },
        {
            "location": "/mp/guides/37_jlink_image",
            "text": " You can build a custom runtime image in 2 different ways: Locally, on your desktop Using Docker Local Build Build the custom runtime image using the jlink image profile: <markup lang=\"bash\" >mvn package -Pjlink-image Tip This uses the helidon-maven-plugin to perform the custom image generation. After the build completes it will report some statistics about the build including the reduction in image size. The target/helidon-quickstart-mp-jri directory is a self contained custom image of your application. It contains your application, its runtime dependencies and the JDK modules it depends on. You can start your application using the provide start script: <markup lang=\"bash\" >./target/helidon-quickstart-mp-jri/bin/start Class Data Sharing (CDS) Archive Also included in the custom image is a Class Data Sharing (CDS) archive that improves your application&#8217;s startup performance and in-memory footprint. You can learn more about Class Data Sharing in the JDK documentation . The CDS archive increases your image size to get these performance optimizations. It can be of significant size (tens of MB). The size of the CDS archive is reported at the end of the build output. If you&#8217;d rather have a smaller image size (with a slightly increased startup time) you can skip the creation of the CDS archive by executing your build like this: <markup lang=\"bash\" >mvn package -Pjlink-image -Djlink.image.addClassDataSharingArchive=false For more information on available configuration options see the helidon-maven-plugin documentation . Multi-Stage Docker Build To build a Docker image with a custom Java runtime image use the jlink Dockerfile included with the quickstart. <markup lang=\"bash\" >docker build -t helidon-quickstart-mp-jri -f Dockerfile.jlink . Tip This does a full build inside the Docker container. The first time you run it, it will take a while because it is downloading all of the Maven dependencies and caching them in a Docker layer. Subsequent builds will be much faster as long as you don&#8217;t change the pom.xml file. If the pom is modified then the dependencies will be re-downloaded. Start the application: <markup lang=\"bash\" >docker run --rm -p 8080:8080 helidon-quickstart-mp-jri:latest You can exercise the application&#8217;s endpoints as before. ",
            "title": "Building a Custom Runtime Image"
        },
        {
            "location": "/mp/guides/37_jlink_image",
            "text": " Custom runtime images are ideal for use when you want all of the runtime performance of the JDK JVM in a reasonably compact form. For cases where absolute minimal startup time and image size are required, then consider using GraalVM Native Images . ",
            "title": "Using Custom Runtime Images"
        },
        {
            "location": "/mp/jpa/01_introduction",
            "text": " Helidon MP supports JPA in much the same way that Java EE application servers do, but with much less weight. If you come from a Java EE background, you&#8217;ll feel right at home: you work with JPA in Helidon MP in all the ways that you&#8217;re familiar with. For example, in Helidon MP&#8217;s JPA integration, you can work with a fully managed EntityManager by injecting it in the same way you would in a Java EE application server: <markup lang=\"java\" >@PersistenceContext private EntityManager em; The Jakarta Persistence API is a specification that governs how Java objects map to relational databases, and has existed since 2006. Hibernate and Eclipselink, two of the most popular JPA implementations, are supported by Helidon MP JPA. ",
            "title": "Overview"
        },
        {
            "location": "/mp/jpa/01_introduction",
            "text": " Learn more about the Java Persistence API (JPA) Configure and use the Java Persistence API (JPA) from within a Helidon MP application. Helidon MP JPA Guide . ",
            "title": "Next Steps"
        },
        {
            "location": "/mp/tracing/02_zipkin",
            "text": " Helidon is integrated with the Zipkin tracer. The Zipkin builder is loaded through ServiceLoader and configured. You could also use the Zipkin builder directly, though this would create a source-code dependency on the Zipkin tracer. ",
            "title": "preambule"
        },
        {
            "location": "/mp/tracing/02_zipkin",
            "text": " To enable Zipkin Tracing add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-zipkin&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/tracing/02_zipkin",
            "text": " The Zipkin tracer supports the following configuration options: Key Default value Builder method Description service N/A serviceName Name of the service, to distinguish traces crossing service boundaries; Zipkin is using lower-case only, name will be automatically lower-cased protocol http collectorProtocol Protocol of the Zipkin trace collector (http or https) host localhost collectorHost Host of the Zipkin trace collector (IP Address, hostname, or FQDN) port 9411 collectorPort Port of the Zipkin trace collector path defined by version collectorPath Path of the Zipkin trace collector, each version uses a different path by default. api-version 2 version Zipkin specific method, set the protocol version to communicate with trace collector enabled true enabled If set to false, tracing would be disabled tags N/A addTracerTag(String, String) String tags to add to each span boolean-tags N/A addTracerTag(String, boolean) boolean tags to add to each span int-tags N/A addTracerTag(String, int) int tags to add to each span The following is an example of a Zipkin configuration, specified in the YAML format. <markup lang=\"yaml\" >tracing: zipkin: service: \"helidon-service\" protocol: \"https\" host: \"192.168.1.1\" port: 9987 api-version: 1 # this is the default path for API version 2 path: \"/api/v2/spans\" tags: tag1: \"tag1-value\" tag2: \"tag2-value\" boolean-tags: tag3: true tag4: false int-tags: tag5: 145 tag6: 741 Example of Zipkin trace: ",
            "title": "Configuring Zipkin"
        },
        {
            "location": "/se/health/02_health_in_k8s",
            "text": " This document describes how to use the Helidon health check API with Kubernetes. ",
            "title": "preambule"
        },
        {
            "location": "/se/health/02_health_in_k8s",
            "text": " The liveness probe is used to verify the container has become unresponsive. For example, it can be used to detect deadlocks or analyze heap usage. When Kubernetes gives up on a liveness probe, the corresponding pod is restarted. The liveness probe can result in repeated restarts in certain cases. For example, if the probe is implemented to check all the dependencies strictly, then it can fail repeatedly for temporary issues. Repeated restarts can also occur if timeoutSeconds or periodSeconds is too low. We recommend the following: Avoid checking dependencies in a liveness probe. Set timeoutSeconds to avoid excessive probe failures. Acknowledge startup times with initialDelaySeconds . ",
            "title": "Liveness probe"
        },
        {
            "location": "/se/health/02_health_in_k8s",
            "text": " The readiness probe is used to avoid routing requests to the pod until it is ready to accept traffic. When Kubernetes gives up on a readiness probe, the pod is not restarted, traffic is not routed to the pod anymore. In certain cases, the readiness probe can cause all the pods to be removed from service routing. For example, if the probe is implemented to check all the dependencies strictly, then it can fail repeatedly for temporary issues. This issue can also occur if timeoutSeconds or periodSeconds is too low. We recommend the following: Be conservative when checking shared dependencies. Be aggressive when checking local dependencies. Set failureThreshold according to periodSeconds in order to accommodate temporary errors. ",
            "title": "Readiness probe"
        },
        {
            "location": "/se/health/02_health_in_k8s",
            "text": " Probes is the term used by Kubernetes to describe health checks for containers ( Kubernetes documentation ). There are two types of probes: liveness : Indicates whether the container is running readiness : Indicates whether the container is ready to service requests You can implement probes using the following mechanisms: Running a command inside a container Sending an HTTP request to a container Opening a TCP socket to a container A microservice exposed to HTTP traffic will typically implement both the liveness probe and the readiness probe using HTTP requests. You can configure several parameters for probes. The following are the most relevant parameters: <div class=\"table__overflow elevation-1 flex sm7 \"> initialDelaySeconds Number of seconds after the container has started before liveness or readiness probes are initiated. periodSeconds Probe interval. Default to 10 seconds. Minimum value is 1. timeoutSeconds Number of seconds after which the probe times out. Defaults to 1 second. Minimum value is 1 failureThreshold Number of consecutive failures after which the probe should stop. Default: 3. Minimum: 1. Liveness probe The liveness probe is used to verify the container has become unresponsive. For example, it can be used to detect deadlocks or analyze heap usage. When Kubernetes gives up on a liveness probe, the corresponding pod is restarted. The liveness probe can result in repeated restarts in certain cases. For example, if the probe is implemented to check all the dependencies strictly, then it can fail repeatedly for temporary issues. Repeated restarts can also occur if timeoutSeconds or periodSeconds is too low. We recommend the following: Avoid checking dependencies in a liveness probe. Set timeoutSeconds to avoid excessive probe failures. Acknowledge startup times with initialDelaySeconds . Readiness probe The readiness probe is used to avoid routing requests to the pod until it is ready to accept traffic. When Kubernetes gives up on a readiness probe, the pod is not restarted, traffic is not routed to the pod anymore. In certain cases, the readiness probe can cause all the pods to be removed from service routing. For example, if the probe is implemented to check all the dependencies strictly, then it can fail repeatedly for temporary issues. This issue can also occur if timeoutSeconds or periodSeconds is too low. We recommend the following: Be conservative when checking shared dependencies. Be aggressive when checking local dependencies. Set failureThreshold according to periodSeconds in order to accommodate temporary errors. ",
            "title": "About Kubernetes probes"
        },
        {
            "location": "/se/health/02_health_in_k8s",
            "text": " Failed probes are recorded as events associated with their corresponding pods. The event message contains only the status code. <markup lang=\"bash\" title=\"Get the events of a single pod:\" >POD_NAME=$(kubectl get pod -l app=acme -o jsonpath='{.items[0].metadata.name}') kubectl get event --field-selector involvedObject.name=${POD_NAME} Get the effective pod name by filtering pods with the label app=acme . Filter the events for the pod. Create log messages in your health check implementation when setting a DOWN status. This will allow you to correlate the cause of a failed probe. ",
            "title": "Troubleshooting probes"
        },
        {
            "location": "/se/health/02_health_in_k8s",
            "text": " This example shows the usage of the Helidon health API in an application that implements health endpoints for the liveness and readiness probes. Note that the application code dissociates the health endpoints from the default routes, so that the health endpoints are not exposed by the service. An example YAML specification is also provided for the Kubernetes service and deployment. <markup lang=\"java\" title=\"Application code:\" >Routing healthRouting = Routing.builder() .register(JsonSupport.create()) .register(HealthSupport.builder() .webContext(\"/live\") .addLiveness(HealthChecks.healthChecks()) .build()) .register(HealthSupport.builder() .webContext(\"/ready\") .addReadiness(() -&gt; HealthCheckResponse.named(\"database\").up().build()) .build()) .build(); Routing defaultRouting = Routing.builder() .any((req, res) -&gt; res.send(\"It works!\")) .build(); WebServer server = WebServer.builder(defaultRouting) .config(ServerConfiguration.builder() .port(8080) .addSocket(\"health\", SocketConfiguration.builder() .port(8081) .build()) .build()) .addNamedRouting(\"health\", healthRouting) .build(); server.start(); The health service for the liveness probe is exposed at /live . Using the built-in health checks for the liveness probe. The health service for the readiness probe is exposed at /ready . Using a custom health check for a pseudo database that is always UP . The default route: returns It works! for any request. The server uses port 8080 for the default routes. A socket configuration named health using port 8081 . Route the health services exclusively on the health socket. <markup lang=\"yaml\" title=\"Kubernetes descriptor:\" >kind: Service apiVersion: v1 metadata: name: acme labels: app: acme spec: type: NodePort selector: app: acme ports: - port: 8080 targetPort: 8080 name: http --- kind: Deployment apiVersion: apps/v1 metadata: name: acme spec: replicas: 1 selector: matchLabels: app: acme template: metadata: name: acme labels: name: acme spec: containers: - name: acme image: acme imagePullPolicy: IfNotPresent ports: - containerPort: 8080 livenessProbe: httpGet: path: /live port: 8081 initialDelaySeconds: 3 periodSeconds: 10 timeoutSeconds: 3 failureThreshold: 3 readinessProbe: httpGet: path: /ready port: 8081 initialDelaySeconds: 10 periodSeconds: 30 timeoutSeconds: 10 --- A service of type NodePort that serves the default routes on port 8080 . A deployment with one replica of a pod. The HTTP endpoint for the liveness probe. The liveness probe configuration. The HTTP endpoint for the readiness probe. The readiness probe configuration. ",
            "title": "Example"
        },
        {
            "location": "/mp/guides/39_jbatch",
            "text": " This guide describes how Helidon and Jakarta Batch (JBatch) can be used together to execute batch jobs in environments that do not fully support EE environments. ",
            "title": "preambule"
        },
        {
            "location": "/mp/guides/39_jbatch",
            "text": " For this 20 minute tutorial, you will need the following: <div class=\"table__overflow elevation-1 flex sm7 \"> A Helidon {upper-case-flavor} Application You can use your own application or use the Helidon {upper-case-flavor} Quickstart to create a sample application. Java&#160;SE&#160;11 ( Open&#160;JDK&#160;11 ) Helidon requires Java 11+. Maven 3.6.1+ Helidon requires Maven 3.6.1+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop ). <markup lang=\"bash\" title=\"Verify Prerequisites\" >java -version mvn --version docker --version kubectl version --short <markup lang=\"bash\" title=\"Setting JAVA_HOME\" ># On Mac export JAVA_HOME=`/usr/libexec/java_home -v 11` # On Linux # Use the appropriate path to your JDK export JAVA_HOME=/usr/lib/jvm/jdk-11 This guide assumes you are familiar with the Jakarta Batch project specification from the Ecplipse Foundation project site. ",
            "title": "What You Need"
        },
        {
            "location": "/mp/guides/39_jbatch",
            "text": " For this example, add the IBM JBatch implementation and the derby embedded DB (since JPA and JPA are not available by default) dependencies to the testing module: <markup lang=\"xml\" title=\"Maven dependencies\" >&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.ibm.jbatch&lt;/groupId&gt; &lt;artifactId&gt;com.ibm.jbatch.container&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.derby&lt;/groupId&gt; &lt;artifactId&gt;derby&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependencies&gt; ",
            "title": "Dependencies"
        },
        {
            "location": "/mp/guides/39_jbatch",
            "text": "<markup lang=\"java\" title=\"MyInputRecord\" >public class MyInputRecord { private int id; public MyInputRecord(int id) { this.id = id; } public int getId() { return id; } public void setId(int id) { this.id = id; } @Override public String toString() { return \"MyInputRecord: \" + id; } } ",
            "title": "1. Create a unit of input information"
        },
        {
            "location": "/mp/guides/39_jbatch",
            "text": "<markup lang=\"java\" title=\"MyOutputRecord\" >public class MyOutputRecord { private int id; public MyOutputRecord(int id) { this.id = id; } public int getId() { return id; } public void setId(int id) { this.id = id; } @Override public String toString() { return \"MyOutputRecord: \" + id; } } ",
            "title": "2. Create a unit of output information"
        },
        {
            "location": "/mp/guides/39_jbatch",
            "text": " MyItemReader should look like this: <markup lang=\"java\" title=\"MyItemReader\" >public class MyItemReader extends AbstractItemReader { private final StringTokenizer tokens; public MyItemReader() { tokens = new StringTokenizer(\"1,2,3,4,5,6,7,8,9,10\", \",\"); } /** * Perform read Item. * @return Stage result. */ @Override public MyInputRecord readItem() { if (tokens.hasMoreTokens()) { return new MyInputRecord(Integer.valueOf(tokens.nextToken())); } return null; } } ",
            "title": "3. Create MyItemReader to extend AbstractItemReader "
        },
        {
            "location": "/mp/guides/39_jbatch",
            "text": " The MyItemProcessor will perform some simple operations: <markup lang=\"java\" title=\"MyItemProcessor\" >public class MyItemProcessor implements ItemProcessor { @Override public MyOutputRecord processItem(Object t) { System.out.println(\"processItem: \" + t); return (((MyInputRecord) t).getId() % 2 == 0) ? null : new MyOutputRecord(((MyInputRecord) t).getId() * 2); } } ",
            "title": "4. Create MyItemProcessor to implement ItemProcessor "
        },
        {
            "location": "/mp/guides/39_jbatch",
            "text": " MyItemWriter prints the result: <markup lang=\"java\" title=\"MyItemWriter\" >public class MyItemWriter extends AbstractItemWriter { @Override public void writeItems(List list) { System.out.println(\"writeItems: \" + list); } } ",
            "title": "5. Create MyItemWriter to extend AbstractItemWriter "
        },
        {
            "location": "/mp/guides/39_jbatch",
            "text": " MyBatchlet simply completes the process: <markup lang=\"java\" title=\"MyBatchlet\" >public class MyBatchlet extends AbstractBatchlet { @Override public String process() { System.out.println(\"Running inside a batchlet\"); return \"COMPLETED\"; } } ",
            "title": "6. Create MyBatchlet to extentd AbstractBatchlet "
        },
        {
            "location": "/mp/guides/39_jbatch",
            "text": " In this demonstration you will first create sample input and output records and then the following jobs: MyItemReader , MyItemProcessor and MyItemWriter . Finally you will create MyBatchlet to demonstrate all possible usages of JBatch. 1. Create a unit of input information <markup lang=\"java\" title=\"MyInputRecord\" >public class MyInputRecord { private int id; public MyInputRecord(int id) { this.id = id; } public int getId() { return id; } public void setId(int id) { this.id = id; } @Override public String toString() { return \"MyInputRecord: \" + id; } } 2. Create a unit of output information <markup lang=\"java\" title=\"MyOutputRecord\" >public class MyOutputRecord { private int id; public MyOutputRecord(int id) { this.id = id; } public int getId() { return id; } public void setId(int id) { this.id = id; } @Override public String toString() { return \"MyOutputRecord: \" + id; } } 3. Create MyItemReader to extend AbstractItemReader MyItemReader should look like this: <markup lang=\"java\" title=\"MyItemReader\" >public class MyItemReader extends AbstractItemReader { private final StringTokenizer tokens; public MyItemReader() { tokens = new StringTokenizer(\"1,2,3,4,5,6,7,8,9,10\", \",\"); } /** * Perform read Item. * @return Stage result. */ @Override public MyInputRecord readItem() { if (tokens.hasMoreTokens()) { return new MyInputRecord(Integer.valueOf(tokens.nextToken())); } return null; } } 4. Create MyItemProcessor to implement ItemProcessor The MyItemProcessor will perform some simple operations: <markup lang=\"java\" title=\"MyItemProcessor\" >public class MyItemProcessor implements ItemProcessor { @Override public MyOutputRecord processItem(Object t) { System.out.println(\"processItem: \" + t); return (((MyInputRecord) t).getId() % 2 == 0) ? null : new MyOutputRecord(((MyInputRecord) t).getId() * 2); } } 5. Create MyItemWriter to extend AbstractItemWriter MyItemWriter prints the result: <markup lang=\"java\" title=\"MyItemWriter\" >public class MyItemWriter extends AbstractItemWriter { @Override public void writeItems(List list) { System.out.println(\"writeItems: \" + list); } } 6. Create MyBatchlet to extentd AbstractBatchlet MyBatchlet simply completes the process: <markup lang=\"java\" title=\"MyBatchlet\" >public class MyBatchlet extends AbstractBatchlet { @Override public String process() { System.out.println(\"Running inside a batchlet\"); return \"COMPLETED\"; } } ",
            "title": "Add Sample Jobs"
        },
        {
            "location": "/mp/guides/39_jbatch",
            "text": " Add this code to your job descriptor.xml file: <markup lang=\"java\" title=\"Updated descriptor file\" >&lt;job id=\"myJob\" xmlns=\"http://xmlns.jcp.org/xml/ns/javaee\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/jobXML_1_0.xsd\" version=\"1.0\"&gt; &lt;step id=\"step1\" next=\"step2\"&gt; &lt;chunk item-count=\"3\"&gt; &lt;reader ref=\"io.helidon.jbatch.example.jobs.MyItemReader\"/&gt; &lt;processor ref=\"io.helidon.jbatch.example.jobs.MyItemProcessor\"/&gt; &lt;writer ref=\"io.helidon.jbatch.example.jobs.MyItemWriter\"/&gt; &lt;/chunk&gt; &lt;/step&gt; &lt;step id=\"step2\" &gt; &lt;batchlet ref=\"io.helidon.jbatch.example.jobs.MyBatchlet\"/&gt; &lt;/step&gt; &lt;/job&gt; The first step of the job includes MyItemReader , MyItemProcessor and MyItemWriter . The second step of the job includes MyBatchlet . You must specify the fully qualified names in the ref properties, like “io.helidon.jbatch.example.jobs.MyItemReader”, otherwise it will not work. ",
            "title": "Update the Descriptor File"
        },
        {
            "location": "/mp/guides/39_jbatch",
            "text": " Create a small endpoint to activate the job: <markup lang=\"java\" title=\"new endpoint\" >@Path(\"/batch\") @ApplicationScoped public class BatchResource { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); private JobOperator jobOperator; @GET @Produces(MediaType.APPLICATION_JSON) public JsonObject executeBatch() { BatchSPIManager batchSPIManager = BatchSPIManager.getInstance(); batchSPIManager.registerPlatformMode(BatchSPIManager.PlatformMode.SE); batchSPIManager.registerExecutorServiceProvider(new HelidonExecutorServiceProvider()); jobOperator = getJobOperator(); Long executionId = jobOperator.start(\"myJob\", new Properties()); return JSON.createObjectBuilder() .add(\"Started a job with Execution ID: \", executionId) .build(); } @GET @Path(\"/status/{execution-id}\") public JsonObject status(@PathParam(\"execution-id\") Long executionId){ JobExecution jobExecution = jobOperator.getJobExecution(executionId); List&lt;StepExecution&gt; stepExecutions = jobOperator.getStepExecutions(executionId); List&lt;String&gt; executedSteps = new ArrayList&lt;&gt;(); for (StepExecution stepExecution : stepExecutions) { executedSteps.add(stepExecution.getStepName()); } return JSON.createObjectBuilder() .add(\"Steps executed\", Arrays.toString(executedSteps.toArray())) .add(\"Status\", jobExecution.getBatchStatus().toString()) .build(); } } Helidon specifies to JBatch that it should run in Standalone (SE) mode. It will also register the HelidonExecutorServiceProvider which is actually relatively small. For our example we need something really small, like a FixedTheadPool with 2 threads. This provider is used to tell our JBatch engine exactly which ExecutorSevice to use. <markup lang=\"java\" title=\"HelidonExecutorServiceProvider\" >public class HelidonExecutorServiceProvider implements ExecutorServiceProvider { @Override public ExecutorService getExecutorService() { return ThreadPoolSupplier.builder().corePoolSize(2).build().get(); } } ",
            "title": "Create an Endpoint"
        },
        {
            "location": "/mp/guides/39_jbatch",
            "text": "<markup lang=\"bash\" >mvn package java -jar target/helidon-jbatch-example.jar ",
            "title": "Run the Code"
        },
        {
            "location": "/mp/guides/39_jbatch",
            "text": "<markup lang=\"bash\" >curl -X GET http://localhost:8080/batch/status/1 In this example the job ID is 1, but make sure that you enter your specfic job ID in the string. The results should look something like this: <markup lang=\"bash\" >{\"Steps executed\":\"[step1, step2]\",\"Status\":\"COMPLETED\"} ",
            "title": "Check the Status"
        },
        {
            "location": "/mp/guides/39_jbatch",
            "text": "<markup lang=\"bash\" >curl -X GET http://localhost:8080/batch You should receive the following log: <markup lang=\"bash\" >processItem: MyInputRecord: 1 processItem: MyInputRecord: 2 processItem: MyInputRecord: 3 writeItems: [MyOutputRecord: 2, MyOutputRecord: 6] processItem: MyInputRecord: 4 processItem: MyInputRecord: 5 processItem: MyInputRecord: 6 writeItems: [MyOutputRecord: 10] processItem: MyInputRecord: 7 processItem: MyInputRecord: 8 processItem: MyInputRecord: 9 writeItems: [MyOutputRecord: 14, MyOutputRecord: 18] processItem: MyInputRecord: 10 Running inside a batchlet and the following result: <markup lang=\"bash\" >{\"Started a job with Execution ID: \":1} This indicates that the batch job was called and executed successfully. Check the Status <markup lang=\"bash\" >curl -X GET http://localhost:8080/batch/status/1 In this example the job ID is 1, but make sure that you enter your specfic job ID in the string. The results should look something like this: <markup lang=\"bash\" >{\"Steps executed\":\"[step1, step2]\",\"Status\":\"COMPLETED\"} ",
            "title": "Call the Endpoint"
        },
        {
            "location": "/mp/guides/39_jbatch",
            "text": " This guide demonstrated how to use Helidon with JBatch even though Helidon is not a full EE container. ",
            "title": "Summary"
        },
        {
            "location": "/se/guides/25_maven_build",
            "text": " This guide describes Helidon&#8217;s support for Maven projects. ",
            "title": "preambule"
        },
        {
            "location": "/se/guides/25_maven_build",
            "text": " Helidon supports Maven by providing the following: The Helidon Application parent POM Dependency management via the Helidon BOM and Dependencies POMs The helidon-maven-plugin ",
            "title": "Introduction"
        },
        {
            "location": "/se/guides/25_maven_build",
            "text": " Helidon examples and projects generated using the Helidon Quickstart use a Helidon application POM as their parent. This parent POM provides the following: Helidon dependency management. Maven plugin configurations to help in the building and packaging of your Helidon application. If you want to use your own parent POM, then take a look at the standalone quickstart example . This example has a stand-alone POM that you can pattern your own application POM after. For more details on Helidon application POMs see the Helidon&#8217;s Application POMS ",
            "title": "The Helidon Application POM"
        },
        {
            "location": "/se/guides/25_maven_build",
            "text": " In Maven you use Dependency Management to manage the versions of the dependencies used by your project so that you do not need to specify versions when declaring project dependencies. Helidon provides two POMs that are used together for dependency management: The Helidon Bill of Materials (BOM) POM ( io.helidon:helidon-bom ): manages the version of Helidon artifacts (to align with the Helidon version). The Helidon Dependencies POM ( io.helidon:helidon-dependencies ): manages the versions of third party dependencies to ensure consistency across Helidon and your Helidon application. Inherits the Helidon BOM POM. When you use a Helidon Application POM as your project&#8217;s parent pom, you inherit Helidon&#8217;s dependency management. If you have your own parent, then you can import Helidon dependency management like this: <markup lang=\"xml\" title=\"Import Helidon Dependency Management\" >&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon&lt;/groupId&gt; &lt;artifactId&gt;helidon-dependencies&lt;/artifactId&gt; &lt;version&gt;2.5.4&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; You then declare dependencies on Helidon (and other) components without specifying a version. <markup lang=\"xml\" title=\"Component dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webserver&lt;/groupId&gt; &lt;artifactId&gt;helidon-webserver&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Dependency Management"
        },
        {
            "location": "/se/guides/25_maven_build",
            "text": " You can override many of the plugin attributes by passing a system property to the mvn command: <markup >mvn -Djlink.image.addClassDataSharingArchive=false ... ",
            "title": "Pass Property on Command Line"
        },
        {
            "location": "/se/guides/25_maven_build",
            "text": " Or you can set the properties in your project&#8217;s pom.xml: <markup >&lt;properties&gt; &lt;jlink.image.addClassDataSharingArchive&gt;false&lt;/jlink.image.addClassDataSharingArchive&gt; &lt;native.image.reportExceptionStackTraces&gt;true&lt;/native.image.reportExceptionStackTraces&gt; &lt;/properties&gt; ",
            "title": "Set Property in pom.xml"
        },
        {
            "location": "/se/guides/25_maven_build",
            "text": " For full control you can override the plugin&#8217;s configuration using pluginManagement : <markup lang=\"xml\" title=\"Turn off generation of the CDS Archive when generating a custom Java runtime image\" > &lt;build&gt; &lt;pluginManagement&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;io.helidon.build-tools&lt;/groupId&gt; &lt;artifactId&gt;helidon-maven-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;jlink-image&lt;/id&gt; &lt;configuration&gt; &lt;addClassDataSharingArchive&gt;false&lt;/addClassDataSharingArchive&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;/build&gt; <markup lang=\"xml\" title=\"Override final name of native image binary\" > &lt;build&gt; &lt;pluginManagement&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;io.helidon.build-tools&lt;/groupId&gt; &lt;artifactId&gt;helidon-maven-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;native-image&lt;/id&gt; &lt;configuration&gt; &lt;finalName&gt;my-fantastic-service&lt;/finalName&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;/build&gt; ",
            "title": "Override Plugin Configuration using pluginManagement "
        },
        {
            "location": "/se/guides/25_maven_build",
            "text": " Helidon provides a Maven plugin that, among other things, provides the following goals: native-image: Build a GraalVM native image . jlink-image: Build a custom runtime Java image . For full documentation of the plugin please see the Helidon Maven Plugin README . If you use the Helidon application parent POM you will have this plugin configured for you. If you need to customize the helidon-maven-plugin you can do so in a few ways: Passing system properties to Maven on the command line. Setting system properties in your project&#8217;s pom.xml Overriding the plugin configuration by using pluginManagment Pass Property on Command Line You can override many of the plugin attributes by passing a system property to the mvn command: <markup >mvn -Djlink.image.addClassDataSharingArchive=false ... Set Property in pom.xml Or you can set the properties in your project&#8217;s pom.xml: <markup >&lt;properties&gt; &lt;jlink.image.addClassDataSharingArchive&gt;false&lt;/jlink.image.addClassDataSharingArchive&gt; &lt;native.image.reportExceptionStackTraces&gt;true&lt;/native.image.reportExceptionStackTraces&gt; &lt;/properties&gt; Override Plugin Configuration using pluginManagement For full control you can override the plugin&#8217;s configuration using pluginManagement : <markup lang=\"xml\" title=\"Turn off generation of the CDS Archive when generating a custom Java runtime image\" > &lt;build&gt; &lt;pluginManagement&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;io.helidon.build-tools&lt;/groupId&gt; &lt;artifactId&gt;helidon-maven-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;jlink-image&lt;/id&gt; &lt;configuration&gt; &lt;addClassDataSharingArchive&gt;false&lt;/addClassDataSharingArchive&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;/build&gt; <markup lang=\"xml\" title=\"Override final name of native image binary\" > &lt;build&gt; &lt;pluginManagement&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;io.helidon.build-tools&lt;/groupId&gt; &lt;artifactId&gt;helidon-maven-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;native-image&lt;/id&gt; &lt;configuration&gt; &lt;finalName&gt;my-fantastic-service&lt;/finalName&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;/build&gt; ",
            "title": "The helidon-maven-plugin "
        },
        {
            "location": "/se/reactivestreams/01_overview",
            "text": " fa-cogs Helidon Reactive Engine A set of reactive operators. fa-book MicroProfile Reactive Streams Operators Microprofile implementation. There are two handy apis for working with reactive streams available in Helidon, one for working with java.util.concurrent.Flow and second for org.reactivestreams based reactive components. ",
            "title": "Reactive Streams"
        },
        {
            "location": "/se/metrics/01a_metrics_capable_components",
            "text": " This document explains Helidon SE metrics-capable components and applications and describes how to create and control them. ",
            "title": "preambule"
        },
        {
            "location": "/se/metrics/01a_metrics_capable_components",
            "text": " Think of Helidon metrics in three related but different parts: The Helidon metrics API allows your code to register, look-up, remove, and update metrics using the RegistryFactory , MetricRegistry , and individual metrics interfaces. Helidon provides two implementations of the Helidon metrics API and selects which one to use at runtime, based on what components are present on the runtime path and whether metrics is configured to be enabled or disabled. The built-in Helidon metrics web service supports the /metrics endpoints by which clients can retrieve metadata and values of the registered metrics. Your Helidon SE app provides this feature (if at all) by explicitly using the MetricsSupport interface. Most Helidon applications are web-based and their developers choose to expose the built-in metrics web service. But by separating the parts of metrics this way, Helidon allows non-web apps to work with metrics as well, just without the web service support. As you plan and write Helidon components and applications, you make some choices about exactly how your code will use metrics. This guide gives some background information, describes the choices you face, explains their ramifications, and provides some code examples. ",
            "title": "Introduction"
        },
        {
            "location": "/se/metrics/01a_metrics_capable_components",
            "text": " We can place each Helidon component and Helidon application into one of three categories based on how it relies on metrics. The type of module dictates the compile-time dependency you declare in the project pom.xml . Types of Metrics Usage Registers, updates, removes metrics? Refers to metrics values? Category times times metrics-independent check times metrics-capable check check metrics-dependent Whenever possible, if your component or app uses metrics write it as metrics-capable code. ",
            "title": "Categorizing Metrics Usage"
        },
        {
            "location": "/se/metrics/01a_metrics_capable_components",
            "text": " Helidon provides two metrics implementations. Full-featured metrics allows registering, removing, and updating metrics and observing metrics' changing values. The helidon-metrics component contains full-featured metrics. Minimal metrics supports registering, removing, and updating metrics. The metrics objects provided by the minimal implementation are no-ops: their values never change. The minimal implementation is part of the helidon-metrics-api component. Any code compiled with helidon-metrics-api can assume that the runtime path will include the minimal implementation. Both implementations support all the operations of the RegistryFactory and the MetricRegistry . The full implementation provides fully-functional metrics instances (counters, timers, etc.). In the minimal implementations, metrics do not update their values. For Helidon to use the full implementation, two conditions must hold: The helidon-metrics component must be on the runtime path. Metrics must be enabled, using either a builder or configuration. (Enabled is the default.) Otherwise, provided that the runtime path includes helidon-metrics-api , Helidon activates the minimal implementation. ",
            "title": "Understanding the Two Metrics Implementations"
        },
        {
            "location": "/se/metrics/01a_metrics_capable_components",
            "text": " Helidon includes two implementations of support for the metrics web service endpoint /metrics (or whatever context value is configured). The full-service implementation sends responses which describe the metadata and current values for the metrics registered in metric registries. The helidon-metrics component contains this implementation. The helidon-metrics-service-api component contains the API for the metrics web service support (the MetricsSupport interface) and also a minimal implementation. This implementation simply responds with 404 and an explanatory message that metrics are disabled. Any code compiled with helidon-metrics-service-api can assume that the runtime path will contain the minimal implementation. Helidon activates the full implementation if the runtime path includes the full implementation and metrics is configured as enabled; Helidon uses the minimal implementation otherwise. ",
            "title": "Understanding the Two Metrics Service Implementations"
        },
        {
            "location": "/se/metrics/01a_metrics_capable_components",
            "text": " Using either builder-style settings or configuration, your component or Helidon SE application can let end users control at runtime whether Helidon should use full-featured metrics. If an end user sets metrics.enabled to false , then Helidon activates the minimal metrics and metrics service implementations provided they are in the runtime path. Further, users can set component-name.metrics.enabled to false which disables metrics for just that component so long as the component was written to check that setting and act on it accordingly. ",
            "title": "Enabling and Disabling Metrics"
        },
        {
            "location": "/se/metrics/01a_metrics_capable_components",
            "text": " Include this dependency: <markup lang=\"xml\" title=\"Dependency for Helidon metrics API\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics-api&lt;/artifactId&gt; &lt;/dependency&gt; This module defines the metrics API: RegistryFactory , MetricRegistry , and the various metrics themselves. To permit the use of the built-in metrics web service support for the /metrics endpoint, add this dependency: <markup lang=\"xml\" title=\"Dependency for metrics web service support\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics-service-api&lt;/artifactId&gt; &lt;/dependency&gt; This module defines the metrics web service API: MetricsSupport . Use the MetricsSupport interface from helidon-metrics-service-api in your SE app initialization code to create a service you can register with the web server. (See the example below .) Declare an explicit runtime dependency on the full-featured metrics implementation: <markup lang=\"xml\" title=\"Dependency for full metrics and metrics service implementations\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; ",
            "title": "Declaring Dependencies"
        },
        {
            "location": "/se/metrics/01a_metrics_capable_components",
            "text": " Write your non-application component to accept component-specific configuration that includes an optional metrics section which can include an optional enabled setting. Helidon defaults the value to true . The following example shows one way to accomplish this: <markup lang=\"java\" title=\"Example code to support disabling metrics usage in a component\" >import io.helidon.config.Config; import io.helidon.metrics.api.ComponentMetricsSettings; import io.helidon.metrics.api.MetricsSettings; import io.helidon.metrics.api.RegistryFactory; import org.eclipse.microprofile.metrics.MetricRegistry; public class UtilComponent { private final MetricRegistry metricRegistry; public static class Builder implements io.helidon.common.Builder&lt;UtilComponent&gt; { private ComponentMetricsSettings.Builder componentMetricsSettingsBuilder = ComponentMetricsSettings.builder(); public Builder componentMetricsSettings(ComponentMetricsSettings.Builder componentMetricsSettingsBuilder) { this.componentMetricsSettingsBuilder = componentMetricsSettingsBuilder; return this; } public Builder config(Config componentConfig) { componentConfig .get(ComponentMetricsSettings.Builder.METRICS_CONFIG_KEY) .as(ComponentMetricsSettings::create) .ifPresent(this::componentMetricsSettings); return this; } public UtilComponent build() { return new UtilComponent(this); } ... } private UtilComponent(Builder builder) { ... metricRegistry = RegistryFactory .getInstance(builder.componentMetricsSettingsBuilder.build()) .getRegistry(MetricRegistry.Type.VENDOR); } MetricRegistry metricRegistry() { return metricRegistry; } } Other code in the component uses this metric registry for registering, looking up, and removing metrics. Applications which use instances of MyComponent use this Builder to set up and create those instances. Applications which layer on your component invoke this method to set up the component-level metrics behavior they want your component to use. If an application supports configuration, it passes the util config to this method. The constructor for your component obtains the MetricRegistry which the rest of your component will use. Provides easy access to the MetricRegistry which the component&#8217;s metrics code should use. Helidon returns either a full-featured RegistryFactory or a minimal one, depending on: whether the full-featured metrics implementation is on the runtime path, whether metrics overall is enabled or disabled, and whether the component metrics settings requests enabled or disabled metrics. ",
            "title": "Writing a Non-application Component "
        },
        {
            "location": "/se/metrics/01a_metrics_capable_components",
            "text": " Write your SE application similarly, but do not use the ComponentMetricsSettings . Instead, build a MetricsSettings object from the configuration. <markup lang=\"java\" title=\"Example code to support disabling metrics usage in a component\" >import io.helidon.config.Config; import io.helidon.metrics.api.MetricsSettings; import io.helidon.metrics.api.RegistryFactory; import io.helidon.webserver.WebServer; import org.eclipse.microprofile.metrics.MetricRegistry; public class MyApp { private static MetricsSettings metricsSettings; static MetricRegistry metricRegistry; public static void main(final String[] args) { startServer(); } static Single&lt;WebServer&gt; startServer() { ... Config config = Config.create(); metricsSettings = MetricsSettings.builder() .config(config) .build(); metricRegistry = RegistryFactory.getInstance(metricsSettings) .getRegistry(MetricRegistry.Type.APPLICATION); WebServer server = WebServer.builder(createRouting(config)) .config(config.get(\"server\")) .addMediaSupport(JsonpSupport.create()) .build(); ... } private static Routing createRouting(Config config) { RestServiceSettings restServiceSettings = RestServiceSettings.create(config); MetricsSupport metricsSupport = MetricsSupport.create(metricsSettings, restServiceSettings); GreetService greetService = new GreetService(config); return Routing.builder() .register(metricsSupport) .register(\"/greet\", greetService) .build(); } } Create and save MetricsSettings from config. Use MetricsSettings to get a suitable RegistryFactory , and use that to get the application registry. Pass config to createRouting which returns the Routing to initialize the web server. Use the config to create RestServiceSettings which controls the routing name, web context, and CORS set-up for the metrics endpoint. Create the MetricsSupport instance using the metrics and REST service settings. Add the properly initialized MetricsSupport instance as a service to the routing, along with the app&#8217;s own service. Helidon uses the enabled value from MetricsSettings in providing the correct implementations of both the RegistryFactory and the MetricsSupport . ",
            "title": "Writing and Packaging a Metrics-capable Helidon SE Application "
        },
        {
            "location": "/se/metrics/01a_metrics_capable_components",
            "text": " Here is an example showing how useful metrics-capable code can be. You (or others) could assemble a Docker image with your metrics-capable app as its top layer or your metrics-capable component in a middle layer, built on a lower layer containing several Helidon modules including the full metrics implementation. When that Docker image runs, your app will run with full-featured metrics support. Separately, someone could build a similar Docker image which does not include the Helidon metrics implementation. In this Docker image, your app or component will run successfully but will not incur the overhead of actually updating the metrics it uses. Users can create different Docker images, some with full metrics support and some without, which all use a single version of your metrics-capable app or component which runs properly in either environment without change. ",
            "title": "An Example: Docker Images"
        },
        {
            "location": "/se/metrics/01a_metrics_capable_components",
            "text": " The way you write a metrics-capable module depends on whether it is a component (that is, not an application) or an application . Writing a Non-application Component Write your non-application component to accept component-specific configuration that includes an optional metrics section which can include an optional enabled setting. Helidon defaults the value to true . The following example shows one way to accomplish this: <markup lang=\"java\" title=\"Example code to support disabling metrics usage in a component\" >import io.helidon.config.Config; import io.helidon.metrics.api.ComponentMetricsSettings; import io.helidon.metrics.api.MetricsSettings; import io.helidon.metrics.api.RegistryFactory; import org.eclipse.microprofile.metrics.MetricRegistry; public class UtilComponent { private final MetricRegistry metricRegistry; public static class Builder implements io.helidon.common.Builder&lt;UtilComponent&gt; { private ComponentMetricsSettings.Builder componentMetricsSettingsBuilder = ComponentMetricsSettings.builder(); public Builder componentMetricsSettings(ComponentMetricsSettings.Builder componentMetricsSettingsBuilder) { this.componentMetricsSettingsBuilder = componentMetricsSettingsBuilder; return this; } public Builder config(Config componentConfig) { componentConfig .get(ComponentMetricsSettings.Builder.METRICS_CONFIG_KEY) .as(ComponentMetricsSettings::create) .ifPresent(this::componentMetricsSettings); return this; } public UtilComponent build() { return new UtilComponent(this); } ... } private UtilComponent(Builder builder) { ... metricRegistry = RegistryFactory .getInstance(builder.componentMetricsSettingsBuilder.build()) .getRegistry(MetricRegistry.Type.VENDOR); } MetricRegistry metricRegistry() { return metricRegistry; } } Other code in the component uses this metric registry for registering, looking up, and removing metrics. Applications which use instances of MyComponent use this Builder to set up and create those instances. Applications which layer on your component invoke this method to set up the component-level metrics behavior they want your component to use. If an application supports configuration, it passes the util config to this method. The constructor for your component obtains the MetricRegistry which the rest of your component will use. Provides easy access to the MetricRegistry which the component&#8217;s metrics code should use. Helidon returns either a full-featured RegistryFactory or a minimal one, depending on: whether the full-featured metrics implementation is on the runtime path, whether metrics overall is enabled or disabled, and whether the component metrics settings requests enabled or disabled metrics. Writing and Packaging a Metrics-capable Helidon SE Application Write your SE application similarly, but do not use the ComponentMetricsSettings . Instead, build a MetricsSettings object from the configuration. <markup lang=\"java\" title=\"Example code to support disabling metrics usage in a component\" >import io.helidon.config.Config; import io.helidon.metrics.api.MetricsSettings; import io.helidon.metrics.api.RegistryFactory; import io.helidon.webserver.WebServer; import org.eclipse.microprofile.metrics.MetricRegistry; public class MyApp { private static MetricsSettings metricsSettings; static MetricRegistry metricRegistry; public static void main(final String[] args) { startServer(); } static Single&lt;WebServer&gt; startServer() { ... Config config = Config.create(); metricsSettings = MetricsSettings.builder() .config(config) .build(); metricRegistry = RegistryFactory.getInstance(metricsSettings) .getRegistry(MetricRegistry.Type.APPLICATION); WebServer server = WebServer.builder(createRouting(config)) .config(config.get(\"server\")) .addMediaSupport(JsonpSupport.create()) .build(); ... } private static Routing createRouting(Config config) { RestServiceSettings restServiceSettings = RestServiceSettings.create(config); MetricsSupport metricsSupport = MetricsSupport.create(metricsSettings, restServiceSettings); GreetService greetService = new GreetService(config); return Routing.builder() .register(metricsSupport) .register(\"/greet\", greetService) .build(); } } Create and save MetricsSettings from config. Use MetricsSettings to get a suitable RegistryFactory , and use that to get the application registry. Pass config to createRouting which returns the Routing to initialize the web server. Use the config to create RestServiceSettings which controls the routing name, web context, and CORS set-up for the metrics endpoint. Create the MetricsSupport instance using the metrics and REST service settings. Add the properly initialized MetricsSupport instance as a service to the routing, along with the app&#8217;s own service. Helidon uses the enabled value from MetricsSettings in providing the correct implementations of both the RegistryFactory and the MetricsSupport . An Example: Docker Images Here is an example showing how useful metrics-capable code can be. You (or others) could assemble a Docker image with your metrics-capable app as its top layer or your metrics-capable component in a middle layer, built on a lower layer containing several Helidon modules including the full metrics implementation. When that Docker image runs, your app will run with full-featured metrics support. Separately, someone could build a similar Docker image which does not include the Helidon metrics implementation. In this Docker image, your app or component will run successfully but will not incur the overhead of actually updating the metrics it uses. Users can create different Docker images, some with full metrics support and some without, which all use a single version of your metrics-capable app or component which runs properly in either environment without change. ",
            "title": "Writing the Metrics-capable Code"
        },
        {
            "location": "/se/metrics/01a_metrics_capable_components",
            "text": " Whoever packages and deploys your application or component can control what code will be on the runtime path and whether metrics is enabled or not. As a result, wherever possible, construct your modules which use metrics so that they do not make decisions based on the values of metrics; that is, design them to be metrics-capable, not metrics-dependent. Doing so allows your code to operate regardless of whether the full-featured metrics implementation is active at runtime. Declaring Dependencies Include this dependency: <markup lang=\"xml\" title=\"Dependency for Helidon metrics API\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics-api&lt;/artifactId&gt; &lt;/dependency&gt; This module defines the metrics API: RegistryFactory , MetricRegistry , and the various metrics themselves. To permit the use of the built-in metrics web service support for the /metrics endpoint, add this dependency: <markup lang=\"xml\" title=\"Dependency for metrics web service support\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics-service-api&lt;/artifactId&gt; &lt;/dependency&gt; This module defines the metrics web service API: MetricsSupport . Use the MetricsSupport interface from helidon-metrics-service-api in your SE app initialization code to create a service you can register with the web server. (See the example below .) Declare an explicit runtime dependency on the full-featured metrics implementation: <markup lang=\"xml\" title=\"Dependency for full metrics and metrics service implementations\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; Writing the Metrics-capable Code The way you write a metrics-capable module depends on whether it is a component (that is, not an application) or an application . Writing a Non-application Component Write your non-application component to accept component-specific configuration that includes an optional metrics section which can include an optional enabled setting. Helidon defaults the value to true . The following example shows one way to accomplish this: <markup lang=\"java\" title=\"Example code to support disabling metrics usage in a component\" >import io.helidon.config.Config; import io.helidon.metrics.api.ComponentMetricsSettings; import io.helidon.metrics.api.MetricsSettings; import io.helidon.metrics.api.RegistryFactory; import org.eclipse.microprofile.metrics.MetricRegistry; public class UtilComponent { private final MetricRegistry metricRegistry; public static class Builder implements io.helidon.common.Builder&lt;UtilComponent&gt; { private ComponentMetricsSettings.Builder componentMetricsSettingsBuilder = ComponentMetricsSettings.builder(); public Builder componentMetricsSettings(ComponentMetricsSettings.Builder componentMetricsSettingsBuilder) { this.componentMetricsSettingsBuilder = componentMetricsSettingsBuilder; return this; } public Builder config(Config componentConfig) { componentConfig .get(ComponentMetricsSettings.Builder.METRICS_CONFIG_KEY) .as(ComponentMetricsSettings::create) .ifPresent(this::componentMetricsSettings); return this; } public UtilComponent build() { return new UtilComponent(this); } ... } private UtilComponent(Builder builder) { ... metricRegistry = RegistryFactory .getInstance(builder.componentMetricsSettingsBuilder.build()) .getRegistry(MetricRegistry.Type.VENDOR); } MetricRegistry metricRegistry() { return metricRegistry; } } Other code in the component uses this metric registry for registering, looking up, and removing metrics. Applications which use instances of MyComponent use this Builder to set up and create those instances. Applications which layer on your component invoke this method to set up the component-level metrics behavior they want your component to use. If an application supports configuration, it passes the util config to this method. The constructor for your component obtains the MetricRegistry which the rest of your component will use. Provides easy access to the MetricRegistry which the component&#8217;s metrics code should use. Helidon returns either a full-featured RegistryFactory or a minimal one, depending on: whether the full-featured metrics implementation is on the runtime path, whether metrics overall is enabled or disabled, and whether the component metrics settings requests enabled or disabled metrics. Writing and Packaging a Metrics-capable Helidon SE Application Write your SE application similarly, but do not use the ComponentMetricsSettings . Instead, build a MetricsSettings object from the configuration. <markup lang=\"java\" title=\"Example code to support disabling metrics usage in a component\" >import io.helidon.config.Config; import io.helidon.metrics.api.MetricsSettings; import io.helidon.metrics.api.RegistryFactory; import io.helidon.webserver.WebServer; import org.eclipse.microprofile.metrics.MetricRegistry; public class MyApp { private static MetricsSettings metricsSettings; static MetricRegistry metricRegistry; public static void main(final String[] args) { startServer(); } static Single&lt;WebServer&gt; startServer() { ... Config config = Config.create(); metricsSettings = MetricsSettings.builder() .config(config) .build(); metricRegistry = RegistryFactory.getInstance(metricsSettings) .getRegistry(MetricRegistry.Type.APPLICATION); WebServer server = WebServer.builder(createRouting(config)) .config(config.get(\"server\")) .addMediaSupport(JsonpSupport.create()) .build(); ... } private static Routing createRouting(Config config) { RestServiceSettings restServiceSettings = RestServiceSettings.create(config); MetricsSupport metricsSupport = MetricsSupport.create(metricsSettings, restServiceSettings); GreetService greetService = new GreetService(config); return Routing.builder() .register(metricsSupport) .register(\"/greet\", greetService) .build(); } } Create and save MetricsSettings from config. Use MetricsSettings to get a suitable RegistryFactory , and use that to get the application registry. Pass config to createRouting which returns the Routing to initialize the web server. Use the config to create RestServiceSettings which controls the routing name, web context, and CORS set-up for the metrics endpoint. Create the MetricsSupport instance using the metrics and REST service settings. Add the properly initialized MetricsSupport instance as a service to the routing, along with the app&#8217;s own service. Helidon uses the enabled value from MetricsSettings in providing the correct implementations of both the RegistryFactory and the MetricsSupport . An Example: Docker Images Here is an example showing how useful metrics-capable code can be. You (or others) could assemble a Docker image with your metrics-capable app as its top layer or your metrics-capable component in a middle layer, built on a lower layer containing several Helidon modules including the full metrics implementation. When that Docker image runs, your app will run with full-featured metrics support. Separately, someone could build a similar Docker image which does not include the Helidon metrics implementation. In this Docker image, your app or component will run successfully but will not incur the overhead of actually updating the metrics it uses. Users can create different Docker images, some with full metrics support and some without, which all use a single version of your metrics-capable app or component which runs properly in either environment without change. ",
            "title": "Designing and Writing Metrics-capable Applications and Components"
        },
        {
            "location": "/se/metrics/01a_metrics_capable_components",
            "text": " By writing a metrics-capable app or component, you give packagers and deployers of your code the flexibility to include or exclude the full metrics implementation at runtime as they see fit. Because your one module works correctly in either environment: The consumers of your app benefit by not needing to understand and choose between two different implementations of your module, or having to add both your main module and an optional add-on which adds metrics support to your module. You benefit by writing and maintaining a single module, not two: one that is metrics-independent and one that is metrics-dependent. ",
            "title": "Advantages of Writing Metrics-capable Modules"
        },
        {
            "location": "/mp/oci/03_vault",
            "text": " You can use Helidon&#8217;s OCI SDK Extension to access OCI Services. This document describes how to use it to access OCI Vault. ",
            "title": "preambule"
        },
        {
            "location": "/mp/oci/03_vault",
            "text": " To enable OCI Vault add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.oci.sdk&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-oci-sdk-cdi&lt;/artifactId&gt; &lt;/dependency&gt; Then add dependencies on the OCI SDK&#8217;s Vault API. Your specific dependencies may differ depending on the OCI SDK features you use. <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;com.oracle.oci.sdk&lt;/groupId&gt; &lt;artifactId&gt;oci-java-sdk-vault&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.oracle.oci.sdk&lt;/groupId&gt; &lt;artifactId&gt;oci-java-sdk-keymanagement&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.oracle.oci.sdk&lt;/groupId&gt; &lt;artifactId&gt;oci-java-sdk-secrets&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/oci/03_vault",
            "text": " Once you have Helidon&#8217;s OCI extension added to your application you can inject OCI SDK Clients. <markup lang=\"java\" title=\"Field-injection example\" > @Inject private Vaults vaults; <markup lang=\"java\" title=\"Constructor-injection example\" > @Inject VaultResource(Secrets secrets, KmsCrypto crypto, Vaults vaults) { this.secrets = secrets; this.crypto = crypto; this.vaults = vaults; } The extension implements these injection points by creating objects in the singleton scope . ",
            "title": "Injecting a Vault client"
        },
        {
            "location": "/mp/oci/03_vault",
            "text": " By default the extension will select and configure an appropriate OCI Authentication Details Provider for you based on your environment. For this reason it is recommended that you configure your environment first and get it working with the OCI CLI before using the Helidon OCI SDK Extension. For more information see Helidon OCI Extension . ",
            "title": "Configuring the Helidon OCI SDK Extension"
        },
        {
            "location": "/mp/oci/03_vault",
            "text": " Once you have injected OCI Vault objects you can use them as described in: OCI SDK Vault Javadocs OCI Vault Overview ",
            "title": "Using the Vault client"
        },
        {
            "location": "/se/webserver/10_jackson-support",
            "text": " To enable Jackson Support add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.media&lt;/groupId&gt; &lt;artifactId&gt;helidon-media-jackson&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/webserver/10_jackson-support",
            "text": " To enable Jackson support, first create and register a JacksonSupport instance with a WebServer.Builder . <markup lang=\"java\" title=\"Registration of the JacksonSupport via WebServer \" >JacksonSupport jacksonSupport = JacksonSupport.create(); WebServer webServer = WebServer.builder() .addMediaSupport(jacksonSupport) .build(); Create a JacksonSupport instance. This instance may be reused freely. Register that JacksonSupport instance to enable automatic deserialization of Java objects from and serialization of Java objects to JSON. Now that automatic JSON serialization and deserialization facilities have been set up, you can register a Handler that works with Java objects instead of raw JSON. Deserialization from and serialization to JSON will be handled by Jackson . Suppose you have a Person class that looks like this: <markup lang=\"java\" title=\"Hypothetical Person class\" >public class Person { private String name; public Person() { super(); } public String getName() { return this.name; } public void setName(final String name) { this.name = name; } } Then you can set up a Handler like this: <markup lang=\"java\" title=\"A Handler that works with Java objects instead of raw JSON\" >final Routing routing = routingBuilder.post(\"/echo\", Handler.create(Person.class, (req, res, person) -&gt; res.send(person)))) .build(); Set up a route for POST requests using the Routing.Builder#post(String, Handler&#8230;&#8203;) method Use the Handler#create(Class, Handler.EntityHandler) method to install a Handler.EntityHandler that works with Person instances. This Handler.EntityHandler consumes a Person instance ( person ) and simply echoes it back. Note that there is no working with raw JSON here. <markup lang=\"bash\" title=\"Example of posting JSON to the /echo endpoint\" >curl --noproxy '*' -X POST -H \"Content-Type: application/json\" \\ http://localhost:8080/echo -d '{\"name\":\"Joe\"}' {\"name\":\"Joe\"} ",
            "title": "Usage"
        },
        {
            "location": "/se/webserver/10_jackson-support",
            "text": " The WebServer supports Jackson . When this support is enabled, Java objects will be serialized to and deserialized from JSON automatically using Jackson. Usage To enable Jackson support, first create and register a JacksonSupport instance with a WebServer.Builder . <markup lang=\"java\" title=\"Registration of the JacksonSupport via WebServer \" >JacksonSupport jacksonSupport = JacksonSupport.create(); WebServer webServer = WebServer.builder() .addMediaSupport(jacksonSupport) .build(); Create a JacksonSupport instance. This instance may be reused freely. Register that JacksonSupport instance to enable automatic deserialization of Java objects from and serialization of Java objects to JSON. Now that automatic JSON serialization and deserialization facilities have been set up, you can register a Handler that works with Java objects instead of raw JSON. Deserialization from and serialization to JSON will be handled by Jackson . Suppose you have a Person class that looks like this: <markup lang=\"java\" title=\"Hypothetical Person class\" >public class Person { private String name; public Person() { super(); } public String getName() { return this.name; } public void setName(final String name) { this.name = name; } } Then you can set up a Handler like this: <markup lang=\"java\" title=\"A Handler that works with Java objects instead of raw JSON\" >final Routing routing = routingBuilder.post(\"/echo\", Handler.create(Person.class, (req, res, person) -&gt; res.send(person)))) .build(); Set up a route for POST requests using the Routing.Builder#post(String, Handler&#8230;&#8203;) method Use the Handler#create(Class, Handler.EntityHandler) method to install a Handler.EntityHandler that works with Person instances. This Handler.EntityHandler consumes a Person instance ( person ) and simply echoes it back. Note that there is no working with raw JSON here. <markup lang=\"bash\" title=\"Example of posting JSON to the /echo endpoint\" >curl --noproxy '*' -X POST -H \"Content-Type: application/json\" \\ http://localhost:8080/echo -d '{\"name\":\"Joe\"}' {\"name\":\"Joe\"} ",
            "title": "Jackson Support"
        },
        {
            "location": "/mp/oci/04_atp",
            "text": " You can use Helidon&#8217;s OCI SDK Extension to access OCI Services. This document describes how to use it to access the OCI Database Service. ",
            "title": "preambule"
        },
        {
            "location": "/mp/oci/04_atp",
            "text": " To enable OCI atp add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.oci.sdk&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-oci-sdk-cdi&lt;/artifactId&gt; &lt;/dependency&gt; Then add dependencies on the OCI SDK&#8217;s Database API. Your specific dependencies may differ depending on the OCI SDK features you use. <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;com.oracle.oci.sdk&lt;/groupId&gt; &lt;artifactId&gt;oci-java-sdk-database&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/oci/04_atp",
            "text": " Once you have Helidon&#8217;s OCI extension added to your application you can inject OCI SDK Clients. <markup lang=\"java\" title=\"Field-injection example\" > @Inject private Database database; The extension implements these injection points by creating objects in the singleton scope . ",
            "title": "Injecting a Database client"
        },
        {
            "location": "/mp/oci/04_atp",
            "text": " By default the extension will select and configure an appropriate OCI Authentication Details Provider for you based on your environment. For this reason it is recommended that you configure your environment first and get it working with the OCI CLI before using the Helidon OCI SDK Extension. For more information see Helidon OCI Extension . ",
            "title": "Configuring the Helidon OCI SDK Extension"
        },
        {
            "location": "/mp/oci/04_atp",
            "text": " Once you have injected OCI Database objects you can use them as described in: OCI SDK Database Javadocs OCI Database Overview ",
            "title": "Using the Database client"
        },
        {
            "location": "/se/grpc/05_interceptors",
            "text": " Helidon gRPC allows you to configure standard `io.grpc.ServerInterceptor`s. For example, you could implement an interceptor that logs each RPC call: <markup lang=\"java\" >class LoggingInterceptor implements ServerInterceptor { private static final Logger LOG = Logger.getLogger(LoggingInterceptor.class.getName()); @Override public &lt;ReqT, ResT&gt; ServerCall.Listener&lt;ReqT&gt; interceptCall(ServerCall&lt;ReqT, ResT&gt; call, Metadata metadata, ServerCallHandler&lt;ReqT, ResT&gt; handler) { LOG.info(() -&gt; \"CALL: \" + call.getMethodDescriptor()); return handler.startCall(call, metadata); } } Implement io.grpc.ServerInterceptor Implement the logging logic Start intercepted call ",
            "title": "Interceptors"
        },
        {
            "location": "/se/grpc/05_interceptors",
            "text": " You can register interceptors globally, in which case they will be applied to all methods of all services, by simply adding them to the GrpcRouting instance: <markup lang=\"java\" >private static GrpcRouting createRouting(Config config) { return GrpcRouting.builder() .intercept(new LoggingInterceptor()) .register(new GreetService(config)) .register(new EchoService()) .build(); } Adds LoggingInterceptor to all methods of GreetService and EchoService You can also register an interceptor for a specific service, either by implementing GrpcService.update method: <markup lang=\"java\" >public class MyService implements GrpcService { @Override public void update(ServiceDescriptor.Rules rules) { rules.intercept(new LoggingInterceptor()) .unary(\"MyMethod\", this::myMethod); } private &lt;ReqT, ResT&gt; void myMethod(ReqT request, StreamObserver&lt;ResT&gt; observer) { // do something } } Adds LoggingInterceptor to all methods of MyService Or by configuring ServiceDescriptor externally, when creating GrpcRouting , which allows you to add interceptors to plain io.grpc.BindableService services as well: <markup lang=\"java\" >private static GrpcRouting createRouting(Config config) { return GrpcRouting.builder() .register(new GreetService(config), cfg -&gt; cfg.intercept(new LoggingInterceptor())) .register(new EchoService()) .build(); } Adds LoggingInterceptor to all methods of GreetService only Finally, you can also register an interceptor at the method level: <markup lang=\"java\" >public class MyService implements GrpcService { @Override public void update(ServiceDescriptor.Rules rules) { rules.unary(\"MyMethod\", this::myMethod, cfg -&gt; cfg.intercept(new LoggingInterceptor())); } private &lt;ReqT, ResT&gt; void myMethod(ReqT request, StreamObserver&lt;ResT&gt; observer) { // do something } } Adds LoggingInterceptor to MyService::MyMethod only ",
            "title": "Registering Interceptors"
        },
        {
            "location": "/se/guides/03_config",
            "text": " This guide describes how to create a sample Helidon SE project that can be used to run some basic examples using both default and custom configuration. ",
            "title": "preambule"
        },
        {
            "location": "/se/guides/03_config",
            "text": " For this 20 minute tutorial, you will need the following: <div class=\"table__overflow elevation-1 flex sm7 \"> A Helidon {upper-case-flavor} Application You can use your own application or use the Helidon {upper-case-flavor} Quickstart to create a sample application. Java&#160;SE&#160;11 ( Open&#160;JDK&#160;11 ) Helidon requires Java 11+. Maven 3.6.1+ Helidon requires Maven 3.6.1+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop ). <markup lang=\"bash\" title=\"Verify Prerequisites\" >java -version mvn --version docker --version kubectl version --short <markup lang=\"bash\" title=\"Setting JAVA_HOME\" ># On Mac export JAVA_HOME=`/usr/libexec/java_home -v 11` # On Linux # Use the appropriate path to your JDK export JAVA_HOME=/usr/lib/jvm/jdk-11 ",
            "title": "What you need"
        },
        {
            "location": "/se/guides/03_config",
            "text": " Use the Helidon SE Maven archetype to create a simple project that can be used for the examples in this guide. <markup lang=\"bash\" title=\"Run the Maven archetype:\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-se \\ -DarchetypeVersion=2.5.4 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-se \\ -Dpackage=io.helidon.examples.quickstart.se <markup lang=\"bash\" title=\"The project will be built and run from the helidon-quickstart-se directory:\" >cd helidon-quickstart-se ",
            "title": "Create a Sample Helidon SE Project"
        },
        {
            "location": "/se/guides/03_config",
            "text": " Helidon configuration sources can use different formats for the configuration data. You can specify the format on a per-source bases, mixing and matching formats as required. Here are the supported formats, each with the extension name you should use. By default, Helidon will determine the media type based on the extension name. Java Property (.properties) JSON (.json) YAML (.yaml) HOCON (.conf) The remainder of this document will use these formats in examples and show you how to configure Helidon to parse them. ",
            "title": "Configuration Formats"
        },
        {
            "location": "/se/guides/03_config",
            "text": " Helidon has an internal configuration, so you are not required to provide any configuration data for your application, though in practice you most likely would. By default, that configuration can be overridden from three sources: system properties, environment variables, and the contents of application.yaml in the classpath. For example, if you specify a custom server port in application.yaml then your server will listen on that port. In your application code, Helidon uses the default configuration when you create a default Config object. See the following code from the project you created. <markup lang=\"Java\" title=\"View Main.startServer :\" > static WebServer startServer() throws IOException { ... Config config = Config.create(); The Config object is created with default settings. ",
            "title": "Default Configuration"
        },
        {
            "location": "/se/guides/03_config",
            "text": " A system property has a higher precedence than application.yaml . <markup lang=\"bash\" title=\"Restart the application with a system property. The app.greeting environment variable is still set:\" >java -Dapp.greeting=\"HelloFromSystemProperty\" -jar target/helidon-quickstart-se.jar <markup lang=\"bash\" title=\"Invoke the endpoint below and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFromSystemProperty World!\" } The system property took precedence over application.yaml . ",
            "title": "System Property Override"
        },
        {
            "location": "/se/guides/03_config",
            "text": " An environment variable has a higher precedence than the system property. <markup lang=\"bash\" title=\"Set the environment variable and restart the application:\" >export APP_GREETING=HelloFromEnvironment java -Dapp.greeting=\"HelloFromSystemProperty\" -jar target/helidon-quickstart-se.jar <markup lang=\"bash\" title=\"Invoke the endpoint below and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFromEnvironment World!\" } The environment variable APP_GREETING took precedence over the system property and the value in application.yaml . ",
            "title": "Environment Variable Override"
        },
        {
            "location": "/se/guides/03_config",
            "text": " Change a configuration parameter in the default configuration resource file, application.yaml . There are no environment variable or system property overrides defined. <markup lang=\"bash\" title=\"Change app.greeting in resources/application.yaml as follows:\" >app: greeting: HelloFrom-application.yaml <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-se.jar <markup lang=\"bash\" title=\"Run the curl command in a new terminal window and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFrom-application.yaml World!\" } The new app.greeting value in application.yaml is used. System Property Override A system property has a higher precedence than application.yaml . <markup lang=\"bash\" title=\"Restart the application with a system property. The app.greeting environment variable is still set:\" >java -Dapp.greeting=\"HelloFromSystemProperty\" -jar target/helidon-quickstart-se.jar <markup lang=\"bash\" title=\"Invoke the endpoint below and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFromSystemProperty World!\" } The system property took precedence over application.yaml . Environment Variable Override An environment variable has a higher precedence than the system property. <markup lang=\"bash\" title=\"Set the environment variable and restart the application:\" >export APP_GREETING=HelloFromEnvironment java -Dapp.greeting=\"HelloFromSystemProperty\" -jar target/helidon-quickstart-se.jar <markup lang=\"bash\" title=\"Invoke the endpoint below and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFromEnvironment World!\" } The environment variable APP_GREETING took precedence over the system property and the value in application.yaml . ",
            "title": "Default Configuration Resource"
        },
        {
            "location": "/se/guides/03_config",
            "text": " In order to properly configure your application using configuration sources, you need to understand the precedence rules that Helidon uses to merge your configuration data. By default, Helidon will use the following sources in precedence order: Environment variables Java system properties Configuration specified in application.yaml If any of the Helidon required properties are not specified in one of these source, like server.port , then Helidon will use a default value. Because environment variable names are restricted to alphanumeric characters and underscore, Helidon adds aliases to the environment configuration source, allowing entries with dotted and/or hyphenated keys to be overriden. For example, this mapping allows an environment variable named \"APP_GREETING\" to override an entry key named \"app.greeting\". In the same way, an environment variable named \"APP_dash_GREETING\" will map to \"app-greeting\". See Advanced Config for more information. The following examples will demonstrate the default precedence order. Default Configuration Resource Change a configuration parameter in the default configuration resource file, application.yaml . There are no environment variable or system property overrides defined. <markup lang=\"bash\" title=\"Change app.greeting in resources/application.yaml as follows:\" >app: greeting: HelloFrom-application.yaml <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-se.jar <markup lang=\"bash\" title=\"Run the curl command in a new terminal window and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFrom-application.yaml World!\" } The new app.greeting value in application.yaml is used. System Property Override A system property has a higher precedence than application.yaml . <markup lang=\"bash\" title=\"Restart the application with a system property. The app.greeting environment variable is still set:\" >java -Dapp.greeting=\"HelloFromSystemProperty\" -jar target/helidon-quickstart-se.jar <markup lang=\"bash\" title=\"Invoke the endpoint below and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFromSystemProperty World!\" } The system property took precedence over application.yaml . Environment Variable Override An environment variable has a higher precedence than the system property. <markup lang=\"bash\" title=\"Set the environment variable and restart the application:\" >export APP_GREETING=HelloFromEnvironment java -Dapp.greeting=\"HelloFromSystemProperty\" -jar target/helidon-quickstart-se.jar <markup lang=\"bash\" title=\"Invoke the endpoint below and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFromEnvironment World!\" } The environment variable APP_GREETING took precedence over the system property and the value in application.yaml . ",
            "title": "Source Precedence for Default Configuration"
        },
        {
            "location": "/se/guides/03_config",
            "text": " Helidon provides a very flexible and comprehensive configuration system, offering you many application configuration choices. You can include configuration data from a variety of sources using different formats, like JSON and YAML. Furthermore, you can customize the precedence of sources and make them optional or mandatory. This guide introduces Helidon SE configuration and demonstrates the fundamental concepts using several examples. Refer to Helidon Config for the full configuration concepts documentation. Create a Sample Helidon SE Project Use the Helidon SE Maven archetype to create a simple project that can be used for the examples in this guide. <markup lang=\"bash\" title=\"Run the Maven archetype:\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-se \\ -DarchetypeVersion=2.5.4 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-se \\ -Dpackage=io.helidon.examples.quickstart.se <markup lang=\"bash\" title=\"The project will be built and run from the helidon-quickstart-se directory:\" >cd helidon-quickstart-se Configuration Formats Helidon configuration sources can use different formats for the configuration data. You can specify the format on a per-source bases, mixing and matching formats as required. Here are the supported formats, each with the extension name you should use. By default, Helidon will determine the media type based on the extension name. Java Property (.properties) JSON (.json) YAML (.yaml) HOCON (.conf) The remainder of this document will use these formats in examples and show you how to configure Helidon to parse them. Default Configuration Helidon has an internal configuration, so you are not required to provide any configuration data for your application, though in practice you most likely would. By default, that configuration can be overridden from three sources: system properties, environment variables, and the contents of application.yaml in the classpath. For example, if you specify a custom server port in application.yaml then your server will listen on that port. In your application code, Helidon uses the default configuration when you create a default Config object. See the following code from the project you created. <markup lang=\"Java\" title=\"View Main.startServer :\" > static WebServer startServer() throws IOException { ... Config config = Config.create(); The Config object is created with default settings. Source Precedence for Default Configuration In order to properly configure your application using configuration sources, you need to understand the precedence rules that Helidon uses to merge your configuration data. By default, Helidon will use the following sources in precedence order: Environment variables Java system properties Configuration specified in application.yaml If any of the Helidon required properties are not specified in one of these source, like server.port , then Helidon will use a default value. Because environment variable names are restricted to alphanumeric characters and underscore, Helidon adds aliases to the environment configuration source, allowing entries with dotted and/or hyphenated keys to be overriden. For example, this mapping allows an environment variable named \"APP_GREETING\" to override an entry key named \"app.greeting\". In the same way, an environment variable named \"APP_dash_GREETING\" will map to \"app-greeting\". See Advanced Config for more information. The following examples will demonstrate the default precedence order. Default Configuration Resource Change a configuration parameter in the default configuration resource file, application.yaml . There are no environment variable or system property overrides defined. <markup lang=\"bash\" title=\"Change app.greeting in resources/application.yaml as follows:\" >app: greeting: HelloFrom-application.yaml <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-se.jar <markup lang=\"bash\" title=\"Run the curl command in a new terminal window and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFrom-application.yaml World!\" } The new app.greeting value in application.yaml is used. System Property Override A system property has a higher precedence than application.yaml . <markup lang=\"bash\" title=\"Restart the application with a system property. The app.greeting environment variable is still set:\" >java -Dapp.greeting=\"HelloFromSystemProperty\" -jar target/helidon-quickstart-se.jar <markup lang=\"bash\" title=\"Invoke the endpoint below and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFromSystemProperty World!\" } The system property took precedence over application.yaml . Environment Variable Override An environment variable has a higher precedence than the system property. <markup lang=\"bash\" title=\"Set the environment variable and restart the application:\" >export APP_GREETING=HelloFromEnvironment java -Dapp.greeting=\"HelloFromSystemProperty\" -jar target/helidon-quickstart-se.jar <markup lang=\"bash\" title=\"Invoke the endpoint below and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFromEnvironment World!\" } The environment variable APP_GREETING took precedence over the system property and the value in application.yaml . ",
            "title": "Getting Started with Configuration"
        },
        {
            "location": "/se/guides/03_config",
            "text": " Here is the full list of external config sources that you can use programmatically. Environment variables - the property is a name/value pair. Java system properties - the property is a name/value pair. Resources in the classpath - the contents of the resource is parsed according to its inferred format. File - the contents of the file is parsed according to its inferred format. Directory - each non-directory file in the directory becomes a config entry: the file name is the key. and the contents of that file are used as the corresponding config String value. A URL resource - contents is parsed according to its inferred format. You can also define custom sources, such as Git, and use them in your Helidon application. See Advanced Config for more information. ",
            "title": "Full List of Configuration Sources"
        },
        {
            "location": "/se/guides/03_config",
            "text": " The first custom resource example demonstrates how to add a second internal configuration resource that is discovered in the classpath . The code needs to build a Config object, which in turn is used to build the Server object. The Config object can be built using a Config.Builder , which lets you inject any number of sources into the builder. Furthermore, you can set precedence for the sources. The first source has highest precedence, then the next has second highest, and so forth. <markup lang=\"text\" title=\"Add a resource file, named config.properties to the resources directory with the following contents:\" >app.greeting=HelloFrom-config.properties <markup lang=\"java\" title=\"Update the Main class; 1) Add new imports, 2) Replace the Config.create() call with buildConfig() , and 3) Add buildConfig method:\" >import static io.helidon.config.ConfigSources.classpath; ... static WebServer startServer() throws IOException { ... Config config = buildConfig(); private static Config buildConfig() { return Config.builder() .disableEnvironmentVariablesSource() .sources( classpath(\"config.properties\"), classpath(\"application.yaml\")) .build(); } Add new import statement. Call the new buildConfig method to build a Config object. Disable the environment variables as a source. Specify the new config.properties resource that is in the classpath . You must specify the existing application.yaml or Helidon will not use it as a configuration source even though it is considered a default source. <markup lang=\"bash\" title=\"Build and run the application (without the system property). Invoke the endpoint and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFrom-config.properties World!\" } The greeting was picked up from config.properties , overriding the value in application.yaml . It is important to remember that configuration from all sources is merged internally. If you have the same configuration property in multiple sources, then only the one with highest precedence will be used at runtime. This is true even the same property comes from sources with different formats. Swap the source order and run the test again. <markup lang=\"java\" title=\"Update the Main class and replace the buildConfig method:\" > private static Config buildConfig() { return Config.builder() .disableEnvironmentVariablesSource() .sources( classpath(\"application.yaml\"), classpath(\"config.properties\")) .build(); } Swap the source order, putting application.yaml first. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFrom-application.yaml World!\" } The file application.yaml was used to get the greeting since it now has precedence over config.properties . ",
            "title": "Classpath Sources"
        },
        {
            "location": "/se/guides/03_config",
            "text": " You can move all or part of your configuration to external files, making them optional or mandatory. The obvious advantage to this approach is that you do not need to rebuild your application to change configuration. In the following example, the app.greeting configuration property will be added to config-file.properties . <markup lang=\"bash\" title=\"Unset the environment variable so that disableEnvironmentVariablesSource doesn&#8217;t need to be called:\" >unset APP_GREETING <markup lang=\"bash\" title=\"Create a file named config-file.properties in the helidon-quickstart-se directory with the following contents:\" >app.greeting=HelloFrom-config-file.properties <markup lang=\"java\" title=\"Update the Main class; 1) Add new import and 2) Replace the buildConfig method:\" >import static io.helidon.config.ConfigSources.file; ... private static Config buildConfig() { return Config.builder() .sources( file(\"config-file.properties\"), classpath(\"application.yaml\")) .build(); } Add a mandatory configuration file. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFrom-config-file.properties World!\" } The configuration property from the file config-file.properties takes precedence. If you want the configuration file to be optional, you must use the optional method with sources , otherwise Helidon will generate an error during startup as shown below. This is true for both file and classpath sources. By default, these sources are mandatory. <markup lang=\"java\" title=\"Update the Main class and replace the buildConfig method:\" > private static Config buildConfig() { return Config.builder() .sources( file(\"missing-file\"), classpath(\"application.yaml\")) .build(); } Specify a file that doesn&#8217;t exist. <markup lang=\"bash\" title=\"Build then start the application and you will see the following output:\" >Exception in thread \"main\" io.helidon.config.ConfigException: Cannot load data from mandatory source FileConfig[missing-file]. File `missing-file` not found. To fix this, use the optional method as shown below, then rerun the test. ... file(\"missing-file\").optional(), The missing-file configuration file is now optional. ",
            "title": "External File Sources"
        },
        {
            "location": "/se/guides/03_config",
            "text": " If you have more than three sources, you can use the addSource method as shown below. <markup lang=\"java\" title=\"Update the Main class and replace the buildConfig method:\" > private static Config buildConfig() { return Config.builder() .addSource(directory(\"conf\")) .addSource(file(\"config-file.properties\")) .addSource(classpath(\"config.properties\").optional()) .addSource(classpath(\"application.yaml\")) .build(); } Add each config source using the addSource method. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFromFileInDirectoryConf World!\" } ",
            "title": "Exceeding Three Sources"
        },
        {
            "location": "/se/guides/03_config",
            "text": " A directory source treats every file in the directory as a key, and the file contents as the value. The following example includes a directory source as highest precedence. <markup lang=\"bash\" title=\"Create a new directory helidon-quickstart-se/conf then create a file named app.greeting in that directory with the following contents:\" >HelloFromFileInDirectoryConf <markup lang=\"java\" title=\"Update the Main class; 1) Add new import and 2) Replace the buildConfig method:\" >import static io.helidon.config.ConfigSources.directory; ... private static Config buildConfig() { return Config.builder() .sources( directory(\"conf\"), classpath(\"config.properties\").optional(), classpath(\"application.yaml\")) .build(); } Add a mandatory configuration directory. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFromFileInDirectoryConf World!\" } The greeting was fetched from the file named app.greeting . Exceeding Three Sources If you have more than three sources, you can use the addSource method as shown below. <markup lang=\"java\" title=\"Update the Main class and replace the buildConfig method:\" > private static Config buildConfig() { return Config.builder() .addSource(directory(\"conf\")) .addSource(file(\"config-file.properties\")) .addSource(classpath(\"config.properties\").optional()) .addSource(classpath(\"application.yaml\")) .build(); } Add each config source using the addSource method. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFromFileInDirectoryConf World!\" } ",
            "title": "Directory Source"
        },
        {
            "location": "/se/guides/03_config",
            "text": " Instead of directly specifying the configuration sources in your code, you can use a profile file that declares the configuration sources and their attributes. Simplest way to use a profile is to define a config-profile.yaml (and possible other files, such as config-profile-dev.yaml for dev profile) on classpath or on file system, and create config using Config.create() . The profile can be changed by a system property config.profile , or using an environment variable HELIDON_CONFIG_PROFILE . Profile file can use any supported format, following example is using YAML . <markup lang=\"yaml\" title=\"Create a file named cofnig-profile.yaml in the helidon-quickstart-se directory with the following contents:\" >sources: - type: \"classpath\" properties: resource: \"application.yaml\" The source type. The name of the mandatory configuration resource. <markup lang=\"java\" title=\"Update the Main class and replace the buildConfig method:\" > private static Config buildConfig() { return Config.create(); } Will use config-profile.yaml by default <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFrom-application.yaml World!\" } The application.yaml resource file was used to get the greeting. The source precedence order in a profile file is the order of appearance in the file. This is demonstrated below where the config-file.properties has highest precedence. <markup lang=\"yaml\" title=\"Replace the contents of the config-profile.yaml file:\" >sources: - type: \"file\" properties: path: \"./config-file.properties\" - type: \"classpath\" properties: resource: \"application.yaml\" - type: \"file\" properties: path: \"optional-config-file\" optional: true The source type specifies a file. The name of the mandatory configuration file. Specify that the optional-config-file file is optional. <markup lang=\"bash\" title=\"Restart the application, then invoke the endpoint below and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFrom-config-file.properties World!\" } The config-file.properties source now takes precedence. When using a profile file, you need to explicitly include both environment variables and system properties as a source if you want to use them. <markup lang=\"bash\" title=\"Replace the contents of the config-profile.yaml file:\" >sources: - type: \"environment-variables\" - type: \"system-properties\" - type: \"classpath\" properties: resource: \"application.yaml\" - type: \"file\" properties: path: \"./config-file.properties\" Environment variables are now used as a source. System properties are now used as a source. You can re-run the previous tests that exercised environment variables and system properties. Swap the two types to see the precedence change. Be sure to unset APP_GREETING after you finish testing. ",
            "title": "Configuration Profiles"
        },
        {
            "location": "/se/guides/03_config",
            "text": " To use custom configuration sources, your application needs to specify the sources when it creates Config object. By doing this, you are in full control of all configuration sources and precedence. By default, the environment variable and system property sources are enabled, but you can disable them using the disableEnvironmentVariablesSource and disableSystemPropertiesSource methods. This section will show you how to use a custom configuration with various sources, formats, and precedence rules. Full List of Configuration Sources Here is the full list of external config sources that you can use programmatically. Environment variables - the property is a name/value pair. Java system properties - the property is a name/value pair. Resources in the classpath - the contents of the resource is parsed according to its inferred format. File - the contents of the file is parsed according to its inferred format. Directory - each non-directory file in the directory becomes a config entry: the file name is the key. and the contents of that file are used as the corresponding config String value. A URL resource - contents is parsed according to its inferred format. You can also define custom sources, such as Git, and use them in your Helidon application. See Advanced Config for more information. Classpath Sources The first custom resource example demonstrates how to add a second internal configuration resource that is discovered in the classpath . The code needs to build a Config object, which in turn is used to build the Server object. The Config object can be built using a Config.Builder , which lets you inject any number of sources into the builder. Furthermore, you can set precedence for the sources. The first source has highest precedence, then the next has second highest, and so forth. <markup lang=\"text\" title=\"Add a resource file, named config.properties to the resources directory with the following contents:\" >app.greeting=HelloFrom-config.properties <markup lang=\"java\" title=\"Update the Main class; 1) Add new imports, 2) Replace the Config.create() call with buildConfig() , and 3) Add buildConfig method:\" >import static io.helidon.config.ConfigSources.classpath; ... static WebServer startServer() throws IOException { ... Config config = buildConfig(); private static Config buildConfig() { return Config.builder() .disableEnvironmentVariablesSource() .sources( classpath(\"config.properties\"), classpath(\"application.yaml\")) .build(); } Add new import statement. Call the new buildConfig method to build a Config object. Disable the environment variables as a source. Specify the new config.properties resource that is in the classpath . You must specify the existing application.yaml or Helidon will not use it as a configuration source even though it is considered a default source. <markup lang=\"bash\" title=\"Build and run the application (without the system property). Invoke the endpoint and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFrom-config.properties World!\" } The greeting was picked up from config.properties , overriding the value in application.yaml . It is important to remember that configuration from all sources is merged internally. If you have the same configuration property in multiple sources, then only the one with highest precedence will be used at runtime. This is true even the same property comes from sources with different formats. Swap the source order and run the test again. <markup lang=\"java\" title=\"Update the Main class and replace the buildConfig method:\" > private static Config buildConfig() { return Config.builder() .disableEnvironmentVariablesSource() .sources( classpath(\"application.yaml\"), classpath(\"config.properties\")) .build(); } Swap the source order, putting application.yaml first. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFrom-application.yaml World!\" } The file application.yaml was used to get the greeting since it now has precedence over config.properties . External File Sources You can move all or part of your configuration to external files, making them optional or mandatory. The obvious advantage to this approach is that you do not need to rebuild your application to change configuration. In the following example, the app.greeting configuration property will be added to config-file.properties . <markup lang=\"bash\" title=\"Unset the environment variable so that disableEnvironmentVariablesSource doesn&#8217;t need to be called:\" >unset APP_GREETING <markup lang=\"bash\" title=\"Create a file named config-file.properties in the helidon-quickstart-se directory with the following contents:\" >app.greeting=HelloFrom-config-file.properties <markup lang=\"java\" title=\"Update the Main class; 1) Add new import and 2) Replace the buildConfig method:\" >import static io.helidon.config.ConfigSources.file; ... private static Config buildConfig() { return Config.builder() .sources( file(\"config-file.properties\"), classpath(\"application.yaml\")) .build(); } Add a mandatory configuration file. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFrom-config-file.properties World!\" } The configuration property from the file config-file.properties takes precedence. If you want the configuration file to be optional, you must use the optional method with sources , otherwise Helidon will generate an error during startup as shown below. This is true for both file and classpath sources. By default, these sources are mandatory. <markup lang=\"java\" title=\"Update the Main class and replace the buildConfig method:\" > private static Config buildConfig() { return Config.builder() .sources( file(\"missing-file\"), classpath(\"application.yaml\")) .build(); } Specify a file that doesn&#8217;t exist. <markup lang=\"bash\" title=\"Build then start the application and you will see the following output:\" >Exception in thread \"main\" io.helidon.config.ConfigException: Cannot load data from mandatory source FileConfig[missing-file]. File `missing-file` not found. To fix this, use the optional method as shown below, then rerun the test. ... file(\"missing-file\").optional(), The missing-file configuration file is now optional. Directory Source A directory source treats every file in the directory as a key, and the file contents as the value. The following example includes a directory source as highest precedence. <markup lang=\"bash\" title=\"Create a new directory helidon-quickstart-se/conf then create a file named app.greeting in that directory with the following contents:\" >HelloFromFileInDirectoryConf <markup lang=\"java\" title=\"Update the Main class; 1) Add new import and 2) Replace the buildConfig method:\" >import static io.helidon.config.ConfigSources.directory; ... private static Config buildConfig() { return Config.builder() .sources( directory(\"conf\"), classpath(\"config.properties\").optional(), classpath(\"application.yaml\")) .build(); } Add a mandatory configuration directory. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFromFileInDirectoryConf World!\" } The greeting was fetched from the file named app.greeting . Exceeding Three Sources If you have more than three sources, you can use the addSource method as shown below. <markup lang=\"java\" title=\"Update the Main class and replace the buildConfig method:\" > private static Config buildConfig() { return Config.builder() .addSource(directory(\"conf\")) .addSource(file(\"config-file.properties\")) .addSource(classpath(\"config.properties\").optional()) .addSource(classpath(\"application.yaml\")) .build(); } Add each config source using the addSource method. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFromFileInDirectoryConf World!\" } Configuration Profiles Instead of directly specifying the configuration sources in your code, you can use a profile file that declares the configuration sources and their attributes. Simplest way to use a profile is to define a config-profile.yaml (and possible other files, such as config-profile-dev.yaml for dev profile) on classpath or on file system, and create config using Config.create() . The profile can be changed by a system property config.profile , or using an environment variable HELIDON_CONFIG_PROFILE . Profile file can use any supported format, following example is using YAML . <markup lang=\"yaml\" title=\"Create a file named cofnig-profile.yaml in the helidon-quickstart-se directory with the following contents:\" >sources: - type: \"classpath\" properties: resource: \"application.yaml\" The source type. The name of the mandatory configuration resource. <markup lang=\"java\" title=\"Update the Main class and replace the buildConfig method:\" > private static Config buildConfig() { return Config.create(); } Will use config-profile.yaml by default <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFrom-application.yaml World!\" } The application.yaml resource file was used to get the greeting. The source precedence order in a profile file is the order of appearance in the file. This is demonstrated below where the config-file.properties has highest precedence. <markup lang=\"yaml\" title=\"Replace the contents of the config-profile.yaml file:\" >sources: - type: \"file\" properties: path: \"./config-file.properties\" - type: \"classpath\" properties: resource: \"application.yaml\" - type: \"file\" properties: path: \"optional-config-file\" optional: true The source type specifies a file. The name of the mandatory configuration file. Specify that the optional-config-file file is optional. <markup lang=\"bash\" title=\"Restart the application, then invoke the endpoint below and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFrom-config-file.properties World!\" } The config-file.properties source now takes precedence. When using a profile file, you need to explicitly include both environment variables and system properties as a source if you want to use them. <markup lang=\"bash\" title=\"Replace the contents of the config-profile.yaml file:\" >sources: - type: \"environment-variables\" - type: \"system-properties\" - type: \"classpath\" properties: resource: \"application.yaml\" - type: \"file\" properties: path: \"./config-file.properties\" Environment variables are now used as a source. System properties are now used as a source. You can re-run the previous tests that exercised environment variables and system properties. Swap the two types to see the precedence change. Be sure to unset APP_GREETING after you finish testing. ",
            "title": "Custom Configuration Sources"
        },
        {
            "location": "/se/guides/03_config",
            "text": " The simplest way to access configuration data is using a key, as shown below in the GreetService class. The key can be composite as shown below: <markup lang=\"java\" title=\"View the GreetService constructor:\" > GreetService(Config config) { greeting.set(config.get(\"app.greeting\").asString().orElse(\"Ciao\")); } Get the app.greeting node using a composite key. You can also access the same greeting by navigating the nodes. <markup lang=\"java\" title=\"Replace the GreetService constructor with the following code:\" > GreetService(Config config) { greeting.set(config.get(\"app\").get(\"greeting\").asString().orElse(\"Ciao\")); } Get the app node, then get the child node, greeting . <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFrom-application.yaml World!\" } ",
            "title": "Accessing Config Using Keys or Navigation"
        },
        {
            "location": "/se/guides/03_config",
            "text": " The Helidon Config class provides several methods that allow you to filter and customize the traversal of the configuration tree. The example below shows how to get the greeting node when you only know it is somewhere in the app subtree. <markup lang=\"bash\" title=\"Replace the contents of the config-profile.yaml file:\" >sources: - type: \"classpath\" properties: resource: \"application.yaml\" <markup lang=\"bash\" title=\"Replace the app section of the application.yaml resource file:\" >app: child1: child1-node child2: child2a: greeting: HelloFrom-application.yaml under child2a child3: child3-node <markup lang=\"java\" title=\"Update the GreetService.java file; 1) Add new imports and 2) Replace the GreetService constructor with the following:\" > import java.util.List; import java.util.stream.Collectors; GreetService(Config config) { List&lt;Config&gt; appGreetings = config.get(\"app\") .traverse() .filter(node -&gt; node.name().equals(\"greeting\")) .collect(Collectors.toList()); greeting.set(appGreetings.get(0).asString().get()); } Add new imports. Traverse the entire subtree of the app node. Include only nodes that have the name greeting . Add the greeting node to the collection. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFrom-application.yaml under child2a World!\" } ",
            "title": "Using Filters and Collections"
        },
        {
            "location": "/se/guides/03_config",
            "text": " Even though in-memory config trees are immutable, the config system internally records configuration source metadata that allows it to watch sources for changes. Your application listens for updates to the underlying config sources and reacts to the changes. See Config Mutability Support for a full discussion on this topic. The following example demonstrates how to listen and react to configuration changes. <markup lang=\"yaml\" title=\"Replace the contents of the config-profile.yaml file:\" >sources: - type: \"file\" properties: path: \"./config-file.properties\" change-watcher: type: \"file\" - type: \"classpath\" properties: resource: \"application.yaml\" <markup lang=\"java\" title=\"Update the GreetService class; 1) Add new import and 2) Replace the GreetService constructor:\" >import java.util.function.Consumer; ... GreetService(Config config) { Config greetingConfig = config.get(\"app.greeting\"); greeting.set(greetingConfig.asString().orElse(\"Ciao\")); greetingConfig.onChange((Consumer&lt;Config&gt;) cfg -&gt; greeting.set(cfg.asString().orElse(\"Ciao\"))); } Get the greeting Config node. Register a listener that will get called by Helidon when the configuration changes. The listener will update the greeting with the new value. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFrom-config-file.properties World!\" } <markup lang=\"bash\" title=\"Update config-file.properties with the following contents:\" >app.greeting=Updated HelloFrom-config-file.properties <markup lang=\"bash\" title=\"After a few seconds, check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"Updated HelloFrom-config-file.properties World!\" } The application reacted to the change and updated the greeting. ",
            "title": "Reacting to Configuration Updates"
        },
        {
            "location": "/se/guides/03_config",
            "text": " You have used Helidon to customize configuration behavior from your code using the Config and Config.Builder classes. As discussed previously, Helidon reads configuration from a config source, which uses a config parser to translate the source into an in-memory tree which represents the configuration’s structure and values. Helidon offers a variety of methods to access in-memory configuration. These can be categorized as key access or tree navigation . You have been using key access for all of the examples to this point. For example app.greeting is accessing the greeting child node of the app parent node. There are many options for access this data using navigation methods as described in Hierarchical Config and Advanced Config . Accessing Config Using Keys or Navigation The simplest way to access configuration data is using a key, as shown below in the GreetService class. The key can be composite as shown below: <markup lang=\"java\" title=\"View the GreetService constructor:\" > GreetService(Config config) { greeting.set(config.get(\"app.greeting\").asString().orElse(\"Ciao\")); } Get the app.greeting node using a composite key. You can also access the same greeting by navigating the nodes. <markup lang=\"java\" title=\"Replace the GreetService constructor with the following code:\" > GreetService(Config config) { greeting.set(config.get(\"app\").get(\"greeting\").asString().orElse(\"Ciao\")); } Get the app node, then get the child node, greeting . <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFrom-application.yaml World!\" } Using Filters and Collections The Helidon Config class provides several methods that allow you to filter and customize the traversal of the configuration tree. The example below shows how to get the greeting node when you only know it is somewhere in the app subtree. <markup lang=\"bash\" title=\"Replace the contents of the config-profile.yaml file:\" >sources: - type: \"classpath\" properties: resource: \"application.yaml\" <markup lang=\"bash\" title=\"Replace the app section of the application.yaml resource file:\" >app: child1: child1-node child2: child2a: greeting: HelloFrom-application.yaml under child2a child3: child3-node <markup lang=\"java\" title=\"Update the GreetService.java file; 1) Add new imports and 2) Replace the GreetService constructor with the following:\" > import java.util.List; import java.util.stream.Collectors; GreetService(Config config) { List&lt;Config&gt; appGreetings = config.get(\"app\") .traverse() .filter(node -&gt; node.name().equals(\"greeting\")) .collect(Collectors.toList()); greeting.set(appGreetings.get(0).asString().get()); } Add new imports. Traverse the entire subtree of the app node. Include only nodes that have the name greeting . Add the greeting node to the collection. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFrom-application.yaml under child2a World!\" } Reacting to Configuration Updates Even though in-memory config trees are immutable, the config system internally records configuration source metadata that allows it to watch sources for changes. Your application listens for updates to the underlying config sources and reacts to the changes. See Config Mutability Support for a full discussion on this topic. The following example demonstrates how to listen and react to configuration changes. <markup lang=\"yaml\" title=\"Replace the contents of the config-profile.yaml file:\" >sources: - type: \"file\" properties: path: \"./config-file.properties\" change-watcher: type: \"file\" - type: \"classpath\" properties: resource: \"application.yaml\" <markup lang=\"java\" title=\"Update the GreetService class; 1) Add new import and 2) Replace the GreetService constructor:\" >import java.util.function.Consumer; ... GreetService(Config config) { Config greetingConfig = config.get(\"app.greeting\"); greeting.set(greetingConfig.asString().orElse(\"Ciao\")); greetingConfig.onChange((Consumer&lt;Config&gt;) cfg -&gt; greeting.set(cfg.asString().orElse(\"Ciao\"))); } Get the greeting Config node. Register a listener that will get called by Helidon when the configuration changes. The listener will update the greeting with the new value. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFrom-config-file.properties World!\" } <markup lang=\"bash\" title=\"Update config-file.properties with the following contents:\" >app.greeting=Updated HelloFrom-config-file.properties <markup lang=\"bash\" title=\"After a few seconds, check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"Updated HelloFrom-config-file.properties World!\" } The application reacted to the change and updated the greeting. ",
            "title": "Accessing Config within an Application"
        },
        {
            "location": "/se/guides/03_config",
            "text": " The following example uses a Kubernetes ConfigMap to pass the configuration data to your Helidon application deployed to Kubernetes. When the pod is created, Kubernetes will automatically create a local file within the container that has the contents of the configuration file used for the ConfigMap. This example will create the file at /etc/config/config-file.properties . <markup lang=\"bash\" title=\"Replace the app section of the application.yaml resource file:\" >app: greeting: \"Hello\" <markup lang=\"java\" title=\"Update the Main class and replace the buildConfig method:\" > private static Config buildConfig() { return Config.builder() .sources( file(\"/etc/config/config-file.properties\").optional(), classpath(\"application.yaml\")) .build(); } The app.greeting value will be fetched from /etc/config/config-file.properties within the container. The server port is specified in application.yaml within the helidon-quickstart-se.jar . <markup lang=\"java\" title=\"Replace the GreetService constructor with the following code:\" > GreetService(Config config) { greeting.set(config.get(\"app.greeting\").asString().orElse(\"Ciao\")); } <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"Hello World!\" } The greeting came from application.yaml since /etc/config/config-file.properties doesn&#8217;t exist. <markup lang=\"bash\" title=\"Stop the application and build the docker image:\" >docker build -t helidon-config-se . <markup lang=\"bash\" title=\"Generate a ConfigMap from config-file.properties :\" >kubectl create configmap helidon-configmap --from-file config-file.properties <markup lang=\"bash\" title=\"View the contents of the ConfigMap:\" >kubectl get configmap helidon-configmap -o yaml ... apiVersion: v1 data: config-file.properties: | app.greeting=Updated HelloFrom-config-file.properties kind: ConfigMap ... The file config-file.properties will be created within the Kubernetes container. The config-file.properties file will have this single property defined. <markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named k8s-config.yaml , with the following contents:\" >kind: Service apiVersion: v1 metadata: name: helidon-config labels: app: helidon-config spec: type: NodePort selector: app: helidon-config ports: - port: 8080 targetPort: 8080 name: http --- kind: Deployment apiVersion: apps/v1 metadata: name: helidon-config spec: replicas: 1 selector: matchLabels: app: helidon-config template: metadata: labels: app: helidon-config version: v1 spec: containers: - name: helidon-config image: helidon-config-se imagePullPolicy: IfNotPresent ports: - containerPort: 8080 volumeMounts: - name: config-volume mountPath: /etc/config volumes: - name: config-volume configMap: # Provide the name of the ConfigMap containing the files you want # to add to the container name: helidon-configmap A service of type NodePort that serves the default routes on port 8080 . A deployment with one replica of a pod. Mount the ConfigMap as a volume at /etc/config . This is where Kubernetes will create config-file.properties . Specify the ConfigMap which contains the configuration data. <markup lang=\"bash\" title=\"Create and deploy the application into Kubernetes:\" >kubectl apply -f ./k8s-config.yaml <markup lang=\"bash\" title=\"Get the service information:\" >kubectl get service/helidon-config <markup lang=\"bash\" >NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE helidon-config NodePort 10.99.159.2 &lt;none&gt; 8080:31143/TCP 8s A service of type NodePort that serves the default routes on port 31143 . <markup lang=\"bash\" title=\"Verify the configuration endpoint using port 31143 , your port will likely be different:\" >curl http://localhost:31143/greet ... { \"message\": \"Updated HelloFrom-config-file.properties World!\" } The greeting value from /etc/config/config-file.properties within the container was used. You can now delete the Kubernetes resources that were just created during this example. <markup lang=\"bash\" title=\"Delete the Kubernetes resources:\" >kubectl delete -f ./k8s-config.yaml kubectl delete configmap helidon-configmap ",
            "title": "Integration with Kubernetes"
        },
        {
            "location": "/se/guides/03_config",
            "text": " This guide has demonstrated how to use basic Helidon configuration features. The full configuration documentation, starting with the introduction section at Helidon Config has much more information including the following: Architecture Parsers Extensions Filters Hierarchical Access Property Mapping Mutability Support and more&#8230;&#8203; Refer to the following references for additional information: Helidon Javadoc at https://helidon.io/docs/latest/apidocs/index.html?overview-summary.html ",
            "title": "Summary"
        },
        {
            "location": "/se/health/01_health",
            "text": " This document describes the health check API available with Helidon SE. ",
            "title": "preambule"
        },
        {
            "location": "/se/health/01_health",
            "text": " To enable Health Checks add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.health&lt;/groupId&gt; &lt;artifactId&gt;helidon-health&lt;/artifactId&gt; &lt;/dependency&gt; Optional dependency to use built-in health checks: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.health&lt;/groupId&gt; &lt;artifactId&gt;helidon-health-checks&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/health/01_health",
            "text": " It’s a good practice to monitor your microservice’s health, to ensure that it is available and performs correctly. Applications implement health checks to expose health status that is collected at regular intervals by external tooling, such as orchestrators like Kubernetes. The orchestrator may then take action, such as restarting your application if the health check fails. A typical health check combines the statuses of all the dependencies that affect availability and the ability to perform correctly: network latency storage database other services used by your application ",
            "title": "About health checks"
        },
        {
            "location": "/se/health/01_health",
            "text": " You can use Helidon-provided health checks to report various common health check statuses: Built-in health check Health check name JavaDoc Config properties Default config value deadlock detection deadlock DeadlockHealthCheck n/a n/a available disk space diskSpace DiskSpaceHealthCheck helidon.healthCheck.diskSpace.thresholdPercent helidon.healthCheck.diskSpace.path 99.999 / available heap memory heapMemory HeapMemoryHealthCheck helidon.healthCheck.heapMemory.thresholdPercent 98 The following code adds the default built-in health checks to your application: <markup lang=\"java\" >HealthSupport health = HealthSupport.builder() .addLiveness(HealthChecks.healthChecks()) .build(); Routing.builder() .register(health) .build(); Add built-in health checks using defaults (requires the helidon-health-checks dependency). Register the created health support with web server routing (adds the /health endpoint). You can control the thresholds for built-in health checks in either of two ways: Create the health checks individually using their builders instead of using the HealthChecks convenience class. Follow the JavaDoc links in the table above. Configure the behavior of the built-in health checks using the config property keys in the table . Further, you can suppress one or more of the built-in health checks by setting the configuration item helidon.health.exclude to a comma-separated list of the health check names (from the table ) you want to exclude. ",
            "title": "Built-in health-checks"
        },
        {
            "location": "/se/health/01_health",
            "text": " Health check API classes org.eclipse.microprofile.health.HealthCheck Java functional interface representing the logic of a single health check org.eclipse.microprofile.health.HealthCheckResponse Result of a health check invocation that contains a state and a description. org.eclipse.microprofile.health.HealthCheckResponseBuilder Builder class to create HealthCheckResponse instances io.helidon.health.HealthSupport WebServer service that exposes /health and invokes the registered health checks io.helidon.health.HealthSupport.Builder Builder class to create HealthSupport instances A health check is a Java functional interface that returns a HealthCheckResponse object. You can choose to implement a health check inline with a lambda expression or you can reference a method with the double colon operator :: . <markup lang=\"java\" title=\"Health check with a lambda expression:\" >HealthCheck hc = () -&gt; HealthCheckResponse .named(\"exampleHealthCheck\") .up() .build(); <markup lang=\"java\" title=\"Health check with method reference:\" >HealthCheckResponse exampleHealthCheck(){ return HealthCheckResponse .named(\"exampleHealthCheck\") .up() .build(); } HealthCheck hc = this::exampleHealthCheck; HealthSupport is a WebServer service that contains a collection of registered HealthCheck instances. When queried, it invokes the registered health check and returns a response with a status code representing the overall state of the application. Health status codes <div class=\"table__overflow elevation-1 flex sm7 \"> 200 The application is healthy (with health check details in the response). 204 The application is healthy (with no health check details in the response). 503 The application is not healthy. 500 An error occurred while reporting the health. HTTP GET responses include JSON content showing the detailed results of all the health checks which the server executed after receiving the request. HTTP HEAD requests return only the status with no payload. <markup lang=\"java\" title=\"Create the health support service:\" >HealthSupport health = HealthSupport.builder() .addLiveness(hc) .build(); <markup lang=\"java\" title=\"Register a custom health check:\" >HealthSupport health = HealthSupport.builder() .addLiveness(() -&gt; HealthCheckResponse.named(\"exampleHealthCheck\") .up() .withData(\"time\", System.currentTimeMillis()) .build()) .build(); Routing.builder() .register(health) .build(); Add a custom health check. This example returns UP and current time. Register health support with web server routing (adds the /health endpoint). Balance collecting a lot of information with the need to avoid overloading the application and overwhelming users. <markup lang=\"json\" title=\"JSON response:\" >{ \"outcome\": \"UP\", \"status\": \"UP\", \"checks\": [ { \"name\": \"exampleHealthCheck\", \"state\": \"UP\", \"data\": { \"time\": 1546958376613 } } ] } Built-in health-checks You can use Helidon-provided health checks to report various common health check statuses: Built-in health check Health check name JavaDoc Config properties Default config value deadlock detection deadlock DeadlockHealthCheck n/a n/a available disk space diskSpace DiskSpaceHealthCheck helidon.healthCheck.diskSpace.thresholdPercent helidon.healthCheck.diskSpace.path 99.999 / available heap memory heapMemory HeapMemoryHealthCheck helidon.healthCheck.heapMemory.thresholdPercent 98 The following code adds the default built-in health checks to your application: <markup lang=\"java\" >HealthSupport health = HealthSupport.builder() .addLiveness(HealthChecks.healthChecks()) .build(); Routing.builder() .register(health) .build(); Add built-in health checks using defaults (requires the helidon-health-checks dependency). Register the created health support with web server routing (adds the /health endpoint). You can control the thresholds for built-in health checks in either of two ways: Create the health checks individually using their builders instead of using the HealthChecks convenience class. Follow the JavaDoc links in the table above. Configure the behavior of the built-in health checks using the config property keys in the table . Further, you can suppress one or more of the built-in health checks by setting the configuration item helidon.health.exclude to a comma-separated list of the health check names (from the table ) you want to exclude. ",
            "title": "API overview"
        },
        {
            "location": "/se/health/01_health",
            "text": " The JSON responses shown above contain properties \"status\" and \"outcome\" with the same values. Helidon reports both of these to maintain backward compatibility with older versions of MicroProfile Health. This behavior can be disabled by setting the property health.backward-compatible to false , in which case only \"status\" is reported. Future versions of Helidon will drop support for older versions of Health, so it is recommended to rely on \"status\" instead of \"outcome\" in your applications. ",
            "title": "Strict JSON Output"
        },
        {
            "location": "/se/health/01_health",
            "text": " Accessing the Helidon-provided /health endpoint reports the health of your application: <markup lang=\"json\" title=\"JSON response.\" >{ \"outcome\": \"UP\", \"status\": \"UP\", \"checks\": [ { \"name\": \"deadlock\", \"state\": \"UP\" }, { \"name\": \"diskSpace\", \"state\": \"UP\", \"data\": { \"free\": \"211.00 GB\", \"freeBytes\": 226563444736, \"percentFree\": \"45.31%\", \"total\": \"465.72 GB\", \"totalBytes\": 500068036608 } }, { \"name\": \"heapMemory\", \"state\": \"UP\", \"data\": { \"free\": \"215.15 MB\", \"freeBytes\": 225600496, \"max\": \"3.56 GB\", \"maxBytes\": 3817865216, \"percentFree\": \"99.17%\", \"total\": \"245.50 MB\", \"totalBytes\": 257425408 } } ] } Strict JSON Output The JSON responses shown above contain properties \"status\" and \"outcome\" with the same values. Helidon reports both of these to maintain backward compatibility with older versions of MicroProfile Health. This behavior can be disabled by setting the property health.backward-compatible to false , in which case only \"status\" is reported. Future versions of Helidon will drop support for older versions of Health, so it is recommended to rely on \"status\" instead of \"outcome\" in your applications. ",
            "title": "Health report"
        },
        {
            "location": "/mp/cors/03_configuration-with-cors-mp",
            "text": " Your application code establishes the CORS behavior of your endpoints using the @CrossOrigin annotation. You and your users can override that behavior, as well as the CORS behavior of the built-in services, using MicroProfile configuration. ",
            "title": "preambule"
        },
        {
            "location": "/mp/cors/03_configuration-with-cors-mp",
            "text": " In configuration, Helidon represents basic CORS information as a section that contains one or more key/value pairs. Each key-value pair assigns one characteristic of CORS behavior. The table below lists the parameters for the @CrossOriginConfig annotation and the configuration keys that identify the CORS characteristics. Annotation Parameter Configuration Key Default CORS Header Name allowCredentials allow-credentials false Access-Control-Allow-Credentials allowHeaders allow-headers [\"*\"] Access-Control-Allow-Headers allowMethods allow-methods [\"*\"] Access-Control-Allow-Methods allowOrigins allow-origins [\"*\"] Access-Control-Allow-Origins exposeHeaders expose-headers none Access-Control-Expose-Headers maxAgeSeconds max-age 3600 Access-Control-Max-Age enabled enabled true n/a If the cross-origin configuration is disabled ( enabled = false), then the Helidon CORS implementation ignores the cross-origin configuration entry. The following example of basic cross-origin configuration limits cross-origin resource sharing for PUT and DELETE operations to only foo.com and there.com : <markup lang=\"hocon\" >... allow-origins: [\"http://foo.com\", \"http://there.com\"] allow-methods: [\"PUT\", \"DELETE\"] ... ",
            "title": "Basic Cross-Origin Configuration"
        },
        {
            "location": "/mp/cors/03_configuration-with-cors-mp",
            "text": " In Helidon MP, you use the mapped cross-origin configuration format. Helidon represents mapped CORS information as a section, identified by a configuration key of your choosing, that contains: An optional enabled setting which defaults to true and applies to the whole mapped CORS config section, and An optional paths subsection containing zero or more entries, each of which contains: a basic CORS config section, and a path-pattern path pattern that maps that basic CORS config section to the resource(s) it affects. You can use mapped configuration to your advantage if you want to allow your users to override the CORS behavior set up in the application code. The following example illustrates the mapped cross-origin configuration format. <markup lang=\"hocon\" >... cors: paths: - path-pattern: /greeting allow-origins: [\"http://foo.com\", \"http://there.com\", \"http://other.com\"] allow-methods: [\"PUT\", \"DELETE\"] - path-pattern: / allow-methods: [\"GET\", \"HEAD\", \"OPTIONS\", \"POST\"] ... The unique identifier for this mapped CORS config section must be cors . Collects the sequence of entries, each of which maps a basic CORS config to a path pattern. Marks the beginning of an entry (the - character) and maps the associated basic CORS config to the /greeting subresource (the path-pattern key and value). Begins the basic CORS config section for /greeting ; it restricts sharing via PUT and DELETE to the listed origins. Marks the beginning of the next entry (the - character) and maps the associated basic CORS config to the top-level resource in the app (the path-pattern key and value). Begins the basic CORS config section for / ; it permits sharing of resources at the top-level path with all origins for the indicated HTTP methods. Path patterns can be any expression accepted by the PathMatcher class. Be sure to arrange the entries in the order that you want Helidon to check them. Helidon CORS support searches the cross-origin entries in the order you define them until it finds an entry that matches an incoming request&#8217;s path pattern and HTTP method. ",
            "title": "Understanding the Mapped Cross-Origin Configuration Format"
        },
        {
            "location": "/mp/cors/03_configuration-with-cors-mp",
            "text": " Support in Helidon for CORS configuration uses two closely-related cross-origin configuration formats: basic and mapped. Each format corresponds to a class in the Helidon CORS library. The basic format corresponds to the CrossOriginConfig class, and the mapped format corresponds to the MappedCrossOriginConfig class. Basic Cross-Origin Configuration In configuration, Helidon represents basic CORS information as a section that contains one or more key/value pairs. Each key-value pair assigns one characteristic of CORS behavior. The table below lists the parameters for the @CrossOriginConfig annotation and the configuration keys that identify the CORS characteristics. Annotation Parameter Configuration Key Default CORS Header Name allowCredentials allow-credentials false Access-Control-Allow-Credentials allowHeaders allow-headers [\"*\"] Access-Control-Allow-Headers allowMethods allow-methods [\"*\"] Access-Control-Allow-Methods allowOrigins allow-origins [\"*\"] Access-Control-Allow-Origins exposeHeaders expose-headers none Access-Control-Expose-Headers maxAgeSeconds max-age 3600 Access-Control-Max-Age enabled enabled true n/a If the cross-origin configuration is disabled ( enabled = false), then the Helidon CORS implementation ignores the cross-origin configuration entry. The following example of basic cross-origin configuration limits cross-origin resource sharing for PUT and DELETE operations to only foo.com and there.com : <markup lang=\"hocon\" >... allow-origins: [\"http://foo.com\", \"http://there.com\"] allow-methods: [\"PUT\", \"DELETE\"] ... Understanding the Mapped Cross-Origin Configuration Format In Helidon MP, you use the mapped cross-origin configuration format. Helidon represents mapped CORS information as a section, identified by a configuration key of your choosing, that contains: An optional enabled setting which defaults to true and applies to the whole mapped CORS config section, and An optional paths subsection containing zero or more entries, each of which contains: a basic CORS config section, and a path-pattern path pattern that maps that basic CORS config section to the resource(s) it affects. You can use mapped configuration to your advantage if you want to allow your users to override the CORS behavior set up in the application code. The following example illustrates the mapped cross-origin configuration format. <markup lang=\"hocon\" >... cors: paths: - path-pattern: /greeting allow-origins: [\"http://foo.com\", \"http://there.com\", \"http://other.com\"] allow-methods: [\"PUT\", \"DELETE\"] - path-pattern: / allow-methods: [\"GET\", \"HEAD\", \"OPTIONS\", \"POST\"] ... The unique identifier for this mapped CORS config section must be cors . Collects the sequence of entries, each of which maps a basic CORS config to a path pattern. Marks the beginning of an entry (the - character) and maps the associated basic CORS config to the /greeting subresource (the path-pattern key and value). Begins the basic CORS config section for /greeting ; it restricts sharing via PUT and DELETE to the listed origins. Marks the beginning of the next entry (the - character) and maps the associated basic CORS config to the top-level resource in the app (the path-pattern key and value). Begins the basic CORS config section for / ; it permits sharing of resources at the top-level path with all origins for the indicated HTTP methods. Path patterns can be any expression accepted by the PathMatcher class. Be sure to arrange the entries in the order that you want Helidon to check them. Helidon CORS support searches the cross-origin entries in the order you define them until it finds an entry that matches an incoming request&#8217;s path pattern and HTTP method. ",
            "title": "Understanding the CORS Configuration Formats"
        },
        {
            "location": "/mp/cors/03_configuration-with-cors-mp",
            "text": " In configuration, you can specify the same CORS-related attributes that you specify using the @CrossOrigin annotation. The following example shows how you can express configuration similar to that shown previously using the mapped cross-origin configuration format. Here, the example uses properties-file syntax in your applications&#8217;s META-INF/microprofile-config.properties file. Note that the top-level config key must be cors . <markup lang=\"properties\" >cors.paths.0.path-pattern = /greeting cors.paths.0.allow-origins = http://foo.com, http://there.com, http://other.com cors.paths.0.allow-methods = PUT, DELETE cors.paths.1.path-pattern = / cors.paths.1.allow-methods = GET, HEAD, OPTIONS, POST Remember that if you set configuration in a file that you include as part of your application JAR file, then you need to rebuild and restart your application for any changes to take effect. ",
            "title": "Specifying Override Values in Configuration"
        },
        {
            "location": "/mp/cors/03_configuration-with-cors-mp",
            "text": " Use these same configuration techniques to control the behavior of the CORS-enabled built-in services. Learn more. See the Helidon CORS support in action by building and running the CORS example . ",
            "title": "Next Steps"
        },
        {
            "location": "/se/webserver/04_request-handling",
            "text": " Each Handler has two parameters. ServerRequest and ServerResponse . Request provides access to the request method, URI, path, query parameters, headers and entity. Response provides an ability to set response code, headers, and entity. ",
            "title": "Process Request and Produce Response"
        },
        {
            "location": "/se/webserver/04_request-handling",
            "text": " The handler forwards the request to the downstream handlers by nexting . There are two options: call req.next() <markup lang=\"java\" >.any(\"/hello\", (req, res) -&gt; { // filtering logic req.next(); }) handler for any HTTP method using the /hello path business logic implementation forward the current request to the downstream handler call req.next(throwable) to forward the handling to the error handlers <markup lang=\"java\" >.any(\"/hello\", (req, res) -&gt; { // filtering logic (e.g., validating parameters) if (userParametersOk()) { req.next(); } else { req.next(new IllegalArgumentException(\"Invalid parameters.\"); } }) handler for any HTTP method using the /hello path custom logic forward the current request to the downstream handler forward the request to the error handler The handling logic can explicitly forward the execution to a different thread. This is the reason why returning from the handler can&#8217;t automatically trigger calling the next handler. ",
            "title": "Handler as a Filter"
        },
        {
            "location": "/se/webserver/04_request-handling",
            "text": " To complete the request handling, you must send a response by calling the res.send() method. <markup lang=\"java\" >.get(\"/hello\", (req, res) -&gt; { // terminating logic res.status(Http.Status.ACCEPTED_201); res.send(\"Saved!\"); }) handler that terminates the request handling for any HTTP method using the /hello path send the response ",
            "title": "Sending a response"
        },
        {
            "location": "/se/webserver/04_request-handling",
            "text": " Implement the logic to handle requests to WebServer in a Handler , which is a FunctionalInterface . Handlers: Process the request and send a response. Act as a filter and forward requests to downstream handlers using the request.next() method. Throw an exception or call request.next(exception) to begin error handling . Process Request and Produce Response Each Handler has two parameters. ServerRequest and ServerResponse . Request provides access to the request method, URI, path, query parameters, headers and entity. Response provides an ability to set response code, headers, and entity. Handler as a Filter The handler forwards the request to the downstream handlers by nexting . There are two options: call req.next() <markup lang=\"java\" >.any(\"/hello\", (req, res) -&gt; { // filtering logic req.next(); }) handler for any HTTP method using the /hello path business logic implementation forward the current request to the downstream handler call req.next(throwable) to forward the handling to the error handlers <markup lang=\"java\" >.any(\"/hello\", (req, res) -&gt; { // filtering logic (e.g., validating parameters) if (userParametersOk()) { req.next(); } else { req.next(new IllegalArgumentException(\"Invalid parameters.\"); } }) handler for any HTTP method using the /hello path custom logic forward the current request to the downstream handler forward the request to the error handler The handling logic can explicitly forward the execution to a different thread. This is the reason why returning from the handler can&#8217;t automatically trigger calling the next handler. Sending a response To complete the request handling, you must send a response by calling the res.send() method. <markup lang=\"java\" >.get(\"/hello\", (req, res) -&gt; { // terminating logic res.status(Http.Status.ACCEPTED_201); res.send(\"Saved!\"); }) handler that terminates the request handling for any HTTP method using the /hello path send the response ",
            "title": "Request Handling"
        },
        {
            "location": "/mp/tracing/01_tracing",
            "text": " To enable MicroProfile Tracing either add a dependency on the helidon-microprofile bundle or add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-tracing&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/tracing/01_tracing",
            "text": " There is a set of common configuration options that this section describes. In addition each tracer implementation may have additional configuration options - please see the documentation of each of them. Each implementation may provide defaults for these options. All common configuration options: key description service Name of the service sending the tracing information. This is usually visible in the trace data to distinguish actors in a conversation (e.g. when multiple microservices are connected together) protocol Protocol of the tracing collector (e.g. http , https ) host Host of the tracing collector (e.g. localhost ) port Port of the tracing collector (e.g. 9411 ) path Path of the tracing collector service that is used to send spans to enabled If set to false, tracing would be disabled tags String tags that are to be added to each span reported (object node of string-string pairs) boolean-tags Boolean tags that are to be added to each span reported (object node of string-boolean pairs) int-tags Int tags that are to be added to each span reported (object node of string-int pairs) To disable Helidon tracing for web server and security: <markup lang=\"properties\" >tracing.components.web-server.enabled=false tracing.components.security.enabled=false To disables MP Tracing as by specification: <markup lang=\"properties\" >mp.opentracing.server.skip-pattern=.* ",
            "title": "Configuration using Helidon Config"
        },
        {
            "location": "/mp/tracing/01_tracing",
            "text": " Tracing support is implemented for both for Helidon MP Server and for Jersey client. In addition, you need to add one of the tracer implementations: Zipkin Jaeger You can configure a custom service name using the tracing.service configuration property. If this property is undefined, name is created from JAX-RS Application name, or Helidon MP is used if no application is defined. All tracer specific configuration is expected in configuration under key tracing . <markup lang=\"properties\" title=\"Example microprofile-config.properties with customized service name.\" >tracing.service=event-service Configuration using Helidon Config There is a set of common configuration options that this section describes. In addition each tracer implementation may have additional configuration options - please see the documentation of each of them. Each implementation may provide defaults for these options. All common configuration options: key description service Name of the service sending the tracing information. This is usually visible in the trace data to distinguish actors in a conversation (e.g. when multiple microservices are connected together) protocol Protocol of the tracing collector (e.g. http , https ) host Host of the tracing collector (e.g. localhost ) port Port of the tracing collector (e.g. 9411 ) path Path of the tracing collector service that is used to send spans to enabled If set to false, tracing would be disabled tags String tags that are to be added to each span reported (object node of string-string pairs) boolean-tags Boolean tags that are to be added to each span reported (object node of string-boolean pairs) int-tags Int tags that are to be added to each span reported (object node of string-int pairs) To disable Helidon tracing for web server and security: <markup lang=\"properties\" >tracing.components.web-server.enabled=false tracing.components.security.enabled=false To disables MP Tracing as by specification: <markup lang=\"properties\" >mp.opentracing.server.skip-pattern=.* ",
            "title": "Configuring Tracing with Helidon MP"
        },
        {
            "location": "/mp/tracing/01_tracing",
            "text": " Helidon MP fully supports MicroProfile OpenTracing. You can add custom spans using @Traced annotation on methods of CDI beans. Note for invoking methods on same class: If you invoke a method on the same class, @Traced annotation would be ignored, as it is not invoked through a CDI proxy and as such cannot be intercepted. To make sure @Traced is honored, use it on JAX-RS resource methods and on CDI bean methods used from other beans. ",
            "title": "Creating custom spans"
        },
        {
            "location": "/mp/tracing/01_tracing",
            "text": " There is an option to provide SpanContext programmatically (such as when writing a command line application that starts the span manually). You can either configure the span context as the active span, or explicitly define it as client property. <markup lang=\"java\" title=\"Tracing propagation with Jersey client\" >import static io.helidon.tracing.jersey.client.ClientTracingFilter.CURRENT_SPAN_CONTEXT_PROPERTY_NAME; import static io.helidon.tracing.jersey.client.ClientTracingFilter.TRACER_PROPERTY_NAME; // ... Response response = client.target(serviceEndpoint) .request() // tracer should be provided unless available as GlobalTracer .property(TRACER_PROPERTY_NAME, tracer) .property(CURRENT_SPAN_CONTEXT_PROPERTY_NAME, spanContext) .get(); ",
            "title": "Manual handling of traces in Jersey Client"
        },
        {
            "location": "/mp/tracing/01_tracing",
            "text": " Automated trace propagation is supported currently only with Jersey client. Tracing propagation works automatically as long as you run within the scope of Helidon MP and use Helidon components to invoke external services. Manual handling of traces in Jersey Client There is an option to provide SpanContext programmatically (such as when writing a command line application that starts the span manually). You can either configure the span context as the active span, or explicitly define it as client property. <markup lang=\"java\" title=\"Tracing propagation with Jersey client\" >import static io.helidon.tracing.jersey.client.ClientTracingFilter.CURRENT_SPAN_CONTEXT_PROPERTY_NAME; import static io.helidon.tracing.jersey.client.ClientTracingFilter.TRACER_PROPERTY_NAME; // ... Response response = client.target(serviceEndpoint) .request() // tracer should be provided unless available as GlobalTracer .property(TRACER_PROPERTY_NAME, tracer) .property(CURRENT_SPAN_CONTEXT_PROPERTY_NAME, spanContext) .get(); ",
            "title": "Trace propagation across services"
        },
        {
            "location": "/mp/tracing/01_tracing",
            "text": " Tracing configuration can be defined in microprofile-config.properties file. <markup lang=\"properties\" title=\"Tracing configuration\" >tracing.components.web-server.spans.0.name=\"HTTP Request\" tracing.components.web-server.spans.0.logs.0.name=\"content-write\" tracing.components.web-server.spans.0.logs.0.enabled=false ",
            "title": "Configuration using MP Config"
        },
        {
            "location": "/mp/tracing/01_tracing",
            "text": " For Web Server we have a path based support for configuring tracing, in addition to the configuration described above. Configuration of path can use any path string supported by the Web Server. The configuration itself has the same possibilities as traced configuration described above. The path specific configuration will be merged with global configuration (path is the \"newer\" configuration, global is the \"older\") <markup lang=\"properties\" title=\"Configuration properties\" >tracing.paths.0.path=\"/favicon.ico\" tracing.paths.0.enabled=false tracing.paths.1.path=\"/metrics\" tracing.paths.1.enabled=false tracing.paths.2.path=\"/health\" tracing.paths.2.enabled=false ",
            "title": "Path based configuration in Helidon Web Server"
        },
        {
            "location": "/mp/tracing/01_tracing",
            "text": " To have a nicer overview in search pane of a tracer, you can customize the top-level span name using configuration. Example: <markup lang=\"properties\" title=\"Configuration properties\" >tracing.components.web-server.spans.0.name=\"HTTP Request\" tracing.components.web-server.spans.0.new-name: \"HTTP %1$s %2$s\" This is supported ONLY for the span named \"HTTP Request\" on component \"web-server\". Parameters provided: Method - HTTP method Path - path of the request (such as '/greet') Query - query of the request (may be null) ",
            "title": "Renaming top level span using request properties"
        },
        {
            "location": "/mp/tracing/01_tracing",
            "text": " The following table lists all spans traced by Helidon components: component span name description web-server HTTP Request The overall span of the Web Server from request intitiation until response Note that in Zipkin the name is replaced with jax-rs span name if jax-rs tracing is used. web-server content-read Span for reading the request entity web-server content-write Span for writing the response entity security security Processing of request security security security:atn Span for request authentication security security:atz Span for request authorization security security:response Processing of response security security security:outbound Processing of outbound security jax-rs A generated name Span for the resource method invocation, name is generated from class and method name jax-rs jersey-client-call Span for outbound client call Some of these spans log to the span. These log events can be (in most cases) configured: span name log name configurable enabled by default description HTTP Request handler.class YES YES Each handler has its class and event logged security status YES YES Logs either \"status: PROCEED\" or \"status: DENY\" security:atn security.user YES NO The username of the user if logged in security:atn security.service YES NO The name of the service if logged in security:atn status YES YES Logs the status of security response (such as SUCCESS ) security:atz status YES YES Logs the status of security response (such as SUCCESS ) security:outbound status YES YES Logs the status of security response (such as SUCCESS ) There are also tags that are set by Helidon components. These are not configurable. span name tag name description HTTP Request component name of the component - helidon-webserver , or jaxrs when using MP HTTP Request http.method HTTP method of the request, such as GET , POST HTTP Request http.status_code HTTP status code of the response HTTP Request http.url The path of the request (for SE without protocol, host and port) HTTP Request error If the request ends in error, this tag is set to true , usually accompanied by logs with details content-read requested.type Type (class) of the requested entity (if entity is read) content-write response.type Type (class) of the entity being sent (if enitty is sent) security security.id ID of the security context created for this request (if security is used) jersey-client-call http.method HTTP method of the client request jersey-client-call http.status_code HTTP status code of client response jersey-client-call http.url Full URL of the request (such as http://localhost:8080/greet ) Configuration using MP Config Tracing configuration can be defined in microprofile-config.properties file. <markup lang=\"properties\" title=\"Tracing configuration\" >tracing.components.web-server.spans.0.name=\"HTTP Request\" tracing.components.web-server.spans.0.logs.0.name=\"content-write\" tracing.components.web-server.spans.0.logs.0.enabled=false Path based configuration in Helidon Web Server For Web Server we have a path based support for configuring tracing, in addition to the configuration described above. Configuration of path can use any path string supported by the Web Server. The configuration itself has the same possibilities as traced configuration described above. The path specific configuration will be merged with global configuration (path is the \"newer\" configuration, global is the \"older\") <markup lang=\"properties\" title=\"Configuration properties\" >tracing.paths.0.path=\"/favicon.ico\" tracing.paths.0.enabled=false tracing.paths.1.path=\"/metrics\" tracing.paths.1.enabled=false tracing.paths.2.path=\"/health\" tracing.paths.2.enabled=false Renaming top level span using request properties To have a nicer overview in search pane of a tracer, you can customize the top-level span name using configuration. Example: <markup lang=\"properties\" title=\"Configuration properties\" >tracing.components.web-server.spans.0.name=\"HTTP Request\" tracing.components.web-server.spans.0.new-name: \"HTTP %1$s %2$s\" This is supported ONLY for the span named \"HTTP Request\" on component \"web-server\". Parameters provided: Method - HTTP method Path - path of the request (such as '/greet') Query - query of the request (may be null) ",
            "title": "Traced spans"
        },
        {
            "location": "/mp/guides/38_se_services",
            "text": " This guide shows how reuse Helidon SE Service in your Helidon MP application. ",
            "title": "preambule"
        },
        {
            "location": "/mp/guides/38_se_services",
            "text": " For this 10 minute tutorial, you will need the following: <div class=\"table__overflow elevation-1 flex sm7 \"> A Helidon {upper-case-flavor} Application You can use your own application or use the Helidon {upper-case-flavor} Quickstart to create a sample application. Java&#160;SE&#160;11 ( Open&#160;JDK&#160;11 ) Helidon requires Java 11+. Maven 3.6.1+ Helidon requires Maven 3.6.1+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop ). <markup lang=\"bash\" title=\"Verify Prerequisites\" >java -version mvn --version docker --version kubectl version --short <markup lang=\"bash\" title=\"Setting JAVA_HOME\" ># On Mac export JAVA_HOME=`/usr/libexec/java_home -v 11` # On Linux # Use the appropriate path to your JDK export JAVA_HOME=/usr/lib/jvm/jdk-11 Helidon MP supports Reactive routing which brings possibility for reusing io.helidon.webserver.Service implementations in Helidon MP. Such feature can be quite useful for common solutions for filtering, auditing, logging or augmenting REST endpoints in hybrid Helidon SE/MP environment. Let&#8217;s define simple Helidon SE Service for adding special header to every REST response: <markup lang=\"java\" >public class CoolingService implements Service, Handler { public static final String COOL_HEADER_NAME = \"Cool-Header\"; public static final String COOLING_VALUE = \"This is way cooler response than \"; @Override public void update(Routing.Rules rules) { rules.any(this); } @Override public void accept(ServerRequest req, ServerResponse res) { res.headers().add(COOL_HEADER_NAME, COOLING_VALUE); req.next(); } } Its easy to use it with Helidon SE: <markup lang=\"java\" >WebServer.builder(Routing.builder() // register service with routing path .register(\"/cool\", new CoolingService()) .build()) .config(config) .addMediaSupport(JsonpSupport.create()) .build() .start(); And not much harder to use it with Helidon MP: <markup lang=\"java\" >@ApplicationScoped public class MyBean { @Produces @ApplicationScoped @RoutingPath(\"/cool\") public Service coolService() { return new CoolingService(); } } You can leverage annotations: @RoutingPath - path of the WebServer service @RoutingName - select routing when serving requests on multiple ports ",
            "title": "What You Need"
        },
        {
            "location": "/se/reactivemessaging/01_introduction",
            "text": " To enable Reactive Messaging add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.messaging&lt;/groupId&gt; &lt;artifactId&gt;helidon-messaging&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/reactivemessaging/01_introduction",
            "text": " Channel is a named pair of Publisher and Subscriber . Channels can be connected together by processors . Registering of Publisher or Subscriber for a channel can be done by Messaging API, or configured implicitly for using registered connector for generating such Publisher or Subscriber . <markup lang=\"java\" title=\"Example of simple channel:\" >Channel&lt;String&gt; channel1 = Channel.create(\"channel1\"); Messaging.builder() .publisher(channel1, Multi.just(\"message 1\", \"message 2\") .map(Message::of)) .listener(channel1, s -&gt; System.out.println(\"Intecepted message \" + s)) .build() .start(); ",
            "title": "Channel"
        },
        {
            "location": "/se/reactivemessaging/01_introduction",
            "text": " Processor is a typical reactive processor acting as a Subscriber to upstream and as a Publisher to downstream. In terms of reactive messaging it is able to connect two channels to one reactive stream. <markup lang=\"java\" title=\"Example of processor usage:\" >Channel&lt;String&gt; firstChannel = Channel.create(\"first-channel\"); Channel&lt;String&gt; secondChannel = Channel.create(\"second-channel\"); Messaging.builder() .publisher(secondChannel, ReactiveStreams.of(\"test1\", \"test2\", \"test3\") .map(Message::of)) .processor(secondChannel, firstChannel, ReactiveStreams.&lt;Message&lt;String&gt;&gt;builder() .map(Message::getPayload) .map(String::toUpperCase) .map(Message::of) ) .subscriber(firstChannel, ReactiveStreams.&lt;Message&lt;String&gt;&gt;builder() .peek(Message::ack) .map(Message::getPayload) .forEach(s -&gt; System.out.println(\"Consuming message \" + s))) .build() .start(); &gt;Consuming message TEST1 &gt;Consuming message TEST2 &gt;Consuming message TEST3 ",
            "title": "Processor"
        },
        {
            "location": "/se/reactivemessaging/01_introduction",
            "text": " Reactive Messaging in Helidon SE uses the same concept of message wrapping as MicroProfile messaging. The only notable difference is that SE Messaging does almost no implicit or automatic acknowledgement due to no magic philosophy of Helidon SE. Only exception to this are variants of methods Messaging.Builder#listener and Messaging.Builder#processor with consumer or function params, conveniently unwrapping payload for you. After such implicit unwrapping is not possible to do a manual acknowledgement, therefore implicit ack before callback is executed is necessary. ",
            "title": "Message"
        },
        {
            "location": "/se/reactivemessaging/01_introduction",
            "text": " Connector concept is a way for connecting channels to external sources. To make creation and usage of connectors as easy and versatile as possible, Helidon SE Messaging uses same API for connectors like MicroProfile Reactive Messaging does. This allows connectors to be usable in both flavors of Helidon with one limitation which is that connector has to be able to work without CDI. Example of such a versatile connectors in Helidon: Kafka connector JMS connector ",
            "title": "Connector"
        },
        {
            "location": "/se/reactivemessaging/01_introduction",
            "text": " Asynchronous messaging is a commonly used form of communication in the world of microservices. While its possible to start building your reactive streams directly by combining operators and connecting them to reactive APIs, with Helidon SE Reactive Messaging, you can now use prepared tools for repetitive use case scenarios . For example connecting your streams to external services usually requires a lot of boiler-plate code for configuration handling, backpressure propagation, acknowledgement and more. For such tasks there is a system of connectors, emitters and means to orchestrate them in Helidon, called Reactive Messaging . It&#8217;s basically an API for connecting and configuring Connectors and Emitters with your reactive streams thru so called Channels . You may wonder how Reactive Messaging relates to MicroProfile Reactive Messaging . As the making of connectors or even configuring them can be repetitive task leading to the same results, Helidon SE Reactive Messaging supports very same configuration format for connectors as its MicroProfile counterpart does. Also, MP Connectors are reusable in Helidon SE Messaging with some limitation(there is no CDI in Helidon SE). All Messaging connectors in Helidon are made to be universally usable by Helidon MP and SE. Channel Channel is a named pair of Publisher and Subscriber . Channels can be connected together by processors . Registering of Publisher or Subscriber for a channel can be done by Messaging API, or configured implicitly for using registered connector for generating such Publisher or Subscriber . <markup lang=\"java\" title=\"Example of simple channel:\" >Channel&lt;String&gt; channel1 = Channel.create(\"channel1\"); Messaging.builder() .publisher(channel1, Multi.just(\"message 1\", \"message 2\") .map(Message::of)) .listener(channel1, s -&gt; System.out.println(\"Intecepted message \" + s)) .build() .start(); Processor Processor is a typical reactive processor acting as a Subscriber to upstream and as a Publisher to downstream. In terms of reactive messaging it is able to connect two channels to one reactive stream. <markup lang=\"java\" title=\"Example of processor usage:\" >Channel&lt;String&gt; firstChannel = Channel.create(\"first-channel\"); Channel&lt;String&gt; secondChannel = Channel.create(\"second-channel\"); Messaging.builder() .publisher(secondChannel, ReactiveStreams.of(\"test1\", \"test2\", \"test3\") .map(Message::of)) .processor(secondChannel, firstChannel, ReactiveStreams.&lt;Message&lt;String&gt;&gt;builder() .map(Message::getPayload) .map(String::toUpperCase) .map(Message::of) ) .subscriber(firstChannel, ReactiveStreams.&lt;Message&lt;String&gt;&gt;builder() .peek(Message::ack) .map(Message::getPayload) .forEach(s -&gt; System.out.println(\"Consuming message \" + s))) .build() .start(); &gt;Consuming message TEST1 &gt;Consuming message TEST2 &gt;Consuming message TEST3 Message Reactive Messaging in Helidon SE uses the same concept of message wrapping as MicroProfile messaging. The only notable difference is that SE Messaging does almost no implicit or automatic acknowledgement due to no magic philosophy of Helidon SE. Only exception to this are variants of methods Messaging.Builder#listener and Messaging.Builder#processor with consumer or function params, conveniently unwrapping payload for you. After such implicit unwrapping is not possible to do a manual acknowledgement, therefore implicit ack before callback is executed is necessary. Connector Connector concept is a way for connecting channels to external sources. To make creation and usage of connectors as easy and versatile as possible, Helidon SE Messaging uses same API for connectors like MicroProfile Reactive Messaging does. This allows connectors to be usable in both flavors of Helidon with one limitation which is that connector has to be able to work without CDI. Example of such a versatile connectors in Helidon: Kafka connector JMS connector ",
            "title": "Reactive Messaging"
        },
        {
            "location": "/mp/lra/01_introduction",
            "text": " To enable Long Running Actions add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.lra&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-lra&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Support for Narayana coordinator --&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.lra&lt;/groupId&gt; &lt;artifactId&gt;helidon-lra-coordinator-narayana-client&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/lra/01_introduction",
            "text": " The following example shows how a simple LRA participant starts and joins a transaction after calling the '/start-example' resource. When startExample method finishes successfully, close is reported to coordinator and /complete-example endpoint is called by coordinator to confirm successful closure of the LRA. If an exception occurs during startExample method execution, coordinator receives cancel call and /compensate-example is called by coordinator to compensate for cancelled LRA transaction. <markup lang=\"java\" title=\"Example of simple LRA participant\" >@PUT @LRA(LRA.Type.REQUIRES_NEW) @Path(\"start-example\") public Response startExample(@HeaderParam(LRA_HTTP_CONTEXT_HEADER) URI lraId, String data) { if (data.contains(\"BOOM\")) { throw new RuntimeException(\"BOOM 💥\"); } LOGGER.info(\"Data \" + data + \" processed 🏭\"); return Response.ok().build(); } @PUT @Complete @Path(\"complete-example\") public Response completeExample(@HeaderParam(LRA_HTTP_CONTEXT_HEADER) URI lraId) { LOGGER.log(Level.INFO, \"LRA id: {0} completed 🎉\", lraId); return LRAResponse.completed(); } @PUT @Compensate @Path(\"compensate-example\") public Response compensateExample(@HeaderParam(LRA_HTTP_CONTEXT_HEADER) URI lraId) { LOGGER.log(Level.SEVERE, \"LRA id: {0} compensated 🦺\", lraId); return LRAResponse.compensated(); } This JAX-RS PUT method will start new LRA transactions and join it before method body gets executed LRA id assigned by coordinator to this LRA transaction When method execution finishes exceptionally, cancel signal for this particular LRA is sent to coordinator When method execution finishes successfully, complete signal for this particular LRA is sent to coordinator Method which will be called by coordinator when LRA is completed Method which will be called by coordinator when LRA is canceled ",
            "title": "Example"
        },
        {
            "location": "/mp/lra/01_introduction",
            "text": "<markup lang=\"yaml\" title=\"Example of lra configuration\" >mp.lra: coordinator.url: http://localhost:8070/lra-coordinator propagation.active: true participant.url: http://coordinator.visibe.host:80/awsomeapp Url of coordinator Propagate LRA headers LRA_HTTP_CONTEXT_HEADER and LRA_HTTP_PARENT_CONTEXT_HEADER through non-LRA endpoints Url of the LRA enabled service overrides standard base uri, so coordinator can call load-balancer instead of the service For more information continue to Micro Profile Long Running Actions specification . ",
            "title": "Configuration"
        },
        {
            "location": "/mp/lra/01_introduction",
            "text": " Distributed transactions for microservices are known as SAGA design patterns and are defined by the Micro Profile Long Running Actions specification . Unlike well known XA protocol, LRA is asynchronous and therefore much more scalable. Every LRA JAX-RS resource ( participant ) defines endpoints to be invoked when transaction needs to be completed or compensated . LRA transactions need to be coordinated over REST API by the LRA coordinator. Coordinator keeps track of all transactions and calls the @Compensate or @Complete endpoints for all participants involved in the particular transaction. LRA transaction is first started, then joined by participant . Participant reports the successful finish of transaction by calling complete. Coordinator then calls the JAX-RS complete endpoint that was registered during the join of each participant . As the completed or compensated participants don&#8217;t have to be on same instance, the whole architecture is highly scalable. In case of error during the LRA transaction, participant reports cancel of LRA to coordinator. Coordinator calls compensate on all the joined participants. When participant joins the LRA with timeout defined @LRA(value = LRA.Type.REQUIRES_NEW, timeLimit = 5, timeUnit = ChronoUnit.MINUTES) , coordinator compensate if timeout occurs before close is reported by participants. Example The following example shows how a simple LRA participant starts and joins a transaction after calling the '/start-example' resource. When startExample method finishes successfully, close is reported to coordinator and /complete-example endpoint is called by coordinator to confirm successful closure of the LRA. If an exception occurs during startExample method execution, coordinator receives cancel call and /compensate-example is called by coordinator to compensate for cancelled LRA transaction. <markup lang=\"java\" title=\"Example of simple LRA participant\" >@PUT @LRA(LRA.Type.REQUIRES_NEW) @Path(\"start-example\") public Response startExample(@HeaderParam(LRA_HTTP_CONTEXT_HEADER) URI lraId, String data) { if (data.contains(\"BOOM\")) { throw new RuntimeException(\"BOOM 💥\"); } LOGGER.info(\"Data \" + data + \" processed 🏭\"); return Response.ok().build(); } @PUT @Complete @Path(\"complete-example\") public Response completeExample(@HeaderParam(LRA_HTTP_CONTEXT_HEADER) URI lraId) { LOGGER.log(Level.INFO, \"LRA id: {0} completed 🎉\", lraId); return LRAResponse.completed(); } @PUT @Compensate @Path(\"compensate-example\") public Response compensateExample(@HeaderParam(LRA_HTTP_CONTEXT_HEADER) URI lraId) { LOGGER.log(Level.SEVERE, \"LRA id: {0} compensated 🦺\", lraId); return LRAResponse.compensated(); } This JAX-RS PUT method will start new LRA transactions and join it before method body gets executed LRA id assigned by coordinator to this LRA transaction When method execution finishes exceptionally, cancel signal for this particular LRA is sent to coordinator When method execution finishes successfully, complete signal for this particular LRA is sent to coordinator Method which will be called by coordinator when LRA is completed Method which will be called by coordinator when LRA is canceled Configuration <markup lang=\"yaml\" title=\"Example of lra configuration\" >mp.lra: coordinator.url: http://localhost:8070/lra-coordinator propagation.active: true participant.url: http://coordinator.visibe.host:80/awsomeapp Url of coordinator Propagate LRA headers LRA_HTTP_CONTEXT_HEADER and LRA_HTTP_PARENT_CONTEXT_HEADER through non-LRA endpoints Url of the LRA enabled service overrides standard base uri, so coordinator can call load-balancer instead of the service For more information continue to Micro Profile Long Running Actions specification . ",
            "title": "Long Running Actions (LRA)"
        },
        {
            "location": "/mp/introduction/01_introduction",
            "text": " Helidon MP is an Eclipse MicroProfile runtime that allows the Jakarta EE community to run microservices in a portable way. ",
            "title": "preambule"
        },
        {
            "location": "/mp/introduction/01_introduction",
            "text": " Helidon MP 2.5.4 is an implementation of the MicroProfile specification and supports MicroProfile 3.3. Since MicroProfile has its roots in Java EE, the MicroProfile APIs follow a familiar, declarative approach with heavy use of annotations. This makes it a good choice for Java EE developers. Helidon has added additional APIs to the core set of Microprofile APIs giving you all the capabilities you need for writing modern cloud native applications. ",
            "title": "About Helidon MP Components"
        },
        {
            "location": "/mp/introduction/01_introduction",
            "text": " save Ahead-of-Time Compilation (AOT) Use GraalVM native image to compile Helidon applications into a native executable. settings Config A flexible configuration framework with support for multiple sources and formats. extension CDI Extensions In addition to MicroProfile support, Helidon MP provides additional CDI extensions to address areas not covered by MicroProfile. share CORS Add support for CORS to your application using a Helidon module. warning Fault Tolerance Defines annotations that improve applications by providing support to handle error conditions (faults). graphic_eq GraphQL Expose GraphQL API using Microprofile GraphQL. swap_horiz gRPC Build gRPC servers and clients. favorite_outline Health Checks Expose health statuses of your applications. settings_ethernet JAX-RS/Jersey Helidon MP supports building RESTful services using JAX-RS/Jersey. dns JPA Work with JPA in Helidon MP in all the ways that you’re familiar with. verified_user JWT Authentication Defines a compact and self-contained way for securely transmitting information between parties as a JSON object. pending_actions Long Running Actions Distributed transactions for microservices following SAGA pattern. av_timer Metrics Instrumentation to expose metrics of your applications. donut_large OpenAPI Support OpenAPI from your application. message Reactive Messaging Use prepared tools for repetitive use case scenarios. waves Reactive Streams APIs to work with reactive streams in Helidon. airplay Rest Client Adds the capability to invoke remote microservices using a JAX-RS like interface to declare the operations. security Security A tool-chain to handle authentication, authorization and context propagation. timeline Tracing Profile and monitor your applications across multiple services. sync_alt WebSocket Enables Java applications to participate in WebSocket interactions as both servers and clients. ",
            "title": "Components"
        },
        {
            "location": "/mp/introduction/01_introduction",
            "text": " Try the Helidon MP quickstart guides to get your first Helidon MP application up and running in minutes. explore Guides Follow step-by-step guides to build your applications using Helidon MP. library_books Javadocs Browse the Helidon Javadocs. ",
            "title": "Next Steps"
        },
        {
            "location": "/se/introduction/01_introduction",
            "text": " Helidon SE is a compact toolkit that embraces the latest Java SE features: reactive streams, asynchronous and functional programming, and fluent-style APIs. ",
            "title": "preambule"
        },
        {
            "location": "/se/introduction/01_introduction",
            "text": " The REST framework for Helidon SE is the Helidon WebServer. It is built on top of Netty and uses a straight forward request routing API. Helidon SE supports a number of additional Helidon features: ",
            "title": "About Helidon SE Components"
        },
        {
            "location": "/se/introduction/01_introduction",
            "text": " save Ahead-of-Time Compilation (AOT) Use GraalVM native image to compile Helidon applications into a native executable. settings Config A flexible configuration framework with support for multiple sources and formats. share CORS Add support for CORS to your application using a Helidon module. storage DB Client Provides a unified, reactive API for working with databases in non-blocking way. graphic_eq GraphQL Build GraphQL servers. swap_horiz gRPC Build gRPC servers and clients. favorite_outline Health Checks Expose health statuses of your applications. av_timer Metrics Instrumentation to expose metrics of your applications. donut_large OpenAPI Support OpenAPI from your application. message Reactive Messaging Use prepared tools for repetitive use case scenarios. waves Reactive Streams APIs to work with reactive streams in Helidon. security Security A tool-chain to handle authentication, authorization and context propagation. timeline Tracing Profile and monitor your applications across multiple services. http WebClient HTTP client that handles responses to the HTTP requests in a reactive way. settings_ethernet WebServer A programmatic HTTP API with reactive features, powered by Netty. timeline WebSocket Enables Java applications to participate in WebSocket interactions as both servers and clients. ",
            "title": "Components"
        },
        {
            "location": "/se/introduction/01_introduction",
            "text": " Try the Helidon SE quickstart guides to get your first Helidon SE application up and running in minutes. explore Guides Follow step-by-step guides to build your applications using Helidon SE. library_books Javadocs Browse the Helidon Javadocs. ",
            "title": "Next Steps"
        },
        {
            "location": "/se/grpc/23_client_implementation",
            "text": " Helidon gRPC client framework allows you to write gRPC clients to access any gRPC service implementation. The benefits of using Helidon gRPC Client Framework include: It provides a number of helper methods that make client implementation significantly simpler. It allows you to configure some of the Helidon value-added features, such as security and metrics collection and interceptors down to the method level. It allows you to easily specify custom marshaller for requests and responses if protobuf does not satisfy your needs. ",
            "title": "preambule"
        },
        {
            "location": "/se/grpc/23_client_implementation",
            "text": " The first step to create a Helidon gRPC client application is to describe the set of methods in the gRPC service. Helidon gRPC Client Framework (simply called the \"Client framework\" in the remainder of the document) provides a class called ClientServiceDescriptor to describe the set of methods of a service that the client may invoke. There are three ways to build and initialize a ClientServiceDescriptor . The first option is to initialize ClientServiceDescriptor using protoc generated artifacts like BindableService or io.grpc.ServiceDescriptor . This option is possible if the gRPC service was built using .proto file. In this case the set of gRPC methods, their types and the appropriate marshallers are detected automatically. This is certainly the easiest way to initialize a ClientServiceDescriptor . The second option is to programmatically build the ClientServiceDescriptor . This option should be taken if the service was not built from protobuf files or if the protoc generated artifacts are not available to the client. ** The third option is to load the method descriptions from a configuration file. (Not yet implemented). The next step is to create a gRPC Channel to use to communicate with the server. Finally, you create an instance of GrpcServiceClient passing the ClientMethodDescriptor and the Channel instances. ",
            "title": "Client Implementation Basics"
        },
        {
            "location": "/se/grpc/23_client_implementation",
            "text": " Lets build a class called ProtoBasedStringServiceClient that invokes the various types of gRPC methods that our StringService offers. <markup lang=\"java\" >public class ProtoBasedStringServiceClient { private GrpcServiceClient client; public ProtoBasedStringServiceClient() { ClientServiceDescriptor desc = ClientServiceDescriptor .builder(StringService.getServiceDescriptor()) // (1) .build(); Channel channel = ManagedChannelBuilder.forAddress(\"localhost\", 1408) // (2) .usePlaintext().build(); this.client = GrpcServiceClient.create(channel, desc); // (3) } /** * Many gRPC methods take a {@link io.grpc.StreamObserver} as an argument. Lets * build a helper class that can be used in our example. */ public static class StringMessageStream&lt;T&gt; // (4) implements StreamObserver&lt;T&gt; { @Override public void onNext(T value) { System.out.println(\"Received : \" + value); } @Override public void onError(Throwable t) { t.printStracktrace(); } @Override public void onCompleted() { System.out.println(\"DONE\"); } } } Initialize the builder by specifying the StringService&#8217;s proto `ServiceDescriptor . From the ServiceDescriptor the builder detects the service name, the set of method names, and for each method its type (like Unary, ServerStreaming etc.), the request and response types (and hence their corresponding Marshallers) etc. We create a Channel to the service that is running on localhost:1408 . Finally, we create our GrpcServiceClient by using the above mentioned ClientServiceDescriptor and Channel . This client reference will be used to invoke various gRPC methods in our StringService We define a static inner class that implements the io.grpc.StreamObserver interface. An instance of this class can be used whereever a io.grpc.StreamObserver is required (like server streaming, bi-directional streaming methods). ",
            "title": "Creating and initializing a ClientServiceDescriptor for StringService (generated from protoc )"
        },
        {
            "location": "/se/grpc/23_client_implementation",
            "text": " The Client Framework provides many helper methods to invoke gRPC unary methods. <markup lang=\"java\" >public class ProtoBasedStringServiceClient { private GrpcServiceClient client; public ProtoBasedStringServiceClient() { /* code omitted */ } public void invokeUnaryMethod() throws Exception { StringMessage input = StringMessage.newBuilder().setText(\"ABC\").build(); CompletableFuture&lt;String&gt; result = client.unary(\"Lower\", input); // (1) String lcase = client.blockingUnary(\"Lower\", input); // (2) StringMessageStream stream = new StringMessageStream&lt;StringMessage&gt;(); client.blockingUnary(\"Lower\", input); // (3) } public static class StringMessageStream&lt;T&gt; { /* code omitted */ } } This variant of the unary API takes the method name and a request object and returns a CompletableFuture&lt;Response&gt; where &lt;Response&gt; is the response type. Here we invoke the Lower method passing the input StringMessage . This method returns a CompletableFuture&lt;StringMessage&gt; as response thus allowing the client to obtain the result asynchronously. This is simply a wrapper around the above method. This method blocks till the result is available. Here we create invoke the unary method by passing the StringMessageStream whose onNext method will be called (once) when the result is available. ",
            "title": "Invoking a unary method on the StringService"
        },
        {
            "location": "/se/grpc/23_client_implementation",
            "text": " Lets invoke the Join method which causes the server to return a single result after the client has streamed the request values to the server. gRPC API expects the client application to provide an instance of io.grpc.StreamObserver as an argument during the invocation of the client streaming method. In order to simplify the task of invoking Client Streaming methods, Helidon Client Framework provides a couple of methods to invoke gRPC Client Streaming methods. The first variant takes an Iterable as argument which in turn is converted into a io.grpc.StreamObserver . The second variant takes a io.grpc.StreamObserver as argument. The first variant can be used if the number of values to be streamed in small and known a priori. <markup lang=\"java\" >public class ProtoBasedStringServiceClient { private GrpcServiceClient client; public ProtoBasedStringServiceClient() { /* code omitted */ } public void invokeClientStreamingWithIterable() throws Exception { String sentence = \"A simple invocation of a client streaming method\"; Collection&lt;StringMessage&gt; input = Arrays.stream(sentence.split(\" \")) // (1) .map(w -&gt; StringMessage.newBuilder().setText(w).build()) .collect(Collectors.toList()); CompletableFuture&lt;StringMessage&gt; result = grpcClient.clientStreaming(\"Join\", input); // (2) } public void invokeClientStreaming() throws Exception { String sentence = \"A simple invocation of a client streaming method\"; StringMessageStream responseStream = new StringMessageStream&lt;StringMessage&gt;(); StreamObserver&lt;StringMessage&gt; clientStream = grpcClient.clientStreaming(\"Join\", responseStream); // (3) for (String word : sentence.split(\" \")) { clientStream.onNext(StringMessage.newBuilder().setText(word).build()); // (4) } clientStream.onCompleted(); // (5) } public static class StringMessageStream&lt;T&gt; { /* code imitted */ } } We prepare the collection that contains the values to be streamed. We call the first variant of the clientStreaming() method that takes the method name and the collection of values to be streamed from the client. Note: The above helper method is useful if the values to be streamed is fixed and small in number. If the number of values to be streamed is large (or unknown), then it is better to use this variant of the clientStreaming() method that takes a io.grpc.StreamObserver as an argument. This method returns a client stream through which the client can stream (potentially a large number of) value to the server. Once the client stream is obtained, the client streams the values using the onNext() method on the stream. When all values have been stream, the client invokes the onCompleted() method signal that all values have been streamed from the client. ",
            "title": "Invoking a client streaming method on the StringService"
        },
        {
            "location": "/se/grpc/23_client_implementation",
            "text": " Lets invoke the \"Split\" method which causes the server to stream the results back. <markup lang=\"java\" >public class ProtoBasedStringServiceClient { private GrpcServiceClient client; public ProtoBasedStringServiceClient() { /* code omitted */ } public void invokeServerStreaming() throws Exception { String sentence = \"This sentence will be split into words and sent back to client\"; StringMessage input = StringMessage.newBuilder().setText(sentence).build(); // (1) StringMessageStream&lt;StringMessage&gt; observer = new StringMessageStream&lt;&gt;(); // (2) grpcClient.serverStreaming(\"Split\", input, observer); // (3) } public static class StringMessageStream&lt;T&gt; { /* code imitted */ } } We prepare the input StringMessage that needs to be split. We create a StringMessageStream which will receive the results streamed from the server. We call the serverStreaming() passing the input and the StringMessageStream as arguments. The server sends a stream of words by calling the onNext() method on the StringMessageStream for each word. ",
            "title": "Invoking a server streaming method on the StringService (generated from protoc )"
        },
        {
            "location": "/se/grpc/23_client_implementation",
            "text": " Now lets invoke the Echo method in which both the client and the server have to stream the request and response. <markup lang=\"java\" >public class ProtoBasedStringServiceClient { private GrpcServiceClient client; public ProtoBasedStringServiceClient() { /* code omitted */ } public void invokeBidiStreaming() throws Exception { StringMessageStream&lt;StringMessage&gt; observer = new StringMessageStream&lt;&gt;(); // (1) StringMessageStream&lt;StringMessage&gt; clientStream = grpcClient .bidiStreaming(\"Echo\", observer); // (2) String sentence = \"Each word will be echoed back to the client by the server\"; for (String word : sentence.split(\" \")) { clientStream.onNext(StringMessage.newBuilder().setText(word).build()); // (3) } clientStream.onCompleted(); // (4) } public static class StringMessageStream&lt;T&gt; { /* code imitted */ } } We create a StringMessageStream which will receive the results streamed from the server. We call the bidiStreaming() passing the observer as argument. The server will send its results through this stream (basically by calling the onNext() on the observer ). The method returns a (client) stream which should be used by the client to stream values to the server. We stream each word in our sentence to the server by calling the onNext() method on the clientStream . We call the onCompleted() method on the clientStream to signal that the client has streamed all its values. ",
            "title": "Invoking a bi-directional streaming method on the StringService (generated from protoc )"
        },
        {
            "location": "/se/grpc/23_client_implementation",
            "text": " As mentioned above, the easiest way to create a ClientServiceDescriptor is to create it from an io.grpc.ServiceDescriptor or from a io.grpc.BindableService . It is fairly trivial to obtain these from a service generated from artifacts generated from protobuf IDL file. For this section we will assume the following proto file: <markup lang=\"proto\" >syntax = \"proto3\"; option java_package = \"io.helidon.grpc.client.test\"; service StringService { rpc Upper (StringMessage) returns (StringMessage) {} // (Unary) rpc Lower (StringMessage) returns (StringMessage) {} // (Unary) rpc Split (StringMessage) returns (stream StringMessage) {} // (Server Streaming) rpc Join (stream StringMessage) returns (StringMessage) {} // (Client Streaming) rpc Echo (stream StringMessage) returns (stream StringMessage) {} // (Bidirectional Streaming) } message StringMessage { string text = 1; } If you run it through protoc it will generate a class (among other things) called StringService . Assuming that the StringService server is running on port 1408, here is how you can create a Helidon gRPC Client that uses the Client Framework to invoke various types of gRPC methods. Creating and initializing a ClientServiceDescriptor for StringService (generated from protoc ) Lets build a class called ProtoBasedStringServiceClient that invokes the various types of gRPC methods that our StringService offers. <markup lang=\"java\" >public class ProtoBasedStringServiceClient { private GrpcServiceClient client; public ProtoBasedStringServiceClient() { ClientServiceDescriptor desc = ClientServiceDescriptor .builder(StringService.getServiceDescriptor()) // (1) .build(); Channel channel = ManagedChannelBuilder.forAddress(\"localhost\", 1408) // (2) .usePlaintext().build(); this.client = GrpcServiceClient.create(channel, desc); // (3) } /** * Many gRPC methods take a {@link io.grpc.StreamObserver} as an argument. Lets * build a helper class that can be used in our example. */ public static class StringMessageStream&lt;T&gt; // (4) implements StreamObserver&lt;T&gt; { @Override public void onNext(T value) { System.out.println(\"Received : \" + value); } @Override public void onError(Throwable t) { t.printStracktrace(); } @Override public void onCompleted() { System.out.println(\"DONE\"); } } } Initialize the builder by specifying the StringService&#8217;s proto `ServiceDescriptor . From the ServiceDescriptor the builder detects the service name, the set of method names, and for each method its type (like Unary, ServerStreaming etc.), the request and response types (and hence their corresponding Marshallers) etc. We create a Channel to the service that is running on localhost:1408 . Finally, we create our GrpcServiceClient by using the above mentioned ClientServiceDescriptor and Channel . This client reference will be used to invoke various gRPC methods in our StringService We define a static inner class that implements the io.grpc.StreamObserver interface. An instance of this class can be used whereever a io.grpc.StreamObserver is required (like server streaming, bi-directional streaming methods). Invoking a unary method on the StringService The Client Framework provides many helper methods to invoke gRPC unary methods. <markup lang=\"java\" >public class ProtoBasedStringServiceClient { private GrpcServiceClient client; public ProtoBasedStringServiceClient() { /* code omitted */ } public void invokeUnaryMethod() throws Exception { StringMessage input = StringMessage.newBuilder().setText(\"ABC\").build(); CompletableFuture&lt;String&gt; result = client.unary(\"Lower\", input); // (1) String lcase = client.blockingUnary(\"Lower\", input); // (2) StringMessageStream stream = new StringMessageStream&lt;StringMessage&gt;(); client.blockingUnary(\"Lower\", input); // (3) } public static class StringMessageStream&lt;T&gt; { /* code omitted */ } } This variant of the unary API takes the method name and a request object and returns a CompletableFuture&lt;Response&gt; where &lt;Response&gt; is the response type. Here we invoke the Lower method passing the input StringMessage . This method returns a CompletableFuture&lt;StringMessage&gt; as response thus allowing the client to obtain the result asynchronously. This is simply a wrapper around the above method. This method blocks till the result is available. Here we create invoke the unary method by passing the StringMessageStream whose onNext method will be called (once) when the result is available. Invoking a client streaming method on the StringService Lets invoke the Join method which causes the server to return a single result after the client has streamed the request values to the server. gRPC API expects the client application to provide an instance of io.grpc.StreamObserver as an argument during the invocation of the client streaming method. In order to simplify the task of invoking Client Streaming methods, Helidon Client Framework provides a couple of methods to invoke gRPC Client Streaming methods. The first variant takes an Iterable as argument which in turn is converted into a io.grpc.StreamObserver . The second variant takes a io.grpc.StreamObserver as argument. The first variant can be used if the number of values to be streamed in small and known a priori. <markup lang=\"java\" >public class ProtoBasedStringServiceClient { private GrpcServiceClient client; public ProtoBasedStringServiceClient() { /* code omitted */ } public void invokeClientStreamingWithIterable() throws Exception { String sentence = \"A simple invocation of a client streaming method\"; Collection&lt;StringMessage&gt; input = Arrays.stream(sentence.split(\" \")) // (1) .map(w -&gt; StringMessage.newBuilder().setText(w).build()) .collect(Collectors.toList()); CompletableFuture&lt;StringMessage&gt; result = grpcClient.clientStreaming(\"Join\", input); // (2) } public void invokeClientStreaming() throws Exception { String sentence = \"A simple invocation of a client streaming method\"; StringMessageStream responseStream = new StringMessageStream&lt;StringMessage&gt;(); StreamObserver&lt;StringMessage&gt; clientStream = grpcClient.clientStreaming(\"Join\", responseStream); // (3) for (String word : sentence.split(\" \")) { clientStream.onNext(StringMessage.newBuilder().setText(word).build()); // (4) } clientStream.onCompleted(); // (5) } public static class StringMessageStream&lt;T&gt; { /* code imitted */ } } We prepare the collection that contains the values to be streamed. We call the first variant of the clientStreaming() method that takes the method name and the collection of values to be streamed from the client. Note: The above helper method is useful if the values to be streamed is fixed and small in number. If the number of values to be streamed is large (or unknown), then it is better to use this variant of the clientStreaming() method that takes a io.grpc.StreamObserver as an argument. This method returns a client stream through which the client can stream (potentially a large number of) value to the server. Once the client stream is obtained, the client streams the values using the onNext() method on the stream. When all values have been stream, the client invokes the onCompleted() method signal that all values have been streamed from the client. Invoking a server streaming method on the StringService (generated from protoc ) Lets invoke the \"Split\" method which causes the server to stream the results back. <markup lang=\"java\" >public class ProtoBasedStringServiceClient { private GrpcServiceClient client; public ProtoBasedStringServiceClient() { /* code omitted */ } public void invokeServerStreaming() throws Exception { String sentence = \"This sentence will be split into words and sent back to client\"; StringMessage input = StringMessage.newBuilder().setText(sentence).build(); // (1) StringMessageStream&lt;StringMessage&gt; observer = new StringMessageStream&lt;&gt;(); // (2) grpcClient.serverStreaming(\"Split\", input, observer); // (3) } public static class StringMessageStream&lt;T&gt; { /* code imitted */ } } We prepare the input StringMessage that needs to be split. We create a StringMessageStream which will receive the results streamed from the server. We call the serverStreaming() passing the input and the StringMessageStream as arguments. The server sends a stream of words by calling the onNext() method on the StringMessageStream for each word. Invoking a bi-directional streaming method on the StringService (generated from protoc ) Now lets invoke the Echo method in which both the client and the server have to stream the request and response. <markup lang=\"java\" >public class ProtoBasedStringServiceClient { private GrpcServiceClient client; public ProtoBasedStringServiceClient() { /* code omitted */ } public void invokeBidiStreaming() throws Exception { StringMessageStream&lt;StringMessage&gt; observer = new StringMessageStream&lt;&gt;(); // (1) StringMessageStream&lt;StringMessage&gt; clientStream = grpcClient .bidiStreaming(\"Echo\", observer); // (2) String sentence = \"Each word will be echoed back to the client by the server\"; for (String word : sentence.split(\" \")) { clientStream.onNext(StringMessage.newBuilder().setText(word).build()); // (3) } clientStream.onCompleted(); // (4) } public static class StringMessageStream&lt;T&gt; { /* code imitted */ } } We create a StringMessageStream which will receive the results streamed from the server. We call the bidiStreaming() passing the observer as argument. The server will send its results through this stream (basically by calling the onNext() on the observer ). The method returns a (client) stream which should be used by the client to stream values to the server. We stream each word in our sentence to the server by calling the onNext() method on the clientStream . We call the onCompleted() method on the clientStream to signal that the client has streamed all its values. ",
            "title": "Creating gRPC clients from protoc generated artifacts"
        },
        {
            "location": "/se/grpc/23_client_implementation",
            "text": " Assuming that the service is still running on port 1408, lets see how to create our Client without using the StringService 's proto ServiceDescriptor . Since we are not going to use the StringService 's proto ServiceDescriptor , we need to describe the methods that the client need to invoke. The Helidon client framework provides a bunch of APIs to easily describe gRPC methods. For example, to register a unary method, we need to use the unary method and configure it to specify the request and response types. Other than describing the methods that our client will invoke, the rest of the following code should be very similar (or same) as the previous section!! <markup lang=\"java\" >public class StringServiceClient { public static void main(String[] args) { ClientMethodDescriptor lower = ClientMethodDescriptor .unary(\"StringService\", \"Lower\") // (1) .requestType(StringMessage.class) // (2) .responseType(StringMessage.class) // (3) .build(); // (4) ClientMethodDescriptor join = ClientMethodDescriptor .clientStreaming(\"StringService\", \"Join\") // (5) .requestType(StringMessage.class) .responseType(StringMessage.class) .build(); ClientMethodDescriptor split = ClientMethodDescriptor .serverStreaming(\"StringService\", \"Split\") // (6) .requestType(StringMessage.class) .responseType(StringMessage.class) .build(); ClientMethodDescriptor echo = ClientMethodDescriptor .bidirectional(\"StringService\", \"Echo\") // (7) .requestType(StringMessage.class) .responseType(StringMessage.class) .build(); ClientServiceDescriptor serviceDesc = ClientServiceDescriptor // (8) .builder(StringService.class) .unary(lower) .clientStreaming(join) .serverStreaming(split) .bidirectional(echo) .build(); Channel channel = ManagedChannelBuilder.forAddress(\"localhost\", 1408) // (9) .usePlaintext().build(); GrpcServiceClient client = GrpcServiceClient.create(channel, serviceDesc); // (10) } } Use the unary() method on ClientMethodDescriptor to create a builder for a gRPC unary method. The service name and the method name (\"Lower\") are specified. Set the request type of the method to be StringMessage (since the Lower method takes StringMessage as a parameter). Set the response type of the method to be StringMessage (since the Lower method returns a StringMessage as a parameter). Build the ClientMethodDescriptor . Note that the return value is a ClientMethodDescriptor that contains the correct Marshallers for the request &amp; response types. Use the clientStreaming() method on ClientMethodDescriptor to create a builder for a gRPC client streaming method. The service name and the method name (\"Join\") are specified. Use the serverStreaming() method on ClientMethodDescriptor to create a builder for a gRPC server streaming method. The service name and the method name (\"Split\") are specified. Use the bidirectional() method on ClientMethodDescriptor to create a builder for a gRPC Bidi streaming method. The service name and the method name (\"Echo\") are specified. Create a ClientServiceDescriptor for service named StringService and add all our ClientMethodDescriptor s. We create a Channel to the service that is running on localhost:1408 . Finally, we create our GrpcServiceClient by using the above mentioned ClientServiceDescriptor and Channel . At this point the client object can be used to invoke any of the four types of methods we have seen in the earlier sections!! ",
            "title": "Programmatically creating ClientServiceDescriptor for StringService"
        },
        {
            "location": "/se/grpc/23_client_implementation",
            "text": " If your service is not using protobuf for serialization, then the Client framework allows you to programmatically initialize ClientMethodDescriptor and create clients to invoke methods on the service. All you have to do is create the set of ClientMethodDescriptor s and the ClientServiceDescriptor as described in the previous section, but with one change. Just do not to set the request and response types in the ClientMethodDescriptor . That&#8217;s all!! In fact, there is an API in the ClientServiceDescriptor that makes this even simpler. You can simply pass the method name. For example, to create a client streaming method called \"JoinString\" that uses java serialization simply call the clientStreamin(\"JoinString\") . Lets see an example of creating a client for a service that uses Java serialization. <markup lang=\"java\" >public static void main(String[] args) throws Exception { ClientServiceDescriptor descriptor = ClientServiceDescriptor.builder(HelloService.class) // (1) .clientStreaming(\"JoinString\") // (2) .build(); Channel channel = ManagedChannelBuilder.forAddress(\"localhost\", 1408) .usePlaintext() .build(); GrpcServiceClient client = GrpcServiceClient.create(channel, descriptor); String sentence = \"A simple invocation of a client streaming method\"; Collection&lt;StringMessage&gt; input = Arrays.stream(sentence.split(\" \")) .map(w -&gt; StringMessage.newBuilder().setText(w).build()) .collect(Collectors.toList()); CompletableFuture&lt;StringMessage&gt; result = grpcClient.clientStreaming(\"Join\", input); } Create a ClientServiceDescriptor for the HelloService . Add the \"JoinString\" client streaming method to the ClientServiceDescriptor . Since we didn&#8217;t set the request or response type (like we did in the previous sections), Java serialization will be used for Marshalling and Unmarshalling the request and response values. Note that whether a ClientServiceDescriptor is built using protobuf artifacts or is built programmatically, the same set of APIs provided by the Client Framework can be used to invoke gRPC methods. ",
            "title": "Creating gRPC clients for non protobuf services"
        },
        {
            "location": "/mp/jaxrs/04_static-content",
            "text": " You can serve static content from a location in a file system or from the classpath. ",
            "title": "preambule"
        },
        {
            "location": "/mp/jaxrs/04_static-content",
            "text": "<markup lang=\"properties\" title=\"META-INF/microprofile-config.properties - File system static content\" ># Location of content on file system server.static.path.location=/var/www/html # default is index.html server.static.path.welcome=resource.html # static content path - default is \"/\" # server.static.path.context=/static-file <markup lang=\"properties\" title=\"META-INF/microprofile-config.properties - Classpath static content\" ># src/main/resources/WEB in your source tree server.static.classpath.location=/WEB # default is index.html server.static.classpath.welcome=resource.html # static content path - default is \"/\" # server.static.classpath.context=/static-cp ",
            "title": "Serving Static Content"
        },
        {
            "location": "/se/guides/05_security_oidc",
            "text": " This guide describes how to set up Keycloak and Helidon to secure your application with OIDC security provider. ",
            "title": "preambule"
        },
        {
            "location": "/se/guides/05_security_oidc",
            "text": " This guide describes the steps required to protect your whole application or a specific area with Open ID Connect (OIDC) security. OIDC is a secure mechanism for an application to contact an identity service. Its built on top of OAuth 2.0 and provides full-fledged authentication and authorization protocols. ",
            "title": "Introduction"
        },
        {
            "location": "/se/guides/05_security_oidc",
            "text": " To install Keycloak with Docker, open a terminal and make sure the port 8080 is free. <markup lang=\"bash\" title=\"Enter the following command\" >docker run -p 8080:8080 -e KEYCLOAK_USER=admin -e KEYCLOAK_PASSWORD=admin quay.io/keycloak/keycloak:11.0.2 This will start Keycloak on local port 8080. It will create the admin user with username admin and password admin Feel free to modify 11.0.2 by any keycloak version of your wish. If you are running docker behind a proxy server, make sure it is either configured into docker or disabled. Otherwise, you might face a connection timeout because docker cannot download the required data. To verify that Keycloak is running correctly, go to the admin console : http://localhost:8080/auth/admin Log in using the username and password mentioned above: admin . You should be logged in successfully, and it prompts the admin console. ",
            "title": "On Docker"
        },
        {
            "location": "/se/guides/05_security_oidc",
            "text": " Download the last version of Keycloak from Keycloak website : https://www.keycloak.org/downloads In the table Server choose Standalone server distribution. ZIP or Tar format are available, click on either to download Keycloak. After extracting the archive file, you should have a directory named keycloak followed by the version. For example, if you chose version 11.0.2, the folder must be named keycloak-11.0.2. Open keycloak folder to make it your current directory. <markup lang=\"bash\" title=\"Run this command from command prompt to open the directory:\" >cd keycloak-11.0.2 ",
            "title": "On JDK"
        },
        {
            "location": "/se/guides/05_security_oidc",
            "text": " On Docker To install Keycloak with Docker, open a terminal and make sure the port 8080 is free. <markup lang=\"bash\" title=\"Enter the following command\" >docker run -p 8080:8080 -e KEYCLOAK_USER=admin -e KEYCLOAK_PASSWORD=admin quay.io/keycloak/keycloak:11.0.2 This will start Keycloak on local port 8080. It will create the admin user with username admin and password admin Feel free to modify 11.0.2 by any keycloak version of your wish. If you are running docker behind a proxy server, make sure it is either configured into docker or disabled. Otherwise, you might face a connection timeout because docker cannot download the required data. To verify that Keycloak is running correctly, go to the admin console : http://localhost:8080/auth/admin Log in using the username and password mentioned above: admin . You should be logged in successfully, and it prompts the admin console. On JDK Download the last version of Keycloak from Keycloak website : https://www.keycloak.org/downloads In the table Server choose Standalone server distribution. ZIP or Tar format are available, click on either to download Keycloak. After extracting the archive file, you should have a directory named keycloak followed by the version. For example, if you chose version 11.0.2, the folder must be named keycloak-11.0.2. Open keycloak folder to make it your current directory. <markup lang=\"bash\" title=\"Run this command from command prompt to open the directory:\" >cd keycloak-11.0.2 ",
            "title": "Keycloak Installation"
        },
        {
            "location": "/se/guides/05_security_oidc",
            "text": " You need to create an admin user because it does not come by default when installing Keycloak. To do this, open http://localhost:8080/auth in your favorite browser. A window Welcome to Keycloak should be prompted. If not, check if any error appear in the terminal. Fill the form by adding Username and Password. Click on Create to create the admin user. Above Administration Console should be printed \"User created\" in a green rectangle. To check that the admin user was created correctly, click on Administration user which should redirect you to a Login form. Enter the Username and Password created earlier to log in. After successfully logged in, the admin console is prompted. ",
            "title": "Create an Admin User"
        },
        {
            "location": "/se/guides/05_security_oidc",
            "text": " To start keycloak and have it ready for further steps, run the following command. <markup lang=\"bash\" title=\"On Linux run:\" >bin/standalone.sh <markup lang=\"bash\" title=\"On Windows run:\" >bin/standalone.bat Keycloak runs on localhost:8080 by default. Create an Admin User You need to create an admin user because it does not come by default when installing Keycloak. To do this, open http://localhost:8080/auth in your favorite browser. A window Welcome to Keycloak should be prompted. If not, check if any error appear in the terminal. Fill the form by adding Username and Password. Click on Create to create the admin user. Above Administration Console should be printed \"User created\" in a green rectangle. To check that the admin user was created correctly, click on Administration user which should redirect you to a Login form. Enter the Username and Password created earlier to log in. After successfully logged in, the admin console is prompted. ",
            "title": "Start Keycloak"
        },
        {
            "location": "/se/guides/05_security_oidc",
            "text": " A realm is the place where groups of applications, and their environment, can be created. It gathers : One or several applications One or several users Sessions Events Clients and their scopes By default, there is a realm called Master . It is used to manage Keycloak. It is not recommended to associate your application with this realm as it could disturb Keycloak functioning. To create a new realm to manage your application: Open Keycloak admin console http://localhost:8080/auth/admin . Hover the mouse over the dropdown in the top-left corner where it says Master , and press Add realm . Fill the form by adding the realm name, myRealm for example. Click on Create to create the new realm. To verify that your realm is created, on the top-left corner where it said Master previously should be now your realm name or myRealm is you followed the example. To switch from a realm to another, hover the realm name, and the other realm created appear in the dropdown. Click on any realm name to change the current realm. Make sure all configuration or modification are saved before changing the current realm or be subject to lose your configuration. ",
            "title": "Create a Realm"
        },
        {
            "location": "/se/guides/05_security_oidc",
            "text": " Initially there are no users in a new realm. An unlimited number of user can be created per realm. A realm contains resources such as client which can be accessed by users. To create a new user: Open the Keycloak admin console: http://localhost:8080/auth/admin Click on Users in the left menu Press Add user Fill the form (Username is the only mandatory field) with this value Username: myUser Click Save A new user is just created but it needs a password to be able to login. To initialize it, do this: Click on Credentials at the top of the page, under Myuser . Fill Password and Password confirmation with the user password of your choice. If the Temporary field is set to ON , the user has to update password on next login. Click ON to make it OFF and prevent it. Press Set Password . A pop-up window is popping off. Click on Set Password to confirm the new password. To verify that the new user is created correctly: Open the Keycloak account console: http://localhost:8080/auth/realms/myRealm/account . Login with myUser and password chosen earlier. You should now be logged-in to the account console where users can manage their accounts. ",
            "title": "Create a User"
        },
        {
            "location": "/se/guides/05_security_oidc",
            "text": " To create your first client: Open the Keycloak admin console: http://localhost:8080/auth/admin . Make sure the current realm is myRealm and not Master . Navigate to the left menu, into configure section, click on Clients . This window displays a table with every client from the realm. Click on Create . Fill the following: Client ID : myClientID Client Protocol : openid-connect Press Save Modify Access type : confidential Update Valid Redirect URIs : http://localhost:7987/* Click on + to add the new URI. Click on Save . A new tab named Credentials is created. Click on it to access this new tab. Select Client Authenticator : Client ID and Secret Click on generate secret to generate client secret. Keycloak is now configured and ready. Keep keycloak running on your terminal and open a new tab to set up Helidon. ",
            "title": "Create a Client"
        },
        {
            "location": "/se/guides/05_security_oidc",
            "text": " To set up Keycloak properly, go to the admin console: http://localhost:8080/auth/admin If you are using Docker, use Username admin and password admin as it is the default admin user. Otherwise, use the username and password you used to create the admin user. Create a Realm A realm is the place where groups of applications, and their environment, can be created. It gathers : One or several applications One or several users Sessions Events Clients and their scopes By default, there is a realm called Master . It is used to manage Keycloak. It is not recommended to associate your application with this realm as it could disturb Keycloak functioning. To create a new realm to manage your application: Open Keycloak admin console http://localhost:8080/auth/admin . Hover the mouse over the dropdown in the top-left corner where it says Master , and press Add realm . Fill the form by adding the realm name, myRealm for example. Click on Create to create the new realm. To verify that your realm is created, on the top-left corner where it said Master previously should be now your realm name or myRealm is you followed the example. To switch from a realm to another, hover the realm name, and the other realm created appear in the dropdown. Click on any realm name to change the current realm. Make sure all configuration or modification are saved before changing the current realm or be subject to lose your configuration. Create a User Initially there are no users in a new realm. An unlimited number of user can be created per realm. A realm contains resources such as client which can be accessed by users. To create a new user: Open the Keycloak admin console: http://localhost:8080/auth/admin Click on Users in the left menu Press Add user Fill the form (Username is the only mandatory field) with this value Username: myUser Click Save A new user is just created but it needs a password to be able to login. To initialize it, do this: Click on Credentials at the top of the page, under Myuser . Fill Password and Password confirmation with the user password of your choice. If the Temporary field is set to ON , the user has to update password on next login. Click ON to make it OFF and prevent it. Press Set Password . A pop-up window is popping off. Click on Set Password to confirm the new password. To verify that the new user is created correctly: Open the Keycloak account console: http://localhost:8080/auth/realms/myRealm/account . Login with myUser and password chosen earlier. You should now be logged-in to the account console where users can manage their accounts. Create a Client To create your first client: Open the Keycloak admin console: http://localhost:8080/auth/admin . Make sure the current realm is myRealm and not Master . Navigate to the left menu, into configure section, click on Clients . This window displays a table with every client from the realm. Click on Create . Fill the following: Client ID : myClientID Client Protocol : openid-connect Press Save Modify Access type : confidential Update Valid Redirect URIs : http://localhost:7987/* Click on + to add the new URI. Click on Save . A new tab named Credentials is created. Click on it to access this new tab. Select Client Authenticator : Client ID and Secret Click on generate secret to generate client secret. Keycloak is now configured and ready. Keep keycloak running on your terminal and open a new tab to set up Helidon. ",
            "title": "Set up Keycloak"
        },
        {
            "location": "/se/guides/05_security_oidc",
            "text": " Update the pom.xml file and add the following Helidon dependency to the &lt;dependencies&gt; section. <markup lang=\"xml\" title=\"Add the following dependency to pom.xml :\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-oidc&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Update Project Dependencies"
        },
        {
            "location": "/se/guides/05_security_oidc",
            "text": " The OIDC security provider configuration can be joined to helidon configuration file. This file is located here: src/main/resources/application.yaml . It can be easily used to configure the web server without modifying application code. <markup lang=\"yaml\" title=\"Add the following line to application.yaml\" >security: providers: - abac: # Adds ABAC Provider - it does not require any configuration - oidc: client-id: \"myClientID\" client-secret: \"Client secret generated into Keycloak client credential\" identity-uri: \"http://localhost:8080/auth/realms/myRealm\" audience: \"account\" header-use: \"true\" # proxy-host should be defined if you operate behind a proxy, can be removed otherwise proxy-host: \"\" frontend-uri: \"http://localhost:7987\" server-type: \"oidc\" web-server: # protected paths on the web server paths: - path: \"/greet\" methods: [\"get\"] authenticate: true client-id must be the same as the one configure in keycloak. The client secret generate by Keycloak during Create a client section. identity-uri is used to redirect the user to keycloak. frontend-uri will direct you back to the application. paths section defines the protected application&#8217;s path. Make sure keycloak and the application are not running on the same port. The application port value can be changed into application.yaml. <markup lang=\"yaml\" title=\"Change these properties to configure the server host and port\" >server: port: 7987 host: localhost If the port 7987 is already used, check what port is free on your machine. <markup lang=\"yaml\" title=\"Replace the old port into application.yaml\" >server: port: \"{Your-new-port}\" ... frontend-uri: \"http://localhost:{Your-new-port}\" ",
            "title": "Add OIDC Security Properties"
        },
        {
            "location": "/se/guides/05_security_oidc",
            "text": " Once the properties are added, the web server must be set up. The Main.createRouting method gather all configuration properties. <markup lang=\"java\" title=\"Add the following to Main.createRouting method\" >import io.helidon.security.Security; import io.helidon.security.integration.webserver.WebSecurity; import io.helidon.security.providers.oidc.OidcSupport; ... Security security = Security.create(config.get(\"security\")); return Routing.builder() .register(WebSecurity.create(security, config.get(\"security\"))) .register(OidcSupport.create(config)) ... Create the Helidon Security instance using configuration. Register Helidon WebSecurity instance using security instance and configuration. Register Helidon OidcSupport instance. That code is extracting security properties from application.yaml into two steps. First the Security instance is used to bootstrap security, so the WebSecurity instance can integrate security into Web Server. Then, OidcSupport instance registers the endpoint to which OIDC redirects browser after a successful login. Helidon sample is now set up and ready. ",
            "title": "Configure Web Server"
        },
        {
            "location": "/se/guides/05_security_oidc",
            "text": " Use the Helidon SE Maven archetype to create a simple project. It will be used as an example to show how to set up Helidon. Replace 2.5.4 by the latest helidon version. It will download the quickstart project into the current directory. <markup lang=\"bash\" title=\"Run the Maven archetype\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-se \\ -DarchetypeVersion=2.5.4 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-se \\ -Dpackage=io.helidon.examples.quickstart.se <markup lang=\"bash\" title=\"The project will be built and run from the helidon-quickstart-se directory:\" >cd helidon-quickstart-se Update Project Dependencies Update the pom.xml file and add the following Helidon dependency to the &lt;dependencies&gt; section. <markup lang=\"xml\" title=\"Add the following dependency to pom.xml :\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-oidc&lt;/artifactId&gt; &lt;/dependency&gt; Add OIDC Security Properties The OIDC security provider configuration can be joined to helidon configuration file. This file is located here: src/main/resources/application.yaml . It can be easily used to configure the web server without modifying application code. <markup lang=\"yaml\" title=\"Add the following line to application.yaml\" >security: providers: - abac: # Adds ABAC Provider - it does not require any configuration - oidc: client-id: \"myClientID\" client-secret: \"Client secret generated into Keycloak client credential\" identity-uri: \"http://localhost:8080/auth/realms/myRealm\" audience: \"account\" header-use: \"true\" # proxy-host should be defined if you operate behind a proxy, can be removed otherwise proxy-host: \"\" frontend-uri: \"http://localhost:7987\" server-type: \"oidc\" web-server: # protected paths on the web server paths: - path: \"/greet\" methods: [\"get\"] authenticate: true client-id must be the same as the one configure in keycloak. The client secret generate by Keycloak during Create a client section. identity-uri is used to redirect the user to keycloak. frontend-uri will direct you back to the application. paths section defines the protected application&#8217;s path. Make sure keycloak and the application are not running on the same port. The application port value can be changed into application.yaml. <markup lang=\"yaml\" title=\"Change these properties to configure the server host and port\" >server: port: 7987 host: localhost If the port 7987 is already used, check what port is free on your machine. <markup lang=\"yaml\" title=\"Replace the old port into application.yaml\" >server: port: \"{Your-new-port}\" ... frontend-uri: \"http://localhost:{Your-new-port}\" Configure Web Server Once the properties are added, the web server must be set up. The Main.createRouting method gather all configuration properties. <markup lang=\"java\" title=\"Add the following to Main.createRouting method\" >import io.helidon.security.Security; import io.helidon.security.integration.webserver.WebSecurity; import io.helidon.security.providers.oidc.OidcSupport; ... Security security = Security.create(config.get(\"security\")); return Routing.builder() .register(WebSecurity.create(security, config.get(\"security\"))) .register(OidcSupport.create(config)) ... Create the Helidon Security instance using configuration. Register Helidon WebSecurity instance using security instance and configuration. Register Helidon OidcSupport instance. That code is extracting security properties from application.yaml into two steps. First the Security instance is used to bootstrap security, so the WebSecurity instance can integrate security into Web Server. Then, OidcSupport instance registers the endpoint to which OIDC redirects browser after a successful login. Helidon sample is now set up and ready. ",
            "title": "Set up Helidon"
        },
        {
            "location": "/se/guides/05_security_oidc",
            "text": " For this 20 minute tutorial, you will need the following: <div class=\"table__overflow elevation-1 flex sm7 \"> A Helidon {upper-case-flavor} Application You can use your own application or use the Helidon {upper-case-flavor} Quickstart to create a sample application. Java&#160;SE&#160;11 ( Open&#160;JDK&#160;11 ) Helidon requires Java 11+. Maven 3.6.1+ Helidon requires Maven 3.6.1+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop ). <markup lang=\"bash\" title=\"Verify Prerequisites\" >java -version mvn --version docker --version kubectl version --short <markup lang=\"bash\" title=\"Setting JAVA_HOME\" ># On Mac export JAVA_HOME=`/usr/libexec/java_home -v 11` # On Linux # Use the appropriate path to your JDK export JAVA_HOME=/usr/lib/jvm/jdk-11 In addition, you will need to install and configure the following: Introduction Keycloak Installation Set up Keycloak Set up Helidon Test Keycloak process with Postman Restrict access to a specific role Introduction This guide describes the steps required to protect your whole application or a specific area with Open ID Connect (OIDC) security. OIDC is a secure mechanism for an application to contact an identity service. Its built on top of OAuth 2.0 and provides full-fledged authentication and authorization protocols. Keycloak Installation On Docker To install Keycloak with Docker, open a terminal and make sure the port 8080 is free. <markup lang=\"bash\" title=\"Enter the following command\" >docker run -p 8080:8080 -e KEYCLOAK_USER=admin -e KEYCLOAK_PASSWORD=admin quay.io/keycloak/keycloak:11.0.2 This will start Keycloak on local port 8080. It will create the admin user with username admin and password admin Feel free to modify 11.0.2 by any keycloak version of your wish. If you are running docker behind a proxy server, make sure it is either configured into docker or disabled. Otherwise, you might face a connection timeout because docker cannot download the required data. To verify that Keycloak is running correctly, go to the admin console : http://localhost:8080/auth/admin Log in using the username and password mentioned above: admin . You should be logged in successfully, and it prompts the admin console. On JDK Download the last version of Keycloak from Keycloak website : https://www.keycloak.org/downloads In the table Server choose Standalone server distribution. ZIP or Tar format are available, click on either to download Keycloak. After extracting the archive file, you should have a directory named keycloak followed by the version. For example, if you chose version 11.0.2, the folder must be named keycloak-11.0.2. Open keycloak folder to make it your current directory. <markup lang=\"bash\" title=\"Run this command from command prompt to open the directory:\" >cd keycloak-11.0.2 Start Keycloak To start keycloak and have it ready for further steps, run the following command. <markup lang=\"bash\" title=\"On Linux run:\" >bin/standalone.sh <markup lang=\"bash\" title=\"On Windows run:\" >bin/standalone.bat Keycloak runs on localhost:8080 by default. Create an Admin User You need to create an admin user because it does not come by default when installing Keycloak. To do this, open http://localhost:8080/auth in your favorite browser. A window Welcome to Keycloak should be prompted. If not, check if any error appear in the terminal. Fill the form by adding Username and Password. Click on Create to create the admin user. Above Administration Console should be printed \"User created\" in a green rectangle. To check that the admin user was created correctly, click on Administration user which should redirect you to a Login form. Enter the Username and Password created earlier to log in. After successfully logged in, the admin console is prompted. Set up Keycloak To set up Keycloak properly, go to the admin console: http://localhost:8080/auth/admin If you are using Docker, use Username admin and password admin as it is the default admin user. Otherwise, use the username and password you used to create the admin user. Create a Realm A realm is the place where groups of applications, and their environment, can be created. It gathers : One or several applications One or several users Sessions Events Clients and their scopes By default, there is a realm called Master . It is used to manage Keycloak. It is not recommended to associate your application with this realm as it could disturb Keycloak functioning. To create a new realm to manage your application: Open Keycloak admin console http://localhost:8080/auth/admin . Hover the mouse over the dropdown in the top-left corner where it says Master , and press Add realm . Fill the form by adding the realm name, myRealm for example. Click on Create to create the new realm. To verify that your realm is created, on the top-left corner where it said Master previously should be now your realm name or myRealm is you followed the example. To switch from a realm to another, hover the realm name, and the other realm created appear in the dropdown. Click on any realm name to change the current realm. Make sure all configuration or modification are saved before changing the current realm or be subject to lose your configuration. Create a User Initially there are no users in a new realm. An unlimited number of user can be created per realm. A realm contains resources such as client which can be accessed by users. To create a new user: Open the Keycloak admin console: http://localhost:8080/auth/admin Click on Users in the left menu Press Add user Fill the form (Username is the only mandatory field) with this value Username: myUser Click Save A new user is just created but it needs a password to be able to login. To initialize it, do this: Click on Credentials at the top of the page, under Myuser . Fill Password and Password confirmation with the user password of your choice. If the Temporary field is set to ON , the user has to update password on next login. Click ON to make it OFF and prevent it. Press Set Password . A pop-up window is popping off. Click on Set Password to confirm the new password. To verify that the new user is created correctly: Open the Keycloak account console: http://localhost:8080/auth/realms/myRealm/account . Login with myUser and password chosen earlier. You should now be logged-in to the account console where users can manage their accounts. Create a Client To create your first client: Open the Keycloak admin console: http://localhost:8080/auth/admin . Make sure the current realm is myRealm and not Master . Navigate to the left menu, into configure section, click on Clients . This window displays a table with every client from the realm. Click on Create . Fill the following: Client ID : myClientID Client Protocol : openid-connect Press Save Modify Access type : confidential Update Valid Redirect URIs : http://localhost:7987/* Click on + to add the new URI. Click on Save . A new tab named Credentials is created. Click on it to access this new tab. Select Client Authenticator : Client ID and Secret Click on generate secret to generate client secret. Keycloak is now configured and ready. Keep keycloak running on your terminal and open a new tab to set up Helidon. Set up Helidon Use the Helidon SE Maven archetype to create a simple project. It will be used as an example to show how to set up Helidon. Replace 2.5.4 by the latest helidon version. It will download the quickstart project into the current directory. <markup lang=\"bash\" title=\"Run the Maven archetype\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-se \\ -DarchetypeVersion=2.5.4 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-se \\ -Dpackage=io.helidon.examples.quickstart.se <markup lang=\"bash\" title=\"The project will be built and run from the helidon-quickstart-se directory:\" >cd helidon-quickstart-se Update Project Dependencies Update the pom.xml file and add the following Helidon dependency to the &lt;dependencies&gt; section. <markup lang=\"xml\" title=\"Add the following dependency to pom.xml :\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-oidc&lt;/artifactId&gt; &lt;/dependency&gt; Add OIDC Security Properties The OIDC security provider configuration can be joined to helidon configuration file. This file is located here: src/main/resources/application.yaml . It can be easily used to configure the web server without modifying application code. <markup lang=\"yaml\" title=\"Add the following line to application.yaml\" >security: providers: - abac: # Adds ABAC Provider - it does not require any configuration - oidc: client-id: \"myClientID\" client-secret: \"Client secret generated into Keycloak client credential\" identity-uri: \"http://localhost:8080/auth/realms/myRealm\" audience: \"account\" header-use: \"true\" # proxy-host should be defined if you operate behind a proxy, can be removed otherwise proxy-host: \"\" frontend-uri: \"http://localhost:7987\" server-type: \"oidc\" web-server: # protected paths on the web server paths: - path: \"/greet\" methods: [\"get\"] authenticate: true client-id must be the same as the one configure in keycloak. The client secret generate by Keycloak during Create a client section. identity-uri is used to redirect the user to keycloak. frontend-uri will direct you back to the application. paths section defines the protected application&#8217;s path. Make sure keycloak and the application are not running on the same port. The application port value can be changed into application.yaml. <markup lang=\"yaml\" title=\"Change these properties to configure the server host and port\" >server: port: 7987 host: localhost If the port 7987 is already used, check what port is free on your machine. <markup lang=\"yaml\" title=\"Replace the old port into application.yaml\" >server: port: \"{Your-new-port}\" ... frontend-uri: \"http://localhost:{Your-new-port}\" Configure Web Server Once the properties are added, the web server must be set up. The Main.createRouting method gather all configuration properties. <markup lang=\"java\" title=\"Add the following to Main.createRouting method\" >import io.helidon.security.Security; import io.helidon.security.integration.webserver.WebSecurity; import io.helidon.security.providers.oidc.OidcSupport; ... Security security = Security.create(config.get(\"security\")); return Routing.builder() .register(WebSecurity.create(security, config.get(\"security\"))) .register(OidcSupport.create(config)) ... Create the Helidon Security instance using configuration. Register Helidon WebSecurity instance using security instance and configuration. Register Helidon OidcSupport instance. That code is extracting security properties from application.yaml into two steps. First the Security instance is used to bootstrap security, so the WebSecurity instance can integrate security into Web Server. Then, OidcSupport instance registers the endpoint to which OIDC redirects browser after a successful login. Helidon sample is now set up and ready. ",
            "title": "What You Need"
        },
        {
            "location": "/se/guides/05_security_oidc",
            "text": " The Authorization Code flow is suitable for browser-based applications. It is composed of three main steps: The browser visits the application. The user is not logged in, so it redirects the browser to Keycloak which requires username and password for authentication. Keycloak authenticates the user and returns a temporary authorization code as a query parameter in the URL. The authorization code is used to get access and refresh token from Keycloak token endpoint. For the first step, paste the following URL into your browser: http://localhost:8080/auth/realms/myRealm/protocol/openid-connect/auth?client_id=myClientID&amp;response_type=code . The first part of the url http:/../auth is the Keycloak endpoint to request an authorization code. Two query parameters are provided, the client id and the response type. Press enter and Keycloak responds with different URL containing a query parameter code . You successfully received the authorization code. In order to achieve the third step, we can use Postman to exchange the authorization code for tokens. In Postman, select the Http POST method. Keycloak endpoint to get token is the following: http://localhost:8080/auth/realms/myRealm/protocol/openid-connect/token . In the body of the request, select x-www-form-urlencoded type. Add the following data: <markup lang=\"json\" title=\"Enter the key:value\" >[{\"key\":\"grant_type\",\"value\":\"authorization_code\"}, {\"key\":\"client_id\",\"value\":\"myClientID\"}, {\"key\":\"client_secret\",\"value\":\"client secret\"}, {\"key\":\"code\",\"value\":\"authorization code\"}] Do not forget to replace the client secret by its value (generated during Create a Client), and authorization code by the code value in the query parameter. Send the request by pressing Send . Keycloak returns an access token and a refresh token. ",
            "title": "Authorization Code Flow"
        },
        {
            "location": "/se/guides/05_security_oidc",
            "text": " The Direct Access Grants flow is used by REST clients that want to request tokens on behalf of a user. To use Postman to make this request on behalf of myuser , select the GET method and enter this URL: http://localhost:7987/greet/ . Under Authorization tab, select authorization type`OAuth 2.0`. Under it, complete the sentence Add authorization data to with Request Headers , and complete the required fields. <markup lang=\"json\" title=\"Enter the following information:\" >[{\"key\":\"Header Prefix\",\"value\":\"bearer\"}, {\"key\":\"Grant type\",\"value\":\"Password Credentials\"}, {\"key\":\"Access Token URL\",\"value\":\"http://localhost:8080/auth/realms/myRealm/protocol/openid-connect/token\"}, {\"key\":\"Client ID\",\"value\":\"myClientID\"}, {\"key\":\"Client Secret\",\"value\":\"client secret\"}, {\"key\":\"Username\",\"value\":\"myuser\"}, {\"key\":\"Password\",\"value\":\"password\"}, {\"key\":\"Scope\",\"value\":\"openid\"}, {\"key\":\"Client Authentication\",\"value\":\"Send as Basic Auth Header\"}] Again, make sure to replace client secret by the actual client secret. Click on Get New Access Token . A popup window appears with Authentication complete, click on proceed to display access, refresh and identity token. Copy and paste the access token to Access Token field and press Send . Helidon greeting application sends back Hello World ! . ",
            "title": "Resource Owner Password Credentials Grant (Direct Access Grants)"
        },
        {
            "location": "/se/guides/05_security_oidc",
            "text": " At this stage of the application, tests cannot pass because of OIDC security. The only way to authenticate a user is through the front end of that server which can be accessed with the browser for example. In order to keep security and test the application locally, a new security provider must be set up. By adding specific configuration to the tests, it is possible to override the application configuration. The following explains how to set a basic authentication instead of oidc security provider only for the tests. Which means, at the end of this guide, the application will be secured by oidc security provider, and the tests will use basic authentication. <markup lang=\"xml\" title=\"Add the following dependency to pom.xml :\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-http-auth&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; In the test folder helidon-quickstart-se/src/test : <markup lang=\"bash\" title=\"Create a new directory and another one inside\" >mkdir resources cd resources touch application.yaml Open the application.yaml file <markup lang=\"yaml\" title=\"Copy these properties into application.yaml\" >app: greeting: \"Hello\" server: port: 7987 host: localhost security: providers: - abac: # Adds ABAC Provider - it does not require any configuration - http-basic-auth: users: - login: \"jack\" password: \"jackIsGreat\" - oidc: client-id: \"Your client ID\" client-secret: \"Your client secret\" identity-uri: \"http://localhost:8080/auth/realms/myRealm\" audience: \"account\" frontend-uri: \"http://localhost:7987\" server-type: \"oidc\" web-server: # protected paths on the web server - do not include paths served by Jersey, as those are protected directly paths: - path: \"/greet\" methods: [\"get\"] authenticate: true Replace this field by your Keycloak client ID. Replace this field by your Keycloak client Password. Add the http-basic-auth properties in the security &#8594; providers property section. This configuration will be used by the tests instead of the java/resources/application.yaml . In the MainTest.java file, tests need to be modified to check the application security when accessing /greet path with a GET method. <markup lang=\"java\" title=\"Import the following class:\" >import java.util.Base64; import io.helidon.common.http.Http; <markup lang=\"java\" title=\"Replace the first webclient call by this one into testHelloWorld method:\" >webClient.get() .path(\"/greet\") .request() .thenAccept(response -&gt; Assertions.assertEquals(401,response.status().code())) .toCompletableFuture() .get(); This piece of code uses the webclient to access the application on /greet path with a GET method. The http basic authentication security protects this path, so the client should receive an HTTP 401 code for unauthorized. Only jack user has access to this part of the application. <markup lang=\"java\" title=\"Add new check to the testHelloWorld method:\" >webClient.get() .path(\"/greet\") .headers(headers -&gt; { String encoding = Base64.getEncoder().encodeToString(\"jack:jackIsGreat\".getBytes()); headers.add(Http.Header.AUTHORIZATION, \"Basic \" + encoding); return headers; }) .request(JsonObject.class) .thenAccept(jsonObject -&gt; Assertions.assertEquals(\"Hello World!\", jsonObject.getString(\"message\"))) .toCompletableFuture() .get(); The username and password are encoded and placed inside the header in order to authenticate as jack to access the application. If the authentication is successful, the application send the Hello World back as a JsonObject . Now, the project can be build without skipping test. <markup lang=\"bash\" title=\"Build the project\" >mvn clean install ",
            "title": "Update Tests to the Secure Environment"
        },
        {
            "location": "/se/guides/05_security_oidc",
            "text": " To give less access to an endpoint, it is possible to configure user role. So the application will only grant access to the user with the required role. Add a user and roles to the helidon-quickstart-se/src/test/resources/application.yaml . <markup lang=\"yaml\" title=\"Add jack role and create a new user named john:\" >- http-basic-auth: users: - login: \"jack\" password: \"jackIsGreat\" roles: [ \"admin\", \"user\" ] - login: \"john\" password: \"johnPassword\" roles: [ \"user\" ] Into the web-server section, the roles-allowed parameter defines which roles have access to the protected path and method. <markup lang=\"yaml\" title=\"Add admin role\" >web-server: # protected paths on the web server - do not include paths served by Jersey, as those are protected directly paths: - path: \"/greet\" methods: [\"get\"] roles-allowed: \"admin\" authenticate: true Now, only Jack has access to secure endpoint as he has an admin role. Jhon, as a simple user, can not access it. Once it is done, go to the tests to check the application behavior. The test from previous section is still passing as jack has access. The user john has only the user role so when accessing protected endpoint, a 403 (Forbidden) http code is returned. <markup lang=\"java\" title=\"Check that john does not have access\" >webClient.get() .path(\"/greet\") .headers(headers -&gt; { String encoding = Base64.getEncoder().encodeToString(\"john:johnPassword\".getBytes()); headers.add(Http.Header.AUTHORIZATION,\"Basic \" + encoding); return headers; }) .request() .thenAccept(response -&gt; Assertions.assertEquals(403, response.status().code())) .toCompletableFuture() .get(); <markup lang=\"bash\" title=\"Build the project\" >mvn clean install The tests pass, and your application is secured with specific roles in addition to user IDs. ",
            "title": "Restrict Access to a Specific Role"
        },
        {
            "location": "/se/guides/05_security_oidc",
            "text": " Keycloak supports many authentication and authorization flows, but only two of them will be shown. This section describes another way you can get an access token or refresh a token or identity token. The identity token contains information about the user. The access token contains access information that the application can use to determine what resources the user is allowed to access. Once expired, the refresh token allows the application to obtain a new access token. As these tokens contain sensitive information, they are valid for a very short period. It is possible to make them last longer in order to let you manipulate them with Postman. To do so: Open the Postman Console. Click on the Realm Setting in the left menu. Navigate to the Tokens tab. You can increase the access token lifespan. Authorization Code Flow The Authorization Code flow is suitable for browser-based applications. It is composed of three main steps: The browser visits the application. The user is not logged in, so it redirects the browser to Keycloak which requires username and password for authentication. Keycloak authenticates the user and returns a temporary authorization code as a query parameter in the URL. The authorization code is used to get access and refresh token from Keycloak token endpoint. For the first step, paste the following URL into your browser: http://localhost:8080/auth/realms/myRealm/protocol/openid-connect/auth?client_id=myClientID&amp;response_type=code . The first part of the url http:/../auth is the Keycloak endpoint to request an authorization code. Two query parameters are provided, the client id and the response type. Press enter and Keycloak responds with different URL containing a query parameter code . You successfully received the authorization code. In order to achieve the third step, we can use Postman to exchange the authorization code for tokens. In Postman, select the Http POST method. Keycloak endpoint to get token is the following: http://localhost:8080/auth/realms/myRealm/protocol/openid-connect/token . In the body of the request, select x-www-form-urlencoded type. Add the following data: <markup lang=\"json\" title=\"Enter the key:value\" >[{\"key\":\"grant_type\",\"value\":\"authorization_code\"}, {\"key\":\"client_id\",\"value\":\"myClientID\"}, {\"key\":\"client_secret\",\"value\":\"client secret\"}, {\"key\":\"code\",\"value\":\"authorization code\"}] Do not forget to replace the client secret by its value (generated during Create a Client), and authorization code by the code value in the query parameter. Send the request by pressing Send . Keycloak returns an access token and a refresh token. Resource Owner Password Credentials Grant (Direct Access Grants) The Direct Access Grants flow is used by REST clients that want to request tokens on behalf of a user. To use Postman to make this request on behalf of myuser , select the GET method and enter this URL: http://localhost:7987/greet/ . Under Authorization tab, select authorization type`OAuth 2.0`. Under it, complete the sentence Add authorization data to with Request Headers , and complete the required fields. <markup lang=\"json\" title=\"Enter the following information:\" >[{\"key\":\"Header Prefix\",\"value\":\"bearer\"}, {\"key\":\"Grant type\",\"value\":\"Password Credentials\"}, {\"key\":\"Access Token URL\",\"value\":\"http://localhost:8080/auth/realms/myRealm/protocol/openid-connect/token\"}, {\"key\":\"Client ID\",\"value\":\"myClientID\"}, {\"key\":\"Client Secret\",\"value\":\"client secret\"}, {\"key\":\"Username\",\"value\":\"myuser\"}, {\"key\":\"Password\",\"value\":\"password\"}, {\"key\":\"Scope\",\"value\":\"openid\"}, {\"key\":\"Client Authentication\",\"value\":\"Send as Basic Auth Header\"}] Again, make sure to replace client secret by the actual client secret. Click on Get New Access Token . A popup window appears with Authentication complete, click on proceed to display access, refresh and identity token. Copy and paste the access token to Access Token field and press Send . Helidon greeting application sends back Hello World ! . Update Tests to the Secure Environment At this stage of the application, tests cannot pass because of OIDC security. The only way to authenticate a user is through the front end of that server which can be accessed with the browser for example. In order to keep security and test the application locally, a new security provider must be set up. By adding specific configuration to the tests, it is possible to override the application configuration. The following explains how to set a basic authentication instead of oidc security provider only for the tests. Which means, at the end of this guide, the application will be secured by oidc security provider, and the tests will use basic authentication. <markup lang=\"xml\" title=\"Add the following dependency to pom.xml :\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-http-auth&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; In the test folder helidon-quickstart-se/src/test : <markup lang=\"bash\" title=\"Create a new directory and another one inside\" >mkdir resources cd resources touch application.yaml Open the application.yaml file <markup lang=\"yaml\" title=\"Copy these properties into application.yaml\" >app: greeting: \"Hello\" server: port: 7987 host: localhost security: providers: - abac: # Adds ABAC Provider - it does not require any configuration - http-basic-auth: users: - login: \"jack\" password: \"jackIsGreat\" - oidc: client-id: \"Your client ID\" client-secret: \"Your client secret\" identity-uri: \"http://localhost:8080/auth/realms/myRealm\" audience: \"account\" frontend-uri: \"http://localhost:7987\" server-type: \"oidc\" web-server: # protected paths on the web server - do not include paths served by Jersey, as those are protected directly paths: - path: \"/greet\" methods: [\"get\"] authenticate: true Replace this field by your Keycloak client ID. Replace this field by your Keycloak client Password. Add the http-basic-auth properties in the security &#8594; providers property section. This configuration will be used by the tests instead of the java/resources/application.yaml . In the MainTest.java file, tests need to be modified to check the application security when accessing /greet path with a GET method. <markup lang=\"java\" title=\"Import the following class:\" >import java.util.Base64; import io.helidon.common.http.Http; <markup lang=\"java\" title=\"Replace the first webclient call by this one into testHelloWorld method:\" >webClient.get() .path(\"/greet\") .request() .thenAccept(response -&gt; Assertions.assertEquals(401,response.status().code())) .toCompletableFuture() .get(); This piece of code uses the webclient to access the application on /greet path with a GET method. The http basic authentication security protects this path, so the client should receive an HTTP 401 code for unauthorized. Only jack user has access to this part of the application. <markup lang=\"java\" title=\"Add new check to the testHelloWorld method:\" >webClient.get() .path(\"/greet\") .headers(headers -&gt; { String encoding = Base64.getEncoder().encodeToString(\"jack:jackIsGreat\".getBytes()); headers.add(Http.Header.AUTHORIZATION, \"Basic \" + encoding); return headers; }) .request(JsonObject.class) .thenAccept(jsonObject -&gt; Assertions.assertEquals(\"Hello World!\", jsonObject.getString(\"message\"))) .toCompletableFuture() .get(); The username and password are encoded and placed inside the header in order to authenticate as jack to access the application. If the authentication is successful, the application send the Hello World back as a JsonObject . Now, the project can be build without skipping test. <markup lang=\"bash\" title=\"Build the project\" >mvn clean install Restrict Access to a Specific Role To give less access to an endpoint, it is possible to configure user role. So the application will only grant access to the user with the required role. Add a user and roles to the helidon-quickstart-se/src/test/resources/application.yaml . <markup lang=\"yaml\" title=\"Add jack role and create a new user named john:\" >- http-basic-auth: users: - login: \"jack\" password: \"jackIsGreat\" roles: [ \"admin\", \"user\" ] - login: \"john\" password: \"johnPassword\" roles: [ \"user\" ] Into the web-server section, the roles-allowed parameter defines which roles have access to the protected path and method. <markup lang=\"yaml\" title=\"Add admin role\" >web-server: # protected paths on the web server - do not include paths served by Jersey, as those are protected directly paths: - path: \"/greet\" methods: [\"get\"] roles-allowed: \"admin\" authenticate: true Now, only Jack has access to secure endpoint as he has an admin role. Jhon, as a simple user, can not access it. Once it is done, go to the tests to check the application behavior. The test from previous section is still passing as jack has access. The user john has only the user role so when accessing protected endpoint, a 403 (Forbidden) http code is returned. <markup lang=\"java\" title=\"Check that john does not have access\" >webClient.get() .path(\"/greet\") .headers(headers -&gt; { String encoding = Base64.getEncoder().encodeToString(\"john:johnPassword\".getBytes()); headers.add(Http.Header.AUTHORIZATION,\"Basic \" + encoding); return headers; }) .request() .thenAccept(response -&gt; Assertions.assertEquals(403, response.status().code())) .toCompletableFuture() .get(); <markup lang=\"bash\" title=\"Build the project\" >mvn clean install The tests pass, and your application is secured with specific roles in addition to user IDs. ",
            "title": "Test Keycloak Process with Postman"
        },
        {
            "location": "/se/guides/05_security_oidc",
            "text": "<markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-se.jar The tests must be skipped, otherwise it produces test failure. As the /greet endpoint for GET request is now protected, its access is limited, and the tests are not built to take oidc security in account. Open your favourite browser and try to access http://localhost:7987/greet/Michael . You should not be redirected and receive greeting from the application. Enter the following into URL : http://localhost:7987/greet . Keycloak redirect you to its login page. Enter the username and associated password: Username : myUser Password : password After successful log in, keycloak redirect you to the http://localhost:7987/greet endpoint and print Hello word. Press Ctrl+C to stop the application. From the actual settings, the user needs to log in only once, then Keycloak saves all the connection data. Test Keycloak Process with Postman Keycloak supports many authentication and authorization flows, but only two of them will be shown. This section describes another way you can get an access token or refresh a token or identity token. The identity token contains information about the user. The access token contains access information that the application can use to determine what resources the user is allowed to access. Once expired, the refresh token allows the application to obtain a new access token. As these tokens contain sensitive information, they are valid for a very short period. It is possible to make them last longer in order to let you manipulate them with Postman. To do so: Open the Postman Console. Click on the Realm Setting in the left menu. Navigate to the Tokens tab. You can increase the access token lifespan. Authorization Code Flow The Authorization Code flow is suitable for browser-based applications. It is composed of three main steps: The browser visits the application. The user is not logged in, so it redirects the browser to Keycloak which requires username and password for authentication. Keycloak authenticates the user and returns a temporary authorization code as a query parameter in the URL. The authorization code is used to get access and refresh token from Keycloak token endpoint. For the first step, paste the following URL into your browser: http://localhost:8080/auth/realms/myRealm/protocol/openid-connect/auth?client_id=myClientID&amp;response_type=code . The first part of the url http:/../auth is the Keycloak endpoint to request an authorization code. Two query parameters are provided, the client id and the response type. Press enter and Keycloak responds with different URL containing a query parameter code . You successfully received the authorization code. In order to achieve the third step, we can use Postman to exchange the authorization code for tokens. In Postman, select the Http POST method. Keycloak endpoint to get token is the following: http://localhost:8080/auth/realms/myRealm/protocol/openid-connect/token . In the body of the request, select x-www-form-urlencoded type. Add the following data: <markup lang=\"json\" title=\"Enter the key:value\" >[{\"key\":\"grant_type\",\"value\":\"authorization_code\"}, {\"key\":\"client_id\",\"value\":\"myClientID\"}, {\"key\":\"client_secret\",\"value\":\"client secret\"}, {\"key\":\"code\",\"value\":\"authorization code\"}] Do not forget to replace the client secret by its value (generated during Create a Client), and authorization code by the code value in the query parameter. Send the request by pressing Send . Keycloak returns an access token and a refresh token. Resource Owner Password Credentials Grant (Direct Access Grants) The Direct Access Grants flow is used by REST clients that want to request tokens on behalf of a user. To use Postman to make this request on behalf of myuser , select the GET method and enter this URL: http://localhost:7987/greet/ . Under Authorization tab, select authorization type`OAuth 2.0`. Under it, complete the sentence Add authorization data to with Request Headers , and complete the required fields. <markup lang=\"json\" title=\"Enter the following information:\" >[{\"key\":\"Header Prefix\",\"value\":\"bearer\"}, {\"key\":\"Grant type\",\"value\":\"Password Credentials\"}, {\"key\":\"Access Token URL\",\"value\":\"http://localhost:8080/auth/realms/myRealm/protocol/openid-connect/token\"}, {\"key\":\"Client ID\",\"value\":\"myClientID\"}, {\"key\":\"Client Secret\",\"value\":\"client secret\"}, {\"key\":\"Username\",\"value\":\"myuser\"}, {\"key\":\"Password\",\"value\":\"password\"}, {\"key\":\"Scope\",\"value\":\"openid\"}, {\"key\":\"Client Authentication\",\"value\":\"Send as Basic Auth Header\"}] Again, make sure to replace client secret by the actual client secret. Click on Get New Access Token . A popup window appears with Authentication complete, click on proceed to display access, refresh and identity token. Copy and paste the access token to Access Token field and press Send . Helidon greeting application sends back Hello World ! . Update Tests to the Secure Environment At this stage of the application, tests cannot pass because of OIDC security. The only way to authenticate a user is through the front end of that server which can be accessed with the browser for example. In order to keep security and test the application locally, a new security provider must be set up. By adding specific configuration to the tests, it is possible to override the application configuration. The following explains how to set a basic authentication instead of oidc security provider only for the tests. Which means, at the end of this guide, the application will be secured by oidc security provider, and the tests will use basic authentication. <markup lang=\"xml\" title=\"Add the following dependency to pom.xml :\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-http-auth&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; In the test folder helidon-quickstart-se/src/test : <markup lang=\"bash\" title=\"Create a new directory and another one inside\" >mkdir resources cd resources touch application.yaml Open the application.yaml file <markup lang=\"yaml\" title=\"Copy these properties into application.yaml\" >app: greeting: \"Hello\" server: port: 7987 host: localhost security: providers: - abac: # Adds ABAC Provider - it does not require any configuration - http-basic-auth: users: - login: \"jack\" password: \"jackIsGreat\" - oidc: client-id: \"Your client ID\" client-secret: \"Your client secret\" identity-uri: \"http://localhost:8080/auth/realms/myRealm\" audience: \"account\" frontend-uri: \"http://localhost:7987\" server-type: \"oidc\" web-server: # protected paths on the web server - do not include paths served by Jersey, as those are protected directly paths: - path: \"/greet\" methods: [\"get\"] authenticate: true Replace this field by your Keycloak client ID. Replace this field by your Keycloak client Password. Add the http-basic-auth properties in the security &#8594; providers property section. This configuration will be used by the tests instead of the java/resources/application.yaml . In the MainTest.java file, tests need to be modified to check the application security when accessing /greet path with a GET method. <markup lang=\"java\" title=\"Import the following class:\" >import java.util.Base64; import io.helidon.common.http.Http; <markup lang=\"java\" title=\"Replace the first webclient call by this one into testHelloWorld method:\" >webClient.get() .path(\"/greet\") .request() .thenAccept(response -&gt; Assertions.assertEquals(401,response.status().code())) .toCompletableFuture() .get(); This piece of code uses the webclient to access the application on /greet path with a GET method. The http basic authentication security protects this path, so the client should receive an HTTP 401 code for unauthorized. Only jack user has access to this part of the application. <markup lang=\"java\" title=\"Add new check to the testHelloWorld method:\" >webClient.get() .path(\"/greet\") .headers(headers -&gt; { String encoding = Base64.getEncoder().encodeToString(\"jack:jackIsGreat\".getBytes()); headers.add(Http.Header.AUTHORIZATION, \"Basic \" + encoding); return headers; }) .request(JsonObject.class) .thenAccept(jsonObject -&gt; Assertions.assertEquals(\"Hello World!\", jsonObject.getString(\"message\"))) .toCompletableFuture() .get(); The username and password are encoded and placed inside the header in order to authenticate as jack to access the application. If the authentication is successful, the application send the Hello World back as a JsonObject . Now, the project can be build without skipping test. <markup lang=\"bash\" title=\"Build the project\" >mvn clean install Restrict Access to a Specific Role To give less access to an endpoint, it is possible to configure user role. So the application will only grant access to the user with the required role. Add a user and roles to the helidon-quickstart-se/src/test/resources/application.yaml . <markup lang=\"yaml\" title=\"Add jack role and create a new user named john:\" >- http-basic-auth: users: - login: \"jack\" password: \"jackIsGreat\" roles: [ \"admin\", \"user\" ] - login: \"john\" password: \"johnPassword\" roles: [ \"user\" ] Into the web-server section, the roles-allowed parameter defines which roles have access to the protected path and method. <markup lang=\"yaml\" title=\"Add admin role\" >web-server: # protected paths on the web server - do not include paths served by Jersey, as those are protected directly paths: - path: \"/greet\" methods: [\"get\"] roles-allowed: \"admin\" authenticate: true Now, only Jack has access to secure endpoint as he has an admin role. Jhon, as a simple user, can not access it. Once it is done, go to the tests to check the application behavior. The test from previous section is still passing as jack has access. The user john has only the user role so when accessing protected endpoint, a 403 (Forbidden) http code is returned. <markup lang=\"java\" title=\"Check that john does not have access\" >webClient.get() .path(\"/greet\") .headers(headers -&gt; { String encoding = Base64.getEncoder().encodeToString(\"john:johnPassword\".getBytes()); headers.add(Http.Header.AUTHORIZATION,\"Basic \" + encoding); return headers; }) .request() .thenAccept(response -&gt; Assertions.assertEquals(403, response.status().code())) .toCompletableFuture() .get(); <markup lang=\"bash\" title=\"Build the project\" >mvn clean install The tests pass, and your application is secured with specific roles in addition to user IDs. ",
            "title": "Build the Application"
        },
        {
            "location": "/community/01_community",
            "text": " Helidon is a Java open source project under the Apache License version 2.0 . We encourage community contributions whether it&#8217;s participating in discussions, creating issues, or submitting pull requests. ",
            "title": "Open Source"
        },
        {
            "location": "/community/01_community",
            "text": " Have a question? Ask them in in Slack at #helidon-user Or on Stack Overflow using the helidon tag Read the Helidon FAQ ",
            "title": "Get Answers"
        },
        {
            "location": "/community/01_community",
            "text": " Helidon source is hosted on GitHub . If you&#8217;d like to report a bug, enhancement request, or check if an issue is on our list, visit the Helidon GitHub issue tracker . ",
            "title": "Code and Issues"
        },
        {
            "location": "/community/01_community",
            "text": " Follow us on Twitter @helidon_project Read the Helidon blog . ",
            "title": "Stay Informed"
        },
        {
            "location": "/about/05_kubernetes",
            "text": " For development it&#8217;s often convenient to run Kubernetes on your desktop. Two popular ways to do this are with Kubernetes Minikube or Kubernetes support in Docker for Desktop . In this guide we&#8217;ll use Docker for Desktop. ",
            "title": "preambule"
        },
        {
            "location": "/about/05_kubernetes",
            "text": " Install Docker for Mac or Docker for Windows . Starting with version 18.06 Docker for Desktop includes Kubernetes support. ",
            "title": "Install"
        },
        {
            "location": "/about/05_kubernetes",
            "text": " Enable Kubernetes Support for Mac or Kubernetes Support for Windows . Once Kubernetes installation is complete, make sure you have your context set correctly to use docker-for-desktop. <markup lang=\"bash\" title=\"Make sure K8s context is set to docker-for-desktop\" >kubectl config get-contexts kubectl config use-context docker-for-desktop kubectl cluster-info kubectl version --short kubectl get nodes ",
            "title": "Enable Kubernetes Support"
        },
        {
            "location": "/mp/guides/10_mp-tutorial",
            "text": " This tutorial describes how to build a Helidon MicroProfile (MP) application from scratch including JSON REST endpoints, metrics, health check, and configuration. ",
            "title": "preambule"
        },
        {
            "location": "/mp/guides/10_mp-tutorial",
            "text": " For this 30 minute tutrial, you will need the following: <div class=\"table__overflow elevation-1 flex sm7 \"> A Helidon {upper-case-flavor} Application You can use your own application or use the Helidon {upper-case-flavor} Quickstart to create a sample application. Java&#160;SE&#160;11 ( Open&#160;JDK&#160;11 ) Helidon requires Java 11+. Maven 3.6.1+ Helidon requires Maven 3.6.1+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop ). curl (Optional) for testing <markup lang=\"bash\" title=\"Verify Prerequisites\" >java -version mvn --version docker --version kubectl version --short <markup lang=\"bash\" title=\"Setting JAVA_HOME\" ># On Mac export JAVA_HOME=`/usr/libexec/java_home -v 11` # On Linux # Use the appropriate path to your JDK export JAVA_HOME=/usr/lib/jvm/jdk-11 ",
            "title": "What You Need"
        },
        {
            "location": "/mp/guides/10_mp-tutorial",
            "text": " This tutorial demonstrates how to create the application from scratch, without using the Maven archetypes as a quickstart. Create a new empty directory for the project (for example, helidon-mp-tutorial ). Change into this directory. Create a new Maven POM file (called pom.xml ) and add the following content: <markup lang=\"xml\" title=\"Initial Maven POM file\" >&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;io.helidon.applications&lt;/groupId&gt; &lt;artifactId&gt;helidon-mp&lt;/artifactId&gt; &lt;version&gt;2.5.4&lt;/version&gt; &lt;relativePath/&gt; &lt;/parent&gt; &lt;groupId&gt;io.helidon.examples&lt;/groupId&gt; &lt;artifactId&gt;helidon-mp-tutorial&lt;/artifactId&gt; &lt;name&gt;${project.artifactId}&lt;/name&gt; &lt;properties&gt; &lt;mainClass&gt;io.helidon.examples.Main&lt;/mainClass&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.bundles&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-dependency-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;copy-libs&lt;/id&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.jboss.jandex&lt;/groupId&gt; &lt;artifactId&gt;jandex-maven-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;make-index&lt;/id&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/project&gt; The POM file contains the basic project information and configurations needed to get started and does the following: Includes the Helidon MP application parent pom. This parent pom contains dependency and plugin management to keep your application&#8217;s pom simple and clean. Establishes the Maven coordinates for the new project. Sets the mainClass which will be used later when building a JAR file. The class will be created later in this tutorial. Adds a dependency for the MicroProfile bundle which allows the use of MicroProfile features in the application. The helidon-mp parent pom includes dependency management, so you don&#8217;t need to include a version number here. You will automatically use the version of Helidon that matches the version of the parent pom ({helidon.version} in this case). Adds plugins to be executed during the build. The maven-dependency-plugin is used to copy the runtime dependencies into your target directory. The jandex-maven-plugin builds an index of your class files for faster loading. The Helidon parent pom handles the details of configuring these plugins. But you can modify the configuration here. MicroProfile contains features like Metrics, Health Check, Streams Operators, Open Tracing, OpenAPI, REST client, and fault tolerance. You can find detailed information about MicroProfile on the Eclipse MicroProfile site. With this pom.xml , the application can be built successfully with Maven: <markup lang=\"bash\" >mvn clean package This will create a JAR file in the target directory. The warning message JAR will be empty - no content was marked for inclusion! can be ignored for now because there is no actual content in the application yet. ",
            "title": "Create the Maven Project"
        },
        {
            "location": "/mp/guides/10_mp-tutorial",
            "text": " The actual application logic can be created now. Create a directory for your source code, and then create directories for the package hierarchy: <markup lang=\"bash\" title=\"Create directories for source code\" >mkdir -p src/main/java/io/helidon/examples The application will be a simple REST service that will return a greeting to the caller. The first iteration of the application will contain a resource class and a Main class which will be used to start up the Helidon server and the application. Technically, your own main class is not needed unless you want to control the startup sequence. You can set the mainClass property to io.helidon.microprofile.cdi.Main and it will use Helidon&#8217;s default main class. The GreetResource is defined in the GreetResource.java class as shown below: <markup lang=\"java\" title=\"src/main/java/io/helidon/examples/GreetResource.java\" >package io.helidon.examples; import javax.enterprise.context.RequestScoped; import javax.json.Json; import javax.json.JsonBuilderFactory; import javax.json.JsonObject; import javax.ws.rs.GET; import javax.ws.rs.Path; import javax.ws.rs.Produces; import javax.ws.rs.core.MediaType; import java.util.Collections; @Path(\"/greet\") @RequestScoped public class GreetResource { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) public JsonObject getDefaultMessage() { return JSON.createObjectBuilder() .add(\"message\", \"Hello World\") .build(); } } This class is annotated with Path which sets the path for this resource as /greet . The RequestScoped annotation defines that this bean is request scoped. The request scope is active only for the duration of one web service invocation and it is destroyed at the end of that invocation. You can learn more about scopes and contexts, and how they are used from the Specification . A public JsonObject getDefaultMessage() method is defined which is annotated with GET , meaning it will accept the HTTP GET method. It is also annotated with Produces(MediaType.APPLICATION_JSON) which declares that this method will return JSON data. The method body creates a JSON object containing a single object named \"message\" with the content \"Hello World\". This method will be expanded and improved later in the tutorial. So far this is just a JAX-RS application, with no Helidon or MicroProfile specific code in it. There are many JAX-RS tutorials available if you want to learn more about this kind of application. A main class is also required to start up the server and run the application. If you don&#8217;t use Helidon&#8217;s built-in main class you can define your own: <markup lang=\"java\" title=\"src/main/java/io/helidon/examples/Main.java\" >package io.helidon.examples; import io.helidon.microprofile.server.Server; import java.io.IOException; public final class Main { private Main() { } public static void main(final String[] args) throws IOException { Server server = startServer(); System.out.println(\"http://localhost:\" + server.port() + \"/greet\"); } static Server startServer() { return Server.create().start(); } } In this class, a main method is defined which starts the Helidon MP server and prints out a message with the listen address. Notice that this class has an empty no-args constructor to make sure this class cannot be instantiated. The MicroProfile server is started with the default configuration. Helidon MP applications also require a beans.xml resource file to tell Helidon to use the annotations discussed above to discover Java beans in the application. Create a beans.xml in the src/main/resources/META-INF directory with the following content: <markup lang=\"xml\" title=\"src/main/resources/META-INF/beans.xml\" >&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;beans xmlns=\"http://xmlns.jcp.org/xml/ns/javaee\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/beans_2_0.xsd\" version=\"2.0\" bean-discovery-mode=\"annotated\"&gt; &lt;/beans&gt; The bean-discovery-mode tells Helidon to look for the annotations to discover Java beans in the application. ",
            "title": "Start Implementing the MicroProfile Application"
        },
        {
            "location": "/mp/guides/10_mp-tutorial",
            "text": " Helidon MP applications are packaged into a JAR file and the dependencies are copied into a libs directory. You can now build the application. <markup lang=\"bash\" title=\"Build the Application\" >mvn package This will build the application jar and save all runtime dependencies in the target/libs directory. This means you can easily start the application by running the application jar file: <markup lang=\"bash\" title=\"Run the application\" >java -jar target/helidon-mp-tutorial.jar At this stage, the application is a very simple \"Hello World\" greeting service. It supports a single GET request for generating a greeting message. The response is encoded using JSON. For example: <markup lang=\"bash\" title=\"Try the Application\" >curl -X GET http://localhost:7001/greet {\"message\":\"Hello World!\"} In the output you can see the JSON output from the getDefaultMessage() method that was discussed earlier. The server has used a default port 7001 . The application can be stopped cleanly by pressing Ctrl+C. ",
            "title": "Build the Application"
        },
        {
            "location": "/mp/guides/10_mp-tutorial",
            "text": " Helidon MP applications can use the META-INF/microprofile-config.properties file to specify configuration data. This file (resource) is read by default if it is present on the classpath. Create this file in src/main/resources/META-INF with the following content: <markup lang=\"bash\" title=\"Initial microprofile-config.properties\" ># Microprofile server properties server.port=8080 server.host=0.0.0.0 Rebuild the application and run it again. Notice that it now uses port 8080 as specified in the configuration file. You can learn more about options for configuring the Helidon Server on the Configuring the Server page. In addition to predefined server properties, application-specific configuration information can be added to this file. Add the app.greeting property to the file as shown below. This property will be used to set the content of greeting message. <markup lang=\"bash\" title=\"Updated META-INF/microprofile-config.properties\" ># Microprofile server properties server.port=8080 server.host=0.0.0.0 # Application properties app.greeting=Hello Add a new \"provider\" class to read this property and make it available to the application. The class will be called GreetingProvider.java and have the following content: <markup lang=\"java\" title=\"src/main/java/io/helidon/examples/GreetingProvider.java\" >package io.helidon.examples; import org.eclipse.microprofile.config.inject.ConfigProperty; import javax.enterprise.context.ApplicationScoped; import javax.inject.Inject; import java.util.concurrent.atomic.AtomicReference; @ApplicationScoped public class GreetingProvider { private final AtomicReference&lt;String&gt; message = new AtomicReference&lt;&gt;(); @Inject public GreetingProvider(@ConfigProperty(name = \"app.greeting\") String message) { this.message.set(message); } String getMessage() { return message.get(); } void setMessage(String message) { this.message.set(message); } } This class also has the ApplicationScoped annotation, so it will persist for the life of the application. The class contains an AtomicReference to a String where the greeting will be stored. The AtomicReference provides lock-free thread-safe access to the underlying String . The public GreetingProvider(&#8230;&#8203;) constructor is annotated with Inject which tells Helidon to use Contexts and Dependency Injection to provide the needed values. In this case, the String message is annotated with ConfigProperty(name = \"app.greeting\") so Helidon will inject the property from the configuration file with the key app.greeting . This method demonstrates how to read configuration information into the application. A getter and setter are also included in this class. The GreetResource must be updated to use this value instead of the hard coded response. Make the following updates to that class: <markup lang=\"java\" title=\"Updated GreetResource class\" >package io.helidon.examples; import javax.enterprise.context.RequestScoped; import javax.inject.Inject; import javax.json.Json; import javax.json.JsonBuilderFactory; import javax.json.JsonObject; import javax.ws.rs.GET; import javax.ws.rs.Path; import javax.ws.rs.Produces; import javax.ws.rs.core.MediaType; import java.util.Collections; @Path(\"/greet\") @RequestScoped public class GreetResource { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); private final GreetingProvider greetingProvider; @Inject public GreetResource(GreetingProvider greetingConfig) { this.greetingProvider = greetingConfig; } @GET @Produces(MediaType.APPLICATION_JSON) public JsonObject getDefaultMessage() { return createResponse(\"World\"); } private JsonObject createResponse(String who) { String msg = String.format(\"%s %s!\", greetingProvider.getMessage(), who); return JSON.createObjectBuilder() .add(\"message\", msg) .build(); } } This updated class adds a GreetingProvider and uses constructor injection to get the value from the configuration file. The logic to create the response message is refactored into a createResponse method and the getDefaultMessage() method is updated to use this new method. In createResponse() the message is obtained from the GreetingProvider which in turn got it from the configuration files. Rebuild and run the application. Notice that it now uses the greeting from the configuration file. Change the configuration file and restart the application, notice that it uses the changed value. To learn more about Helidon MP configuration please see the Config section of the documentation. ",
            "title": "Configuration"
        },
        {
            "location": "/mp/guides/10_mp-tutorial",
            "text": " In this section, the application will be extended to add a PUT resource method which will allow users to update the greeting and a second GET resource method which will accept a parameter. Here are the two new methods to add to GreetResource.java : <markup lang=\"java\" title=\"New methods for GreetResource.java\" >import javax.ws.rs.Consumes; import javax.ws.rs.PUT; import javax.ws.rs.PathParam; import javax.ws.rs.core.Response; // some lines omitted @Path(\"/{name}\") @GET @Produces(MediaType.APPLICATION_JSON) public JsonObject getMessage(@PathParam(\"name\") String name) { return createResponse(name); } @Path(\"/greeting\") @PUT @Consumes(MediaType.APPLICATION_JSON) @Produces(MediaType.APPLICATION_JSON) public Response updateGreeting(JsonObject jsonObject) { if (!jsonObject.containsKey(\"greeting\")) { JsonObject entity = JSON.createObjectBuilder() .add(\"error\", \"No greeting provided\") .build(); return Response.status(Response.Status.BAD_REQUEST).entity(entity).build(); } String newGreeting = jsonObject.getString(\"greeting\"); greetingProvider.setMessage(newGreeting); return Response.status(Response.Status.NO_CONTENT).build(); } The first of these two methods implements a new HTTP GET service that returns JSON and it has a path parameter. The Path annotation defines the next part of the path to be a parameter named name . In the method arguments the PathParam(\"name\") annotation on String name has the effect of passing the parameter from the URL into this method as name . The second method implements a new HTTP PUT service which produces and consumes JSON, note the Consumes and PUT annotations. It also defines a path of \"/greeting\". Notice that the method argument is a JsonObject . Inside the method body there is code to check for the expected JSON, extract the value and update the message in the GreetingProvider . Rebuild and run the application. Test the new services using curl commands similar to those shown below: <markup lang=\"bash\" title=\"Testing the new services\" >curl -X GET http://localhost:8080/greet {\"message\":\"Hello World!\"} curl -X GET http://localhost:8080/greet/Joe {\"message\":\"Hello Joe!\"} curl -X PUT -H \"Content-Type: application/json\" -d '{\"greeting\" : \"Hola\"}' http://localhost:8080/greet/greeting curl -X GET http://localhost:8080/greet/Jose {\"message\":\"Hola Jose!\"} Helidon MP provides many other features which can be added to the application. ",
            "title": "Extending the Application"
        },
        {
            "location": "/mp/guides/10_mp-tutorial",
            "text": " The application logging can be customized. The default logging provider is java.util.logging , however it is possible to use other providers. In this tutorial the default provider is used. Create a logging.properties file in src/main/resources with the following content: <markup lang=\"properties\" title=\"Example logging.properties file\" ># Send messages to the console handlers=io.helidon.common.HelidonConsoleHandler # HelidonConsoleHandler uses a SimpleFormatter subclass that replaces \"!thread!\" with the current thread java.util.logging.SimpleFormatter.format=%1$tY.%1$tm.%1$td %1$tH:%1$tM:%1$tS %4$s %3$s !thread!: %5$s%6$s%n # Global logging level. Can be overridden by specific loggers .level=INFO The Helidon console logging handler is configured. This handler writes to System.out , does not filter by level and uses a custom SimpleFormatter that supports thread names. The format string is set using the standard options to include the timestamp, thread name and message. The global logging level is set to INFO . The Helidon MicroProfile server will detect the new logging.properties file and configure the LogManager for you. Rebuild and run the application and notice the new logging format takes effect. <markup lang=\"bash\" title=\"Log output\" >// before Aug 22, 2019 11:10:11 AM io.helidon.webserver.NettyWebServer lambda$start$8 INFO: Channel '@default' started: [id: 0xd0afba31, L:/0:0:0:0:0:0:0:0:8080] Aug 22, 2019 11:10:11 AM io.helidon.microprofile.server.ServerImpl lambda$start$10 INFO: Server started on http://localhost:8080 (and all other host addresses) in 182 milliseconds. http://localhost:8080/greet // after 2019.08.22 11:24:42 INFO io.helidon.webserver.NettyWebServer Thread[main,5,main]: Version: 1.2.0 2019.08.22 11:24:42 INFO io.helidon.webserver.NettyWebServer Thread[nioEventLoopGroup-2-1,10,main]: Channel '@default' started: [id: 0x8f652dfe, L:/0:0:0:0:0:0:0:0:8080] 2019.08.22 11:24:42 INFO io.helidon.microprofile.server.ServerImpl Thread[nioEventLoopGroup-2-1,10,main]: Server started on http://localhost:8080 (and all other host addresses) in 237 milliseconds. http://localhost:8080/greet ",
            "title": "Logging"
        },
        {
            "location": "/mp/guides/10_mp-tutorial",
            "text": " Helidon provides built-in support for metrics endpoints. <markup lang=\"bash\" title=\"Metrics in Prometheus Format\" >curl -s -X GET http://localhost:8080/metrics <markup lang=\"bash\" title=\"Metrics in JSON Format\" >curl -H 'Accept: application/json' -X GET http://localhost:8080/metrics It is possible to disable metrics by adding properties to the microprofile-config.properties file, for example: <markup lang=\"bash\" title=\"Disable a metric\" >metrics.base.classloader.currentLoadedClass.count.enabled=false Call the metrics endpoint before adding this change to confirm that the metric is included, then add the property to disable the metric, rebuild and restart the application and check again: <markup lang=\"bash\" title=\"Checking metrics before and after disabling the metric\" ># before curl -s http://localhost:8080/metrics | grep classloader_current # TYPE base:classloader_current_loaded_class_count counter # HELP base:classloader_current_loaded_class_count Displays the number of classes that are currently loaded in the Java virtual machine. base:classloader_current_loaded_class_count 7936 # after curl -s http://localhost:8080/metrics | grep classloader_current # (no output) Helidon also support custom metrics. To add a new metric, annotate the JAX-RS resource with one of the metric annotations as shown in the example below: You can find details of the available annotations in the MicroProfile Metrics Specification . <markup lang=\"java\" title=\"Updated GreetResource.java with custom metrics\" >import org.eclipse.microprofile.metrics.annotation.Timed; // some lines omitted @GET @Produces(MediaType.APPLICATION_JSON) @Timed public JsonObject getDefaultMessage() { return createResponse(\"World\"); } The Timed annotation is added to the getDefaultMessage() method. Rebuild and run the application. Make some calls to the endpoint ( http://localhost:8080/greet ) so there will be some data to report. Then obtain the application metrics as follows: <markup lang=\"bash\" title=\"Checking the application metrics\" >curl -H \"Accept: application/json\" http://localhost:8080/metrics/application { \"io.helidon.examples.GreetResource.getDefaultMessage\": { \"count\": 2, \"meanRate\": 0.036565171873527716, \"oneMinRate\": 0.015991117074135343, \"fiveMinRate\": 0.0033057092356765017, \"fifteenMinRate\": 0.0011080303990206543, \"min\": 78658, \"max\": 1614077, \"mean\": 811843.8728029992, \"stddev\": 766932.8494434259, \"p50\": 78658, \"p75\": 1614077, \"p95\": 1614077, \"p98\": 1614077, \"p99\": 1614077, \"p999\": 1614077 } } Learn more about using Helidon and MicroProfile metrics in the Metrics Guide . ",
            "title": "Metrics"
        },
        {
            "location": "/mp/guides/10_mp-tutorial",
            "text": " Helidon provides built-in support for health check endpoints. Obtain the built-in health check using the following URL: <markup lang=\"bash\" title=\"Health check\" >curl -s -X GET http://localhost:8080/health { \"outcome\": \"UP\", \"status\": \"UP\", \"checks\": [ { \"name\": \"deadlock\", \"state\": \"UP\", \"status\": \"UP\" }, { \"name\": \"diskSpace\", \"state\": \"UP\", \"status\": \"UP\", \"data\": { \"free\": \"381.23 GB\", \"freeBytes\": 409340088320, \"percentFree\": \"43.39%\", \"total\": \"878.70 GB\", \"totalBytes\": 943491723264 } }, { \"name\": \"heapMemory\", \"state\": \"UP\", \"status\": \"UP\", \"data\": { \"free\": \"324.90 MB\", \"freeBytes\": 340682920, \"max\": \"3.46 GB\", \"maxBytes\": 3715629056, \"percentFree\": \"97.65%\", \"total\": \"408.00 MB\", \"totalBytes\": 427819008 } } ] } Endpoints for readiness and liveness checks are also provided by default. Obtain the default results using these URLs, which return the same result as the previous example.: <markup lang=\"bash\" title=\"Default readiness and liveness endpoints\" ># readiness curl -i -X GET http://localhost:8080/health/ready # liveness curl -i -X GET http://localhost:8080/health/live Helidon allows the addition of custom health checks to applications. Create a new class GreetHealthcheck.java with the following content: <markup lang=\"java\" title=\"src/main/java/io/helidon/examples/GreetHealthcheck.java\" >package io.helidon.examples; import javax.enterprise.context.ApplicationScoped; import javax.inject.Inject; import org.eclipse.microprofile.health.HealthCheck; import org.eclipse.microprofile.health.HealthCheckResponse; import org.eclipse.microprofile.health.Liveness; @Liveness @ApplicationScoped public class GreetHealthcheck implements HealthCheck { private GreetingProvider provider; @Inject public GreetHealthcheck(GreetingProvider provider) { this.provider = provider; } @Override public HealthCheckResponse call() { String message = provider.getMessage(); return HealthCheckResponse.named(\"greeting\") .state(\"Hello\".equals(message)) .withData(\"greeting\", message) .build(); } } This class has the MicroProfile Liveness annotation which tells Helidon that this class provides a custom health check. You can learn more about the available annotations in the MicroProfile Health Protocol and Wireformat document. This class also has the ApplicationScoped annotation, as seen previously. The GreetingProvider is injected using Context and Dependency Injection. This example will use the greeting to determine whether the application is healthy, this is a contrived example for demonstration purposes. Health checks must implement the HealthCheck functional interface, which includes the method HealthCheckResponse call() . Helidon will invoke the call() method to verify the healthiness of the application. In this example, the application is deemed to be healthy if the GreetingProvider,getMessage() method returns the string \"Hello\" and unhealthy otherwise. Rebuild the application, make sure that the mp.conf has the greeting set to something other than \"Hello\" and then run the application and check the health: <markup lang=\"bash\" title=\"Custom health check reporting unhealthy state\" >curl -i -X GET http://localhost:8080/health/live HTTP/1.1 503 Service Unavailable Content-Type: application/json Date: Fri, 23 Aug 2019 10:07:23 -0400 transfer-encoding: chunked connection: keep-alive {\"outcome\":\"DOWN\",\"status\":\"DOWN\",\"checks\":[{\"name\":\"deadlock\",\"state\":\"UP\",\"status\":\"UP\"},{\"name\":\"diskSpace\",\"state\":\"UP\",\"status\":\"UP\",\"data\":{\"free\":\"381.08 GB\",\"freeBytes\":409182306304,\"percentFree\":\"43.37%\",\"total\":\"878.70 GB\",\"totalBytes\":943491723264}},{\"name\":\"greeting\",\"state\":\"DOWN\",\"status\":\"DOWN\",\"data\":{\"greeting\":\"Hey\"}},{\"name\":\"heapMemory\",\"state\":\"UP\",\"status\":\"UP\",\"data\":{\"free\":\"243.81 MB\",\"freeBytes\":255651048,\"max\":\"3.46 GB\",\"maxBytes\":3715629056,\"percentFree\":\"98.58%\",\"total\":\"294.00 MB\",\"totalBytes\":308281344}}]} The HTTP return code is now 503 Service Unavailable. The status is reported as \"DOWN\" and the custom check is included in the output. Now update the greeting to \"Hello\" using the following request, and then check health again: <markup lang=\"bash\" title=\"Update the greeting and check health again\" ># update greeting curl -i -X PUT -H \"Content-Type: application/json\" -d '{\"greeting\": \"Hello\"}' http://localhost:8080/greet/greeting HTTP/1.1 204 No Content Date: Thu, 22 Aug 2019 13:29:57 -0400 connection: keep-alive # check health curl -i -X GET http://localhost:8080/health/live HTTP/1.1 200 OK Content-Type: application/json Date: Fri, 23 Aug 2019 10:08:09 -0400 connection: keep-alive content-length: 536 {\"outcome\":\"UP\",\"status\":\"UP\",\"checks\":[{\"name\":\"deadlock\",\"state\":\"UP\",\"status\":\"UP\"},{\"name\":\"diskSpace\",\"state\":\"UP\",\"status\":\"UP\",\"data\":{\"free\":\"381.08 GB\",\"freeBytes\":409179811840,\"percentFree\":\"43.37%\",\"total\":\"878.70 GB\",\"totalBytes\":943491723264}},{\"name\":\"greeting\",\"state\":\"UP\",\"status\":\"UP\",\"data\":{\"greeting\":\"Hello\"}},{\"name\":\"heapMemory\",\"state\":\"UP\",\"status\":\"UP\",\"data\":{\"free\":\"237.25 MB\",\"freeBytes\":248769720,\"max\":\"3.46 GB\",\"maxBytes\":3715629056,\"percentFree\":\"98.40%\",\"total\":\"294.00 MB\",\"totalBytes\":308281344}}]} The PUT returns a HTTP 204. The health check now returns a HTTP 200. The status is now reported as \"UP\" and the details are provided in the checks. Learn more about health checks in the Health Check Guide . ",
            "title": "Health Check"
        },
        {
            "location": "/mp/guides/10_mp-tutorial",
            "text": " To run the application in Docker (or Kubernetes), a Dockerfile is needed to build a Docker image. To build the Docker image, you need to have Docker installed and running on your system. Add a new Dockerfile in the project root directory with the following content: <markup lang=\"bash\" title=\"Dockerfile content\" >FROM maven:3.6-jdk-11 as build WORKDIR /helidon ADD pom.xml . RUN mvn package -DskipTests ADD src src RUN mvn package -DskipTests RUN echo \"done!\" FROM openjdk:11-jre-slim WORKDIR /helidon COPY --from=build /helidon/target/helidon-mp-tutorial.jar ./ COPY --from=build /helidon/target/libs ./libs CMD [\"java\", \"-jar\", \"helidon-mp-tutorial.jar\"] EXPOSE 8080 This Dockerfile uses Docker&#8217;s multi-stage build feature. The FROM keyword creates the first stage. In this stage, the base container has the build tools needed to build the application. These are not required to run the application, so the second stage uses a smaller container. Add the pom.xml and running an \"empty\" maven build will download all of the dependencies and plugins in this layer. This will make future builds faster because they will use this cached layer rather than downloading everything again. Add the source code and do the real build. Start a second stage using a much smaller runtime image. Copy the binary and libraries from the first stage. Set the initial command and expose port 8080. To create the Docker image, use the following command: <markup lang=\"bash\" title=\"Docker build\" >docker build -t helidon-mp-tutorial . Make sure the application is shutdown if it was still running locally so that port 8080 will not be in use, then start the application in Docker using the following command: <markup lang=\"bash\" title=\"Run Docker Image\" >docker run --rm -p 8080:8080 helidon-mp-tutorial:latest Try the application as before. <markup lang=\"bash\" title=\"Try the application\" >curl http://localhost:8080/greet/bob {\"message\":\"Howdee bob!\"} curl http://localhost:8080/health/ready {\"outcome\":\"UP\",\"status\":\"UP\",\"checks\":[]} ",
            "title": "Build a Docker Image"
        },
        {
            "location": "/mp/guides/10_mp-tutorial",
            "text": " If you don&#8217;t have access to a Kubernetes cluster, you can install one on your desktop . Then deploy the example: <markup lang=\"bash\" title=\"Verify connectivity to cluster\" >kubectl cluster-info kubectl get nodes To deploy the application to Kubernetes, a Kubernetes YAML file that defines the deployment and associated resources is needed. In this case all that is required is the deployment and a service. Create a file called app.yaml in the project&#8217;s root directory with the following content: <markup lang=\"yaml\" title=\"Kubernetes YAML file\" >--- kind: Service apiVersion: v1 metadata: name: helidon-mp-tutorial labels: app: helidon-mp-tutorial spec: type: NodePort selector: app: helidon-mp-tutorial ports: - port: 8080 targetPort: 8080 name: http --- kind: Deployment apiVersion: apps/v1 metadata: name: helidon-mp-tutorial spec: replicas: 1 selector: matchLabels: app: helidon-mp-tutorial template: metadata: labels: app: helidon-mp-tutorial version: v1 spec: containers: - name: helidon-mp-tutorial image: helidon-mp-tutorial imagePullPolicy: IfNotPresent ports: - containerPort: 8080 Define a Service to provide access to the application. Define a NodePort to expose the application outside the Kubernetes cluster. Define a Deployment of the application. Define how many replicas of the application to run. Define the Docker image to use - this must be the one that was built in the previous step. If the image was built on a different machine to the one where Kubernetes is running, or if Kubernetes is running on multiple machines (worker nodes) then the image must either be manually copied to each node or otherwise pushed to a Docker registry that is accessible to the worker nodes. This Kubernetes YAML file can be used to deploy the application to Kubernetes: <markup lang=\"bash\" title=\"Deploy the application to Kubernetes\" >kubectl create -f app.yaml kubectl get pods # Wait for quickstart pod to be RUNNING Remember, if Kubernetes is running on a different machine, or inside a VM (as in Docker for Desktop) then the Docker image must either be manually copied to the Kubernetes worker nodes or pushed to a Docker registry that is accessible to those worker nodes. Update the image entry in the example above to include the Docker registry name. If the registry is private a Docker registry secret will also be required. The step above created a service that is exposed using any available node port. Kubernetes allocates a free port. Lookup the service to find the port. <markup lang=\"bash\" title=\"Lookup the service\" >kubectl get service helidon-mp-tutorial Note the PORTs. The application can be exercised as before but use the second port number (the NodePort) instead of 8080. For example: <markup lang=\"bash\" title=\"Access the application\" >curl -X GET http://localhost:31431/greet If desired, the Kubernetes YAML file can also be used to remove the application from Kubernetes as follows: <markup lang=\"bash\" title=\"Remove the application from Kubernetes\" >kubectl delete -f app.yaml ",
            "title": "Deploy the application to Kubernetes"
        },
        {
            "location": "/mp/guides/10_mp-tutorial",
            "text": " This tutorial demonstrated how to build a new Helidon MP application, how to use Helidon and MicroProfile configuration, logging, metrics, and health checks. It also demonstrated how to package the application in a Docker image and run it in Kubernetes. There were several links to more detailed information included in the tutorial. These links are repeated below and can be explored to learn more details about Helidon application development. ",
            "title": "Summary"
        },
        {
            "location": "/mp/guides/10_mp-tutorial",
            "text": " Eclipse MicroProfile Contexts and Dependency Injection Specification Configuring the Server Config MicroProfile Metrics Specification Metrics Guide MicroProfile Health Protocol and Wireformat Install Kubernetes on your desktop ",
            "title": "Related links"
        },
        {
            "location": "/se/openapi/01_openapi",
            "text": " Easily allow your Helidon SE application to serve an OpenAPI document that describes your application&#8217;s endpoints. ",
            "title": "preambule"
        },
        {
            "location": "/se/openapi/01_openapi",
            "text": " To enable OpenAPI add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.openapi&lt;/groupId&gt; &lt;artifactId&gt;helidon-openapi&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/openapi/01_openapi",
            "text": " You can very simply add support for OpenAPI to your Helidon SE application. This document shows what changes you need to make to your application and how to access the OpenAPI document for your application at runtime. ",
            "title": "OpenAPI support in Helidon SE"
        },
        {
            "location": "/se/openapi/01_openapi",
            "text": " Add a dependency for Helidon SE OpenAPI runtime support. This is a compile-time dependency, because your code must register OpenAPISupport (a class in that artifact) like this: ",
            "title": "Edit your pom.xml "
        },
        {
            "location": "/se/openapi/01_openapi",
            "text": "<markup lang=\"java\" >Config config = Config.create(); ... return Routing.builder() .register(JsonSupport.create()) .register(OpenAPISupport.create(config)) .register(health) // Health at \"/health\" .register(metrics) // Metrics at \"/metrics\" .register(\"/greet\", greetService) .build(); Adds the OpenAPISupport service to your server. ",
            "title": "Register OpenAPISupport in your Java code"
        },
        {
            "location": "/se/openapi/01_openapi",
            "text": " Add a static file at META-INF/openapi.yml , META-INF/openapi.yaml , or META-INF/openapi.json . Tools such as Swagger let you describe your app&#8217;s API and they then generate an OpenAPI document file which you can include in your application so OpenAPI can use it. ",
            "title": "Provide a static OpenAPI file"
        },
        {
            "location": "/se/openapi/01_openapi",
            "text": " Write a Java class that implements the OpenAPI org.eclipse.microprofile.openapi.OASModelReader interface. Your model reader code programmatically adds elements to the internal model that OpenAPI builds. Change your application&#8217;s configuration to set openapi.model.reader as the fully-qualified class name of your class. Also see Add OpenAPI dependency below. ",
            "title": "Write and configure a model reader class"
        },
        {
            "location": "/se/openapi/01_openapi",
            "text": " Write a Java class that implements the OpenAPI org.eclipse.microprofile.openapi.OASFilter interface. As OpenAPI composes its internal model, it invokes your filter with each model element before adding the element to the model. Your filter can accept the element as-is, modify it, or suppress it. Change your application&#8217;s configuration to set openapi.filter as the full-qualified class name of your class. Also see Add OpenAPI dependency below. ",
            "title": "Write and configure a filter class"
        },
        {
            "location": "/se/openapi/01_openapi",
            "text": " If you implement either a model reader or a filter, add this dependency to your pom.xml : <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;org.eclipse.microprofile.openapi&lt;/groupId&gt; &lt;artifactId&gt;microprofile-openapi-api&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt; &lt;/dependency&gt; ",
            "title": "Add OpenAPI dependency"
        },
        {
            "location": "/se/openapi/01_openapi",
            "text": " Helidon SE OpenAPI combines information from all of the following sources as it builds its in-memory model of your application&#8217;s API. It constructs the OpenAPI document from this internal model. Your application can use one or more of these techniques. Provide a static OpenAPI file Add a static file at META-INF/openapi.yml , META-INF/openapi.yaml , or META-INF/openapi.json . Tools such as Swagger let you describe your app&#8217;s API and they then generate an OpenAPI document file which you can include in your application so OpenAPI can use it. Write and configure a model reader class Write a Java class that implements the OpenAPI org.eclipse.microprofile.openapi.OASModelReader interface. Your model reader code programmatically adds elements to the internal model that OpenAPI builds. Change your application&#8217;s configuration to set openapi.model.reader as the fully-qualified class name of your class. Also see Add OpenAPI dependency below. Write and configure a filter class Write a Java class that implements the OpenAPI org.eclipse.microprofile.openapi.OASFilter interface. As OpenAPI composes its internal model, it invokes your filter with each model element before adding the element to the model. Your filter can accept the element as-is, modify it, or suppress it. Change your application&#8217;s configuration to set openapi.filter as the full-qualified class name of your class. Also see Add OpenAPI dependency below. Add OpenAPI dependency If you implement either a model reader or a filter, add this dependency to your pom.xml : <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;org.eclipse.microprofile.openapi&lt;/groupId&gt; &lt;artifactId&gt;microprofile-openapi-api&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt; &lt;/dependency&gt; ",
            "title": "Furnish OpenAPI information about your endpoints"
        },
        {
            "location": "/se/openapi/01_openapi",
            "text": " Helidon SE support for OpenAPI supports a handful of config properties patterned after those described in the MicroProfile OpenAPI spec, two of which were mentioned above. Helidon SE OpenAPI Config Properties Property Use openapi.model.reader Fully-qualified class name for the model reader openapi.filter Fully-qualified class name for the filter openapi.servers Lists servers that provide connectivity information openapi.servers.path Prefix for config properties specifying alternative servers for given paths openapi.servers.operation Prefix for config properties specifying alternative servers for given operations For more information on what these settings do consult the MicroProfile OpenAPI spec. Helidon SE also supports additional properties specific to Helidon. Helidon-specific OpenAPI Config Properties Property Use openapi.web-context Path which serves the OpenAPI document (defaults to /openapi ) openapi.static-file Full path to the static OpenAPI file (defaults to META-INF/openapi.yml , META-INF/openapi.yaml , or META-INF/openapi.json ) Set these config properties in one of the config sources your app uses so the Helidon config system will load them. Often developers use application.yaml at the top level of the application JAR. ",
            "title": "Update application configuration"
        },
        {
            "location": "/se/openapi/01_openapi",
            "text": " OpenAPI support in Helidon SE largely follows the MicroProfile OpenAPI spec . But Helidon SE does not process annotations, which is one way to convey OpenAPI information about the endpoints in your app. You can still use OpenAPI with your Helidon SE app by providing OpenAPI information about the endpoints without using annotations. Helidon SE includes a complete OpenAPI example based on the SE quick-start sample app. To use OpenAPI from your Helidon SE app: Edit your pom.xml . Update your Java code to register OpenAPISupport . Furnish OpenAPI information about your application&#8217;s endpoints. Update your application&#8217;s Helidon configuration (optional). Edit your pom.xml Add a dependency for Helidon SE OpenAPI runtime support. This is a compile-time dependency, because your code must register OpenAPISupport (a class in that artifact) like this: Register OpenAPISupport in your Java code <markup lang=\"java\" >Config config = Config.create(); ... return Routing.builder() .register(JsonSupport.create()) .register(OpenAPISupport.create(config)) .register(health) // Health at \"/health\" .register(metrics) // Metrics at \"/metrics\" .register(\"/greet\", greetService) .build(); Adds the OpenAPISupport service to your server. Furnish OpenAPI information about your endpoints Helidon SE OpenAPI combines information from all of the following sources as it builds its in-memory model of your application&#8217;s API. It constructs the OpenAPI document from this internal model. Your application can use one or more of these techniques. Provide a static OpenAPI file Add a static file at META-INF/openapi.yml , META-INF/openapi.yaml , or META-INF/openapi.json . Tools such as Swagger let you describe your app&#8217;s API and they then generate an OpenAPI document file which you can include in your application so OpenAPI can use it. Write and configure a model reader class Write a Java class that implements the OpenAPI org.eclipse.microprofile.openapi.OASModelReader interface. Your model reader code programmatically adds elements to the internal model that OpenAPI builds. Change your application&#8217;s configuration to set openapi.model.reader as the fully-qualified class name of your class. Also see Add OpenAPI dependency below. Write and configure a filter class Write a Java class that implements the OpenAPI org.eclipse.microprofile.openapi.OASFilter interface. As OpenAPI composes its internal model, it invokes your filter with each model element before adding the element to the model. Your filter can accept the element as-is, modify it, or suppress it. Change your application&#8217;s configuration to set openapi.filter as the full-qualified class name of your class. Also see Add OpenAPI dependency below. Add OpenAPI dependency If you implement either a model reader or a filter, add this dependency to your pom.xml : <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;org.eclipse.microprofile.openapi&lt;/groupId&gt; &lt;artifactId&gt;microprofile-openapi-api&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt; &lt;/dependency&gt; Update application configuration Helidon SE support for OpenAPI supports a handful of config properties patterned after those described in the MicroProfile OpenAPI spec, two of which were mentioned above. Helidon SE OpenAPI Config Properties Property Use openapi.model.reader Fully-qualified class name for the model reader openapi.filter Fully-qualified class name for the filter openapi.servers Lists servers that provide connectivity information openapi.servers.path Prefix for config properties specifying alternative servers for given paths openapi.servers.operation Prefix for config properties specifying alternative servers for given operations For more information on what these settings do consult the MicroProfile OpenAPI spec. Helidon SE also supports additional properties specific to Helidon. Helidon-specific OpenAPI Config Properties Property Use openapi.web-context Path which serves the OpenAPI document (defaults to /openapi ) openapi.static-file Full path to the static OpenAPI file (defaults to META-INF/openapi.yml , META-INF/openapi.yaml , or META-INF/openapi.json ) Set these config properties in one of the config sources your app uses so the Helidon config system will load them. Often developers use application.yaml at the top level of the application JAR. ",
            "title": "Changing your application"
        },
        {
            "location": "/se/openapi/01_openapi",
            "text": " Now your Helidon SE application will automatically respond to an additional endpoint&#8201;&#8212;&#8201; /openapi &#8201;&#8212;&#8201;and it will return the OpenAPI document describing the endpoints in your application. By default, Helidon OpenAPI returns the OpenAPI document in YAML. There is not yet an adopted IANA YAML media type, but a proposed one specifically for OpenAPI documents that has some support is application/vnd.oai.openapi . That is what Helidon returns, by default. In addition a client can specify Accept: as either application/vnd.oai.openapi+json or application/json to request JSON. ",
            "title": "Accessing the OpenAPI document"
        },
        {
            "location": "/mp/reactivemessaging/02_message",
            "text": " Message carries a callback for reception acknowledgement, acknowledgement in messaging methods is possible manually by org.eclipse.microprofile.reactive.messaging.Message#ack or automatically according explicit or implicit acknowledgement strategy by messaging core. Explicit strategy configuration is possible with @Acknowledgment annotation which has one required attribute value that expects the strategy type from enum org.eclipse.microprofile.reactive.messaging.Acknowledgment.Strategy . More information about supported signatures and implicit automatic acknowledgement can be found in specification Message acknowledgement . Acknowledgement strategies @Acknowledgment(Acknowledgment.Strategy.NONE) No acknowledgment @Acknowledgment(Acknowledgment.Strategy.MANUAL) No automatic acknowledgment @Acknowledgment(Acknowledgment.Strategy.PRE_PROCESSING) Ack automatically before method invocation or processing @Acknowledgment(Acknowledgment.Strategy.POST_PROCESSING) Ack automatically after method invocation or processing <markup lang=\"java\" title=\"Example of manual acknowledgment\" >@Outgoing(\"consume-and-ack\") public PublisherBuilder&lt;Integer&gt; streamOfMessages() { return ReactiveStreams.of(Message.of(\"This is Payload\", () -&gt; { System.out.println(\"This particular message was acked!\"); return CompletableFuture.completedFuture(null); })).buildRs(); } @Incoming(\"consume-and-ack\") @Acknowledgment(Acknowledgment.Strategy.MANUAL) public void receiveAndAckMessage(Message&lt;String&gt; msg) { msg.ack(); } Calling ack() will print \"This particular message was acked!\" to System.out <markup lang=\"java\" title=\"Example of manual acknowledgment\" >@Outgoing(\"consume-and-ack\") public PublisherBuilder&lt;Integer&gt; streamOfMessages() { return ReactiveStreams.of(Message.of(\"This is Payload\", () -&gt; { System.out.println(\"This particular message was acked!\"); return CompletableFuture.completedFuture(null); })).buildRs(); } @Incoming(\"consume-and-ack\") @Acknowledgment(Acknowledgment.Strategy.MANUAL) public void receiveAndAckMessage(Message&lt;String&gt; msg) { msg.ack(); } Calling ack() will print \"This particular message was acked!\" to System.out <markup lang=\"java\" title=\"Example of explicit pre-process acknowledgment\" >@Outgoing(\"consume-and-ack\") public PublisherBuilder&lt;Integer&gt; streamOfMessages() { return ReactiveStreams.of(Message.of(\"This is Payload\", () -&gt; { System.out.println(\"This particular message was acked!\"); return CompletableFuture.completedFuture(null); })).buildRs(); } /** * Prints to the console: * &gt; This particular message was acked! * &gt; Method invocation! */ @Incoming(\"consume-and-ack\") @Acknowledgment(Acknowledgment.Strategy.PRE_PROCESSING) public void receiveAndAckMessage(Message&lt;String&gt; msg) { System.out.println(\"Method invocation!\"); } <markup lang=\"java\" title=\"Example of explicit post-rocess acknowledgment\" >@Outgoing(\"consume-and-ack\") public PublisherBuilder&lt;Integer&gt; streamOfMessages() { return ReactiveStreams.of(Message.of(\"This is Payload\", () -&gt; { System.out.println(\"This particular message was acked!\"); return CompletableFuture.completedFuture(null); })).buildRs(); } /** * Prints to the console: * &gt; Method invocation! * &gt; This particular message was acked! */ @Incoming(\"consume-and-ack\") @Acknowledgment(Acknowledgment.Strategy.POST_PROCESSING) public void receiveAndAckMessage(Message&lt;String&gt; msg) { System.out.println(\"Method invocation!\"); } ",
            "title": "Acknowledgement"
        },
        {
            "location": "/mp/reactivemessaging/02_message",
            "text": " The Reactive Messaging Message class can be used to wrap or unwrap data items between methods and connectors. The message wrapping and unwrapping can be performed explicitly by using org.eclipse.microprofile.reactive.messaging.Message#of(T) or implicitly through the messaging core. <markup lang=\"java\" title=\"Example of explicit and implicit wrapping and unwrapping\" >@Outgoing(\"publisher-payload\") public PublisherBuilder&lt;Integer&gt; streamOfMessages() { return ReactiveStreams.of(0, 1, 2, 3, 4, 5, 6, 7, 8, 9); } @Incoming(\"publisher-payload\") @Outgoing(\"wrapped-message\") public Message&lt;String&gt; rewrapMessageManually(Message&lt;Integer&gt; message) { return Message.of(Integer.toString(message.getPayload())); } @Incoming(\"wrapped-message\") public void consumeImplicitlyUnwrappedMessage(String value) { System.out.println(\"Consuming message: \" + value); } Acknowledgement Message carries a callback for reception acknowledgement, acknowledgement in messaging methods is possible manually by org.eclipse.microprofile.reactive.messaging.Message#ack or automatically according explicit or implicit acknowledgement strategy by messaging core. Explicit strategy configuration is possible with @Acknowledgment annotation which has one required attribute value that expects the strategy type from enum org.eclipse.microprofile.reactive.messaging.Acknowledgment.Strategy . More information about supported signatures and implicit automatic acknowledgement can be found in specification Message acknowledgement . Acknowledgement strategies @Acknowledgment(Acknowledgment.Strategy.NONE) No acknowledgment @Acknowledgment(Acknowledgment.Strategy.MANUAL) No automatic acknowledgment @Acknowledgment(Acknowledgment.Strategy.PRE_PROCESSING) Ack automatically before method invocation or processing @Acknowledgment(Acknowledgment.Strategy.POST_PROCESSING) Ack automatically after method invocation or processing <markup lang=\"java\" title=\"Example of manual acknowledgment\" >@Outgoing(\"consume-and-ack\") public PublisherBuilder&lt;Integer&gt; streamOfMessages() { return ReactiveStreams.of(Message.of(\"This is Payload\", () -&gt; { System.out.println(\"This particular message was acked!\"); return CompletableFuture.completedFuture(null); })).buildRs(); } @Incoming(\"consume-and-ack\") @Acknowledgment(Acknowledgment.Strategy.MANUAL) public void receiveAndAckMessage(Message&lt;String&gt; msg) { msg.ack(); } Calling ack() will print \"This particular message was acked!\" to System.out <markup lang=\"java\" title=\"Example of manual acknowledgment\" >@Outgoing(\"consume-and-ack\") public PublisherBuilder&lt;Integer&gt; streamOfMessages() { return ReactiveStreams.of(Message.of(\"This is Payload\", () -&gt; { System.out.println(\"This particular message was acked!\"); return CompletableFuture.completedFuture(null); })).buildRs(); } @Incoming(\"consume-and-ack\") @Acknowledgment(Acknowledgment.Strategy.MANUAL) public void receiveAndAckMessage(Message&lt;String&gt; msg) { msg.ack(); } Calling ack() will print \"This particular message was acked!\" to System.out <markup lang=\"java\" title=\"Example of explicit pre-process acknowledgment\" >@Outgoing(\"consume-and-ack\") public PublisherBuilder&lt;Integer&gt; streamOfMessages() { return ReactiveStreams.of(Message.of(\"This is Payload\", () -&gt; { System.out.println(\"This particular message was acked!\"); return CompletableFuture.completedFuture(null); })).buildRs(); } /** * Prints to the console: * &gt; This particular message was acked! * &gt; Method invocation! */ @Incoming(\"consume-and-ack\") @Acknowledgment(Acknowledgment.Strategy.PRE_PROCESSING) public void receiveAndAckMessage(Message&lt;String&gt; msg) { System.out.println(\"Method invocation!\"); } <markup lang=\"java\" title=\"Example of explicit post-rocess acknowledgment\" >@Outgoing(\"consume-and-ack\") public PublisherBuilder&lt;Integer&gt; streamOfMessages() { return ReactiveStreams.of(Message.of(\"This is Payload\", () -&gt; { System.out.println(\"This particular message was acked!\"); return CompletableFuture.completedFuture(null); })).buildRs(); } /** * Prints to the console: * &gt; Method invocation! * &gt; This particular message was acked! */ @Incoming(\"consume-and-ack\") @Acknowledgment(Acknowledgment.Strategy.POST_PROCESSING) public void receiveAndAckMessage(Message&lt;String&gt; msg) { System.out.println(\"Method invocation!\"); } ",
            "title": "Message"
        },
        {
            "location": "/mp/reactivemessaging/05_jms",
            "text": " To enable JMS Connector add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.messaging.jms&lt;/groupId&gt; &lt;artifactId&gt;helidon-messaging-jms&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/reactivemessaging/05_jms",
            "text": " Connector name: helidon-jms Attributes username User name used to connect JMS session password Password to connect JMS session type Possible values are: queue , topic destination Queue or topic name acknowledge-mode Possible values are: AUTO_ACKNOWLEDGE - session automatically acknowledges a client&#8217;s receipt of a message, CLIENT_ACKNOWLEDGE - receipt of a message is acknowledged only when Message.ack() is called manually, DUPS_OK_ACKNOWLEDGE - session lazily acknowledges the delivery of messages. Default value: AUTO_ACKNOWLEDGE transacted Indicates whether the session will use a local transaction. Default value: false message-selector JMS API message selector expression based on a subset of the SQL92. Expression can only access headers and properties, not the payload. client-id Client identifier for JMS connection. durable True for creating durable consumer (only for topic). Default value: false subscriber-name Subscriber name for durable consumer used to identify subscription. non-local If true then any messages published to the topic using this session&#8217;s connection, or any other connection with the same client identifier, will not be added to the durable subscription. Default value: false named-factory Select in case factory is injected as a named bean or configured with name. poll-timeout Timeout for polling for next message in every poll cycle in millis. Default value: 50 period-executions Period for executing poll cycles in millis. Default value: 100 session-group-id When multiple channels share same session-group-id , they share same JMS session and same JDBC connection as well. jndi.jms-factory JNDI name of JMS factory. jndi.env-properties Environment properties used for creating initial context java.naming.factory.initial , java.naming.provider.url &#8230;&#8203; producer.someproperty property with producer prefix is set to producer instance (for example WLS Unit-of-Order WLMessageProducer.setUnitOfOrder(\"unit-1\") can be configured as producer.unit-of-order=unit-1 ) ",
            "title": "Config"
        },
        {
            "location": "/mp/reactivemessaging/05_jms",
            "text": " The simplest possible usage is looking up JMS ConnectionFactory in the naming context. <markup lang=\"yaml\" title=\"Example of connector config:\" >mp.messaging: incoming.from-jms: connector: helidon-jms destination: messaging-test-queue-1 type: queue outgoing.to-jms: connector: helidon-jms destination: messaging-test-queue-1 type: queue connector: helidon-jms: user: Gandalf password: mellon jndi: jms-factory: ConnectionFactory env-properties: java.naming: factory.initial: org.apache.activemq.jndi.ActiveMQInitialContextFactory provider.url: tcp://localhost:61616 ",
            "title": "Configured JMS factory"
        },
        {
            "location": "/mp/reactivemessaging/05_jms",
            "text": " In case you need more advanced setup, connector can work with injected factory instance. <markup lang=\"java\" title=\"Inject:\" > @Produces @ApplicationScoped @Named(\"active-mq-factory\") public ConnectionFactory connectionFactory() { return new ActiveMQConnectionFactory(config.get(\"jms.url\").asString().get()); } <markup lang=\"yaml\" title=\"Config:\" >jms: url: tcp://127.0.0.1:61616 mp: messaging: connector: helidon-jms: named-factory: active-mq-factory outgoing.to-jms: connector: helidon-jms session-group-id: order-connection-1 destination: TESTQUEUE type: queue incoming.from-jms: connector: helidon-jms session-group-id: order-connection-1 destination: TESTQUEUE type: queue ",
            "title": "Injected JMS factory"
        },
        {
            "location": "/mp/reactivemessaging/05_jms",
            "text": "<markup lang=\"java\" title=\"Consuming one by one unwrapped value:\" >@Incoming(\"from-jms\") public void consumeJms(String msg) { System.out.println(\"JMS says: \" + msg); } <markup lang=\"java\" title=\"Consuming one by one, manual ack:\" >@Incoming(\"from-jms\") @Acknowledgment(Acknowledgment.Strategy.MANUAL) public CompletionStage&lt;?&gt; consumeJms(JmsMessage&lt;String&gt; msg) { System.out.println(\"JMS says: \" + msg.getPayload()); return msg.ack(); } ",
            "title": "Consuming"
        },
        {
            "location": "/mp/reactivemessaging/05_jms",
            "text": "<markup lang=\"java\" title=\"Example of producing to JMS:\" >@Outgoing(\"to-jms\") public PublisherBuilder&lt;String&gt; produceToJms() { return ReactiveStreams.of(\"test1\", \"test2\"); } <markup lang=\"java\" title=\"Example of more advanced producing to JMS:\" >@Outgoing(\"to-jms\") public PublisherBuilder&lt;String&gt; produceToJms() { return ReactiveStreams.of(\"test1\", \"test2\") .map(s -&gt; JmsMessage.builder(s) .correlationId(UUID.randomUUID().toString()) .property(\"stringProp\", \"cool property\") .property(\"byteProp\", 4) .property(\"intProp\", 5) .onAck(() -&gt; System.out.println(\"Acked!\")) .build()); } <markup lang=\"java\" title=\"Example of even more advanced producing to JMS with custom mapper:\" >@Outgoing(\"to-jms\") public PublisherBuilder&lt;String&gt; produceToJms() { return ReactiveStreams.of(\"test1\", \"test2\") .map(s -&gt; JmsMessage.builder(s) .customMapper((p, session) -&gt; { TextMessage textMessage = session.createTextMessage(p); textMessage.setStringProperty(\"custom-mapped-property\", \"XXX\" + p); return textMessage; }) .build() ); } ",
            "title": "Producing"
        },
        {
            "location": "/mp/reactivemessaging/05_jms",
            "text": " Connecting streams to JMS with Reactive Messaging couldn&#8217;t be easier. Config Connector name: helidon-jms Attributes username User name used to connect JMS session password Password to connect JMS session type Possible values are: queue , topic destination Queue or topic name acknowledge-mode Possible values are: AUTO_ACKNOWLEDGE - session automatically acknowledges a client&#8217;s receipt of a message, CLIENT_ACKNOWLEDGE - receipt of a message is acknowledged only when Message.ack() is called manually, DUPS_OK_ACKNOWLEDGE - session lazily acknowledges the delivery of messages. Default value: AUTO_ACKNOWLEDGE transacted Indicates whether the session will use a local transaction. Default value: false message-selector JMS API message selector expression based on a subset of the SQL92. Expression can only access headers and properties, not the payload. client-id Client identifier for JMS connection. durable True for creating durable consumer (only for topic). Default value: false subscriber-name Subscriber name for durable consumer used to identify subscription. non-local If true then any messages published to the topic using this session&#8217;s connection, or any other connection with the same client identifier, will not be added to the durable subscription. Default value: false named-factory Select in case factory is injected as a named bean or configured with name. poll-timeout Timeout for polling for next message in every poll cycle in millis. Default value: 50 period-executions Period for executing poll cycles in millis. Default value: 100 session-group-id When multiple channels share same session-group-id , they share same JMS session and same JDBC connection as well. jndi.jms-factory JNDI name of JMS factory. jndi.env-properties Environment properties used for creating initial context java.naming.factory.initial , java.naming.provider.url &#8230;&#8203; producer.someproperty property with producer prefix is set to producer instance (for example WLS Unit-of-Order WLMessageProducer.setUnitOfOrder(\"unit-1\") can be configured as producer.unit-of-order=unit-1 ) Configured JMS factory The simplest possible usage is looking up JMS ConnectionFactory in the naming context. <markup lang=\"yaml\" title=\"Example of connector config:\" >mp.messaging: incoming.from-jms: connector: helidon-jms destination: messaging-test-queue-1 type: queue outgoing.to-jms: connector: helidon-jms destination: messaging-test-queue-1 type: queue connector: helidon-jms: user: Gandalf password: mellon jndi: jms-factory: ConnectionFactory env-properties: java.naming: factory.initial: org.apache.activemq.jndi.ActiveMQInitialContextFactory provider.url: tcp://localhost:61616 Injected JMS factory In case you need more advanced setup, connector can work with injected factory instance. <markup lang=\"java\" title=\"Inject:\" > @Produces @ApplicationScoped @Named(\"active-mq-factory\") public ConnectionFactory connectionFactory() { return new ActiveMQConnectionFactory(config.get(\"jms.url\").asString().get()); } <markup lang=\"yaml\" title=\"Config:\" >jms: url: tcp://127.0.0.1:61616 mp: messaging: connector: helidon-jms: named-factory: active-mq-factory outgoing.to-jms: connector: helidon-jms session-group-id: order-connection-1 destination: TESTQUEUE type: queue incoming.from-jms: connector: helidon-jms session-group-id: order-connection-1 destination: TESTQUEUE type: queue Consuming <markup lang=\"java\" title=\"Consuming one by one unwrapped value:\" >@Incoming(\"from-jms\") public void consumeJms(String msg) { System.out.println(\"JMS says: \" + msg); } <markup lang=\"java\" title=\"Consuming one by one, manual ack:\" >@Incoming(\"from-jms\") @Acknowledgment(Acknowledgment.Strategy.MANUAL) public CompletionStage&lt;?&gt; consumeJms(JmsMessage&lt;String&gt; msg) { System.out.println(\"JMS says: \" + msg.getPayload()); return msg.ack(); } Producing <markup lang=\"java\" title=\"Example of producing to JMS:\" >@Outgoing(\"to-jms\") public PublisherBuilder&lt;String&gt; produceToJms() { return ReactiveStreams.of(\"test1\", \"test2\"); } <markup lang=\"java\" title=\"Example of more advanced producing to JMS:\" >@Outgoing(\"to-jms\") public PublisherBuilder&lt;String&gt; produceToJms() { return ReactiveStreams.of(\"test1\", \"test2\") .map(s -&gt; JmsMessage.builder(s) .correlationId(UUID.randomUUID().toString()) .property(\"stringProp\", \"cool property\") .property(\"byteProp\", 4) .property(\"intProp\", 5) .onAck(() -&gt; System.out.println(\"Acked!\")) .build()); } <markup lang=\"java\" title=\"Example of even more advanced producing to JMS with custom mapper:\" >@Outgoing(\"to-jms\") public PublisherBuilder&lt;String&gt; produceToJms() { return ReactiveStreams.of(\"test1\", \"test2\") .map(s -&gt; JmsMessage.builder(s) .customMapper((p, session) -&gt; { TextMessage textMessage = session.createTextMessage(p); textMessage.setStringProperty(\"custom-mapped-property\", \"XXX\" + p); return textMessage; }) .build() ); } ",
            "title": "Reactive JMS Connector"
        },
        {
            "location": "/se/guides/26_gradle_build",
            "text": " This guide describes Helidon&#8217;s support for Gradle projects. ",
            "title": "preambule"
        },
        {
            "location": "/se/guides/26_gradle_build",
            "text": " While most of Helidon&#8217;s examples use Maven, you can also use Helidon with a Gradle project. We recommend Gradle 6+. ",
            "title": "Introduction"
        },
        {
            "location": "/se/guides/26_gradle_build",
            "text": " The Helidon Quickstart Example contains a build.gradle file that you can use as an example for building your Helidon application using Gradle. ",
            "title": "Gradle Example"
        },
        {
            "location": "/se/guides/26_gradle_build",
            "text": " Gradle supports using a Maven POM to perform dependency management. You can use the Helidon Dependencies POM for this purpose. Once you import the Helidon dependency management POM you can specify dependencies without providing a version. <markup lang=\"xml\" title=\"Using the Helidon Dependencies POM\" >dependencies { // import Helidon dependency management implementation platform(\"io.helidon:helidon-dependencies:${project.helidonversion}\") implementation 'io.helidon.microprofile.bundles:helidon-microprofile' implementation 'org.glassfish.jersey.media:jersey-media-json-binding' runtimeOnly 'org.jboss:jandex' runtimeOnly 'javax.activation:javax.activation-api' testCompileOnly 'org.junit.jupiter:junit-jupiter-api:' } ",
            "title": "Dependency Management"
        },
        {
            "location": "/se/guides/15_migration",
            "text": " In Helidon 2 we have made some changes to APIs and runtime behavior. This guide will help you migrate a Helidon SE 1.x application to 2.x. ",
            "title": "preambule"
        },
        {
            "location": "/se/guides/15_migration",
            "text": " Java 8 is no longer supported. Java 11 or newer is required. ",
            "title": "Java 8 Runtime"
        },
        {
            "location": "/se/guides/15_migration",
            "text": " Since Helidon 2.x now requires Java 11 the helper classes that were provided for Java 8 support have been removed. These have been replaced by the standard JDK classes: Removed Replacement io.helidon.reactive.Flow java.util.concurrent.Flow io.helidon.common.CollectionsHelper Factory methods of Set , Map and List io.helidon.common.OptionalHelper Methods of java.util.Optional io.helidon.common.StackWalker java.lang.StackWalker io.helidon.common.InputStreamHelper Methods of java.io.InputStream ",
            "title": "Common Utilities"
        },
        {
            "location": "/se/guides/15_migration",
            "text": " We have upgraded to OpenTracing version 0.33.0 that is not backward compatible. OpenTracing introduced the following breaking changes: Removed Replacement ScopeManager.active() Tracer.activeSpan() ScopeManager.activate(Span, boolean) ScopeManager.activate(Span) - second parameter is now always false SpanBuilder.startActive() Tracer.activateSpan(Span) TextMapExtractAdapter and TextMapInjectAdapter TextMapAdapter Module name changed opentracing.api io.opentracing.api (same for noop and util ) If you use the TracerBuilder abstraction in Helidon and have no custom Spans, there is no change required ",
            "title": "Tracing"
        },
        {
            "location": "/se/guides/15_migration",
            "text": " When the OIDC provider is configured to use cookie (default configuration) to carry authentication information, the cookie Same-Site is now set to Lax (used to be Strict ). This is to prevent infinite redirects, as browsers would refuse to set the cookie on redirected requests (due to this setting). Only in the case of the frontend host and identity host match, we leave Strict as the default ",
            "title": "Security: OIDC"
        },
        {
            "location": "/se/guides/15_migration",
            "text": " Some methods that act as getters of type T have been modified to return Optional&lt;T&gt; . You will need to change your code to handle the Optional return type. For example ServerRequest.spanContext() in 1.x had a return type of SpanContext . In 2.x it has a return type of Optional&lt;SpanContext&gt; . So if you had code like: <markup lang=\"java\" title=\"Helidon 1.x Code\" >Span myNewSpan = GlobalTracer.get() .buildSpan(“my-operation”) .asChildOf(serverRequest.spanContext()) .start(); you will need to change it to something like: <markup lang=\"java\" title=\"Helidon 2.x Code\" >Tracer.SpanBuilder spanBuilder = serverRequest.tracer() .buildSpan(\"my-operation\"); serverRequest.spanContext().ifPresent(spanBuilder::asChildOf); Span myNewSpan = spanBuilder.start(); Note the use of ifPresent() on the returned Optional&lt;SpanContext&gt; . ",
            "title": "Getters"
        },
        {
            "location": "/se/guides/15_migration",
            "text": " File watching is now done through a ChangeWatcher - use of PollingStrategies.watch() needs to be refactored to FileSystemWatcher.create() and the method to configure it on config source builder has changed to changeWatcher(ChangeWatcher) . Methods on ConfigSources now return specific builders (they used to return AbstractParsableConfigSource.Builder with a complex type declaration). If you store such a builder in a variable, either change it to the correct type, or use var Some APIs were cleaned up to be aligned with the development guidelines of Helidon. When using Git config source, or etcd config source, the factory methods moved to the config source itself, and the builder now accepts all configuration options through methods The API of config source builders has been cleaned, so now only methods that are relevant to a specific config source type can be invoked on such a builder. Previously you could configure a polling strategy on a source that did not support polling There is a small change in behavior of Helidon Config vs. MicroProfile Config: The MP TCK require that system properties are fully mutable (e.g. as soon as the property is changed, it must be used), so MP Config methods work in this manner (with a certain performance overhead). Helidon Config treats System properties as a mutable config source, with a (optional) time based polling strategy. So the change is reflected as well, though not immediately (this is only relevant if you use change notifications). CompositeConfigSource has been removed from Config . If you need to configure MerginStrategy , you can do it now on Config Builder Example of advanced configuration of config: <markup lang=\"java\" >Config.builder() // system properties with a polling strategy of 10 seconds .addSource(ConfigSources.systemProperties() .pollingStrategy(PollingStrategies.regular(Duration.ofSeconds(10)))) // environment variables .addSource(ConfigSources.environmentVariables()) // optional file config source with change watcher .addSource(ConfigSources.file(Paths.get(\"/conf/app.yaml\")) .optional() .changeWatcher(FileSystemWatcher.create())) // classpath config source .addSource(ConfigSources.classpath(\"application.yaml\")) // map config source (also supports polling strategy) .addSource(ConfigSources.create(Map.of(\"key\", \"value\"))) .build(); ",
            "title": "Configuration"
        },
        {
            "location": "/se/guides/15_migration",
            "text": " The configuration approach to Resource class was using prefixes which was not aligned with our approach to configuration. All usages were refactored as follows: The Resource class expects a config node resource that will be used to read it The feature set remains unchanged - we support path, classpath, url, content as plain text, and content as base64 Classes using resources are changed as well, such as KeyConfig - see details below ",
            "title": "Resource Class When Loaded from Config"
        },
        {
            "location": "/se/guides/15_migration",
            "text": " In Helidon 1.x support for JSON and other media types was configured when constructing webserver.Routing using the register method. In Helidon 2 Media Support has been refactored so that it can be shared between the Helidon WebServer and WebClient . You now specify media support as part of the WebServer build: <markup lang=\"java\" >WebServer.builder() .addMediaSupport(JsonpSupport.create()) //registers reader and writer for Json-P .build() This replaces Routing.builder().register(JsonSupport.create())&#8230;&#8203; The new JSON MediaSupport classes are: io.helidon.media.jsonp.JsonpSupport in module io.helidon.media:helidon-media-jsonp io.helidon.media.jsonb.JsonbSupport in module io.helidon.media:helidon-media-jsonb io.helidon.media.jackson.JacksonSupport in module io.helidon.media:helidon-media-jackson ",
            "title": "Media Support"
        },
        {
            "location": "/se/guides/15_migration",
            "text": " Removed Replacement io.helidon.common.reactive.ReactiveStreamsAdapter org.reactivestreams.FlowAdapters ",
            "title": "Reactive"
        },
        {
            "location": "/se/guides/15_migration",
            "text": " Configuration has been updated to use the new Resource approach: oidc-metadata.resource is the new key for loading oidc-metadata from local resource sign-jwk.resource is the new key for loading signing JWK resource ",
            "title": "Security: OidcConfig"
        },
        {
            "location": "/se/guides/15_migration",
            "text": " Configuration has been updated to use the new Resource approach: jwk.resource is the new key for loading JWK for verifying signatures jwt.resource is also used for outbound as key for loading JWK for signing tokens ",
            "title": "Security: JwtProvider and JwtAuthProvider"
        },
        {
            "location": "/se/guides/15_migration",
            "text": " The configuration has been updated to have a nicer tree structure: Example of a public key from keystore: <markup lang=\"yaml\" >keystore: cert.alias: \"service_cert\" resource.path: \"/conf/keystore.p12\" type: \"PKCS12\" passphrase: \"password\" Example of a private key from keystore: <markup lang=\"yaml\" >keystore: key: alias: \"myPrivateKey\" passphrase: \"password\" resource.resource-path: \"keystore/keystore.p12\" passphrase: \"password\" Example of a pem resource with private key and certificate chain: <markup lang=\"yaml\" >pem: key: passphrase: \"password\" resource.resource-path: \"keystore/id_rsa.p8\" cert-chain: resource.resource-path: \"keystore/public_key_cert.pem\" ",
            "title": "PKI Key Configuration"
        },
        {
            "location": "/se/guides/15_migration",
            "text": " Configuration has been updated to use the new Resource approach: tls-cert.resource is the new key for certificate tls-key.resource is the new key for private key tl-ca-cert is the the new key for certificate ",
            "title": "GrpcTlsDescriptor"
        },
        {
            "location": "/se/guides/15_migration",
            "text": " There is a new class io.helidon.webserver.WebServerTls that can be used to configure TLS for a WebServer socket. Class io.helidon.webserver.SSLContextBuilder has been deprecated and will be removed. The class uses a Builder pattern: <markup lang=\"java\" >WebServerTls.builder() .privateKey(KeyConfig.keystoreBuilder() .keystore(Resource.create(\"certificate.p12\")) .keystorePassphrase(\"helidon\") The builder or built instance can be registered with a socket configuration builder including the WebServer.Builder itself: <markup lang=\"java\" >WebServer.builder(routing()) .tls(webServerTls) .build(); ",
            "title": "SSL/TLS"
        },
        {
            "location": "/se/guides/15_migration",
            "text": " Additional socket configuration has changed both in config and in API. The configuration now accepts following structure: <markup lang=\"yaml\" >server: port: 8000 sockets: - name: \"admin\" port: 8001 - name: \"static\" port: 8002 enabled: false Socket name is now a value of a property, allowing more freedom in naming. The default socket name is implicit (and set to @default ). We have added the enabled flag to support disabling sockets through configuration. To add socket using a builder, you can use: <markup lang=\"java\" >WebServer.builder() .addSocket(SocketConfigurationBuilder.builder() .port(8001) .name(\"admin\"))); There is also a specialized method to add a socket and routing together, to remove mapping through a name. ",
            "title": "Additional Sockets"
        },
        {
            "location": "/se/guides/15_migration",
            "text": " io.helidon.webserver.ServerConfiguration.Builder is no longer used to configure WebServer . Most methods from this class have been moved to WebServer.Builder or deprecated. Example of a simple WebServer setup: <markup lang=\"java\" >WebServer.builder() .port(8001) .host(\"localhost\") .routing(createRouting()) .build(); ",
            "title": "Deprecation of ServerConfiguration"
        },
        {
            "location": "/se/guides/15_migration",
            "text": " io.helidon.webserver.WebServer.Builder - all methods that accept ServerConfiguration or its builder are deprecated, please use methods on WebServer.Builder instead io.helidon.webserver.WebServer.Builder - all methods for socket configuration that accept a name and socket are deprecated, socket name is now part of socket configuration itself io.helidon.webserver.ResponseHeaders.whenSend() - please use whenSent() io.helidon.webserver.Routing.createServer(ServerConfiguration) - please use WebServer.builder() io.helidon.webserver.Routing.createServer() - please use WebServer.builder() io.helidon.webserver.SocketConfiguration.DEFAULT - use a builder to create a named configuration io.helidon.webserver.SocketConfiguration.Builder.ssl(SSLContext) - use `WebServerTls instead io.helidon.webserver.SocketConfiguration.Builder.enabledSSlProtocols(String&#8230;&#8203;) - use `WebServerTls instead ",
            "title": "Other Significant WebServer Deprecations"
        },
        {
            "location": "/se/guides/15_migration",
            "text": " SSL/TLS There is a new class io.helidon.webserver.WebServerTls that can be used to configure TLS for a WebServer socket. Class io.helidon.webserver.SSLContextBuilder has been deprecated and will be removed. The class uses a Builder pattern: <markup lang=\"java\" >WebServerTls.builder() .privateKey(KeyConfig.keystoreBuilder() .keystore(Resource.create(\"certificate.p12\")) .keystorePassphrase(\"helidon\") The builder or built instance can be registered with a socket configuration builder including the WebServer.Builder itself: <markup lang=\"java\" >WebServer.builder(routing()) .tls(webServerTls) .build(); Additional Sockets Additional socket configuration has changed both in config and in API. The configuration now accepts following structure: <markup lang=\"yaml\" >server: port: 8000 sockets: - name: \"admin\" port: 8001 - name: \"static\" port: 8002 enabled: false Socket name is now a value of a property, allowing more freedom in naming. The default socket name is implicit (and set to @default ). We have added the enabled flag to support disabling sockets through configuration. To add socket using a builder, you can use: <markup lang=\"java\" >WebServer.builder() .addSocket(SocketConfigurationBuilder.builder() .port(8001) .name(\"admin\"))); There is also a specialized method to add a socket and routing together, to remove mapping through a name. Deprecation of ServerConfiguration io.helidon.webserver.ServerConfiguration.Builder is no longer used to configure WebServer . Most methods from this class have been moved to WebServer.Builder or deprecated. Example of a simple WebServer setup: <markup lang=\"java\" >WebServer.builder() .port(8001) .host(\"localhost\") .routing(createRouting()) .build(); Other Significant WebServer Deprecations io.helidon.webserver.WebServer.Builder - all methods that accept ServerConfiguration or its builder are deprecated, please use methods on WebServer.Builder instead io.helidon.webserver.WebServer.Builder - all methods for socket configuration that accept a name and socket are deprecated, socket name is now part of socket configuration itself io.helidon.webserver.ResponseHeaders.whenSend() - please use whenSent() io.helidon.webserver.Routing.createServer(ServerConfiguration) - please use WebServer.builder() io.helidon.webserver.Routing.createServer() - please use WebServer.builder() io.helidon.webserver.SocketConfiguration.DEFAULT - use a builder to create a named configuration io.helidon.webserver.SocketConfiguration.Builder.ssl(SSLContext) - use `WebServerTls instead io.helidon.webserver.SocketConfiguration.Builder.enabledSSlProtocols(String&#8230;&#8203;) - use `WebServerTls instead ",
            "title": "WebServer Configuration"
        },
        {
            "location": "/mp/guides/36_graalnative",
            "text": " This guide describes how to build a GraalVM native image for a Helidon MP application. ",
            "title": "preambule"
        },
        {
            "location": "/mp/guides/36_graalnative",
            "text": " Native images are ahead-of-time compiled Java code that result in a self contained native executable. When used appropriately native images have dramatically faster startup and lower runtime memory overhead compared to a Java VM. In this guide you will learn how to build a native image locally on your machine, as well as using Docker. ",
            "title": "Introduction"
        },
        {
            "location": "/mp/guides/36_graalnative",
            "text": " For this 10 minute tutorial, you will need the following: <div class=\"table__overflow elevation-1 flex sm7 \"> A Helidon {upper-case-flavor} Application You can use your own application or use the Helidon {upper-case-flavor} Quickstart to create a sample application. Java&#160;SE&#160;11 ( Open&#160;JDK&#160;11 ) Helidon requires Java 11+. Maven 3.6.1+ Helidon requires Maven 3.6.1+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop ). GraalVM CE 21.0.0 <markup lang=\"bash\" title=\"Verify Prerequisites\" >java -version mvn --version docker --version kubectl version --short <markup lang=\"bash\" title=\"Setting JAVA_HOME\" ># On Mac export JAVA_HOME=`/usr/libexec/java_home -v 11` # On Linux # Use the appropriate path to your JDK export JAVA_HOME=/usr/lib/jvm/jdk-11 ",
            "title": "What You Need"
        },
        {
            "location": "/mp/guides/36_graalnative",
            "text": " After downloading and installing GraalVM, set the GRAALVM_HOME environment variable to point at your GraalVM installation. <markup lang=\"bash\" ># Your path might be different export GRAALVM_HOME=/usr/local/graalvm-ce-21.3.0/Contents/Home/ Then install the optional native-image command: <markup lang=\"bash\" >$GRAALVM_HOME/bin/gu install native-image And verify: <markup lang=\"bash\" >$GRAALVM_HOME/bin/java -version $GRAALVM_HOME/bin/native-image --version ",
            "title": "Install GraalVM and the Native Image Command"
        },
        {
            "location": "/mp/guides/36_graalnative",
            "text": " Generate the project using the Helidon MP Quickstart Maven archetype. <markup lang=\"bash\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-mp \\ -DarchetypeVersion=2.5.4 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-mp \\ -Dpackage=io.helidon.examples.quickstart.mp The archetype generates a Maven project in your current directory (for example, helidon-quickstart-mp ). Change into this directory and build. <markup lang=\"bash\" >cd helidon-quickstart-mp mvn package At this point you can run the application using the JVM: <markup lang=\"bash\" >java -jar target/helidon-quickstart-mp.jar In another shell test an endpoint: <markup lang=\"bash\" >curl -X GET http://localhost:8080/greet The application should respond with {\"message\":\"Hello World!\"} Now stop the running application (by pressing Ctrl+C). For more information about the Quickstart application and other enpoints it supports see the Helidon MP Quickstart Guide . ",
            "title": "Generate the Project"
        },
        {
            "location": "/mp/guides/36_graalnative",
            "text": " Make sure you have GraalVM locally installed: <markup lang=\"bash\" >$GRAALVM_HOME/bin/native-image --version Build the native image using the native image profile: <markup lang=\"bash\" >mvn package -Pnative-image Tip This uses the helidon-maven-plugin to perform the native compilation using your installed copy of GraalVM. It might take a while to complete. Once it completes start the application using the native executable (no JVM!): <markup lang=\"bash\" >./target/helidon-quickstart-mp Yep, it starts fast. You can exercise the application&#8217;s endpoints as before. ",
            "title": "Local build"
        },
        {
            "location": "/mp/guides/36_graalnative",
            "text": " Build the \"native\" Docker image <markup lang=\"bash\" >docker build -t helidon-quickstart-mp-native -f Dockerfile.native . Tip This does a full build inside the Docker container. The first time you run it, it will take a while because it is downloading all of the Maven dependencies and caching them in a Docker layer. Subsequent builds will be much faster as long as you don&#8217;t change the pom.xml file. If the pom is modified then the dependencies will be re-downloaded. Start the application: <markup lang=\"bash\" >docker run --rm -p 8080:8080 helidon-quickstart-mp-native:latest Again, it starts fast. You can exercise the application&#8217;s endpoints as before. ",
            "title": "Multi-stage Docker build"
        },
        {
            "location": "/mp/guides/36_graalnative",
            "text": " You can build a native executable in 2 different ways: With a local installation of GraalVM Using Docker Local build Make sure you have GraalVM locally installed: <markup lang=\"bash\" >$GRAALVM_HOME/bin/native-image --version Build the native image using the native image profile: <markup lang=\"bash\" >mvn package -Pnative-image Tip This uses the helidon-maven-plugin to perform the native compilation using your installed copy of GraalVM. It might take a while to complete. Once it completes start the application using the native executable (no JVM!): <markup lang=\"bash\" >./target/helidon-quickstart-mp Yep, it starts fast. You can exercise the application&#8217;s endpoints as before. Multi-stage Docker build Build the \"native\" Docker image <markup lang=\"bash\" >docker build -t helidon-quickstart-mp-native -f Dockerfile.native . Tip This does a full build inside the Docker container. The first time you run it, it will take a while because it is downloading all of the Maven dependencies and caching them in a Docker layer. Subsequent builds will be much faster as long as you don&#8217;t change the pom.xml file. If the pom is modified then the dependencies will be re-downloaded. Start the application: <markup lang=\"bash\" >docker run --rm -p 8080:8080 helidon-quickstart-mp-native:latest Again, it starts fast. You can exercise the application&#8217;s endpoints as before. ",
            "title": "Building a Native Image"
        },
        {
            "location": "/mp/guides/36_graalnative",
            "text": " Native images are ideal for applications with high horizontal scalability requirements where the ability to rapidly scale out to numerous instances is important. That said, native images do have some limitations , and for long running applications where startup and footprint are less of a priority, the Java SE HotSpot VM might be more appropriate. For information about creating custom Java runtime images see Custom Runtime Images with jlink ",
            "title": "When should I use Native Images?"
        },
        {
            "location": "/mp/guides/04_health",
            "text": " This guide describes how to create a sample MicroProfile (MP) project that can be used to run some basic examples using both built-in and custom health checks with Helidon MP. ",
            "title": "preambule"
        },
        {
            "location": "/mp/guides/04_health",
            "text": " Generate the project sources using the Helidon MP Maven archetype. The result is a simple project that can be used for the examples in this guide. <markup lang=\"bash\" title=\"Run the Maven archetype:\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-mp \\ -DarchetypeVersion=2.5.4 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-mp \\ -Dpackage=io.helidon.examples.quickstart.mp ",
            "title": "Create a Sample MP Project"
        },
        {
            "location": "/mp/guides/04_health",
            "text": " Helidon has a set of built-in health checks that are automatically enabled to report various health check statuses that are commonly used: deadlock detection available disk space available heap memory The following example will demonstrate how to use the built-in health checks. These examples are all executed from the root directory of your project (helidon-quickstart-mp). <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-mp.jar <markup lang=\"bash\" title=\"Verify the health endpoint in a new terminal window:\" >curl http://localhost:8080/health <markup lang=\"json\" title=\"JSON response:\" >{ \"outcome\": \"UP\", \"status\": \"UP\", \"checks\": [ { \"name\": \"deadlock\", \"state\": \"UP\", \"status\": \"UP\" }, { \"name\": \"diskSpace\", \"state\": \"UP\", \"status\": \"UP\", \"data\": { \"free\": \"325.54 GB\", \"freeBytes\": 349543358464, \"percentFree\": \"69.91%\", \"total\": \"465.63 GB\", \"totalBytes\": 499963174912 } }, { \"name\": \"heapMemory\", \"state\": \"UP\", \"status\": \"UP\", \"data\": { \"free\": \"230.87 MB\", \"freeBytes\": 242085696, \"max\": \"3.56 GB\", \"maxBytes\": 3817865216, \"percentFree\": \"98.90%\", \"total\": \"271.00 MB\", \"totalBytes\": 284164096 } } ] } In MicroProfile Health 2.0 outcome and state were replaced by status in the JSON response wire format. Helidon currently provides both fields for backwards compatibility, but use of outcome and state is deprecated and will be removed in a future release. You should rely on status instead. ",
            "title": "Using the Built-In Health Checks"
        },
        {
            "location": "/mp/guides/04_health",
            "text": " You can create application-specific custom health checks and integrate them with Helidon using CDI. The following example shows how to add a custom liveness health check. <markup lang=\"java\" title=\"Create a new GreetLivenessCheck class with the following content:\" >package io.helidon.examples.quickstart.mp; import javax.enterprise.context.ApplicationScoped; import org.eclipse.microprofile.health.HealthCheck; import org.eclipse.microprofile.health.HealthCheckResponse; import org.eclipse.microprofile.health.Liveness; @Liveness @ApplicationScoped public class GreetLivenessCheck implements HealthCheck { private GreetingProvider provider; @Override public HealthCheckResponse call() { return HealthCheckResponse.named(\"LivenessCheck\") .up() .withData(\"time\", System.currentTimeMillis()) .build(); } } Annotation indicating this is a liveness health check. Annotation indicating there is a single liveness HealthCheck object during the lifetime of the application. Build the HealthCheckResponse with status UP and the current time. <markup lang=\"bash\" title=\"Build and run the application, then verify the custom liveness health endpoint:\" >curl http://localhost:8080/health/live <markup lang=\"json\" title=\"JSON response:\" >{ \"outcome\": \"UP\", \"status\": \"UP\", \"checks\": [ { \"name\": \"LivenessCheck\", \"state\": \"UP\", \"status\": \"UP\", \"data\": { \"time\": 1566338255331 } } ] } ",
            "title": "Custom Liveness Health Checks"
        },
        {
            "location": "/mp/guides/04_health",
            "text": " You can add a readiness check to indicate that the application is ready to be used. In this example, the server will wait five seconds before it becomes ready. <markup lang=\"java\" title=\"Create a new GreetReadinessCheck class with the following content:\" >package io.helidon.examples.quickstart.mp; import java.time.Duration; import java.util.concurrent.atomic.AtomicLong; import javax.enterprise.context.ApplicationScoped; import javax.enterprise.context.Initialized; import javax.enterprise.event.Observes; import org.eclipse.microprofile.health.HealthCheck; import org.eclipse.microprofile.health.HealthCheckResponse; import org.eclipse.microprofile.health.Readiness; @Readiness @ApplicationScoped public class GreetReadinessCheck implements HealthCheck { private AtomicLong readyTime = new AtomicLong(0); @Override public HealthCheckResponse call() { return HealthCheckResponse.named(\"ReadinessCheck\") .state(isReady()) .withData(\"time\", readyTime.get()) .build(); } public void onStartUp( @Observes @Initialized(ApplicationScoped.class) Object init) { readyTime = new AtomicLong(System.currentTimeMillis()); } /** * Become ready after 5 seconds * * @return true if application ready */ private boolean isReady() { return Duration.ofMillis(System.currentTimeMillis() - readyTime.get()).getSeconds() &gt;= 5; } } Include additional imports. Annotation indicating that this is a readiness health-check. Build the HealthCheckResponse with status UP after five seconds, else DOWN . Initialize the time at startup. <markup lang=\"bash\" title=\"Build and run the application. Issue the curl command with -v within five seconds and you will see that the application is not ready:\" >curl -v http://localhost:8080/health/ready <markup lang=\"json\" title=\"HTTP response:\" >... &lt; HTTP/1.1 503 Service Unavailable ... { \"outcome\": \"DOWN\", \"status\": \"DOWN\", \"checks\": [ { \"name\": \"ReadinessCheck\", \"state\": \"DOWN\", \"status\": \"DOWN\", \"data\": { \"time\": 1566399775700 } } ] } The HTTP status is 503 since the application is not ready. <markup lang=\"bash\" title=\"After five seconds you will see the application is ready:\" >curl -v http://localhost:8080/health/ready <markup lang=\"json\" title=\"JSON response:\" >... &lt; HTTP/1.1 200 OK ... { \"outcome\": \"UP\", \"status\": \"UP\", \"checks\": [ { \"name\": \"ReadinessCheck\", \"state\": \"UP\", \"status\": \"UP\", \"data\": { \"time\": 1566399775700 } } ] } The HTTP status is 200 indicating that the application is ready. When using the health check URLs, you can get the following health check data: custom liveness only - http://localhost:8080/health/live custom readiness only - http://localhost:8080/health/ready all health check data - http://localhost:8080/health <markup lang=\"bash\" title=\"Get all the health check data, including custom data:\" >curl http://localhost:8080/health <markup lang=\"json\" title=\"JSON response:\" >{ \"outcome\": \"UP\", \"status\": \"UP\", \"checks\": [ { \"name\": \"LivenessCheck\", \"state\": \"UP\", \"status\": \"UP\", \"data\": { \"time\": 1566403431536 } }, { \"name\": \"ReadinessCheck\", \"state\": \"UP\", \"status\": \"UP\", \"data\": { \"time\": 1566403280639 } }, { \"name\": \"deadlock\", \"state\": \"UP\", \"status\": \"UP\" }, { \"name\": \"diskSpace\", \"state\": \"UP\", \"status\": \"UP\", \"data\": { \"free\": \"325.50 GB\", \"freeBytes\": 349500698624, \"percentFree\": \"69.91%\", \"total\": \"465.63 GB\", \"totalBytes\": 499963174912 } }, { \"name\": \"heapMemory\", \"state\": \"UP\", \"status\": \"UP\", \"data\": { \"free\": \"231.01 MB\", \"freeBytes\": 242235928, \"max\": \"3.56 GB\", \"maxBytes\": 3817865216, \"percentFree\": \"98.79%\", \"total\": \"275.00 MB\", \"totalBytes\": 288358400 } } ] } ",
            "title": "Custom Readiness Health Check"
        },
        {
            "location": "/mp/guides/04_health",
            "text": " You can specify a custom port and root context for the root health endpoint path. However, you cannot use different ports, such as http://localhost:8080/myhealth and http://localhost:8081/myhealth/live . Likewise, you cannot use different paths, such as http://localhost:8080/health and http://localhost:8080/probe/live . The example below will change the root path. <markup lang=\"yaml\" title=\"Create a file named application.yaml in the resources directory with the following contents:\" >health: web-context: \"myhealth\" The web-context specifies a new root path for the health endpoint. <markup lang=\"bash\" title=\"Build and run the application, then verify that the health endpoint is using the new /myhealth root:\" >curl http://localhost:8080/myhealth curl http://localhost:8080/myhealth/live curl http://localhost:8080/myhealth/ready The following example will change the root path and the health port. <markup lang=\"yaml\" title=\"Update application.yaml to use a different port and root path for the health endpoint:\" >server: port: 8080 host: \"localhost\" sockets: health: port: 8081 bind-address: \"localhost\" health: routing: \"health\" web-context: \"myhealth\" The default port for the application. The name of the new socket, it can be any name, this example uses health . The port for the new health socket. The health endpoint routing uses the new socket health . <markup lang=\"bash\" title=\"Build and run the application, then verify the health endpoint using port 8081 and /myhealth :\" >curl http://localhost:8081/myhealth curl http://localhost:8081/myhealth/live curl http://localhost:8081/myhealth/ready ",
            "title": "Custom Health Root Path and Port"
        },
        {
            "location": "/mp/guides/04_health",
            "text": " The following example shows how to integrate the Helidon health check API with an application that implements health endpoints for the Kubernetes liveness and readiness probes. Delete the contents of application.yaml so that the default health endpoint path and port are used. <markup lang=\"bash\" title=\"Rebuild and start the application, then verify the health endpoint:\" >curl http://localhost:8080/health <markup lang=\"bash\" title=\"Stop the application and build the docker image:\" >docker build -t helidon-quickstart-mp . <markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named health.yaml , with the following content:\" >kind: Service apiVersion: v1 metadata: name: helidon-health labels: app: helidon-health spec: type: NodePort selector: app: helidon-health ports: - port: 8080 targetPort: 8080 name: http --- kind: Deployment apiVersion: apps/v1 metadata: name: helidon-health spec: replicas: 1 selector: matchLabels: app: helidon-health template: metadata: labels: app: helidon-health version: v1 spec: containers: - name: helidon-health image: helidon-quickstart-mp imagePullPolicy: IfNotPresent ports: - containerPort: 8080 livenessProbe: httpGet: path: /health/live port: 8080 initialDelaySeconds: 5 periodSeconds: 10 timeoutSeconds: 3 failureThreshold: 3 readinessProbe: httpGet: path: /health/ready port: 8080 initialDelaySeconds: 5 periodSeconds: 2 timeoutSeconds: 3 --- A service of type NodePort that serves the default routes on port 8080 . A deployment with one replica of a pod. The HTTP endpoint for the liveness probe. The liveness probe configuration. The HTTP endpoint for the readiness probe. The readiness probe configuration. <markup lang=\"bash\" title=\"Create and deploy the application into Kubernetes:\" >kubectl apply -f ./health.yaml <markup lang=\"bash\" title=\"Get the service information:\" >kubectl get service/helidon-health <markup lang=\"bash\" >NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE helidon-health NodePort 10.107.226.62 &lt;none&gt; 8080:30116/TCP 4s A service of type NodePort that serves the default routes on port 30116 . <markup lang=\"bash\" title=\"Verify the health endpoints using port '30116', your port may be different. The JSON response will be the same as your previous test:\" >curl http://localhost:30116/health <markup lang=\"bash\" title=\"Delete the application, cleaning up Kubernetes resources:\" >kubectl delete -f ./health.yaml ",
            "title": "Using Liveness and Readiness Health Checks with Kubernetes"
        },
        {
            "location": "/mp/guides/04_health",
            "text": " This guide demonstrated how to use health checks in a Helidon MP application as follows: Access the default health checks Create and use custom readiness and liveness checks Customize the health check root path and port Integrate Helidon health check API with Kubernetes Refer to the following references for additional information: MicroProfile health-check specification at https://github.com/eclipse/microprofile-health/releases/tag/2.0 MicroProfile health-check Javadoc at https://javadoc.io/doc/org.eclipse.microprofile.health/microprofile-health-api/2.0 Helidon Javadoc at https://helidon.io/docs/latest/apidocs/index.html?overview-summary.html ",
            "title": "Summary"
        },
        {
            "location": "/mp/guides/04_health",
            "text": " For this 15 minute tutorial, you will need the following: <div class=\"table__overflow elevation-1 flex sm7 \"> A Helidon {upper-case-flavor} Application You can use your own application or use the Helidon {upper-case-flavor} Quickstart to create a sample application. Java&#160;SE&#160;11 ( Open&#160;JDK&#160;11 ) Helidon requires Java 11+. Maven 3.6.1+ Helidon requires Maven 3.6.1+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop ). <markup lang=\"bash\" title=\"Verify Prerequisites\" >java -version mvn --version docker --version kubectl version --short <markup lang=\"bash\" title=\"Setting JAVA_HOME\" ># On Mac export JAVA_HOME=`/usr/libexec/java_home -v 11` # On Linux # Use the appropriate path to your JDK export JAVA_HOME=/usr/lib/jvm/jdk-11 Create a Sample MP Project Generate the project sources using the Helidon MP Maven archetype. The result is a simple project that can be used for the examples in this guide. <markup lang=\"bash\" title=\"Run the Maven archetype:\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-mp \\ -DarchetypeVersion=2.5.4 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-mp \\ -Dpackage=io.helidon.examples.quickstart.mp Using the Built-In Health Checks Helidon has a set of built-in health checks that are automatically enabled to report various health check statuses that are commonly used: deadlock detection available disk space available heap memory The following example will demonstrate how to use the built-in health checks. These examples are all executed from the root directory of your project (helidon-quickstart-mp). <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-mp.jar <markup lang=\"bash\" title=\"Verify the health endpoint in a new terminal window:\" >curl http://localhost:8080/health <markup lang=\"json\" title=\"JSON response:\" >{ \"outcome\": \"UP\", \"status\": \"UP\", \"checks\": [ { \"name\": \"deadlock\", \"state\": \"UP\", \"status\": \"UP\" }, { \"name\": \"diskSpace\", \"state\": \"UP\", \"status\": \"UP\", \"data\": { \"free\": \"325.54 GB\", \"freeBytes\": 349543358464, \"percentFree\": \"69.91%\", \"total\": \"465.63 GB\", \"totalBytes\": 499963174912 } }, { \"name\": \"heapMemory\", \"state\": \"UP\", \"status\": \"UP\", \"data\": { \"free\": \"230.87 MB\", \"freeBytes\": 242085696, \"max\": \"3.56 GB\", \"maxBytes\": 3817865216, \"percentFree\": \"98.90%\", \"total\": \"271.00 MB\", \"totalBytes\": 284164096 } } ] } In MicroProfile Health 2.0 outcome and state were replaced by status in the JSON response wire format. Helidon currently provides both fields for backwards compatibility, but use of outcome and state is deprecated and will be removed in a future release. You should rely on status instead. Custom Liveness Health Checks You can create application-specific custom health checks and integrate them with Helidon using CDI. The following example shows how to add a custom liveness health check. <markup lang=\"java\" title=\"Create a new GreetLivenessCheck class with the following content:\" >package io.helidon.examples.quickstart.mp; import javax.enterprise.context.ApplicationScoped; import org.eclipse.microprofile.health.HealthCheck; import org.eclipse.microprofile.health.HealthCheckResponse; import org.eclipse.microprofile.health.Liveness; @Liveness @ApplicationScoped public class GreetLivenessCheck implements HealthCheck { private GreetingProvider provider; @Override public HealthCheckResponse call() { return HealthCheckResponse.named(\"LivenessCheck\") .up() .withData(\"time\", System.currentTimeMillis()) .build(); } } Annotation indicating this is a liveness health check. Annotation indicating there is a single liveness HealthCheck object during the lifetime of the application. Build the HealthCheckResponse with status UP and the current time. <markup lang=\"bash\" title=\"Build and run the application, then verify the custom liveness health endpoint:\" >curl http://localhost:8080/health/live <markup lang=\"json\" title=\"JSON response:\" >{ \"outcome\": \"UP\", \"status\": \"UP\", \"checks\": [ { \"name\": \"LivenessCheck\", \"state\": \"UP\", \"status\": \"UP\", \"data\": { \"time\": 1566338255331 } } ] } Custom Readiness Health Check You can add a readiness check to indicate that the application is ready to be used. In this example, the server will wait five seconds before it becomes ready. <markup lang=\"java\" title=\"Create a new GreetReadinessCheck class with the following content:\" >package io.helidon.examples.quickstart.mp; import java.time.Duration; import java.util.concurrent.atomic.AtomicLong; import javax.enterprise.context.ApplicationScoped; import javax.enterprise.context.Initialized; import javax.enterprise.event.Observes; import org.eclipse.microprofile.health.HealthCheck; import org.eclipse.microprofile.health.HealthCheckResponse; import org.eclipse.microprofile.health.Readiness; @Readiness @ApplicationScoped public class GreetReadinessCheck implements HealthCheck { private AtomicLong readyTime = new AtomicLong(0); @Override public HealthCheckResponse call() { return HealthCheckResponse.named(\"ReadinessCheck\") .state(isReady()) .withData(\"time\", readyTime.get()) .build(); } public void onStartUp( @Observes @Initialized(ApplicationScoped.class) Object init) { readyTime = new AtomicLong(System.currentTimeMillis()); } /** * Become ready after 5 seconds * * @return true if application ready */ private boolean isReady() { return Duration.ofMillis(System.currentTimeMillis() - readyTime.get()).getSeconds() &gt;= 5; } } Include additional imports. Annotation indicating that this is a readiness health-check. Build the HealthCheckResponse with status UP after five seconds, else DOWN . Initialize the time at startup. <markup lang=\"bash\" title=\"Build and run the application. Issue the curl command with -v within five seconds and you will see that the application is not ready:\" >curl -v http://localhost:8080/health/ready <markup lang=\"json\" title=\"HTTP response:\" >... &lt; HTTP/1.1 503 Service Unavailable ... { \"outcome\": \"DOWN\", \"status\": \"DOWN\", \"checks\": [ { \"name\": \"ReadinessCheck\", \"state\": \"DOWN\", \"status\": \"DOWN\", \"data\": { \"time\": 1566399775700 } } ] } The HTTP status is 503 since the application is not ready. <markup lang=\"bash\" title=\"After five seconds you will see the application is ready:\" >curl -v http://localhost:8080/health/ready <markup lang=\"json\" title=\"JSON response:\" >... &lt; HTTP/1.1 200 OK ... { \"outcome\": \"UP\", \"status\": \"UP\", \"checks\": [ { \"name\": \"ReadinessCheck\", \"state\": \"UP\", \"status\": \"UP\", \"data\": { \"time\": 1566399775700 } } ] } The HTTP status is 200 indicating that the application is ready. When using the health check URLs, you can get the following health check data: custom liveness only - http://localhost:8080/health/live custom readiness only - http://localhost:8080/health/ready all health check data - http://localhost:8080/health <markup lang=\"bash\" title=\"Get all the health check data, including custom data:\" >curl http://localhost:8080/health <markup lang=\"json\" title=\"JSON response:\" >{ \"outcome\": \"UP\", \"status\": \"UP\", \"checks\": [ { \"name\": \"LivenessCheck\", \"state\": \"UP\", \"status\": \"UP\", \"data\": { \"time\": 1566403431536 } }, { \"name\": \"ReadinessCheck\", \"state\": \"UP\", \"status\": \"UP\", \"data\": { \"time\": 1566403280639 } }, { \"name\": \"deadlock\", \"state\": \"UP\", \"status\": \"UP\" }, { \"name\": \"diskSpace\", \"state\": \"UP\", \"status\": \"UP\", \"data\": { \"free\": \"325.50 GB\", \"freeBytes\": 349500698624, \"percentFree\": \"69.91%\", \"total\": \"465.63 GB\", \"totalBytes\": 499963174912 } }, { \"name\": \"heapMemory\", \"state\": \"UP\", \"status\": \"UP\", \"data\": { \"free\": \"231.01 MB\", \"freeBytes\": 242235928, \"max\": \"3.56 GB\", \"maxBytes\": 3817865216, \"percentFree\": \"98.79%\", \"total\": \"275.00 MB\", \"totalBytes\": 288358400 } } ] } Custom Health Root Path and Port You can specify a custom port and root context for the root health endpoint path. However, you cannot use different ports, such as http://localhost:8080/myhealth and http://localhost:8081/myhealth/live . Likewise, you cannot use different paths, such as http://localhost:8080/health and http://localhost:8080/probe/live . The example below will change the root path. <markup lang=\"yaml\" title=\"Create a file named application.yaml in the resources directory with the following contents:\" >health: web-context: \"myhealth\" The web-context specifies a new root path for the health endpoint. <markup lang=\"bash\" title=\"Build and run the application, then verify that the health endpoint is using the new /myhealth root:\" >curl http://localhost:8080/myhealth curl http://localhost:8080/myhealth/live curl http://localhost:8080/myhealth/ready The following example will change the root path and the health port. <markup lang=\"yaml\" title=\"Update application.yaml to use a different port and root path for the health endpoint:\" >server: port: 8080 host: \"localhost\" sockets: health: port: 8081 bind-address: \"localhost\" health: routing: \"health\" web-context: \"myhealth\" The default port for the application. The name of the new socket, it can be any name, this example uses health . The port for the new health socket. The health endpoint routing uses the new socket health . <markup lang=\"bash\" title=\"Build and run the application, then verify the health endpoint using port 8081 and /myhealth :\" >curl http://localhost:8081/myhealth curl http://localhost:8081/myhealth/live curl http://localhost:8081/myhealth/ready Using Liveness and Readiness Health Checks with Kubernetes The following example shows how to integrate the Helidon health check API with an application that implements health endpoints for the Kubernetes liveness and readiness probes. Delete the contents of application.yaml so that the default health endpoint path and port are used. <markup lang=\"bash\" title=\"Rebuild and start the application, then verify the health endpoint:\" >curl http://localhost:8080/health <markup lang=\"bash\" title=\"Stop the application and build the docker image:\" >docker build -t helidon-quickstart-mp . <markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named health.yaml , with the following content:\" >kind: Service apiVersion: v1 metadata: name: helidon-health labels: app: helidon-health spec: type: NodePort selector: app: helidon-health ports: - port: 8080 targetPort: 8080 name: http --- kind: Deployment apiVersion: apps/v1 metadata: name: helidon-health spec: replicas: 1 selector: matchLabels: app: helidon-health template: metadata: labels: app: helidon-health version: v1 spec: containers: - name: helidon-health image: helidon-quickstart-mp imagePullPolicy: IfNotPresent ports: - containerPort: 8080 livenessProbe: httpGet: path: /health/live port: 8080 initialDelaySeconds: 5 periodSeconds: 10 timeoutSeconds: 3 failureThreshold: 3 readinessProbe: httpGet: path: /health/ready port: 8080 initialDelaySeconds: 5 periodSeconds: 2 timeoutSeconds: 3 --- A service of type NodePort that serves the default routes on port 8080 . A deployment with one replica of a pod. The HTTP endpoint for the liveness probe. The liveness probe configuration. The HTTP endpoint for the readiness probe. The readiness probe configuration. <markup lang=\"bash\" title=\"Create and deploy the application into Kubernetes:\" >kubectl apply -f ./health.yaml <markup lang=\"bash\" title=\"Get the service information:\" >kubectl get service/helidon-health <markup lang=\"bash\" >NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE helidon-health NodePort 10.107.226.62 &lt;none&gt; 8080:30116/TCP 4s A service of type NodePort that serves the default routes on port 30116 . <markup lang=\"bash\" title=\"Verify the health endpoints using port '30116', your port may be different. The JSON response will be the same as your previous test:\" >curl http://localhost:30116/health <markup lang=\"bash\" title=\"Delete the application, cleaning up Kubernetes resources:\" >kubectl delete -f ./health.yaml Summary This guide demonstrated how to use health checks in a Helidon MP application as follows: Access the default health checks Create and use custom readiness and liveness checks Customize the health check root path and port Integrate Helidon health check API with Kubernetes Refer to the following references for additional information: MicroProfile health-check specification at https://github.com/eclipse/microprofile-health/releases/tag/2.0 MicroProfile health-check Javadoc at https://javadoc.io/doc/org.eclipse.microprofile.health/microprofile-health-api/2.0 Helidon Javadoc at https://helidon.io/docs/latest/apidocs/index.html?overview-summary.html ",
            "title": "What You Need"
        },
        {
            "location": "/se/config/03_hierarchical-features",
            "text": " The config system represents configuration as a tree in memory. Many developers will choose to work directly with config values&#8201;&#8212;&#8201;values from the leaves in the tree&#8201;&#8212;&#8201;accessing them by their keys. You can also navigate explicitly among the nodes of the tree without using keys. This section describes what the tree looks like and how you can traverse it. ",
            "title": "preambule"
        },
        {
            "location": "/se/config/03_hierarchical-features",
            "text": " The config system represents configuration in memory using three types of nodes, each a different interface defined within the ConfigNode interface. ConfigNode Types Type Java Interface Usage object ConfigNode.ObjectNode Represents complex structure (a subtree). Its child nodes can be of any type. list ConfigNode.ListNode Represents a list of nodes. Its components can be of any type. value ConfigNode.ValueNode Represents a leaf node. A node of any type can have a String value. Each config tree in memory will have an object node as its root with child nodes as dictated by the source config data from which the config system built the tree. Missing Config Nodes If your application attempts to access a non-existent node, for example using <markup lang=\"java\" >config.get(\"key.does.not.exist\") the config system returns a Config node object with type MISSING . The in-memory config tree contains nodes only of types OBJECT , LIST , and VALUE . ",
            "title": "Configuration Node Types"
        },
        {
            "location": "/se/config/03_hierarchical-features",
            "text": " The following example is in HOCON (human-optimized config object notation) format. The config system supports HOCON as an extension module . <markup lang=\"hocon\" title=\"HOCON application.conf file\" >app { greeting = \"Hello\" page-size = 20 basic-range = [ -20, 20 ] } data { providers: [ { name = \"Provider1\" class = \"this.is.my.Provider1\" }, { name = \"Provider2\" class = \"this.is.my.Provider2\" } ] } The diagram below illustrates the in-memory tree for that configuration. Config Nodes structure of application.conf file Notes Each non-root node has a name which distinguishes it from other nodes with the same parent. The interpretation of the name depends on the node type. Node Type Name object value member name of the node within its parent list element index of the node within the containing list Each node&#8217;s key is the fully-qualified path using dotted names from the root to that node. The root has an empty key, empty name, and no value. The Config object exposes methods to return the name , key , and type of the node. ",
            "title": "In-memory Representation of Configuration"
        },
        {
            "location": "/se/config/03_hierarchical-features",
            "text": " For many applications, accessing configuration values by key will be the simplest approach. If you write the code with a specific configuration structure in mind, your code can retrieve the value from a specific configuration node very easily. Your application can specify the entire navigation path as the key to a single get invocation, using dotted notation to separate the names of the nodes along the path. The code can navigate one level at a time using chained get invocations, each specifying one level of the path to the expected node. Or, you can mix the two styles. All of the following lines retrieve the same Config node. <markup lang=\"java\" title=\"Equivalent Config Retrievals\" >assert config.get(\"\") == config; Config provName1 = config.get(\"data.providers.0.name\"); Config provName2 = config.get(\"data.providers.0\").get(\"name\"); Config provName3 = config.get(\"data.providers\").get(\"0.name\"); Config provName4 = config.get(\"data\").get(\"providers.0\").get(\"name\"); Config provName5 = config.get(\"data\").get(\"providers\").get(\"0\").get(\"name\"); using a single key mixed style (composite key and single key) navigating one level with each get invocation The Config.get(key) method always returns a Config object without throwing an exception. If the specified key does not exist the method returns a Config node of type MISSING . There are several ways your application can tell whether a given config value exists. Method Usage exists Returns true or false ifExists Execute functional operations for present nodes type Returns enum value for the Config.Type ; Config.Type.MISSING if the node represents a config value that does not exist as Returns the ConfigValue with the correct type that has all methods of Optional and a few additional ones - see ConfigValue interface. The config system throws a MissingValueException if the application tries to access the value of a missing node by invoking the ConfigValue.get() method. ",
            "title": "Access by Key"
        },
        {
            "location": "/se/config/03_hierarchical-features",
            "text": " Some applications might need to work with configuration without knowing its structure or key names ahead of time, and such applications can use various methods on the Config class to do this. General Config Node Methods Method Usage asNodeList() Returns a ConfigValue&lt;List&lt;Config&gt;&gt;. For nodes of type OBJECT contains child nodes as a List . hasValue() For any node reports if the node has a value. This can be true for any node type except MISSING . isLeaf() Reports whether the node has no child nodes. Leaf nodes have no children and has a single value. key() Returns the fully-qualified path of the node using dotted notation. name() Returns the name of the node (the last part of the key). asNode() Returns a ConfigValue&lt;Config&gt; wrapped around the node traverse() traverse(Predicate&lt;Config&gt;) Returns a Stream&lt;Config&gt; as an iterative deepening depth-first traversal of the subtree type() Returns the Type enum value for the node: OBJECT , LIST , VALUE , or MISSING <markup lang=\"java\" title=\"List names of child nodes of an object node\" >List&lt;String&gt; appNodeNames = config.get(\"app\") .asNodeList() .map(nodes -&gt; { return nodes .stream() .map(Config::name) .sorted() .collect(Collectors.toList()); }) .orElse(Collections.emptyList()); assert appNodeNames.get(0).equals(\"basic-range\"); assert appNodeNames.get(1).equals(\"greeting\"); assert appNodeNames.get(2).equals(\"page-size\"); Get the ConfigValue with child Config instances. Map the node list to names using the Java Stream API (if present) Use an empty list if the \"app\" node does not exist Check that the list contains the expected child names: basic-range , greeting and page-size . <markup lang=\"java\" title=\"List child nodes of a list node\" >List&lt;Config&gt; providers = config.get(\"data.providers\") .asNodeList().orElse(Collections.emptyList()); assert providers.get(0).key().toString().equals(\"data.providers.0\"); assert providers.get(1).key().toString().equals(\"data.providers.1\"); Get child nodes of the data.providers list node as a List of Config instances. Check that the list contains the expected child nodes with keys data.providers.0 and data.providers.1 . The traverse() method returns a stream of the nodes in the subtree that is rooted at the current configuration node. Depending on the structure of the loaded configuration the stream contains a mix of object, list or leaf value nodes. <markup lang=\"java\" title=\"Traverse subtree below a list node\" >config.get(\"data.providers\") .traverse() .forEach(node -&gt; System.out.println(node.type() + \" \\t\" + node.key())); Visit the subtree rooted at the data.providers list node. Prints out following list of nodes (type and key): OBJECT data.providers.0 VALUE data.providers.0.name VALUE data.providers.0.class OBJECT data.providers.1 VALUE data.providers.1.name VALUE data.providers.1.class The optional Predicate&lt;Config&gt; argument to the traverse methods allows the application to prune the traversal of a subtree at any point. <markup lang=\"java\" title=\"Traverse root ( object ) node, skipping the entire data subtree\" >config.traverse(node -&gt; !node.name().equals(\"data\")) .forEach(node -&gt; System.out.println(node.type() + \" \\t\" + node.key())); Visit all root sub-nodes, excluding whole data tree structure but including others. Prints out following list of nodes (type and key): OBJECT app VALUE app.page-size VALUE app.greeting LIST app.basic-range VALUE app.basic-range.0 VALUE app.basic-range.1 ",
            "title": "Access by General Navigation"
        },
        {
            "location": "/se/config/03_hierarchical-features",
            "text": " Sometimes it can be convenient to write part of your application to deal with configuration without it knowing if or where the relevant configuration is plugged into a larger config tree. For example, the application.properties from the introduction section contains several settings prefixed with web such as web.page-size . Perhaps in another config source the same information might be stored as server.web.page-size : <markup lang=\"java\" title=\"Alternate Structure for Web Config\" >server.web.page-size: 40 server.web.debug = true server.web.ratio = 1.4 You might want to write the web portion of your app to work with a config subtree with keys that are independent of the subtree&#8217;s position in a larger tree. This would allow you to reuse the web portion of your application without change, regardless of which structure a config source used. One easy way to do this is to detach a subtree from a larger config tree. When your application invokes the Config.detach method it gets back a copy of the config node but with no parent. The copy and the original node both point to the same objects for their child nodes (if any). The original node is unchanged. <markup lang=\"java\" title=\"Detaching a Subtree\" >Config originalRoot = // from the original example `.conf` file Config alternateRoot = // from the alternate structure above Config detachedFromOriginal = originalRoot.get(\"web\").detach(); Config detachedFromAlternate = alternateRoot.get(\"server.web\").detach(); assert originalRoot.get(\"web.debug\").equals(\"true\"); assert alternateRoot.get(\"server.web.debug\").equals(\"true\"); assert detachedFromOriginal.get(\"debug\").equals(\"true\"); assert detachedFromAlternate.get(\"debug\").equals(\"true\"); Navigation depends on knowing the full structure of the config and so is different for the two cases. Detaching so the web node is the root can use the same key regardless of where the config subtree came from. ",
            "title": "Detaching a Config Subtree"
        },
        {
            "location": "/mp/security/03_configuration-secrets",
            "text": " When security requires a configuration with repeating complex elements, use Helidon Config. This example configures a basic authentication provider and protects static content on the web server. It also includes annotations in Jersey. ",
            "title": "preambule"
        },
        {
            "location": "/mp/security/03_configuration-secrets",
            "text": " The config encryption filter has an option that defines whether encryption is required or not. If it&#8217;s set to true, which is the default, then: Configuration values with ${CLEAR=&#8230;&#8203;} template will cause an exception when requested. The filter fails during bootstrap if security.config.aes.insecure-passphrase is configured. ",
            "title": "Requiring encryption"
        },
        {
            "location": "/mp/security/03_configuration-secrets",
            "text": " The config encryption filter provides a Main class io.helidon.config.encryption.Main that can be used to encrypt values. <markup lang=\"bash\" title=\"Encrypt secret secretToEncrypt using shared secret masterPassword \" >java -jar &lt;path-to-app-libs-dir&gt;/helidon-config-encryption-{helidon-version}.jar aes masterPassword secretToEncrypt The tool returns the string to be entered into configuration as the value of a property. ",
            "title": "Encrypting values (AES)"
        },
        {
            "location": "/mp/security/03_configuration-secrets",
            "text": " You can provide a shared secret in a couple of ways: in configuration - for testing/demo purposes only - key is security.config.aes.insecure-passphrase as an environment variable - SECURE_CONFIG_AES_MASTER_PWD ",
            "title": "Shared Secret (AES)"
        },
        {
            "location": "/mp/security/03_configuration-secrets",
            "text": " Symmetric encryption is based on a shared secret that is known by the person encrypting the value and is also provided to the application. Encrypting values (AES) The config encryption filter provides a Main class io.helidon.config.encryption.Main that can be used to encrypt values. <markup lang=\"bash\" title=\"Encrypt secret secretToEncrypt using shared secret masterPassword \" >java -jar &lt;path-to-app-libs-dir&gt;/helidon-config-encryption-{helidon-version}.jar aes masterPassword secretToEncrypt The tool returns the string to be entered into configuration as the value of a property. Shared Secret (AES) You can provide a shared secret in a couple of ways: in configuration - for testing/demo purposes only - key is security.config.aes.insecure-passphrase as an environment variable - SECURE_CONFIG_AES_MASTER_PWD ",
            "title": "Using symmetric encryption (AES)"
        },
        {
            "location": "/mp/security/03_configuration-secrets",
            "text": " The config encryption filter provides a Main class io.helidon.config.encryption.Main that can be used to encrypt values. <markup lang=\"bash\" title=\"Encrypt secret secretToEncrypt using public certificate in a keystore\" >java -jar &lt;path-to-app-libs-dir&gt;/helidon-config-encryption-{helidon-version}.jar rsa /path/to/keystore.p12 keystorePassword publicCertAlias secretToEncrypt The tool returns the string to be entered into configuration as the value of a property. ",
            "title": "Encrypting values (RSA)"
        },
        {
            "location": "/mp/security/03_configuration-secrets",
            "text": " You can configure the properties of a private key. These keys are prefixed with security.config.rsa RSA Configuration Options: Keystore What Configuration Key Environment Variable Description Keystore path keystore-path SECURE_CONFIG_RSA_PRIVATE_KEY Keystore is located in file system Keystore keystore-resource-path N/A Keystore is located on classpath Private key alias key-alias SECURE_CONFIG_PRIVATE_KEY_ALIAS Alias of the private key (such as \"1\", which is usually the default) Keystore passphrase keystore-passphrase SECURE_CONFIG_PRIVATE_KEYSTORE_PASSPHRASE Password for the keystore (and private key). RSA Configuration Options: PEM (PKCS#8) private key What Configuration Key Environment Variable Description Path pem-key-path SECURE_CONFIG_RSA_PEM_KEY Key is located on file system Resource path pem-key-resource-path N/A Key is located on classpath Passphrase pem-key-passphrase SECURE_CONFIG_PRIVATE_KEY_PASSPHRASE Password protecting the private key <markup lang=\"yaml\" title=\"Example yaml configuration\" >security.config: # Set to true for production - if set to true, clear text passwords will cause failure require-encryption: false # The \"master\" password for AES decryption. For production, set this via system property or environment variable. aes.insecure-passphrase: \"myMasterPasswordForEncryption\" # See documentation of pki-util rsa: # load from classpath keystore-resource-path: \".ssh/keystore.p12\" # If keystore is used, alias to use from the keystore (in this example, it is \"1\") key-alias: \"1\" # Password of keystore keystore-passphrase: \"helidon\" ",
            "title": "Configure config encryption filter (RSA)"
        },
        {
            "location": "/mp/security/03_configuration-secrets",
            "text": " This approach is based on a pair of keys: a public key which is known to anybody, and a private key which is known to a limited set of parties (usually a single person or process). For asymmetric encryption, the following is true: a value encrypted by a public key can only be decrypted by the private key When using the config encryption filter, you should encrypt the configuration values using the public key, and give the application process access to the private key to decrypt the values. Encrypting values (RSA) The config encryption filter provides a Main class io.helidon.config.encryption.Main that can be used to encrypt values. <markup lang=\"bash\" title=\"Encrypt secret secretToEncrypt using public certificate in a keystore\" >java -jar &lt;path-to-app-libs-dir&gt;/helidon-config-encryption-{helidon-version}.jar rsa /path/to/keystore.p12 keystorePassword publicCertAlias secretToEncrypt The tool returns the string to be entered into configuration as the value of a property. Configure config encryption filter (RSA) You can configure the properties of a private key. These keys are prefixed with security.config.rsa RSA Configuration Options: Keystore What Configuration Key Environment Variable Description Keystore path keystore-path SECURE_CONFIG_RSA_PRIVATE_KEY Keystore is located in file system Keystore keystore-resource-path N/A Keystore is located on classpath Private key alias key-alias SECURE_CONFIG_PRIVATE_KEY_ALIAS Alias of the private key (such as \"1\", which is usually the default) Keystore passphrase keystore-passphrase SECURE_CONFIG_PRIVATE_KEYSTORE_PASSPHRASE Password for the keystore (and private key). RSA Configuration Options: PEM (PKCS#8) private key What Configuration Key Environment Variable Description Path pem-key-path SECURE_CONFIG_RSA_PEM_KEY Key is located on file system Resource path pem-key-resource-path N/A Key is located on classpath Passphrase pem-key-passphrase SECURE_CONFIG_PRIVATE_KEY_PASSPHRASE Password protecting the private key <markup lang=\"yaml\" title=\"Example yaml configuration\" >security.config: # Set to true for production - if set to true, clear text passwords will cause failure require-encryption: false # The \"master\" password for AES decryption. For production, set this via system property or environment variable. aes.insecure-passphrase: \"myMasterPasswordForEncryption\" # See documentation of pki-util rsa: # load from classpath keystore-resource-path: \".ssh/keystore.p12\" # If keystore is used, alias to use from the keystore (in this example, it is \"1\") key-alias: \"1\" # Password of keystore keystore-passphrase: \"helidon\" ",
            "title": "Using asymmetric encryption (RSA)"
        },
        {
            "location": "/mp/security/03_configuration-secrets",
            "text": " In Helidon MP, the config encryption filter is enabled by default . However, if you don&#8217;t configure it, the filter only supports a template for aliasing that checks that no clear text passwords are present (template ${CLEAR=&#8230;&#8203;}. In Helidon SE, you may add support for this filter with dependency (loaded through a java service mechanism): <markup lang=\"xml\" title=\"Maven Dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.config&lt;/groupId&gt; &lt;artifactId&gt;helidon-config-encryption&lt;/artifactId&gt; &lt;/dependency&gt; Put encrypted values into your configuration file so that it can be stored in a public repository with no danger of exposing the secret values. Be sure to use a strong and secret password. The supported templates are: Templates Template Description Example ${CLEAR=&#8230;&#8203;} Secret in clear text (for testing) - requiresEncryption must be disabled ${CLEAR=knownSecret} ${RSA-P=&#8230;&#8203;} Public/private key encryption, base64 value ${RSA-P=aGr3sFCMQznixrgbIk9qNfoLnO1cdi3H86qweCNjxFvH4dYg5IQM1EuoyTjJaXcSCG5MBskpeA3bjnWYrzeAFFlZHuYSPsb+wJVzGLrfUColTn+BPJjpJ3rmEd3AVkJl1ASfBBMh3q3deC+rvUdhfoTGBO8sC0teUATklCQSxfHOnIxswxqrplnoGXToGiTIfehiN2IZNulRKeoDQ0AeoKREmq5au4L8OOmS+D9BqnlKMc0F1tULZ7+h3Cxla4lXC5WRPoPfHBU4vzRZOGzeDvLkRgrD60caw/wKn5M0Wy1A1cKR8E46ceBXCjJ2eWIcLyhZSAZWDe3ceNrawHZtCg==} ${GCM=&#8230;&#8203;} Shared secret ecryption, base64 value ${GCM=D/UgMzsNb265HU1NDvdzm7tACHdsW6u1PjYEcRkV/OLiWcI+ET6Q4MKCz0zHyEh9} Requiring encryption The config encryption filter has an option that defines whether encryption is required or not. If it&#8217;s set to true, which is the default, then: Configuration values with ${CLEAR=&#8230;&#8203;} template will cause an exception when requested. The filter fails during bootstrap if security.config.aes.insecure-passphrase is configured. Using symmetric encryption (AES) Symmetric encryption is based on a shared secret that is known by the person encrypting the value and is also provided to the application. Encrypting values (AES) The config encryption filter provides a Main class io.helidon.config.encryption.Main that can be used to encrypt values. <markup lang=\"bash\" title=\"Encrypt secret secretToEncrypt using shared secret masterPassword \" >java -jar &lt;path-to-app-libs-dir&gt;/helidon-config-encryption-{helidon-version}.jar aes masterPassword secretToEncrypt The tool returns the string to be entered into configuration as the value of a property. Shared Secret (AES) You can provide a shared secret in a couple of ways: in configuration - for testing/demo purposes only - key is security.config.aes.insecure-passphrase as an environment variable - SECURE_CONFIG_AES_MASTER_PWD Using asymmetric encryption (RSA) This approach is based on a pair of keys: a public key which is known to anybody, and a private key which is known to a limited set of parties (usually a single person or process). For asymmetric encryption, the following is true: a value encrypted by a public key can only be decrypted by the private key When using the config encryption filter, you should encrypt the configuration values using the public key, and give the application process access to the private key to decrypt the values. Encrypting values (RSA) The config encryption filter provides a Main class io.helidon.config.encryption.Main that can be used to encrypt values. <markup lang=\"bash\" title=\"Encrypt secret secretToEncrypt using public certificate in a keystore\" >java -jar &lt;path-to-app-libs-dir&gt;/helidon-config-encryption-{helidon-version}.jar rsa /path/to/keystore.p12 keystorePassword publicCertAlias secretToEncrypt The tool returns the string to be entered into configuration as the value of a property. Configure config encryption filter (RSA) You can configure the properties of a private key. These keys are prefixed with security.config.rsa RSA Configuration Options: Keystore What Configuration Key Environment Variable Description Keystore path keystore-path SECURE_CONFIG_RSA_PRIVATE_KEY Keystore is located in file system Keystore keystore-resource-path N/A Keystore is located on classpath Private key alias key-alias SECURE_CONFIG_PRIVATE_KEY_ALIAS Alias of the private key (such as \"1\", which is usually the default) Keystore passphrase keystore-passphrase SECURE_CONFIG_PRIVATE_KEYSTORE_PASSPHRASE Password for the keystore (and private key). RSA Configuration Options: PEM (PKCS#8) private key What Configuration Key Environment Variable Description Path pem-key-path SECURE_CONFIG_RSA_PEM_KEY Key is located on file system Resource path pem-key-resource-path N/A Key is located on classpath Passphrase pem-key-passphrase SECURE_CONFIG_PRIVATE_KEY_PASSPHRASE Password protecting the private key <markup lang=\"yaml\" title=\"Example yaml configuration\" >security.config: # Set to true for production - if set to true, clear text passwords will cause failure require-encryption: false # The \"master\" password for AES decryption. For production, set this via system property or environment variable. aes.insecure-passphrase: \"myMasterPasswordForEncryption\" # See documentation of pki-util rsa: # load from classpath keystore-resource-path: \".ssh/keystore.p12\" # If keystore is used, alias to use from the keystore (in this example, it is \"1\") key-alias: \"1\" # Password of keystore keystore-passphrase: \"helidon\" ",
            "title": "Protecting Configuration Secrets"
        },
        {
            "location": "/mp/reactivemessaging/03_connector",
            "text": "<markup lang=\"java\" title=\"Example connector accessing configuration:\" >@ApplicationScoped @Connector(\"example-connector\") public class ExampleConnector implements IncomingConnectorFactory { @Override public PublisherBuilder&lt;? extends Message&lt;?&gt;&gt; getPublisherBuilder(final Config config) { String firstPropValue = config.getValue(\"first-test-prop\", String.class); String secondPropValue = config.getValue(\"second-test-prop\", String.class); return ReactiveStreams.of(firstPropValue, secondPropValue) .map(Message::of); } } Config context is merged from channel and connector contexts <markup lang=\"yaml\" title=\"Example of channel to connector mapping config with custom properties:\" >mp.messaging.incoming.from-connector-channel.connector: example-connector mp.messaging.incoming.from-connector-channel.first-test-prop: foo mp.messaging.connector.example-connector.second-test-prop: bar Channel &#8594; Connector mapping Channel configuration properties Connector configuration properties <markup lang=\"java\" title=\"Example consuming from connector:\" >@Incoming(\"from-connector-channel\") public void consume(String value) { System.out.println(\"Consuming: \" + value); } &gt; Consuming: foo &gt; Consuming: bar ",
            "title": "Configuration"
        },
        {
            "location": "/mp/reactivemessaging/03_connector",
            "text": " Messaging connector is just an application scoped bean which implements IncomingConnectorFactory , OutgoingConnectorFactory or both. <markup lang=\"java\" title=\"Example connector example-connector :\" >@ApplicationScoped @Connector(\"example-connector\") public class ExampleConnector implements IncomingConnectorFactory, OutgoingConnectorFactory { @Override public PublisherBuilder&lt;? extends Message&lt;?&gt;&gt; getPublisherBuilder(Config config) { return ReactiveStreams.of(\"foo\", \"bar\") .map(Message::of); } @Override public SubscriberBuilder&lt;? extends Message&lt;?&gt;, Void&gt; getSubscriberBuilder(Config config) { return ReactiveStreams.&lt;Message&lt;?&gt;&gt;builder() .map(Message::getPayload) .forEach(o -&gt; System.out.println(\"Connector says: \" + o)); } } <markup lang=\"yaml\" title=\"Example of channel to connector mapping config:\" >mp.messaging.outgoing.to-connector-channel.connector: example-connector mp.messaging.incoming.from-connector-channel.connector: example-connector <markup lang=\"java\" title=\"Example producing to connector:\" >@Outgoing(\"to-connector-channel\") public Publisher&lt;String&gt; produce() { return Flowable.just(\"fee\", \"fie\"); } &gt; Connector says: fee &gt; Connector says: fie <markup lang=\"java\" title=\"Example consuming from connector:\" >@Incoming(\"from-connector-channel\") public void consume(String value) { System.out.println(\"Consuming: \" + value); } &gt; Consuming: foo &gt; Consuming: bar Configuration <markup lang=\"java\" title=\"Example connector accessing configuration:\" >@ApplicationScoped @Connector(\"example-connector\") public class ExampleConnector implements IncomingConnectorFactory { @Override public PublisherBuilder&lt;? extends Message&lt;?&gt;&gt; getPublisherBuilder(final Config config) { String firstPropValue = config.getValue(\"first-test-prop\", String.class); String secondPropValue = config.getValue(\"second-test-prop\", String.class); return ReactiveStreams.of(firstPropValue, secondPropValue) .map(Message::of); } } Config context is merged from channel and connector contexts <markup lang=\"yaml\" title=\"Example of channel to connector mapping config with custom properties:\" >mp.messaging.incoming.from-connector-channel.connector: example-connector mp.messaging.incoming.from-connector-channel.first-test-prop: foo mp.messaging.connector.example-connector.second-test-prop: bar Channel &#8594; Connector mapping Channel configuration properties Connector configuration properties <markup lang=\"java\" title=\"Example consuming from connector:\" >@Incoming(\"from-connector-channel\") public void consume(String value) { System.out.println(\"Consuming: \" + value); } &gt; Consuming: foo &gt; Consuming: bar ",
            "title": "Messaging Connector Bean"
        },
        {
            "location": "/se/guides/36_graalnative",
            "text": " This guide describes how to build a GraalVM native image for a Helidon SE application. ",
            "title": "preambule"
        },
        {
            "location": "/se/guides/36_graalnative",
            "text": " Native images are ahead-of-time compiled Java code that result in a self contained native executable. When used appropriately native images have dramatically faster startup and lower runtime memory overhead compared to a Java VM. In this guide you will learn how to build a native image locally on your machine, as well as using Docker. ",
            "title": "Introduction"
        },
        {
            "location": "/se/guides/36_graalnative",
            "text": " For this 10 minute tutorial, you will need the following: <div class=\"table__overflow elevation-1 flex sm7 \"> A Helidon {upper-case-flavor} Application You can use your own application or use the Helidon {upper-case-flavor} Quickstart to create a sample application. Java&#160;SE&#160;11 ( Open&#160;JDK&#160;11 ) Helidon requires Java 11+. Maven 3.6.1+ Helidon requires Maven 3.6.1+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop ). GraalVM CE 21.0.0 <markup lang=\"bash\" title=\"Verify Prerequisites\" >java -version mvn --version docker --version kubectl version --short <markup lang=\"bash\" title=\"Setting JAVA_HOME\" ># On Mac export JAVA_HOME=`/usr/libexec/java_home -v 11` # On Linux # Use the appropriate path to your JDK export JAVA_HOME=/usr/lib/jvm/jdk-11 ",
            "title": "What You Need"
        },
        {
            "location": "/se/guides/36_graalnative",
            "text": " After downloading and installing GraalVM, set the GRAALVM_HOME environment variable to point at your GraalVM installation. <markup lang=\"bash\" ># Your path might be different export GRAALVM_HOME=/usr/local/graalvm-ce-21.3.0/Contents/Home/ Then install the optional native-image command: <markup lang=\"bash\" >$GRAALVM_HOME/bin/gu install native-image And verify: <markup lang=\"bash\" >$GRAALVM_HOME/bin/java -version $GRAALVM_HOME/bin/native-image --version ",
            "title": "Install GraalVM and the Native Image Command"
        },
        {
            "location": "/se/guides/36_graalnative",
            "text": " Generate the project using the Helidon SE Quickstart Maven archetype. <markup lang=\"bash\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-se \\ -DarchetypeVersion=2.5.4 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-se \\ -Dpackage=io.helidon.examples.quickstart.se The archetype generates a Maven project in your current directory (for example, helidon-quickstart-se ). Change into this directory and build. <markup lang=\"bash\" >cd helidon-quickstart-se mvn package At this point you can run the application using the JVM: <markup lang=\"bash\" >java -jar target/helidon-quickstart-se.jar In another shell test an endpoint: <markup lang=\"bash\" >curl -X GET http://localhost:8080/greet The application should respond with {\"message\":\"Hello World!\"} Now stop the running application (by pressing Ctrl+C). For more information about the Quickstart application and other enpoints it supports see the Helidon SE Quickstart Guide . ",
            "title": "Generate the Project"
        },
        {
            "location": "/se/guides/36_graalnative",
            "text": " Make sure you have GraalVM locally installed: <markup lang=\"bash\" >$GRAALVM_HOME/bin/native-image --version Build the native image using the native image profile: <markup lang=\"bash\" >mvn package -Pnative-image Tip This uses the helidon-maven-plugin to perform the native compilation using your installed copy of GraalVM. It might take a while to complete. Once it completes start the application using the native executable (no JVM!): <markup lang=\"bash\" >./target/helidon-quickstart-se Yep, it starts fast. You can exercise the application&#8217;s endpoints as before. ",
            "title": "Local build"
        },
        {
            "location": "/se/guides/36_graalnative",
            "text": " Build the \"native\" Docker image <markup lang=\"bash\" >docker build -t helidon-quickstart-se-native -f Dockerfile.native . Tip This does a full build inside the Docker container. The first time you run it, it will take a while because it is downloading all of the Maven dependencies and caching them in a Docker layer. Subsequent builds will be much faster as long as you don&#8217;t change the pom.xml file. If the pom is modified then the dependencies will be re-downloaded. Start the application: <markup lang=\"bash\" >docker run --rm -p 8080:8080 helidon-quickstart-se-native:latest Again, it starts fast. You can exercise the application&#8217;s endpoints as before. ",
            "title": "Multi-stage Docker build"
        },
        {
            "location": "/se/guides/36_graalnative",
            "text": " You can build a native executable in 2 different ways: With a local installation of GraalVM Using Docker Local build Make sure you have GraalVM locally installed: <markup lang=\"bash\" >$GRAALVM_HOME/bin/native-image --version Build the native image using the native image profile: <markup lang=\"bash\" >mvn package -Pnative-image Tip This uses the helidon-maven-plugin to perform the native compilation using your installed copy of GraalVM. It might take a while to complete. Once it completes start the application using the native executable (no JVM!): <markup lang=\"bash\" >./target/helidon-quickstart-se Yep, it starts fast. You can exercise the application&#8217;s endpoints as before. Multi-stage Docker build Build the \"native\" Docker image <markup lang=\"bash\" >docker build -t helidon-quickstart-se-native -f Dockerfile.native . Tip This does a full build inside the Docker container. The first time you run it, it will take a while because it is downloading all of the Maven dependencies and caching them in a Docker layer. Subsequent builds will be much faster as long as you don&#8217;t change the pom.xml file. If the pom is modified then the dependencies will be re-downloaded. Start the application: <markup lang=\"bash\" >docker run --rm -p 8080:8080 helidon-quickstart-se-native:latest Again, it starts fast. You can exercise the application&#8217;s endpoints as before. ",
            "title": "Building a Native Image"
        },
        {
            "location": "/se/guides/36_graalnative",
            "text": " Native images are ideal for applications with high horizontal scalability requirements where the ability to rapidly scale out to numerous instances is important. That said, native images do have some limitations , and for long running applications where startup and footprint are less of a priority, the Java SE HotSpot VM might be more appropriate. For information about creating custom Java runtime images see Custom Runtime Images with jlink ",
            "title": "When should I use Native Images?"
        },
        {
            "location": "/se/reactivemessaging/06_aq",
            "text": " To enable AQ Connector add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.messaging.aq&lt;/groupId&gt; &lt;artifactId&gt;helidon-messaging-aq&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/reactivemessaging/06_aq",
            "text": "<markup lang=\"java\" title=\"Example of producing to and consuming from Oracle AQ:\" >PoolDataSource pds = PoolDataSourceFactory.getPoolDataSource(); pds.setConnectionFactoryClassName(\"oracle.jdbc.pool.OracleDataSource\"); pds.setURL(\"jdbc:oracle:thin:@(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(Host=192.168.0.123)(Port=1521))(CONNECT_DATA=(SID=XE)))\"); pds.setUser(\"frank\"); pds.setPassword(\"frank\"); AqConnector seConn = AqConnector.builder() .dataSource(\"test-ds\", pds) .build(); Channel&lt;String&gt; toAq = Channel.&lt;String&gt;builder() .name(\"toAq\") .subscriberConfig(AqConnector.configBuilder() .queue(\"example_queue_1\") .dataSource(\"test-ds\") .build()) .build(); Channel&lt;String&gt; fromAq = Channel.&lt;String&gt;builder() .name(\"fromAq\") .publisherConfig(AqConnector.configBuilder() .queue(\"example_queue_1\") .dataSource(\"test-ds\") .build()) .build(); Messaging.builder() .connector(seConn) .publisher(toAq, Multi.just(\"Hello\", \"world\", \"from\", \"Oracle\", \"DB!\").map(Message::of)) .listener(fromAq, s -&gt; System.out.pritln(\"Message received: \"+s)) .build() .start(); Prepare Oracle UCP Setup AQ connector and provide datasource with an identifier test-ds Setup channel for sending messages to queue example_queue_1 with datasource test-ds Setup channel for receiving messages from queue example_queue_1 with datasource test-ds Register connector and channels Add a publisher for several test messages to publish them to example_queue_1 immediately Subscribe callback for any message coming from example_queue_1 ",
            "title": "Sending and receiving"
        },
        {
            "location": "/se/reactivemessaging/06_aq",
            "text": " Sending and receiving <markup lang=\"java\" title=\"Example of producing to and consuming from Oracle AQ:\" >PoolDataSource pds = PoolDataSourceFactory.getPoolDataSource(); pds.setConnectionFactoryClassName(\"oracle.jdbc.pool.OracleDataSource\"); pds.setURL(\"jdbc:oracle:thin:@(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(Host=192.168.0.123)(Port=1521))(CONNECT_DATA=(SID=XE)))\"); pds.setUser(\"frank\"); pds.setPassword(\"frank\"); AqConnector seConn = AqConnector.builder() .dataSource(\"test-ds\", pds) .build(); Channel&lt;String&gt; toAq = Channel.&lt;String&gt;builder() .name(\"toAq\") .subscriberConfig(AqConnector.configBuilder() .queue(\"example_queue_1\") .dataSource(\"test-ds\") .build()) .build(); Channel&lt;String&gt; fromAq = Channel.&lt;String&gt;builder() .name(\"fromAq\") .publisherConfig(AqConnector.configBuilder() .queue(\"example_queue_1\") .dataSource(\"test-ds\") .build()) .build(); Messaging.builder() .connector(seConn) .publisher(toAq, Multi.just(\"Hello\", \"world\", \"from\", \"Oracle\", \"DB!\").map(Message::of)) .listener(fromAq, s -&gt; System.out.pritln(\"Message received: \"+s)) .build() .start(); Prepare Oracle UCP Setup AQ connector and provide datasource with an identifier test-ds Setup channel for sending messages to queue example_queue_1 with datasource test-ds Setup channel for receiving messages from queue example_queue_1 with datasource test-ds Register connector and channels Add a publisher for several test messages to publish them to example_queue_1 immediately Subscribe callback for any message coming from example_queue_1 ",
            "title": "Reactive Oracle AQ Connector"
        },
        {
            "location": "/mp/cors/01_introduction",
            "text": " Cross-origin resource sharing (CORS) support in Helidon MP provides a flexible mechanism that allows a Helidon MP application to control how another web application can access its resources, even if that web application is served from a different domain. ",
            "title": "preambule"
        },
        {
            "location": "/mp/cors/01_introduction",
            "text": " The CORS protocol helps developers control if and how REST resources served by their applications can be shared across origins. Helidon MP includes an implementation of CORS that you can use to add CORS behavior to the services you develop. You can define your application&#8217;s CORS behavior programmatically using the Helidon CORS API alone, or together with configuration. Helidon also provides three built-in services that add their own endpoints to your application - health, metrics, and OpenAPI - that have integrated CORS support. By adding very little code to your application, you control how all the resources in your application&#8201;&#8212;&#8201;the ones you write and the ones provided by the Helidon built-in services&#8201;&#8212;&#8201;can be shared across origins. ",
            "title": "Overview"
        },
        {
            "location": "/mp/cors/01_introduction",
            "text": " Before you revise your application to add CORS support, you need to decide what type of cross-origin sharing you want to allow for each resource your application exposes. For example, suppose for a given resource you want to allow unrestricted sharing for GET, HEAD, and POST requests (what CORS refers to as \"simple\" requests), but permit other types of requests only from the two origins foo.com and there.com . Your application would implement two types of CORS sharing: more relaxed for the simple requests and stricter for others. Once you know the type of sharing you want to allow for each of your resources&#8201;&#8212;&#8201;including any from built-in services&#8201;&#8212;&#8201;you can change your application accordingly. ",
            "title": "Before You Begin"
        },
        {
            "location": "/mp/cors/01_introduction",
            "text": " To introduce CORS into your Helidon MP application, do any or all of the following: Modify your code using the Helidon MP CORS API. Learn more. Use configuration to allow users to override the CORS settings established in your application code. Learn more. Update your application to include any of the built-in Helidon services that automatically support CORS. Learn more. ",
            "title": "Next Steps"
        },
        {
            "location": "/se/metrics/01_metrics",
            "text": " Helidon SE provides the following to support metrics: The endpoint /metrics : A configurable endpoint that exposes metrics information in JSON format (as specified by the MicroProfile Metrics specification) or in plain text (for Prometheus metrics). A base set of metrics, available at /metrics/base , as specified by the MicroProfile Metrics specification. A set of Helidon-specific metrics, available at /metrics/vendor ",
            "title": "preambule"
        },
        {
            "location": "/se/metrics/01_metrics",
            "text": " To enable Metrics add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.metrics.api&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/metrics/01_metrics",
            "text": " To enable Metrics, register it with the WebServer. <markup lang=\"java\" >import io.helidon.metrics.serviceapi.MetricsSupport; //... Routing.builder() .register(MetricsSupport.create()) .register(\"/myapp\", new MyService()) .build(); Then you can use metrics in your service. <markup lang=\"java\" title=\"Define and use a Metrics Counter\" >import io.helidon.metrics.api.RegistryFactory; import org.eclipse.microprofile.metrics.Counter; import org.eclipse.microprofile.metrics.MetricRegistry; //... public class MyService implements Service { private final MetricRegistry registry = RegistryFactory.getInstance() .getRegistry(MetricRegistry.Type.APPLICATION); private final Counter accessCtr = registry.counter(\"accessctr\"); @Override public void update(Routing.Rules rules) { rules .any(this::countAccess) .get(\"/\", this::myGet); } private void countAccess(ServerRequest request, ServerResponse response) { accessCtr.inc(); request.next(); } } Get the application metrics registry Create a counter in that registry Increment the counter for every request Helidon-provided endpoints for /metrics do their work synchronously, using the same thread on which the request arrived via Netty. To prevent performance degradation, avoid including long-running code that can be invoked by these handlers while Helidon is responding to the metric. For example, if you implement your own application-specific metric types, you will write logic to format the JSON and OpenMetrics output for those metric types. Helidon invokes this formatting logic whenever a client accesses the /metrics endpoints, so make that formatting code as efficient as possible. ",
            "title": "Using Metrics in Your Application"
        },
        {
            "location": "/se/metrics/01_metrics",
            "text": " Access metrics data via the /metrics endpoint. Two reporting formats are supported. The HTTP Accept header sent by the client determines the reporting format: JSON format - used when the HTTP Accept header matches application/json Prometheus text format - used when the HTTP Accept header is text/plain or otherwise does not match application/json <markup lang=\"bash\" title=\"Example Reporting: Prometheus format\" >curl -s -H 'Accept: text/plain' -X GET http://localhost:8080/metrics/ # TYPE base:classloader_total_loaded_class_count counter # HELP base:classloader_total_loaded_class_count Displays the total number of classes that have been loaded since the Java virtual machine has started execution. base:classloader_total_loaded_class_count 3157 #... <markup lang=\"bash\" title=\"Example Reporting: JSON format\" >curl -s -H 'Accept: application/json' -X GET http://localhost:8080/metrics/ | json_pp { \"base\" : { \"memory.maxHeap\" : 3817865216, \"memory.committedHeap\" : 335544320, #... In addition to your application metrics the reports contain other metrics of interest such as system and VM information. For full details see the MicroProfile Metrics specification. The Metrics component in Helidon SE is the core for the Helidon MP implementation of the MicroProfile Metrics specification. ",
            "title": "Accessing Metrics Endpoint"
        },
        {
            "location": "/se/webserver/05_error-handling",
            "text": " If no user-defined error handler is matched, or if the last error handler of the exception called req.next() , then the exception is translated to an HTTP response as follows: Subtypes of HttpException are translated to their associated HTTP error codes. <markup lang=\"java\" title=\"Reply with the 406 HTTP error code by throwing an exception\" >(req, res) -&gt; throw new HttpException(\"Amount of money must be greater than 0.\", Http.Status.NOT_ACCEPTABLE_406) Otherwise, the exceptions are translated to an Internal Server Error HTTP error code 500 . ",
            "title": "Default error handling"
        },
        {
            "location": "/se/webserver/05_error-handling",
            "text": " You may register an error handler for a specific Throwable in the Routing.Builder method. <markup lang=\"java\" >Routing routing = Routing.builder() .error(MyException.class, (req, res, ex) -&gt; { // handle the error, set the HTTP status code res.send(errorDescriptionObject); }) .build Registers an error handler that handles MyException that are thrown from the upstream handlers Finishes the request handling by sending a response Error handlers are called when an exception is thrown from a handler req.next(ex) is called, where ex is an instance of Throwable As with the standard handlers, the error handler must either send a response <markup lang=\"java\" >.error(MyException.class, (req, res, ex) -&gt; { res.status(Http.Status.BAD_REQUEST_400); res.send(\"Unable to parse request. Message: \" + ex.getMessage()); }) or, forward the error handling to the downstream error handlers <markup lang=\"java\" >.error(Throwable.class, (req, res, ex) -&gt; { // some logic req.next(ex); }) Error handling can&#8217;t be forwarded to the standard handlers. In fact, invoking req.next(ex) or req.next() in an error handler are equivalent. <markup lang=\"java\" >.error(Throwable.class, (req, res, ex) -&gt; { if (condition) { req.next(ex); } else { req.next(); } }) Call a downstream error handler with the Throwable instance. Here, req.next() is the same as req.next(ex) . In both cases, the downstream error handler is called. Default error handling If no user-defined error handler is matched, or if the last error handler of the exception called req.next() , then the exception is translated to an HTTP response as follows: Subtypes of HttpException are translated to their associated HTTP error codes. <markup lang=\"java\" title=\"Reply with the 406 HTTP error code by throwing an exception\" >(req, res) -&gt; throw new HttpException(\"Amount of money must be greater than 0.\", Http.Status.NOT_ACCEPTABLE_406) Otherwise, the exceptions are translated to an Internal Server Error HTTP error code 500 . ",
            "title": "Error Routing"
        },
        {
            "location": "/se/config/05_mutability-support",
            "text": " An in-memory config tree, once loaded, is immutable, even though the data in the underlying config sources can change over time. Your application can find out metadata about a loaded in-memory config and can track changes in config sources. ",
            "title": "preambule"
        },
        {
            "location": "/se/config/05_mutability-support",
            "text": " Even though in-memory config trees are immutable, the config system internally records which config sources it used to load each config tree and some metadata about the configuration. Your application can be aware of updates to the underlying config sources by: using the metadata the config system maintains, responding to changes when the config sources are updated, or using Supplier s of particular config values to obtain the always-current value for a key. ",
            "title": "Overview"
        },
        {
            "location": "/se/config/05_mutability-support",
            "text": " The config system records when it loads each configuration into memory. Your application can retrieve it by invoking the timestamp method : <markup lang=\"java\" >java.time.Instance loadTime = myConfig.timestamp(); on any config node. ",
            "title": "Loading Time"
        },
        {
            "location": "/se/config/05_mutability-support",
            "text": " The config system maintains a Config.Context for each Config node. Your application can retrieve the context by invoking the Config.context() method and then use it for these operations: Uses of Config.Context Method Usage Instant timestamp() Returns the load time of the last loaded configuration that used the context. Config last() Returns the most recently loaded configuration that used the context. Config reload() Reloads the entire config tree from the current contents of the same config sources used to load the tree in which the current node resides. Note that the config context describes or replaces a currently-loaded config tree. It by itself does not help your application decide when reloading the config might be useful. ",
            "title": "Config Context"
        },
        {
            "location": "/se/config/05_mutability-support",
            "text": " Loading Time The config system records when it loads each configuration into memory. Your application can retrieve it by invoking the timestamp method : <markup lang=\"java\" >java.time.Instance loadTime = myConfig.timestamp(); on any config node. Config Context The config system maintains a Config.Context for each Config node. Your application can retrieve the context by invoking the Config.context() method and then use it for these operations: Uses of Config.Context Method Usage Instant timestamp() Returns the load time of the last loaded configuration that used the context. Config last() Returns the most recently loaded configuration that used the context. Config reload() Reloads the entire config tree from the current contents of the same config sources used to load the tree in which the current node resides. Note that the config context describes or replaces a currently-loaded config tree. It by itself does not help your application decide when reloading the config might be useful. ",
            "title": "Using Config Metadata"
        },
        {
            "location": "/se/config/05_mutability-support",
            "text": " When the application creates a config source, it can set up change detection for that source. This is called polling in the Helidon API but specific change detection algorithms might not use actual polling. You choose a specific PollingStrategy for each config source you want to monitor. See the section on polling strategies in the config extensions doc page for more information. The config system provides some built-in polling strategies, exposed as these methods on the PollingStrategies class: regular(Duration interval) - a general-purpose scheduled polling strategy with a specified, constant polling interval. watch(Path watchedPath) - a filesystem-specific strategy to watch specified path. You can use this strategy with the file and classpath built-in config sources. nop() - a no-op strategy This example builds a Config object from three sources, each set up with a different polling strategy: <markup lang=\"java\" title=\"Build a Config with a different PollingStrategy for each config source\" >Config config = Config.create( ConfigSources.file(\"conf/dev.properties\") .pollingStrategy(PollingStrategies.regular(Duration.ofSeconds(2))) .optional(), ConfigSources.file(\"conf/config.properties\") .changeWatcher(FileSystemWatcher.create()) .optional(), ConfigSources.classpath(\"application.properties\") .pollingStrategy(PollingStrategies::nop)); Optional file source conf/dev.properties will be checked for changes every 2 seconds. Optional file source conf/config.properties will be watched by the Java WatchService for changes on filesystem. The classpath resource application.properties will not be checked for changes. PollingStrategies.nop() polling strategy is default. The polling strategies internally inform the config system when they detect changes in the monitored config sources (except that the nop strategy does nothing). ",
            "title": "Setting up Config Source Change Detection"
        },
        {
            "location": "/se/config/05_mutability-support",
            "text": " A simple approach is for your application to register a function that should run when any change occurs. <markup lang=\"java\" title=\"Subscribe on greeting property changes via onChange method\" >config.get(\"greeting\") .onChange((changedNode) -&gt; { System.out.println(\"Node \" + changedNode.key() + \" has changed!\"); return true; }); Navigate to the Config node on which you want to register. Invoke the onChange method, passing a function ( Function&lt;Config, Boolean&gt; ). The config system invokes that function each time the subtree rooted at the greeting node changes. The changedNode is a new instance of Config representing the updated subtree rooted at greeting . The function should return true to continue being run on subsequent changes, false to stop. ",
            "title": "Registering Actions"
        },
        {
            "location": "/se/config/05_mutability-support",
            "text": " The config system also supports the flow publisher/subscriber model for applications that need more control over the pace at which the config system delivers config change events. Each Config instance exposes the Config.changes() method which returns a Flow.Publisher&lt;Config&gt; . Your application can invoke this method, then invoke subscribe on the returned Flow.Publisher , passing your own Flow.Subscriber implementation. The config system will invoke your subscriber&#8217;s methods as appropriate, most notably calling onNext whenever it detects a change in one of the underlying config sources for the config node of interest. Mote that your subscriber will be notified when a change occurs anywhere in the subtree represented by the Config node. <markup lang=\"java\" title=\"Subscribe on greeting property changes\" >config.get(\"greeting\") .changes() .subscribe(new Flow.Subscriber&lt;&gt;() { Flow.Subscription subscription; @Override public void onSubscribe(Flow.Subscription subscription) { this.subscription = subscription; subscription.request(1); } @Override public void onNext(Config changedNode) { System.out.println(\"Node \" + changedNode.key() + \" has changed!\"); subscription.request(1); } @Override public void onError(Throwable throwable) { } @Override public void onComplete() { } }); Navigate to the Config node on which you want to register. Invoke changes to get the Flow.Publisher of changes to the subtree rooted at the Config node. Subscribe to the publisher passing a custom Flow.Subscriber&lt;Config&gt; implementation. Request the first event delivery in onSubscribe method. The config system invokes onNext each time the subtree rooted at the greeting node changes. The changedNode is a new instance of Config representing the updated subtree rooted at greeting , regardless of where in the subtree the change actually occurred. Remember to request the next event delivery in onNext . The config system does not currently invoke onError . The config system invokes onComplete if all config sources indicate there will be no other change event . Note Your application does not need to subscribe to the new Config instance passed to your onNext method. The original subscription remains in force for changes to the \"new\" instance. ",
            "title": "Subscribing to Events"
        },
        {
            "location": "/se/config/05_mutability-support",
            "text": " To know when config sources have changed, your application must register its interest on the Config node of interest. The config system will then notify your application of any change within the subtree rooted at that node. In particular, if you register on the root node, then the config system notifies your code of changes anywhere in the config tree. You can register in either of two ways: register an action to be run upon each change, or subscribe to a Flow.Publisher that notifies of changes. Registering Actions A simple approach is for your application to register a function that should run when any change occurs. <markup lang=\"java\" title=\"Subscribe on greeting property changes via onChange method\" >config.get(\"greeting\") .onChange((changedNode) -&gt; { System.out.println(\"Node \" + changedNode.key() + \" has changed!\"); return true; }); Navigate to the Config node on which you want to register. Invoke the onChange method, passing a function ( Function&lt;Config, Boolean&gt; ). The config system invokes that function each time the subtree rooted at the greeting node changes. The changedNode is a new instance of Config representing the updated subtree rooted at greeting . The function should return true to continue being run on subsequent changes, false to stop. Subscribing to Events The config system also supports the flow publisher/subscriber model for applications that need more control over the pace at which the config system delivers config change events. Each Config instance exposes the Config.changes() method which returns a Flow.Publisher&lt;Config&gt; . Your application can invoke this method, then invoke subscribe on the returned Flow.Publisher , passing your own Flow.Subscriber implementation. The config system will invoke your subscriber&#8217;s methods as appropriate, most notably calling onNext whenever it detects a change in one of the underlying config sources for the config node of interest. Mote that your subscriber will be notified when a change occurs anywhere in the subtree represented by the Config node. <markup lang=\"java\" title=\"Subscribe on greeting property changes\" >config.get(\"greeting\") .changes() .subscribe(new Flow.Subscriber&lt;&gt;() { Flow.Subscription subscription; @Override public void onSubscribe(Flow.Subscription subscription) { this.subscription = subscription; subscription.request(1); } @Override public void onNext(Config changedNode) { System.out.println(\"Node \" + changedNode.key() + \" has changed!\"); subscription.request(1); } @Override public void onError(Throwable throwable) { } @Override public void onComplete() { } }); Navigate to the Config node on which you want to register. Invoke changes to get the Flow.Publisher of changes to the subtree rooted at the Config node. Subscribe to the publisher passing a custom Flow.Subscriber&lt;Config&gt; implementation. Request the first event delivery in onSubscribe method. The config system invokes onNext each time the subtree rooted at the greeting node changes. The changedNode is a new instance of Config representing the updated subtree rooted at greeting , regardless of where in the subtree the change actually occurred. Remember to request the next event delivery in onNext . The config system does not currently invoke onError . The config system invokes onComplete if all config sources indicate there will be no other change event . Note Your application does not need to subscribe to the new Config instance passed to your onNext method. The original subscription remains in force for changes to the \"new\" instance. ",
            "title": "Registering a Config Change Response"
        },
        {
            "location": "/se/config/05_mutability-support",
            "text": " Evolving API This section describes the Config.changes() method. It is marked as deprecated because it returns an io.helidon.reactive.Flow.Publisher object. In a future Helidon release that requires Java 11 or later this method will be undeprecated and changed&#8201;&#8212;&#8201;or a similar method will be added&#8201;&#8212;&#8201;so that the return type is java.util.concurrent.Flow.Publisher instead. Any code you write using the existing Config.changes() method might need to change at that time. Although in-memory config trees do not change once loaded, applications can respond to changes in the underlying config sources by: setting up change detection for the config sources used to build a configuration, and registering a response to be run when a source changes. Your code&#8217;s response can react to the changes in whatever way makes sense for your application. The following sections describe these steps in detail. Setting up Config Source Change Detection When the application creates a config source, it can set up change detection for that source. This is called polling in the Helidon API but specific change detection algorithms might not use actual polling. You choose a specific PollingStrategy for each config source you want to monitor. See the section on polling strategies in the config extensions doc page for more information. The config system provides some built-in polling strategies, exposed as these methods on the PollingStrategies class: regular(Duration interval) - a general-purpose scheduled polling strategy with a specified, constant polling interval. watch(Path watchedPath) - a filesystem-specific strategy to watch specified path. You can use this strategy with the file and classpath built-in config sources. nop() - a no-op strategy This example builds a Config object from three sources, each set up with a different polling strategy: <markup lang=\"java\" title=\"Build a Config with a different PollingStrategy for each config source\" >Config config = Config.create( ConfigSources.file(\"conf/dev.properties\") .pollingStrategy(PollingStrategies.regular(Duration.ofSeconds(2))) .optional(), ConfigSources.file(\"conf/config.properties\") .changeWatcher(FileSystemWatcher.create()) .optional(), ConfigSources.classpath(\"application.properties\") .pollingStrategy(PollingStrategies::nop)); Optional file source conf/dev.properties will be checked for changes every 2 seconds. Optional file source conf/config.properties will be watched by the Java WatchService for changes on filesystem. The classpath resource application.properties will not be checked for changes. PollingStrategies.nop() polling strategy is default. The polling strategies internally inform the config system when they detect changes in the monitored config sources (except that the nop strategy does nothing). Registering a Config Change Response To know when config sources have changed, your application must register its interest on the Config node of interest. The config system will then notify your application of any change within the subtree rooted at that node. In particular, if you register on the root node, then the config system notifies your code of changes anywhere in the config tree. You can register in either of two ways: register an action to be run upon each change, or subscribe to a Flow.Publisher that notifies of changes. Registering Actions A simple approach is for your application to register a function that should run when any change occurs. <markup lang=\"java\" title=\"Subscribe on greeting property changes via onChange method\" >config.get(\"greeting\") .onChange((changedNode) -&gt; { System.out.println(\"Node \" + changedNode.key() + \" has changed!\"); return true; }); Navigate to the Config node on which you want to register. Invoke the onChange method, passing a function ( Function&lt;Config, Boolean&gt; ). The config system invokes that function each time the subtree rooted at the greeting node changes. The changedNode is a new instance of Config representing the updated subtree rooted at greeting . The function should return true to continue being run on subsequent changes, false to stop. Subscribing to Events The config system also supports the flow publisher/subscriber model for applications that need more control over the pace at which the config system delivers config change events. Each Config instance exposes the Config.changes() method which returns a Flow.Publisher&lt;Config&gt; . Your application can invoke this method, then invoke subscribe on the returned Flow.Publisher , passing your own Flow.Subscriber implementation. The config system will invoke your subscriber&#8217;s methods as appropriate, most notably calling onNext whenever it detects a change in one of the underlying config sources for the config node of interest. Mote that your subscriber will be notified when a change occurs anywhere in the subtree represented by the Config node. <markup lang=\"java\" title=\"Subscribe on greeting property changes\" >config.get(\"greeting\") .changes() .subscribe(new Flow.Subscriber&lt;&gt;() { Flow.Subscription subscription; @Override public void onSubscribe(Flow.Subscription subscription) { this.subscription = subscription; subscription.request(1); } @Override public void onNext(Config changedNode) { System.out.println(\"Node \" + changedNode.key() + \" has changed!\"); subscription.request(1); } @Override public void onError(Throwable throwable) { } @Override public void onComplete() { } }); Navigate to the Config node on which you want to register. Invoke changes to get the Flow.Publisher of changes to the subtree rooted at the Config node. Subscribe to the publisher passing a custom Flow.Subscriber&lt;Config&gt; implementation. Request the first event delivery in onSubscribe method. The config system invokes onNext each time the subtree rooted at the greeting node changes. The changedNode is a new instance of Config representing the updated subtree rooted at greeting , regardless of where in the subtree the change actually occurred. Remember to request the next event delivery in onNext . The config system does not currently invoke onError . The config system invokes onComplete if all config sources indicate there will be no other change event . Note Your application does not need to subscribe to the new Config instance passed to your onNext method. The original subscription remains in force for changes to the \"new\" instance. ",
            "title": "Responding to Changes in Config Sources"
        },
        {
            "location": "/se/config/05_mutability-support",
            "text": " Some applications do not need to respond to changes as they happen. Instead it&#8217;s sufficient that they simply have access to the current value for a particular key in the configuration. Each asXXX method on the Config class has a companion asXXXSupplier method. These supplier methods return Supplier&lt;XXX&gt; , and when your application invokes the supplier&#8217;s get method the config system returns the then-current value as stored in the config source. <markup lang=\"java\" title=\"Access greeting property as Supplier&lt;String&gt; \" >// Construct a Config with the appropriate PollingStrategy on each config source. Supplier&lt;String&gt; greetingSupplier = config.get(\"greeting\") .asString().supplier(); System.out.println(\"Always actual greeting value: \" + greetingSupplier.get()); Navigate to the Config node for which you want access to the always-current value. Retrieve and store the returned supplier for later use. Invoke the supplier&#8217;s get() method to retrieve the current value of the node. Important Supplier support requires that you create the Config object from config sources that have proper polling strategies set up. ",
            "title": "Accessing Always-current Values"
        },
        {
            "location": "/se/tracing/02_zipkin",
            "text": " Helidon is integrated with the Zipkin tracer. The Zipkin builder is loaded through ServiceLoader and configured. You could also use the Zipkin builder directly, though this would create a source-code dependency on the Zipkin tracer. ",
            "title": "preambule"
        },
        {
            "location": "/se/tracing/02_zipkin",
            "text": " To enable Zipkin Tracing add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-zipkin&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/tracing/02_zipkin",
            "text": " The Zipkin tracer supports the following configuration options: Key Default value Builder method Description service N/A serviceName Name of the service, to distinguish traces crossing service boundaries; Zipkin is using lower-case only, name will be automatically lower-cased protocol http collectorProtocol Protocol of the Zipkin trace collector (http or https) host localhost collectorHost Host of the Zipkin trace collector (IP Address, hostname, or FQDN) port 9411 collectorPort Port of the Zipkin trace collector path defined by version collectorPath Path of the Zipkin trace collector, each version uses a different path by default. api-version 2 version Zipkin specific method, set the protocol version to communicate with trace collector enabled true enabled If set to false, tracing would be disabled tags N/A addTracerTag(String, String) String tags to add to each span boolean-tags N/A addTracerTag(String, boolean) boolean tags to add to each span int-tags N/A addTracerTag(String, int) int tags to add to each span The following is an example of a Zipkin configuration, specified in the YAML format. <markup lang=\"yaml\" >tracing: zipkin: service: \"helidon-service\" protocol: \"https\" host: \"192.168.1.1\" port: 9987 api-version: 1 # this is the default path for API version 2 path: \"/api/v2/spans\" tags: tag1: \"tag1-value\" tag2: \"tag2-value\" boolean-tags: tag3: true tag4: false int-tags: tag5: 145 tag6: 741 Example of Zipkin trace: ",
            "title": "Configuring Zipkin"
        },
        {
            "location": "/se/reactivemessaging/03_connector",
            "text": " An explicit config for channel&#8217;s publisher is possible with Channel.Builder#publisherConfig(Config config) and for subscriber with Channel.Builder#subscriberConfig(Config config) . Supplied Helidon Config is merged with mandatory attributes and any implicit config found. Resulting config is served to Connector. <markup lang=\"java\" title=\"Example consuming from Kafka connector with explicit config:\" >String kafkaServer = config.get(\"app.kafka.bootstrap.servers\").asString().get(); String topic = config.get(\"app.kafka.topic\").asString().get(); Channel&lt;String&gt; fromKafka = Channel.&lt;String&gt;builder() .name(\"from-kafka\") .publisherConfig(KafkaConnector.configBuilder() .bootstrapServers(kafkaServer) .groupId(\"example-group-\" + session.getId()) .topic(topic) .autoOffsetReset(KafkaConfigBuilder.AutoOffsetReset.LATEST) .enableAutoCommit(true) .keyDeserializer(StringDeserializer.class) .valueDeserializer(StringDeserializer.class) .build() ) .build(); KafkaConnector kafkaConnector = KafkaConnector.create(); Messaging messaging = Messaging.builder() .connector(kafkaConnector) .listener(fromKafka, payload -&gt; { System.out.println(\"Kafka says: \" + payload); }) .build() .start(); Prepare channel for connecting kafka connector with specific publisher configuration &#8594; listener, Channel &#8594; connector mapping is automatic when using KafkaConnector.configBuilder() Prepare Kafka connector, can be used by any channel ",
            "title": "Explicit Config"
        },
        {
            "location": "/se/reactivemessaging/03_connector",
            "text": " Implicit config without any hard-coding is possible with Helidon Config following notation of MicroProfile Reactive Messaging . <markup lang=\"yaml\" title=\"Example of channel to connector mapping config with custom properties:\" >mp.messaging.incoming.from-connector-channel.connector: example-connector mp.messaging.incoming.from-connector-channel.first-test-prop: foo mp.messaging.connector.example-connector.second-test-prop: bar Channel &#8594; Connector mapping Channel configuration properties Connector configuration properties <markup lang=\"java\" title=\"Example consuming from connector:\" >Config config = Config.create(); Messaging.builder() .config(config) .connector(new ExampleConnector()) .listener(Channel.create(\"from-connector-channel\"), s -&gt; System.out.println(\"Consuming: \" + s)) .build() .start(); &gt; Consuming: foo &gt; Consuming: bar ",
            "title": "Implicit Config"
        },
        {
            "location": "/se/reactivemessaging/03_connector",
            "text": " Messaging connector in Helidon SE can be configured explicitly by API or implicitly by config following notation of MicroProfile Reactive Messaging . Configuration is being supplied to connector by Messaging implementation, two mandatory attributes are always present: channel-name name of the channel which has this connector configured as Publisher or Subscriber, Channel.create('name-of-channel') in case of explicit configuration or mp.messaging.incoming.name-of-channel.connector: connector-name in case of implicit config connector name of the connector @Connector(\"connector-name\") <markup lang=\"java\" title=\"Example connector accessing configuration:\" >@Connector(\"example-connector\") public class ExampleConnector implements IncomingConnectorFactory { @Override public PublisherBuilder&lt;? extends Message&lt;?&gt;&gt; getPublisherBuilder(final Config config) { String firstPropValue = config.getValue(\"first-test-prop\", String.class); String secondPropValue = config.getValue(\"second-test-prop\", String.class); return ReactiveStreams.of(firstPropValue, secondPropValue) .map(Message::of); } } Config context is merged from channel and connector contexts Explicit Config An explicit config for channel&#8217;s publisher is possible with Channel.Builder#publisherConfig(Config config) and for subscriber with Channel.Builder#subscriberConfig(Config config) . Supplied Helidon Config is merged with mandatory attributes and any implicit config found. Resulting config is served to Connector. <markup lang=\"java\" title=\"Example consuming from Kafka connector with explicit config:\" >String kafkaServer = config.get(\"app.kafka.bootstrap.servers\").asString().get(); String topic = config.get(\"app.kafka.topic\").asString().get(); Channel&lt;String&gt; fromKafka = Channel.&lt;String&gt;builder() .name(\"from-kafka\") .publisherConfig(KafkaConnector.configBuilder() .bootstrapServers(kafkaServer) .groupId(\"example-group-\" + session.getId()) .topic(topic) .autoOffsetReset(KafkaConfigBuilder.AutoOffsetReset.LATEST) .enableAutoCommit(true) .keyDeserializer(StringDeserializer.class) .valueDeserializer(StringDeserializer.class) .build() ) .build(); KafkaConnector kafkaConnector = KafkaConnector.create(); Messaging messaging = Messaging.builder() .connector(kafkaConnector) .listener(fromKafka, payload -&gt; { System.out.println(\"Kafka says: \" + payload); }) .build() .start(); Prepare channel for connecting kafka connector with specific publisher configuration &#8594; listener, Channel &#8594; connector mapping is automatic when using KafkaConnector.configBuilder() Prepare Kafka connector, can be used by any channel Implicit Config Implicit config without any hard-coding is possible with Helidon Config following notation of MicroProfile Reactive Messaging . <markup lang=\"yaml\" title=\"Example of channel to connector mapping config with custom properties:\" >mp.messaging.incoming.from-connector-channel.connector: example-connector mp.messaging.incoming.from-connector-channel.first-test-prop: foo mp.messaging.connector.example-connector.second-test-prop: bar Channel &#8594; Connector mapping Channel configuration properties Connector configuration properties <markup lang=\"java\" title=\"Example consuming from connector:\" >Config config = Config.create(); Messaging.builder() .config(config) .connector(new ExampleConnector()) .listener(Channel.create(\"from-connector-channel\"), s -&gt; System.out.println(\"Consuming: \" + s)) .build() .start(); &gt; Consuming: foo &gt; Consuming: bar ",
            "title": "Configuration"
        },
        {
            "location": "/se/reactivemessaging/03_connector",
            "text": " As the API is the same for MicroProfile Reactive Messaging connectors, all that is needed to make connector work in both ways is annotating it with @ApplicationScoped . Such connector is treated as a bean in Helidon MP. For specific informations about creating messaging connectors for Helidon MP visit Messaging Connector Bean . ",
            "title": "Reusability in MP Messaging"
        },
        {
            "location": "/se/reactivemessaging/03_connector",
            "text": " Connector for Reactive Messaging is a factory producing Publishers and Subscribers for Channels in Reactive Messaging. Messaging connector is just an implementation of IncomingConnectorFactory , OutgoingConnectorFactory or both. <markup lang=\"java\" title=\"Example connector example-connector :\" >@Connector(\"example-connector\") public class ExampleConnector implements IncomingConnectorFactory, OutgoingConnectorFactory { @Override public PublisherBuilder&lt;? extends Message&lt;?&gt;&gt; getPublisherBuilder(Config config) { return ReactiveStreams.of(\"foo\", \"bar\") .map(Message::of); } @Override public SubscriberBuilder&lt;? extends Message&lt;?&gt;, Void&gt; getSubscriberBuilder(Config config) { return ReactiveStreams.&lt;Message&lt;?&gt;&gt;builder() .map(Message::getPayload) .forEach(o -&gt; System.out.println(\"Connector says: \" + o)); } } <markup lang=\"yaml\" title=\"Example of channel to connector mapping config:\" >mp.messaging.outgoing.to-connector-channel.connector: example-connector mp.messaging.incoming.from-connector-channel.connector: example-connector <markup lang=\"java\" title=\"Example producing to connector:\" >Config config = Config.create(); Messaging.builder() .config(config) .connector(new ExampleConnector()) .publisher(Channel.create(\"to-connector-channel\"), ReactiveStreams.of(\"fee\", \"fie\") .map(Message::of) ) .build() .start(); &gt; Connector says: fee &gt; Connector says: fie <markup lang=\"java\" title=\"Example consuming from connector:\" >Messaging.builder() .connector(new ExampleConnector()) .subscriber(Channel.create(\"from-connector-channel\"), ReactiveStreams.&lt;Message&lt;String&gt;&gt;builder() .peek(Message::ack) .map(Message::getPayload) .forEach(s -&gt; System.out.println(\"Consuming: \" + s)) ) .build() .start(); &gt; Consuming: foo &gt; Consuming: bar Configuration Messaging connector in Helidon SE can be configured explicitly by API or implicitly by config following notation of MicroProfile Reactive Messaging . Configuration is being supplied to connector by Messaging implementation, two mandatory attributes are always present: channel-name name of the channel which has this connector configured as Publisher or Subscriber, Channel.create('name-of-channel') in case of explicit configuration or mp.messaging.incoming.name-of-channel.connector: connector-name in case of implicit config connector name of the connector @Connector(\"connector-name\") <markup lang=\"java\" title=\"Example connector accessing configuration:\" >@Connector(\"example-connector\") public class ExampleConnector implements IncomingConnectorFactory { @Override public PublisherBuilder&lt;? extends Message&lt;?&gt;&gt; getPublisherBuilder(final Config config) { String firstPropValue = config.getValue(\"first-test-prop\", String.class); String secondPropValue = config.getValue(\"second-test-prop\", String.class); return ReactiveStreams.of(firstPropValue, secondPropValue) .map(Message::of); } } Config context is merged from channel and connector contexts Explicit Config An explicit config for channel&#8217;s publisher is possible with Channel.Builder#publisherConfig(Config config) and for subscriber with Channel.Builder#subscriberConfig(Config config) . Supplied Helidon Config is merged with mandatory attributes and any implicit config found. Resulting config is served to Connector. <markup lang=\"java\" title=\"Example consuming from Kafka connector with explicit config:\" >String kafkaServer = config.get(\"app.kafka.bootstrap.servers\").asString().get(); String topic = config.get(\"app.kafka.topic\").asString().get(); Channel&lt;String&gt; fromKafka = Channel.&lt;String&gt;builder() .name(\"from-kafka\") .publisherConfig(KafkaConnector.configBuilder() .bootstrapServers(kafkaServer) .groupId(\"example-group-\" + session.getId()) .topic(topic) .autoOffsetReset(KafkaConfigBuilder.AutoOffsetReset.LATEST) .enableAutoCommit(true) .keyDeserializer(StringDeserializer.class) .valueDeserializer(StringDeserializer.class) .build() ) .build(); KafkaConnector kafkaConnector = KafkaConnector.create(); Messaging messaging = Messaging.builder() .connector(kafkaConnector) .listener(fromKafka, payload -&gt; { System.out.println(\"Kafka says: \" + payload); }) .build() .start(); Prepare channel for connecting kafka connector with specific publisher configuration &#8594; listener, Channel &#8594; connector mapping is automatic when using KafkaConnector.configBuilder() Prepare Kafka connector, can be used by any channel Implicit Config Implicit config without any hard-coding is possible with Helidon Config following notation of MicroProfile Reactive Messaging . <markup lang=\"yaml\" title=\"Example of channel to connector mapping config with custom properties:\" >mp.messaging.incoming.from-connector-channel.connector: example-connector mp.messaging.incoming.from-connector-channel.first-test-prop: foo mp.messaging.connector.example-connector.second-test-prop: bar Channel &#8594; Connector mapping Channel configuration properties Connector configuration properties <markup lang=\"java\" title=\"Example consuming from connector:\" >Config config = Config.create(); Messaging.builder() .config(config) .connector(new ExampleConnector()) .listener(Channel.create(\"from-connector-channel\"), s -&gt; System.out.println(\"Consuming: \" + s)) .build() .start(); &gt; Consuming: foo &gt; Consuming: bar Reusability in MP Messaging As the API is the same for MicroProfile Reactive Messaging connectors, all that is needed to make connector work in both ways is annotating it with @ApplicationScoped . Such connector is treated as a bean in Helidon MP. For specific informations about creating messaging connectors for Helidon MP visit Messaging Connector Bean . ",
            "title": "Messaging Connector"
        },
        {
            "location": "/se/security/03_containers-integration",
            "text": " There are two steps to configure security with web server: Create security instance and register it with server Protect routes of web server with various security features <markup lang=\"java\" title=\"Example using builders\" >// web server's Routing Routing.builder() // This is step 1 - register security instance with web server processing // security - instance of security either from config or from a builder // securityDefaults - default enforcement for each route that has a security definition .register(WebSecurity.create(security).securityDefaults(WebSecurity.authenticate())) // this is step 2 - protect a route // protect this route with authentication (from defaults) and role \"user\" .get(\"/service1\", WebSecurity.rolesAllowed(\"user\"), (req, res) -&gt; { processService1Request(req, res); }) .build(); <markup lang=\"java\" title=\"Example using configuration\" >Routing.builder() // helper method to load both security and web server security from configuration .register(WebSecurity.create(config)) // continue with web server route configuration .build(); <markup lang=\"yaml\" title=\"Example using configuration (YAML)\" ># This may change in the future - to align with web server configuration, once it is supported security.web-server: # Configuration of integration with web server defaults: authenticate: true paths: - path: \"/service1/[/{*}]\" methods: [\"get\"] roles-allowed: [\"user\"] ",
            "title": "Bootstrapping"
        },
        {
            "location": "/se/security/03_containers-integration",
            "text": " Integration of reactive web server <markup lang=\"xml\" title=\"Maven Dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.integration&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-integration-webserver&lt;/artifactId&gt; &lt;/dependency&gt; Bootstrapping There are two steps to configure security with web server: Create security instance and register it with server Protect routes of web server with various security features <markup lang=\"java\" title=\"Example using builders\" >// web server's Routing Routing.builder() // This is step 1 - register security instance with web server processing // security - instance of security either from config or from a builder // securityDefaults - default enforcement for each route that has a security definition .register(WebSecurity.create(security).securityDefaults(WebSecurity.authenticate())) // this is step 2 - protect a route // protect this route with authentication (from defaults) and role \"user\" .get(\"/service1\", WebSecurity.rolesAllowed(\"user\"), (req, res) -&gt; { processService1Request(req, res); }) .build(); <markup lang=\"java\" title=\"Example using configuration\" >Routing.builder() // helper method to load both security and web server security from configuration .register(WebSecurity.create(config)) // continue with web server route configuration .build(); <markup lang=\"yaml\" title=\"Example using configuration (YAML)\" ># This may change in the future - to align with web server configuration, once it is supported security.web-server: # Configuration of integration with web server defaults: authenticate: true paths: - path: \"/service1/[/{*}]\" methods: [\"get\"] roles-allowed: [\"user\"] ",
            "title": "Web server"
        },
        {
            "location": "/se/security/03_containers-integration",
            "text": " The configuration is usually placed under security.web-server (this can be customized in Helidon SE). The following shows an example we will explain in detail: <markup lang=\"yaml\" title=\"application.yaml\" >security: providers: - abac: - provider-key: web-server: defaults: authenticate: true paths: - path: \"/metrics[/{*}]\" roles-allowed: \"admin\" - path: \"/health[/{*}]\" roles-allowed: \"monitor\" - path: \"/openapi[/{*}]\" abac: scopes: [\"openapi\"] - path: \"/static[/{*}]\" roles-allowed: [\"user\", \"monitor\"] Attribute based access control provider that checks roles and scopes The provider(s) used in your application, such as oidc Default configuration for all configured paths Protection of /metrics and all nested paths with admin role required Protection of /health and all nested paths with monitor role required Protection of /openapi and all nested paths with openapi scope required Protection of static content configured on /static path with either user or monitor role required If you need to use a properties file, such as microprofile-config.properties , you can convert the file by using index based numbers for arrays, such as: <markup lang=\"properties\" title=\"microprofile-config.properties\" >security.providers.0.abac= security.providers.1.provider-key.optional=false security.web-server.defaults.authenticate=true security.web-server.paths.0.path=/metrics[/{*}] security.web-server.paths.0.roles-allowed=admin # .... security.web-server.paths.3.path=/static[/{*}] security.web-server.paths.3.roles-allowed=user,monitor ",
            "title": "Configuring endpoint protection"
        },
        {
            "location": "/se/security/03_containers-integration",
            "text": " There are several endpoints provided by Helidon services, such as: Health endpoint ( /health ) Metrics endpoint ( /metrics ) OpenAPI endpoint ( /openapi ) Configured static content (can use any path configured) These endpoints are all implemented using Helidon reactive WebServer and as such can be protected only through Security integration with WebServer. The following section describes configuration of such protection using configuration files, in this case using a yaml file, as it provides a tree structure. Configuring endpoint protection The configuration is usually placed under security.web-server (this can be customized in Helidon SE). The following shows an example we will explain in detail: <markup lang=\"yaml\" title=\"application.yaml\" >security: providers: - abac: - provider-key: web-server: defaults: authenticate: true paths: - path: \"/metrics[/{*}]\" roles-allowed: \"admin\" - path: \"/health[/{*}]\" roles-allowed: \"monitor\" - path: \"/openapi[/{*}]\" abac: scopes: [\"openapi\"] - path: \"/static[/{*}]\" roles-allowed: [\"user\", \"monitor\"] Attribute based access control provider that checks roles and scopes The provider(s) used in your application, such as oidc Default configuration for all configured paths Protection of /metrics and all nested paths with admin role required Protection of /health and all nested paths with monitor role required Protection of /openapi and all nested paths with openapi scope required Protection of static content configured on /static path with either user or monitor role required If you need to use a properties file, such as microprofile-config.properties , you can convert the file by using index based numbers for arrays, such as: <markup lang=\"properties\" title=\"microprofile-config.properties\" >security.providers.0.abac= security.providers.1.provider-key.optional=false security.web-server.defaults.authenticate=true security.web-server.paths.0.path=/metrics[/{*}] security.web-server.paths.0.roles-allowed=admin # .... security.web-server.paths.3.path=/static[/{*}] security.web-server.paths.3.roles-allowed=user,monitor ",
            "title": "Protecting Helidon endpoints"
        },
        {
            "location": "/se/security/03_containers-integration",
            "text": "<markup lang=\"java\" title=\"Integrate with Jersey\" >ResourceConfig resourceConfig = new ResourceConfig() // register JAX-RS resource .register(JaxRsResource.class) // integrate security .register(new io.helidon.security.jersey.SecurityFeature(security)); ",
            "title": "Inbound security"
        },
        {
            "location": "/se/security/03_containers-integration",
            "text": " Integration of Jersey (JAX-RS implementation) both for inbound and outbound security. <markup lang=\"xml\" title=\"Maven Dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.integration&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-integration-jersey&lt;/artifactId&gt; &lt;/dependency&gt; Inbound security <markup lang=\"java\" title=\"Integrate with Jersey\" >ResourceConfig resourceConfig = new ResourceConfig() // register JAX-RS resource .register(JaxRsResource.class) // integrate security .register(new io.helidon.security.jersey.SecurityFeature(security)); ",
            "title": "Jersey"
        },
        {
            "location": "/se/security/03_containers-integration",
            "text": " The current approach does not have a configuration option. The security must be configured through annotations. Security currently supports @Authenticated and @Authorized. When a resource is annotated with one of these annotations (application class, resource class, or resource method), security will be triggered. <markup lang=\"java\" title=\"Securing a resource method\" >// this is sufficient for security to be triggered, see javadoc for further details @Authenticated @Path(\"/{name}\") @GET @Produces(MediaType.TEXT_PLAIN) // due to Jersey approach to path matching, we need two methods to match both the \"root\" and \"root\" + subpaths public String getHelloName(@PathParam(\"name\") String name) { return \"Hello \" + name + \", your current subject: \" + securityContext.getSubject(); } ",
            "title": "Protecting a resource"
        },
        {
            "location": "/se/security/03_containers-integration",
            "text": " Outbound security is automatically registered with Jersey client. The provider must have outbound security configured for identity to be propagated. <markup lang=\"xml\" title=\"Maven Dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.integration&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-integration-jersey-client&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"java\" title=\"Call remote target with outbound security\" >Client client = ClientBuilder.newClient(); try { // call the resource, will propagate identity as configured in Security String response = client.target(\"http://www.google.com\") .request() // configure the security context for this request (as client and targets may be re-used) .property(ClientSecurity.PROPERTY_CONTEXT, securityContext) .get(String.class); } finally { client.close(); } ",
            "title": "Outbound security"
        },
        {
            "location": "/se/security/03_containers-integration",
            "text": "<markup lang=\"java\" title=\"Support in a JAX-RS resource\" >// inject io.helidon.security.SecurityContext @Context private SecurityContext securityContext; Outbound security Outbound security is automatically registered with Jersey client. The provider must have outbound security configured for identity to be propagated. <markup lang=\"xml\" title=\"Maven Dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.integration&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-integration-jersey-client&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"java\" title=\"Call remote target with outbound security\" >Client client = ClientBuilder.newClient(); try { // call the resource, will propagate identity as configured in Security String response = client.target(\"http://www.google.com\") .request() // configure the security context for this request (as client and targets may be re-used) .property(ClientSecurity.PROPERTY_CONTEXT, securityContext) .get(String.class); } finally { client.close(); } ",
            "title": "Access context"
        },
        {
            "location": "/se/security/03_containers-integration",
            "text": " The following containers are integrated with Helidon Security: Web server Integration of reactive web server <markup lang=\"xml\" title=\"Maven Dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.integration&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-integration-webserver&lt;/artifactId&gt; &lt;/dependency&gt; Bootstrapping There are two steps to configure security with web server: Create security instance and register it with server Protect routes of web server with various security features <markup lang=\"java\" title=\"Example using builders\" >// web server's Routing Routing.builder() // This is step 1 - register security instance with web server processing // security - instance of security either from config or from a builder // securityDefaults - default enforcement for each route that has a security definition .register(WebSecurity.create(security).securityDefaults(WebSecurity.authenticate())) // this is step 2 - protect a route // protect this route with authentication (from defaults) and role \"user\" .get(\"/service1\", WebSecurity.rolesAllowed(\"user\"), (req, res) -&gt; { processService1Request(req, res); }) .build(); <markup lang=\"java\" title=\"Example using configuration\" >Routing.builder() // helper method to load both security and web server security from configuration .register(WebSecurity.create(config)) // continue with web server route configuration .build(); <markup lang=\"yaml\" title=\"Example using configuration (YAML)\" ># This may change in the future - to align with web server configuration, once it is supported security.web-server: # Configuration of integration with web server defaults: authenticate: true paths: - path: \"/service1/[/{*}]\" methods: [\"get\"] roles-allowed: [\"user\"] Protecting Helidon endpoints There are several endpoints provided by Helidon services, such as: Health endpoint ( /health ) Metrics endpoint ( /metrics ) OpenAPI endpoint ( /openapi ) Configured static content (can use any path configured) These endpoints are all implemented using Helidon reactive WebServer and as such can be protected only through Security integration with WebServer. The following section describes configuration of such protection using configuration files, in this case using a yaml file, as it provides a tree structure. Configuring endpoint protection The configuration is usually placed under security.web-server (this can be customized in Helidon SE). The following shows an example we will explain in detail: <markup lang=\"yaml\" title=\"application.yaml\" >security: providers: - abac: - provider-key: web-server: defaults: authenticate: true paths: - path: \"/metrics[/{*}]\" roles-allowed: \"admin\" - path: \"/health[/{*}]\" roles-allowed: \"monitor\" - path: \"/openapi[/{*}]\" abac: scopes: [\"openapi\"] - path: \"/static[/{*}]\" roles-allowed: [\"user\", \"monitor\"] Attribute based access control provider that checks roles and scopes The provider(s) used in your application, such as oidc Default configuration for all configured paths Protection of /metrics and all nested paths with admin role required Protection of /health and all nested paths with monitor role required Protection of /openapi and all nested paths with openapi scope required Protection of static content configured on /static path with either user or monitor role required If you need to use a properties file, such as microprofile-config.properties , you can convert the file by using index based numbers for arrays, such as: <markup lang=\"properties\" title=\"microprofile-config.properties\" >security.providers.0.abac= security.providers.1.provider-key.optional=false security.web-server.defaults.authenticate=true security.web-server.paths.0.path=/metrics[/{*}] security.web-server.paths.0.roles-allowed=admin # .... security.web-server.paths.3.path=/static[/{*}] security.web-server.paths.3.roles-allowed=user,monitor Jersey Integration of Jersey (JAX-RS implementation) both for inbound and outbound security. <markup lang=\"xml\" title=\"Maven Dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.integration&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-integration-jersey&lt;/artifactId&gt; &lt;/dependency&gt; Inbound security <markup lang=\"java\" title=\"Integrate with Jersey\" >ResourceConfig resourceConfig = new ResourceConfig() // register JAX-RS resource .register(JaxRsResource.class) // integrate security .register(new io.helidon.security.jersey.SecurityFeature(security)); Protecting a resource The current approach does not have a configuration option. The security must be configured through annotations. Security currently supports @Authenticated and @Authorized. When a resource is annotated with one of these annotations (application class, resource class, or resource method), security will be triggered. <markup lang=\"java\" title=\"Securing a resource method\" >// this is sufficient for security to be triggered, see javadoc for further details @Authenticated @Path(\"/{name}\") @GET @Produces(MediaType.TEXT_PLAIN) // due to Jersey approach to path matching, we need two methods to match both the \"root\" and \"root\" + subpaths public String getHelloName(@PathParam(\"name\") String name) { return \"Hello \" + name + \", your current subject: \" + securityContext.getSubject(); } Access context <markup lang=\"java\" title=\"Support in a JAX-RS resource\" >// inject io.helidon.security.SecurityContext @Context private SecurityContext securityContext; Outbound security Outbound security is automatically registered with Jersey client. The provider must have outbound security configured for identity to be propagated. <markup lang=\"xml\" title=\"Maven Dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.integration&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-integration-jersey-client&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"java\" title=\"Call remote target with outbound security\" >Client client = ClientBuilder.newClient(); try { // call the resource, will propagate identity as configured in Security String response = client.target(\"http://www.google.com\") .request() // configure the security context for this request (as client and targets may be re-used) .property(ClientSecurity.PROPERTY_CONTEXT, securityContext) .get(String.class); } finally { client.close(); } ",
            "title": "Cloud Security Container Integrations"
        },
        {
            "location": "/se/config/08_supported-formats",
            "text": " Helidon Config provides several extension modules that support other configuration formats (parsers) and sources. This section describes how to add these modules to your build and how to use them from your application. ",
            "title": "preambule"
        },
        {
            "location": "/se/config/08_supported-formats",
            "text": " This document describes the additional config formats and sources the Helidon config system supports and how to include them and use them in your project. In each case you need to add module dependencies to your project and, in some cases, write your application accordingly. ",
            "title": "Introduction"
        },
        {
            "location": "/se/config/08_supported-formats",
            "text": " With each of the parsers described here, your application can either explicitly add a parser of the correct implementation to the Config.Builder , or rely on Java service loading and the config system&#8217;s matching of file types and media types to parsers. If your application creates a Config.Builder with parser services disabled (see disableParserServices then that builder will not find the Java services for the various parsers and so will be unable to match the file type or media type of sources with the corresponding parser automatically. So if you want to use automatic type matching with a given builder, do not invoke Config.Builder.disableParserServices() . ",
            "title": "Automatic Media Type and File Type Handling"
        },
        {
            "location": "/se/config/08_supported-formats",
            "text": " Add the following dependency in your project: <markup lang=\"xml\" title=\"Config YAML Dependency in pom.xml \" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.config&lt;/groupId&gt; &lt;artifactId&gt;helidon-config-yaml&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"java\" title=\"Config YAML Dependency in module-info.java \" >module myModule { requires io.helidon.config.yaml; } ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/config/08_supported-formats",
            "text": " The YAML parser handles the following media type: application/x-yaml - YAML format (file type .yaml ) <markup lang=\"java\" title=\"Automatic selection\" >Config config = Config.create(classpath(\"application.yaml\")); The config system automatically maps the file type .yaml to the media type application/x-yaml which the Helidon YAML parser matches. <markup lang=\"java\" title=\"YAML parser specified - no file type on source\" >Config config = Config.create(classpath(\"my-config\") .parser(YamlConfigParserBuilder.buildDefault())); The media type of the source my-config is unknown, so the config system cannot choose a parser automatically. The config system will parse the resource my-config on the runtime classpath using the YAML parser instance created by the YamlConfigParserBuilder . The buildDefault() method creates a config parser with default behavior. <markup lang=\"java\" title=\"Media type specified\" >Config config = Config.create(classpath(\"my-config\") .mediaType(\"application/x-yaml\")); The media type of the source my-config is unknown, so the config system cannot choose a parser automatically. Specifying the media type for the config source allows the config system to use its matching algorithm with the available parsers to choose a parser for that type. <markup lang=\"java\" title=\"YAML parser specified because parser services disabled\" >Config config = Config.builder(classpath(\"application.yaml\")) .disableParserServices() .addParser(YamlConfigParserBuilder.buildDefault()) .build(); Disables automatic parser lookup and registration. Explicit registration of the YAML parser is therefore required. ",
            "title": "Using the YAML Parser"
        },
        {
            "location": "/se/config/08_supported-formats",
            "text": " Maven Coordinates Add the following dependency in your project: <markup lang=\"xml\" title=\"Config YAML Dependency in pom.xml \" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.config&lt;/groupId&gt; &lt;artifactId&gt;helidon-config-yaml&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"java\" title=\"Config YAML Dependency in module-info.java \" >module myModule { requires io.helidon.config.yaml; } Using the YAML Parser The YAML parser handles the following media type: application/x-yaml - YAML format (file type .yaml ) <markup lang=\"java\" title=\"Automatic selection\" >Config config = Config.create(classpath(\"application.yaml\")); The config system automatically maps the file type .yaml to the media type application/x-yaml which the Helidon YAML parser matches. <markup lang=\"java\" title=\"YAML parser specified - no file type on source\" >Config config = Config.create(classpath(\"my-config\") .parser(YamlConfigParserBuilder.buildDefault())); The media type of the source my-config is unknown, so the config system cannot choose a parser automatically. The config system will parse the resource my-config on the runtime classpath using the YAML parser instance created by the YamlConfigParserBuilder . The buildDefault() method creates a config parser with default behavior. <markup lang=\"java\" title=\"Media type specified\" >Config config = Config.create(classpath(\"my-config\") .mediaType(\"application/x-yaml\")); The media type of the source my-config is unknown, so the config system cannot choose a parser automatically. Specifying the media type for the config source allows the config system to use its matching algorithm with the available parsers to choose a parser for that type. <markup lang=\"java\" title=\"YAML parser specified because parser services disabled\" >Config config = Config.builder(classpath(\"application.yaml\")) .disableParserServices() .addParser(YamlConfigParserBuilder.buildDefault()) .build(); Disables automatic parser lookup and registration. Explicit registration of the YAML parser is therefore required. ",
            "title": "YAML"
        },
        {
            "location": "/se/config/08_supported-formats",
            "text": " Add the following dependency in your project: <markup lang=\"xml\" title=\"Config HOCON Dependency in pom.xml \" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.config&lt;/groupId&gt; &lt;artifactId&gt;helidon-config-hocon&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"java\" title=\"Config HOCON Dependency in module-info.java \" >module myModule { requires io.helidon.config.hocon; } ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/config/08_supported-formats",
            "text": " The parser handles the following media types: application/hocon - HOCON format (file type .conf ) application/json - JSON format (file type .json ) <markup lang=\"java\" title=\"Automatic selection\" >Config config = Config.create(classpath(\"application.conf\")); The config system automatically maps the file type .conf to the media type `application/hocon which the Helidon HOCON parser matches. The same module and parser supports file type .json and the media type application/json . <markup lang=\"java\" title=\"HOCON parser specified - no file type on source\" >Config config = Config.create(classpath(\"my-config\") .parser(HoconConfigParserBuilder.buildDefault())); the media type of the source `my-config`is unknown, so the config system cannot choose a parser automatically. The config system will parse the resource my-config using the HOCON parser created by the HoconConfigParserBuilder . The buildDefault() method creates a config parser with default behavior. <markup lang=\"java\" title=\"Media type specified\" >Config config = Config.create(classpath(\"my-config\") .mediaType(\"application/hocon\")); The media type of the source my-config is unknown, so the config system cannot choose a parser automatically. Specifying the media type for the config source allows the config system to use its matching algorithm with the available parsers to choose a parser for that type. <markup lang=\"java\" title=\"HOCON parser specified because parser services disabled\" >Config config = Config.builder(classpath(\"application.conf\")) .disableParserServices() .addParser(HoconConfigParserBuilder.buildDefault()) .build(); Disables automatic parser lookup and registration. Explicit registration of the HOCON parser is therefore required. <markup lang=\"java\" title=\"Customized HOCON parser\" >Config config = Config.builder(classpath(\"application.conf\")) .disableParserServices() .addParser(HoconConfigParserBuilder.create() .disableResolving() .build()) .build(); Creates new instance of the parser builder. Disables resolution of substitutions. (See the HOCON documentation .) Builds a new instance of the HOCON config parser. You can also specify ConfigResolveOptions using the HoconConfigParserBuilder.resolveOptions method. ",
            "title": "Using the HOCON/JSON Parser"
        },
        {
            "location": "/se/config/08_supported-formats",
            "text": " The Helidon HOCON config module handles sources in the HOCON and JSON formats. Maven Coordinates Add the following dependency in your project: <markup lang=\"xml\" title=\"Config HOCON Dependency in pom.xml \" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.config&lt;/groupId&gt; &lt;artifactId&gt;helidon-config-hocon&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"java\" title=\"Config HOCON Dependency in module-info.java \" >module myModule { requires io.helidon.config.hocon; } Using the HOCON/JSON Parser The parser handles the following media types: application/hocon - HOCON format (file type .conf ) application/json - JSON format (file type .json ) <markup lang=\"java\" title=\"Automatic selection\" >Config config = Config.create(classpath(\"application.conf\")); The config system automatically maps the file type .conf to the media type `application/hocon which the Helidon HOCON parser matches. The same module and parser supports file type .json and the media type application/json . <markup lang=\"java\" title=\"HOCON parser specified - no file type on source\" >Config config = Config.create(classpath(\"my-config\") .parser(HoconConfigParserBuilder.buildDefault())); the media type of the source `my-config`is unknown, so the config system cannot choose a parser automatically. The config system will parse the resource my-config using the HOCON parser created by the HoconConfigParserBuilder . The buildDefault() method creates a config parser with default behavior. <markup lang=\"java\" title=\"Media type specified\" >Config config = Config.create(classpath(\"my-config\") .mediaType(\"application/hocon\")); The media type of the source my-config is unknown, so the config system cannot choose a parser automatically. Specifying the media type for the config source allows the config system to use its matching algorithm with the available parsers to choose a parser for that type. <markup lang=\"java\" title=\"HOCON parser specified because parser services disabled\" >Config config = Config.builder(classpath(\"application.conf\")) .disableParserServices() .addParser(HoconConfigParserBuilder.buildDefault()) .build(); Disables automatic parser lookup and registration. Explicit registration of the HOCON parser is therefore required. <markup lang=\"java\" title=\"Customized HOCON parser\" >Config config = Config.builder(classpath(\"application.conf\")) .disableParserServices() .addParser(HoconConfigParserBuilder.create() .disableResolving() .build()) .build(); Creates new instance of the parser builder. Disables resolution of substitutions. (See the HOCON documentation .) Builds a new instance of the HOCON config parser. You can also specify ConfigResolveOptions using the HoconConfigParserBuilder.resolveOptions method. ",
            "title": "HOCON/JSON"
        },
        {
            "location": "/se/config/08_supported-formats",
            "text": " Automatic Media Type and File Type Handling With each of the parsers described here, your application can either explicitly add a parser of the correct implementation to the Config.Builder , or rely on Java service loading and the config system&#8217;s matching of file types and media types to parsers. If your application creates a Config.Builder with parser services disabled (see disableParserServices then that builder will not find the Java services for the various parsers and so will be unable to match the file type or media type of sources with the corresponding parser automatically. So if you want to use automatic type matching with a given builder, do not invoke Config.Builder.disableParserServices() . YAML Maven Coordinates Add the following dependency in your project: <markup lang=\"xml\" title=\"Config YAML Dependency in pom.xml \" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.config&lt;/groupId&gt; &lt;artifactId&gt;helidon-config-yaml&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"java\" title=\"Config YAML Dependency in module-info.java \" >module myModule { requires io.helidon.config.yaml; } Using the YAML Parser The YAML parser handles the following media type: application/x-yaml - YAML format (file type .yaml ) <markup lang=\"java\" title=\"Automatic selection\" >Config config = Config.create(classpath(\"application.yaml\")); The config system automatically maps the file type .yaml to the media type application/x-yaml which the Helidon YAML parser matches. <markup lang=\"java\" title=\"YAML parser specified - no file type on source\" >Config config = Config.create(classpath(\"my-config\") .parser(YamlConfigParserBuilder.buildDefault())); The media type of the source my-config is unknown, so the config system cannot choose a parser automatically. The config system will parse the resource my-config on the runtime classpath using the YAML parser instance created by the YamlConfigParserBuilder . The buildDefault() method creates a config parser with default behavior. <markup lang=\"java\" title=\"Media type specified\" >Config config = Config.create(classpath(\"my-config\") .mediaType(\"application/x-yaml\")); The media type of the source my-config is unknown, so the config system cannot choose a parser automatically. Specifying the media type for the config source allows the config system to use its matching algorithm with the available parsers to choose a parser for that type. <markup lang=\"java\" title=\"YAML parser specified because parser services disabled\" >Config config = Config.builder(classpath(\"application.yaml\")) .disableParserServices() .addParser(YamlConfigParserBuilder.buildDefault()) .build(); Disables automatic parser lookup and registration. Explicit registration of the YAML parser is therefore required. HOCON/JSON The Helidon HOCON config module handles sources in the HOCON and JSON formats. Maven Coordinates Add the following dependency in your project: <markup lang=\"xml\" title=\"Config HOCON Dependency in pom.xml \" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.config&lt;/groupId&gt; &lt;artifactId&gt;helidon-config-hocon&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"java\" title=\"Config HOCON Dependency in module-info.java \" >module myModule { requires io.helidon.config.hocon; } Using the HOCON/JSON Parser The parser handles the following media types: application/hocon - HOCON format (file type .conf ) application/json - JSON format (file type .json ) <markup lang=\"java\" title=\"Automatic selection\" >Config config = Config.create(classpath(\"application.conf\")); The config system automatically maps the file type .conf to the media type `application/hocon which the Helidon HOCON parser matches. The same module and parser supports file type .json and the media type application/json . <markup lang=\"java\" title=\"HOCON parser specified - no file type on source\" >Config config = Config.create(classpath(\"my-config\") .parser(HoconConfigParserBuilder.buildDefault())); the media type of the source `my-config`is unknown, so the config system cannot choose a parser automatically. The config system will parse the resource my-config using the HOCON parser created by the HoconConfigParserBuilder . The buildDefault() method creates a config parser with default behavior. <markup lang=\"java\" title=\"Media type specified\" >Config config = Config.create(classpath(\"my-config\") .mediaType(\"application/hocon\")); The media type of the source my-config is unknown, so the config system cannot choose a parser automatically. Specifying the media type for the config source allows the config system to use its matching algorithm with the available parsers to choose a parser for that type. <markup lang=\"java\" title=\"HOCON parser specified because parser services disabled\" >Config config = Config.builder(classpath(\"application.conf\")) .disableParserServices() .addParser(HoconConfigParserBuilder.buildDefault()) .build(); Disables automatic parser lookup and registration. Explicit registration of the HOCON parser is therefore required. <markup lang=\"java\" title=\"Customized HOCON parser\" >Config config = Config.builder(classpath(\"application.conf\")) .disableParserServices() .addParser(HoconConfigParserBuilder.create() .disableResolving() .build()) .build(); Creates new instance of the parser builder. Disables resolution of substitutions. (See the HOCON documentation .) Builds a new instance of the HOCON config parser. You can also specify ConfigResolveOptions using the HoconConfigParserBuilder.resolveOptions method. ",
            "title": "Additional Config Formats and Parsers"
        },
        {
            "location": "/se/config/08_supported-formats",
            "text": " Add the following dependency to your project: <markup lang=\"xml\" title=\"Config Etcd Dependency in pom.xml \" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.config&lt;/groupId&gt; &lt;artifactId&gt;helidon-config-etcd&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"java\" title=\"Config Etcd Dependency in module-info.java \" >module myModule { requires io.helidon.config.etcd; } ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/config/08_supported-formats",
            "text": " To read configuration from an Etcd source, your application uses the EtcdConfigSourceBuilder . <markup lang=\"java\" title=\"Use Etcd config source\" >Config config = Config.create( EtcdConfigSourceBuilder .create(URI.create(\"http://my-etcd:2379\"), \"/config.yaml\", EtcdConfigSourceBuilder.EtcdApi.v3)); Use the factory method EtcdConfigSourceBuilder.create to initialize the builder. Specify the Etcd endpoint address. Specify the Etcd key of the configuration document. Version of the Etcd API to use; v2 and v3 are supported. The config system will use the YAML parser automatically in this example because the file type of the key is .yaml . The EtcdConfigSourceBuilder class extends AbstractParsableConfigSource.Builder and so supports the usual settings on config sources. ",
            "title": "Using the Etcd Config Source"
        },
        {
            "location": "/se/config/08_supported-formats",
            "text": " The Etcd support includes a polling strategy designed for an etcd config source. <markup lang=\"java\" title=\"Use Etcd config source\" >Config config = Config.create( EtcdConfigSourceBuilder .create(URI.create(\"http://my-etcd:2379\"), \"/config.yaml\", EtcdApi.v3) .pollingStrategy(EtcdWatchPollingStrategy::new)); Use the etcd-specific polling strategy. ",
            "title": "Monitoring for Source Changes"
        },
        {
            "location": "/se/config/08_supported-formats",
            "text": " The config system can load information about config sources from meta-configuration rather than requiring your application to construct the builder. To read meta-configuration from an Etcd source set the following required properties for the source: type to etcd , or class to io.helidon.config.etcd.EtcdConfigSourceBuilder uri (type URI ) - Etcd endpoint URI. key (type String ) - Etcd key that is associated with the configuration. api (type EtcdConfigSourceBuilder.EtcdApi , i.e. v2 or v3 ) - Etcd API version. Other optional properties are inherited from AbstractParsableConfigSource.Builder . (see javadoc ) <markup lang=\"java\" title=\"Load Config from meta-configuration\" >Config config = Config.loadSourcesFrom(classpath(\"config-meta-etcd.yaml\")); <markup lang=\"YAML\" title=\"Meta-config config-meta-etcd.yaml for the etcd source\" >sources: - type: \"etcd\" properties: uri: \"http://my-etcd:2379\" key: \"/config.yaml\" api: \"v3\" polling-strategy: class: \"io.helidon.config.etcd.EtcdWatchPollingStrategy\" etcd config source type Etcd source-specific (mandatory) properties : uri , key and api . Polling strategy EtcdWatchPollingStrategy is automatically initialized by specified mandatory properties . ",
            "title": "Loading Meta-configuration via Etcd"
        },
        {
            "location": "/se/config/08_supported-formats",
            "text": " The Helidon Etcd config module supports reading configuration from a specified Etcd key. Maven Coordinates Add the following dependency to your project: <markup lang=\"xml\" title=\"Config Etcd Dependency in pom.xml \" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.config&lt;/groupId&gt; &lt;artifactId&gt;helidon-config-etcd&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"java\" title=\"Config Etcd Dependency in module-info.java \" >module myModule { requires io.helidon.config.etcd; } Using the Etcd Config Source To read configuration from an Etcd source, your application uses the EtcdConfigSourceBuilder . <markup lang=\"java\" title=\"Use Etcd config source\" >Config config = Config.create( EtcdConfigSourceBuilder .create(URI.create(\"http://my-etcd:2379\"), \"/config.yaml\", EtcdConfigSourceBuilder.EtcdApi.v3)); Use the factory method EtcdConfigSourceBuilder.create to initialize the builder. Specify the Etcd endpoint address. Specify the Etcd key of the configuration document. Version of the Etcd API to use; v2 and v3 are supported. The config system will use the YAML parser automatically in this example because the file type of the key is .yaml . The EtcdConfigSourceBuilder class extends AbstractParsableConfigSource.Builder and so supports the usual settings on config sources. Monitoring for Source Changes The Etcd support includes a polling strategy designed for an etcd config source. <markup lang=\"java\" title=\"Use Etcd config source\" >Config config = Config.create( EtcdConfigSourceBuilder .create(URI.create(\"http://my-etcd:2379\"), \"/config.yaml\", EtcdApi.v3) .pollingStrategy(EtcdWatchPollingStrategy::new)); Use the etcd-specific polling strategy. Loading Meta-configuration via Etcd The config system can load information about config sources from meta-configuration rather than requiring your application to construct the builder. To read meta-configuration from an Etcd source set the following required properties for the source: type to etcd , or class to io.helidon.config.etcd.EtcdConfigSourceBuilder uri (type URI ) - Etcd endpoint URI. key (type String ) - Etcd key that is associated with the configuration. api (type EtcdConfigSourceBuilder.EtcdApi , i.e. v2 or v3 ) - Etcd API version. Other optional properties are inherited from AbstractParsableConfigSource.Builder . (see javadoc ) <markup lang=\"java\" title=\"Load Config from meta-configuration\" >Config config = Config.loadSourcesFrom(classpath(\"config-meta-etcd.yaml\")); <markup lang=\"YAML\" title=\"Meta-config config-meta-etcd.yaml for the etcd source\" >sources: - type: \"etcd\" properties: uri: \"http://my-etcd:2379\" key: \"/config.yaml\" api: \"v3\" polling-strategy: class: \"io.helidon.config.etcd.EtcdWatchPollingStrategy\" etcd config source type Etcd source-specific (mandatory) properties : uri , key and api . Polling strategy EtcdWatchPollingStrategy is automatically initialized by specified mandatory properties . ",
            "title": "Etcd"
        },
        {
            "location": "/se/config/08_supported-formats",
            "text": " Add the following dependency to your project: <markup lang=\"xml\" title=\"Config git Dependency in pom.xml \" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.config&lt;/groupId&gt; &lt;artifactId&gt;helidon-config-git&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"java\" title=\"Config git Dependency in module-info.java \" >module myModule { requires io.helidon.config.git; } ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/config/08_supported-formats",
            "text": " To read configuration from a git source, your application uses the GitConfigSourceBuilder . <markup lang=\"java\" title=\"Use git config source\" >Config config = Config.create( GitConfigSourceBuilder .create(\"application.conf\") .uri(URI.create(\"https://github.com/okosatka/test-config.git\")) .directory(Paths.get(\"/config\")) .branch(\"dev\")); Use the factory method GitConfigSourceBuilder.create to initialize the builder with a mandatory path to the configuration file. Specify the git repository URI. Specify a directory where the git repository is already cloned or it will be cloned. Specify the git branch. Note that the config system will use the HOCON parser in this example because the file type is .conf . Recall that for this to work the HOCON config module must be on module-path or classpath. The GitConfigSourceBuilder supports the usual source builder properties because it extends AbstractParsableConfigSource.Builder . ",
            "title": "Using the git Config Source"
        },
        {
            "location": "/se/config/08_supported-formats",
            "text": " Your application can monitor changes to a configuration loaded from a git source associating the regular built-in polling strategy with the source. <markup lang=\"java\" title=\"Use of git config source with polling strategy\" >Config config = Config.create( GitConfigSourceBuilder .create(\"application.conf\") .uri(URI.create(\"https://github.com/okosatka/test-config.git\")) .pollingStrategy(PollingStrategies.regular(Duration.ofMinutes(5)))); Use PollingStrategies.regular(Duration duration) to monitor for config changes. You can also implement your own polling strategy by implementing PollingStrategy . See the mutability support and polling strategy discussions. ",
            "title": "Monitoring for Source Changes"
        },
        {
            "location": "/se/config/08_supported-formats",
            "text": " The config system can load information about config sources from meta-configuration rather than requiring your application to construct the builder. To read meta-configuration from a git config source set the following properties for the source: type to git or class to io.helidon.config.git.GitConfigSourceBuilder path (type String ) - Relative path to the configuration file in repository. uri (type URI ) - URI to the git repository. directory (type Path ) - Directory with a cloned repository, by default a temporary directory. branch (type String ) - git branch (default is master ). The meta-configuration must set the path and one of uri or directory . Other optional properties are inherited from AbstractParsableConfigSource.Builder (see javadoc ) <markup lang=\"java\" title=\"Load Config from meta-configuration\" >Config config = Config.loadSourcesFrom(classpath(\"config-meta-git.yaml\")); <markup lang=\"YAML\" title=\"Meta-config config-meta-git.yaml for the git source\" >sources: - type: \"git\" properties: path: \"application.conf\" uri: \"https://github.com/okosatka/test-config.git\" directory: \"/config\" branch: \"dev\" polling-strategy: type: \"regular\" properties: interval: \"PT5M\" git config source type git source-specific properties: path , uri , directory and branch . Polling strategy regular with an interval, in Duration format, of 5 minutes in this example. ",
            "title": "Loading Meta-configuration via git"
        },
        {
            "location": "/se/config/08_supported-formats",
            "text": " The Helidon git config module supports reading configuration from a git repository. Maven Coordinates Add the following dependency to your project: <markup lang=\"xml\" title=\"Config git Dependency in pom.xml \" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.config&lt;/groupId&gt; &lt;artifactId&gt;helidon-config-git&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"java\" title=\"Config git Dependency in module-info.java \" >module myModule { requires io.helidon.config.git; } Using the git Config Source To read configuration from a git source, your application uses the GitConfigSourceBuilder . <markup lang=\"java\" title=\"Use git config source\" >Config config = Config.create( GitConfigSourceBuilder .create(\"application.conf\") .uri(URI.create(\"https://github.com/okosatka/test-config.git\")) .directory(Paths.get(\"/config\")) .branch(\"dev\")); Use the factory method GitConfigSourceBuilder.create to initialize the builder with a mandatory path to the configuration file. Specify the git repository URI. Specify a directory where the git repository is already cloned or it will be cloned. Specify the git branch. Note that the config system will use the HOCON parser in this example because the file type is .conf . Recall that for this to work the HOCON config module must be on module-path or classpath. The GitConfigSourceBuilder supports the usual source builder properties because it extends AbstractParsableConfigSource.Builder . Monitoring for Source Changes Your application can monitor changes to a configuration loaded from a git source associating the regular built-in polling strategy with the source. <markup lang=\"java\" title=\"Use of git config source with polling strategy\" >Config config = Config.create( GitConfigSourceBuilder .create(\"application.conf\") .uri(URI.create(\"https://github.com/okosatka/test-config.git\")) .pollingStrategy(PollingStrategies.regular(Duration.ofMinutes(5)))); Use PollingStrategies.regular(Duration duration) to monitor for config changes. You can also implement your own polling strategy by implementing PollingStrategy . See the mutability support and polling strategy discussions. Loading Meta-configuration via git The config system can load information about config sources from meta-configuration rather than requiring your application to construct the builder. To read meta-configuration from a git config source set the following properties for the source: type to git or class to io.helidon.config.git.GitConfigSourceBuilder path (type String ) - Relative path to the configuration file in repository. uri (type URI ) - URI to the git repository. directory (type Path ) - Directory with a cloned repository, by default a temporary directory. branch (type String ) - git branch (default is master ). The meta-configuration must set the path and one of uri or directory . Other optional properties are inherited from AbstractParsableConfigSource.Builder (see javadoc ) <markup lang=\"java\" title=\"Load Config from meta-configuration\" >Config config = Config.loadSourcesFrom(classpath(\"config-meta-git.yaml\")); <markup lang=\"YAML\" title=\"Meta-config config-meta-git.yaml for the git source\" >sources: - type: \"git\" properties: path: \"application.conf\" uri: \"https://github.com/okosatka/test-config.git\" directory: \"/config\" branch: \"dev\" polling-strategy: type: \"regular\" properties: interval: \"PT5M\" git config source type git source-specific properties: path , uri , directory and branch . Polling strategy regular with an interval, in Duration format, of 5 minutes in this example. ",
            "title": "git"
        },
        {
            "location": "/se/config/08_supported-formats",
            "text": " Etcd The Helidon Etcd config module supports reading configuration from a specified Etcd key. Maven Coordinates Add the following dependency to your project: <markup lang=\"xml\" title=\"Config Etcd Dependency in pom.xml \" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.config&lt;/groupId&gt; &lt;artifactId&gt;helidon-config-etcd&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"java\" title=\"Config Etcd Dependency in module-info.java \" >module myModule { requires io.helidon.config.etcd; } Using the Etcd Config Source To read configuration from an Etcd source, your application uses the EtcdConfigSourceBuilder . <markup lang=\"java\" title=\"Use Etcd config source\" >Config config = Config.create( EtcdConfigSourceBuilder .create(URI.create(\"http://my-etcd:2379\"), \"/config.yaml\", EtcdConfigSourceBuilder.EtcdApi.v3)); Use the factory method EtcdConfigSourceBuilder.create to initialize the builder. Specify the Etcd endpoint address. Specify the Etcd key of the configuration document. Version of the Etcd API to use; v2 and v3 are supported. The config system will use the YAML parser automatically in this example because the file type of the key is .yaml . The EtcdConfigSourceBuilder class extends AbstractParsableConfigSource.Builder and so supports the usual settings on config sources. Monitoring for Source Changes The Etcd support includes a polling strategy designed for an etcd config source. <markup lang=\"java\" title=\"Use Etcd config source\" >Config config = Config.create( EtcdConfigSourceBuilder .create(URI.create(\"http://my-etcd:2379\"), \"/config.yaml\", EtcdApi.v3) .pollingStrategy(EtcdWatchPollingStrategy::new)); Use the etcd-specific polling strategy. Loading Meta-configuration via Etcd The config system can load information about config sources from meta-configuration rather than requiring your application to construct the builder. To read meta-configuration from an Etcd source set the following required properties for the source: type to etcd , or class to io.helidon.config.etcd.EtcdConfigSourceBuilder uri (type URI ) - Etcd endpoint URI. key (type String ) - Etcd key that is associated with the configuration. api (type EtcdConfigSourceBuilder.EtcdApi , i.e. v2 or v3 ) - Etcd API version. Other optional properties are inherited from AbstractParsableConfigSource.Builder . (see javadoc ) <markup lang=\"java\" title=\"Load Config from meta-configuration\" >Config config = Config.loadSourcesFrom(classpath(\"config-meta-etcd.yaml\")); <markup lang=\"YAML\" title=\"Meta-config config-meta-etcd.yaml for the etcd source\" >sources: - type: \"etcd\" properties: uri: \"http://my-etcd:2379\" key: \"/config.yaml\" api: \"v3\" polling-strategy: class: \"io.helidon.config.etcd.EtcdWatchPollingStrategy\" etcd config source type Etcd source-specific (mandatory) properties : uri , key and api . Polling strategy EtcdWatchPollingStrategy is automatically initialized by specified mandatory properties . git The Helidon git config module supports reading configuration from a git repository. Maven Coordinates Add the following dependency to your project: <markup lang=\"xml\" title=\"Config git Dependency in pom.xml \" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.config&lt;/groupId&gt; &lt;artifactId&gt;helidon-config-git&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"java\" title=\"Config git Dependency in module-info.java \" >module myModule { requires io.helidon.config.git; } Using the git Config Source To read configuration from a git source, your application uses the GitConfigSourceBuilder . <markup lang=\"java\" title=\"Use git config source\" >Config config = Config.create( GitConfigSourceBuilder .create(\"application.conf\") .uri(URI.create(\"https://github.com/okosatka/test-config.git\")) .directory(Paths.get(\"/config\")) .branch(\"dev\")); Use the factory method GitConfigSourceBuilder.create to initialize the builder with a mandatory path to the configuration file. Specify the git repository URI. Specify a directory where the git repository is already cloned or it will be cloned. Specify the git branch. Note that the config system will use the HOCON parser in this example because the file type is .conf . Recall that for this to work the HOCON config module must be on module-path or classpath. The GitConfigSourceBuilder supports the usual source builder properties because it extends AbstractParsableConfigSource.Builder . Monitoring for Source Changes Your application can monitor changes to a configuration loaded from a git source associating the regular built-in polling strategy with the source. <markup lang=\"java\" title=\"Use of git config source with polling strategy\" >Config config = Config.create( GitConfigSourceBuilder .create(\"application.conf\") .uri(URI.create(\"https://github.com/okosatka/test-config.git\")) .pollingStrategy(PollingStrategies.regular(Duration.ofMinutes(5)))); Use PollingStrategies.regular(Duration duration) to monitor for config changes. You can also implement your own polling strategy by implementing PollingStrategy . See the mutability support and polling strategy discussions. Loading Meta-configuration via git The config system can load information about config sources from meta-configuration rather than requiring your application to construct the builder. To read meta-configuration from a git config source set the following properties for the source: type to git or class to io.helidon.config.git.GitConfigSourceBuilder path (type String ) - Relative path to the configuration file in repository. uri (type URI ) - URI to the git repository. directory (type Path ) - Directory with a cloned repository, by default a temporary directory. branch (type String ) - git branch (default is master ). The meta-configuration must set the path and one of uri or directory . Other optional properties are inherited from AbstractParsableConfigSource.Builder (see javadoc ) <markup lang=\"java\" title=\"Load Config from meta-configuration\" >Config config = Config.loadSourcesFrom(classpath(\"config-meta-git.yaml\")); <markup lang=\"YAML\" title=\"Meta-config config-meta-git.yaml for the git source\" >sources: - type: \"git\" properties: path: \"application.conf\" uri: \"https://github.com/okosatka/test-config.git\" directory: \"/config\" branch: \"dev\" polling-strategy: type: \"regular\" properties: interval: \"PT5M\" git config source type git source-specific properties: path , uri , directory and branch . Polling strategy regular with an interval, in Duration format, of 5 minutes in this example. ",
            "title": "Additional Config Source Types"
        },
        {
            "location": "/mp/config/01_introduction",
            "text": " Helidon&#8217;s MicroProfile Config, an implementation of Eclipse MicroProfile Config, enables you to configure your applications using MicroProfile’s config configuration sources and APIs. ",
            "title": "preambule"
        },
        {
            "location": "/mp/config/01_introduction",
            "text": " To enable MicroProfile Config either add a dependency on the helidon-microprofile bundle or add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.config&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-config&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/config/01_introduction",
            "text": " You can use MicroProfile Config API to get configuration properties by using ConfigProvider.getConfig() or injecting configuration values with @ConfigProperty . <markup lang=\"java\" title=\"Using ConfigProvider.getConfig()\" >org.eclipse.microprofile.config.Config config = ConfigProvider.getConfig(); config.getOptionalValue(\"app.greeting\", String.class).orElse(\"Hello\"); <markup lang=\"java\" title=\"Injecting configured properties into a constructor\" >@Inject public GreetingProvider(@ConfigProperty(name = \"app.greeting\", defaultValue = \"Hello\") String message) { this.message = message } ",
            "title": "Using MicroProfile Config API"
        },
        {
            "location": "/mp/config/01_introduction",
            "text": " The example below shows how the MicroProfile configuration file microprofile-config.properties can be used to modify the server listen port property. <markup lang=\"properties\" >// Application properties. This is the default greeting app.greeting=Hello // Microprofile server properties server.port=8080 server.host=0.0.0.0 ",
            "title": "MicroProfile Config Config Sources"
        },
        {
            "location": "/mp/config/01_introduction",
            "text": " MicroProfile Config supports a concept of configuration profiles. You can define a profile using the configuration property mp.config.profile (when using default configuration, this can be defined as a system property, environment variable or as a property in microprofile-config.properties ). When a profile is defined, additional config source is loaded ( microprofile-config-profile.properties ) and properties from profile have precedence over default properties. Profile properties can be defined using %profile prefix, such as %dev.server.port . ",
            "title": "MicroProfile Config Profiles"
        },
        {
            "location": "/mp/config/01_introduction",
            "text": " MicroProfile Config uses ConfigSource SPI to load configuration data, either from default configuration sources such file META-INF/microprofile-config.properties , environment variables, and system properties; or from custom ConfigSource located by Java Service Loader. The data is then available through MicroProfile Config APIs to be injected into CDI Beans, or to be obtained using a Config instance programmatically. MicroProfile Config provides typed access to configuration values, using built-in converters, and Converter implementations located by Java Service Loader. Using MicroProfile Config API You can use MicroProfile Config API to get configuration properties by using ConfigProvider.getConfig() or injecting configuration values with @ConfigProperty . <markup lang=\"java\" title=\"Using ConfigProvider.getConfig()\" >org.eclipse.microprofile.config.Config config = ConfigProvider.getConfig(); config.getOptionalValue(\"app.greeting\", String.class).orElse(\"Hello\"); <markup lang=\"java\" title=\"Injecting configured properties into a constructor\" >@Inject public GreetingProvider(@ConfigProperty(name = \"app.greeting\", defaultValue = \"Hello\") String message) { this.message = message } MicroProfile Config Config Sources The example below shows how the MicroProfile configuration file microprofile-config.properties can be used to modify the server listen port property. <markup lang=\"properties\" >// Application properties. This is the default greeting app.greeting=Hello // Microprofile server properties server.port=8080 server.host=0.0.0.0 MicroProfile Config Profiles MicroProfile Config supports a concept of configuration profiles. You can define a profile using the configuration property mp.config.profile (when using default configuration, this can be defined as a system property, environment variable or as a property in microprofile-config.properties ). When a profile is defined, additional config source is loaded ( microprofile-config-profile.properties ) and properties from profile have precedence over default properties. Profile properties can be defined using %profile prefix, such as %dev.server.port . ",
            "title": "MicroProfile Config Features"
        },
        {
            "location": "/mp/config/01_introduction",
            "text": " Helidon MicroProfile Config offers the following features on top of the specification: References You can use ${reference} to reference another configuration key in a key value. This allows to configure a single key to be reused in multiple other keys. <markup lang=\"yaml\" title=\"Example\" >uri: \"http://localhost:8080\" service-1: \"${uri}/service1\" service-2: \"${uri}/service2\" Change support Polling (or change watching) for file based config sources (not classpath based). To enable polling for a config source created using meta configuration (see below), or using MpConfigSources.create(Path) , or YamlMpConfigSource.create(Path) , use the following properties: Property Description helidon.config.polling.enabled To enable polling file for changes, uses timestamp to identify a change. helidon.config.polling.duration Polling period duration, defaults to 10 seconds ('PT10S`) See https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/time/Duration.html#parse(java.lang.CharSequence ) helidon.config.watcher.enabled To enable watching file for changes using the Java WatchService . See https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/nio/file/WatchService.html Encryption You can encrypt secrets using a master password and store them in a configuration file. The config encryption filter in MicroProfile Config is enabled by default. For more information, see Configuration Secrets . <markup lang=\"properties\" title=\"Example of encrypted secrets\" ># Password encrypted using a master password client_secret=${GCM=mYRkg+4Q4hua1kvpCCI2hg==} # Password encrypted using public key (there are length limits when using RSA) client_secret=${RSA=mYRkg+4Q4hua1kvpCCI2hg==} # Password in clear text, can be used in development # The system needs to be configured to accept clear text client_secret=${CLEAR=known_password} Meta Configuration You can configure the Config using Helidon MP Config meta configuration feature. The meta-config allows configuration of config sources and other configuration options, including addition of discovered sources and converters. This is a Helidon specific feature available since version 2.3.0. See Microprofile Config Sources for detailed information. For backward compatibility, we will support usage of Helidon SE meta-configuration until version 3.0.0. Using this approach causes behavior that is not compatible with MicroProfile Config specification. ",
            "title": "Helidon MicroProfile Config Features"
        },
        {
            "location": "/mp/config/01_introduction",
            "text": " Helidon MicroProfile Config is an implementation of Eclipse MicroProfile Config . You can configure your applications using MicroProfile&#8217;s config configuration sources and APIs. You can also extend the configuration using MicroProfile SPI to add custom ConfigSource and Converter . MicroProfile Config Features MicroProfile Config uses ConfigSource SPI to load configuration data, either from default configuration sources such file META-INF/microprofile-config.properties , environment variables, and system properties; or from custom ConfigSource located by Java Service Loader. The data is then available through MicroProfile Config APIs to be injected into CDI Beans, or to be obtained using a Config instance programmatically. MicroProfile Config provides typed access to configuration values, using built-in converters, and Converter implementations located by Java Service Loader. Using MicroProfile Config API You can use MicroProfile Config API to get configuration properties by using ConfigProvider.getConfig() or injecting configuration values with @ConfigProperty . <markup lang=\"java\" title=\"Using ConfigProvider.getConfig()\" >org.eclipse.microprofile.config.Config config = ConfigProvider.getConfig(); config.getOptionalValue(\"app.greeting\", String.class).orElse(\"Hello\"); <markup lang=\"java\" title=\"Injecting configured properties into a constructor\" >@Inject public GreetingProvider(@ConfigProperty(name = \"app.greeting\", defaultValue = \"Hello\") String message) { this.message = message } MicroProfile Config Config Sources The example below shows how the MicroProfile configuration file microprofile-config.properties can be used to modify the server listen port property. <markup lang=\"properties\" >// Application properties. This is the default greeting app.greeting=Hello // Microprofile server properties server.port=8080 server.host=0.0.0.0 MicroProfile Config Profiles MicroProfile Config supports a concept of configuration profiles. You can define a profile using the configuration property mp.config.profile (when using default configuration, this can be defined as a system property, environment variable or as a property in microprofile-config.properties ). When a profile is defined, additional config source is loaded ( microprofile-config-profile.properties ) and properties from profile have precedence over default properties. Profile properties can be defined using %profile prefix, such as %dev.server.port . Helidon MicroProfile Config Features Helidon MicroProfile Config offers the following features on top of the specification: References You can use ${reference} to reference another configuration key in a key value. This allows to configure a single key to be reused in multiple other keys. <markup lang=\"yaml\" title=\"Example\" >uri: \"http://localhost:8080\" service-1: \"${uri}/service1\" service-2: \"${uri}/service2\" Change support Polling (or change watching) for file based config sources (not classpath based). To enable polling for a config source created using meta configuration (see below), or using MpConfigSources.create(Path) , or YamlMpConfigSource.create(Path) , use the following properties: Property Description helidon.config.polling.enabled To enable polling file for changes, uses timestamp to identify a change. helidon.config.polling.duration Polling period duration, defaults to 10 seconds ('PT10S`) See https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/time/Duration.html#parse(java.lang.CharSequence ) helidon.config.watcher.enabled To enable watching file for changes using the Java WatchService . See https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/nio/file/WatchService.html Encryption You can encrypt secrets using a master password and store them in a configuration file. The config encryption filter in MicroProfile Config is enabled by default. For more information, see Configuration Secrets . <markup lang=\"properties\" title=\"Example of encrypted secrets\" ># Password encrypted using a master password client_secret=${GCM=mYRkg+4Q4hua1kvpCCI2hg==} # Password encrypted using public key (there are length limits when using RSA) client_secret=${RSA=mYRkg+4Q4hua1kvpCCI2hg==} # Password in clear text, can be used in development # The system needs to be configured to accept clear text client_secret=${CLEAR=known_password} Meta Configuration You can configure the Config using Helidon MP Config meta configuration feature. The meta-config allows configuration of config sources and other configuration options, including addition of discovered sources and converters. This is a Helidon specific feature available since version 2.3.0. See Microprofile Config Sources for detailed information. For backward compatibility, we will support usage of Helidon SE meta-configuration until version 3.0.0. Using this approach causes behavior that is not compatible with MicroProfile Config specification. ",
            "title": "About MicroProfile Config"
        },
        {
            "location": "/mp/config/01_introduction",
            "text": " MP Config Guide Step-by-step guide about using MicroProfile Config in your Helidon MP application. ",
            "title": "Guides"
        },
        {
            "location": "/mp/config/01_introduction",
            "text": " Helidon Config SPI Helidon Config API Eclispe MicroProfile API ",
            "title": "Additional Information"
        },
        {
            "location": "/mp/guides/07_datasource",
            "text": " This guide shows how to configure and use named DataSource s in your Helidon MP application. ",
            "title": "preambule"
        },
        {
            "location": "/mp/guides/07_datasource",
            "text": " For this 20 minute tutorial, you will need the following: <div class=\"table__overflow elevation-1 flex sm7 \"> A Helidon {upper-case-flavor} Application You can use your own application or use the Helidon {upper-case-flavor} Quickstart to create a sample application. Java&#160;SE&#160;11 ( Open&#160;JDK&#160;11 ) Helidon requires Java 11+. Maven 3.6.1+ Helidon requires Maven 3.6.1+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop ). curl (Optional) for testing <markup lang=\"bash\" title=\"Verify Prerequisites\" >java -version mvn --version docker --version kubectl version --short <markup lang=\"bash\" title=\"Setting JAVA_HOME\" ># On Mac export JAVA_HOME=`/usr/libexec/java_home -v 11` # On Linux # Use the appropriate path to your JDK export JAVA_HOME=/usr/lib/jvm/jdk-11 ",
            "title": "What You Need"
        },
        {
            "location": "/mp/guides/07_datasource",
            "text": " By following this guide you&#8217;ll enhance a bare-bones Helidon MP application to access an in-memory H2 database database. You&#8217;ll see how to install the relevant dependencies, set up and configure the datasource, and add datasource-related code to your application. ",
            "title": "Overview"
        },
        {
            "location": "/mp/guides/07_datasource",
            "text": " Add the following dependency in your pom.xml : <markup lang=\"xml\" title=\" pom.xml \" >&lt;dependency&gt; &lt;groupId&gt;com.h2database&lt;/groupId&gt; &lt;artifactId&gt;h2&lt;/artifactId&gt; &lt;version&gt;1.4.199&lt;/version&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; In a production application, you may use a different database, so in that case you may add a different database driver dependency here instead. ",
            "title": "Add the H2 Database Driver to the Runtime Classpath"
        },
        {
            "location": "/mp/guides/07_datasource",
            "text": " Add the following dependency in your pom.xml : <markup lang=\"xml\" title=\" pom.xml \" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.cdi&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-cdi-datasource-hikaricp&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; ",
            "title": "Add the Hikari Connection Pool Extension to the Runtime Classpath"
        },
        {
            "location": "/mp/guides/07_datasource",
            "text": " Replace the contents of the following file under src/main/resources : <markup lang=\"yaml\" title=\" src/main/resources/application.yaml \" >server: port: 8080 javax: sql: DataSource: test: dataSourceClassName: org.h2.jdbcx.JdbcDataSource dataSource: url: jdbc:h2:mem:test user: sa password: \"\" This javax: / sql: / DataSource: preamble is required. test is the name of the DataSource being configured here. dataSourceClassName is an essential Hikari connection pool property . dataSource is a Hikari connection pool keyword . These are some of the Java Beans-compliant properties exposed by, in this case, the org.h2.jdbcx.JdbcDataSource class . ",
            "title": "Add an application.yaml File With Database Connectivity Information"
        },
        {
            "location": "/mp/guides/07_datasource",
            "text": " For more information about datasources, see https://docs.oracle.com/javase/8/docs/api/javax/sql/DataSource.html In the src/main/java/io/helidon/example/ds/ExampleResource.java file, add the following imports: <markup lang=\"java\" title=\" src/main/java/io/helidon/example/ds/ExampleResource.java \" >import javax.enterprise.context.Dependent; import javax.inject.Inject; import javax.inject.Named; import javax.sql.DataSource; Annotate the resource class declaration with @Dependent : <markup lang=\"java\" title=\" src/main/java/io/helidon/example/ds/ExampleResource.java \" >@Dependent public class ExampleResource { This ensures that io.helidon.example.jpa.ExampleResource is a discoverable CDI bean. Then add the following annotated field declaration: <markup lang=\"java\" title=\" src/main/java/io/helidon/example/ds/ExampleResource.java \" >@Inject @Named(\"test\") private DataSource testDataSource; The @Inject annotation is used to indicate that the CDI container should set the annotated field automatically. The @Named annotation is used to select which data source should be injected. Here, the test data source is requested. ",
            "title": "Inject a Datasource into Your Application Code"
        },
        {
            "location": "/mp/guides/07_datasource",
            "text": " Now that you have a DataSource , you&#8217;ll use it to connect to the database. First, ensure the io.helidon.example.ds.ExampleResource resource class imports various java.sql classes: <markup lang=\"java\" title=\" src/main/java/io/helidon/example/ds/ExampleResource.java \" >import java.sql.Connection; import java.sql.PreparedStatement; import java.sql.ResultSet; import java.sql.SQLException; Add the following resource method to the ExampleResource class: <markup lang=\"java\" title=\" src/main/java/io/helidon/example/ds/ExampleResource.java \" >@GET @Path(\"tables\") @Produces(\"text/plain\") public String getTableNames() throws SQLException { StringBuilder sb = new StringBuilder(); try (Connection connection = this.testDataSource.getConnection(); PreparedStatement ps = connection.prepareStatement(\" SELECT TABLE_NAME\" + \" FROM INFORMATION_SCHEMA.TABLES \" + \"ORDER BY TABLE_NAME ASC\"); ResultSet rs = ps.executeQuery()) { while (rs.next()) { sb.append(rs.getString(1)).append(\"\"); } } return sb.toString(); } Database interactions can throw SQLException . We acquire a Connection , a PreparedStatement and a ResultSet in a try-with-resources block. This SQL statement returns a list of all table names in the database. ",
            "title": "Use The Injected DataSource"
        },
        {
            "location": "/mp/guides/07_datasource",
            "text": " In a shell, cd into an empty directory and run this: <markup lang=\"bash\" >mvn -U archetype:generate \\ -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-bare-mp \\ -DarchetypeVersion=2.5.4 \\ -DgroupId=io.helidon.example \\ -DartifactId=helidon-ds \\ -Dpackage=io.helidon.example.ds \\ -DrestResourceName=ExampleResource \\ -DapplicationName=ExampleApplication Now cd into helidon-ds . The rest of this guide will assume all relative paths are relative to this directory. Add the H2 Database Driver to the Runtime Classpath Add the following dependency in your pom.xml : <markup lang=\"xml\" title=\" pom.xml \" >&lt;dependency&gt; &lt;groupId&gt;com.h2database&lt;/groupId&gt; &lt;artifactId&gt;h2&lt;/artifactId&gt; &lt;version&gt;1.4.199&lt;/version&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; In a production application, you may use a different database, so in that case you may add a different database driver dependency here instead. Add the Hikari Connection Pool Extension to the Runtime Classpath Add the following dependency in your pom.xml : <markup lang=\"xml\" title=\" pom.xml \" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.cdi&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-cdi-datasource-hikaricp&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; Add an application.yaml File With Database Connectivity Information Replace the contents of the following file under src/main/resources : <markup lang=\"yaml\" title=\" src/main/resources/application.yaml \" >server: port: 8080 javax: sql: DataSource: test: dataSourceClassName: org.h2.jdbcx.JdbcDataSource dataSource: url: jdbc:h2:mem:test user: sa password: \"\" This javax: / sql: / DataSource: preamble is required. test is the name of the DataSource being configured here. dataSourceClassName is an essential Hikari connection pool property . dataSource is a Hikari connection pool keyword . These are some of the Java Beans-compliant properties exposed by, in this case, the org.h2.jdbcx.JdbcDataSource class . Inject a Datasource into Your Application Code For more information about datasources, see https://docs.oracle.com/javase/8/docs/api/javax/sql/DataSource.html In the src/main/java/io/helidon/example/ds/ExampleResource.java file, add the following imports: <markup lang=\"java\" title=\" src/main/java/io/helidon/example/ds/ExampleResource.java \" >import javax.enterprise.context.Dependent; import javax.inject.Inject; import javax.inject.Named; import javax.sql.DataSource; Annotate the resource class declaration with @Dependent : <markup lang=\"java\" title=\" src/main/java/io/helidon/example/ds/ExampleResource.java \" >@Dependent public class ExampleResource { This ensures that io.helidon.example.jpa.ExampleResource is a discoverable CDI bean. Then add the following annotated field declaration: <markup lang=\"java\" title=\" src/main/java/io/helidon/example/ds/ExampleResource.java \" >@Inject @Named(\"test\") private DataSource testDataSource; The @Inject annotation is used to indicate that the CDI container should set the annotated field automatically. The @Named annotation is used to select which data source should be injected. Here, the test data source is requested. Use The Injected DataSource Now that you have a DataSource , you&#8217;ll use it to connect to the database. First, ensure the io.helidon.example.ds.ExampleResource resource class imports various java.sql classes: <markup lang=\"java\" title=\" src/main/java/io/helidon/example/ds/ExampleResource.java \" >import java.sql.Connection; import java.sql.PreparedStatement; import java.sql.ResultSet; import java.sql.SQLException; Add the following resource method to the ExampleResource class: <markup lang=\"java\" title=\" src/main/java/io/helidon/example/ds/ExampleResource.java \" >@GET @Path(\"tables\") @Produces(\"text/plain\") public String getTableNames() throws SQLException { StringBuilder sb = new StringBuilder(); try (Connection connection = this.testDataSource.getConnection(); PreparedStatement ps = connection.prepareStatement(\" SELECT TABLE_NAME\" + \" FROM INFORMATION_SCHEMA.TABLES \" + \"ORDER BY TABLE_NAME ASC\"); ResultSet rs = ps.executeQuery()) { while (rs.next()) { sb.append(rs.getString(1)).append(\"\"); } } return sb.toString(); } Database interactions can throw SQLException . We acquire a Connection , a PreparedStatement and a ResultSet in a try-with-resources block. This SQL statement returns a list of all table names in the database. ",
            "title": "Use the Maven Archetype to Generate a Helidon MP Application"
        },
        {
            "location": "/mp/guides/07_datasource",
            "text": " Execute the following from the root directory of your application: <markup lang=\"bash\" >mvn clean package ",
            "title": "Build the Application"
        },
        {
            "location": "/mp/guides/07_datasource",
            "text": " Execute the following from the root directory of your application: <markup lang=\"bash\" >java -jar target/helidon-ds.jar ",
            "title": "Run the Application"
        },
        {
            "location": "/mp/guides/07_datasource",
            "text": " Execute the following: <markup lang=\"bash\" >curl http://localhost:8080/example/tables Observe that the result will be a list of database table names. ",
            "title": "Test the Application"
        },
        {
            "location": "/mp/guides/07_datasource",
            "text": " Helidon features a few examples of projects that use datasources. An example showing a Hikari connection pool data source connected to an H2 database An example showing a Hikari connection pool data source connected to a MySQL database Some examples' configurations can be found in their META-INF/microprofile-config.properties resources instead of in an application.yaml file as described above. Though the syntax is different, the same principles as those described above still apply. ",
            "title": "Related Examples"
        },
        {
            "location": "/se/webserver/03_routing",
            "text": " Routing lets you use request matching criteria to bind requests to a handler that implements your custom business logic. Matching criteria include one or more HTTP Method(s) and, optionally, a request path matcher . Use the RequestPredicate class to specify more routing criteria. ",
            "title": "preambule"
        },
        {
            "location": "/se/webserver/03_routing",
            "text": " Routing also supports Error Routing which binds Java Throwable to the handling logic. Configure HTTP request routing using Routing.Builder . <markup lang=\"java\" title=\"Using Routing.Builder to specify how HTTP requests are handled\" >Routing routing = Routing.builder() .get(\"/hello\", (req, res) -&gt; res.send(\"Hello World!\")) .build(); WebServer webServer = WebServer.create(routing); Handle all GETs to /hello path. Send the Hello World! string. Add the routing to the WebServer. ",
            "title": "Basics"
        },
        {
            "location": "/se/webserver/03_routing",
            "text": " Routing.Builder lets you specify how to handle each HTTP method. For example: HTTP Method Routing.Builder example GET .get((req, res) -&gt; { /* handler */ }) PUT .put((req, res) -&gt; { /* handler */ }) POST .post((req, res) -&gt; { /* handler */ }) HEAD .head((req, res) -&gt; { /* handler */ }) DELETE .delete((req, res) -&gt; { /* handler */ }) TRACE .trace((req, res) -&gt; { /* handler */ }) OPTIONS .options((req, res) -&gt; { /* handler */ }) any method .any((req, res) -&gt; { /* handler */ }) multiple methods .anyOf(List.of(Http.Method.GET, Http.Method.POST), (req, res) -&gt; { /* handler */ }) custom method .anyOf(Set.of(Http.RequestMethod.create(\"CUSTOM\")), (req, res) -&gt; { /* handler */ }) ",
            "title": "HTTP Method Routing"
        },
        {
            "location": "/se/webserver/03_routing",
            "text": " You can combine HTTP method routing with request path matching. <markup lang=\"java\" >Routing.builder() .post(\"/some/path\", (req, res) -&gt; { /* handler */ }) You can use path pattern instead of path with the following syntax: /foo/bar/baz - Exact path match against resolved path even with non-usual characters /foo/{}/baz - {} Unnamed regular expression segment ([^/]+) /foo/{var}/baz - Named regular expression segment ([^/]+) /foo/{var:\\d+} - Named regular expression segment with a specified expression /foo/{:\\d+} - Unnamed regular expression segment with a specified expression /foo/{+var} - Convenience shortcut for {var:.+}. A matcher is not a true URI template (as defined by RFC) but this convenience is in sync with the Apiary templates /foo/{+} - Convenience shortcut for unnamed segment with regular expression {:.+} /foo[/bar] - An optional block, which translates to the /foo(/bar)? regular expression / or /foo - * Wildcard character can be matched with any number of characters. Path (matcher) routing is exact . For example, a /foo/bar request is not routed to .post('/foo', &#8230;&#8203;) . Always start path and path patterns with the / character. ",
            "title": "Path Matcher Routing"
        },
        {
            "location": "/se/webserver/03_routing",
            "text": " Use the RequestPredicate utility class to identify more criteria. You can construct (build) a predicate based on typical request criteria such as content type, or the existence of a header or cookie. You can also construct a handler that only processes requests accepted by the predicate. All other requests are nexted , meaning that they are routed to the next valid handler. <markup lang=\"java\" >.post(\"/foo\", RequestPredicate.create() .containsHeader(\"my-gr8-header\") .accepts(MediaType.TEXT_PLAIN) .and(this::isUserAuthenticated) .thenApply((req, resp) -&gt; { // Some logic }) .otherwise((req, resp) -&gt; { /* Otherwise logic */ }); // Optional. Default logic is req.next() ",
            "title": "Request Predicate"
        },
        {
            "location": "/se/webserver/03_routing",
            "text": " By implementing the Service interface you can organize your code into one or more services, each with its own path prefix and set of handlers. <markup lang=\"java\" title=\"Use Routing.Builder.register to register your service\" >.register(\"/hello\", new HelloService()) <markup lang=\"java\" title=\"Service implementation\" >public class HelloService implements Service { @Override public void update(Routing.Rules rules) { rules.get(\"/subpath\", this::getHandler); } private void getHandler(ServerRequest request, ServerResponse response) { // Some logic } } In this example, the GET handler matches requests to /hello/subpath . ",
            "title": "Organizing Code into Services"
        },
        {
            "location": "/se/webserver/07_jersey-support",
            "text": " To enable Jersey (JAX-RS) Support add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webserver&lt;/groupId&gt; &lt;artifactId&gt;helidon-webserver-jersey&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/webserver/07_jersey-support",
            "text": " You can also register the JAX-RS Application object. <markup lang=\"java\" title=\"Register the HelloWorld resource\" >Routing.builder() .register(\"/jersey\", JerseySupport.builder(new MyApplication()) .build()) .build(); Register the Jersey application at /jersey context root MyApplication handles requests made to /jersey context root. ",
            "title": "Registering a JAX-RS Application"
        },
        {
            "location": "/se/webserver/07_jersey-support",
            "text": " You can inject WebServer request and response objects into your JAX-RS application using @Context . <markup lang=\"java\" title=\"Injection of WebServer internal objects\" >@Path(\"/\") @RequestScoped public class HelloWorld { @Context private ServerRequest request; @Context private ServerResponse response; } ",
            "title": "Accessing WebServer Internals from a JAX-RS Application"
        },
        {
            "location": "/se/webserver/07_jersey-support",
            "text": " To register a Jersey application at a context root, use the JerseySupport class and its JerseySupport.Builder builder. JerseySupport can register the JAX-RS resources directly. <markup lang=\"java\" title=\"Jersey (JAX-RS) HelloWorld resource\" >@Path(\"/\") public class HelloWorld { @GET @Path(\"hello\") public Response hello() { return Response.ok(\"Hello World!\").build(); } } <markup lang=\"java\" title=\"Registering the HelloWorld resource\" >Routing.builder() .register(\"/jersey\", JerseySupport.builder() .register(HelloWorld.class) .build()) .build(); Register the Jersey application at /jersey context root The Jersey Application stays hidden and consists of a single HelloWorld resource class As a result, an HTTP GET request to /jersey/hello would yield a Hello World! response string. Registering a JAX-RS Application You can also register the JAX-RS Application object. <markup lang=\"java\" title=\"Register the HelloWorld resource\" >Routing.builder() .register(\"/jersey\", JerseySupport.builder(new MyApplication()) .build()) .build(); Register the Jersey application at /jersey context root MyApplication handles requests made to /jersey context root. Accessing WebServer Internals from a JAX-RS Application You can inject WebServer request and response objects into your JAX-RS application using @Context . <markup lang=\"java\" title=\"Injection of WebServer internal objects\" >@Path(\"/\") @RequestScoped public class HelloWorld { @Context private ServerRequest request; @Context private ServerResponse response; } ",
            "title": "Registering a Jersey Application"
        },
        {
            "location": "/se/webserver/07_jersey-support",
            "text": " You can register a Jersey (JAX-RS) application at a context root using the JerseySupport class. Registering a Jersey Application To register a Jersey application at a context root, use the JerseySupport class and its JerseySupport.Builder builder. JerseySupport can register the JAX-RS resources directly. <markup lang=\"java\" title=\"Jersey (JAX-RS) HelloWorld resource\" >@Path(\"/\") public class HelloWorld { @GET @Path(\"hello\") public Response hello() { return Response.ok(\"Hello World!\").build(); } } <markup lang=\"java\" title=\"Registering the HelloWorld resource\" >Routing.builder() .register(\"/jersey\", JerseySupport.builder() .register(HelloWorld.class) .build()) .build(); Register the Jersey application at /jersey context root The Jersey Application stays hidden and consists of a single HelloWorld resource class As a result, an HTTP GET request to /jersey/hello would yield a Hello World! response string. Registering a JAX-RS Application You can also register the JAX-RS Application object. <markup lang=\"java\" title=\"Register the HelloWorld resource\" >Routing.builder() .register(\"/jersey\", JerseySupport.builder(new MyApplication()) .build()) .build(); Register the Jersey application at /jersey context root MyApplication handles requests made to /jersey context root. Accessing WebServer Internals from a JAX-RS Application You can inject WebServer request and response objects into your JAX-RS application using @Context . <markup lang=\"java\" title=\"Injection of WebServer internal objects\" >@Path(\"/\") @RequestScoped public class HelloWorld { @Context private ServerRequest request; @Context private ServerResponse response; } ",
            "title": "JAX-RS Support"
        },
        {
            "location": "/se/websocket/01_overview",
            "text": " Helidon integrates with Tyrus to provide support for the Jakarta WebSocket API . The WebSocket API enables Java applications to participate in WebSocket interactions as both servers and clients. The server API supports two flavors: annotated and programmatic endpoints. Annotated endpoints, as suggested by their name, use Java annotations to provide the necessary meta-data to define WebSocket handlers; programmatic endpoints implement API interfaces and are annotation free. Annotated endpoints tend to be more flexible since they allow different method signatures depending on the application needs, whereas programmatic endpoints must implement an interface and are, therefore, bounded to its definition. Helidon SE support is based on the TyrusSupport class which is akin to JerseySupport , and enables Helidon application to defined both annotated and programmatic WebSocket endpoints. ",
            "title": "preambule"
        },
        {
            "location": "/se/websocket/01_overview",
            "text": " This section describes the implementation of a simple application that uses a REST resource to push messages into a shared queue and a programmatic WebSocket endpoint to download messages from the queue, one at a time, over a connection. The example will show how REST and WebSocket connections can be seamlessly combined into a Helidon application. The complete Helidon SE example is available here . Let us start by looking at MessageQueueService : <markup lang=\"java\" >public class MessageQueueService implements Service { private final MessageQueue messageQueue = MessageQueue.instance(); @Override public void update(Routing.Rules routingRules) { routingRules.post(\"/board\", this::handlePost); } private void handlePost(ServerRequest request, ServerResponse response) { request.content().as(String.class).thenAccept(messageQueue::push); response.status(204).send(); } } This class exposes a REST resource where messages can be posted. Upon receiving a message, it simply pushes it into a shared queue and returns 204 (No Content). Messages pushed into the queue can be obtained by opening a WebSocket connection served by MessageBoardEndpoint : <markup lang=\"java\" >public class MessageBoardEndpoint extends Endpoint { private final MessageQueue messageQueue = MessageQueue.instance(); @Override public void onOpen(Session session, EndpointConfig endpointConfig) { session.addMessageHandler(new MessageHandler.Whole&lt;String&gt;() { @Override public void onMessage(String message) { try { if (message.equals(\"SEND\")) { while (!messageQueue.isEmpty()) { session.getBasicRemote().sendObject(messageQueue.pop()); } } } catch (Exception e) { // ... } } }); } } This is an example of a programmatic endpoint that extends Endpoint . The method onOpen will be invoked for every new connection. In this example, the application registers a message handler for strings, and when the special SEND message is received, it empties the shared queue sending messages one at a time over the WebSocket connection. In Helidon SE, REST and WebSocket classes need to be manually registered into the web server. This is accomplished via a Routing builder: <markup lang=\"java\" > List&lt;Class&lt;? extends Encoder&gt;&gt; encoders = Collections.singletonList(UppercaseEncoder.class); Routing.builder() .register(\"/rest\", new MessageQueueService()) .register(\"/websocket\", TyrusSupport.builder().register( ServerEndpointConfig.Builder.create( MessageBoardEndpoint.class, \"/board\").encoders( encoders).build()).build()) .build(); This code snippet uses multiple builders for Routing , TyrusSupport and ServerEndpointConfig . In particular, it registers MessageBoardEndpoint.class at \"/websocket/board\" and associates with it a message encoder . For more information on message encoders and decoders the reader see the websocket specification ; in this example , UppercaseEncoder.class simply uppercases every message sent from the server. Endpoint methods in Helidon SE are executed in Netty&#8217;s worker thread pool. Threads in this pool are intended to be non-blocking , thus it is recommended for any blocking or long-running operation triggered by an endpoint method to be executed using a separate thread pool. See the documentation for io.helidon.common.configurable.ThreadPoolSupplier . ",
            "title": "Helidon SE Example"
        },
        {
            "location": "/mp/grpc/02_mp_clients",
            "text": " Building Java gRPC clients using the Helidon MP gRPC APIs is very simple and removes a lot of the boiler plate code typically associated to more traditional approaches to writing gRPC Java clients. At it simplest a gRPC Java client can be written using nothing more than a suitably annotated interface. ",
            "title": "preambule"
        },
        {
            "location": "/mp/grpc/02_mp_clients",
            "text": " To enable gRPC MicroProfile Clients add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.grpc&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-grpc-client&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/grpc/02_mp_clients",
            "text": " The next step is to produce an interface with the service methods that the client requires. For example, suppose we have a simple server side service that has a unary method to convert a string to uppercase. <markup lang=\"java\" title=\"Simple gRPC Service\" >@ApplicationScoped @io.helidon.microprofile.grpc.core.Grpc public interface StringService { @io.helidon.microprofile.grpc.core.Unary public String upper(String s) { return s == null ? null : s.toUpperCase(); } } The service has been written using the Helidon MP APIs but could just as easily be a traditional gRPC Java service generated from Protobuf files. The client API is agnostic of the server side implementation, it only cares about the method type, the request and response types and the type of Marshaller used to serialize the request and response. To write a client for the StringService all that is required is an interface. <markup lang=\"java\" title=\"Simple gRPC Service\" >@ApplicationScoped @io.helidon.microprofile.grpc.core.Grpc public interface StringService { @io.helidon.microprofile.grpc.core.Unary public String upper(String s); } There is no need to write any code to implement the client. The Helidon MP gRPC APIs will create a dynamic proxy for the interface using the information from the annotations and method signatures. The interface in the example above used the same method signature as the server but this does not have to be the case, the interface could have used any supported signature for a unary method, so for example it could just have easily been the standard unary method signature: <markup lang=\"java\" title=\"Simple gRPC Service\" >@ApplicationScoped @io.helidon.microprofile.grpc.core.Grpc public interface StringService { @io.helidon.microprofile.grpc.core.Unary public void upper(String s, StreamObserver&lt;String&gt; response); } We could also have made the client asynchronous by using one of the async method signatures: <markup lang=\"java\" title=\"Simple gRPC Service\" >@ApplicationScoped @io.helidon.microprofile.grpc.core.Grpc public interface StringService { @io.helidon.microprofile.grpc.core.Unary public CompletableFuture&lt;String&gt; upper(String s); } ",
            "title": "The Client Service Interface"
        },
        {
            "location": "/mp/grpc/02_mp_clients",
            "text": " It is also possible to configure a Channel to use TLS if the server is using TLS. <markup lang=\"yaml\" title=\"application.yaml\" >grpc: channels: test-server: host: localhost port: 1408 tls: enabled: true tls-cert-path: /certs/foo.cert tls-key-path: /certs/foo.key tls-ca-cert-path: /certs/ca.cert The tls section of the channel configuration is used to configure TLS. The enabled value is used to enable or disable TLS for this channel. The tls-cert value is the location of the TLS certificate file The tls-key value is the location of the TLS key file The tls-ca-cert value is the location of the TLS CA certificate file The SSL configuration uses the Helidon Resource class to locate configured keys and certificates. In the example above the tls-cert-path config key has the -path suffix which tells the configuration to load /certs/foo.cert as a file. If /certs/foo.cert was a resource on the classpath the configuration key could have been changed to tls-cert-resource-path to load /certs/foo.cert from the classpath. The same applies to the tls-key and tls-ca-cert configuration keys. See the io.helidon.common.configurable.Resource class for details. ",
            "title": "Configuring TLS"
        },
        {
            "location": "/mp/grpc/02_mp_clients",
            "text": " For a gRPC client to connect to a server it requires a Channel. The Helidon MP gRPC APIs provide a way to inject channels into CDI beans that require them. Channels are configured in the grpc section of the Helidon application configuration. The examples below use an application.yaml file but there are many other ways to use and override configuration in Helidon <markup lang=\"yaml\" title=\"application.yaml\" >grpc: channels: test-server: host: localhost port: 1408 Channels are configured in the`channels` section Each sub-section is the Channel name that is then used to refer to this Channel in the application code Each channel contains a host name and a port. While most client application only connect to a single server it is possible to configure multiple named channels if the client needs to connect to multiple servers. <markup lang=\"yaml\" title=\"application.yaml\" >grpc: channels: london: host: london.foo.com port: 1408 new-york: host: ny.foo.com port: 1408 The above example shows two channel configurations, one named london and the other new-york . Configuring TLS It is also possible to configure a Channel to use TLS if the server is using TLS. <markup lang=\"yaml\" title=\"application.yaml\" >grpc: channels: test-server: host: localhost port: 1408 tls: enabled: true tls-cert-path: /certs/foo.cert tls-key-path: /certs/foo.key tls-ca-cert-path: /certs/ca.cert The tls section of the channel configuration is used to configure TLS. The enabled value is used to enable or disable TLS for this channel. The tls-cert value is the location of the TLS certificate file The tls-key value is the location of the TLS key file The tls-ca-cert value is the location of the TLS CA certificate file The SSL configuration uses the Helidon Resource class to locate configured keys and certificates. In the example above the tls-cert-path config key has the -path suffix which tells the configuration to load /certs/foo.cert as a file. If /certs/foo.cert was a resource on the classpath the configuration key could have been changed to tls-cert-resource-path to load /certs/foo.cert from the classpath. The same applies to the tls-key and tls-ca-cert configuration keys. See the io.helidon.common.configurable.Resource class for details. ",
            "title": "Configuring Channels"
        },
        {
            "location": "/mp/grpc/02_mp_clients",
            "text": " If code is running in an application that is executing as part of a Helidon MP gRPC server there is a special in-process channel available. This allows code executing on the server to make calls to gRPC services deployed on that server in the same way an external client does. To inject an in-process channel a different qualifier annotation is used. <markup lang=\"java\" title=\"gRPC in-Process Channel Injection\" > @Inject @InProcessGrpcChannel private Channel channel; The @Inject annotation is used the same as previously. The @InProcessGrpcChannel is the qualifier that is used to tell the Helidon MP gRPC API to inject an in-process channel. ",
            "title": "The In-Process Channel"
        },
        {
            "location": "/mp/grpc/02_mp_clients",
            "text": " Once one or more channels have been configured they can be used by client code. The simplest way to use a channel is to inject it into beans using CDI. The Helidon gRPC client APIs have CDI producers that can provide io.grpc.Channel instances. For example, a class might have an injectable io.grpc.Channel field: <markup lang=\"java\" title=\"gRPC Channel Injection\" > @Inject @GrpcChannel(name = \"test-server\") private Channel channel; The @Inject annotation tells CDI to inject the channel. The @GrpcChannel annotation is the qualifier that supplies the Channel name. This is the same name as used in the channel configuration in the configuration examples above. When an instance of the CDI bean with the channel field is instantiated a channel will be injected into it. The In-Process Channel If code is running in an application that is executing as part of a Helidon MP gRPC server there is a special in-process channel available. This allows code executing on the server to make calls to gRPC services deployed on that server in the same way an external client does. To inject an in-process channel a different qualifier annotation is used. <markup lang=\"java\" title=\"gRPC in-Process Channel Injection\" > @Inject @InProcessGrpcChannel private Channel channel; The @Inject annotation is used the same as previously. The @InProcessGrpcChannel is the qualifier that is used to tell the Helidon MP gRPC API to inject an in-process channel. ",
            "title": "Using Channels"
        },
        {
            "location": "/mp/grpc/02_mp_clients",
            "text": " Now that there is a client interface and a Channel configuration we can use these in the client application. The simplest way is to use the client in a CDI microprofile application. In the application class that requires the client we can declare a field of the same type as the client service interface. The field is then annotated so that CDI will inject the client proxy into the field. <markup lang=\"java\" title=\"Simple gRPC Service\" >@ApplicationScoped public class Client { @Inject @GrpcProxy @GrpcChannel(name = \"test-server\") private StringService stringService; The @Inject annotation tells the CDI to inject the client implementation; the gRPC MP APIs have a bean provider that does this. The @GrpcProxy annotation is used by the CDI container to match the injection point to the gRPC MP APIs provider The @GrpcChannel annotation identifies the gRPC channel to be used by the client. The name used in the annotation refers to a channel name in the application configuration. Now when the CDI container instantiates instances of the Client it will inject a dynamic proxy into the stringService field and then any code in methods in the Client class can call methods on the StringService which will be translated to gRPC calls. In the example above there is no need to directly use a Channel directly. The correct channel is added to the dynamic client proxy internally by the Helidon MP gRPC APIs. ",
            "title": "Using the Client Interface in an Application"
        },
        {
            "location": "/mp/grpc/02_mp_clients",
            "text": " There are a few steps to building and using a gRPC client in Helidon MP. As discussed in the section on Server-Side Services there are four different types of gRPC method. Unary - a simple method with at most a single request value and returning at most a single response value. Server Streaming - a method that takes at most a single request value but may return zero or more response values. Client Streaming - a request that takes one or more request values and returns at most one response value. Bi-directional Streaming - a method that can take one or more request values and return zero or more response values. An as with the server-side APIS, the Helidon MP gRPC client APIs support a number of different method signatures for each of the different gRPC method types. The Client Service Interface The next step is to produce an interface with the service methods that the client requires. For example, suppose we have a simple server side service that has a unary method to convert a string to uppercase. <markup lang=\"java\" title=\"Simple gRPC Service\" >@ApplicationScoped @io.helidon.microprofile.grpc.core.Grpc public interface StringService { @io.helidon.microprofile.grpc.core.Unary public String upper(String s) { return s == null ? null : s.toUpperCase(); } } The service has been written using the Helidon MP APIs but could just as easily be a traditional gRPC Java service generated from Protobuf files. The client API is agnostic of the server side implementation, it only cares about the method type, the request and response types and the type of Marshaller used to serialize the request and response. To write a client for the StringService all that is required is an interface. <markup lang=\"java\" title=\"Simple gRPC Service\" >@ApplicationScoped @io.helidon.microprofile.grpc.core.Grpc public interface StringService { @io.helidon.microprofile.grpc.core.Unary public String upper(String s); } There is no need to write any code to implement the client. The Helidon MP gRPC APIs will create a dynamic proxy for the interface using the information from the annotations and method signatures. The interface in the example above used the same method signature as the server but this does not have to be the case, the interface could have used any supported signature for a unary method, so for example it could just have easily been the standard unary method signature: <markup lang=\"java\" title=\"Simple gRPC Service\" >@ApplicationScoped @io.helidon.microprofile.grpc.core.Grpc public interface StringService { @io.helidon.microprofile.grpc.core.Unary public void upper(String s, StreamObserver&lt;String&gt; response); } We could also have made the client asynchronous by using one of the async method signatures: <markup lang=\"java\" title=\"Simple gRPC Service\" >@ApplicationScoped @io.helidon.microprofile.grpc.core.Grpc public interface StringService { @io.helidon.microprofile.grpc.core.Unary public CompletableFuture&lt;String&gt; upper(String s); } Configuring Channels For a gRPC client to connect to a server it requires a Channel. The Helidon MP gRPC APIs provide a way to inject channels into CDI beans that require them. Channels are configured in the grpc section of the Helidon application configuration. The examples below use an application.yaml file but there are many other ways to use and override configuration in Helidon <markup lang=\"yaml\" title=\"application.yaml\" >grpc: channels: test-server: host: localhost port: 1408 Channels are configured in the`channels` section Each sub-section is the Channel name that is then used to refer to this Channel in the application code Each channel contains a host name and a port. While most client application only connect to a single server it is possible to configure multiple named channels if the client needs to connect to multiple servers. <markup lang=\"yaml\" title=\"application.yaml\" >grpc: channels: london: host: london.foo.com port: 1408 new-york: host: ny.foo.com port: 1408 The above example shows two channel configurations, one named london and the other new-york . Configuring TLS It is also possible to configure a Channel to use TLS if the server is using TLS. <markup lang=\"yaml\" title=\"application.yaml\" >grpc: channels: test-server: host: localhost port: 1408 tls: enabled: true tls-cert-path: /certs/foo.cert tls-key-path: /certs/foo.key tls-ca-cert-path: /certs/ca.cert The tls section of the channel configuration is used to configure TLS. The enabled value is used to enable or disable TLS for this channel. The tls-cert value is the location of the TLS certificate file The tls-key value is the location of the TLS key file The tls-ca-cert value is the location of the TLS CA certificate file The SSL configuration uses the Helidon Resource class to locate configured keys and certificates. In the example above the tls-cert-path config key has the -path suffix which tells the configuration to load /certs/foo.cert as a file. If /certs/foo.cert was a resource on the classpath the configuration key could have been changed to tls-cert-resource-path to load /certs/foo.cert from the classpath. The same applies to the tls-key and tls-ca-cert configuration keys. See the io.helidon.common.configurable.Resource class for details. Using Channels Once one or more channels have been configured they can be used by client code. The simplest way to use a channel is to inject it into beans using CDI. The Helidon gRPC client APIs have CDI producers that can provide io.grpc.Channel instances. For example, a class might have an injectable io.grpc.Channel field: <markup lang=\"java\" title=\"gRPC Channel Injection\" > @Inject @GrpcChannel(name = \"test-server\") private Channel channel; The @Inject annotation tells CDI to inject the channel. The @GrpcChannel annotation is the qualifier that supplies the Channel name. This is the same name as used in the channel configuration in the configuration examples above. When an instance of the CDI bean with the channel field is instantiated a channel will be injected into it. The In-Process Channel If code is running in an application that is executing as part of a Helidon MP gRPC server there is a special in-process channel available. This allows code executing on the server to make calls to gRPC services deployed on that server in the same way an external client does. To inject an in-process channel a different qualifier annotation is used. <markup lang=\"java\" title=\"gRPC in-Process Channel Injection\" > @Inject @InProcessGrpcChannel private Channel channel; The @Inject annotation is used the same as previously. The @InProcessGrpcChannel is the qualifier that is used to tell the Helidon MP gRPC API to inject an in-process channel. Using the Client Interface in an Application Now that there is a client interface and a Channel configuration we can use these in the client application. The simplest way is to use the client in a CDI microprofile application. In the application class that requires the client we can declare a field of the same type as the client service interface. The field is then annotated so that CDI will inject the client proxy into the field. <markup lang=\"java\" title=\"Simple gRPC Service\" >@ApplicationScoped public class Client { @Inject @GrpcProxy @GrpcChannel(name = \"test-server\") private StringService stringService; The @Inject annotation tells the CDI to inject the client implementation; the gRPC MP APIs have a bean provider that does this. The @GrpcProxy annotation is used by the CDI container to match the injection point to the gRPC MP APIs provider The @GrpcChannel annotation identifies the gRPC channel to be used by the client. The name used in the annotation refers to a channel name in the application configuration. Now when the CDI container instantiates instances of the Client it will inject a dynamic proxy into the stringService field and then any code in methods in the Client class can call methods on the StringService which will be translated to gRPC calls. In the example above there is no need to directly use a Channel directly. The correct channel is added to the dynamic client proxy internally by the Helidon MP gRPC APIs. ",
            "title": "Building a gRPC Client"
        },
        {
            "location": "/mp/jwtauth/01_introduction",
            "text": " To enable JWT Authentication either add a dependency on the helidon-microprofile bundle or add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.jwt&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-jwt-auth&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/jwtauth/01_introduction",
            "text": " JSON Web Token (JWT) defines a compact and self-contained way for securely transmitting information between parties as a JSON object. With JWT Auth you can integrate security features such as single sign on into your Helidon MP applications. ",
            "title": "Overview"
        },
        {
            "location": "/mp/jwtauth/01_introduction",
            "text": " The main configuration point for JWT Auth is a JAX-RS Application class. As this class is discovered using CDI, it must have a bean defining annotation. Example of an application that enables JWT-Auth (with minimal required annotations): <markup lang=\"java\" >@LoginConfig(authMethod = \"MP-JWT\") @ApplicationScoped public class ProtectedApplication extends Application{ } Learn more about JWT authentication: Eclipse MicroProfile Interoperable JWT RBAC ",
            "title": "Next Steps"
        },
        {
            "location": "/se/config/06_advanced-configuration",
            "text": " This section discusses several advanced topics related to Helidon configuration. ",
            "title": "preambule"
        },
        {
            "location": "/se/config/06_advanced-configuration",
            "text": " The config system supports using environment variables as a config source, and is enabled by default. Since environment variable names are normally restricted to alphanumeric characters and underscore, this config source adds aliases that enable setting or overriding config entries with dotted and/or hyphenated keys. The mapping makes it possible to set or override a config entry with a key of \"foo.bar\" using an environment variable named \"FOO_BAR\" and \"foo.bar-baz\" using \"FOO_BAR_dash_BAZ\" . One use case for this mapping is config overrides in containers, where passing environment variables directly or via Kubernetes Secrets/ConfigMaps is common. Scripts that solve the mapping problem by explicitly converting variables to system properties can also be simplified. Aliases are produced for any environment variable name that matches all of the following: does not begin or end with a '_' character does not contain \"__\" contains one or more '_' characters For each such name, two aliases are added with the names mapped as follows: Replace any \"_dash_\" or \"_DASH_\" substrings with \"-\" , e.g. \"APP_PAGE_dash_SIZE\" becomes \"APP_PAGE-SIZE\" . Replace '_' with '.' and add as an alias, e.g. \"APP_GREETING\" is added as \"APP.GREETING\" and \"APP_PAGE-SIZE\" is added as \"APP.PAGE-SIZE\" . This mapping is added primarily to support mixed case config keys such as \"app.someCamelCaseKey\" . Convert the result of step 2 to lowercase and add as an alias, e.g. \"APP.GREETING\" is added as \"app.greeting\" and \"APP.PAGE-SIZE\" is added as \"app.page-size\" . ",
            "title": "Environment Variables Config Source"
        },
        {
            "location": "/se/config/06_advanced-configuration",
            "text": " The config system supports using a file system directory as a config source. Each non-directory file in the directory becomes a config entry: the file name is the key and the contents of that file are used as the corresponding config String value. The following example shows, for example, one way to load Kubernetes secrets mounted on the pod&#8217;s filesystem. If the directory conf/secrets contains these two files <markup title=\"File secrets/username \" >jose <markup title=\"File secrets/password \" >^ery$ecretP&amp;ssword your application can load this as configuration as follows: <markup lang=\"java\" title=\"Using directory config source\" >Config secrets = Config.builder( ConfigSources.directory(\"conf/secrets\")) .disableEnvironmentVariablesSource() .disableSystemPropertiesSource() .build(); assert secrets.get(\"username\") .asString() .get() .equals(\"jose\"); assert secrets.get(\"password\") .asString() .get() .equals(\"^ery$ecretP&amp;ssword\"); Loads all files from the conf/secrets directory. No need to use environment variables or system properties as sources in building the Config . The loaded config maps the key username to the value jose &#8230;&#8203; &#8230;&#8203;and the key password to ^ery$ecretP&amp;ssword . Remember that your application can process the contents of a given file as configuration. See the config sources section and the ConfigSources.file JavaDoc. ",
            "title": "Directory Config Source"
        },
        {
            "location": "/se/config/06_advanced-configuration",
            "text": "<markup lang=\"java\" >Config anotherConfig = Config.create(classpath(\"application.conf\")); Config config = Config.create( ConfigSources.create(anotherConfig.get(\"data\"))); ",
            "title": "Subtree of Another Config "
        },
        {
            "location": "/se/config/06_advanced-configuration",
            "text": "<markup lang=\"java\" >Config config = Config.create( ConfigSources.create(System.getProperties()).build()); ",
            "title": " Properties Object"
        },
        {
            "location": "/se/config/06_advanced-configuration",
            "text": "<markup lang=\"java\" >Config config = Config.create( ConfigSources.create(\"app.greeting = Hi\", \"text/x-java-properties\")); ",
            "title": " String of a Given Media Type"
        },
        {
            "location": "/se/config/06_advanced-configuration",
            "text": "<markup lang=\"java\" >Config config = Config.crate( ConfigSources.create(Map.of(\"app.page-size\", \"20\")) .lax() .build()); ",
            "title": " Map "
        },
        {
            "location": "/se/config/06_advanced-configuration",
            "text": "<markup lang=\"java\" >Config config = Config.create( ConfigSources.create(ObjectNode.builder() .addList(\"app.basic-range\", ListNode.builder() .addValue(\"-20\") .addValue(\"20\") .build()) .build())); ConfigSources.create variants for Properties or Map arguments return a ConfigSources.MapBuilder instance. A similar create variant accepts a Readable instead of a String . MapBuilder by default throws an exception if a key appears more than once in the map. The lax() method relaxes this; the config system logs a warning instead. ",
            "title": " ad hoc Config Nodes"
        },
        {
            "location": "/se/config/06_advanced-configuration",
            "text": " The config system provides several ways to create a Config tree from data already in memory. See the ConfigSources javadoc for further details. The numerous variants of the from method construct ConfigSource or Builder&lt;ConfigSource&gt; instances. Subtree of Another Config <markup lang=\"java\" >Config anotherConfig = Config.create(classpath(\"application.conf\")); Config config = Config.create( ConfigSources.create(anotherConfig.get(\"data\"))); Properties Object <markup lang=\"java\" >Config config = Config.create( ConfigSources.create(System.getProperties()).build()); String of a Given Media Type <markup lang=\"java\" >Config config = Config.create( ConfigSources.create(\"app.greeting = Hi\", \"text/x-java-properties\")); Map <markup lang=\"java\" >Config config = Config.crate( ConfigSources.create(Map.of(\"app.page-size\", \"20\")) .lax() .build()); ad hoc Config Nodes <markup lang=\"java\" >Config config = Config.create( ConfigSources.create(ObjectNode.builder() .addList(\"app.basic-range\", ListNode.builder() .addValue(\"-20\") .addValue(\"20\") .build()) .build())); ConfigSources.create variants for Properties or Map arguments return a ConfigSources.MapBuilder instance. A similar create variant accepts a Readable instead of a String . MapBuilder by default throws an exception if a key appears more than once in the map. The lax() method relaxes this; the config system logs a warning instead. ",
            "title": "In-memory Config Sources"
        },
        {
            "location": "/se/config/06_advanced-configuration",
            "text": " Sometimes you might want to create a single config tree from multiple sources but in a way that keeps the config from different sources in different subtrees. The config system lets you assign a prefix to all keys from a given source using the ConfigSources.prefixed method. The following example shows two YAML files as config sources and the code to load each with a different prefix into a single Config tree: <markup lang=\"hocon\" title=\"File app.conf \" >greeting = \"Hello\" page-size = 20 basic-range = [ -20, 20 ] <markup lang=\"hocon\" title=\"File data.conf \" >providers: [ { name = \"Provider1\" class = \"this.is.my.Provider1\" }, { name = \"Provider2\" class = \"this.is.my.Provider2\" } ] <markup lang=\"java\" title=\"Using prefixed config source\" >Config config = Config.create( ConfigSources.prefixed(\"app\", classpath(\"app.conf\")), ConfigSources.prefixed(\"data\", classpath(\"data.conf\"))); assert config.get(\"app.greeting\") .asString() .get() .equals(\"Hello\"); assert config.get(\"data.providers.0.name\") .asString() .get() .equals(\"Provider1\"); Specifies the prefix app for the associated source. Supplier&lt;ConfigSource&gt; for the file app.conf loaded from the current classpath . Specifies the prefix data for the associated source. Supplier&lt;ConfigSource&gt; for the file app.conf loaded from the current classpath . Key app.greeting combines the app prefix and the original key greeting from the app.conf source. Key data.providers.0.name combines the data prefix and the original key providers.0.name property from data.conf source. This technique can be useful, for example, if multiple sources contain keys that might overlap; assigning different prefixes to the keys from different sources gives your application a way to access all config elements distinctly even if their keys would otherwise conflict. ",
            "title": "Prefixed Config Sources"
        },
        {
            "location": "/se/config/06_advanced-configuration",
            "text": " The ConfigSources.create(Supplier&lt;ConfigSource&gt;&#8230;&#8203;) and ConfigSources.create(List&lt;Supplier&lt;ConfigSource&gt;&#8230;&#8203;) methods return a CompositeBuilder . By default, earlier sources in the list have higher priority than later ones, meaning that if the same key appears in two or more sources the source earlier in the list prevails. Each CompositeConfigSource 's merging strategy actually controls this behavior. The config system provides the FallbackMergingStrategy which implements the default, \"first wins\" algorithm. You can write your own implementation of ConfigSources.MergingStrategy and use it instead to provide a different algorithm. <markup lang=\"java\" title=\"Composite config source example\" >Config config = Config.create( ConfigSources.create(file(\"conf/dev.properties\").optional(), file(\"conf/config.properties\").optional()) .add(classpath(\"application.properties\")) .mergingStrategy(ConfigSources.MergingStrategy.fallback())); Creates a new Config instance from a single composite config source. Method ConfigSources.create(sources&#8230;&#8203;) returns CompositeBuilder instance initialized with two sources (from dev.properties and config.properties files). Adds third config source ( application.properties on classpath) to the same CompositeBuilder . Specifies the merging strategy. This example uses the default fallback merging strategy. ",
            "title": "Merging Strategies"
        },
        {
            "location": "/se/config/06_advanced-configuration",
            "text": " Prefixed Config Sources Sometimes you might want to create a single config tree from multiple sources but in a way that keeps the config from different sources in different subtrees. The config system lets you assign a prefix to all keys from a given source using the ConfigSources.prefixed method. The following example shows two YAML files as config sources and the code to load each with a different prefix into a single Config tree: <markup lang=\"hocon\" title=\"File app.conf \" >greeting = \"Hello\" page-size = 20 basic-range = [ -20, 20 ] <markup lang=\"hocon\" title=\"File data.conf \" >providers: [ { name = \"Provider1\" class = \"this.is.my.Provider1\" }, { name = \"Provider2\" class = \"this.is.my.Provider2\" } ] <markup lang=\"java\" title=\"Using prefixed config source\" >Config config = Config.create( ConfigSources.prefixed(\"app\", classpath(\"app.conf\")), ConfigSources.prefixed(\"data\", classpath(\"data.conf\"))); assert config.get(\"app.greeting\") .asString() .get() .equals(\"Hello\"); assert config.get(\"data.providers.0.name\") .asString() .get() .equals(\"Provider1\"); Specifies the prefix app for the associated source. Supplier&lt;ConfigSource&gt; for the file app.conf loaded from the current classpath . Specifies the prefix data for the associated source. Supplier&lt;ConfigSource&gt; for the file app.conf loaded from the current classpath . Key app.greeting combines the app prefix and the original key greeting from the app.conf source. Key data.providers.0.name combines the data prefix and the original key providers.0.name property from data.conf source. This technique can be useful, for example, if multiple sources contain keys that might overlap; assigning different prefixes to the keys from different sources gives your application a way to access all config elements distinctly even if their keys would otherwise conflict. Merging Strategies The ConfigSources.create(Supplier&lt;ConfigSource&gt;&#8230;&#8203;) and ConfigSources.create(List&lt;Supplier&lt;ConfigSource&gt;&#8230;&#8203;) methods return a CompositeBuilder . By default, earlier sources in the list have higher priority than later ones, meaning that if the same key appears in two or more sources the source earlier in the list prevails. Each CompositeConfigSource 's merging strategy actually controls this behavior. The config system provides the FallbackMergingStrategy which implements the default, \"first wins\" algorithm. You can write your own implementation of ConfigSources.MergingStrategy and use it instead to provide a different algorithm. <markup lang=\"java\" title=\"Composite config source example\" >Config config = Config.create( ConfigSources.create(file(\"conf/dev.properties\").optional(), file(\"conf/config.properties\").optional()) .add(classpath(\"application.properties\")) .mergingStrategy(ConfigSources.MergingStrategy.fallback())); Creates a new Config instance from a single composite config source. Method ConfigSources.create(sources&#8230;&#8203;) returns CompositeBuilder instance initialized with two sources (from dev.properties and config.properties files). Adds third config source ( application.properties on classpath) to the same CompositeBuilder . Specifies the merging strategy. This example uses the default fallback merging strategy. ",
            "title": "Handling Key Collisions"
        },
        {
            "location": "/se/config/06_advanced-configuration",
            "text": " Although the examples above use a single source, you can build a single Config from multiple sources. Handling Key Collisions Prefixed Config Sources Sometimes you might want to create a single config tree from multiple sources but in a way that keeps the config from different sources in different subtrees. The config system lets you assign a prefix to all keys from a given source using the ConfigSources.prefixed method. The following example shows two YAML files as config sources and the code to load each with a different prefix into a single Config tree: <markup lang=\"hocon\" title=\"File app.conf \" >greeting = \"Hello\" page-size = 20 basic-range = [ -20, 20 ] <markup lang=\"hocon\" title=\"File data.conf \" >providers: [ { name = \"Provider1\" class = \"this.is.my.Provider1\" }, { name = \"Provider2\" class = \"this.is.my.Provider2\" } ] <markup lang=\"java\" title=\"Using prefixed config source\" >Config config = Config.create( ConfigSources.prefixed(\"app\", classpath(\"app.conf\")), ConfigSources.prefixed(\"data\", classpath(\"data.conf\"))); assert config.get(\"app.greeting\") .asString() .get() .equals(\"Hello\"); assert config.get(\"data.providers.0.name\") .asString() .get() .equals(\"Provider1\"); Specifies the prefix app for the associated source. Supplier&lt;ConfigSource&gt; for the file app.conf loaded from the current classpath . Specifies the prefix data for the associated source. Supplier&lt;ConfigSource&gt; for the file app.conf loaded from the current classpath . Key app.greeting combines the app prefix and the original key greeting from the app.conf source. Key data.providers.0.name combines the data prefix and the original key providers.0.name property from data.conf source. This technique can be useful, for example, if multiple sources contain keys that might overlap; assigning different prefixes to the keys from different sources gives your application a way to access all config elements distinctly even if their keys would otherwise conflict. Merging Strategies The ConfigSources.create(Supplier&lt;ConfigSource&gt;&#8230;&#8203;) and ConfigSources.create(List&lt;Supplier&lt;ConfigSource&gt;&#8230;&#8203;) methods return a CompositeBuilder . By default, earlier sources in the list have higher priority than later ones, meaning that if the same key appears in two or more sources the source earlier in the list prevails. Each CompositeConfigSource 's merging strategy actually controls this behavior. The config system provides the FallbackMergingStrategy which implements the default, \"first wins\" algorithm. You can write your own implementation of ConfigSources.MergingStrategy and use it instead to provide a different algorithm. <markup lang=\"java\" title=\"Composite config source example\" >Config config = Config.create( ConfigSources.create(file(\"conf/dev.properties\").optional(), file(\"conf/config.properties\").optional()) .add(classpath(\"application.properties\")) .mergingStrategy(ConfigSources.MergingStrategy.fallback())); Creates a new Config instance from a single composite config source. Method ConfigSources.create(sources&#8230;&#8203;) returns CompositeBuilder instance initialized with two sources (from dev.properties and config.properties files). Adds third config source ( application.properties on classpath) to the same CompositeBuilder . Specifies the merging strategy. This example uses the default fallback merging strategy. ",
            "title": "Multi-Source Config s and Composite Config Sources"
        },
        {
            "location": "/se/config/06_advanced-configuration",
            "text": " Most applications let the config system try to infer the media type of the config source. By default config source implementations use the io.helidon.common.media.type.MediaTypes API to infer the source media type from the source, typically (but not always) based on the file type portion of the file path. Helidon media type module has a predefined set of mappings as configured in common/media-type/src/main/resources/io/helidon/common/media/type/default-media-types.properties , including the Config supported formats: .properties , .yaml , .json and .conf . To handle other formats you can implement and register your own io.helidon.common.media.type.spi.MediaTypeDetector Java Service implementations. (Typically you would also write and register a config parser to translate that format; see Locating a Parser below.). ",
            "title": "By Inference"
        },
        {
            "location": "/se/config/06_advanced-configuration",
            "text": " Your application can specify what media type to use in interpreting a config source. Use this if your application knows the media type but the system might not be able to infer it correctly, either because no type detector would recognize it or because there might be more than one inferred media type. <markup lang=\"java\" title=\"Specify mediaType for config source\" >Config config = Config.create(classpath(\"props\") .mediaType(\"text/x-java-properties\")); The config system cannot infer the media type because there is no file type in the path props . The developer knows the file is in Java Properties format so specifies the media type explicitly. Note that a file type detector could be written to also inspect the contents of the file to infer the media type. The detectors provided by Helidon only inspect the suffix in the name of the file. ",
            "title": "By Application Directive"
        },
        {
            "location": "/se/config/06_advanced-configuration",
            "text": " By Inference Most applications let the config system try to infer the media type of the config source. By default config source implementations use the io.helidon.common.media.type.MediaTypes API to infer the source media type from the source, typically (but not always) based on the file type portion of the file path. Helidon media type module has a predefined set of mappings as configured in common/media-type/src/main/resources/io/helidon/common/media/type/default-media-types.properties , including the Config supported formats: .properties , .yaml , .json and .conf . To handle other formats you can implement and register your own io.helidon.common.media.type.spi.MediaTypeDetector Java Service implementations. (Typically you would also write and register a config parser to translate that format; see Locating a Parser below.). By Application Directive Your application can specify what media type to use in interpreting a config source. Use this if your application knows the media type but the system might not be able to infer it correctly, either because no type detector would recognize it or because there might be more than one inferred media type. <markup lang=\"java\" title=\"Specify mediaType for config source\" >Config config = Config.create(classpath(\"props\") .mediaType(\"text/x-java-properties\")); The config system cannot infer the media type because there is no file type in the path props . The developer knows the file is in Java Properties format so specifies the media type explicitly. Note that a file type detector could be written to also inspect the contents of the file to infer the media type. The detectors provided by Helidon only inspect the suffix in the name of the file. ",
            "title": "Identifying the Media Type"
        },
        {
            "location": "/se/config/06_advanced-configuration",
            "text": " Each config parser reports which media types it handles. Once the config system has determined a source&#8217;s media type, it searches the config parsers associated with the config builder for one that recognizes that media type. It then uses that parser to translate the config in the source into the in-memory config tree. The application can add one or more parsers to a Config.Builder using the addParser method. This makes the parser available for use by the config sources associated with that builder, but does not directly tie a given parser to a given source. The builder uses media-type matching to select one of the parsers registered with the builder for each source. If the config system cannot locate a parser that matches the media type of a source, it throws a ConfigException when trying to prepare the configuration. ",
            "title": "By Inference from media-type "
        },
        {
            "location": "/se/config/06_advanced-configuration",
            "text": " Your application can specify which parser to use for a config source. The AbstractParsableConfigSource.Builder class exposes the parser method, which accepts the ConfigParser to be used for that source. Several methods on ConfigSources such as classpath , directory , and file return this builder class. Generally try to rely on media-type matching rather than specifying a given parser for a given source in the application. This keeps your application more flexible, both by insulating it from implementation classes and by letting it easily take advantage of improvements in or alternatives to the parsers available for a given media type. <markup lang=\"java\" title=\"Specify parser for config source\" >Config config = Config.create(classpath(\"props\") .parser(ConfigParsers.properties())); The config system cannot infer the media type because there is no file type in the path props . The developer knows the file is in Java Properties format so specifies the properties parser explicitly. ",
            "title": "By Application Directive"
        },
        {
            "location": "/se/config/06_advanced-configuration",
            "text": " By Inference from media-type Each config parser reports which media types it handles. Once the config system has determined a source&#8217;s media type, it searches the config parsers associated with the config builder for one that recognizes that media type. It then uses that parser to translate the config in the source into the in-memory config tree. The application can add one or more parsers to a Config.Builder using the addParser method. This makes the parser available for use by the config sources associated with that builder, but does not directly tie a given parser to a given source. The builder uses media-type matching to select one of the parsers registered with the builder for each source. If the config system cannot locate a parser that matches the media type of a source, it throws a ConfigException when trying to prepare the configuration. By Application Directive Your application can specify which parser to use for a config source. The AbstractParsableConfigSource.Builder class exposes the parser method, which accepts the ConfigParser to be used for that source. Several methods on ConfigSources such as classpath , directory , and file return this builder class. Generally try to rely on media-type matching rather than specifying a given parser for a given source in the application. This keeps your application more flexible, both by insulating it from implementation classes and by letting it easily take advantage of improvements in or alternatives to the parsers available for a given media type. <markup lang=\"java\" title=\"Specify parser for config source\" >Config config = Config.create(classpath(\"props\") .parser(ConfigParsers.properties())); The config system cannot infer the media type because there is no file type in the path props . The developer knows the file is in Java Properties format so specifies the properties parser explicitly. ",
            "title": "Locating a Parser"
        },
        {
            "location": "/se/config/06_advanced-configuration",
            "text": " As the config sources and parsers section describes, these two work together to read and translate configuration data from some external form into the corresponding in-memory config tree. Although most applications are explicit about the config sources they use in building a Config , the config system often has to figure out what parser to use. It does so by: determining, the best that it can, the media type of the source, and locating a parser that can translate that media type. Identifying the Media Type By Inference Most applications let the config system try to infer the media type of the config source. By default config source implementations use the io.helidon.common.media.type.MediaTypes API to infer the source media type from the source, typically (but not always) based on the file type portion of the file path. Helidon media type module has a predefined set of mappings as configured in common/media-type/src/main/resources/io/helidon/common/media/type/default-media-types.properties , including the Config supported formats: .properties , .yaml , .json and .conf . To handle other formats you can implement and register your own io.helidon.common.media.type.spi.MediaTypeDetector Java Service implementations. (Typically you would also write and register a config parser to translate that format; see Locating a Parser below.). By Application Directive Your application can specify what media type to use in interpreting a config source. Use this if your application knows the media type but the system might not be able to infer it correctly, either because no type detector would recognize it or because there might be more than one inferred media type. <markup lang=\"java\" title=\"Specify mediaType for config source\" >Config config = Config.create(classpath(\"props\") .mediaType(\"text/x-java-properties\")); The config system cannot infer the media type because there is no file type in the path props . The developer knows the file is in Java Properties format so specifies the media type explicitly. Note that a file type detector could be written to also inspect the contents of the file to infer the media type. The detectors provided by Helidon only inspect the suffix in the name of the file. Locating a Parser By Inference from media-type Each config parser reports which media types it handles. Once the config system has determined a source&#8217;s media type, it searches the config parsers associated with the config builder for one that recognizes that media type. It then uses that parser to translate the config in the source into the in-memory config tree. The application can add one or more parsers to a Config.Builder using the addParser method. This makes the parser available for use by the config sources associated with that builder, but does not directly tie a given parser to a given source. The builder uses media-type matching to select one of the parsers registered with the builder for each source. If the config system cannot locate a parser that matches the media type of a source, it throws a ConfigException when trying to prepare the configuration. By Application Directive Your application can specify which parser to use for a config source. The AbstractParsableConfigSource.Builder class exposes the parser method, which accepts the ConfigParser to be used for that source. Several methods on ConfigSources such as classpath , directory , and file return this builder class. Generally try to rely on media-type matching rather than specifying a given parser for a given source in the application. This keeps your application more flexible, both by insulating it from implementation classes and by letting it easily take advantage of improvements in or alternatives to the parsers available for a given media type. <markup lang=\"java\" title=\"Specify parser for config source\" >Config config = Config.create(classpath(\"props\") .parser(ConfigParsers.properties())); The config system cannot infer the media type because there is no file type in the path props . The developer knows the file is in Java Properties format so specifies the properties parser explicitly. ",
            "title": "How Config Chooses Parsers"
        },
        {
            "location": "/se/config/06_advanced-configuration",
            "text": "<markup lang=\"java\" title=\"Specify JSON as media type for node\" >Config config = Config.create( classpath(\"application.yaml\") .mediaTypeMapping( key -&gt; \"app\".equals(key.toString()) ? \"application/json\" : null)); assert config.get(\"secrets.username\").asString() .get().equals(\"jose\"); assert config.get(\"secrets.password\").asString() .get().equals(\"^ery$ecretP&amp;ssword\"); assert config.get(\"app\").type() == Type.OBJECT; assert config.get(\"app.greeting\") .asString().get().equals(\"Hello\"); assert config.get(\"app.page-size\") .asInt().get() == 20; assert config.get(\"app.basic-range.0\") .asInt().get() == -20; assert config.get(\"app.basic-range.1\") .asInt().get() == 20; The source builder&#8217;s mediaTypeMapping method accepts a function which returns the appropriate media types (if any) for config keys. The function says to treat the app property value as a JSON document and leave other nodes unchanged. Other properties are loaded as expected. Property app is now an structured object node. Because the function passed to mediaTypeMapping identifies the app node as a JSON document, the config system selects the config parser that is registered with the builder which also handles the JSON media type. Also, note that the config system replaces the original String value node with an object node resulting from parsing that String value as JSON. ",
            "title": "Specify Key-to-media-type Mapping"
        },
        {
            "location": "/se/config/06_advanced-configuration",
            "text": " Alternatively, your application could map config keys to the specific parsers you want to use for parsing those keys' values. <markup lang=\"java\" title=\"Specify JSON formatted property' parser instance\" >Config config = Config.create( ConfigSources.classpath(\"application.yaml\") .parserMapping( key -&gt; \"app\".equals(key.toString()) ? HoconConfigParserBuilder.buildDefault() : null)); Uses the parserMapping method to map keys to parser instances. Tells the config system to use the HOCON parser for translating the String value of the app key. (HCON is a superset of JSON.) As before, the config system replaces the value node in the containing config tree with the config tree resulting from the additional parse. ",
            "title": "Specify Key-to-parser Mapping"
        },
        {
            "location": "/se/config/06_advanced-configuration",
            "text": " A config value node might contain an entire config document in String form, but in a format different from the containing document. Your application can tell the config system to parse such a node as config in a different format and replace the String value node in the original tree with the config tree that results from parsing that String . In this example, a YAML document contains a JSON document as a leaf. <markup lang=\"yaml\" title=\"YAML file with included JSON formated property\" >secrets: username: \"jose\" password: \"^ery$ecretP&amp;ssword\" app: &gt; { \"greeting\": \"Hello\", \"page-size\": 20, \"basic-range\": [ -20, 20 ] } The property app is itself formatted as a JSON document. Specify Key-to-media-type Mapping <markup lang=\"java\" title=\"Specify JSON as media type for node\" >Config config = Config.create( classpath(\"application.yaml\") .mediaTypeMapping( key -&gt; \"app\".equals(key.toString()) ? \"application/json\" : null)); assert config.get(\"secrets.username\").asString() .get().equals(\"jose\"); assert config.get(\"secrets.password\").asString() .get().equals(\"^ery$ecretP&amp;ssword\"); assert config.get(\"app\").type() == Type.OBJECT; assert config.get(\"app.greeting\") .asString().get().equals(\"Hello\"); assert config.get(\"app.page-size\") .asInt().get() == 20; assert config.get(\"app.basic-range.0\") .asInt().get() == -20; assert config.get(\"app.basic-range.1\") .asInt().get() == 20; The source builder&#8217;s mediaTypeMapping method accepts a function which returns the appropriate media types (if any) for config keys. The function says to treat the app property value as a JSON document and leave other nodes unchanged. Other properties are loaded as expected. Property app is now an structured object node. Because the function passed to mediaTypeMapping identifies the app node as a JSON document, the config system selects the config parser that is registered with the builder which also handles the JSON media type. Also, note that the config system replaces the original String value node with an object node resulting from parsing that String value as JSON. Specify Key-to-parser Mapping Alternatively, your application could map config keys to the specific parsers you want to use for parsing those keys' values. <markup lang=\"java\" title=\"Specify JSON formatted property' parser instance\" >Config config = Config.create( ConfigSources.classpath(\"application.yaml\") .parserMapping( key -&gt; \"app\".equals(key.toString()) ? HoconConfigParserBuilder.buildDefault() : null)); Uses the parserMapping method to map keys to parser instances. Tells the config system to use the HOCON parser for translating the String value of the app key. (HCON is a superset of JSON.) As before, the config system replaces the value node in the containing config tree with the config tree resulting from the additional parse. ",
            "title": "Parsing a Config Value as Config"
        },
        {
            "location": "/se/config/06_advanced-configuration",
            "text": " Your application loads the configuration specified by a meta-config file by invoking the MetaConfig.config(Config) method, passing a config object read from the meta-config source as the argument; If you desire a Config.Builder instead of a fully built Config instance, you can use the Config.Builder.config(Config) method to update the builder with meta configuration. Your application can further fine-tune this builder before using it to construct a Config tree. The config system interprets the meta-config as directions for how to build a config tree, rather than as the config data itself. ",
            "title": "Loading Config by Specifying a Meta-configuration File"
        },
        {
            "location": "/se/config/06_advanced-configuration",
            "text": " The introduction section shows how to use Config.create() to load config from one of several possible default config files. That same method also searches for one of several possible default meta-config files from which to load config sources to be used for the default config. The Config.create() method determines the default configuration from the following search: Attempt to load meta-config from at most one of the following files, first on the file system in current directory, then on classpath, checked in this order: meta-config.yaml - meta configuration file in YAML format meta-config.conf - meta configuration file in HOCON format meta-config.json - meta configuration file in JSON format meta-config.properties - meta configuration file in Java Properties format Otherwise, load config from: environment variables, and Java system properties, and at most one of the following, checking in this order: application.yaml - configuration file in YAML format application.conf - configuration file in HOCON format application.json - configuration file in JSON format application.properties - configuration file in Java Properties format Remember that the config system will check for these default meta-config and config files only if the classpath includes the corresponding parsers. The introduction section on built-in formats section describes this further. See javadoc Config.Builder.config(Config) . ",
            "title": "Loading Config from an Implicit Meta-configuration File"
        },
        {
            "location": "/se/config/06_advanced-configuration",
            "text": " This section is now available in config profile format ",
            "title": "Meta-configuration File Format"
        },
        {
            "location": "/se/config/06_advanced-configuration",
            "text": " Here is how your application can use meta-configuration in a particular resource on the classpath to load a Config tree: <markup lang=\"java\" title=\"Loading Config using Meta-configuration\" >Config metaConfig = Config.create(classpath(\"config-meta-all.conf\")); Config config = MetaConfig.config(metaConfig); We create a meta configuration from our meta configuration source This method populates the config sources from all the actual sources declared in the meta-configuration. ",
            "title": "Loading Config using Meta-configuration"
        },
        {
            "location": "/se/config/06_advanced-configuration",
            "text": " This section is now available in config profiles , which make meta-configuration obsolete - you can achieve the same with less configuration. A profile file is a meta-configuration file selected by the rules defined in the link above. Instead of including code in your application to construct config trees from builders, sources, etc., you can instead prepare meta-configuration in a file that declares the sources to load and their attributes. You can either specify the meta-config file in your application or allow the config system to search for and load meta-config from a preset list of possible sources. Loading Config by Specifying a Meta-configuration File Your application loads the configuration specified by a meta-config file by invoking the MetaConfig.config(Config) method, passing a config object read from the meta-config source as the argument; If you desire a Config.Builder instead of a fully built Config instance, you can use the Config.Builder.config(Config) method to update the builder with meta configuration. Your application can further fine-tune this builder before using it to construct a Config tree. The config system interprets the meta-config as directions for how to build a config tree, rather than as the config data itself. Loading Config from an Implicit Meta-configuration File The introduction section shows how to use Config.create() to load config from one of several possible default config files. That same method also searches for one of several possible default meta-config files from which to load config sources to be used for the default config. The Config.create() method determines the default configuration from the following search: Attempt to load meta-config from at most one of the following files, first on the file system in current directory, then on classpath, checked in this order: meta-config.yaml - meta configuration file in YAML format meta-config.conf - meta configuration file in HOCON format meta-config.json - meta configuration file in JSON format meta-config.properties - meta configuration file in Java Properties format Otherwise, load config from: environment variables, and Java system properties, and at most one of the following, checking in this order: application.yaml - configuration file in YAML format application.conf - configuration file in HOCON format application.json - configuration file in JSON format application.properties - configuration file in Java Properties format Remember that the config system will check for these default meta-config and config files only if the classpath includes the corresponding parsers. The introduction section on built-in formats section describes this further. See javadoc Config.Builder.config(Config) . Meta-configuration File Format This section is now available in config profile format Loading Config using Meta-configuration Here is how your application can use meta-configuration in a particular resource on the classpath to load a Config tree: <markup lang=\"java\" title=\"Loading Config using Meta-configuration\" >Config metaConfig = Config.create(classpath(\"config-meta-all.conf\")); Config config = MetaConfig.config(metaConfig); We create a meta configuration from our meta configuration source This method populates the config sources from all the actual sources declared in the meta-configuration. ",
            "title": "Loading Config using Meta-configuration"
        },
        {
            "location": "/se/config/06_advanced-configuration",
            "text": " Environment Variables Config Source The config system supports using environment variables as a config source, and is enabled by default. Since environment variable names are normally restricted to alphanumeric characters and underscore, this config source adds aliases that enable setting or overriding config entries with dotted and/or hyphenated keys. The mapping makes it possible to set or override a config entry with a key of \"foo.bar\" using an environment variable named \"FOO_BAR\" and \"foo.bar-baz\" using \"FOO_BAR_dash_BAZ\" . One use case for this mapping is config overrides in containers, where passing environment variables directly or via Kubernetes Secrets/ConfigMaps is common. Scripts that solve the mapping problem by explicitly converting variables to system properties can also be simplified. Aliases are produced for any environment variable name that matches all of the following: does not begin or end with a '_' character does not contain \"__\" contains one or more '_' characters For each such name, two aliases are added with the names mapped as follows: Replace any \"_dash_\" or \"_DASH_\" substrings with \"-\" , e.g. \"APP_PAGE_dash_SIZE\" becomes \"APP_PAGE-SIZE\" . Replace '_' with '.' and add as an alias, e.g. \"APP_GREETING\" is added as \"APP.GREETING\" and \"APP_PAGE-SIZE\" is added as \"APP.PAGE-SIZE\" . This mapping is added primarily to support mixed case config keys such as \"app.someCamelCaseKey\" . Convert the result of step 2 to lowercase and add as an alias, e.g. \"APP.GREETING\" is added as \"app.greeting\" and \"APP.PAGE-SIZE\" is added as \"app.page-size\" . Directory Config Source The config system supports using a file system directory as a config source. Each non-directory file in the directory becomes a config entry: the file name is the key and the contents of that file are used as the corresponding config String value. The following example shows, for example, one way to load Kubernetes secrets mounted on the pod&#8217;s filesystem. If the directory conf/secrets contains these two files <markup title=\"File secrets/username \" >jose <markup title=\"File secrets/password \" >^ery$ecretP&amp;ssword your application can load this as configuration as follows: <markup lang=\"java\" title=\"Using directory config source\" >Config secrets = Config.builder( ConfigSources.directory(\"conf/secrets\")) .disableEnvironmentVariablesSource() .disableSystemPropertiesSource() .build(); assert secrets.get(\"username\") .asString() .get() .equals(\"jose\"); assert secrets.get(\"password\") .asString() .get() .equals(\"^ery$ecretP&amp;ssword\"); Loads all files from the conf/secrets directory. No need to use environment variables or system properties as sources in building the Config . The loaded config maps the key username to the value jose &#8230;&#8203; &#8230;&#8203;and the key password to ^ery$ecretP&amp;ssword . Remember that your application can process the contents of a given file as configuration. See the config sources section and the ConfigSources.file JavaDoc. In-memory Config Sources The config system provides several ways to create a Config tree from data already in memory. See the ConfigSources javadoc for further details. The numerous variants of the from method construct ConfigSource or Builder&lt;ConfigSource&gt; instances. Subtree of Another Config <markup lang=\"java\" >Config anotherConfig = Config.create(classpath(\"application.conf\")); Config config = Config.create( ConfigSources.create(anotherConfig.get(\"data\"))); Properties Object <markup lang=\"java\" >Config config = Config.create( ConfigSources.create(System.getProperties()).build()); String of a Given Media Type <markup lang=\"java\" >Config config = Config.create( ConfigSources.create(\"app.greeting = Hi\", \"text/x-java-properties\")); Map <markup lang=\"java\" >Config config = Config.crate( ConfigSources.create(Map.of(\"app.page-size\", \"20\")) .lax() .build()); ad hoc Config Nodes <markup lang=\"java\" >Config config = Config.create( ConfigSources.create(ObjectNode.builder() .addList(\"app.basic-range\", ListNode.builder() .addValue(\"-20\") .addValue(\"20\") .build()) .build())); ConfigSources.create variants for Properties or Map arguments return a ConfigSources.MapBuilder instance. A similar create variant accepts a Readable instead of a String . MapBuilder by default throws an exception if a key appears more than once in the map. The lax() method relaxes this; the config system logs a warning instead. Multi-Source Config s and Composite Config Sources Although the examples above use a single source, you can build a single Config from multiple sources. Handling Key Collisions Prefixed Config Sources Sometimes you might want to create a single config tree from multiple sources but in a way that keeps the config from different sources in different subtrees. The config system lets you assign a prefix to all keys from a given source using the ConfigSources.prefixed method. The following example shows two YAML files as config sources and the code to load each with a different prefix into a single Config tree: <markup lang=\"hocon\" title=\"File app.conf \" >greeting = \"Hello\" page-size = 20 basic-range = [ -20, 20 ] <markup lang=\"hocon\" title=\"File data.conf \" >providers: [ { name = \"Provider1\" class = \"this.is.my.Provider1\" }, { name = \"Provider2\" class = \"this.is.my.Provider2\" } ] <markup lang=\"java\" title=\"Using prefixed config source\" >Config config = Config.create( ConfigSources.prefixed(\"app\", classpath(\"app.conf\")), ConfigSources.prefixed(\"data\", classpath(\"data.conf\"))); assert config.get(\"app.greeting\") .asString() .get() .equals(\"Hello\"); assert config.get(\"data.providers.0.name\") .asString() .get() .equals(\"Provider1\"); Specifies the prefix app for the associated source. Supplier&lt;ConfigSource&gt; for the file app.conf loaded from the current classpath . Specifies the prefix data for the associated source. Supplier&lt;ConfigSource&gt; for the file app.conf loaded from the current classpath . Key app.greeting combines the app prefix and the original key greeting from the app.conf source. Key data.providers.0.name combines the data prefix and the original key providers.0.name property from data.conf source. This technique can be useful, for example, if multiple sources contain keys that might overlap; assigning different prefixes to the keys from different sources gives your application a way to access all config elements distinctly even if their keys would otherwise conflict. Merging Strategies The ConfigSources.create(Supplier&lt;ConfigSource&gt;&#8230;&#8203;) and ConfigSources.create(List&lt;Supplier&lt;ConfigSource&gt;&#8230;&#8203;) methods return a CompositeBuilder . By default, earlier sources in the list have higher priority than later ones, meaning that if the same key appears in two or more sources the source earlier in the list prevails. Each CompositeConfigSource 's merging strategy actually controls this behavior. The config system provides the FallbackMergingStrategy which implements the default, \"first wins\" algorithm. You can write your own implementation of ConfigSources.MergingStrategy and use it instead to provide a different algorithm. <markup lang=\"java\" title=\"Composite config source example\" >Config config = Config.create( ConfigSources.create(file(\"conf/dev.properties\").optional(), file(\"conf/config.properties\").optional()) .add(classpath(\"application.properties\")) .mergingStrategy(ConfigSources.MergingStrategy.fallback())); Creates a new Config instance from a single composite config source. Method ConfigSources.create(sources&#8230;&#8203;) returns CompositeBuilder instance initialized with two sources (from dev.properties and config.properties files). Adds third config source ( application.properties on classpath) to the same CompositeBuilder . Specifies the merging strategy. This example uses the default fallback merging strategy. How Config Chooses Parsers As the config sources and parsers section describes, these two work together to read and translate configuration data from some external form into the corresponding in-memory config tree. Although most applications are explicit about the config sources they use in building a Config , the config system often has to figure out what parser to use. It does so by: determining, the best that it can, the media type of the source, and locating a parser that can translate that media type. Identifying the Media Type By Inference Most applications let the config system try to infer the media type of the config source. By default config source implementations use the io.helidon.common.media.type.MediaTypes API to infer the source media type from the source, typically (but not always) based on the file type portion of the file path. Helidon media type module has a predefined set of mappings as configured in common/media-type/src/main/resources/io/helidon/common/media/type/default-media-types.properties , including the Config supported formats: .properties , .yaml , .json and .conf . To handle other formats you can implement and register your own io.helidon.common.media.type.spi.MediaTypeDetector Java Service implementations. (Typically you would also write and register a config parser to translate that format; see Locating a Parser below.). By Application Directive Your application can specify what media type to use in interpreting a config source. Use this if your application knows the media type but the system might not be able to infer it correctly, either because no type detector would recognize it or because there might be more than one inferred media type. <markup lang=\"java\" title=\"Specify mediaType for config source\" >Config config = Config.create(classpath(\"props\") .mediaType(\"text/x-java-properties\")); The config system cannot infer the media type because there is no file type in the path props . The developer knows the file is in Java Properties format so specifies the media type explicitly. Note that a file type detector could be written to also inspect the contents of the file to infer the media type. The detectors provided by Helidon only inspect the suffix in the name of the file. Locating a Parser By Inference from media-type Each config parser reports which media types it handles. Once the config system has determined a source&#8217;s media type, it searches the config parsers associated with the config builder for one that recognizes that media type. It then uses that parser to translate the config in the source into the in-memory config tree. The application can add one or more parsers to a Config.Builder using the addParser method. This makes the parser available for use by the config sources associated with that builder, but does not directly tie a given parser to a given source. The builder uses media-type matching to select one of the parsers registered with the builder for each source. If the config system cannot locate a parser that matches the media type of a source, it throws a ConfigException when trying to prepare the configuration. By Application Directive Your application can specify which parser to use for a config source. The AbstractParsableConfigSource.Builder class exposes the parser method, which accepts the ConfigParser to be used for that source. Several methods on ConfigSources such as classpath , directory , and file return this builder class. Generally try to rely on media-type matching rather than specifying a given parser for a given source in the application. This keeps your application more flexible, both by insulating it from implementation classes and by letting it easily take advantage of improvements in or alternatives to the parsers available for a given media type. <markup lang=\"java\" title=\"Specify parser for config source\" >Config config = Config.create(classpath(\"props\") .parser(ConfigParsers.properties())); The config system cannot infer the media type because there is no file type in the path props . The developer knows the file is in Java Properties format so specifies the properties parser explicitly. Parsing a Config Value as Config A config value node might contain an entire config document in String form, but in a format different from the containing document. Your application can tell the config system to parse such a node as config in a different format and replace the String value node in the original tree with the config tree that results from parsing that String . In this example, a YAML document contains a JSON document as a leaf. <markup lang=\"yaml\" title=\"YAML file with included JSON formated property\" >secrets: username: \"jose\" password: \"^ery$ecretP&amp;ssword\" app: &gt; { \"greeting\": \"Hello\", \"page-size\": 20, \"basic-range\": [ -20, 20 ] } The property app is itself formatted as a JSON document. Specify Key-to-media-type Mapping <markup lang=\"java\" title=\"Specify JSON as media type for node\" >Config config = Config.create( classpath(\"application.yaml\") .mediaTypeMapping( key -&gt; \"app\".equals(key.toString()) ? \"application/json\" : null)); assert config.get(\"secrets.username\").asString() .get().equals(\"jose\"); assert config.get(\"secrets.password\").asString() .get().equals(\"^ery$ecretP&amp;ssword\"); assert config.get(\"app\").type() == Type.OBJECT; assert config.get(\"app.greeting\") .asString().get().equals(\"Hello\"); assert config.get(\"app.page-size\") .asInt().get() == 20; assert config.get(\"app.basic-range.0\") .asInt().get() == -20; assert config.get(\"app.basic-range.1\") .asInt().get() == 20; The source builder&#8217;s mediaTypeMapping method accepts a function which returns the appropriate media types (if any) for config keys. The function says to treat the app property value as a JSON document and leave other nodes unchanged. Other properties are loaded as expected. Property app is now an structured object node. Because the function passed to mediaTypeMapping identifies the app node as a JSON document, the config system selects the config parser that is registered with the builder which also handles the JSON media type. Also, note that the config system replaces the original String value node with an object node resulting from parsing that String value as JSON. Specify Key-to-parser Mapping Alternatively, your application could map config keys to the specific parsers you want to use for parsing those keys' values. <markup lang=\"java\" title=\"Specify JSON formatted property' parser instance\" >Config config = Config.create( ConfigSources.classpath(\"application.yaml\") .parserMapping( key -&gt; \"app\".equals(key.toString()) ? HoconConfigParserBuilder.buildDefault() : null)); Uses the parserMapping method to map keys to parser instances. Tells the config system to use the HOCON parser for translating the String value of the app key. (HCON is a superset of JSON.) As before, the config system replaces the value node in the containing config tree with the config tree resulting from the additional parse. Loading Config using Meta-configuration This section is now available in config profiles , which make meta-configuration obsolete - you can achieve the same with less configuration. A profile file is a meta-configuration file selected by the rules defined in the link above. Instead of including code in your application to construct config trees from builders, sources, etc., you can instead prepare meta-configuration in a file that declares the sources to load and their attributes. You can either specify the meta-config file in your application or allow the config system to search for and load meta-config from a preset list of possible sources. Loading Config by Specifying a Meta-configuration File Your application loads the configuration specified by a meta-config file by invoking the MetaConfig.config(Config) method, passing a config object read from the meta-config source as the argument; If you desire a Config.Builder instead of a fully built Config instance, you can use the Config.Builder.config(Config) method to update the builder with meta configuration. Your application can further fine-tune this builder before using it to construct a Config tree. The config system interprets the meta-config as directions for how to build a config tree, rather than as the config data itself. Loading Config from an Implicit Meta-configuration File The introduction section shows how to use Config.create() to load config from one of several possible default config files. That same method also searches for one of several possible default meta-config files from which to load config sources to be used for the default config. The Config.create() method determines the default configuration from the following search: Attempt to load meta-config from at most one of the following files, first on the file system in current directory, then on classpath, checked in this order: meta-config.yaml - meta configuration file in YAML format meta-config.conf - meta configuration file in HOCON format meta-config.json - meta configuration file in JSON format meta-config.properties - meta configuration file in Java Properties format Otherwise, load config from: environment variables, and Java system properties, and at most one of the following, checking in this order: application.yaml - configuration file in YAML format application.conf - configuration file in HOCON format application.json - configuration file in JSON format application.properties - configuration file in Java Properties format Remember that the config system will check for these default meta-config and config files only if the classpath includes the corresponding parsers. The introduction section on built-in formats section describes this further. See javadoc Config.Builder.config(Config) . Meta-configuration File Format This section is now available in config profile format Loading Config using Meta-configuration Here is how your application can use meta-configuration in a particular resource on the classpath to load a Config tree: <markup lang=\"java\" title=\"Loading Config using Meta-configuration\" >Config metaConfig = Config.create(classpath(\"config-meta-all.conf\")); Config config = MetaConfig.config(metaConfig); We create a meta configuration from our meta configuration source This method populates the config sources from all the actual sources declared in the meta-configuration. ",
            "title": "Advanced Config Sources and Config Parsers"
        },
        {
            "location": "/se/config/06_advanced-configuration",
            "text": " As described in the hierarchical features section each config node (except the root) has a non-null key. Here is the formal definition of what keys can be: <markup lang=\"abnf\" title=\"The ABNF syntax of config key\" >config-key = *1( key-token *( \".\" key-token ) ) key-token = *( unescaped / escaped ) unescaped = %x00-2D / %x2F-7D / %x7F-10FFFF ; %x2E ('.') and %x7E ('~') are excluded from 'unescaped' escaped = \"~\" ( \"0\" / \"1\" ) ; representing '~' and '.', respectively Important To emphasize, the dot character (&#8220;.&#8221;) has special meaning as a name separator in keys. To include a dot as a character in a key escape it as &#8220;~1&#8221;. To include a tilda escape it as &#8220;~0&#8221;. For example, the following configuration file contains two object nodes with names oracle and oracle.com . <markup lang=\"json\" title=\"Example application.json with dot character in key\" >{ \"oracle\" : { \"com\" : true, \"cz\" : false }, \"oracle.com\" : { \"secured\" : true } } <markup lang=\"java\" title=\"Working with configuration with dot character in node name\" >Config config = Config.create(classpath(\"application.json\")); // node `oracle` assert config.get(\"oracle.com\").asBoolean().get() == true; assert config.get(\"oracle\").get(\"com\").asBoolean().get() == true; assert config.get(\"oracle.com\").type() == Type.VALUE; assert config.get(\"oracle.com\").name().equals(\"com\"); // node `oracle.com` assert config.get(\"oracle~1com.secured\").asBoolean().get() == true; assert config.get(Key.escapeName(\"oracle.com\")) .get(\"secured\").asBoolean().get() == true; assert config.get(Key.escapeName(\"oracle.com\")).type() == Type.OBJECT; assert config.get(Key.escapeName(\"oracle.com\")).name().equals(\"oracle.com\"); Work with the first oracle object as usual. As always you can use the fully-qualified key oracle.com or chain get(key) calls to access the com property value. Config node \"oracle\" / \"com\" is a leaf node (has type VALUE )&#8230;&#8203; &#8230;&#8203; and has the name com (the last token in its key). The second object has name oracle.com . The code must escape the dot in the node&#8217;s name using oracle~1com . Or, use the utility method Config.Key.escapeName(name) to escape dots or tildes that might be in the node&#8217;s name, in this example in oracle.com . The config node \"oracle.com\" has type OBJECT &#8230;&#8203; &#8230;&#8203;and name \"oracle.com\" . ",
            "title": "Configuration Key"
        },
        {
            "location": "/se/config/06_advanced-configuration",
            "text": " Each filter accepts a key and the value as defined in the source, and returns the value to be used. The filter can leave the value unchanged or alter it, as it sees fit. The built-in value-resolving filter enables the token substitution described below. See the ConfigFilter JavaDoc for more information. ",
            "title": "Filters"
        },
        {
            "location": "/se/config/06_advanced-configuration",
            "text": " The overrides feature allows you to create an external document containing key/value pairs which replace the value otherwise returned for the name, and then add that document as an override source to a config builder. There are some key differences between overrides and filters. Because overrides are loaded from sources those sources can change while your application runs and so the overrides they that prescribe can change. The override document can use wildcards in key expressions. Overrides can affect only keys that already exist in the original source; filters can supply values even if the key is absent from the config source. Each override entry consists of a Java properties-format definition. The key is an expression (which can use wildcards) to match config keys read from the current config sources, and the override value is the new value for any key matching the key expression from that entry. Order is important. The config system tests every key expression/value pair one by one in the order they appear in the overrides sources. Once the config system finds an override entry in which the key expression matches the configuration key, the system returns that entry&#8217;s value for the key being processed. See the OverrideSource JavaDoc for more detail. ",
            "title": "Overrides"
        },
        {
            "location": "/se/config/06_advanced-configuration",
            "text": " A token reference is a key token starting with $ , optionally enclosed between { and } , i.e. $ref , ${ref} . Even a key composed of more than one token can be referenced in another key, i.e. ${env.ref} . As an example use case, you can use token references to declare the default values (see resolving-tokens.yaml below), while the references may be resolved in another config source, which identifies a current environment (see env.yaml examples below). You can then use the same overrides for different environments, say test and prod . The configuration in each environment is then overridden with a different values using wildcards (see overrides.properties below). <markup lang=\"java\" title=\"Initialize Config with Override Definition from overrides.properties file\" >Config config = Config.builder() .overrides(OverrideSources.file(\"conf/overrides.properties\")) .sources(file(\"conf/env.yaml\"), classpath(\"resolving-tokens.yaml\")) .build(); Loads overrides from the specified file. A deployment-specific environment configuration file. A default configuration containing token references that are resolved using the environment-specific override. ",
            "title": "Tokens"
        },
        {
            "location": "/se/config/06_advanced-configuration",
            "text": " When your application retrieves a config value, the config system can transform it before returning the value, according to filters , overrides , and tokens . The config system provides some built-in instances of these you can use, and you can add your own as described in the sections which describe filters and overrides . Your application can add filters and overrides explicitly to a config builder and the config system by default uses the Java service loader mechanism to locate all available filters and overrides and add them automatically to all config builders (unless your code disables that behavior for a given builder). Filters Each filter accepts a key and the value as defined in the source, and returns the value to be used. The filter can leave the value unchanged or alter it, as it sees fit. The built-in value-resolving filter enables the token substitution described below. See the ConfigFilter JavaDoc for more information. Overrides The overrides feature allows you to create an external document containing key/value pairs which replace the value otherwise returned for the name, and then add that document as an override source to a config builder. There are some key differences between overrides and filters. Because overrides are loaded from sources those sources can change while your application runs and so the overrides they that prescribe can change. The override document can use wildcards in key expressions. Overrides can affect only keys that already exist in the original source; filters can supply values even if the key is absent from the config source. Each override entry consists of a Java properties-format definition. The key is an expression (which can use wildcards) to match config keys read from the current config sources, and the override value is the new value for any key matching the key expression from that entry. Order is important. The config system tests every key expression/value pair one by one in the order they appear in the overrides sources. Once the config system finds an override entry in which the key expression matches the configuration key, the system returns that entry&#8217;s value for the key being processed. See the OverrideSource JavaDoc for more detail. Tokens A token reference is a key token starting with $ , optionally enclosed between { and } , i.e. $ref , ${ref} . Even a key composed of more than one token can be referenced in another key, i.e. ${env.ref} . As an example use case, you can use token references to declare the default values (see resolving-tokens.yaml below), while the references may be resolved in another config source, which identifies a current environment (see env.yaml examples below). You can then use the same overrides for different environments, say test and prod . The configuration in each environment is then overridden with a different values using wildcards (see overrides.properties below). <markup lang=\"java\" title=\"Initialize Config with Override Definition from overrides.properties file\" >Config config = Config.builder() .overrides(OverrideSources.file(\"conf/overrides.properties\")) .sources(file(\"conf/env.yaml\"), classpath(\"resolving-tokens.yaml\")) .build(); Loads overrides from the specified file. A deployment-specific environment configuration file. A default configuration containing token references that are resolved using the environment-specific override. ",
            "title": "Filter, Overrides, and Token Substitution"
        },
        {
            "location": "/se/config/06_advanced-configuration",
            "text": " The two methods PollingStrategies.regular(Duration) and PollingStrategies.watch(Path) return builders for their respective strategies. Both builders expose the executor method which your application can invoke, passing a java.util.concurrent.ScheduledExecutorService instance it wants used for the polling work. By default each polling strategy instance uses a separate thread pool executor. The following example shares the same executor for two different polling strategy instances. <markup lang=\"java\" title=\"Customize polling strategy executors\" >ScheduledExecutorService executor = Executors.newScheduledThreadPool(2); Config config = Config.create( ConfigSources.file(\"conf/dev.properties\") .pollingStrategy( PollingStrategies.regular(Duration.ofSeconds(2)) .executor(executor)), ConfigSources.create(\"conf/config.properties\") .pollingStrategy( path -&gt; PollingStrategies.watch(path) .executor(executor))); Prepares a thread pool executor with core pool size set 2 to be shared by all polling strategies. Selects the built-in periodic polling strategy. Tells the config system to use the specific executor to poll the dev.properties config source. Uses the Java filesystem WatchService to monitor the specified path. Tells the config system to use the same executor to monitor the path. ",
            "title": "Executors for Polling Strategy"
        },
        {
            "location": "/se/config/06_advanced-configuration",
            "text": " Recall that when a polling strategy detects a change in a source, it informs interested parties of the changes. By default each Config.Builder arranges for the resulting Config tree to use a shared executor that reuses available threads from a pool, creating new threads as needed. The same executor is used for actually reloading the source. Your application can invoke the polling strategy builder&#8217;s changesExecutor method to tell the builder to use a different Executor . (As an aside, your application can also control the size of the buffer used for holding source change events by invoking the builder&#8217;s changesMaxBuffer method. The default is 256.) <markup lang=\"java\" title=\"Customize config and override sources' executors\" >Executor executor = Executors.newCachedThreadPool(); Config config = Config.builder() .overrides( OverrideSources.file(\"conf/overrides.properties\") .pollingStrategy(PollingStrategies::watch) .changesExecutor(executor) .changesMaxBuffer(4)) .sources( ConfigSources.file(\"conf/env.yaml\") .pollingStrategy(PollingStrategies::watch) .changesExecutor(executor) .changesMaxBuffer(4)) .build(); Prepares a thread pool executor to be shared by selected sources. Tells the builder that the resulting overrides source should use the specified Executor for notifying interested parties of changes and for reloading the override source. Specifies an event buffer size of 4. Uses the same Executor and event buffer size for the config source as for the override source above. ",
            "title": "Publishers for Source Change Events"
        },
        {
            "location": "/se/config/06_advanced-configuration",
            "text": " When your application supplies multiple sources to a config builder, as with Config.create(Supplier&lt;ConfigSource&gt;&#8230;&#8203;) and Config.create(List&lt;Supplier&lt;ConfigSource&gt;&gt;) , the config system automatically uses a composite config source which aggregates the separate sources but also listens for changes to any of the individual sources so it can delegate the change notification. For this change detection and notification the config system, by default, uses an executor with a dedicated thread pool that is shared across all Config instances. Your application can invoke the builder&#8217;s changesExecutor method to use a different ScheduledExecutorService instance. The builder returned by the from methods mentioned above is a CompositeBuilder which extends Config.Builder . Because a composite source might yield more numerous change events&#8201;&#8212;&#8201;because of the multiple underlying sources&#8201;&#8212;&#8201;your application can specify a debounce timeout for the composite source by invoking the CompositeBuilder.changesDebounce(Duration) method. The composite source aggregates multiple change events within this period into a single event and broadcasts that one instead and reloads the sources at that time, not necessarily in response to every single change in any source. The default is 100 milliseconds. <markup lang=\"java\" title=\"Customize composite source executors\" >ScheduledExecutorService executor = Executors.newScheduledThreadPool(1); Config config = Config.create( ConfigSources.create(file(\"conf/dev.properties\") .pollingStrategy(PollingStrategies::watch), file(\"conf/config.properties\") .pollingStrategy(PollingStrategies::watch)) .changesExecutor(executor) .changesMaxBuffer(4) .changesDebounce(Duration.ofSeconds(1))); Prepares a thread pool executor. ConfigSources.create(Supplier&lt;ConfigSource&gt;&#8230;&#8203;) creates and returns a CompositeBuilder based on the two sources. Specifies a particular executor for monitoring and change event notification. Sets the subscriber&#8217;s buffer size to 4 events. The composite source discards any events not consumed by a subscriber if it needs to create room for more recent events. Change events will not fire more frequently than once per a second. ",
            "title": "Composite Config Source Executor"
        },
        {
            "location": "/se/config/06_advanced-configuration",
            "text": " A loaded config tree subscribes to change events publishes by its source(s). By default, each Config uses an executor which manages a dedicated thread pool reusing previously-created threads when they are available and creating new threads as needed. All Config instances share the dedicated thread pool. Your application can specify a non-default Executor for a tree to use for accepting and propagating those events by invoking the changesExecutor method on the Config.Builder . Each source subscriber has a dedicated buffer for holding changes events. This defaults to 256 but you can tailor this value as needed. <markup lang=\"java\" title=\"Customize config executor\" >Executor executor = Executors.newCachedThreadPool(); Config config = Config.create( file(\"conf/config.properties\") .pollingStrategy(PollingStrategies::watch)) .changesExecutor(executor) .changesMaxBuffer(16) .build(); Prepares a specific thread pool executor. Specifies the executor the Config tree will use to listen for and propagate change events. Sets the event subscriber buffer to 16 events. ",
            "title": "Config Custom Executor"
        },
        {
            "location": "/se/config/06_advanced-configuration",
            "text": " You can control which executor a retry policy should use for its work. The RetryPolicies.repeat(int retries) method returns a RetryPolicies.Builder . Your application can invoke the retry policy builder&#8217;s executor method to specify which ScheduledExecutorService instance it should use to schedule and execute delayed retries. By default the config system uses a separate thread pool executor for each retry policy instance. <markup lang=\"java\" title=\"Customize retry policy executors\" >ScheduledExecutorService executor = Executors.newScheduledThreadPool(2, myThreadFactory); Config config = Config.create( ConfigSources.file(\"conf/dev.properties\") .optional() .retryPolicy(RetryPolicies.repeat(2) .executor(executor))); Prepares a thread pool executor with core pool size set to 2 and a custom java.util.concurrent.ThreadFactory . When the source is flagged as optional() , the loading attempt will be repeated as the retry policy defines, but an overall failure will not lead to failing the initial load or preventing the source from being polled if so configured. Uses the built-in repeating implementation of RetryPolicy that can be used with any config source, but typically for ones that might suffer brief, intermittent outages. Specifies the executor to use for loading and retries. ",
            "title": "Retry Policy Custom Executor"
        },
        {
            "location": "/se/config/06_advanced-configuration",
            "text": " Various parts of the config system work asychronously: polling strategies to detect changes to config sources, publishers to notify your application when such changes occur, Config instances which subscribe to and respond to change notifications for their underlying sources, and retry policies (which might wait between retries). Each of these uses an executor to perform its work. The config system provides default executors, but your application can specify different ones if necessary. Executors for Polling Strategy The two methods PollingStrategies.regular(Duration) and PollingStrategies.watch(Path) return builders for their respective strategies. Both builders expose the executor method which your application can invoke, passing a java.util.concurrent.ScheduledExecutorService instance it wants used for the polling work. By default each polling strategy instance uses a separate thread pool executor. The following example shares the same executor for two different polling strategy instances. <markup lang=\"java\" title=\"Customize polling strategy executors\" >ScheduledExecutorService executor = Executors.newScheduledThreadPool(2); Config config = Config.create( ConfigSources.file(\"conf/dev.properties\") .pollingStrategy( PollingStrategies.regular(Duration.ofSeconds(2)) .executor(executor)), ConfigSources.create(\"conf/config.properties\") .pollingStrategy( path -&gt; PollingStrategies.watch(path) .executor(executor))); Prepares a thread pool executor with core pool size set 2 to be shared by all polling strategies. Selects the built-in periodic polling strategy. Tells the config system to use the specific executor to poll the dev.properties config source. Uses the Java filesystem WatchService to monitor the specified path. Tells the config system to use the same executor to monitor the path. Publishers for Source Change Events Recall that when a polling strategy detects a change in a source, it informs interested parties of the changes. By default each Config.Builder arranges for the resulting Config tree to use a shared executor that reuses available threads from a pool, creating new threads as needed. The same executor is used for actually reloading the source. Your application can invoke the polling strategy builder&#8217;s changesExecutor method to tell the builder to use a different Executor . (As an aside, your application can also control the size of the buffer used for holding source change events by invoking the builder&#8217;s changesMaxBuffer method. The default is 256.) <markup lang=\"java\" title=\"Customize config and override sources' executors\" >Executor executor = Executors.newCachedThreadPool(); Config config = Config.builder() .overrides( OverrideSources.file(\"conf/overrides.properties\") .pollingStrategy(PollingStrategies::watch) .changesExecutor(executor) .changesMaxBuffer(4)) .sources( ConfigSources.file(\"conf/env.yaml\") .pollingStrategy(PollingStrategies::watch) .changesExecutor(executor) .changesMaxBuffer(4)) .build(); Prepares a thread pool executor to be shared by selected sources. Tells the builder that the resulting overrides source should use the specified Executor for notifying interested parties of changes and for reloading the override source. Specifies an event buffer size of 4. Uses the same Executor and event buffer size for the config source as for the override source above. Composite Config Source Executor When your application supplies multiple sources to a config builder, as with Config.create(Supplier&lt;ConfigSource&gt;&#8230;&#8203;) and Config.create(List&lt;Supplier&lt;ConfigSource&gt;&gt;) , the config system automatically uses a composite config source which aggregates the separate sources but also listens for changes to any of the individual sources so it can delegate the change notification. For this change detection and notification the config system, by default, uses an executor with a dedicated thread pool that is shared across all Config instances. Your application can invoke the builder&#8217;s changesExecutor method to use a different ScheduledExecutorService instance. The builder returned by the from methods mentioned above is a CompositeBuilder which extends Config.Builder . Because a composite source might yield more numerous change events&#8201;&#8212;&#8201;because of the multiple underlying sources&#8201;&#8212;&#8201;your application can specify a debounce timeout for the composite source by invoking the CompositeBuilder.changesDebounce(Duration) method. The composite source aggregates multiple change events within this period into a single event and broadcasts that one instead and reloads the sources at that time, not necessarily in response to every single change in any source. The default is 100 milliseconds. <markup lang=\"java\" title=\"Customize composite source executors\" >ScheduledExecutorService executor = Executors.newScheduledThreadPool(1); Config config = Config.create( ConfigSources.create(file(\"conf/dev.properties\") .pollingStrategy(PollingStrategies::watch), file(\"conf/config.properties\") .pollingStrategy(PollingStrategies::watch)) .changesExecutor(executor) .changesMaxBuffer(4) .changesDebounce(Duration.ofSeconds(1))); Prepares a thread pool executor. ConfigSources.create(Supplier&lt;ConfigSource&gt;&#8230;&#8203;) creates and returns a CompositeBuilder based on the two sources. Specifies a particular executor for monitoring and change event notification. Sets the subscriber&#8217;s buffer size to 4 events. The composite source discards any events not consumed by a subscriber if it needs to create room for more recent events. Change events will not fire more frequently than once per a second. Config Custom Executor A loaded config tree subscribes to change events publishes by its source(s). By default, each Config uses an executor which manages a dedicated thread pool reusing previously-created threads when they are available and creating new threads as needed. All Config instances share the dedicated thread pool. Your application can specify a non-default Executor for a tree to use for accepting and propagating those events by invoking the changesExecutor method on the Config.Builder . Each source subscriber has a dedicated buffer for holding changes events. This defaults to 256 but you can tailor this value as needed. <markup lang=\"java\" title=\"Customize config executor\" >Executor executor = Executors.newCachedThreadPool(); Config config = Config.create( file(\"conf/config.properties\") .pollingStrategy(PollingStrategies::watch)) .changesExecutor(executor) .changesMaxBuffer(16) .build(); Prepares a specific thread pool executor. Specifies the executor the Config tree will use to listen for and propagate change events. Sets the event subscriber buffer to 16 events. Retry Policy Custom Executor You can control which executor a retry policy should use for its work. The RetryPolicies.repeat(int retries) method returns a RetryPolicies.Builder . Your application can invoke the retry policy builder&#8217;s executor method to specify which ScheduledExecutorService instance it should use to schedule and execute delayed retries. By default the config system uses a separate thread pool executor for each retry policy instance. <markup lang=\"java\" title=\"Customize retry policy executors\" >ScheduledExecutorService executor = Executors.newScheduledThreadPool(2, myThreadFactory); Config config = Config.create( ConfigSources.file(\"conf/dev.properties\") .optional() .retryPolicy(RetryPolicies.repeat(2) .executor(executor))); Prepares a thread pool executor with core pool size set to 2 and a custom java.util.concurrent.ThreadFactory . When the source is flagged as optional() , the loading attempt will be repeated as the retry policy defines, but an overall failure will not lead to failing the initial load or preventing the source from being polled if so configured. Uses the built-in repeating implementation of RetryPolicy that can be used with any config source, but typically for ones that might suffer brief, intermittent outages. Specifies the executor to use for loading and retries. ",
            "title": "Executors for Asynchronous Config Activity"
        },
        {
            "location": "/se/webserver/12_tls-configuration",
            "text": " Configure TLS either programmatically, or by the Helidon configuration framework. ",
            "title": "preambule"
        },
        {
            "location": "/se/webserver/12_tls-configuration",
            "text": " To configure TLS in WebServer programmatically create your keystore configuration and pass it to the WebServer builder. <markup lang=\"java\" >KeyConfig keyConfig = KeyConfig.keystoreBuilder() //Whether this keystore is also trust store .trustStore() //Keystore location/name .keystore(Resource.create(\"keystore.p12\")) //Password to the keystore .keystorePassphrase(\"password\") .build(); WebServer.builder() .tls(WebServerTls.builder() .trust(keyConfig) .privateKey(keyConfig) .build()) .build(); ",
            "title": "Configuring TLS in your code"
        },
        {
            "location": "/se/webserver/12_tls-configuration",
            "text": " It is also possible to configure TLS via the config file. <markup lang=\"yaml\" title=\"WebServer TLS configuration file application.yaml \" >server: tls: #Truststore setup trust: keystore: passphrase: \"password\" trust-store: true resource: resource-path: \"keystore.p12\" #Keystore with private key and server certificate private-key: keystore: passphrase: \"password\" resource: resource-path: \"keystore.p12\" Then, in your application code, load the configuration from that file. <markup lang=\"java\" title=\"WebServer initialization using the application.yaml file located on the classpath\" >Config config = Config.create(); WebServer webClient = WebServer.create(routing, config.get(\"server\")); Or you can only create WebServerTls instance based on the config file. <markup lang=\"java\" title=\"WebServerTls instance based on application.yaml file located on the classpath\" >Config config = Config.create(); WebServerTls.builder() .config(config.get(\"server.tls\")) .build(); This can alternatively be configured with paths to PKCS#8 PEM files rather than KeyStores: <markup lang=\"yaml\" title=\"WebServer TLS configuration file application.yaml \" >server: tls: #Truststore setup trust: pem: certificates: resource: resource-path: \"ca-bundle.pem\" private-key: pem: key: resource: resource-path: \"key.pem\" cert-chain: resource: resource-path: \"chain.pem\" ",
            "title": "Configuring TLS in the config file"
        },
        {
            "location": "/se/webserver/12_tls-configuration",
            "text": " See all configuration options here . Available server certificate configuration options: Configuration key Default value Java type Description client-auth NONE Enum See here for all possible values. Whether to require client certificate authentication protocols &#160; String TLS protocols to enable with the server socket session-cache-size &#160; int The size of the cache used for storing SSL session objects session-timeout-seconds &#160; int The timeout for the cached SSL session objects, in seconds private-key &#160; Object Keystore configuration, please follow the example above trust &#160; Object Keystore configuration, please follow the example above ",
            "title": "Configuration options"
        },
        {
            "location": "/se/webclient/01_introduction",
            "text": " To enable WebClient add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-webclient&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/webclient/01_introduction",
            "text": " WebClient is an HTTP client for Helidon SE 2.0. It handles the responses to the HTTP requests in a reactive way. Helidon WebClient provides the following features: Reactive approach Allows you to execute HTTP requests and handle the responses without having to wait for the server response. When the response is received, the client requests only the amount of data that it can handle at that time. So, there is no overflow of memory. Builder-like setup and execution Creates every client and request as a builder pattern. This improves readability and code maintenance. Redirect chain Follows the redirect chain and perform requests on the correct endpoint by itself. Tracing, metrics and security propagation Automatically propagates the configured tracing, metrics and security settings of the Helidon WebServer to the WebClient and uses them during request and response. ",
            "title": "Overview"
        },
        {
            "location": "/se/webclient/01_introduction",
            "text": "<markup lang=\"java\" >Config config = Config.create(); WebClient client = WebClient.builder() .baseUri(\"http://localhost\") .config(config.get(\"client\")) .build(); ",
            "title": "Example of a WebClient Configuration"
        },
        {
            "location": "/se/webclient/01_introduction",
            "text": "<markup lang=\"java\" >client: connect-timeout-millis: 2000 read-timeout-millis: 2000 follow-redirects: true max-redirects: 5 cookies: automatic-store-enabled: true default-cookies: - name: \"env\" value: \"dev\" headers: - name: \"Accept\" value: [\"application/json\",\"text/plain\"] services: config: metrics: - methods: [\"PUT\", \"POST\", \"DELETE\"] - type: METER name-format: \"client.meter.overall\" - type: TIMER # meter per method name-format: \"client.meter.%1$s\" - methods: [\"GET\"] type: COUNTER errors: false name-format: \"client.counter.%1$s.success\" description: \"Counter of successful GET requests\" - methods: [\"PUT\", \"POST\", \"DELETE\"] type: COUNTER success: false name-format: \"wc.counter.%1$s.error\" description: \"Counter of failed PUT, POST and DELETE requests\" - methods: [\"GET\"] type: GAUGE_IN_PROGRESS name-format: \"client.inprogress.%2$s\" description: \"In progress requests to host\" tracing: proxy: use-system-selector: false host: \"hostName\" port: 80 no-proxy: [\"localhost:8080\", \".helidon.io\", \"192.168.1.1\"] tls: server: trust-all: true disable-hostname-verification: true keystore: passphrase: \"password\" trust-store: true resource: resource-path: \"client.p12\" client: keystore: passphrase: \"password\" resource: resource-path: \"client.p12\" Client functional settings Default client headers and cookies Client service configuration Proxy configuration TLS configuration ",
            "title": "Example of Yaml WebClient Configuration"
        },
        {
            "location": "/se/webclient/01_introduction",
            "text": " The WebClient default configuration may be suitable in most use cases. However, you can configure it to suit your specific requirements. Example of a WebClient Configuration <markup lang=\"java\" >Config config = Config.create(); WebClient client = WebClient.builder() .baseUri(\"http://localhost\") .config(config.get(\"client\")) .build(); Example of Yaml WebClient Configuration <markup lang=\"java\" >client: connect-timeout-millis: 2000 read-timeout-millis: 2000 follow-redirects: true max-redirects: 5 cookies: automatic-store-enabled: true default-cookies: - name: \"env\" value: \"dev\" headers: - name: \"Accept\" value: [\"application/json\",\"text/plain\"] services: config: metrics: - methods: [\"PUT\", \"POST\", \"DELETE\"] - type: METER name-format: \"client.meter.overall\" - type: TIMER # meter per method name-format: \"client.meter.%1$s\" - methods: [\"GET\"] type: COUNTER errors: false name-format: \"client.counter.%1$s.success\" description: \"Counter of successful GET requests\" - methods: [\"PUT\", \"POST\", \"DELETE\"] type: COUNTER success: false name-format: \"wc.counter.%1$s.error\" description: \"Counter of failed PUT, POST and DELETE requests\" - methods: [\"GET\"] type: GAUGE_IN_PROGRESS name-format: \"client.inprogress.%2$s\" description: \"In progress requests to host\" tracing: proxy: use-system-selector: false host: \"hostName\" port: 80 no-proxy: [\"localhost:8080\", \".helidon.io\", \"192.168.1.1\"] tls: server: trust-all: true disable-hostname-verification: true keystore: passphrase: \"password\" trust-store: true resource: resource-path: \"client.p12\" client: keystore: passphrase: \"password\" resource: resource-path: \"client.p12\" Client functional settings Default client headers and cookies Client service configuration Proxy configuration TLS configuration ",
            "title": "Configuring the WebClient"
        },
        {
            "location": "/se/webclient/01_introduction",
            "text": "<markup lang=\"java\" title=\"Create a WebClient with simple builder:\" >WebClient client = WebClient.builder() .baseUri(\"http://localhost\") .build(); ",
            "title": "Example"
        },
        {
            "location": "/se/webclient/01_introduction",
            "text": " You can create WebClient by executing WebClient.create() method. This will create an instance of client with default settings and without a base uri set. To change the default settings and register additional services, you can use simple builder that allows you to customize the client behavior. Example <markup lang=\"java\" title=\"Create a WebClient with simple builder:\" >WebClient client = WebClient.builder() .baseUri(\"http://localhost\") .build(); ",
            "title": "Creating the WebClient"
        },
        {
            "location": "/se/webclient/01_introduction",
            "text": "<markup lang=\"java\" title=\"Execute a simple GET request to endpoint:\" >Single&lt;String&gt; response = client.get() .path(\"/endpoint\") .request(String.class); ",
            "title": "Example"
        },
        {
            "location": "/se/webclient/01_introduction",
            "text": " The request settings are based on the following optional parameters, and change when a specific request is executed. Parameter Description uri(\"http://example.com\") Overrides baseUri from WebClient path(\"/path\") Adds path to the uri queryParam(\"query\", \"parameter\") Adds query parameter to the request fragment(\"someFragment\") Adds fragment to the request headers(headers &#8594; headers.addAccept(MediaType.APPLICATION_JSON)) Adds header to the request WebClientRequestBuilder class also provides specific header methods that help the user to set a particular header. The methods are: contentType (MediaType contentType) accept (MediaType&#8230;&#8203; mediaTypes) For more details, see the Request Headers API. ",
            "title": "Request Configuration"
        },
        {
            "location": "/se/webclient/01_introduction",
            "text": " WebClient executes requests to the target endpoints and returns specific response type. It offers variety of methods to specify the type of request you want to execute: put() get() method(String methodName) These methods set specific request type based on their name or parameter to the new instance of WebClientRequesBuilder and return this instance based on configurations for specific request type. You can set configuration for every request type before it is sent as described in . For the final execution, use the following methods with variations and different parameters: Single&lt;T&gt; submit(Object entity, Class&lt;T&gt; responseType) Single&lt;T&gt; request(Class&lt;T&gt; responseType) Example <markup lang=\"java\" title=\"Execute a simple GET request to endpoint:\" >Single&lt;String&gt; response = client.get() .path(\"/endpoint\") .request(String.class); Request Configuration The request settings are based on the following optional parameters, and change when a specific request is executed. Parameter Description uri(\"http://example.com\") Overrides baseUri from WebClient path(\"/path\") Adds path to the uri queryParam(\"query\", \"parameter\") Adds query parameter to the request fragment(\"someFragment\") Adds fragment to the request headers(headers &#8594; headers.addAccept(MediaType.APPLICATION_JSON)) Adds header to the request WebClientRequestBuilder class also provides specific header methods that help the user to set a particular header. The methods are: contentType (MediaType contentType) accept (MediaType&#8230;&#8203; mediaTypes) For more details, see the Request Headers API. ",
            "title": "Creating and Executing the WebClient Request"
        },
        {
            "location": "/se/webclient/01_introduction",
            "text": "<markup lang=\"java\" title=\"Register JSON-P support to the WebClient.\" >WebClient.builder() .baseUri(\"http://localhost\") .addReader(JsonpSupport.reader()) .addWriter(JsonpSupport.writer()) .addMediaService(JsonpSupport.create()) .build(); Adds JSON-P reader to all client requests. Adds JSON-P writer to all client requests. Adds JSON-P writer and reader to all client requests. <markup lang=\"java\" title=\"Register JSON-P support only to the specific request.\" >WebClient webClient = WebClient.create(); WebClientRequestBuilder requestBuilder = webClient.get(); requestBuilder.writerContext().registerWriter(JsonSupport.writer()); requestBuilder.readerContext().registerReader(JsonSupport.reader()); requestBuilder.request(JsonObject.class) Adds JSON-P writer only to this request. Adds JSON-P reader only to this request. ",
            "title": "Example"
        },
        {
            "location": "/se/webclient/01_introduction",
            "text": " JSON Processing (JSON-P) media support is not present in the WebClient by default. So, in this case, you must first register it before making a request. This example shows how to register JsonpSupport using the following two methods. Example <markup lang=\"java\" title=\"Register JSON-P support to the WebClient.\" >WebClient.builder() .baseUri(\"http://localhost\") .addReader(JsonpSupport.reader()) .addWriter(JsonpSupport.writer()) .addMediaService(JsonpSupport.create()) .build(); Adds JSON-P reader to all client requests. Adds JSON-P writer to all client requests. Adds JSON-P writer and reader to all client requests. <markup lang=\"java\" title=\"Register JSON-P support only to the specific request.\" >WebClient webClient = WebClient.create(); WebClientRequestBuilder requestBuilder = webClient.get(); requestBuilder.writerContext().registerWriter(JsonSupport.writer()); requestBuilder.readerContext().registerReader(JsonSupport.reader()); requestBuilder.request(JsonObject.class) Adds JSON-P writer only to this request. Adds JSON-P reader only to this request. ",
            "title": "Adding JSON Processing Media Support to the WebClient"
        },
        {
            "location": "/mp/guides/03_config",
            "text": " This guide describes how to create a sample MicroProfile (MP) project that can be used to run some basic examples using both default and custom configuration with Helidon MP. ",
            "title": "preambule"
        },
        {
            "location": "/mp/guides/03_config",
            "text": " For this 20 minute tutorial, you will need the following: <div class=\"table__overflow elevation-1 flex sm7 \"> A Helidon {upper-case-flavor} Application You can use your own application or use the Helidon {upper-case-flavor} Quickstart to create a sample application. Java&#160;SE&#160;11 ( Open&#160;JDK&#160;11 ) Helidon requires Java 11+. Maven 3.6.1+ Helidon requires Maven 3.6.1+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop ). <markup lang=\"bash\" title=\"Verify Prerequisites\" >java -version mvn --version docker --version kubectl version --short <markup lang=\"bash\" title=\"Setting JAVA_HOME\" ># On Mac export JAVA_HOME=`/usr/libexec/java_home -v 11` # On Linux # Use the appropriate path to your JDK export JAVA_HOME=/usr/lib/jvm/jdk-11 ",
            "title": "What You Need"
        },
        {
            "location": "/mp/guides/03_config",
            "text": " Use the Helidon MP Maven archetype to create a simple project that can be used for the examples in this guide. <markup lang=\"bash\" title=\"Run the Maven archetype:\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-mp \\ -DarchetypeVersion=2.5.4 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-mp \\ -Dpackage=io.helidon.examples.quickstart.mp <markup lang=\"bash\" title=\"The project will be built and run from the helidon-quickstart-mp directory:\" >cd helidon-quickstart-mp ",
            "title": "Create a Sample Helidon MP Project"
        },
        {
            "location": "/mp/guides/03_config",
            "text": " Helidon has an internal configuration, so you are not required to provide any configuration data for your application, though in practice you most likely would. By default, that configuration can be overridden from three sources: system properties, environment variables, and the contents of META-INF/microprofile-config.properties . For example, if you specify a custom server port in META-INF/microprofile-config.properties then your server will listen on that port. A main class is also required to start up the server and run the application. By default the Quickstart sample project uses the built-in Helidon main class. In this guide you want to use your own main class so you have more control over the server initialization. First define your own Main : <markup lang=\"java\" title=\"src/main/java/io/helidon/examples/quickstart/mp/Main.java\" >package io.helidon.examples.quickstart.mp; import io.helidon.microprofile.server.Server; import java.io.IOException; public final class Main { private Main() { } public static void main(final String[] args) throws IOException { Server server = startServer(); System.out.println(\"http://localhost:\" + server.port() + \"/greet\"); } static Server startServer() { return Server.create().start(); } } In this class, a main method is defined which starts the Helidon MP server and prints out a message with the listen address. Notice that this class has an empty no-args constructor to make sure this class cannot be instantiated. The MicroProfile server is started with the default configuration. Next change the project&#8217;s pom.xml to use your main class: <markup lang=\"xml\" title=\"pom.xml\" > &lt;properties&gt; &lt;mainClass&gt;io.helidon.examples.quickstart.mp.Main&lt;/mainClass&gt; &lt;/properties&gt; This property will be used to set the Main-Class attribute in the application jar&#8217;s MANIFEST. In your application code, Helidon uses the default configuration when you create a Server object without a custom Config object. See the following code from the project you created. <markup lang=\"Java\" title=\"View Main.startServer :\" > static Server startServer() { return Server.create().start(); } There is no Config object being used during server creation, so the default configuration is used. ",
            "title": "Default Configuration"
        },
        {
            "location": "/mp/guides/03_config",
            "text": " An environment variable has a higher precedence than the configuration properties file. <markup lang=\"bash\" title=\"Set the environment variable and restart the application:\" >export APP_GREETING=HelloFromEnvironment java -jar target/helidon-quickstart-mp.jar <markup lang=\"bash\" title=\"Invoke the endpoint below and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFromEnvironment World!\" } The environment variable took precedence over the value in META-INF/microprofile-config.properties . ",
            "title": "Environment Variable Override"
        },
        {
            "location": "/mp/guides/03_config",
            "text": " A system property has a higher precedence than environment variables. <markup lang=\"bash\" title=\"Restart the application with a system property. The app.greeting environment variable is still set:\" >java -Dapp.greeting=\"HelloFromSystemProperty\" -jar target/helidon-quickstart-mp.jar <markup lang=\"bash\" title=\"Invoke the endpoint below and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFromSystemProperty World!\" } The system property took precedence over both the environment variable and META-INF/microprofile-config.properties . ",
            "title": "System Property Override"
        },
        {
            "location": "/mp/guides/03_config",
            "text": " Change a configuration parameter in the default configuration resource file, META-INF/microprofile-config.properties . There are no environment variable or system property overrides defined. <markup lang=\"bash\" title=\"Change app.greeting in the META-INF/microprofile-config.properties from Hello to HelloFromMPConfig :\" >app.greeting=HelloFromMPConfig <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-mp.jar <markup lang=\"bash\" title=\"Run the curl command in a new terminal window and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFromMPConfig World!\" } The new app.greeting value in META-INF/microprofile-config.properties is used. Environment Variable Override An environment variable has a higher precedence than the configuration properties file. <markup lang=\"bash\" title=\"Set the environment variable and restart the application:\" >export APP_GREETING=HelloFromEnvironment java -jar target/helidon-quickstart-mp.jar <markup lang=\"bash\" title=\"Invoke the endpoint below and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFromEnvironment World!\" } The environment variable took precedence over the value in META-INF/microprofile-config.properties . System Property Override A system property has a higher precedence than environment variables. <markup lang=\"bash\" title=\"Restart the application with a system property. The app.greeting environment variable is still set:\" >java -Dapp.greeting=\"HelloFromSystemProperty\" -jar target/helidon-quickstart-mp.jar <markup lang=\"bash\" title=\"Invoke the endpoint below and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFromSystemProperty World!\" } The system property took precedence over both the environment variable and META-INF/microprofile-config.properties . ",
            "title": "Default Configuration Resource"
        },
        {
            "location": "/mp/guides/03_config",
            "text": " In order to properly configure your application using configuration sources, you need to understand the precedence rules that Helidon uses to merge your configuration data. By default, Helidon will use the following sources in precedence order: Java system properties Environment variables Properties specified in META-INF/microprofile-config.properties Each of these sources specify configuration properties in Java Property format (key/value), like color=red . If any of the Helidon required properties are not specified in one of these source, like server.port , then Helidon will use a default value. Because environment variable names are restricted to alphanumeric characters and underscores, Helidon adds aliases to the environment configuration source, allowing entries with dotted and/or hyphenated keys to be overriden. For example, this mapping allows an environment variable named \"APP_GREETING\" to override an entry key named \"app.greeting\". In the same way, an environment variable named \"APP_dash_GREETING\" will map to \"app-greeting\". See Advanced Configuration for more information. The following examples will demonstrate the default precedence order. Default Configuration Resource Change a configuration parameter in the default configuration resource file, META-INF/microprofile-config.properties . There are no environment variable or system property overrides defined. <markup lang=\"bash\" title=\"Change app.greeting in the META-INF/microprofile-config.properties from Hello to HelloFromMPConfig :\" >app.greeting=HelloFromMPConfig <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-mp.jar <markup lang=\"bash\" title=\"Run the curl command in a new terminal window and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFromMPConfig World!\" } The new app.greeting value in META-INF/microprofile-config.properties is used. Environment Variable Override An environment variable has a higher precedence than the configuration properties file. <markup lang=\"bash\" title=\"Set the environment variable and restart the application:\" >export APP_GREETING=HelloFromEnvironment java -jar target/helidon-quickstart-mp.jar <markup lang=\"bash\" title=\"Invoke the endpoint below and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFromEnvironment World!\" } The environment variable took precedence over the value in META-INF/microprofile-config.properties . System Property Override A system property has a higher precedence than environment variables. <markup lang=\"bash\" title=\"Restart the application with a system property. The app.greeting environment variable is still set:\" >java -Dapp.greeting=\"HelloFromSystemProperty\" -jar target/helidon-quickstart-mp.jar <markup lang=\"bash\" title=\"Invoke the endpoint below and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFromSystemProperty World!\" } The system property took precedence over both the environment variable and META-INF/microprofile-config.properties . ",
            "title": "Source Precedence for Default Configuration"
        },
        {
            "location": "/mp/guides/03_config",
            "text": " Helidon provides a very flexible and comprehensive configuration system, offering you many application configuration choices. You can include configuration data from a variety of sources using different formats, like JSON and YAML. Furthermore, you can customize the precedence of sources and make them optional or mandatory. This guide introduces Helidon MP configuration and demonstrates the fundamental concepts using several examples. Refer to Helidon Config for the full configuration concepts documentation. Create a Sample Helidon MP Project Use the Helidon MP Maven archetype to create a simple project that can be used for the examples in this guide. <markup lang=\"bash\" title=\"Run the Maven archetype:\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-mp \\ -DarchetypeVersion=2.5.4 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-mp \\ -Dpackage=io.helidon.examples.quickstart.mp <markup lang=\"bash\" title=\"The project will be built and run from the helidon-quickstart-mp directory:\" >cd helidon-quickstart-mp Default Configuration Helidon has an internal configuration, so you are not required to provide any configuration data for your application, though in practice you most likely would. By default, that configuration can be overridden from three sources: system properties, environment variables, and the contents of META-INF/microprofile-config.properties . For example, if you specify a custom server port in META-INF/microprofile-config.properties then your server will listen on that port. A main class is also required to start up the server and run the application. By default the Quickstart sample project uses the built-in Helidon main class. In this guide you want to use your own main class so you have more control over the server initialization. First define your own Main : <markup lang=\"java\" title=\"src/main/java/io/helidon/examples/quickstart/mp/Main.java\" >package io.helidon.examples.quickstart.mp; import io.helidon.microprofile.server.Server; import java.io.IOException; public final class Main { private Main() { } public static void main(final String[] args) throws IOException { Server server = startServer(); System.out.println(\"http://localhost:\" + server.port() + \"/greet\"); } static Server startServer() { return Server.create().start(); } } In this class, a main method is defined which starts the Helidon MP server and prints out a message with the listen address. Notice that this class has an empty no-args constructor to make sure this class cannot be instantiated. The MicroProfile server is started with the default configuration. Next change the project&#8217;s pom.xml to use your main class: <markup lang=\"xml\" title=\"pom.xml\" > &lt;properties&gt; &lt;mainClass&gt;io.helidon.examples.quickstart.mp.Main&lt;/mainClass&gt; &lt;/properties&gt; This property will be used to set the Main-Class attribute in the application jar&#8217;s MANIFEST. In your application code, Helidon uses the default configuration when you create a Server object without a custom Config object. See the following code from the project you created. <markup lang=\"Java\" title=\"View Main.startServer :\" > static Server startServer() { return Server.create().start(); } There is no Config object being used during server creation, so the default configuration is used. Source Precedence for Default Configuration In order to properly configure your application using configuration sources, you need to understand the precedence rules that Helidon uses to merge your configuration data. By default, Helidon will use the following sources in precedence order: Java system properties Environment variables Properties specified in META-INF/microprofile-config.properties Each of these sources specify configuration properties in Java Property format (key/value), like color=red . If any of the Helidon required properties are not specified in one of these source, like server.port , then Helidon will use a default value. Because environment variable names are restricted to alphanumeric characters and underscores, Helidon adds aliases to the environment configuration source, allowing entries with dotted and/or hyphenated keys to be overriden. For example, this mapping allows an environment variable named \"APP_GREETING\" to override an entry key named \"app.greeting\". In the same way, an environment variable named \"APP_dash_GREETING\" will map to \"app-greeting\". See Advanced Configuration for more information. The following examples will demonstrate the default precedence order. Default Configuration Resource Change a configuration parameter in the default configuration resource file, META-INF/microprofile-config.properties . There are no environment variable or system property overrides defined. <markup lang=\"bash\" title=\"Change app.greeting in the META-INF/microprofile-config.properties from Hello to HelloFromMPConfig :\" >app.greeting=HelloFromMPConfig <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-mp.jar <markup lang=\"bash\" title=\"Run the curl command in a new terminal window and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFromMPConfig World!\" } The new app.greeting value in META-INF/microprofile-config.properties is used. Environment Variable Override An environment variable has a higher precedence than the configuration properties file. <markup lang=\"bash\" title=\"Set the environment variable and restart the application:\" >export APP_GREETING=HelloFromEnvironment java -jar target/helidon-quickstart-mp.jar <markup lang=\"bash\" title=\"Invoke the endpoint below and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFromEnvironment World!\" } The environment variable took precedence over the value in META-INF/microprofile-config.properties . System Property Override A system property has a higher precedence than environment variables. <markup lang=\"bash\" title=\"Restart the application with a system property. The app.greeting environment variable is still set:\" >java -Dapp.greeting=\"HelloFromSystemProperty\" -jar target/helidon-quickstart-mp.jar <markup lang=\"bash\" title=\"Invoke the endpoint below and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFromSystemProperty World!\" } The system property took precedence over both the environment variable and META-INF/microprofile-config.properties . ",
            "title": "Getting Started with Configuration"
        },
        {
            "location": "/mp/guides/03_config",
            "text": " You can inject configuration at the field level as shown below. Use the volatile keyword since you cannot use AtomicReference with field level injection. <markup lang=\"yaml\" title=\"Update the meta-config.yaml with the following contents:\" >sources: - type: \"classpath\" properties: resource: \"META-INF/microprofile-config.properties\" This example only uses the default classpath source. <markup lang=\"java\" title=\"Update the following code from GreetingProvider.java :\" >@ApplicationScoped public class GreetingProvider { @Inject @ConfigProperty(name = \"app.greeting\") private volatile String message; String getMessage() { return message; } void setMessage(String message) { this.message = message; } } Inject the value of app.greeting into the GreetingProvider object. Define a class member variable to hold the greeting. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFromMPConfig World!\" } ",
            "title": "Injecting at Field Level"
        },
        {
            "location": "/mp/guides/03_config",
            "text": " You can inject the Config object into the class and access it directly as shown below. <markup lang=\"java\" title=\"Update the GreetingProvider.java file; 1) Add new imports and 2) Replace the GreetingProvider class:\" > import io.helidon.config.Config; import javax.enterprise.context.Initialized; import javax.enterprise.event.Observes; ... @ApplicationScoped public class GreetingProvider { private final AtomicReference&lt;String&gt; message = new AtomicReference&lt;&gt;(); @Inject public GreetingProvider(Config config) { String message = config.get(\"app.greeting\").asString().get(); this.message.set(message); } String getMessage() { return message.get(); } void setMessage(String message) { this.message.set(message); } } Add three new imports. Inject the Config object into the GreetingProvider object. Get the app.greeting value from the Config object and set the member variable. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFromMPConfig World!\" } ",
            "title": "Injecting the Config Object"
        },
        {
            "location": "/mp/guides/03_config",
            "text": " Helidon offers a variety of methods to access in-memory configuration. These can be categorized as key access or tree navigation . You have been using key access for all of the examples to this point. For example app.greeting is accessing the greeting child node of the app parent node. There are many options for access this data using navigation methods as described in Hierarchical Configuration and Advanced Configuration . This simple example below demonstrates how to access a child node as a detached configuration sub-tree. <markup lang=\"yaml\" title=\"Create a file config-file.yaml in the helidon-quickstart-mp directory and add the following contents:\" >app: greeting: sender: Joe message: Hello-from-config-file.yaml <markup lang=\"yaml\" title=\"Update the meta-config.yaml with the following contents:\" >sources: - type: \"classpath\" properties: resource: \"META-INF/microprofile-config.properties\" - type: \"file\" properties: path: \"./config-file.yaml\" <markup lang=\"java\" title=\"Replace GreetingProvider class with the following code:\" >@ApplicationScoped public class GreetingProvider { private final AtomicReference&lt;String&gt; message = new AtomicReference&lt;&gt;(); private final AtomicReference&lt;String&gt; sender = new AtomicReference&lt;&gt;(); @Inject Config config; public void onStartUp(@Observes @Initialized(ApplicationScoped.class) Object init) { Config appNode = config.get(\"app.greeting\"); message.set(appNode.get(\"message\").asString().get()); sender.set(appNode.get(\"sender\").asString().get()); } String getMessage() { return sender.get() + \" says \" + message.get(); } void setMessage(String message) { this.message.set(message); } } Get the configuration subtree where the app.greeting node is the root. Get the value from the message Config node. Get the value from the sender Config node. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"Joe says Hello-from-config-file.yaml World!\" } ",
            "title": "Navigating the Config Tree"
        },
        {
            "location": "/mp/guides/03_config",
            "text": " You have used Helidon to customize configuration behavior from your code using the Config and Config.Builder classes. The examples in this section will demonstrate how to access that config data at runtime. As discussed previously, Helidon reads configuration from a config source, which uses a config parser to translate the source into an immutable in-memory tree representing the configuration’s structure and values. Your application uses the Config object to access the in-memory tree, retrieving config data. The generated project already accesses configuration data in the GreetingProvider class as follows: <markup lang=\"java\" title=\"View the following code from GreetingProvider.java :\" >@ApplicationScoped public class GreetingProvider { private final AtomicReference&lt;String&gt; message = new AtomicReference&lt;&gt;(); @Inject public GreetingProvider(@ConfigProperty(name = \"app.greeting\") String message) { this.message.set(message); } String getMessage() { return message.get(); } void setMessage(String message) { this.message.set(message); } } This class is application scoped so a single instance of GreetingProvider will be shared across the entire application. Define a thread-safe reference that will refer to the message member variable. The value of the configuration property app.greeting is injected into the GreetingProvider . constructor as a String parameter named message . Injecting at Field Level You can inject configuration at the field level as shown below. Use the volatile keyword since you cannot use AtomicReference with field level injection. <markup lang=\"yaml\" title=\"Update the meta-config.yaml with the following contents:\" >sources: - type: \"classpath\" properties: resource: \"META-INF/microprofile-config.properties\" This example only uses the default classpath source. <markup lang=\"java\" title=\"Update the following code from GreetingProvider.java :\" >@ApplicationScoped public class GreetingProvider { @Inject @ConfigProperty(name = \"app.greeting\") private volatile String message; String getMessage() { return message; } void setMessage(String message) { this.message = message; } } Inject the value of app.greeting into the GreetingProvider object. Define a class member variable to hold the greeting. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFromMPConfig World!\" } Injecting the Config Object You can inject the Config object into the class and access it directly as shown below. <markup lang=\"java\" title=\"Update the GreetingProvider.java file; 1) Add new imports and 2) Replace the GreetingProvider class:\" > import io.helidon.config.Config; import javax.enterprise.context.Initialized; import javax.enterprise.event.Observes; ... @ApplicationScoped public class GreetingProvider { private final AtomicReference&lt;String&gt; message = new AtomicReference&lt;&gt;(); @Inject public GreetingProvider(Config config) { String message = config.get(\"app.greeting\").asString().get(); this.message.set(message); } String getMessage() { return message.get(); } void setMessage(String message) { this.message.set(message); } } Add three new imports. Inject the Config object into the GreetingProvider object. Get the app.greeting value from the Config object and set the member variable. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFromMPConfig World!\" } Navigating the Config Tree Helidon offers a variety of methods to access in-memory configuration. These can be categorized as key access or tree navigation . You have been using key access for all of the examples to this point. For example app.greeting is accessing the greeting child node of the app parent node. There are many options for access this data using navigation methods as described in Hierarchical Configuration and Advanced Configuration . This simple example below demonstrates how to access a child node as a detached configuration sub-tree. <markup lang=\"yaml\" title=\"Create a file config-file.yaml in the helidon-quickstart-mp directory and add the following contents:\" >app: greeting: sender: Joe message: Hello-from-config-file.yaml <markup lang=\"yaml\" title=\"Update the meta-config.yaml with the following contents:\" >sources: - type: \"classpath\" properties: resource: \"META-INF/microprofile-config.properties\" - type: \"file\" properties: path: \"./config-file.yaml\" <markup lang=\"java\" title=\"Replace GreetingProvider class with the following code:\" >@ApplicationScoped public class GreetingProvider { private final AtomicReference&lt;String&gt; message = new AtomicReference&lt;&gt;(); private final AtomicReference&lt;String&gt; sender = new AtomicReference&lt;&gt;(); @Inject Config config; public void onStartUp(@Observes @Initialized(ApplicationScoped.class) Object init) { Config appNode = config.get(\"app.greeting\"); message.set(appNode.get(\"message\").asString().get()); sender.set(appNode.get(\"sender\").asString().get()); } String getMessage() { return sender.get() + \" says \" + message.get(); } void setMessage(String message) { this.message.set(message); } } Get the configuration subtree where the app.greeting node is the root. Get the value from the message Config node. Get the value from the sender Config node. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"Joe says Hello-from-config-file.yaml World!\" } ",
            "title": "Accessing Config within an Application"
        },
        {
            "location": "/mp/guides/03_config",
            "text": " The following example uses a Kubernetes ConfigMap to pass the configuration data to your Helidon application deployed to Kubernetes. When the pod is created, Kubernetes will automatically create a local file within the container that has the contents of the configuration file used for the ConfigMap. This example will create the file at /etc/config/config-file.properties . <markup lang=\"java\" title=\"Update the Main class and replace the buildConfig method:\" > private static Config buildConfig() { return Config.builder() .sources( file(\"/etc/config/config-file.properties\").optional(), classpath(\"META-INF/microprofile-config.properties\")) .build(); } The app.greeting value will be fetched from /etc/config/config-file.properties within the container. The server port is specified in META-INF/microprofile-config.properties within the helidon-quickstart-mp.jar . <markup lang=\"java\" title=\"Update the following code from GreetingProvider.java :\" >@ApplicationScoped public class GreetingProvider { @Inject @ConfigProperty(name = \"app.greeting\") private volatile String message; String getMessage() { return message; } void setMessage(String message) { this.message = message; } } <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFromConfigFile World!\" } <markup lang=\"bash\" title=\"Stop the application and build the docker image:\" >docker build -t helidon-config-mp . <markup lang=\"bash\" title=\"Generate a ConfigMap from config-file.properties :\" >kubectl create configmap helidon-configmap --from-file config-file.properties <markup lang=\"bash\" title=\"View the contents of the ConfigMap:\" >kubectl get configmap helidon-configmap -o yaml ... apiVersion: v1 data: config-file.properties: | app.greeting=HelloFromConfigFile kind: ConfigMap ... The file config-file.properties will be created within the Kubernetes container. The config-file.properties file will have this single property defined. <markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named k8s-config.yaml , with the following contents:\" >kind: Service apiVersion: v1 metadata: name: helidon-config labels: app: helidon-config spec: type: NodePort selector: app: helidon-config ports: - port: 8080 targetPort: 8080 name: http --- kind: Deployment apiVersion: apps/v1 metadata: name: helidon-config spec: replicas: 1 selector: matchLabels: app: helidon-config template: metadata: labels: app: helidon-config version: v1 spec: containers: - name: helidon-config image: helidon-config-mp imagePullPolicy: IfNotPresent ports: - containerPort: 8080 volumeMounts: - name: config-volume mountPath: /etc/config volumes: - name: config-volume configMap: # Provide the name of the ConfigMap containing the files you want # to add to the container name: helidon-configmap A service of type NodePort that serves the default routes on port 8080 . A deployment with one replica of a pod. Mount the ConfigMap as a volume at /etc/config . This is where Kubernetes will create config-file.properties . Specify the ConfigMap which contains the configuration data. <markup lang=\"bash\" title=\"Create and deploy the application into Kubernetes:\" >kubectl apply -f ./k8s-config.yaml <markup lang=\"bash\" title=\"Get the service information:\" >kubectl get service/helidon-config <markup lang=\"bash\" >NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE helidon-config NodePort 10.99.159.2 &lt;none&gt; 8080:31143/TCP 8s A service of type NodePort that serves the default routes on port 31143 . <markup lang=\"bash\" title=\"Verify the configuration endpoint using port 31143 , your port will likely be different:\" >curl http://localhost:31143/greet ... { \"message\": \"HelloFromConfigFile World!\" } The greeting value from /etc/config/config-file.properties within the container was used. You can now delete the Kubernetes resources that were just created during this example. <markup lang=\"bash\" title=\"Delete the Kubernetes resources:\" >kubectl delete -f ./k8s-config.yaml kubectl delete configmap helidon-configmap ",
            "title": "Integration with Kubernetes"
        },
        {
            "location": "/mp/guides/03_config",
            "text": " This guide has demonstrated how to use basic Helidon configuration features. For more information about using the advanced Helidon configuration features, including mutability support and extensions, see Helidon Configuration . Refer to the following references for additional information: MicroProfile Config specification at https://github.com/eclipse/microprofile-config/releases/tag/1.3 MicroProfile Config Javadoc at https://javadoc.io/doc/org.eclipse.microprofile.config/microprofile-config-api/1.3 Helidon Javadoc at https://helidon.io/docs/latest/apidocs/index.html?overview-summary.html ",
            "title": "Summary"
        },
        {
            "location": "/mp/guides/26_gradle_build",
            "text": " This guide describes Helidon&#8217;s support for Gradle projects. ",
            "title": "preambule"
        },
        {
            "location": "/mp/guides/26_gradle_build",
            "text": " While most of Helidon&#8217;s examples use Maven, you can also use Helidon with a Gradle project. We recommend Gradle 6+. ",
            "title": "Introduction"
        },
        {
            "location": "/mp/guides/26_gradle_build",
            "text": " The Helidon Quickstart Example contains a build.gradle file that you can use as an example for building your Helidon application using Gradle. ",
            "title": "Gradle Example"
        },
        {
            "location": "/mp/guides/26_gradle_build",
            "text": " Gradle supports using a Maven POM to perform dependency management. You can use the Helidon Dependencies POM for this purpose. Once you import the Helidon dependency management POM you can specify dependencies without providing a version. <markup lang=\"xml\" title=\"Using the Helidon Dependencies POM\" >dependencies { // import Helidon dependency management implementation platform(\"io.helidon:helidon-dependencies:${project.helidonversion}\") implementation 'io.helidon.microprofile.bundles:helidon-microprofile' implementation 'org.glassfish.jersey.media:jersey-media-json-binding' runtimeOnly 'org.jboss:jandex' runtimeOnly 'javax.activation:javax.activation-api' testCompileOnly 'org.junit.jupiter:junit-jupiter-api:' } ",
            "title": "Dependency Management"
        },
        {
            "location": "/mp/grpc/01_mp_server_side_services",
            "text": " The gRPC Microprofile APIs are an extension to Helidon MP to allow building of gRPC services and clients that integrate with the Microprofile APIs. Using Helidon gRPC MP makes building gRPC services and clients an easier process that the traditional approach using Protobuf files and code generation. Services can be built using POJOs that are then discovered and deployed at runtime in the same way the Helidon MP discovers and deploys web resources in the MP http server. Building gRPC services using Helidon gRPC MP is very simple and allows the developer to concentrate on their application logic without needing to write a lot of boilerplate gRPC code. ",
            "title": "preambule"
        },
        {
            "location": "/mp/grpc/01_mp_server_side_services",
            "text": " To enable gRPC MicroProfile Server add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.grpc&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-grpc-server&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/grpc/01_mp_server_side_services",
            "text": " By default when a class is annotated with Grpc the class name will be used as the gRPC service name. So in the example above the service name will be StringService . This can be change by supplying a name to the annotation. <markup lang=\"java\" >@ApplicationScoped @io.helidon.microprofile.grpc.core.Grpc(name=\"Strings\") public class StringService { in the example above the name of the deployed service will be Strings . ",
            "title": "Service Name"
        },
        {
            "location": "/mp/grpc/01_mp_server_side_services",
            "text": " The traditional approach to building Java gRPC services is to write Protobuf files describing the service and then use these to generate service stubs and finally implementing the service methods by extending the generated stub classes. Using Helidon gRPC MP you just need to write an annotated service implementation class that is just a normal POJO. For example: <markup lang=\"java\" title=\"Simple gRPC Service\" >@ApplicationScoped @io.helidon.microprofile.grpc.core.Grpc public class StringService { @io.helidon.microprofile.grpc.core.Unary public String upper(String s) { return s == null ? null : s.toUpperCase(); } } The code above is a simple service with a single unary method that just converts a String to uppercase. The important parts in the example are the @ApplicationScoped , @Grpc and @Unary annotations; these, along with other annotations discussed later, allow the gRPC MP APIs to discover, configure and deploy the service. Of course Helidon gRPC MP does not preclude you from using the Protobuf files approach, traditional gRPC Java services also work in a gRPC MP server. As already shown above a Helidon gRPC MP service is just an annotated POJO. To make a class a service it requires two annotations. <markup lang=\"java\" >@ApplicationScoped @io.helidon.microprofile.grpc.core.Grpc public class StringService { The ApplicationScoped annotation is what makes the service implementation a CDI bean and hence discoverable. The Grpc annotation is what defines the class as a gRPC service so that when the bean is discovered it is then deployed by the gRPC MP server. Service Name By default when a class is annotated with Grpc the class name will be used as the gRPC service name. So in the example above the service name will be StringService . This can be change by supplying a name to the annotation. <markup lang=\"java\" >@ApplicationScoped @io.helidon.microprofile.grpc.core.Grpc(name=\"Strings\") public class StringService { in the example above the name of the deployed service will be Strings . ",
            "title": "Defining a Service"
        },
        {
            "location": "/mp/grpc/01_mp_server_side_services",
            "text": " A gRPC service method typically takes a request parameter and returns a response value (streaming methods may take or return multiple requests or responses). In traditional gRPC Java the types used for the request and response values must be Protobuf serializable classes but this is not the case with Helidon gRPC. Helidon supports pluggable Marshallers and by default will support any Java primitive or Java Serializable as well as Protobuf types. Any type that can be marshalled by the built-in marshallers or custom supplied marshaller may be used as a request or response type. ",
            "title": "Request an Response Types"
        },
        {
            "location": "/mp/grpc/01_mp_server_side_services",
            "text": " A unary gRPC method is the simplest type of service method. Typically a unary method takes a request value and returns a response value but this does not have to be the case, a unary method could just as easily take no request parameter and/or return no response. All of the signatures below are valid unary methods in Helidon gRPC MP. <markup lang=\"java\" >// A unary method with a simple request and response @io.helidon.microprofile.grpc.core.Unary public ResponseType invoke(RequestType req) // A unary method that just returns a response @io.helidon.microprofile.grpc.core.Unary public ResponseType invoke() // A unary method that takes a request but returns no response @io.helidon.microprofile.grpc.core.Unary public void invoke(RequestType req) // A unary method that takes no request and returns no response @io.helidon.microprofile.grpc.core.Unary public void invoke() // An async unary request that takes a request and returns a future // that will complete when the response is ready @io.helidon.microprofile.grpc.core.Unary public CompletableFuture&lt;ResponseType&gt; invoke(RequestType req) // An async unary request that takes no request and returns a future // that will complete when the response is ready @io.helidon.microprofile.grpc.core.Unary public CompletableFuture&lt;ResponseType&gt; invoke() // The standard gRPC Java unary method signature @io.helidon.microprofile.grpc.core.Unary public void invoke(RequestType req, StreamObserver&lt;ResponseType&gt; observer) // The standard gRPC Java unary method signature but without a request type @io.helidon.microprofile.grpc.core.Unary public void invoke(StreamObserver&lt;ResponseType&gt; observer) // A unary method that takes a request type and a future to complete // with the response type @io.helidon.microprofile.grpc.core.Unary public void invoke(RequestType req, CompletableFuture&lt;ResponseType&gt; observer) // A unary method that takes no request type but just takes a future // to complete with the response type @io.helidon.microprofile.grpc.core.Unary public void invoke(CompletableFuture&lt;ResponseType&gt; observer) The various signatures supported above allow the service developer to choose the method signature that best fits their application business logic without needing to worry about handling standard gRPC Java requests and StreamObservers. The standard gRPC Java method signature is in the list above so it can still be used if required. ",
            "title": "Unary Methods"
        },
        {
            "location": "/mp/grpc/01_mp_server_side_services",
            "text": " A server streaming method receives a requests from the client and when the request stream is complete it sends back a stream of response values. A traditional gRPC Java server streaming method takes two parameters, the request and a StreamObserver that is used to send back the single response in the same way that a unary method sends a response. As with unary methods Helidon gRPC MP supports different method signatures for server streaming methods. All of the signatures below are valid server streaming methods in Helidon gRPC MP. <markup lang=\"java\" >// The standard gRPC Java server streaming method signature @io.helidon.microprofile.grpc.core.ServerStreaming public void invoke(RequestType req, StreamObserver&lt;ResponseType&gt; observer) // A server streaming method that uses a Stream to send the responses to the client @io.helidon.microprofile.grpc.core.ServerStreaming public Stream&lt;ResponseType&gt; invoke(RequestType req) // The server streaming method without a request parameter @io.helidon.microprofile.grpc.core.ServerStreaming public void invoke(StreamObserver&lt;ResponseType&gt; observer) // A server streaming method without a request parameter // that uses a Stream to send the responses to the client @io.helidon.microprofile.grpc.core.ServerStreaming public Stream&lt;ResponseType&gt; invoke(RequestType req) As with unary methods, the Helidon gRPC MP API supports multiple different method signatures for implementing server streaming methods. ",
            "title": "ServerStreaming Methods"
        },
        {
            "location": "/mp/grpc/01_mp_server_side_services",
            "text": " A client streaming method receives a stream of requests from the client and when the request stream is complete it sends back a response. A traditional gRPC Java client streaming method takes two StreamObserver parameters, one is the stream of client requests and the other is used to send back the single response in the same way that a unary method sends a response. As with unary methods Helidon gRPC MP supports different method signatures for client streaming methods. All of the signatures below are valid client streaming methods in Helidon gRPC MP. <markup lang=\"java\" >// The standard gRPC Java client streaming method signature @io.helidon.microprofile.grpc.core.ClientStreaming public StreamObserver&lt;RequestType&gt; invoke(StreamObserver&lt;ResponseType&gt; observer) // The gRPC Java client streaming method with an asynchronous response @io.helidon.microprofile.grpc.core.ClientStreaming public StreamObserver&lt;RequestType&gt; invoke(CompletableFuture&lt;ResponseType&gt; observer) ",
            "title": "ClientStreaming Methods"
        },
        {
            "location": "/mp/grpc/01_mp_server_side_services",
            "text": " A bidirectional streaming method is a method that is a constant stream of client requests and server responses. Other than the standard gRPC Java StreamObserver there are not any other built in types that make sense to use to implement different method signatures for a bidirectional method so the only supported signature is the standard gRPC Java method. <markup lang=\"java\" >@io.helidon.microprofile.grpc.core.Bidirectional public StreamObserver&lt;RequestType&gt; invoke(StreamObserver&lt;ResponseType&gt; observer) ",
            "title": "Bi-Directional Streaming Methods"
        },
        {
            "location": "/mp/grpc/01_mp_server_side_services",
            "text": " Once a class is properly annotated to make it a gRPC MP service it needs to have service methods that implement the application business logic. In gRPC there are four different types of method: Unary - a simple method with at most a single request value and returning at most a single response value. Server Streaming - a method that takes at most a single request value but may return zero or more response values. Client Streaming - a request that takes one or more request values and returns at most one response value. Bi-directional Streaming - a method that can take one or more request values and return zero or more response values. The Helidon gRPC MP API determines a method type by its annotation, which should be one of the following: <markup lang=\"java\" >@io.helidon.microprofile.grpc.core.Unary @io.helidon.microprofile.grpc.core.ServerStreaming @io.helidon.microprofile.grpc.core.ClientStreaming @io.helidon.microprofile.grpc.core.Bidirectional Request an Response Types A gRPC service method typically takes a request parameter and returns a response value (streaming methods may take or return multiple requests or responses). In traditional gRPC Java the types used for the request and response values must be Protobuf serializable classes but this is not the case with Helidon gRPC. Helidon supports pluggable Marshallers and by default will support any Java primitive or Java Serializable as well as Protobuf types. Any type that can be marshalled by the built-in marshallers or custom supplied marshaller may be used as a request or response type. Unary Methods A unary gRPC method is the simplest type of service method. Typically a unary method takes a request value and returns a response value but this does not have to be the case, a unary method could just as easily take no request parameter and/or return no response. All of the signatures below are valid unary methods in Helidon gRPC MP. <markup lang=\"java\" >// A unary method with a simple request and response @io.helidon.microprofile.grpc.core.Unary public ResponseType invoke(RequestType req) // A unary method that just returns a response @io.helidon.microprofile.grpc.core.Unary public ResponseType invoke() // A unary method that takes a request but returns no response @io.helidon.microprofile.grpc.core.Unary public void invoke(RequestType req) // A unary method that takes no request and returns no response @io.helidon.microprofile.grpc.core.Unary public void invoke() // An async unary request that takes a request and returns a future // that will complete when the response is ready @io.helidon.microprofile.grpc.core.Unary public CompletableFuture&lt;ResponseType&gt; invoke(RequestType req) // An async unary request that takes no request and returns a future // that will complete when the response is ready @io.helidon.microprofile.grpc.core.Unary public CompletableFuture&lt;ResponseType&gt; invoke() // The standard gRPC Java unary method signature @io.helidon.microprofile.grpc.core.Unary public void invoke(RequestType req, StreamObserver&lt;ResponseType&gt; observer) // The standard gRPC Java unary method signature but without a request type @io.helidon.microprofile.grpc.core.Unary public void invoke(StreamObserver&lt;ResponseType&gt; observer) // A unary method that takes a request type and a future to complete // with the response type @io.helidon.microprofile.grpc.core.Unary public void invoke(RequestType req, CompletableFuture&lt;ResponseType&gt; observer) // A unary method that takes no request type but just takes a future // to complete with the response type @io.helidon.microprofile.grpc.core.Unary public void invoke(CompletableFuture&lt;ResponseType&gt; observer) The various signatures supported above allow the service developer to choose the method signature that best fits their application business logic without needing to worry about handling standard gRPC Java requests and StreamObservers. The standard gRPC Java method signature is in the list above so it can still be used if required. ServerStreaming Methods A server streaming method receives a requests from the client and when the request stream is complete it sends back a stream of response values. A traditional gRPC Java server streaming method takes two parameters, the request and a StreamObserver that is used to send back the single response in the same way that a unary method sends a response. As with unary methods Helidon gRPC MP supports different method signatures for server streaming methods. All of the signatures below are valid server streaming methods in Helidon gRPC MP. <markup lang=\"java\" >// The standard gRPC Java server streaming method signature @io.helidon.microprofile.grpc.core.ServerStreaming public void invoke(RequestType req, StreamObserver&lt;ResponseType&gt; observer) // A server streaming method that uses a Stream to send the responses to the client @io.helidon.microprofile.grpc.core.ServerStreaming public Stream&lt;ResponseType&gt; invoke(RequestType req) // The server streaming method without a request parameter @io.helidon.microprofile.grpc.core.ServerStreaming public void invoke(StreamObserver&lt;ResponseType&gt; observer) // A server streaming method without a request parameter // that uses a Stream to send the responses to the client @io.helidon.microprofile.grpc.core.ServerStreaming public Stream&lt;ResponseType&gt; invoke(RequestType req) As with unary methods, the Helidon gRPC MP API supports multiple different method signatures for implementing server streaming methods. ClientStreaming Methods A client streaming method receives a stream of requests from the client and when the request stream is complete it sends back a response. A traditional gRPC Java client streaming method takes two StreamObserver parameters, one is the stream of client requests and the other is used to send back the single response in the same way that a unary method sends a response. As with unary methods Helidon gRPC MP supports different method signatures for client streaming methods. All of the signatures below are valid client streaming methods in Helidon gRPC MP. <markup lang=\"java\" >// The standard gRPC Java client streaming method signature @io.helidon.microprofile.grpc.core.ClientStreaming public StreamObserver&lt;RequestType&gt; invoke(StreamObserver&lt;ResponseType&gt; observer) // The gRPC Java client streaming method with an asynchronous response @io.helidon.microprofile.grpc.core.ClientStreaming public StreamObserver&lt;RequestType&gt; invoke(CompletableFuture&lt;ResponseType&gt; observer) Bi-Directional Streaming Methods A bidirectional streaming method is a method that is a constant stream of client requests and server responses. Other than the standard gRPC Java StreamObserver there are not any other built in types that make sense to use to implement different method signatures for a bidirectional method so the only supported signature is the standard gRPC Java method. <markup lang=\"java\" >@io.helidon.microprofile.grpc.core.Bidirectional public StreamObserver&lt;RequestType&gt; invoke(StreamObserver&lt;ResponseType&gt; observer) ",
            "title": "Defining Service Methods"
        },
        {
            "location": "/mp/grpc/01_mp_server_side_services",
            "text": " When the gRPC MP server is starting it will discover all CDI beans of type io.grpc.BindableService . Service sub-classes implemented the traditional way with code generation are instances of BindableService so by annotating the implementation class with the @ApplicationScoped annotation they become discoverable and will be deployed into the gRPC server. <markup lang=\"java\" >@ApplicationScoped public class StringService extends StringServiceGrpc.StringServiceImplBase { In exactly the same way, if a class is an implementation of io.helidon.grpc.server.GrpcService then by annotating the class with the @ApplicationScoped annotation it will be discovered and deployed when the MP gRPC server starts. <markup lang=\"java\" >@ApplicationScoped public class StringService implements GrpcService { ",
            "title": "Annotate the Service Implementation"
        },
        {
            "location": "/mp/grpc/01_mp_server_side_services",
            "text": " If it is not possible to annotate the service class (for example the code is built by a third party) another way to deploy none CDI bean services is to implement a gRPC MP server extension. The extension will then be called when the MP server is starting and be given the chance to add additional services for deployment. An extension should implement the io.helidon.microprofile.grpc.server.spi.GrpcMpExtension interface. For example, assuming that there was a gRPC service class called StringService that needed to be deployed an extension class might look like this: <markup lang=\"java\" >public class MyExtension implements GrpcMpExtension { @Override public void configure(GrpcMpContext context) { context.routing() .register(new ServiceService()); } } The configure method of the extension will be called to allow the extension to add extra configuration to the server. In this example an instance of the StringService is registered with the routing (as described in the basic gRPC server documentation ). The GrpcMpExtension instances are discovered and loaded using the service loader so for the example above to work a file META-INF/services/io.helidon.microprofile.grpc.server.spi.GrpcMpExtension would need to be created that contained the names of the service implementations. ",
            "title": "Implement a GrpcMpExtension"
        },
        {
            "location": "/mp/grpc/01_mp_server_side_services",
            "text": " Whilst the examples above show how simple it is to write gRPC services with basic POJOs there may be cases where there is a requirement to deploy services built the traditional way using gRPC Java generated classes or built as non-microprofile Helidon gRCP services . Annotate the Service Implementation When the gRPC MP server is starting it will discover all CDI beans of type io.grpc.BindableService . Service sub-classes implemented the traditional way with code generation are instances of BindableService so by annotating the implementation class with the @ApplicationScoped annotation they become discoverable and will be deployed into the gRPC server. <markup lang=\"java\" >@ApplicationScoped public class StringService extends StringServiceGrpc.StringServiceImplBase { In exactly the same way, if a class is an implementation of io.helidon.grpc.server.GrpcService then by annotating the class with the @ApplicationScoped annotation it will be discovered and deployed when the MP gRPC server starts. <markup lang=\"java\" >@ApplicationScoped public class StringService implements GrpcService { Implement a GrpcMpExtension If it is not possible to annotate the service class (for example the code is built by a third party) another way to deploy none CDI bean services is to implement a gRPC MP server extension. The extension will then be called when the MP server is starting and be given the chance to add additional services for deployment. An extension should implement the io.helidon.microprofile.grpc.server.spi.GrpcMpExtension interface. For example, assuming that there was a gRPC service class called StringService that needed to be deployed an extension class might look like this: <markup lang=\"java\" >public class MyExtension implements GrpcMpExtension { @Override public void configure(GrpcMpContext context) { context.routing() .register(new ServiceService()); } } The configure method of the extension will be called to allow the extension to add extra configuration to the server. In this example an instance of the StringService is registered with the routing (as described in the basic gRPC server documentation ). The GrpcMpExtension instances are discovered and loaded using the service loader so for the example above to work a file META-INF/services/io.helidon.microprofile.grpc.server.spi.GrpcMpExtension would need to be created that contained the names of the service implementations. ",
            "title": "Deploying Protobuf Services"
        },
        {
            "location": "/se/config/01_introduction",
            "text": " The config component provides a Java API to load and process configuration properties from various sources into a Config object which the application can use to retrieve config data. ",
            "title": "preambule"
        },
        {
            "location": "/se/config/01_introduction",
            "text": " To enable Config add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.config&lt;/groupId&gt; &lt;artifactId&gt;helidon-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/config/01_introduction",
            "text": " A brief overview of the config system helps clarify its different parts and how they work together. Most applications will typically deal with more than one of these parts. These are the main parts of the configuration system: Config system - allows you to read configuration data in an application A config source - a location containing configuration data (File, Map, Properties etc.) A config parser - a component capable of transforming bytes into configuration data (such as JSON content, YAML etc.) The Config system handles configuration data in an in-memory tree that represents the configuration structure and values. This approach allows us to take any source data, be it a flat properties file or an object structure such as JSON, and transform it into a single tree that allows for overriding of values using heterogeneous config sources. We are using the . as a separator of tree structure. Example of two config sources that can be used by Config with the same data tree in different formats: A Properties source: <markup lang=\"properties\" >web.page-size=25 A YAML source: <markup lang=\"yaml\" >web: page-size: 25 The configuration has the same internal representation in Config and can be accessed using the Config API as follows: <markup lang=\"java\" >int pageSize = config.get(\"web.page-size\") .asInt() .orElse(20); Or using the tree node approach: <markup lang=\"java\" >int pageSize = config .get(\"web\") .get(\"page-size\") .asInt() .orElse(20); For this first example we can see the basic features of Config : Configuration is a tree of Config nodes You can use . as a tree separator when requesting node values Each config value can be retrieved as a typed object, with shortcut methods for the most commonly used types, such as int , String , long and other You can immediately provide a default value for the cases the configuration option is not defined in any source ",
            "title": "Introducing the Config System"
        },
        {
            "location": "/se/config/01_introduction",
            "text": " The Config system treats config sources as a hierarchy, where the first source that has a specific configuration key \"wins\" and its value is used, other sources are not even queried for it. For example the default configuration when you use Config.create() uses the following config sources: System properties config source Environment variables config source A classpath config source called application.? where the ? depends on supported media types currently on the classpath. By default it is properties , if you have YAML support on classpath, it would be application.yaml (a ConfigParser may add additional supported suffixes for default file) Let&#8217;s consider the following keys: System property answer=42 Environment variable ANSWER=38 A key in a configuration file answer=36 When you request config.get(`answer ).asInt().orElse(25) , you would get `42 This allows you to configure environment specific configuration values through system properties, environment variables, or through files available on each environment (be it a physical machine, a Kubernetes pod, or a docker image) without changing your source code. ",
            "title": "Overriding Values"
        },
        {
            "location": "/se/config/01_introduction",
            "text": " If you add additional Helidon config maven artifacts to your dependencies, then the config system can read formats other than Java properties format and the default configuration will search for other application file types in the following order. Note that the default configuration stops once it finds one of the files below; it does not merge all such files it can find. Default Config Files (most to least important) Source Helidon maven artifact ID (group ID: io.helidon.config ) Notes application.yaml helidon-config-yaml YAML format http://yaml.org application.conf helidon-config-hocon HOCON format https://github.com/lightbend/config#using-hocon-the-json-superset application.json helidon-config-hocon JSON format https://json.org/ application.properties helidon-config Java properties format ",
            "title": "Built-in Support for Config Formats"
        },
        {
            "location": "/se/config/01_introduction",
            "text": " Config system applies configured config filters on each value when it is requested for the first time. There is a built-in filter called ValueResolvingFilter (enabled by default, can be disabled through API) that resolves references to other keys in values in configuration. Example: Let&#8217;s consider the following example properties file <markup lang=\"properties\" >host=localhost first-service.host=${host}/firstservice second-service.host=${host}/secondservice The filter resolves the ${host} reference to the localhost value. This makes it easier to override values in testing and production, as you can just override the host key and leave the URIs same. ",
            "title": "Config Filters"
        },
        {
            "location": "/se/config/01_introduction",
            "text": " Config is an immutable in-memory tree. Nevertheless we know that configuration sometimes changes, and we may want to react to such changes. In Config system, you can do this through change support provided by these components: Config.onChange() API - you can use to add your listener, to be notified of configuration changes PollingStrategy - a component providing regular events to check if a source has changed. This requires support in config sources themselves (see PollableSource ) ChangeWatcher - a component watching the underlying source for changes. This requires support in config sources themselves (see WatchableSource ) EventConfigSource - an event source that is capable of notifying about changes iteslf If you want to receive onChange events, you must configure your Config with at least one source that is capable of providing changes (having a PollingStrategy or ChangeWatcher configured, or implementing EventConfigSource ) ",
            "title": "Change Support"
        },
        {
            "location": "/se/config/01_introduction",
            "text": " The Config object lets your application retrieve config data as a typed ConfigValue. You can retrieve a ConfigValue&lt;T&gt; using the following as methods in Config : * asString() - to get a string config value * asBoolean() and other accessors for primitive types * as(Class) - to get a value for a type that has a mapper configured * as(Generic) - to get a value for a type supporting generics (such as Set&lt;String&gt; ) * asMap() - to get a map of key to value pairs * asList(Class) - to get a list of typed values * as(Function&lt;Config,T&gt;) - to get a typed value providing a mapper function ConfigValue&lt;T&gt; can be used to obtain: * an Optional&lt;T&gt; value from a single node , * the T value from a single node interpreted as a basic Java type (primitive or simple object) already known to the config system (such as a boolean or a Double ), or * a complex Java type from a subtree of the config tree. + The config system automatically knows how to return List and Map complex types, and you can provide config mappers to convert a config subtree to whatever Java types your application needs. ",
            "title": "Typed config values"
        },
        {
            "location": "/se/config/01_introduction",
            "text": " Introducing the Config System A brief overview of the config system helps clarify its different parts and how they work together. Most applications will typically deal with more than one of these parts. These are the main parts of the configuration system: Config system - allows you to read configuration data in an application A config source - a location containing configuration data (File, Map, Properties etc.) A config parser - a component capable of transforming bytes into configuration data (such as JSON content, YAML etc.) The Config system handles configuration data in an in-memory tree that represents the configuration structure and values. This approach allows us to take any source data, be it a flat properties file or an object structure such as JSON, and transform it into a single tree that allows for overriding of values using heterogeneous config sources. We are using the . as a separator of tree structure. Example of two config sources that can be used by Config with the same data tree in different formats: A Properties source: <markup lang=\"properties\" >web.page-size=25 A YAML source: <markup lang=\"yaml\" >web: page-size: 25 The configuration has the same internal representation in Config and can be accessed using the Config API as follows: <markup lang=\"java\" >int pageSize = config.get(\"web.page-size\") .asInt() .orElse(20); Or using the tree node approach: <markup lang=\"java\" >int pageSize = config .get(\"web\") .get(\"page-size\") .asInt() .orElse(20); For this first example we can see the basic features of Config : Configuration is a tree of Config nodes You can use . as a tree separator when requesting node values Each config value can be retrieved as a typed object, with shortcut methods for the most commonly used types, such as int , String , long and other You can immediately provide a default value for the cases the configuration option is not defined in any source Overriding Values The Config system treats config sources as a hierarchy, where the first source that has a specific configuration key \"wins\" and its value is used, other sources are not even queried for it. For example the default configuration when you use Config.create() uses the following config sources: System properties config source Environment variables config source A classpath config source called application.? where the ? depends on supported media types currently on the classpath. By default it is properties , if you have YAML support on classpath, it would be application.yaml (a ConfigParser may add additional supported suffixes for default file) Let&#8217;s consider the following keys: System property answer=42 Environment variable ANSWER=38 A key in a configuration file answer=36 When you request config.get(`answer ).asInt().orElse(25) , you would get `42 This allows you to configure environment specific configuration values through system properties, environment variables, or through files available on each environment (be it a physical machine, a Kubernetes pod, or a docker image) without changing your source code. Built-in Support for Config Formats If you add additional Helidon config maven artifacts to your dependencies, then the config system can read formats other than Java properties format and the default configuration will search for other application file types in the following order. Note that the default configuration stops once it finds one of the files below; it does not merge all such files it can find. Default Config Files (most to least important) Source Helidon maven artifact ID (group ID: io.helidon.config ) Notes application.yaml helidon-config-yaml YAML format http://yaml.org application.conf helidon-config-hocon HOCON format https://github.com/lightbend/config#using-hocon-the-json-superset application.json helidon-config-hocon JSON format https://json.org/ application.properties helidon-config Java properties format Config Filters Config system applies configured config filters on each value when it is requested for the first time. There is a built-in filter called ValueResolvingFilter (enabled by default, can be disabled through API) that resolves references to other keys in values in configuration. Example: Let&#8217;s consider the following example properties file <markup lang=\"properties\" >host=localhost first-service.host=${host}/firstservice second-service.host=${host}/secondservice The filter resolves the ${host} reference to the localhost value. This makes it easier to override values in testing and production, as you can just override the host key and leave the URIs same. Change Support Config is an immutable in-memory tree. Nevertheless we know that configuration sometimes changes, and we may want to react to such changes. In Config system, you can do this through change support provided by these components: Config.onChange() API - you can use to add your listener, to be notified of configuration changes PollingStrategy - a component providing regular events to check if a source has changed. This requires support in config sources themselves (see PollableSource ) ChangeWatcher - a component watching the underlying source for changes. This requires support in config sources themselves (see WatchableSource ) EventConfigSource - an event source that is capable of notifying about changes iteslf If you want to receive onChange events, you must configure your Config with at least one source that is capable of providing changes (having a PollingStrategy or ChangeWatcher configured, or implementing EventConfigSource ) Typed config values The Config object lets your application retrieve config data as a typed ConfigValue. You can retrieve a ConfigValue&lt;T&gt; using the following as methods in Config : * asString() - to get a string config value * asBoolean() and other accessors for primitive types * as(Class) - to get a value for a type that has a mapper configured * as(Generic) - to get a value for a type supporting generics (such as Set&lt;String&gt; ) * asMap() - to get a map of key to value pairs * asList(Class) - to get a list of typed values * as(Function&lt;Config,T&gt;) - to get a typed value providing a mapper function ConfigValue&lt;T&gt; can be used to obtain: * an Optional&lt;T&gt; value from a single node , * the T value from a single node interpreted as a basic Java type (primitive or simple object) already known to the config system (such as a boolean or a Double ), or * a complex Java type from a subtree of the config tree. + The config system automatically knows how to return List and Map complex types, and you can provide config mappers to convert a config subtree to whatever Java types your application needs. ",
            "title": "Getting Started"
        },
        {
            "location": "/se/config/01_introduction",
            "text": " Although the default configuration is very simple to use, your application can take as much control as it needs over loading configuration data, accessing the data once loaded, and extending and modifying the behavior of the config system. You do this by: creating and invoking methods on a Config.Builder object to construct a Config instance Using a builder, the application can control everything about how the config system creates the resulting Config instance: config sources, parsers, polling strategy, filters, overrides, mappers, whether or not environment variables and Java system properties serve as config sources. The JavaDoc explains how to use the Config.Builder . using a config profile to choose the sources to be used creating a meta-configuration file on the runtime classpath or file system to control how the config system prepares the default configuration. Once created, the Config object provides many methods the application can use to retrieve config data as various Java types. See the Config JavaDoc for complete details. The links in the following tables lead you to more information about various other config topics. Controlling How Config is Loaded Topic Documentation Where config comes from Config sources , Config Profiles , meta-configuration What format config data is expressed in Config parsers , supported formats How to filter, override, and dereference values Filters and overrides What happens when config data changes Config polling How to deal with loading errors Config retry policies Accessing Configuration Data Topic Documentation How config data is translated into Java types Config mappers How to navigate config trees Navigation Extending and Fine-tuning the Config System Topic Documentation Writing extensions Extensions ",
            "title": "Next Steps"
        },
        {
            "location": "/se/webserver/09_jsonb-support",
            "text": " To enable JSON-B Support add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.media&lt;/groupId&gt; &lt;artifactId&gt;helidon-media-jsonb&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/webserver/09_jsonb-support",
            "text": " To enable JSON-B support, first create and register a JsonbSupport instance with a WebServer.Builder . <markup lang=\"java\" title=\"Registration of the JsonbSupport via WebServer \" >JsonbSupport jsonbSupport = JsonbSupport.create(); WebServer webServer = WebServer.builder() .addMediaSupport(jsonbSupport) .build(); Create a JsonbSupport instance. This instance may be reused freely. Register that JsonbSupport instance to enable automatic deserialization of Java objects from and serialization of Java objects to JSON. Now that automatic JSON serialization and deserialization facilities have been set up, you can register a Handler that works with Java objects instead of raw JSON. Deserialization from and serialization to JSON will be handled according to the JSON-B specification . Suppose you have a Person class that looks like this: <markup lang=\"java\" title=\"Hypothetical Person class\" >public class Person { private String name; public Person() { super(); } public String getName() { return this.name; } public void setName(final String name) { this.name = name; } } Then you can set up a Handler like this: <markup lang=\"java\" title=\"A Handler that works with Java objects instead of raw JSON\" >final Routing routing = routingBuilder.post(\"/echo\", Handler.create(Person.class, (req, res, person) -&gt; res.send(person)))) .build(); Set up a route for POST requests using the Routing.Builder#post(String, Handler&#8230;&#8203;) method Use the Handler#create(Class, Handler.EntityHandler) method to install a Handler.EntityHandler that works with Person instances. This Handler.EntityHandler consumes a Person instance ( person ) and simply echoes it back. Note that there is no working with raw JSON here. <markup lang=\"bash\" title=\"Example of posting JSON to the /echo endpoint\" >curl --noproxy '*' -X POST -H \"Content-Type: application/json\" \\ http://localhost:8080/echo -d '{\"name\":\"Joe\"}' {\"name\":\"Joe\"} ",
            "title": "Usage"
        },
        {
            "location": "/se/webserver/09_jsonb-support",
            "text": " The WebServer supports the JSON-B specification . When this support is enabled, Java objects will be serialized to and deserialized from JSON automatically using Yasson , an implementation of the JSON-B specification . Usage To enable JSON-B support, first create and register a JsonbSupport instance with a WebServer.Builder . <markup lang=\"java\" title=\"Registration of the JsonbSupport via WebServer \" >JsonbSupport jsonbSupport = JsonbSupport.create(); WebServer webServer = WebServer.builder() .addMediaSupport(jsonbSupport) .build(); Create a JsonbSupport instance. This instance may be reused freely. Register that JsonbSupport instance to enable automatic deserialization of Java objects from and serialization of Java objects to JSON. Now that automatic JSON serialization and deserialization facilities have been set up, you can register a Handler that works with Java objects instead of raw JSON. Deserialization from and serialization to JSON will be handled according to the JSON-B specification . Suppose you have a Person class that looks like this: <markup lang=\"java\" title=\"Hypothetical Person class\" >public class Person { private String name; public Person() { super(); } public String getName() { return this.name; } public void setName(final String name) { this.name = name; } } Then you can set up a Handler like this: <markup lang=\"java\" title=\"A Handler that works with Java objects instead of raw JSON\" >final Routing routing = routingBuilder.post(\"/echo\", Handler.create(Person.class, (req, res, person) -&gt; res.send(person)))) .build(); Set up a route for POST requests using the Routing.Builder#post(String, Handler&#8230;&#8203;) method Use the Handler#create(Class, Handler.EntityHandler) method to install a Handler.EntityHandler that works with Person instances. This Handler.EntityHandler consumes a Person instance ( person ) and simply echoes it back. Note that there is no working with raw JSON here. <markup lang=\"bash\" title=\"Example of posting JSON to the /echo endpoint\" >curl --noproxy '*' -X POST -H \"Content-Type: application/json\" \\ http://localhost:8080/echo -d '{\"name\":\"Joe\"}' {\"name\":\"Joe\"} ",
            "title": "JSON-B Support"
        },
        {
            "location": "/se/config/07_extensions",
            "text": " Developer-provided extensions influence how the config system behaves. The config system introduction explains the design of the config system and how its parts work together to read and parse config data, convert it to Java types, fine-tune the look-up of config data, and reload and reprocess data when it changes. Config extensions provided by the application modify and expand the way the config system performs these steps. ",
            "title": "preambule"
        },
        {
            "location": "/se/config/07_extensions",
            "text": " Each config extension implements one of the interfaces defined in the Configuration SPI: ConfigSource - Loads raw configuration data from a given type of source and delegates to a ConfigParser , producing the in-memory data structure which represents the loaded and parsed configuration. ConfigParser - Translates configuration content in a given format into the corresponding internal config data structures. OverrideSource - Provides key/value pairs which override config values loaded from any ConfigSource , given the key and ignoring the original value. ConfigFilter - Transforms config String values returned from any value-type Config node, given the key and the original value. ConfigMapperProvider - Provides one or more ConfigMapper s each of which converts a Config object tree to a Java type specific to the application. PollingStrategy - Implements a custom technique to trigger polling of underlying sources for changes ChangeWatcher - Implements a custom technique to watch underlying sources for changes and notifying the config system of such a change The extension mechanism of Config can also use Java ServiceLoader . For this purpose, you implement providers that serve as factories for your implementation of an extension. This is to support config profiles even for custom extensions. Service providers: ConfigMapperProvider - support for config mappers, automatically discovered by the config system ConfigFilter - support for config filters, automatically discovered by the config system ConfigParser - support for config parsers, automatically discovered by the config system ConfigSourceProvider - support for named config sources, configurable through profiles ChangeWatcherProvider - support for named change watchers, configurable through profiles OverrideSourceProvider - support for named override sources, configurable through profiles PollingStrategyProvider - support for named polling strategies, configurable through profiles RetryPolicyProvider - support for retry policies, configurable through profiles The config system itself implements several of these SPIs, as noted in the sections below. ",
            "title": "Introduction"
        },
        {
            "location": "/se/config/07_extensions",
            "text": " The following example shows configuration of all possible extensions with Config (all custom extension have a name prefix My ): <markup lang=\"java\" >Config config = Config.builder() .addSource(FileConfigSource.builder() .changeWatcher(MyChangeWatcher.create()) .pollingStrategy(MyPollingStrategy.create()) .parser(MyConfigParser.create()) .retryPolicy(MyRetryPolicy.create())) .addSource(MySource.create()) .addFilter(MyFilter.create()) .overrides(MyOverrides.create()) .build() ",
            "title": "Manual configuration with builder"
        },
        {
            "location": "/se/config/07_extensions",
            "text": " The following extensions are loaded using a service loader for any configuration instance, and do not require an explicit setup: ConfigParser - each config parser on the classpath that implements ConfigParserProvider as a Java service loader service ConfigFilter - each filter on the classpath that implements ConfigFilter as a Java service loader service Other extensions are only used from Java service loader when you use config profiles. Mapping is done through the type configured in config profile, and the type defined by the extension provider interface. For example for config sources, the interface defines the following methods (only subset shown): <markup lang=\"java\" >boolean supports(String type); ConfigSource create(String type, Config metaConfig); Considering the following meta configuration (or config profile): <markup lang=\"yaml\" >sources: - type: \"my-type\" properties: my-config: \"configuration\" The config system would iterate through all ConfigSourceProvider implementations found through Java ServiceLoader based on their priority. First provider that returns true when supports(\"my-type\") is called would be used, and an instance of a ConfigSource created using create(\"my-type\", config) , where config is located on the node of properties from config profile. ",
            "title": "Automatic configuration using a service loader"
        },
        {
            "location": "/se/config/07_extensions",
            "text": " The config system invokes extensions of a given type in priority order. Developers can express the relative importance of an extension by annotating the service implementation class with @javax.annotation.Priority . The default value is 100. A lower priority value represents greater importance. ",
            "title": "About Priority"
        },
        {
            "location": "/se/config/07_extensions",
            "text": " You can configure a custom extension in two ways: Manual configuration with builder Automatic configuration using a Java service loader Manual configuration with builder The following example shows configuration of all possible extensions with Config (all custom extension have a name prefix My ): <markup lang=\"java\" >Config config = Config.builder() .addSource(FileConfigSource.builder() .changeWatcher(MyChangeWatcher.create()) .pollingStrategy(MyPollingStrategy.create()) .parser(MyConfigParser.create()) .retryPolicy(MyRetryPolicy.create())) .addSource(MySource.create()) .addFilter(MyFilter.create()) .overrides(MyOverrides.create()) .build() Automatic configuration using a service loader The following extensions are loaded using a service loader for any configuration instance, and do not require an explicit setup: ConfigParser - each config parser on the classpath that implements ConfigParserProvider as a Java service loader service ConfigFilter - each filter on the classpath that implements ConfigFilter as a Java service loader service Other extensions are only used from Java service loader when you use config profiles. Mapping is done through the type configured in config profile, and the type defined by the extension provider interface. For example for config sources, the interface defines the following methods (only subset shown): <markup lang=\"java\" >boolean supports(String type); ConfigSource create(String type, Config metaConfig); Considering the following meta configuration (or config profile): <markup lang=\"yaml\" >sources: - type: \"my-type\" properties: my-config: \"configuration\" The config system would iterate through all ConfigSourceProvider implementations found through Java ServiceLoader based on their priority. First provider that returns true when supports(\"my-type\") is called would be used, and an instance of a ConfigSource created using create(\"my-type\", config) , where config is located on the node of properties from config profile. About Priority The config system invokes extensions of a given type in priority order. Developers can express the relative importance of an extension by annotating the service implementation class with @javax.annotation.Priority . The default value is 100. A lower priority value represents greater importance. ",
            "title": "Setting up an extension"
        },
        {
            "location": "/se/config/07_extensions",
            "text": " The config system includes built-in support for several types of sources (for example, Java String , Readable , Properties , and Map objects - see ConfigSources ). Implement a ConfigSource to load raw configuration data from a type of source that the config system does not already support. ConfigSource SPI For config sources that work directly with config nodes, the followin API is available. These interfaces have an implementation provided by Helidon. The interfaces ConfigNode , ObjectNode , ValueNode and ListNode represent the in-memory data structure for loaded and parsed configuration data. ConfigNode API For config sources that work return data ( NodeConfigSource and ParsableConfigSource ) a Content must be returned that describes the loaded data. The following diagram depicts the Content API. Content API Some of the methods provided are not always mandatory, yet they are part of the APIs to simplify the overall class structure: ConfigContent.stamp() - this method is used by PollingStrategy to determine if content has been changed. This can be always empty for sources, that do not implement PollableSource ConfigParser.Content.charset() - this can return any Charset for media types that are binary ConfigParser.Content.mediaType() - this can be used to override media type (that would otherwise be \"guessed\" from the underlying source) ParsableSource.parser() - this can be used to override parser (that would otherwise be based on mediaType ) ParsableSource.mediaType() - return the configured or \"guessed\" media type of this source, see io.helidon.common.media.type.MediaTypes , if not returned, media type must be present on Content , or provided through media type mapping ",
            "title": "ConfigSource SPI"
        },
        {
            "location": "/se/config/07_extensions",
            "text": " The parsing step converts config data in some format into the corresponding in-memory representation of config ObjectNode s. The config system can already parse several data formats (for example Java Properties , YAML, and HOCON). Implement the ConfigParser SPI to allow the config system to handle additional formats. ConfigParser SPI The ConfigParser.Content interface defines operations on the content that is to be parsed by a ConfigParser implementation: mediaType() - Reports the media type of the content (if it is to override media type defined on the config source) data() - Provides the InputStream with config source data charset() - Defines the charset to use to parse the stream in case this is a text based media type, ignored by parsers of binary content The application can register parsers for a builder by invoking Config.Builder#addParser(ConfigParser) . The config system also uses the Java service loader mechanism to load automatically, for all builders, any parsers listed in the META-INF/services/io.helidon.config.spi.ConfigParser resource on the runtime classpath. Prevent autoloading of parsers for a given builder by invoking Config.Builder#disableParserServices() . ConfigParser accepts @Priority . See About Priority . <markup lang=\"java\" title=\"Example custom parser implementation listed in META-INF/services/io.helidon.config.spi.ConfigParser \" >my.module.MyConfigParser <markup lang=\"java\" title=\"Example custom parser definition in module-info.java \" >module my.module { requires transitive io.helidon.config; provides io.helidon.config.spi.ConfigParser with myModule.MyConfigParser; } ",
            "title": "ConfigParser SPI"
        },
        {
            "location": "/se/config/07_extensions",
            "text": " When the application retrieves a configuration value the config system first uses the relevant config sources and filters. It then applies any overrides the application has provided. Each override has: a Predicate&lt;Config.Key&gt; (a boolean-valued function that operates on the config key), and a replacement, overriding , String value the config system should use if the predicate evaluates to true. To furnish overrides to the config system, implement the OverrideSource SPI one or more times and pass instances of those implementations to the config builder&#8217;s overrides method. The config system will apply the overrides returned from each OverrideSource to each config key requested from a Config that is based on that Config.Builder . To support custom override sources in config profiles, also implement the OverrideSourceProvider service loader SPI OverrideSource SPI Note that override sources can also implement PollableSource , and WatchableSource to add change support. ",
            "title": "OverrideSource SPI"
        },
        {
            "location": "/se/config/07_extensions",
            "text": " The ConfigFilter JavaDoc describes multiple methods for adding filters to a Config.Builder . Some accept a ConfigFilter directly and some accept a provider function which, when passed a Config instance, returns a ConfigFilter . Neither a ConfigFilter nor a provider function which furnishes one should access the Config instance passed to the provider function. Instead, implement the ConfigFilter.init(Config) method on the filter. The config system invokes the filters' init methods according to the filters' @Priority order. Recall that whenever any code invokes Config.get , the Config instance invokes the apply method of all registered filters. By the time the application retrieves config this way the config system will have run the init method on all the filters. But note that when a filter&#8217;s init method invokes Config.get , the init methods of lower-priority filters will not yet have run. ConfigFilter SPI ",
            "title": "Initializing Filters"
        },
        {
            "location": "/se/config/07_extensions",
            "text": " Before returning a String from Config.value() the config system applies any filters set up on the Config.Builder used to create the config tree that contains the config node of interest. The application provides filters as implementations of the ConfigFilter interface. Each filter is a function which accepts a Config.Key and an input String value and returns a String value the config system should use for that key going forward. The filter can return the original value or return some other value. The application registers filters and filter providers by passing ConfigFilter implementations to one of the config builder addFilter methods . The config system also uses the Java service loader mechanism to load additional filters automatically, for all builders, using the service interface described in the following table. Prevent a given builder from using the auto-loaded filters by invoking the disableFilterServices method. Config SPI Interfaces for Filtering Interface Method Usage ConfigFilter Accepts @Priority . See About Priority . String apply(Config.Key key, String stringValue); Accepts a key and the corresponding String value and returns the String which the config system should use for that key. Initializing Filters The ConfigFilter JavaDoc describes multiple methods for adding filters to a Config.Builder . Some accept a ConfigFilter directly and some accept a provider function which, when passed a Config instance, returns a ConfigFilter . Neither a ConfigFilter nor a provider function which furnishes one should access the Config instance passed to the provider function. Instead, implement the ConfigFilter.init(Config) method on the filter. The config system invokes the filters' init methods according to the filters' @Priority order. Recall that whenever any code invokes Config.get , the Config instance invokes the apply method of all registered filters. By the time the application retrieves config this way the config system will have run the init method on all the filters. But note that when a filter&#8217;s init method invokes Config.get , the init methods of lower-priority filters will not yet have run. ConfigFilter SPI ",
            "title": "ConfigFilter SPI"
        },
        {
            "location": "/se/config/07_extensions",
            "text": " The config system provides built-in mappings from String values to various Java types. (See ConfigMappers .) To handle mappings to other types the application can register custom mappers with the config system by implementing the ConfigMapperProvider SPI. Such providers return a map, with entries in which: the key is the Java type (a Class object) the mapper produces, and the value is a ConfigMapper that converts the config in-memory data structure into the type in the key. The provider may also implement other methods for finer tuned conversion mechanisms: genericTypeMappers() returns a map with entries for specific GenericType conversions, for example when the provider supports only mapping for GenericType&lt;Map&lt;String, Integer&gt;&gt; mapper(Class) returns a conversion function (optional) that converts a config node to the typed instance (if supported by this provider) mapper(GenericType) returns a conversion function (optional) that coverts a config node to the GenericType (if supported by this provider) - for example in case this provider supports any Map&lt;String, ?&gt; type, such as Map&lt;String, Integer&gt; and Map&lt;String, Double&gt; The config conversion system works as follows: For Config.as(Class) : Check whether a conversion function exists for the class requested (from method mappers() ). Check whether a conversion function is provided by any ConfigMapperProvider with method mapper(Class) . Check whether a conversion function exists for a generic type for the class requested (from method genericTypeMappers ). Check whether a conversion function is provided by any ConfigMapperProvider with method mapper(GenericType) for a generic type for the class requested. For Config.as(GenericType) - the first two steps are skipped. The config system also uses the Java ServiceLoader mechanism to load automatically, for all builders, any mappers returned by the providers listed in the META-INF/services/io.helidon.config.spi.ConfigMapperProvider resource on the runtime classpath. The application can prevent autoloading of mappers for a given builder by invoking Config.Builder#disableMapperServices() . Note that the built-in mappers described in ConfigMappers still operate. Mapper providers accept @Priority . See About Priority . ConfigMapperProvider SPI A mapper provider can specify a @javax.annotation.Priority . If no priority is explicitly assigned, the value of 100 is assumed. <markup lang=\"java\" title=\"Reference custom mapper provider implementation in META-INF/services/io.helidon.config.spi.ConfigMapperProvider \" >my.module.MyConfigMapperProvider <markup lang=\"java\" title=\"Reference custom mapper provider implementation in module-info.java \" >module my.module { requires transitive io.helidon.config; provides io.helidon.config.spi.ConfigMapperProvider with my.module.MyConfigMapperProvider; } ",
            "title": "ConfigMapperProvider SPI"
        },
        {
            "location": "/se/config/07_extensions",
            "text": " An implementation of PollingStrategy gets an instance to poll, and triggers its poll method. The result of poll method may be used to update the polling strategy schedule. The approach of checking for changes is part of the config system, and the PollingStrategy does not need to be concerned with it. This is based on the source stamp as defined in ConfigContent and used in PollableSource.isModified(Object) methods. If a more sophisticated solution is needed, you may need to implement a ChangeWatcher instead. The config system offers polling strategy for periodic time-based checks. Often an application can create a config source simply by using one of the methods on ConfigSources (for example, ConfigSources#file(path) to get a builder and then invoke pollingStrategy passing a polling strategy. But the application can implement its own PollingStrategy and set it on the config source builder instead. PollingStrategy SPI To support polling strategies that can be configured in config profile, also implement the PollingStrategyProvider Java service loader SPI. ",
            "title": "PollingStrategy SPI"
        },
        {
            "location": "/se/config/07_extensions",
            "text": " An implementation of ChangeWatcher gets the underlying source information and a change listener. The \"watcher\" then watches for changes of the source and notifies the listener when a change occurs. This is designed to support sources that can react on changes (such as file system). When a polling mechanism is needed, please check PollingStrategy above. The config system offers a change watcher for any Path based config source (such as FileConfigSource ) and for the etcd config source. To use a change watcher, simply create a config source using its builder and register the change watcher on the builder (the config source must support appropriate type of change watchers). ChangeWatcher SPI To support change watchers that can be configured in config profile, also implement the ChangeWatcherProvider Java service loader SPI. ",
            "title": "ChangeWatcher SPI"
        },
        {
            "location": "/se/config/07_extensions",
            "text": " Once it loads a Config tree from ConfigSource s the config system does not itself change the in-memory Config tree. Even so, the underlying data available via the tree&#8217;s ConfigSource s can change. Implementations of PollingStrategy may trigger regular check whether a source has new data. Implementation of ChangeWatcher may watch the underlying source for changes and trigger an update. PollingStrategy SPI An implementation of PollingStrategy gets an instance to poll, and triggers its poll method. The result of poll method may be used to update the polling strategy schedule. The approach of checking for changes is part of the config system, and the PollingStrategy does not need to be concerned with it. This is based on the source stamp as defined in ConfigContent and used in PollableSource.isModified(Object) methods. If a more sophisticated solution is needed, you may need to implement a ChangeWatcher instead. The config system offers polling strategy for periodic time-based checks. Often an application can create a config source simply by using one of the methods on ConfigSources (for example, ConfigSources#file(path) to get a builder and then invoke pollingStrategy passing a polling strategy. But the application can implement its own PollingStrategy and set it on the config source builder instead. PollingStrategy SPI To support polling strategies that can be configured in config profile, also implement the PollingStrategyProvider Java service loader SPI. ChangeWatcher SPI An implementation of ChangeWatcher gets the underlying source information and a change listener. The \"watcher\" then watches for changes of the source and notifies the listener when a change occurs. This is designed to support sources that can react on changes (such as file system). When a polling mechanism is needed, please check PollingStrategy above. The config system offers a change watcher for any Path based config source (such as FileConfigSource ) and for the etcd config source. To use a change watcher, simply create a config source using its builder and register the change watcher on the builder (the config source must support appropriate type of change watchers). ChangeWatcher SPI To support change watchers that can be configured in config profile, also implement the ChangeWatcherProvider Java service loader SPI. ",
            "title": "Change support SPI"
        },
        {
            "location": "/se/config/07_extensions",
            "text": " The builder for each ConfigSource and OverrideSource accepts a RetryPolicy governing if and how the source should deal with failures loading the underlying data. A retry policy accepts a function, the invocation of which the policy will govern according to its own implementation. Applications can use the predefined policies in RetryPolicies , such as RetryPolicies.justCall which simply invokes the function without any retry. That class also exposes a builder for constructing a time-based retry policy, with several parameters: Parameters Controlling Built-in RetryPolicy Parameter Usage Default delay Initial delay between calls to the function 200 ms delayFactor Multiplier applied to delay on each successive call 2 callTimeout Time limit for each individual call of the function 500 ms overallTimeout Limit for the total elapsed time attempting to call the function successfully, including delays between calls 2 s The actual delay between function call starts as delay and changes by the factor delayFactor on each successive attempt. Note that the job of each retry policy is to call the provided function successfully. As such, the policy must perform the first attempt as well as any retries. RetryPolicy SPI The application can try to cancel the overall execution of a RetryPolicy by invoking the RetryPolicy#cancel(boolean mayInterruptIfRunning) method. Ideally the retry policy implementation should be able to abort the execution of the retry policy, even while a function call is in progress, but the policy must respond to cancels between function calls. In either case cancel returns true if the retry was aborted without a successful call to the function, and false otherwise, including if the function call had already completed successfully or had previously been successfully canceled. To support retry policies in config profiles, also implement the Java service loader SPI RetryPolicyProvider . ",
            "title": "RetryPolicy SPI"
        },
        {
            "location": "/mp/guides/15_migration",
            "text": " In Helidon 2.x we have made some changes to APIs and runtime behavior. This guide will help you migrate a Helidon MP 1.x application to 2.x. ",
            "title": "preambule"
        },
        {
            "location": "/mp/guides/15_migration",
            "text": " Java 8 is no longer supported. Java 11 or newer is required. ",
            "title": "Java 8 Runtime"
        },
        {
            "location": "/mp/guides/15_migration",
            "text": " Since Helidon 2.x now requires Java 11 the helper classes that were provided for Java 8 support have been removed. These have been replaced by the standard JDK classes: Removed Replacement io.helidon.reactive.Flow java.util.concurrent.Flow io.helidon.common.CollectionsHelper Factory methods of Set , Map and List io.helidon.common.OptionalHelper Methods of java.util.Optional io.helidon.common.StackWalker java.lang.StackWalker io.helidon.common.InputStreamHelper Methods of java.io.InputStream ",
            "title": "Common Utilities"
        },
        {
            "location": "/mp/guides/15_migration",
            "text": " We have upgraded to OpenTracing version 0.33.0 that is not backward compatible. OpenTracing introduced the following breaking changes: Removed Replacement ScopeManager.active() Tracer.activeSpan() ScopeManager.activate(Span, boolean) ScopeManager.activate(Span) - second parameter is now always false SpanBuilder.startActive() Tracer.activateSpan(Span) TextMapExtractAdapter and TextMapInjectAdapter TextMapAdapter Module name changed opentracing.api io.opentracing.api (same for noop and util ) If you use the TracerBuilder abstraction in Helidon and have no custom Spans, there is no change required ",
            "title": "Tracing"
        },
        {
            "location": "/mp/guides/15_migration",
            "text": " When the OIDC provider is configured to use cookie (default configuration) to carry authentication information, the cookie Same-Site is now set to Lax (used to be Strict ). This is to prevent infinite redirects, as browsers would refuse to set the cookie on redirected requests (due to this setting). Only in the case of the frontend host and identity host match, we leave Strict as the default ",
            "title": "Security: OIDC"
        },
        {
            "location": "/mp/guides/15_migration",
            "text": " We have removed the versioned MicroProfile bundles (i.e. helidon-microprofile-x.x ), and introduced unversioned core and full bundles: io.helidon.microprofile.bundles:helidon-microprofile-core - contains only MP Server and Config. Allows you to add only the specifications needed by your application. io.helidon.microprofile.bundles:helidon-microprofile - contains the latest full MicroProfile version implemented by Helidon ",
            "title": "MicroProfile Bundles"
        },
        {
            "location": "/mp/guides/15_migration",
            "text": " io.helidon.microprofile.server.Main has been deprecated. Use io.helidon.microprofile.cdi.Main instead. io.helidon.microprofile.server.Server is still available, although the features are much reduced. You no longer need to initialize Java Util Logging explicitly. Put logging.properties on the classpath or in the current directory to be automatically picked up to configure Java Util Logging. ",
            "title": "Application Main and Startup"
        },
        {
            "location": "/mp/guides/15_migration",
            "text": " Helidon 1.x usually required that you have an Application subclass that returned the Application classes to scan. For common cases this is no longer necessary, and you might be able to remove your Application class. JAX-RS applications now work similarly to how they work in application servers: if there is an Application subclass that returns anything from getClasses or getSingletons , it is used as is if there is an Application subclass that returns empty sets from these methods, all available resource classes will be part of such an application if there is no Application subclass, a synthetic application will be created with all available resource classes Application subclasses MUST be annotated with @ApplicationScoped , otherwise they are ignored ",
            "title": "JAX-RS Applications"
        },
        {
            "location": "/mp/guides/15_migration",
            "text": " If a JAX-RS application exists that is annotated with @LoginConfig with value MP-JWT, the correct authentication provider is added to security. The startup would fail if the provider is required yet not configured. ",
            "title": "MicroProfile JWT-Auth"
        },
        {
            "location": "/mp/guides/15_migration",
            "text": " If there is no authentication provider configured, authentication will now fail. If there is no authorization provider configured, the ABAC provider will be configured. In Helidon 1.x these were configured if there was no provider configured overall. ",
            "title": "Security in Helidon MP"
        },
        {
            "location": "/mp/guides/15_migration",
            "text": " In order to support GraalVM native-image we have had to re-implement how CDI is initialized and started. This has resulted in some changes in APIs and behavior: You can no longer start the CDI container yourself. You can only run a single instance of Server in a JVM. If you use SeContainerInitializer you will get an exception. This can be worked around by configuration property mp.initializer.allow=true , and warning can be removed using mp.initializer.no-warn=true Once SeContainerInitializer is used you can no longer use MP with native-image You can no longer provide a Context instance. The root context is now built-in. MpService and MpServiceContext have been removed. Methods from context have been moved to JaxRsCdiExtension and ServerCdiExtension . These can be accessed from CDI extension through BeanManager.getExtension . Methods register can be used on current io.helidon.context.Context MpService equivalent is a CDI extension. All Helidon services were refactored to CDI extension (you can use these for reference). Server.cdiContainer is removed, use CDI.current() instead. ",
            "title": "CDI and MicroProfile Server"
        },
        {
            "location": "/mp/guides/15_migration",
            "text": " Helidon now supports only MicroProfile Metrics 2.x. Support for Metrics 1.x has been removed, and modules for 2.x have been renamed from metrics2 to metrics . ",
            "title": "Metrics"
        },
        {
            "location": "/mp/guides/15_migration",
            "text": " We have moved from dependencies in groupId javax (Java EE modules) to dependencies in groupId jakarta (Jakarta EE modules). In case you declared a dependency on a javax module, you should change it to a jakarta one. Example: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;javax.activation&lt;/groupId&gt; &lt;artifactId&gt;javax.activation-api&lt;/artifactId&gt; &lt;/dependency&gt; should be changed to <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;jakarta.activation&lt;/groupId&gt; &lt;artifactId&gt;jakarta.activation-api&lt;/artifactId&gt; &lt;/dependency&gt; As the javax module is no longer in dependency management of Helidon parent pom files. ",
            "title": "Java EE dependencies"
        },
        {
            "location": "/mp/reactivemessaging/01_introduction",
            "text": " To enable MicroProfile Reactive Messaging add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.messaging&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-messaging&lt;/artifactId&gt; &lt;/dependency&gt; To include health checks for Messaging add the following dependency: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.messaging&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-messaging-health&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/reactivemessaging/01_introduction",
            "text": " The annotation has one required attribute value that defines the channel name. Such annotated messaging method can function in two ways: consume every message coming from the stream connected to the channel prepare reactive stream&#8217;s subscriber and connect it to the channel <markup lang=\"java\" title=\"Example consuming every message from channel example-channel-2 :\" >@Incoming(\"example-channel-2\") public void printMessage(String msg) { System.out.println(\"Just received message: \" + msg); } <markup lang=\"java\" title=\"Example preparing reactive stream subscriber for channel example-channel-1 :\" >@Incoming(\"example-channel-2\") public Subscriber&lt;String&gt; printMessage() { return ReactiveStreams.&lt;String&gt;builder() .forEach(msg -&gt; System.out.println(\"Just received message: \" + msg)) .build(); } ",
            "title": "Consuming methods with @Incoming annotation"
        },
        {
            "location": "/mp/reactivemessaging/01_introduction",
            "text": " The annotation has one required attribute value that defines the channel name. Such annotated messaging method can function in two ways: produce exactly one message to the stream connected to the channel prepare reactive stream&#8217;s publisher and connect it to the channel <markup lang=\"java\" title=\"Example producing exactly one message to channel example-channel-1 :\" >@Outgoing(\"example-channel-1\") public String produceMessage() { return \"foo\"; } <markup lang=\"java\" title=\"Example preparing reactive stream publisher publishing three messages to the channel example-channel-1 :\" >@Outgoing(\"example-channel-1\") public Publisher&lt;String&gt; printMessage() { return ReactiveStreams.of(\"foo\", \"bar\", \"baz\").buildRs(); } ",
            "title": "Producing methods with @Outgoing annotation"
        },
        {
            "location": "/mp/reactivemessaging/01_introduction",
            "text": " Such methods acts as processors, consuming messages from one channel and producing to another. Such annotated messaging method can function in multiple ways: process every message prepare reactive stream&#8217;s processor and connect it between the channels on every message prepare new publisher(equivalent to flatMap operator) <markup lang=\"java\" title=\"Example processing every message from channel example-channel-1 to channel example-channel-2 :\" >@Incoming(\"example-channel-1\") @Outgoing(\"example-channel-2\") public String processMessage(String msg) { return msg.toUpperCase(); } <markup lang=\"java\" title=\"Example preparing processor stream to be connected between channels example-channel-1 and example-channel-2 :\" >@Incoming(\"example-channel-1\") @Outgoing(\"example-channel-2\") public Processor&lt;String, String&gt; processMessage() { return ReactiveStreams.&lt;String&gt;builder() .map(String::toUpperCase) .buildRs(); } <markup lang=\"java\" title=\"Example processing every message from channel example-channel-1`as stream to be flattened to channel `example-channel-2 :\" >@Incoming(\"example-channel-1\") @Outgoing(\"example-channel-2\") public String processMessage(String msg) { return ReactiveStreams.of(msg.toUpperCase(), msg.toLowerCase()).buildRs(); } ",
            "title": "Processing methods with @Incoming and @Outgoing annotation"
        },
        {
            "location": "/mp/reactivemessaging/01_introduction",
            "text": " Messaging in Helidon has built in health probes for liveness and readiness. To activate it add the health check dependency . Liveness - channel is considered UP until cancel or onError signal is intercepted on it. Readiness - channel is considered DOWN until onSubscribe signal is intercepted on it. If you check your health endpoints /health/live and /health/ready you will discover every messaging channel to have its own probe. <markup lang=\"json\" >{ \"name\": \"messaging\", \"state\": \"UP\", \"status\": \"UP\", \"data\": { \"my-channel-1\": \"UP\", \"my-channel-2\": \"UP\" } } ",
            "title": "Health check"
        },
        {
            "location": "/mp/reactivemessaging/01_introduction",
            "text": " MicroProfile Reactive Messaging uses CDI beans to produce, consume or process messages over Reactive Streams. Such messaging bean is expected to be either in ApplicationScoped or Dependent scope. Messages are managed by methods annotated by @Incoming and @Outgoing and the invocation is always driven by message core - either at assembly time, or for every message coming from the stream. Messaging methods are not meant to be invoked directly! Terms definition messaging method bean method invoked by messaging Specification connector Reactive Messaging connector channel named pair of producer and consumer, both sides can be either messaging method or connector The bean can have methods annotated by @Incoming , @Outgoing or both. Consuming methods with @Incoming annotation The annotation has one required attribute value that defines the channel name. Such annotated messaging method can function in two ways: consume every message coming from the stream connected to the channel prepare reactive stream&#8217;s subscriber and connect it to the channel <markup lang=\"java\" title=\"Example consuming every message from channel example-channel-2 :\" >@Incoming(\"example-channel-2\") public void printMessage(String msg) { System.out.println(\"Just received message: \" + msg); } <markup lang=\"java\" title=\"Example preparing reactive stream subscriber for channel example-channel-1 :\" >@Incoming(\"example-channel-2\") public Subscriber&lt;String&gt; printMessage() { return ReactiveStreams.&lt;String&gt;builder() .forEach(msg -&gt; System.out.println(\"Just received message: \" + msg)) .build(); } Producing methods with @Outgoing annotation The annotation has one required attribute value that defines the channel name. Such annotated messaging method can function in two ways: produce exactly one message to the stream connected to the channel prepare reactive stream&#8217;s publisher and connect it to the channel <markup lang=\"java\" title=\"Example producing exactly one message to channel example-channel-1 :\" >@Outgoing(\"example-channel-1\") public String produceMessage() { return \"foo\"; } <markup lang=\"java\" title=\"Example preparing reactive stream publisher publishing three messages to the channel example-channel-1 :\" >@Outgoing(\"example-channel-1\") public Publisher&lt;String&gt; printMessage() { return ReactiveStreams.of(\"foo\", \"bar\", \"baz\").buildRs(); } Processing methods with @Incoming and @Outgoing annotation Such methods acts as processors, consuming messages from one channel and producing to another. Such annotated messaging method can function in multiple ways: process every message prepare reactive stream&#8217;s processor and connect it between the channels on every message prepare new publisher(equivalent to flatMap operator) <markup lang=\"java\" title=\"Example processing every message from channel example-channel-1 to channel example-channel-2 :\" >@Incoming(\"example-channel-1\") @Outgoing(\"example-channel-2\") public String processMessage(String msg) { return msg.toUpperCase(); } <markup lang=\"java\" title=\"Example preparing processor stream to be connected between channels example-channel-1 and example-channel-2 :\" >@Incoming(\"example-channel-1\") @Outgoing(\"example-channel-2\") public Processor&lt;String, String&gt; processMessage() { return ReactiveStreams.&lt;String&gt;builder() .map(String::toUpperCase) .buildRs(); } <markup lang=\"java\" title=\"Example processing every message from channel example-channel-1`as stream to be flattened to channel `example-channel-2 :\" >@Incoming(\"example-channel-1\") @Outgoing(\"example-channel-2\") public String processMessage(String msg) { return ReactiveStreams.of(msg.toUpperCase(), msg.toLowerCase()).buildRs(); } Health check Messaging in Helidon has built in health probes for liveness and readiness. To activate it add the health check dependency . Liveness - channel is considered UP until cancel or onError signal is intercepted on it. Readiness - channel is considered DOWN until onSubscribe signal is intercepted on it. If you check your health endpoints /health/live and /health/ready you will discover every messaging channel to have its own probe. <markup lang=\"json\" >{ \"name\": \"messaging\", \"state\": \"UP\", \"status\": \"UP\", \"data\": { \"my-channel-1\": \"UP\", \"my-channel-2\": \"UP\" } } ",
            "title": "Reactive Messaging"
        },
        {
            "location": "/se/oci/04_atp",
            "text": " The Helidon SE OCI Autonomous Transaction Processing integration provides a reactive API to ATP database in Oracle cloud. ",
            "title": "preambule"
        },
        {
            "location": "/se/oci/04_atp",
            "text": " The custom Helidon SE OCI clients documented here are deprecated. It is recommended that you use the OCI Java SDK directly, in particular the Async clients. For more information see: OCI Database Documentation OCI Database Javadoc Helidon SE OCI ATP Example ",
            "title": "Deprecated"
        },
        {
            "location": "/se/oci/04_atp",
            "text": " Helidon integration with Oracle Cloud Infrastructure is still experimental and not intended for production use. APIs and features have not yet been fully tested and are subject to change. ",
            "title": "Experimental"
        },
        {
            "location": "/se/oci/04_atp",
            "text": " To enable OCI Autonomous Transaction Processing add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.oci&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-oci-atp&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/oci/04_atp",
            "text": " In order to use the OCI Autonomous Transaction Processing integration, the following setup should be made: <markup lang=\"java\" >Config ociConfig = config.get(\"oci\"); OciAutonomousDbRx ociAutonomousDb = OciAutonomousDbRx.create(ociConfig); Current configuration requires ~/.oci/config to be available in the home folder. This configuration file can be downloaded from OCI. Routing should be added to the WebServer , in our case pointing to /atp : <markup lang=\"java\" > WebServer.builder() .config(config.get(\"server\")) .routing(Routing.builder() .register(\"/atp\", new AtpService(autonomousDbRx, config))) .build(); Additionally, in application.yaml OCI properties should be specified: <markup lang=\"yaml\" >oci: atp: ocid: \"&lt;ocid of your ATP database&gt;\" walletPassword: \"&lt;password to encrypt the keys inside the wallet&gt;\" The exact values are available from OCI console. ",
            "title": "Setting up the Autonomous Transaction Processing"
        },
        {
            "location": "/se/oci/04_atp",
            "text": " To generate wallet file for OCI Autonomous Transaction Processing: <markup lang=\"java\" > private void generateWallet(ServerRequest req, ServerResponse res) { autonomousDbRx.generateWallet(GenerateAutonomousDatabaseWallet.Request.builder()) .flatMapOptional(ApiOptionalResponse::entity) .map(GenerateAutonomousDatabaseWallet.Response::walletArchive) .ifEmpty(() -&gt; LOGGER.severe(\"Unable to obtain wallet!\")) .flatMapSingle(this::createDbClient) .flatMap(dbClient -&gt; dbClient.execute(exec -&gt; exec.query(\"SELECT 'Hello world!!' FROM DUAL\"))) .first() .map(dbRow -&gt; dbRow.column(1).as(String.class)) .ifEmpty(() -&gt; res.status(404).send()) .onError(res::send) .forSingle(res::send); } Create the Request using GenerateAutonomousDatabaseWallet.Request.builder() Retrieve 'walletArchive' from the response. Create DBClient using info from 'walletArchive' Read the first column from first row of result. For complete code, about how to create DBClient using wallet info, please see ATP Reactive Example ",
            "title": "Generate Wallet"
        },
        {
            "location": "/se/oci/04_atp",
            "text": " In the Service we must specify the mapping for operations with the database and their handlers: <markup lang=\"java\" >@Override public void update(Routing.Rules rules) { rules.get(\"/wallet\", this::generateWallet); } Generate Wallet To generate wallet file for OCI Autonomous Transaction Processing: <markup lang=\"java\" > private void generateWallet(ServerRequest req, ServerResponse res) { autonomousDbRx.generateWallet(GenerateAutonomousDatabaseWallet.Request.builder()) .flatMapOptional(ApiOptionalResponse::entity) .map(GenerateAutonomousDatabaseWallet.Response::walletArchive) .ifEmpty(() -&gt; LOGGER.severe(\"Unable to obtain wallet!\")) .flatMapSingle(this::createDbClient) .flatMap(dbClient -&gt; dbClient.execute(exec -&gt; exec.query(\"SELECT 'Hello world!!' FROM DUAL\"))) .first() .map(dbRow -&gt; dbRow.column(1).as(String.class)) .ifEmpty(() -&gt; res.status(404).send()) .onError(res::send) .forSingle(res::send); } Create the Request using GenerateAutonomousDatabaseWallet.Request.builder() Retrieve 'walletArchive' from the response. Create DBClient using info from 'walletArchive' Read the first column from first row of result. For complete code, about how to create DBClient using wallet info, please see ATP Reactive Example ",
            "title": "Using the Autonomous Transaction Processing"
        },
        {
            "location": "/mp/reactivestreams/02_engine",
            "text": "",
            "title": "Helidon Reactive Engine"
        },
        {
            "location": "/mp/reactivestreams/02_engine",
            "text": " To enable Reactive Engine add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.common&lt;/groupId&gt; &lt;artifactId&gt;helidon-common-reactive&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/reactivestreams/02_engine",
            "text": " In the situations when part of the operator chain needs to be prepared in advance, compose and to operators are at hand. <markup lang=\"java\" title=\"Combining operator chains:\" > // Assembly of stream, nothing is streamed yet Multi&lt;String&gt; publisherStage = Multi.just(\"foo\", \"bar\") .map(String::trim); Function&lt;Multi&lt;T&gt;, Multi&lt;T&gt;&gt; processorStage = upstream -&gt; upstream.map(String::toUpperCase); // Execution of pre-prepared stream publisherStage .compose(processorStage) .map(s -&gt; \"Item received: \" + s) .forEach(System.out::println); &gt; Item received: FOO &gt; Item received: BAR ",
            "title": "Operator chains composition"
        },
        {
            "location": "/mp/reactivestreams/02_engine",
            "text": " Helidon has its own set of reactive operators that have no dependencies outside of the Helidon ecosystem. These operators can be used with java.util.concurrent.Flow based reactive streams. Stream processing operator chain can be easily constructed by io.helidon.common.reactive.Multi , or io.helidon.common.reactive.Single for streams with single value. <markup lang=\"java\" title=\"Example of Multi usage:\" >AtomicInteger sum = new AtomicInteger(); Multi.just(\"1\", \"2\", \"3\", \"4\", \"5\") .limit(3) .map(Integer::parseInt) .forEach(sum::addAndGet); System.out.println(\"Sum: \" + sum.get()); &gt; Sum: 6 <markup lang=\"java\" title=\"Example of Single usage:\" >Single.just(\"1\") .map(Integer::parseInt) .map(i -&gt; i + 5) .toStage() .whenComplete((i, t) -&gt; System.out.println(\"Result: \" + i)); &gt; Result: 6 Operators defer Call the given supplier function for each individual downstream Subscriber to return a Flow.Publisher to subscribe to. map Map this Multi instance to a new Multi of another type using the given Mapper . defaultIfEmpty Signals the default item if the upstream is empty. switchIfEmpty Switch to the other publisher if the upstream is empty. peek Invoke provided consumer for every item in stream. distinct Filter out all duplicates. filter Filter stream items with provided predicate. takeWhile Take the longest prefix of elements from this stream that satisfy the given predicate. As long as predicate returns true, items from upstream are sent to downstream, when predicate returns false stream is completed. dropWhile Drop the longest prefix of elements from this stream that satisfy the given predicate. As long as predicate returns true, items from upstream are NOT sent to downstream but being dropped, predicate is never called again after it returns false for the first time. limit Limit stream to allow only specified number of items to pass. skip Skip first n items, all the others are emitted. flatMap Transform each upstream item with the supplied function into a Flow.Publisher , subscribe to them and then flatten their items into a single sequence of items emitted to the downstream. flatMap Transform each upstream item with the supplied function and flatten the resulting Flow.Publisher to downstream while limiting the maximum number of concurrent inner `Flow.Publisher`s and their in-flight item count, optionally aggregating and delaying all errors until all sources terminate. flatMapCompletionStage Transform each upstream item with the supplied function and flatten the resulting CompletionStage results to downstream. flatMapIterable Transform each upstream item with the supplied function and flatten the resulting Iterable to the downstream. flatMapOptional Transform each upstream item with the supplied function and flatten the resulting Optional to the downstream as item if present. observeOn Re-emit the upstream&#8217;s signals to the downstream on the given executor&#8217;s thread using a default buffer size of 32 and errors skipping ahead of items. observeOn Re-emit the upstream&#8217;s signals to the downstream on the given executor&#8217;s thread. forEach Terminal stage, invokes provided consumer for every item in the stream. collectList Collect the items of this Multi instance into a Single of List . collect Collect the items of this Multi instance into a Single . collect Collect the items of this Multi into a collection provided via a Supplier and mutated by a BiConsumer callback. collectStream Collects up upstream items with the help of the callbacks of a java.util.stream.Collector . reduce Combine subsequent items via a callback function and emit the final value result as a Single. reduce Combine every upstream item with an accumulator value to produce a new accumulator value and emit the final accumulator value as a Single. first Get the first item of this Multi instance as a Single . from Wrap a CompletionStage into a Multi and signal its outcome non-blockingly. from Wrap a CompletionStage into a Multi and signal its outcome non-blockingly. from Create a Multi instance wrapped around the given publisher. from Create a Multi instance that publishes the given iterable. from Create a Multi instance that publishes the given Stream . just Create a Multi instance that publishes the given items to a single subscriber. just Create a Multi instance that publishes the given items to a single subscriber. singleton Create a Multi that emits a pre-existing item and then completes. error Create a Multi instance that reports the given exception to its subscriber(s). The exception is reported by invoking Subscriber#onError(java.lang.Throwable) when Publisher#subscribe(Subscriber) is called. empty Get a Multi instance that completes immediately. never Get a Multi instance that never completes. concat Concat streams to one. onTerminate Executes given java.lang.Runnable when any of signals onComplete, onCancel or onError is received. ifEmpty Executes given java.lang.Runnable when stream is finished without value(empty stream). onComplete Executes given java.lang.Runnable when onComplete signal is received. onError Executes the given java.util.function.Consumer when an onError signal is received. onCancel Executes given java.lang.Runnable when a cancel signal is received. takeUntil Relay upstream items until the other source signals an item or completes. range Emits a range of ever increasing integers. rangeLong Emits a range of ever increasing longs. timer Signal 0L and complete the sequence after the given time elapsed. interval Signal 0L, 1L and so on periodically to the downstream. interval Signal 0L after an initial delay, then 1L, 2L and so on periodically to the downstream. timeout Signals a TimeoutException if the upstream doesn&#8217;t signal the next item, error or completion within the specified time. timeout Switches to a fallback source if the upstream doesn&#8217;t signal the next item, error or completion within the specified time. onErrorResume java.util.function.Function providing one item to be submitted as onNext in case of onError signal is received. onErrorResumeWith Resume stream from supplied publisher if onError signal is intercepted. retry Retry a failing upstream at most the given number of times before giving up. retry Retry a failing upstream if the predicate returns true. retryWhen Retry a failing upstream when the given function returns a publisher that signals an item. Operator chains composition In the situations when part of the operator chain needs to be prepared in advance, compose and to operators are at hand. <markup lang=\"java\" title=\"Combining operator chains:\" > // Assembly of stream, nothing is streamed yet Multi&lt;String&gt; publisherStage = Multi.just(\"foo\", \"bar\") .map(String::trim); Function&lt;Multi&lt;T&gt;, Multi&lt;T&gt;&gt; processorStage = upstream -&gt; upstream.map(String::toUpperCase); // Execution of pre-prepared stream publisherStage .compose(processorStage) .map(s -&gt; \"Item received: \" + s) .forEach(System.out::println); &gt; Item received: FOO &gt; Item received: BAR ",
            "title": "Reactive Engine"
        },
        {
            "location": "/se/reactivestreams/03_rsoperators",
            "text": " To enable Reactive Streams add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.reactive-streams&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-reactive-streams&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/reactivestreams/03_rsoperators",
            "text": " Graphs are pre-prepared stream builders with stages , which can be combined together to closed graph with methods via and to . <markup lang=\"java\" title=\"Combining the graphs and running the stream:\" > // Assembly of stream, nothing is streamed yet PublisherBuilder&lt;String&gt; publisherStage = ReactiveStreams.of(\"foo\", \"bar\") .map(String::trim); ProcessorBuilder&lt;String, String&gt; processorStage = ReactiveStreams.&lt;String&gt;builder() .map(String::toUpperCase); SubscriberBuilder&lt;String, Void&gt; subscriberStage = ReactiveStreams.&lt;String&gt;builder() .map(s -&gt; \"Item received: \" + s) .forEach(System.out::println); // Execution of pre-prepared stream publisherStage .via(processorStage) .to(subscriberStage).run(); &gt; Item received: FOO &gt; Item received: BAR ",
            "title": "Graphs"
        },
        {
            "location": "/se/reactivestreams/03_rsoperators",
            "text": " Implementation of MicroProfile Reactive Streams Operators specification. A standardised tool for manipulation with Reactive Streams , provides set of operators as so called stages, and the builders to prepare graphs of stages for streams to be build from. <markup lang=\"java\" title=\"Example of simple closed graph usage:\" >AtomicInteger sum = new AtomicInteger(); ReactiveStreams.of(\"1\", \"2\", \"3\", \"4\", \"5\") .limit(3) .map(Integer::parseInt) .forEach(sum::addAndGet) .run() .whenComplete((r, t) -&gt; System.out.println(\"Sum: \" + sum.get())); &gt; Sum: 6 Operators(Stages) fromIterable Create new PublisherBuilder from supplied Iterable of Create new PublisherBuilder emitting supplied elements ofNullable Empty stream if supplied item is null iterate Create infinite stream with every next item created by supplied operator from previous item generate Create infinite stream with every item created by invocation of supplier empty Create new PublisherBuilder emitting as a first thing complete signal failed Create new PublisherBuilder emitting as a first thing error signal concat Concat two streams coupled Two parallel streams sharing cancel, onError and onComplete signals limit Limit the size of the stream, when limit is reached completes peek Invoke consumer for every item passing this operator filter Drop item when expression result to false map Transform items flatMap Flatten supplied stream to current stream flatMapIterable Flatten supplied iterable to current stream flatMapCompletionStage Map elements to completion stage and wait for each to be completed, keeps the order flatMapRSPublisher Map elements to Publishers and flatten this sub streams to original stream takeWhile Let items pass until expression is true, first time its false completes dropWhile Drop items until expression is true, first time its false let everything pass skip Drop first n items distinct Let pass only distinct items via Connect supplied processor to current stream return supplied processor onError Invoke supplied consumer when onError signal received onErrorResume Emit one last supplied item when onError signal received onErrorResumeWith When onError signal received continue emitting from supplied publisher builder onErrorResumeWithRsPublisher When onError signal received continue emitting from supplied publisher onComplete Invoke supplied runnable when onComplete signal received onTerminate Invoke supplied runnable when onComplete or onError signal received ifEmpty Executes given java.lang.Runnable when stream is finished without value(empty stream). to Connect this stream to supplied subscriber toList Collect all intercepted items to List collect Collect all intercepted items with provided collector forEach Invoke supplied Consumer for each intercepted item ignore Ignore all onNext signals, wait for onComplete reduce Reduction with provided expression cancel Cancel stream immediately findFirst Return first intercepted element Graphs Graphs are pre-prepared stream builders with stages , which can be combined together to closed graph with methods via and to . <markup lang=\"java\" title=\"Combining the graphs and running the stream:\" > // Assembly of stream, nothing is streamed yet PublisherBuilder&lt;String&gt; publisherStage = ReactiveStreams.of(\"foo\", \"bar\") .map(String::trim); ProcessorBuilder&lt;String, String&gt; processorStage = ReactiveStreams.&lt;String&gt;builder() .map(String::toUpperCase); SubscriberBuilder&lt;String, Void&gt; subscriberStage = ReactiveStreams.&lt;String&gt;builder() .map(s -&gt; \"Item received: \" + s) .forEach(System.out::println); // Execution of pre-prepared stream publisherStage .via(processorStage) .to(subscriberStage).run(); &gt; Item received: FOO &gt; Item received: BAR ",
            "title": "Reactive Streams Operators"
        },
        {
            "location": "/se/tracing/04_jaeger_metrics",
            "text": " Integrate the metrics from Jaeger tracing into your Helidon SE application simply by adding a dependency. ",
            "title": "preambule"
        },
        {
            "location": "/se/tracing/04_jaeger_metrics",
            "text": " As the Helidon Jaeger Tracing document describes, you can use Jaeger tracing in your Helidon SE application. Jaeger maintains several metrics about its own activity (briefly outlined in the Jaeger client documentation ). This document explains how you can integrate those Jaeger tracing metrics with Helidon&#8217;s metrics. ",
            "title": "Overview"
        },
        {
            "location": "/se/tracing/04_jaeger_metrics",
            "text": " Your pom.xml file should already contain the dependency for Helidon-Jaeger tracing integration. To enable integration with Jaeger&#8217;s metrics, add the following dependency: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics-jaeger&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; You can leave your application&#8217;s Java code unchanged. By adding this dependency, you instruct Helidon to monitor the Jaeger tracing metrics internally and to publish them using the Helidon metrics system. Rebuild and start your application. ",
            "title": "Prerequisites"
        },
        {
            "location": "/se/tracing/04_jaeger_metrics",
            "text": " Submit a few requests to your application&#8217;s endpoints. This causes Jaeger to update its internal metrics. Then, when you access your application&#8217;s metrics endpoint ( /metrics by default), Helidon displays the updated Jaeger tracing metrics as part of the vendor metrics section. <markup lang=\"bash\" >curl -H \"Accept: application/json\" -X GET http://localhost:8080/metrics/vendor <markup lang=\"json\" title=\"Partial Helidon Metrics vendor Output Showing Jaeger Metrics\" > ... \"jaeger_tracer_baggage_restrictions_updates;result=err\": 0, \"jaeger_tracer_baggage_restrictions_updates;result=ok\": 0, \"jaeger_tracer_baggage_truncations\": 0, \"jaeger_tracer_baggage_updates;result=err\": 0, \"jaeger_tracer_baggage_updates;result=ok\": 0, \"jaeger_tracer_finished_spans\": 0, \"jaeger_tracer_reporter_queue_length\": 0, \"jaeger_tracer_reporter_spans;result=dropped\": 0, \"jaeger_tracer_reporter_spans;result=err\": 0, \"jaeger_tracer_reporter_spans;result=ok\": 0, \"jaeger_tracer_sampler_queries;result=err\": 1, \"jaeger_tracer_sampler_queries;result=ok\": 0, \"jaeger_tracer_sampler_updates;result=err\": 0, \"jaeger_tracer_sampler_updates;result=ok\": 0, \"jaeger_tracer_span_context_decoding_errors\": 0, \"jaeger_tracer_started_spans;sampled=n\": 15, \"jaeger_tracer_started_spans;sampled=y\": 0, \"jaeger_tracer_traces;sampled=n;state=joined\": 2, \"jaeger_tracer_traces;sampled=n;state=started\": 3, \"jaeger_tracer_traces;sampled=y;state=joined\": 0, \"jaeger_tracer_traces;sampled=y;state=started\": 0, ... Helidon publishes whatever metrics Jaeger creates. ",
            "title": "Accessing Jaeger Tracing Metrics"
        },
        {
            "location": "/mp/security/01_security",
            "text": " To add security, such as protecting resource methods with authentication, to a MicroProfile application, add the Helidon security integration dependency to your project. ",
            "title": "preambule"
        },
        {
            "location": "/mp/security/01_security",
            "text": " For JAX-RS resources, declare security by adding annotations to a resource class or method. <markup lang=\"java\" title=\"Protected resource method\" >@GET @io.helidon.security.annotations.Authenticated @io.helidon.security.annotations.Authorized // you can also use io.helidon.security.abac.role.RoleValidator.Roles @RolesAllowed(\"admin\") public String adminResource(@Context io.helidon.security.SecurityContext securityContext) { return \"you are \" + securityContext.userName(); } Security in Helidon MicroProfile is built on top of Jersey&#8217;s and can be enabled/disabled using the property security.jersey.enabled=[true|false] . ",
            "title": "Securing a JAX-RS Resource"
        },
        {
            "location": "/mp/security/01_security",
            "text": " The configuration is usually placed under security.web-server (this can be customized in Helidon SE). The following shows an example we will explain in detail: <markup lang=\"yaml\" title=\"application.yaml\" >security: providers: - abac: - provider-key: web-server: defaults: authenticate: true paths: - path: \"/metrics[/{*}]\" roles-allowed: \"admin\" - path: \"/health[/{*}]\" roles-allowed: \"monitor\" - path: \"/openapi[/{*}]\" abac: scopes: [\"openapi\"] - path: \"/static[/{*}]\" roles-allowed: [\"user\", \"monitor\"] Attribute based access control provider that checks roles and scopes The provider(s) used in your application, such as oidc Default configuration for all configured paths Protection of /metrics and all nested paths with admin role required Protection of /health and all nested paths with monitor role required Protection of /openapi and all nested paths with openapi scope required Protection of static content configured on /static path with either user or monitor role required If you need to use a properties file, such as microprofile-config.properties , you can convert the file by using index based numbers for arrays, such as: <markup lang=\"properties\" title=\"microprofile-config.properties\" >security.providers.0.abac= security.providers.1.provider-key.optional=false security.web-server.defaults.authenticate=true security.web-server.paths.0.path=/metrics[/{*}] security.web-server.paths.0.roles-allowed=admin # .... security.web-server.paths.3.path=/static[/{*}] security.web-server.paths.3.roles-allowed=user,monitor ",
            "title": "Configuring endpoint protection"
        },
        {
            "location": "/mp/security/01_security",
            "text": " There are several endpoints provided by Helidon services, such as: Health endpoint ( /health ) Metrics endpoint ( /metrics ) OpenAPI endpoint ( /openapi ) Configured static content (can use any path configured) These endpoints are all implemented using Helidon reactive WebServer and as such can be protected only through Security integration with WebServer. The following section describes configuration of such protection using configuration files, in this case using a yaml file, as it provides a tree structure. Configuring endpoint protection The configuration is usually placed under security.web-server (this can be customized in Helidon SE). The following shows an example we will explain in detail: <markup lang=\"yaml\" title=\"application.yaml\" >security: providers: - abac: - provider-key: web-server: defaults: authenticate: true paths: - path: \"/metrics[/{*}]\" roles-allowed: \"admin\" - path: \"/health[/{*}]\" roles-allowed: \"monitor\" - path: \"/openapi[/{*}]\" abac: scopes: [\"openapi\"] - path: \"/static[/{*}]\" roles-allowed: [\"user\", \"monitor\"] Attribute based access control provider that checks roles and scopes The provider(s) used in your application, such as oidc Default configuration for all configured paths Protection of /metrics and all nested paths with admin role required Protection of /health and all nested paths with monitor role required Protection of /openapi and all nested paths with openapi scope required Protection of static content configured on /static path with either user or monitor role required If you need to use a properties file, such as microprofile-config.properties , you can convert the file by using index based numbers for arrays, such as: <markup lang=\"properties\" title=\"microprofile-config.properties\" >security.providers.0.abac= security.providers.1.provider-key.optional=false security.web-server.defaults.authenticate=true security.web-server.paths.0.path=/metrics[/{*}] security.web-server.paths.0.roles-allowed=admin # .... security.web-server.paths.3.path=/static[/{*}] security.web-server.paths.3.roles-allowed=user,monitor ",
            "title": "Protecting Helidon endpoints"
        },
        {
            "location": "/mp/security/01_security",
            "text": " To enable Security add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-security&lt;/artifactId&gt; &lt;/dependency&gt; Securing a JAX-RS Resource For JAX-RS resources, declare security by adding annotations to a resource class or method. <markup lang=\"java\" title=\"Protected resource method\" >@GET @io.helidon.security.annotations.Authenticated @io.helidon.security.annotations.Authorized // you can also use io.helidon.security.abac.role.RoleValidator.Roles @RolesAllowed(\"admin\") public String adminResource(@Context io.helidon.security.SecurityContext securityContext) { return \"you are \" + securityContext.userName(); } Security in Helidon MicroProfile is built on top of Jersey&#8217;s and can be enabled/disabled using the property security.jersey.enabled=[true|false] . Protecting Helidon endpoints There are several endpoints provided by Helidon services, such as: Health endpoint ( /health ) Metrics endpoint ( /metrics ) OpenAPI endpoint ( /openapi ) Configured static content (can use any path configured) These endpoints are all implemented using Helidon reactive WebServer and as such can be protected only through Security integration with WebServer. The following section describes configuration of such protection using configuration files, in this case using a yaml file, as it provides a tree structure. Configuring endpoint protection The configuration is usually placed under security.web-server (this can be customized in Helidon SE). The following shows an example we will explain in detail: <markup lang=\"yaml\" title=\"application.yaml\" >security: providers: - abac: - provider-key: web-server: defaults: authenticate: true paths: - path: \"/metrics[/{*}]\" roles-allowed: \"admin\" - path: \"/health[/{*}]\" roles-allowed: \"monitor\" - path: \"/openapi[/{*}]\" abac: scopes: [\"openapi\"] - path: \"/static[/{*}]\" roles-allowed: [\"user\", \"monitor\"] Attribute based access control provider that checks roles and scopes The provider(s) used in your application, such as oidc Default configuration for all configured paths Protection of /metrics and all nested paths with admin role required Protection of /health and all nested paths with monitor role required Protection of /openapi and all nested paths with openapi scope required Protection of static content configured on /static path with either user or monitor role required If you need to use a properties file, such as microprofile-config.properties , you can convert the file by using index based numbers for arrays, such as: <markup lang=\"properties\" title=\"microprofile-config.properties\" >security.providers.0.abac= security.providers.1.provider-key.optional=false security.web-server.defaults.authenticate=true security.web-server.paths.0.path=/metrics[/{*}] security.web-server.paths.0.roles-allowed=admin # .... security.web-server.paths.3.path=/static[/{*}] security.web-server.paths.3.roles-allowed=user,monitor ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/guides/06_tracing",
            "text": " This guide describes how to create a sample Helidon SE project that can be used to run some basic examples using tracing with a Helidon SE application. ",
            "title": "preambule"
        },
        {
            "location": "/se/guides/06_tracing",
            "text": " For this 30 minute tutorial, you will need the following: <div class=\"table__overflow elevation-1 flex sm7 \"> A Helidon {upper-case-flavor} Application You can use your own application or use the Helidon {upper-case-flavor} Quickstart to create a sample application. Java&#160;SE&#160;11 ( Open&#160;JDK&#160;11 ) Helidon requires Java 11+. Maven 3.6.1+ Helidon requires Maven 3.6.1+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop ). <markup lang=\"bash\" title=\"Verify Prerequisites\" >java -version mvn --version docker --version kubectl version --short <markup lang=\"bash\" title=\"Setting JAVA_HOME\" ># On Mac export JAVA_HOME=`/usr/libexec/java_home -v 11` # On Linux # Use the appropriate path to your JDK export JAVA_HOME=/usr/lib/jvm/jdk-11 ",
            "title": "What You Need"
        },
        {
            "location": "/se/guides/06_tracing",
            "text": " This section explains a few concepts that you need to understand before you get started with tracing. In the context of this document, a service is synonymous with an application. A span is the basic unit of work done within a single service, on a single host. Every span has a name, starting timestamp, and duration. For example, the work done by a REST endpoint is a span. A span is associated to a single service, but its descendants can belong to different services and hosts. A trace contains a collection of spans from one or more services, running on one or more hosts. For example, if you trace a service endpoint that calls another service, then the trace would contain spans from both services. Within a trace, spans are organized as a directed acyclic graph (DAG) and can belong to multiple services, running on multiple hosts. The OpenTracing Data Model describes the details at The OpenTracing Semantic Specification . Spans are automatically created by Helidon as needed during execution of the REST request. ",
            "title": "Tracing Concepts"
        },
        {
            "location": "/se/guides/06_tracing",
            "text": " Distributed tracing is a critical feature of micro-service based applications, since it traces workflow both within a service and across multiple services. This provides insight to sequence and timing data for specific blocks of work, which helps you identify performance and operational issues. Helidon SE includes support for distributed tracing through the OpenTracing API . Tracing is integrated with WebServer, gRPC Server, and Security using either the Zipkin or Jaeger tracers. Tracing Concepts This section explains a few concepts that you need to understand before you get started with tracing. In the context of this document, a service is synonymous with an application. A span is the basic unit of work done within a single service, on a single host. Every span has a name, starting timestamp, and duration. For example, the work done by a REST endpoint is a span. A span is associated to a single service, but its descendants can belong to different services and hosts. A trace contains a collection of spans from one or more services, running on one or more hosts. For example, if you trace a service endpoint that calls another service, then the trace would contain spans from both services. Within a trace, spans are organized as a directed acyclic graph (DAG) and can belong to multiple services, running on multiple hosts. The OpenTracing Data Model describes the details at The OpenTracing Semantic Specification . Spans are automatically created by Helidon as needed during execution of the REST request. ",
            "title": "Introduction"
        },
        {
            "location": "/se/guides/06_tracing",
            "text": " Use the Helidon SE Maven archetype to create a simple project that can be used for the examples in this guide. <markup lang=\"bash\" title=\"Run the Maven archetype:\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-se \\ -DarchetypeVersion=2.5.4 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-se \\ -Dpackage=io.helidon.examples.quickstart.se <markup lang=\"bash\" title=\"The project will be built and run from the helidon-quickstart-se directory:\" >cd helidon-quickstart-se ",
            "title": "Create a Sample Helidon SE Project"
        },
        {
            "location": "/se/guides/06_tracing",
            "text": " First, you need to run the Zipkin tracer. Helidon will communicate with this tracer at runtime. <markup lang=\"bash\" title=\"Run Zipkin within a docker container, then check the Zipkin server health:\" >docker run -d --name zipkin -p 9411:9411 openzipkin/zipkin Run the Zipkin docker image named openzipkin/zipkin . <markup lang=\"bash\" title=\"Check the Zipkin server health:\" >curl http://localhost:9411/health ... { \"status\": \"UP\", \"zipkin\": { \"status\": \"UP\", \"details\": { \"InMemoryStorage{}\": { \"status\": \"UP\" } } } } Invoke the Zipkin REST API to check the Zipkin server health. All status fields should be UP . ",
            "title": "Set up Zipkin"
        },
        {
            "location": "/se/guides/06_tracing",
            "text": " Update the pom.xml file and add the following Zipkin dependency to the &lt;dependencies&gt; section ( not &lt;dependencyManagement&gt; ). This will enable Helidon to use Zipkin at the default host and port, localhost:9411 . <markup lang=\"xml\" title=\"Add the following dependency to pom.xml :\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-zipkin&lt;/artifactId&gt; &lt;/dependency&gt; All spans sent by Helidon to Zipkin need to be associated with a service. Specify the service name below. <markup lang=\"bash\" title=\"Add the following line to resources/application.yaml :\" >tracing: service: helidon-se-1 <markup lang=\"java\" title=\"Update the Main class; Add Tracer to the WebServer builder\" >import io.helidon.tracing.TracerBuilder; ... WebServer server = WebServer.builder(createRouting(config)) .config(config.get(\"server\")) .tracer(TracerBuilder.create(config.get(\"tracing\")).build()) .addMediaSupport(JsonpSupport.create()) .build(); Add a new import statement. Build and register a Tracer object using the tracing configuration. <markup lang=\"java\" title=\"Update the GreetService class; 1) Add a new import and 2) Replace the getDefaultMessageHandler method:\" >import io.opentracing.Span; ... private void getDefaultMessageHandler(ServerRequest request, ServerResponse response) { var spanBuilder = request.tracer() .buildSpan(\"getDefaultMessageHandler\"); request.spanContext().ifPresent(spanBuilder::asChildOf); Span span = spanBuilder.start(); try { sendResponse(response, \"World\"); } finally { span.finish(); } } Add new import statement. Get the Tracer object from the request. Build a new span named getDefaultMessageHandler . Make the new span a child of the current span. Start the span. The current timestamp is used as the starting time for the span. Finish the span. The current timestamp is used as the ending time for the span. <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-se.jar <markup lang=\"bash\" title=\"Run the curl command in a new terminal window and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"Hello World!\" } ",
            "title": "Enable Tracing in the Helidon Application"
        },
        {
            "location": "/se/guides/06_tracing",
            "text": " Because you had tracing enabled, the previous /greet endpoint invocation resulted in a new trace being created. Let&#8217;s get the trace data that was generated using the Zipkin API. First, get the service information. <markup lang=\"bash\" title=\"Run the curl command and check the response:\" >curl http://localhost:9411/api/v2/services ... [\"helidon-se-1\"] This is the tracing service name specified in resources/application.yaml . Each span used by a service has a name, which is unique within a trace. If you invoke the /greet endpoint multiple times, you will still get the same set of names. <markup lang=\"bash\" title=\"Invoke the endpoint below and check the response:\" > curl -X GET \"http://localhost:9411/api/v2/spans?serviceName=helidon-se-1\" -H \"accept: application/json\" ... [ \"content-write\", \"getdefaultmessagehandler\", \"http request\" ] Get the span names for the helidon-se-1 service. These are the span names. If you invoke the /greet endpoint again, then invoke the /spans endpoint, you will get the same response. Next, get the spans in the trace as shown below. <markup lang=\"bash\" title=\"Invoke the endpoint below and check the response:\" > curl -X GET \"http://localhost:9411/api/v2/traces?serviceName=helidon-se-1&amp;limit=1\" -H \"accept: application/json\" ... [ [ { \"traceId\": \"f193adb3f2bab3b3\", \"parentId\": \"f193adb3f2bab3b3\", \"id\": \"1536021daf3845e1\", \"kind\": \"SERVER\", \"name\": \"content-write\", \"timestamp\": 1568245972222815, \"duration\": 527, \"localEndpoint\": { \"serviceName\": \"helidon-se-1\", \"ipv4\": \"192.168.1.115\" }, \"tags\": { \"response.type\": \"org.glassfish.json.JsonObjectBuilderImpl$JsonObjectImpl\" } }, ... (truncated) ] Get the newest trace only, using the limit=1 query param. There are other query params that let you restrict results to a specific time window. The request will return 3 spans, one for each name. Each span has a parentId field, except the http request span, which is the root. ",
            "title": "Viewing Tracing Using Zipkin REST API"
        },
        {
            "location": "/se/guides/06_tracing",
            "text": " The tracing output data is verbose and can be difficult to interpret using the REST API, especially since it represents a structure of spans. Zipkin provides a web-based UI at http://localhost:9411/zipkin , where you can see a visual representation of the same data and the relationship between spans within a trace. Click on the UI refresh button (the search icon) as shown in the image below. Notice that you can change the look-back time to restrict the trace list. Trace refresh The image below shows the trace summary, including start time and duration of each trace. There are two traces, each one generated in response to a curl http://localhost:8080/greet invocation. The oldest trace will have a much longer duration since there is one-time initialization that occurs. Tracing list view Click on a trace and you will see the trace detail page where the spans are listed. You can clearly see the root span and the relationship among all the spans in the trace, along with timing information. Trace detail page A parent span might not depend on the result of the child. This is called a FollowsFrom reference, see Open Tracing Semantic Spec . You can examine span details by clicking on the span row. Refer to the image below, which shows the span details, including timing information. You can see times for each space relative to the root span. These rows are annotated with Server Start and Server Finish , as shown in the third column. Span detail page ",
            "title": "Viewing Tracing Using Zipkin UI"
        },
        {
            "location": "/se/guides/06_tracing",
            "text": " Helidon automatically traces across services, providing that the services use the same tracer, for example, the same instance of Zipkin. This means a single trace can include spans from multiple services and hosts. OpenTracing uses a SpanContext to propagate tracing information across process boundaries. When you make client API calls, Helidon will internally call OpenTracing APIs to propagate the SpanContext . There is nothing you need to do in your application to make this work. To demonstrate distributed tracing, you will need to create a second project, where the server listens on port 8081. Create a new root directory to hold this new project, then do the following steps, similar to what you did at the start of this guide: ",
            "title": "Tracing Across Services"
        },
        {
            "location": "/se/guides/06_tracing",
            "text": "<markup lang=\"bash\" title=\"Run the Maven archetype:\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-se \\ -DarchetypeVersion=2.5.4 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-se-2 \\ -Dpackage=io.helidon.examples.quickstart.se <markup lang=\"bash\" title=\"The project will be built and run from the helidon-quickstart-se directory:\" >cd helidon-quickstart-se-2 <markup lang=\"xml\" title=\"Add the following dependency to pom.xml :\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-zipkin&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"bash\" title=\"Replace resources/application.yaml with the following:\" >app: greeting: \"Hello From SE-2\" tracing: service: \"helidon-se-2\" server: port: 8081 host: 0.0.0.0 <markup lang=\"java\" title=\"Update the Main class; Add Tracer to the WebServer builder\" >import io.helidon.tracing.TracerBuilder; ... WebServer server = WebServer.builder(createRouting(config)) .config(config.get(\"server\")) .tracer(TracerBuilder.create(config.get(\"tracing\")).build()) .addMediaSupport(JsonpSupport.create()) .build(); <markup lang=\"java\" title=\"Update the GreetService class; 1) Add new import and 2) Replace the getDefaultMessageHandler method:\" >import io.opentracing.Span; ... private void getDefaultMessageHandler(ServerRequest request, ServerResponse response) { var spanBuilder = request.tracer() .buildSpan(\"getDefaultMessageHandler\"); request.spanContext().ifPresent(spanBuilder::asChildOf); Span span = spanBuilder.start(); try { sendResponse(response, \"World\"); } finally { span.finish(); } } <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-se-2.jar <markup lang=\"bash\" title=\"Run the curl command in a new terminal window and check the response ( notice the port is 8081 ) :\" >curl http://localhost:8081/greet ... { \"message\": \"Hello From SE-2 World!\" } ",
            "title": "Create the Second Service"
        },
        {
            "location": "/se/guides/06_tracing",
            "text": " Once you have validated that the second service is running correctly, you need to modify the original application to call it. <markup lang=\"xml\" title=\"Add the following dependency to pom.xml :\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.integration&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-integration-jersey&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-jersey-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.glassfish.jersey.core&lt;/groupId&gt; &lt;artifactId&gt;jersey-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.glassfish.jersey.inject&lt;/groupId&gt; &lt;artifactId&gt;jersey-hk2&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"java\" title=\"Replace the GreetService class with the following code:\" >package io.helidon.examples.quickstart.se; import io.helidon.common.http.Http; import io.helidon.config.Config; import io.helidon.tracing.jersey.client.ClientTracingFilter; import io.helidon.webserver.Routing; import io.helidon.webserver.ServerRequest; import io.helidon.webserver.ServerResponse; import io.helidon.webserver.Service; import io.opentracing.Span; import java.util.Collections; import java.util.concurrent.atomic.AtomicReference; import javax.json.Json; import javax.json.JsonBuilderFactory; import javax.json.JsonObject; import javax.ws.rs.client.Client; import javax.ws.rs.client.ClientBuilder; import javax.ws.rs.client.Invocation; import javax.ws.rs.client.WebTarget; public class GreetService implements Service { private final AtomicReference&lt;String&gt; greeting = new AtomicReference&lt;&gt;(); private WebTarget webTarget; private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); GreetService(Config config) { greeting.set(config.get(\"app.greeting\").asString().orElse(\"Ciao\")); Client jaxRsClient = ClientBuilder.newBuilder().build(); webTarget = jaxRsClient.target(\"http://localhost:8081/greet\"); } @Override public void update(Routing.Rules rules) { rules .get(\"/\", this::getDefaultMessageHandler) .get(\"/outbound\", this::outboundMessageHandler) .put(\"/greeting\", this::updateGreetingHandler); } private void getDefaultMessageHandler(ServerRequest request, ServerResponse response) { var spanBuilder = request.tracer() .buildSpan(\"getDefaultMessageHandler\"); request.spanContext().ifPresent(spanBuilder::asChildOf); Span span = spanBuilder.start(); try { sendResponse(response, \"World\"); } finally { span.finish(); } } private void sendResponse(ServerResponse response, String name) { String msg = String.format(\"%s %s!\", greeting.get(), name); JsonObject returnObject = JSON.createObjectBuilder().add(\"message\", msg).build(); response.send(returnObject); } private void updateGreetingFromJson(JsonObject jo, ServerResponse response) { if (!jo.containsKey(\"greeting\")) { JsonObject jsonErrorObject = JSON.createObjectBuilder().add(\"error\", \"No greeting provided\").build(); response.status(Http.Status.BAD_REQUEST_400).send(jsonErrorObject); return; } greeting.set(jo.getString(\"greeting\")); response.status(Http.Status.NO_CONTENT_204).send(); } private void outboundMessageHandler(ServerRequest request, ServerResponse response) { Invocation.Builder requestBuilder = webTarget.request(); var spanBuilder = request.tracer() .buildSpan(\"outboundMessageHandler\"); request.spanContext().ifPresent(spanBuilder::asChildOf); Span span = spanBuilder.start(); try { requestBuilder.property( ClientTracingFilter.CURRENT_SPAN_CONTEXT_PROPERTY_NAME, request.spanContext()); requestBuilder .rx() .get(String.class) .thenAccept(response::send) .exceptionally( throwable -&gt; { // process exception response.status(Http.Status.INTERNAL_SERVER_ERROR_500); response.send(\"Failed with: \" + throwable); return null; }); } finally { span.finish(); } } private void updateGreetingHandler(ServerRequest request, ServerResponse response) { request.content().as(JsonObject.class).thenAccept(jo -&gt; updateGreetingFromJson(jo, response)); } } Add outboundMessageHandler to the routing rules. Create and start a span that is a child of the current span. Set a property with the SpanContext . Invoke the second service. Stop the span. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl -i http://localhost:8080/greet/outbound ... { \"message\": \"Hello From SE-2 World!\" } The request went to the service on 8080 , which then invoked the service at 8081 to get the greeting. Notice the greeting came from the second service. Refresh the Zipkin UI trace listing page and notice that there is a trace across two services. Tracing multiple service list view Click on the trace with two services to see the detail view. Tracing across multiple services detail view In the image above, you can see that the trace includes spans from two services. You will notice there is a gap before the sixth span, which is a get operation. This is a one-time client initialization delay. Run the /outbound curl command again and look at the new trace to see that the delay no longer exists. You can now stop your second service, it is not longer used in this guide. ",
            "title": "Modify the First Service"
        },
        {
            "location": "/se/guides/06_tracing",
            "text": " The examples in this guide demonstrate how to integrate tracing with Helidon, how to view traces, how to trace across multiple services, and how to integrate with tracing with Kubernetes. All examples use Zipkin and traces will be viewed using both the Zipkin API and UI. Create a Sample Helidon SE Project Use the Helidon SE Maven archetype to create a simple project that can be used for the examples in this guide. <markup lang=\"bash\" title=\"Run the Maven archetype:\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-se \\ -DarchetypeVersion=2.5.4 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-se \\ -Dpackage=io.helidon.examples.quickstart.se <markup lang=\"bash\" title=\"The project will be built and run from the helidon-quickstart-se directory:\" >cd helidon-quickstart-se Set up Zipkin First, you need to run the Zipkin tracer. Helidon will communicate with this tracer at runtime. <markup lang=\"bash\" title=\"Run Zipkin within a docker container, then check the Zipkin server health:\" >docker run -d --name zipkin -p 9411:9411 openzipkin/zipkin Run the Zipkin docker image named openzipkin/zipkin . <markup lang=\"bash\" title=\"Check the Zipkin server health:\" >curl http://localhost:9411/health ... { \"status\": \"UP\", \"zipkin\": { \"status\": \"UP\", \"details\": { \"InMemoryStorage{}\": { \"status\": \"UP\" } } } } Invoke the Zipkin REST API to check the Zipkin server health. All status fields should be UP . Enable Tracing in the Helidon Application Update the pom.xml file and add the following Zipkin dependency to the &lt;dependencies&gt; section ( not &lt;dependencyManagement&gt; ). This will enable Helidon to use Zipkin at the default host and port, localhost:9411 . <markup lang=\"xml\" title=\"Add the following dependency to pom.xml :\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-zipkin&lt;/artifactId&gt; &lt;/dependency&gt; All spans sent by Helidon to Zipkin need to be associated with a service. Specify the service name below. <markup lang=\"bash\" title=\"Add the following line to resources/application.yaml :\" >tracing: service: helidon-se-1 <markup lang=\"java\" title=\"Update the Main class; Add Tracer to the WebServer builder\" >import io.helidon.tracing.TracerBuilder; ... WebServer server = WebServer.builder(createRouting(config)) .config(config.get(\"server\")) .tracer(TracerBuilder.create(config.get(\"tracing\")).build()) .addMediaSupport(JsonpSupport.create()) .build(); Add a new import statement. Build and register a Tracer object using the tracing configuration. <markup lang=\"java\" title=\"Update the GreetService class; 1) Add a new import and 2) Replace the getDefaultMessageHandler method:\" >import io.opentracing.Span; ... private void getDefaultMessageHandler(ServerRequest request, ServerResponse response) { var spanBuilder = request.tracer() .buildSpan(\"getDefaultMessageHandler\"); request.spanContext().ifPresent(spanBuilder::asChildOf); Span span = spanBuilder.start(); try { sendResponse(response, \"World\"); } finally { span.finish(); } } Add new import statement. Get the Tracer object from the request. Build a new span named getDefaultMessageHandler . Make the new span a child of the current span. Start the span. The current timestamp is used as the starting time for the span. Finish the span. The current timestamp is used as the ending time for the span. <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-se.jar <markup lang=\"bash\" title=\"Run the curl command in a new terminal window and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"Hello World!\" } Viewing Tracing Using Zipkin REST API Because you had tracing enabled, the previous /greet endpoint invocation resulted in a new trace being created. Let&#8217;s get the trace data that was generated using the Zipkin API. First, get the service information. <markup lang=\"bash\" title=\"Run the curl command and check the response:\" >curl http://localhost:9411/api/v2/services ... [\"helidon-se-1\"] This is the tracing service name specified in resources/application.yaml . Each span used by a service has a name, which is unique within a trace. If you invoke the /greet endpoint multiple times, you will still get the same set of names. <markup lang=\"bash\" title=\"Invoke the endpoint below and check the response:\" > curl -X GET \"http://localhost:9411/api/v2/spans?serviceName=helidon-se-1\" -H \"accept: application/json\" ... [ \"content-write\", \"getdefaultmessagehandler\", \"http request\" ] Get the span names for the helidon-se-1 service. These are the span names. If you invoke the /greet endpoint again, then invoke the /spans endpoint, you will get the same response. Next, get the spans in the trace as shown below. <markup lang=\"bash\" title=\"Invoke the endpoint below and check the response:\" > curl -X GET \"http://localhost:9411/api/v2/traces?serviceName=helidon-se-1&amp;limit=1\" -H \"accept: application/json\" ... [ [ { \"traceId\": \"f193adb3f2bab3b3\", \"parentId\": \"f193adb3f2bab3b3\", \"id\": \"1536021daf3845e1\", \"kind\": \"SERVER\", \"name\": \"content-write\", \"timestamp\": 1568245972222815, \"duration\": 527, \"localEndpoint\": { \"serviceName\": \"helidon-se-1\", \"ipv4\": \"192.168.1.115\" }, \"tags\": { \"response.type\": \"org.glassfish.json.JsonObjectBuilderImpl$JsonObjectImpl\" } }, ... (truncated) ] Get the newest trace only, using the limit=1 query param. There are other query params that let you restrict results to a specific time window. The request will return 3 spans, one for each name. Each span has a parentId field, except the http request span, which is the root. Viewing Tracing Using Zipkin UI The tracing output data is verbose and can be difficult to interpret using the REST API, especially since it represents a structure of spans. Zipkin provides a web-based UI at http://localhost:9411/zipkin , where you can see a visual representation of the same data and the relationship between spans within a trace. Click on the UI refresh button (the search icon) as shown in the image below. Notice that you can change the look-back time to restrict the trace list. Trace refresh The image below shows the trace summary, including start time and duration of each trace. There are two traces, each one generated in response to a curl http://localhost:8080/greet invocation. The oldest trace will have a much longer duration since there is one-time initialization that occurs. Tracing list view Click on a trace and you will see the trace detail page where the spans are listed. You can clearly see the root span and the relationship among all the spans in the trace, along with timing information. Trace detail page A parent span might not depend on the result of the child. This is called a FollowsFrom reference, see Open Tracing Semantic Spec . You can examine span details by clicking on the span row. Refer to the image below, which shows the span details, including timing information. You can see times for each space relative to the root span. These rows are annotated with Server Start and Server Finish , as shown in the third column. Span detail page Tracing Across Services Helidon automatically traces across services, providing that the services use the same tracer, for example, the same instance of Zipkin. This means a single trace can include spans from multiple services and hosts. OpenTracing uses a SpanContext to propagate tracing information across process boundaries. When you make client API calls, Helidon will internally call OpenTracing APIs to propagate the SpanContext . There is nothing you need to do in your application to make this work. To demonstrate distributed tracing, you will need to create a second project, where the server listens on port 8081. Create a new root directory to hold this new project, then do the following steps, similar to what you did at the start of this guide: Create the Second Service <markup lang=\"bash\" title=\"Run the Maven archetype:\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-se \\ -DarchetypeVersion=2.5.4 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-se-2 \\ -Dpackage=io.helidon.examples.quickstart.se <markup lang=\"bash\" title=\"The project will be built and run from the helidon-quickstart-se directory:\" >cd helidon-quickstart-se-2 <markup lang=\"xml\" title=\"Add the following dependency to pom.xml :\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-zipkin&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"bash\" title=\"Replace resources/application.yaml with the following:\" >app: greeting: \"Hello From SE-2\" tracing: service: \"helidon-se-2\" server: port: 8081 host: 0.0.0.0 <markup lang=\"java\" title=\"Update the Main class; Add Tracer to the WebServer builder\" >import io.helidon.tracing.TracerBuilder; ... WebServer server = WebServer.builder(createRouting(config)) .config(config.get(\"server\")) .tracer(TracerBuilder.create(config.get(\"tracing\")).build()) .addMediaSupport(JsonpSupport.create()) .build(); <markup lang=\"java\" title=\"Update the GreetService class; 1) Add new import and 2) Replace the getDefaultMessageHandler method:\" >import io.opentracing.Span; ... private void getDefaultMessageHandler(ServerRequest request, ServerResponse response) { var spanBuilder = request.tracer() .buildSpan(\"getDefaultMessageHandler\"); request.spanContext().ifPresent(spanBuilder::asChildOf); Span span = spanBuilder.start(); try { sendResponse(response, \"World\"); } finally { span.finish(); } } <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-se-2.jar <markup lang=\"bash\" title=\"Run the curl command in a new terminal window and check the response ( notice the port is 8081 ) :\" >curl http://localhost:8081/greet ... { \"message\": \"Hello From SE-2 World!\" } Modify the First Service Once you have validated that the second service is running correctly, you need to modify the original application to call it. <markup lang=\"xml\" title=\"Add the following dependency to pom.xml :\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.integration&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-integration-jersey&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-jersey-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.glassfish.jersey.core&lt;/groupId&gt; &lt;artifactId&gt;jersey-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.glassfish.jersey.inject&lt;/groupId&gt; &lt;artifactId&gt;jersey-hk2&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"java\" title=\"Replace the GreetService class with the following code:\" >package io.helidon.examples.quickstart.se; import io.helidon.common.http.Http; import io.helidon.config.Config; import io.helidon.tracing.jersey.client.ClientTracingFilter; import io.helidon.webserver.Routing; import io.helidon.webserver.ServerRequest; import io.helidon.webserver.ServerResponse; import io.helidon.webserver.Service; import io.opentracing.Span; import java.util.Collections; import java.util.concurrent.atomic.AtomicReference; import javax.json.Json; import javax.json.JsonBuilderFactory; import javax.json.JsonObject; import javax.ws.rs.client.Client; import javax.ws.rs.client.ClientBuilder; import javax.ws.rs.client.Invocation; import javax.ws.rs.client.WebTarget; public class GreetService implements Service { private final AtomicReference&lt;String&gt; greeting = new AtomicReference&lt;&gt;(); private WebTarget webTarget; private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); GreetService(Config config) { greeting.set(config.get(\"app.greeting\").asString().orElse(\"Ciao\")); Client jaxRsClient = ClientBuilder.newBuilder().build(); webTarget = jaxRsClient.target(\"http://localhost:8081/greet\"); } @Override public void update(Routing.Rules rules) { rules .get(\"/\", this::getDefaultMessageHandler) .get(\"/outbound\", this::outboundMessageHandler) .put(\"/greeting\", this::updateGreetingHandler); } private void getDefaultMessageHandler(ServerRequest request, ServerResponse response) { var spanBuilder = request.tracer() .buildSpan(\"getDefaultMessageHandler\"); request.spanContext().ifPresent(spanBuilder::asChildOf); Span span = spanBuilder.start(); try { sendResponse(response, \"World\"); } finally { span.finish(); } } private void sendResponse(ServerResponse response, String name) { String msg = String.format(\"%s %s!\", greeting.get(), name); JsonObject returnObject = JSON.createObjectBuilder().add(\"message\", msg).build(); response.send(returnObject); } private void updateGreetingFromJson(JsonObject jo, ServerResponse response) { if (!jo.containsKey(\"greeting\")) { JsonObject jsonErrorObject = JSON.createObjectBuilder().add(\"error\", \"No greeting provided\").build(); response.status(Http.Status.BAD_REQUEST_400).send(jsonErrorObject); return; } greeting.set(jo.getString(\"greeting\")); response.status(Http.Status.NO_CONTENT_204).send(); } private void outboundMessageHandler(ServerRequest request, ServerResponse response) { Invocation.Builder requestBuilder = webTarget.request(); var spanBuilder = request.tracer() .buildSpan(\"outboundMessageHandler\"); request.spanContext().ifPresent(spanBuilder::asChildOf); Span span = spanBuilder.start(); try { requestBuilder.property( ClientTracingFilter.CURRENT_SPAN_CONTEXT_PROPERTY_NAME, request.spanContext()); requestBuilder .rx() .get(String.class) .thenAccept(response::send) .exceptionally( throwable -&gt; { // process exception response.status(Http.Status.INTERNAL_SERVER_ERROR_500); response.send(\"Failed with: \" + throwable); return null; }); } finally { span.finish(); } } private void updateGreetingHandler(ServerRequest request, ServerResponse response) { request.content().as(JsonObject.class).thenAccept(jo -&gt; updateGreetingFromJson(jo, response)); } } Add outboundMessageHandler to the routing rules. Create and start a span that is a child of the current span. Set a property with the SpanContext . Invoke the second service. Stop the span. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl -i http://localhost:8080/greet/outbound ... { \"message\": \"Hello From SE-2 World!\" } The request went to the service on 8080 , which then invoked the service at 8081 to get the greeting. Notice the greeting came from the second service. Refresh the Zipkin UI trace listing page and notice that there is a trace across two services. Tracing multiple service list view Click on the trace with two services to see the detail view. Tracing across multiple services detail view In the image above, you can see that the trace includes spans from two services. You will notice there is a gap before the sixth span, which is a get operation. This is a one-time client initialization delay. Run the /outbound curl command again and look at the new trace to see that the delay no longer exists. You can now stop your second service, it is not longer used in this guide. ",
            "title": "Getting Started with Tracing"
        },
        {
            "location": "/se/guides/06_tracing",
            "text": "<markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named zipkin.yaml , with the following contents:\" >apiVersion: v1 kind: Service metadata: name: zipkin spec: ports: - port: 9411 protocol: TCP selector: app: zipkin --- kind: Pod apiVersion: v1 metadata: name: zipkin labels: app: zipkin spec: containers: - name: zipkin image: openzipkin/zipkin imagePullPolicy: IfNotPresent ports: - containerPort: 9411 <markup lang=\"bash\" title=\"Create the Zipkin pod and ClusterIP service:\" >kubectl apply -f ./zipkin.yaml <markup lang=\"bash\" title=\"Create a Zipkin external server to view the UI and expose it on port 9142:\" >kubectl expose pod zipkin --name=zipkin-external --port=9412 --target-port=9411 --type=LoadBalancer Navigate to http://localhost:9412/zipkin to validate that you can access Zipkin running in Kubernetes. It may take a few seconds before it is ready. ",
            "title": "Deploy Zipkin into Kubernetes"
        },
        {
            "location": "/se/guides/06_tracing",
            "text": "<markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named tracing.yaml , with the following contents:\" >kind: Service apiVersion: v1 metadata: name: helidon-tracing labels: app: helidon-tracing spec: type: NodePort selector: app: helidon-tracing ports: - port: 8080 targetPort: 8080 name: http --- kind: Deployment apiVersion: apps/v1 metadata: name: helidon-tracing spec: replicas: 1 selector: matchLabels: app: helidon-tracing template: metadata: labels: app: helidon-tracing version: v1 spec: containers: - name: helidon-tracing image: helidon-tracing-se imagePullPolicy: IfNotPresent ports: - containerPort: 8080 A service of type NodePort that serves the default routes on port 8080 . A deployment with one replica of a pod. <markup lang=\"bash\" title=\"Create and deploy the application into Kubernetes:\" >kubectl apply -f ./tracing.yaml ",
            "title": "Deploy Your Helidon Application into Kubernetes"
        },
        {
            "location": "/se/guides/06_tracing",
            "text": "<markup lang=\"bash\" title=\"Get the application service information:\" >kubectl get service/helidon-tracing <markup lang=\"bash\" >NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE helidon-tracing NodePort 10.99.159.2 &lt;none&gt; 8080:31143/TCP 8s A service of type NodePort that serves the default routes on port 31143 . <markup lang=\"bash\" title=\"Verify the tracing endpoint using port 31143 , your port will likely be different:\" >curl http://localhost:31143/greet ... { \"message\": \"Hello World!\" } Access the Zipkin UI at http://localhost:9412/zipkin and click on the refresh icon to see the trace that was just created. ",
            "title": "Access Your Application and the Zipkin Trace"
        },
        {
            "location": "/se/guides/06_tracing",
            "text": " You can now delete the Kubernetes resources that were just created during this example. <markup lang=\"bash\" title=\"Delete the Kubernetes resources:\" >kubectl delete -f ./zipkin.yaml kubectl delete -f ./tracing.yaml kubectl delete service zipkin-external docker rm -f zipkin ",
            "title": "Cleanup"
        },
        {
            "location": "/se/guides/06_tracing",
            "text": " The following example demonstrate how to use Zipkin from a Helidon application running in Kubernetes. <markup lang=\"bash\" title=\"Replace the tracing configuration in resources/application.yaml with the following:\" > tracing: service: helidon-se-1 host: zipkin Helidon service helidon-se-1 will connect to the Zipkin server at host name zipkin . <markup lang=\"bash\" title=\"Stop the application and build the docker image for your application:\" >docker build -t helidon-tracing-se . Deploy Zipkin into Kubernetes <markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named zipkin.yaml , with the following contents:\" >apiVersion: v1 kind: Service metadata: name: zipkin spec: ports: - port: 9411 protocol: TCP selector: app: zipkin --- kind: Pod apiVersion: v1 metadata: name: zipkin labels: app: zipkin spec: containers: - name: zipkin image: openzipkin/zipkin imagePullPolicy: IfNotPresent ports: - containerPort: 9411 <markup lang=\"bash\" title=\"Create the Zipkin pod and ClusterIP service:\" >kubectl apply -f ./zipkin.yaml <markup lang=\"bash\" title=\"Create a Zipkin external server to view the UI and expose it on port 9142:\" >kubectl expose pod zipkin --name=zipkin-external --port=9412 --target-port=9411 --type=LoadBalancer Navigate to http://localhost:9412/zipkin to validate that you can access Zipkin running in Kubernetes. It may take a few seconds before it is ready. Deploy Your Helidon Application into Kubernetes <markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named tracing.yaml , with the following contents:\" >kind: Service apiVersion: v1 metadata: name: helidon-tracing labels: app: helidon-tracing spec: type: NodePort selector: app: helidon-tracing ports: - port: 8080 targetPort: 8080 name: http --- kind: Deployment apiVersion: apps/v1 metadata: name: helidon-tracing spec: replicas: 1 selector: matchLabels: app: helidon-tracing template: metadata: labels: app: helidon-tracing version: v1 spec: containers: - name: helidon-tracing image: helidon-tracing-se imagePullPolicy: IfNotPresent ports: - containerPort: 8080 A service of type NodePort that serves the default routes on port 8080 . A deployment with one replica of a pod. <markup lang=\"bash\" title=\"Create and deploy the application into Kubernetes:\" >kubectl apply -f ./tracing.yaml Access Your Application and the Zipkin Trace <markup lang=\"bash\" title=\"Get the application service information:\" >kubectl get service/helidon-tracing <markup lang=\"bash\" >NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE helidon-tracing NodePort 10.99.159.2 &lt;none&gt; 8080:31143/TCP 8s A service of type NodePort that serves the default routes on port 31143 . <markup lang=\"bash\" title=\"Verify the tracing endpoint using port 31143 , your port will likely be different:\" >curl http://localhost:31143/greet ... { \"message\": \"Hello World!\" } Access the Zipkin UI at http://localhost:9412/zipkin and click on the refresh icon to see the trace that was just created. Cleanup You can now delete the Kubernetes resources that were just created during this example. <markup lang=\"bash\" title=\"Delete the Kubernetes resources:\" >kubectl delete -f ./zipkin.yaml kubectl delete -f ./tracing.yaml kubectl delete service zipkin-external docker rm -f zipkin ",
            "title": "Integration with Kubernetes"
        },
        {
            "location": "/se/guides/06_tracing",
            "text": " This guide has demonstrated how to use the Helidon SE tracing feature with Zipkin. You have learned to do the following: Enable tracing within a service Use tracing with JAX-RS Use the Zipkin REST API and UI Use tracing across multiple services Integrate tracing with Kubernetes Refer to the following references for additional information: MicroProfile OpenTracing specification at https://github.com/eclipse/microprofile-opentracing/releases/tag/1.3 Helidon Javadoc at https://helidon.io/docs/latest/apidocs/index.html?overview-summary.html ",
            "title": "Summary"
        },
        {
            "location": "/about/02_introduction",
            "text": " Helidon is a collection of Java libraries for writing microservices that run on a fast web core powered by Netty. Its available in two frameworks: Helidon SE and Helidon MP. ",
            "title": "preambule"
        },
        {
            "location": "/about/02_introduction",
            "text": " Helidon provides an open source, lightweight, fast, reactive, cloud native framework for developing Java microservices. Helidon implements and supports MicroProfile, a baseline platform definition that leverages Java EE and Jakarta EE technologies for microservices and delivers application portability across multiple runtimes. ",
            "title": "A Collection of Java Libraries"
        },
        {
            "location": "/about/02_introduction",
            "text": " Helidon libraries interoperate with popular tools from the cloud-native space, so there&#8217;s no need for any specific tooling or deployment model. Helidon can be used with: Docker Kubernetes Prometheus OpenTracing Etcd The Helidon Quickstart Examples contain support for Docker and Kubernetes. ",
            "title": "Using Cloud-native Tools with Helidon"
        },
        {
            "location": "/about/02_introduction",
            "text": " Helidon supports two programming models for writing microservices: Helidon SE and Helidon MP . SE is designed to be a microframework that supports the reactive programming model, while Helidon MP is an Eclipse MicroProfile runtime that allows the Jakarta EE community to run microservices in a portable way. The table below shows to primary differences between Helidon SE and Helidon MP. Helidon SE Helidon MP Helidon SE gives you full transparency and puts you in control. Helidon MP is built on top of the Helidon libraries and provides platform definition that is familiar to enterprise Java developers. Microframework model with a very small footprint and limited functionality (~7 MB) Eclipse MicroProfile implementation; slightly larger footprint than SE (~13 MB) Functional style is reactive non-blocking Declarative style with dependency injection Transparent \"no magic\" development experience; pure java application development with no annotations and no dependency injections Jakarta EE microprofile development experience; all Jakarta components (CDI, JAX-RS, JSON-P/B) Learn more about Helidon SE . Learn more about Helidon MP . ",
            "title": "Understanding the Helidon Frameworks"
        },
        {
            "location": "/about/02_introduction",
            "text": " The Helidon 2.0 release contains significant new features, enhancements and fixes. For a complete list of fixes and enhancements, see the Helidon 2.0 changelog . GraalVM Native-image Support in Helidon MP Helidon SE already supports GraalVM, but in 2.0 GraalVM native image support will also be available in Helidon MP. GraalVM Native Images Guide Helidon Command Line Tool One of the new features in Helidon 2.0 is the addition of a command line interface. The Helidon CLI enables developers to get started with Helidon with minimal effort: you can create a new application, build it, run it, and more, by writing some simple commands. DB Client for Helidon SE The new database client for Helidon SE will include support for the MongoDB reactive driver and brings Health Checks, Metrics, and Tracing support to every Helidon API. Learn more about the DB Client . Extending MicroProfile Reactive Messaging and Reactive Operators Support MP Reactive Operators will be included in both frameworks, while MP Reactive Messaging will only be included in Helidon MP. Learn more about Reactive Messaging and Reactive Streams . Helidon Web Client The new reactive web client can integrate with other Helidon SE APIs. Learn more about the Helidon Web Client . Additional Websocket Support Based upon the Tyrus implementation, Helidon receives WebSocket API support. Learn more about Websocket Support . Support for Java 11 APIs Helidon will require Java 11 or newer. Learn more about the prerequisites for Helidon 2.0 . CORS support for MP and SE Although it is possible for any Helidon application to implement its own support for CORS, there are common tasks (such as processing preflight requests) that can be provided in a Helidon module. Learn more about CORS support . Backward Incompatible Changes View the changelog for information about potential breaking changes, including package name changes. ",
            "title": "What&#8217;s New in Helidon 2.0"
        },
        {
            "location": "/about/02_introduction",
            "text": " Try the Helidon Quickstart Examples . ",
            "title": "Next Steps"
        },
        {
            "location": "/se/webserver/08_json-support",
            "text": " To enable JSON Support add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.media&lt;/groupId&gt; &lt;artifactId&gt;helidon-media-jsonp&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/webserver/08_json-support",
            "text": " To enable JSON-P support, first register it with the web server. Then you can add routes that handle and return JSON. <markup lang=\"java\" title=\"Configure JsonpSupport and use it for reading and writing of entities\" >JsonpSupport jsonbSupport = JsonpSupport.create(); WebServer webServer = WebServer.builder() .addMediaSupport(jsonpSupport) .build(); Register JsonpSupport to enable transformation from and to JsonObject objects Register that JsonpSupport instance to enable automatic deserialization of Java objects from and serialization of Java objects to JSON. <markup lang=\"java\" title=\"Handler that receives and returns JSON objects\" >private static final JsonBuilderFactory JSON_FACTORY = Json.createBuilderFactory(Collections.emptyMap()); private void sayHello(ServerRequest req, ServerResponse res, JsonObject json) { JsonObject msg = JSON_FACTORY.createObjectBuilder() .add(\"message\", \"Hello \" + json.getString(\"name\")) .build(); res.send(msg); } Using a JsonBuilderFactory is more efficient than Json.createObjectBuilder() JsonObject is passed to handler Create a JsonObject using JSON-P to hold return data Send JsonObject in response <markup lang=\"bash\" title=\"Example of posting JSON to sayHello endpoint\" >curl --noproxy '*' -X POST -H \"Content-Type: application/json\" \\ http://localhost:8080/sayhello -d '{\"name\":\"Joe\"}' {\"message\":\"Hello Joe\"} ",
            "title": "Usage"
        },
        {
            "location": "/se/webserver/08_json-support",
            "text": " To configure JSON-P JsonReaderFactory and JsonWriterFactory that are used by the JsonpSupport instance, create the JsonpSupport object: <markup lang=\"java\" title=\"Create JsonpSupport with the provided configuration\" >JsonpSupport.create(Map.of(JsonGenerator.PRETTY_PRINTING, false)) ",
            "title": "Configuring Json Reader/Writer factories"
        },
        {
            "location": "/se/webserver/08_json-support",
            "text": " The WebServer supports JSON-P. When enabled, you can send and receive JSON-P objects transparently. Usage To enable JSON-P support, first register it with the web server. Then you can add routes that handle and return JSON. <markup lang=\"java\" title=\"Configure JsonpSupport and use it for reading and writing of entities\" >JsonpSupport jsonbSupport = JsonpSupport.create(); WebServer webServer = WebServer.builder() .addMediaSupport(jsonpSupport) .build(); Register JsonpSupport to enable transformation from and to JsonObject objects Register that JsonpSupport instance to enable automatic deserialization of Java objects from and serialization of Java objects to JSON. <markup lang=\"java\" title=\"Handler that receives and returns JSON objects\" >private static final JsonBuilderFactory JSON_FACTORY = Json.createBuilderFactory(Collections.emptyMap()); private void sayHello(ServerRequest req, ServerResponse res, JsonObject json) { JsonObject msg = JSON_FACTORY.createObjectBuilder() .add(\"message\", \"Hello \" + json.getString(\"name\")) .build(); res.send(msg); } Using a JsonBuilderFactory is more efficient than Json.createObjectBuilder() JsonObject is passed to handler Create a JsonObject using JSON-P to hold return data Send JsonObject in response <markup lang=\"bash\" title=\"Example of posting JSON to sayHello endpoint\" >curl --noproxy '*' -X POST -H \"Content-Type: application/json\" \\ http://localhost:8080/sayhello -d '{\"name\":\"Joe\"}' {\"message\":\"Hello Joe\"} Configuring Json Reader/Writer factories To configure JSON-P JsonReaderFactory and JsonWriterFactory that are used by the JsonpSupport instance, create the JsonpSupport object: <markup lang=\"java\" title=\"Create JsonpSupport with the provided configuration\" >JsonpSupport.create(Map.of(JsonGenerator.PRETTY_PRINTING, false)) ",
            "title": "Json Support"
        },
        {
            "location": "/mp/extensions/04_cdi_oci-objectstorage",
            "text": " This CDI portable extension provides support for injecting an Oracle Cloud Infrastructure Object Storage client in your Helidon MicroProfile applications. ",
            "title": "preambule"
        },
        {
            "location": "/mp/extensions/04_cdi_oci-objectstorage",
            "text": " To enable OCI Object Storage Support add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.oci.sdk&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-oci-sdk-cdi&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/extensions/04_cdi_oci-objectstorage",
            "text": " Please see Helidon&#8217;s Oracle Cloud Infrastructure Integration for information on how to use Helidon&#8217;s OCI SDK Extension. ",
            "title": "Using The Helidon OCI SDK Extension"
        },
        {
            "location": "/mp/openapi/01_openapi",
            "text": " Easily allow your Helidon MP application to serve an OpenAPI document that describes your application&#8217;s endpoints. ",
            "title": "preambule"
        },
        {
            "location": "/mp/openapi/01_openapi",
            "text": " To enable MicroProfile OpenAPI either add a dependency on the helidon-microprofile bundle or add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;org.eclipse.microprofile.openapi&lt;/groupId&gt; &lt;artifactId&gt;microprofile-openapi-api&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.openapi&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-openapi&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; Defines the MicroProfile OpenAPI annotations so you can use them in your code. Adds the Helidon MP OpenAPI runtime support. ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/mp/openapi/01_openapi",
            "text": " You can very simply add support for OpenAPI to your Helidon MP application. This document shows what changes you need to make to your application and how to access the OpenAPI document for your application at runtime. ",
            "title": "OpenAPI support in Helidon MP"
        },
        {
            "location": "/mp/openapi/01_openapi",
            "text": " A Jandex index stores information about the classes and methods in your app and what annotations they have. It allows CDI to process annotations faster during your application&#8217;s start-up. Add the Jandex maven plug-in to the &lt;build&gt;&lt;plugins&gt; section of your pom.xml : <markup lang=\"xml\" >&lt;plugin&gt; &lt;groupId&gt;org.jboss.jandex&lt;/groupId&gt; &lt;artifactId&gt;jandex-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.1.0&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;make-index&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;jandex&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; When you build your app maven should include the index META-INF/jandex.idx in the JAR. Note If you do not modify your build to create the index then the Helidon MP OpenAPI runtime automatically creates one in memory during app start-up. This slows down your app start-up and, depending on how CDI is configured, might inadvertently miss information. We strongly recommend using the Jandex plug-in to build the index into your app. ",
            "title": "Building the Jandex index"
        },
        {
            "location": "/mp/openapi/01_openapi",
            "text": " Building the Jandex index A Jandex index stores information about the classes and methods in your app and what annotations they have. It allows CDI to process annotations faster during your application&#8217;s start-up. Add the Jandex maven plug-in to the &lt;build&gt;&lt;plugins&gt; section of your pom.xml : <markup lang=\"xml\" >&lt;plugin&gt; &lt;groupId&gt;org.jboss.jandex&lt;/groupId&gt; &lt;artifactId&gt;jandex-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.1.0&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;make-index&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;jandex&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; When you build your app maven should include the index META-INF/jandex.idx in the JAR. Note If you do not modify your build to create the index then the Helidon MP OpenAPI runtime automatically creates one in memory during app start-up. This slows down your app start-up and, depending on how CDI is configured, might inadvertently miss information. We strongly recommend using the Jandex plug-in to build the index into your app. ",
            "title": "Edit your pom.xml "
        },
        {
            "location": "/mp/openapi/01_openapi",
            "text": " You can add MicroProfile OpenAPI annotations to the endpoints in your source code. These annotations allow the Helidon MP OpenAPI runtime to discover the endpoints and information about them via CDI at app start-up. Here is one of the endpoints, annotated for OpenAPI, from the example mentioned earlier: <markup lang=\"java\" >@GET @Operation(summary = \"Returns a generic greeting\", description = \"Greets the user generically\") @APIResponse(description = \"Simple JSON containing the greeting\", content = @Content(mediaType = \"application/json\", schema = @Schema(implementation = GreetingMessage.class))) @Produces(MediaType.APPLICATION_JSON) public JsonObject getDefaultMessage() {...} @Operation gives information about this endpoint. @APIResponse describes the HTTP response and declares its media type and contents. You can also define any request parameters the endpoint expects, although this endpoint uses none. This excerpt shows only a few annotations for illustration. The Helidon MP OpenAPI example illustrates more, and the MicroProfile OpenAPI spec describes them all. ",
            "title": "Annotate the endpoints in your app"
        },
        {
            "location": "/mp/openapi/01_openapi",
            "text": " Add a static file at META-INF/openapi.yml , META-INF/openapi.yaml , or META-INF/openapi.json . Tools such as Swagger let you describe your app&#8217;s API and they then generate an OpenAPI document file which you can include in your application so OpenAPI can use it. ",
            "title": "Provide a static OpenAPI file"
        },
        {
            "location": "/mp/openapi/01_openapi",
            "text": " Write a Java class that implements the OpenAPI org.eclipse.microprofile.openapi.OASModelReader interface. Your model reader code programmatically adds elements to the internal model that OpenAPI builds. Change your application&#8217;s MP configuration to set mp.openapi.model.reader as the fully-qualified class name of your class. ",
            "title": "Write and configure a model reader class"
        },
        {
            "location": "/mp/openapi/01_openapi",
            "text": " Write a Java class that implements the OpenAPI org.eclipse.microprofile.openapi.OASFilter interface. As OpenAPI composes its internal model, it invokes your filter with each model element before adding the element to the model. Your filter can accept the element as-is, modify it, or suppress it. Change your application&#8217;s configuration to set mp.openapi.filter as the full-qualified class name of your class. ",
            "title": "Write and configure a filter class"
        },
        {
            "location": "/mp/openapi/01_openapi",
            "text": " Helidon MP OpenAPI combines information from all of the following sources as it builds its in-memory model of your application&#8217;s API. It constructs the OpenAPI document from this internal model. Your application can use one or more of these techniques. Annotate the endpoints in your app You can add MicroProfile OpenAPI annotations to the endpoints in your source code. These annotations allow the Helidon MP OpenAPI runtime to discover the endpoints and information about them via CDI at app start-up. Here is one of the endpoints, annotated for OpenAPI, from the example mentioned earlier: <markup lang=\"java\" >@GET @Operation(summary = \"Returns a generic greeting\", description = \"Greets the user generically\") @APIResponse(description = \"Simple JSON containing the greeting\", content = @Content(mediaType = \"application/json\", schema = @Schema(implementation = GreetingMessage.class))) @Produces(MediaType.APPLICATION_JSON) public JsonObject getDefaultMessage() {...} @Operation gives information about this endpoint. @APIResponse describes the HTTP response and declares its media type and contents. You can also define any request parameters the endpoint expects, although this endpoint uses none. This excerpt shows only a few annotations for illustration. The Helidon MP OpenAPI example illustrates more, and the MicroProfile OpenAPI spec describes them all. Provide a static OpenAPI file Add a static file at META-INF/openapi.yml , META-INF/openapi.yaml , or META-INF/openapi.json . Tools such as Swagger let you describe your app&#8217;s API and they then generate an OpenAPI document file which you can include in your application so OpenAPI can use it. Write and configure a model reader class Write a Java class that implements the OpenAPI org.eclipse.microprofile.openapi.OASModelReader interface. Your model reader code programmatically adds elements to the internal model that OpenAPI builds. Change your application&#8217;s MP configuration to set mp.openapi.model.reader as the fully-qualified class name of your class. Write and configure a filter class Write a Java class that implements the OpenAPI org.eclipse.microprofile.openapi.OASFilter interface. As OpenAPI composes its internal model, it invokes your filter with each model element before adding the element to the model. Your filter can accept the element as-is, modify it, or suppress it. Change your application&#8217;s configuration to set mp.openapi.filter as the full-qualified class name of your class. ",
            "title": "Furnish OpenAPI information about your endpoints"
        },
        {
            "location": "/mp/openapi/01_openapi",
            "text": " Beyond the two config properties that denote the model reader and filter, Helidon MP OpenAPI supports a number of other mandated settings. These are described in the configuration section of the MicroProfile OpenAPI spec. Helidon MP also supports additional properties specific to Helidon. Helidon-specific OpenAPI Config Properties Property Use openapi.web-context Path which serves the OpenAPI document (defaults to /openapi ) openapi.static-file Full path to the static OpenAPI file (defaults to META-INF/openapi.yml , META-INF/openapi.yaml , or META-INF/openapi.json ) Assign these settings in META-INF/microprofile-config.properties . ",
            "title": "Update your application configuration"
        },
        {
            "location": "/mp/openapi/01_openapi",
            "text": " Helidon MP conforms to the MicroProfile OpenAPI specification , which was inspired by the OpenAPI spec itself. Helidon MP includes a complete OpenAPI example based on the MP quick-start sample app. To use OpenAPI from your Helidon MP app: Edit your pom.xml . Furnish OpenAPI information about your application&#8217;s endpoints. Update your application&#8217;s configuration (optional). Edit your pom.xml Building the Jandex index A Jandex index stores information about the classes and methods in your app and what annotations they have. It allows CDI to process annotations faster during your application&#8217;s start-up. Add the Jandex maven plug-in to the &lt;build&gt;&lt;plugins&gt; section of your pom.xml : <markup lang=\"xml\" >&lt;plugin&gt; &lt;groupId&gt;org.jboss.jandex&lt;/groupId&gt; &lt;artifactId&gt;jandex-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.1.0&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;make-index&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;jandex&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; When you build your app maven should include the index META-INF/jandex.idx in the JAR. Note If you do not modify your build to create the index then the Helidon MP OpenAPI runtime automatically creates one in memory during app start-up. This slows down your app start-up and, depending on how CDI is configured, might inadvertently miss information. We strongly recommend using the Jandex plug-in to build the index into your app. Furnish OpenAPI information about your endpoints Helidon MP OpenAPI combines information from all of the following sources as it builds its in-memory model of your application&#8217;s API. It constructs the OpenAPI document from this internal model. Your application can use one or more of these techniques. Annotate the endpoints in your app You can add MicroProfile OpenAPI annotations to the endpoints in your source code. These annotations allow the Helidon MP OpenAPI runtime to discover the endpoints and information about them via CDI at app start-up. Here is one of the endpoints, annotated for OpenAPI, from the example mentioned earlier: <markup lang=\"java\" >@GET @Operation(summary = \"Returns a generic greeting\", description = \"Greets the user generically\") @APIResponse(description = \"Simple JSON containing the greeting\", content = @Content(mediaType = \"application/json\", schema = @Schema(implementation = GreetingMessage.class))) @Produces(MediaType.APPLICATION_JSON) public JsonObject getDefaultMessage() {...} @Operation gives information about this endpoint. @APIResponse describes the HTTP response and declares its media type and contents. You can also define any request parameters the endpoint expects, although this endpoint uses none. This excerpt shows only a few annotations for illustration. The Helidon MP OpenAPI example illustrates more, and the MicroProfile OpenAPI spec describes them all. Provide a static OpenAPI file Add a static file at META-INF/openapi.yml , META-INF/openapi.yaml , or META-INF/openapi.json . Tools such as Swagger let you describe your app&#8217;s API and they then generate an OpenAPI document file which you can include in your application so OpenAPI can use it. Write and configure a model reader class Write a Java class that implements the OpenAPI org.eclipse.microprofile.openapi.OASModelReader interface. Your model reader code programmatically adds elements to the internal model that OpenAPI builds. Change your application&#8217;s MP configuration to set mp.openapi.model.reader as the fully-qualified class name of your class. Write and configure a filter class Write a Java class that implements the OpenAPI org.eclipse.microprofile.openapi.OASFilter interface. As OpenAPI composes its internal model, it invokes your filter with each model element before adding the element to the model. Your filter can accept the element as-is, modify it, or suppress it. Change your application&#8217;s configuration to set mp.openapi.filter as the full-qualified class name of your class. Update your application configuration Beyond the two config properties that denote the model reader and filter, Helidon MP OpenAPI supports a number of other mandated settings. These are described in the configuration section of the MicroProfile OpenAPI spec. Helidon MP also supports additional properties specific to Helidon. Helidon-specific OpenAPI Config Properties Property Use openapi.web-context Path which serves the OpenAPI document (defaults to /openapi ) openapi.static-file Full path to the static OpenAPI file (defaults to META-INF/openapi.yml , META-INF/openapi.yaml , or META-INF/openapi.json ) Assign these settings in META-INF/microprofile-config.properties . ",
            "title": "Changing your application"
        },
        {
            "location": "/mp/openapi/01_openapi",
            "text": " Now your Helidon MP application will automatially respond to an additional endpoint&#8201;&#8212;&#8201; /openapi &#8201;&#8212;&#8201;and it will return the OpenAPI document describing the endpoints in your application. By default, per the MicroProfile OpenAPI spec, the default format of the OpenAPI document is YAML. There is not yet an adopted IANA YAML media type, but a proposed one specifically for OpenAPI documents that has some support is application/vnd.oai.openapi . That is what Helidon returns, by default. A client can specify Accept: as either application/vnd.oai.openapi+json or application/json to request JSON. ",
            "title": "Accessing the OpenAPI document"
        },
        {
            "location": "/se/scheduling/01_introduction",
            "text": " To enable Scheduling add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.scheduling&lt;/groupId&gt; &lt;artifactId&gt;helidon-scheduling&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "/se/scheduling/01_introduction",
            "text": " For simple fixed rate invocation use . <markup lang=\"java\" title=\"Example of scheduling with fixed rate use Scheduling.fixedRateBuilder() builder.\" >Scheduling.fixedRateBuilder() .delay(10) .initialDelay(5) .timeUnit(TimeUnit.MINUTES) .task(inv -&gt; System.out.println(\"Every 10 minutes, first invocation 5 minutes after start\")) .build(); Metadata like human-readable interval description or configured values are available through FixedRateInvocation provided as task parameter. <markup lang=\"java\" title=\"Example with ivocation metadata\" >Scheduling.fixedRateBuilder() .delay(10) .task(inv -&gt; System.out.println(\"Method invoked \" + inv.description())) .build(); ",
            "title": "Fixed rate"
        },
        {
            "location": "/se/scheduling/01_introduction",
            "text": " For more complicated interval definition, cron expression can be leveraged with Scheduling.cronBuilder() builder. <markup lang=\"java\" title=\"Example of scheduling with cron expression\" >Scheduling.cronBuilder() .expression(\"0 15 8 ? * *\") .task(inv -&gt; System.out.println(\"Executer every day at 8:15\")) .build(); <markup title=\"Cron expression format\" >&lt;seconds&gt; &lt;minutes&gt; &lt;hours&gt; &lt;day-of-month&gt; &lt;month&gt; &lt;day-of-week&gt; &lt;year&gt; Cron expression fields Order Name Supported values Supported field format Optional 1 seconds 0-59 CONST, LIST, RANGE, WILDCARD, INCREMENT false 2 minutes 0-59 CONST, LIST, RANGE, WILDCARD, INCREMENT false 3 hours 0-23 CONST, LIST, RANGE, WILDCARD, INCREMENT false 4 day-of-month 1-31 CONST, LIST, RANGE, WILDCARD, INCREMENT, ANY, LAST, WEEKDAY false 5 month 1-12 or JAN-DEC CONST, LIST, RANGE, WILDCARD, INCREMENT false 6 day-of-week 1-7 or SUN-SAT CONST, LIST, RANGE, WILDCARD, INCREMENT, ANY, NTH, LAST false 7 year 1970-2099 CONST, LIST, RANGE, WILDCARD, INCREMENT true Field formats Name Regex format Example Description CONST \\d+ 12 exact value LIST \\d+,\\d+(,\\d+)* 1,2,3,4 list of constants RANGE \\d+-\\d+ 15-30 range of values from-to WILDCARD \\* * all values withing the field INCREMENT \\d+\\/\\d+ 0/5 inital number / increments, 2/5 means 2,7,9,11,16,&#8230;&#8203; ANY \\? ? any day(apply only to day-of-week and day-of-month) NTH \\# 1#3 nth day of the month, 2#3 means third monday of the month LAST \\d*L(+\\d+|\\-\\d+)? 3L-3 last day of the month in day-of-month or last nth day in the day-of-week WEEKDAY \\# 1#3 nearest weekday of the nth day of month, 1W is the first monday of the week Examples Cron expression Description * * * * * ? Every second 0/2 * * * * ? * Every 2 seconds 0 45 9 ? * * Every day at 9:45 0 15 8 ? * MON-FRI Every workday at 8:15 Metadata like human-readable interval description or configured values are available through CronInvocation provided as task parameter. <markup lang=\"java\" title=\"Example with ivocation metadata\" >Scheduling.cronBuilder() .expression(\"0 15 8 ? * *\") .task(inv -&gt; System.out.println(\"Method invoked \" + inv.description())) .build(); ",
            "title": "Cron expression"
        },
        {
            "location": "/se/scheduling/01_introduction",
            "text": " For scheduling periodic tasks it is possible to choose fixed rate setup or Cron expression. Fixed rate For simple fixed rate invocation use . <markup lang=\"java\" title=\"Example of scheduling with fixed rate use Scheduling.fixedRateBuilder() builder.\" >Scheduling.fixedRateBuilder() .delay(10) .initialDelay(5) .timeUnit(TimeUnit.MINUTES) .task(inv -&gt; System.out.println(\"Every 10 minutes, first invocation 5 minutes after start\")) .build(); Metadata like human-readable interval description or configured values are available through FixedRateInvocation provided as task parameter. <markup lang=\"java\" title=\"Example with ivocation metadata\" >Scheduling.fixedRateBuilder() .delay(10) .task(inv -&gt; System.out.println(\"Method invoked \" + inv.description())) .build(); Cron expression For more complicated interval definition, cron expression can be leveraged with Scheduling.cronBuilder() builder. <markup lang=\"java\" title=\"Example of scheduling with cron expression\" >Scheduling.cronBuilder() .expression(\"0 15 8 ? * *\") .task(inv -&gt; System.out.println(\"Executer every day at 8:15\")) .build(); <markup title=\"Cron expression format\" >&lt;seconds&gt; &lt;minutes&gt; &lt;hours&gt; &lt;day-of-month&gt; &lt;month&gt; &lt;day-of-week&gt; &lt;year&gt; Cron expression fields Order Name Supported values Supported field format Optional 1 seconds 0-59 CONST, LIST, RANGE, WILDCARD, INCREMENT false 2 minutes 0-59 CONST, LIST, RANGE, WILDCARD, INCREMENT false 3 hours 0-23 CONST, LIST, RANGE, WILDCARD, INCREMENT false 4 day-of-month 1-31 CONST, LIST, RANGE, WILDCARD, INCREMENT, ANY, LAST, WEEKDAY false 5 month 1-12 or JAN-DEC CONST, LIST, RANGE, WILDCARD, INCREMENT false 6 day-of-week 1-7 or SUN-SAT CONST, LIST, RANGE, WILDCARD, INCREMENT, ANY, NTH, LAST false 7 year 1970-2099 CONST, LIST, RANGE, WILDCARD, INCREMENT true Field formats Name Regex format Example Description CONST \\d+ 12 exact value LIST \\d+,\\d+(,\\d+)* 1,2,3,4 list of constants RANGE \\d+-\\d+ 15-30 range of values from-to WILDCARD \\* * all values withing the field INCREMENT \\d+\\/\\d+ 0/5 inital number / increments, 2/5 means 2,7,9,11,16,&#8230;&#8203; ANY \\? ? any day(apply only to day-of-week and day-of-month) NTH \\# 1#3 nth day of the month, 2#3 means third monday of the month LAST \\d*L(+\\d+|\\-\\d+)? 3L-3 last day of the month in day-of-month or last nth day in the day-of-week WEEKDAY \\# 1#3 nearest weekday of the nth day of month, 1W is the first monday of the week Examples Cron expression Description * * * * * ? Every second 0/2 * * * * ? * Every 2 seconds 0 45 9 ? * * Every day at 9:45 0 15 8 ? * MON-FRI Every workday at 8:15 Metadata like human-readable interval description or configured values are available through CronInvocation provided as task parameter. <markup lang=\"java\" title=\"Example with ivocation metadata\" >Scheduling.cronBuilder() .expression(\"0 15 8 ? * *\") .task(inv -&gt; System.out.println(\"Method invoked \" + inv.description())) .build(); ",
            "title": "Scheduling"
        },
        {
            "location": "/mp/cors/hide_why-options",
            "text": " There are some good reasons why it is @OPTIONS methods that you decorate with the Helidon MP @CrossOrigin annotation. Take an informal look at the rationale for this choice. ",
            "title": "preambule"
        },
        {
            "location": "/mp/cors/hide_why-options",
            "text": " At the heart of cross-origin resource sharing is the resource itself. CORS lets you control how a given resource should be shared among various origins. All the attributes of CORS&#8201;&#8212;&#8201;whether authentication should be used, what headers can be passed through on CORS-controlled requests, and so on&#8201;&#8212;&#8201;pertain to a given resource. In Helidon MP, the parameters defined on the @CrossOrigin annotation map directly to those CORS sharing attributes. It would be natural, then, to use @CrossOrigin to annotate the single Java element in the application that represents a resource. ",
            "title": "The Resource"
        },
        {
            "location": "/mp/cors/hide_why-options",
            "text": " Unfortunately, there is no single Java element that is sure to correspond one-to-one with a JAX-RS resource, for two reasons. JAX-RS allows a resource class to define one or more subresources, denoted by the @Path annotation on methods. So a resource class does not necessarily represent only a single resource. A JAX-RS resource class can contain multiple endpoints for the same resource. A common example is two methods, annotated with @GET and @PUT respectively, that have the same path. Although no single endpoint method by itself fully represents the resource, at least each endpoint method maps to exactly one resource. So we could annotate any one of those endpoint methods with @CrossOrigin and unambiguously link the CORS behavior that the annotation defines to the resource. But which endpoint method, and why? ",
            "title": "Methods, Resources, and Subresources in JAX-RS Resource Classes"
        },
        {
            "location": "/mp/cors/hide_why-options",
            "text": " The OPTIONS HTTP method plays an important role in CORS. While the CORS protocol applies to all HTTP methods, it relies on OPTIONS &#8201;&#8212;&#8201;with suitable headers&#8201;&#8212;&#8201;to represent CORS pre-flight requests. From that point of view, the OPTIONS HTTP method has a more prominent place in CORS than the other methods. In a JAX-RS resource class, the @OPTIONS annotation denotes which endpoint method should receive incoming OPTIONS HTTP requests for a resource. Therefore, we could view a Java method annotated with @OPTIONS as somewhat distinguished in the same way that we think of the OPTIONS HTTP method as distinguished within the CORS protocol. Furthermore, there is this technical detail: Helidon MP uses a JAX-RS filter internally to gather information about each @CrossOrigin annotation. Some JAX-RS implementations do not provide the filter with what it needs to find and introspect the @CrossOrigin annotation unless the application itself implements the @OPTIONS endpoint for the resource. ",
            "title": " OPTIONS in CORS, @OPTIONS in JAX-RS, and Technical Reality"
        },
        {
            "location": "/mp/cors/hide_why-options",
            "text": " If you want a resource to participate in CORS, Helidon MP needs you to implement the @OPTIONS endpoint method for the resource, even if the method does nothing. Given that you have to write that method, and given that any endpoint method uniquely identifies its resource, the @OPTIONS method is a reasonable place to ask you to annotate with @CrossOrigin . ",
            "title": "The Bottom Line"
        }
 ]
}