{
    "docs": [
        {
            "location": "about/cli",
            "text": " The Helidon CLI lets you easily create a Helidon project by picking from a set of archetypes. It also supports a developer loop that performs continuous compilation and application restart, so you can easily iterate over source code changes. The CLI is distributed as a standalone executable (compiled using GraalVM) for ease of installation. It is currently available as a download for Linux, Mac and Windows. Simply download the binary, install it at a location accessible from your PATH and you’re ready to go. ",
            "title": "Introduction"
        },
        {
            "location": "about/cli",
            "text": " Helidon 3 requires Java 17 (or newer) and Maven. <div class=\"table__overflow elevation-1 flex sm7 \"> Java&#160;SE&#160;17 ( Open&#160;JDK&#160;17 ) or newer Maven 3.6.1+ You should make sure java and mvn are in your path. <markup lang=\"bash\" >java -version mvn --version ",
            "title": "Prerequisites"
        },
        {
            "location": "about/cli",
            "text": "<markup lang=\"bash\" title=\"MacOS\" >curl -L -O https://helidon.io/cli/latest/darwin/helidon chmod +x ./helidon sudo mv ./helidon /usr/local/bin/ If you get a warning that \"the developer cannot be verified\" when running the CLI this is due to the Helidon CLI not being signed and notarized yet. You can disable this check by running: xattr -d com.apple.quarantine helidon <markup lang=\"bash\" title=\"Linux\" >curl -L -O https://helidon.io/cli/latest/linux/helidon chmod +x ./helidon sudo mv ./helidon /usr/local/bin/ <markup lang=\"powershell\" title=\"Windows\" >PowerShell -Command Invoke-WebRequest -Uri \"https://helidon.io/cli/latest/windows/helidon.exe\" -OutFile \"C:\\Windows\\system32\\helidon.exe\" For Windows you will also need the Visual C++ Redistributable Runtime. See Helidon on Windows for more information. ",
            "title": "Installation"
        },
        {
            "location": "about/cli",
            "text": "<markup lang=\"bash\" >helidon init Then answer the questions. ",
            "title": "Create a New Project"
        },
        {
            "location": "about/cli",
            "text": "<markup lang=\"bash\" >cd myproject helidon dev As you make source code changes the project will automatically recompile and restart your application. ",
            "title": "Developer Loop"
        },
        {
            "location": "about/cli",
            "text": " ",
            "title": "Demo"
        },
        {
            "location": "about/introduction",
            "text": " What is Helidon? Helidon Flavors What flavor shall I use? Prerequisites Next Steps ",
            "title": "Contents"
        },
        {
            "location": "about/introduction",
            "text": " Helidon is a collection of Java libraries for writing microservices that run on a fast web core powered by Netty . It&#8217;s small, fast, and fun to use. Helidon is open source under the Apache 2.0 license. Sources are available on GitHub . Helidon is cloud-native ready. It provides fast start-up time and has low memory consumption and a small disk footprint. It also comes with a full observability stack out of the box including health checks, metrics, tracing and logging. Helidon fully supports GraalVM native image allowing you to build a native executable from your Java application. ",
            "title": "What is Helidon?"
        },
        {
            "location": "about/introduction",
            "text": " Use Helidon SE if Performance is your main goal. You are familiar with reactive programming. Your application is heavily using concurrency. You are not planning to use any CDI-based components. You want to use a minimum number of third-party dependencies. Use Helidon MP if You want to base your application on modern enterprise Java standards such as Jakarta EE and MicroProfile. You are familiar with Java EE, Jakarta EE or Spring Boot and would like to have a similar development experience. You are migrating existing Java EE/Jakarta EE application to microservices. You are planning to use CDI components or extensions. You are planning to use JPA for data access and Jersey (JAX-RS) for RESTful services. Note If you don&#8217;t know which Helidon flavor to use – use Helidon MP . ",
            "title": "What flavor shall I use?"
        },
        {
            "location": "about/introduction",
            "text": " Helidon comes in two flavors: Helidon SE and Helidon MP . Think about these flavors as frameworks providing similar functionality but offering different developer experiences. Helidon SE Helidon MP Gives you full transparency and puts you in control. Built on top of the Helidon SE libraries and provides a platform that is familiar to enterprise Java developers. Microframework model with a very small footprint and limited functionality (~7 MB). MicroProfile implementation; slightly larger footprint than SE (~13 MB). Functional style, reactive, non-blocking. Declarative style with dependency injection. Transparent \"no magic\" development experience; pure java application development with no annotations and no dependency injections. Developer experience similar to that of Spring Boot, Jakarta EE and MicroProfile; layers on some Jakarta EE components (CDI, JAX-RS, JSON-P, JSON-B). Learn more about Helidon SE . Learn more about Helidon MP . To help illustrate the differences, below are two samples implementing a simple RESTful service. One uses Helidon SE, the other Helidon MP. <markup lang=\"java\" title=\"Helidon SE sample\" >Routing routing = Routing.builder() .get(\"/hello\", (req, res) -&gt; res.send(\"Hello World\")) .build(); WebServer.create(routing) .start(); <markup lang=\"java\" title=\"Helidon MP sample\" >@Path(\"hello\") public class HelloWorld { @GET public String hello() { return \"Hello World\"; } } What flavor shall I use? Use Helidon SE if Performance is your main goal. You are familiar with reactive programming. Your application is heavily using concurrency. You are not planning to use any CDI-based components. You want to use a minimum number of third-party dependencies. Use Helidon MP if You want to base your application on modern enterprise Java standards such as Jakarta EE and MicroProfile. You are familiar with Java EE, Jakarta EE or Spring Boot and would like to have a similar development experience. You are migrating existing Java EE/Jakarta EE application to microservices. You are planning to use CDI components or extensions. You are planning to use JPA for data access and Jersey (JAX-RS) for RESTful services. Note If you don&#8217;t know which Helidon flavor to use – use Helidon MP . ",
            "title": "Helidon Flavors"
        },
        {
            "location": "about/introduction",
            "text": " Helidon requires Java and Maven. You might also need Docker and Kubernetes depending on how you plan to deploy your services. Prerequisite product versions for Helidon 3.0.2 Java&#160;SE&#160;17 ( Open&#160;JDK&#160;17 ) Helidon requires Java 17+. Maven 3.6.1+ Helidon requires Maven 3.6.1+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop . We also strongly suggest installing the Helidon CLI (command line interface) which helps in generating and building Helidon projects. ",
            "title": "Prerequisites"
        },
        {
            "location": "about/introduction",
            "text": " In case you need to upgrade the version of Helidon, follow the Migration Guides . For migration from Helidon 1.x to 2.x: Helidon SE 2x Migration Guide Helidon MP 2x Migration Guide For migration from Helidon 2.x to 3.x: Helidon SE 3x Migration Guide Helidon MP 3x Migration Guide ",
            "title": "Migration"
        },
        {
            "location": "about/introduction",
            "text": " Choose a Helidon flavor to explore and start using it. Check out the following: Helidon SE Documentation Helidon MP Documentation ",
            "title": "Next Steps"
        },
        {
            "location": "about/kubernetes",
            "text": " For development it&#8217;s often convenient to run Kubernetes on your desktop. Two popular ways to do this are with Kubernetes Minikube or Kubernetes support in Docker for Desktop . In this guide we&#8217;ll use Docker for Desktop. ",
            "title": "preambule"
        },
        {
            "location": "about/kubernetes",
            "text": " Install Docker for Mac or Docker for Windows . Starting with version 18.06 Docker for Desktop includes Kubernetes support. ",
            "title": "Install"
        },
        {
            "location": "about/kubernetes",
            "text": " Enable Kubernetes Support for Mac or Kubernetes Support for Windows . Once Kubernetes installation is complete, make sure you have your context set correctly to use docker-for-desktop. <markup lang=\"bash\" title=\"Make sure K8s context is set to docker-for-desktop\" >kubectl config get-contexts kubectl config use-context docker-for-desktop kubectl cluster-info kubectl version --short kubectl get nodes ",
            "title": "Enable Kubernetes Support"
        },
        {
            "location": "about/managing-dependencies",
            "text": " Helidon provides a &#8220;Bill Of Materials&#8221; (BOM) to manage dependencies. This is a special Maven pom file that provides dependency management. Using the Helidon BOM allows you to use Helidon component dependencies with a single version: the Helidon version. ",
            "title": "preambule"
        },
        {
            "location": "about/managing-dependencies",
            "text": " If you created your application using the Helidon CLI or archetypes then your project will have a Helidon Application POM as its parent POM. In this case you will get Helidon&#8217;s dependency management automatically. If your project doesn&#8217;t use a Helidon Application POM as its parent, then you will need to import the Helidon BOM POM. ",
            "title": "The Helidon Application POMs"
        },
        {
            "location": "about/managing-dependencies",
            "text": " To import the Helidon BOM POM add the following snippet to your pom.xml file. <markup lang=\"xml\" title=\"Import the Helidon BOM\" >&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon&lt;/groupId&gt; &lt;artifactId&gt;helidon-bom&lt;/artifactId&gt; &lt;version&gt;3.0.2&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; ",
            "title": "The Helidon BOM POM"
        },
        {
            "location": "about/managing-dependencies",
            "text": " Once you have imported the BOM, you can declare dependencies on Helidon components without specifying a version. <markup lang=\"xml\" title=\"Component dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webserver&lt;/groupId&gt; &lt;artifactId&gt;helidon-webserver&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Using Helidon Component Dependencies"
        },
        {
            "location": "about/managing-dependencies",
            "text": " Maven Build Guide for SE and MP Gradle Build Guide for SE and MP ",
            "title": "For More Information"
        },
        {
            "location": "about/prerequisites",
            "text": " Everything you need to get started with Helidon is listed here. ",
            "title": "preambule"
        },
        {
            "location": "about/prerequisites",
            "text": " Helidon requires Java and Maven. You might also need Docker and Kubernetes depending on how you plan to deploy your services. Prerequisite product versions for Helidon 3.0.2 Java&#160;SE&#160;17 ( Open&#160;JDK&#160;17 ) Helidon requires Java 17+. Maven 3.6.1+ Helidon requires Maven 3.6.1+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop . <markup lang=\"bash\" title=\"Verify Prerequisites\" >java -version mvn --version docker --version kubectl version --short ",
            "title": "Prerequisites"
        },
        {
            "location": "about/prerequisites",
            "text": "<markup lang=\"bash\" title=\"Setting JAVA_HOME \" ># On Mac export JAVA_HOME=`/usr/libexec/java_home -v 17` # On Linux # Use the appropriate path to your JDK export JAVA_HOME=/usr/lib/jvm/jdk-17 ",
            "title": "Setting JAVA_HOME "
        },
        {
            "location": "about/prerequisites",
            "text": " Now you are ready to try the Quickstart Examples: Helidon MP Quickstart Example Helidon SE Quickstart Example See About Helidon for more information on the differences between Helidon MP and SE. See Helidon on Windows for some tips on using Helidon on Windows. ",
            "title": "Try the Quickstart Examples"
        },
        {
            "location": "about/windows",
            "text": " Most of the Helidon documentation is Linux/Mac/Unix centric. This document gives some tips for Windows users. ",
            "title": "Introduction"
        },
        {
            "location": "about/windows",
            "text": " Windows 10 is required. For general pre-requisites like Java and Maven see Getting Started . If you want to use the Helidon CLI you&#8217;ll also need to install the Visual C++ Redistributable Runtime: x64 x86 We also recommend installing the following from the Microsoft Store: PowerShell Windows Terminal This document assumes you will be using PowerShell. ",
            "title": "Prerequisites"
        },
        {
            "location": "about/windows",
            "text": "<markup lang=\"bash\" >mvn \"-U\" \"archetype:generate\" \"-DinteractiveMode=false\" ` \"-DarchetypeGroupId=io.helidon.archetypes\" ` \"-DarchetypeArtifactId=helidon-quickstart-se\" ` \"-DarchetypeVersion=3.0.2\" ` \"-DgroupId=io.helidon.examples\" ` \"-DartifactId=helidon-quickstart-se\" ` \"-Dpackage=io.helidon.examples.quickstart.se\" You can then follow the instructions in the Helidon SE Quickstart . If you do not have curl installed you can use Invoke-WebRequest : <markup lang=\"bash\" >Invoke-WebRequest -Uri \"http://localhost:8080/greet\" ",
            "title": "Helidon SE"
        },
        {
            "location": "about/windows",
            "text": "<markup lang=\"bash\" >mvn \"-U\" \"archetype:generate\" \"-DinteractiveMode=false\" ` \"-DarchetypeGroupId=io.helidon.archetypes\" ` \"-DarchetypeArtifactId=helidon-quickstart-mp\" ` \"-DarchetypeVersion=3.0.2\" ` \"-DgroupId=io.helidon.examples\" ` \"-DartifactId=helidon-quickstart-mp\" ` \"-Dpackage=io.helidon.examples.quickstart.mp\" You can then follow the instructions in the Helidon MP Quickstart . If you do not have curl installed you can use Invoke-WebRequest : <markup lang=\"bash\" >Invoke-WebRequest -Uri \"http://localhost:8080/greet\" ",
            "title": "Helidon MP"
        },
        {
            "location": "about/windows",
            "text": " Helidon SE <markup lang=\"bash\" >mvn \"-U\" \"archetype:generate\" \"-DinteractiveMode=false\" ` \"-DarchetypeGroupId=io.helidon.archetypes\" ` \"-DarchetypeArtifactId=helidon-quickstart-se\" ` \"-DarchetypeVersion=3.0.2\" ` \"-DgroupId=io.helidon.examples\" ` \"-DartifactId=helidon-quickstart-se\" ` \"-Dpackage=io.helidon.examples.quickstart.se\" You can then follow the instructions in the Helidon SE Quickstart . If you do not have curl installed you can use Invoke-WebRequest : <markup lang=\"bash\" >Invoke-WebRequest -Uri \"http://localhost:8080/greet\" Helidon MP <markup lang=\"bash\" >mvn \"-U\" \"archetype:generate\" \"-DinteractiveMode=false\" ` \"-DarchetypeGroupId=io.helidon.archetypes\" ` \"-DarchetypeArtifactId=helidon-quickstart-mp\" ` \"-DarchetypeVersion=3.0.2\" ` \"-DgroupId=io.helidon.examples\" ` \"-DartifactId=helidon-quickstart-mp\" ` \"-Dpackage=io.helidon.examples.quickstart.mp\" You can then follow the instructions in the Helidon MP Quickstart . If you do not have curl installed you can use Invoke-WebRequest : <markup lang=\"bash\" >Invoke-WebRequest -Uri \"http://localhost:8080/greet\" ",
            "title": "Maven Quickstart Archetypes"
        },
        {
            "location": "community",
            "text": " Helidon is a Java open source project under the Apache License version 2.0 . We encourage community contributions whether it&#8217;s participating in discussions, creating issues, or submitting pull requests. ",
            "title": "Open Source"
        },
        {
            "location": "community",
            "text": " Have a question? Ask them in in Slack at #helidon-user Or on Stack Overflow using the helidon tag Read the Helidon FAQ ",
            "title": "Get Answers"
        },
        {
            "location": "community",
            "text": " Helidon source is hosted on GitHub . If you&#8217;d like to report a bug, enhancement request, or check if an issue is on our list, visit the Helidon GitHub issue tracker . ",
            "title": "Code and Issues"
        },
        {
            "location": "community",
            "text": " Follow us on Twitter @helidon_project Read the Helidon blog . ",
            "title": "Stay Informed"
        },
        {
            "location": "config/io_helidon_common_configurable_LruCache",
            "text": " Type: io.helidon.common.configurable.LruCache ",
            "title": "preambule"
        },
        {
            "location": "config/io_helidon_common_configurable_LruCache",
            "text": " Optional configuration options key type default value description capacity int 10000 Configure capacity of the cache. ",
            "title": "Configuration options"
        },
        {
            "location": "config/io_helidon_common_configurable_Resource",
            "text": " Type: io.helidon.common.configurable.Resource ",
            "title": "preambule"
        },
        {
            "location": "config/io_helidon_common_configurable_Resource",
            "text": " Optional configuration options key type default value description content string &#160; Base64 encoded content of the resource content-plain string &#160; Plain text content of the resource path string &#160; File system path to the resource. proxy-host string &#160; Host of the proxy when using url. proxy-port int &#160; Port of the proxy when using url. resource-path string &#160; Classpath location of the resource. uri URI &#160; URI of the resource. use-proxy boolean true Whether to use proxy. Only used if proxy-host is defined as well. ",
            "title": "Configuration options"
        },
        {
            "location": "config/io_helidon_common_configurable_ScheduledThreadPoolSupplier",
            "text": " Type: io.helidon.common.configurable.ScheduledThreadPoolSupplier ",
            "title": "preambule"
        },
        {
            "location": "config/io_helidon_common_configurable_ScheduledThreadPoolSupplier",
            "text": " Optional configuration options key type default value description core-pool-size int 16 Core pool size of the thread pool executor. is-daemon boolean true Is daemon of the thread pool executor. should-prestart boolean true Whether to prestart core threads in this thread pool executor. thread-name-prefix string helidon- Name prefix for threads in this thread pool executor. ",
            "title": "Configuration options"
        },
        {
            "location": "config/io_helidon_common_configurable_ThreadPoolSupplier",
            "text": " Type: io.helidon.common.configurable.ThreadPoolSupplier ",
            "title": "preambule"
        },
        {
            "location": "config/io_helidon_common_configurable_ThreadPoolSupplier",
            "text": " Optional configuration options key type default value description core-pool-size int 10 Core pool size of the thread pool executor. is-daemon boolean true Is daemon of the thread pool executor. keep-alive-minutes int 3 Keep alive minutes of the thread pool executor. max-pool-size int 50 Max pool size of the thread pool executor. queue-capacity int 10000 Queue capacity of the thread pool executor. should-prestart boolean true Whether to prestart core threads in this thread pool executor. thread-name-prefix string helidon- Name prefix for threads in this thread pool executor. virtual-enforced boolean false Experimental When configured to true , virtual thread executor service must be available, otherwise the built executor would fail to start. virtual-threads boolean false Experimental When configured to true , an unbounded virtual executor service (project Loom) will be used if available. This is an experimental feature. If enabled and available, all other configuration options of this executor service are ignored! ",
            "title": "Configuration options"
        },
        {
            "location": "config/io_helidon_common_pki_KeyConfig",
            "text": " Type: io.helidon.common.pki.KeyConfig ",
            "title": "preambule"
        },
        {
            "location": "config/io_helidon_common_pki_KeyConfig",
            "text": " Optional configuration options key type default value description keystore KeystoreBuilder &#160; Update this builder with information from a keystore builder. pem PemBuilder &#160; Update this builder with information from a pem builder. ",
            "title": "Configuration options"
        },
        {
            "location": "config/io_helidon_common_pki_KeyConfig_KeystoreBuilder",
            "text": " Type: io.helidon.common.pki.KeyConfig.KeystoreBuilder ",
            "title": "preambule"
        },
        {
            "location": "config/io_helidon_common_pki_KeyConfig_KeystoreBuilder",
            "text": " Required configuration options key type default value description resource Resource &#160; Keystore resource definition. Optional configuration options key type default value description cert-chain.alias string &#160; Alias of an X.509 chain. cert.alias string &#160; Alias of X.509 certificate of public key. Used to load both the certificate and public key. key.alias string 1 Alias of the private key in the keystore. key.passphrase string &#160; Pass-phrase of the key in the keystore (used for private keys). This is (by default) the same as keystore passphrase - only configure if it differs from keystore passphrase. passphrase string &#160; Pass-phrase of the keystore (supported with JKS and PKCS12 keystores). trust-store boolean false If you want to build a trust store, call this method to add all certificates present in the keystore to certificate list. @return updated builder instance type string PKCS12 Set type of keystore. Defaults to \"PKCS12\", expected are other keystore types supported by java then can store keys under aliases. ",
            "title": "Configuration options"
        },
        {
            "location": "config/io_helidon_common_pki_KeyConfig_PemBuilder",
            "text": " Type: io.helidon.common.pki.KeyConfig.PemBuilder ",
            "title": "preambule"
        },
        {
            "location": "config/io_helidon_common_pki_KeyConfig_PemBuilder",
            "text": " Optional configuration options key type default value description cert-chain.resource Resource &#160; Load certificate chain from PEM resource. key.passphrase string &#160; Passphrase for private key. If the key is encrypted (and in PEM PKCS#8 format), this passphrase will be used to decrypt it. key.resource Resource &#160; Read a private key from PEM format from a resource definition. ",
            "title": "Configuration options"
        },
        {
            "location": "config/io_helidon_config_mp_MpConfigBuilder",
            "text": " Type: org.eclipse.microprofile.config.Config This is a standalone configuration type, prefix from configuration root: mp.config ",
            "title": "preambule"
        },
        {
            "location": "config/io_helidon_config_mp_MpConfigBuilder",
            "text": " Optional configuration options key type default value description profile string &#160; Configure an explicit profile name. ",
            "title": "Configuration options"
        },
        {
            "location": "config/io_helidon_faulttolerance_Bulkhead",
            "text": " Type: io.helidon.faulttolerance.Bulkhead ",
            "title": "preambule"
        },
        {
            "location": "config/io_helidon_faulttolerance_Bulkhead",
            "text": " Optional configuration options key type default value description cancel-source boolean true Policy to cancel any source stage if the value return by Bulkhead#invoke is cancelled. Default is true ; mostly used by FT MP to change default. limit int 10 Maximal number of parallel requests going through this bulkhead. When the limit is reached, additional requests are enqueued. name string Bulkhead- A name assigned for debugging, error reporting or configuration purposes. queue-length int 10 Maximal number of enqueued requests waiting for processing. When the limit is reached, additional attempts to invoke a request will receive a io.helidon.faulttolerance.BulkheadException. ",
            "title": "Configuration options"
        },
        {
            "location": "config/io_helidon_faulttolerance_CircuitBreaker",
            "text": " Type: io.helidon.faulttolerance.CircuitBreaker ",
            "title": "preambule"
        },
        {
            "location": "config/io_helidon_faulttolerance_CircuitBreaker",
            "text": " Optional configuration options key type default value description cancel-source boolean true Policy to cancel any source stage if the value return by CircuitBreaker#invoke is cancelled. Default is true ; mostly used by FT MP to change default. delay Duration PT5S How long to wait before transitioning from open to half-open state. error-ratio int 60 How many failures out of 100 will trigger the circuit to open. This is adapted to the #volume(int) used to handle the window of requests. If errorRatio is 40, and volume is 10, 4 failed requests will open the circuit. name string CircuitBreaker- A name assigned for debugging, error reporting or configuration purposes. success-threshold int 1 How many successful calls will close a half-open circuit. Nevertheless the first failed call will open the circuit again. volume int 10 Rolling window size used to calculate ratio of failed requests. ",
            "title": "Configuration options"
        },
        {
            "location": "config/io_helidon_faulttolerance_Retry",
            "text": " Type: io.helidon.faulttolerance.Retry ",
            "title": "preambule"
        },
        {
            "location": "config/io_helidon_faulttolerance_Retry",
            "text": " Optional configuration options key type default value description cancel-source boolean true Policy to cancel any source stage if the value return by Retry#invoke is cancelled. Default is true ; mostly used by FT MP to change default. name string Retry- A name assigned for debugging, error reporting or configuration purposes. overall-timeout Duration PT1S Overall timeout. When overall timeout is reached, execution terminates (even if the retry policy was not exhausted). retry-policy io.helidon.faulttolerance.Retry.RetryPolicy (service provider interface) Such as: DelayingRetryPolicy JitterRetryPolicy &#160; Configure a retry policy to use to calculate delays between retries. Defaults to a io.helidon.faulttolerance.Retry.JitterRetryPolicy with 4 calls (initial call + 3 retries), delay of 200 millis and a jitter of 50 millis. ",
            "title": "Configuration options"
        },
        {
            "location": "config/io_helidon_faulttolerance_Retry_DelayingRetryPolicy",
            "text": " A retry policy that prolongs the delays between retries by a defined factor. Type: io.helidon.faulttolerance.Retry.DelayingRetryPolicy This type provides the following service implementations: io.helidon.faulttolerance.Retry.RetryPolicy ",
            "title": "preambule"
        },
        {
            "location": "config/io_helidon_faulttolerance_Retry_DelayingRetryPolicy",
            "text": " Optional configuration options key type default value description calls int 3 Total number of calls (first + retries). delay Duration PT0.2S Base delay between the invocations. delay-factor double 2 A delay multiplication factor. ",
            "title": "Configuration options"
        },
        {
            "location": "config/io_helidon_faulttolerance_Retry_JitterRetryPolicy",
            "text": " Type: io.helidon.faulttolerance.Retry.JitterRetryPolicy This type provides the following service implementations: io.helidon.faulttolerance.Retry.RetryPolicy ",
            "title": "preambule"
        },
        {
            "location": "config/io_helidon_faulttolerance_Retry_JitterRetryPolicy",
            "text": " Optional configuration options key type default value description calls int 3 Total number of calls (first + retries). delay Duration PT0.2S Base delay between the invocations. jitter Duration PT0.05S Random part of the delay. A number between [-jitter,+jitter] is applied to delay each time delay is calculated. ",
            "title": "Configuration options"
        },
        {
            "location": "config/io_helidon_faulttolerance_Timeout",
            "text": " Type: io.helidon.faulttolerance.Timeout ",
            "title": "preambule"
        },
        {
            "location": "config/io_helidon_faulttolerance_Timeout",
            "text": " Optional configuration options key type default value description cancel-source boolean true Cancel source if destination stage is cancelled. current-thread boolean false Flag to indicate that code must be executed in current thread instead of in an executor&#8217;s thread. This flag is false by default. name string Timeout- A name assigned for debugging, error reporting or configuration purposes. timeout Duration PT10S Timeout duration. ",
            "title": "Configuration options"
        },
        {
            "location": "config/io_helidon_grpc_client_GrpcChannelDescriptor",
            "text": " Type: io.helidon.grpc.client.GrpcChannelDescriptor ",
            "title": "preambule"
        },
        {
            "location": "config/io_helidon_grpc_client_GrpcChannelDescriptor",
            "text": " Optional configuration options key type default value description host string localhost Set the host name to connect. port int 1408 Set the port that will be used to connect to the server. target string &#160; Set the target string, which can be either a valid io.grpc.NameResolver compliant URI, or an authority string. tls GrpcTlsDescriptor &#160; Set the GrpcTlsDescriptor. If tlsDescriptor is null or if the tlsDescriptor.isEnabled() is false, then no TLS will be used. ",
            "title": "Configuration options"
        },
        {
            "location": "config/io_helidon_grpc_core_GrpcTlsDescriptor",
            "text": " Type: io.helidon.grpc.core.GrpcTlsDescriptor ",
            "title": "preambule"
        },
        {
            "location": "config/io_helidon_grpc_core_GrpcTlsDescriptor",
            "text": " Optional configuration options key type default value description enabled boolean true Enable or disable TLS. If enabled is false, then the rest of the TLS configuration properties are ignored. jdk-ssl boolean false Sets the type of SSL implementation to be used. tls-ca-cert Resource &#160; Set the CA (certificate authority) certificate path. tls-cert Resource &#160; Set the client tlsCert path. Required only if mutual auth is desired. tls-key Resource &#160; Set the client private key path. Required only if mutual auth is desired. ",
            "title": "Configuration options"
        },
        {
            "location": "config/io_helidon_grpc_server_GrpcServerConfiguration",
            "text": " Type: io.helidon.grpc.server.GrpcServerConfiguration ",
            "title": "preambule"
        },
        {
            "location": "config/io_helidon_grpc_server_GrpcServerConfiguration",
            "text": " Optional configuration options key type default value description name string grpc.server Set the name of the gRPC server. Configuration key: `name` native boolean false Specify if native transport should be used. port int 1408 Sets server port. If port is 0 or less then any available ephemeral port will be used. Configuration key: `port` workers int Number of processors available to the JVM Sets a count of threads in pool used to process HTTP requests. Default value is CPU_COUNT * 2 . Configuration key: `workers` ",
            "title": "Configuration options"
        },
        {
            "location": "config/io_helidon_health_HealthSupport",
            "text": " Type: io.helidon.health.HealthSupport This is a standalone configuration type, prefix from configuration root: health ",
            "title": "preambule"
        },
        {
            "location": "config/io_helidon_health_HealthSupport",
            "text": " Optional configuration options key type default value description cors CrossOriginConfig &#160; Sets the cross-origin config builder for use in establishing CORS support for the service endpoints. enabled boolean true HealthSupport can be disabled by invoking this method. exclude string[&#93; &#160; Add health checks to a black list. Health check results that match by name with a blacklisted records will not be part of the result. exclude-classes Class&lt;?&gt;[&#93; &#160; A class may be excluded from invoking health checks on it. This allows configurable approach to disabling broken health-checks. include string[&#93; &#160; Add health checks to a white list (in case #includeAll is set to false . routing string &#160; Sets the routing name to use for setting up the service&#8217;s endpoint. timeout-millis long 10000 health endpoint timeout (ms) web-context string &#160; Sets the web context to use for the service&#8217;s endpoint. ",
            "title": "Configuration options"
        },
        {
            "location": "config/io_helidon_integrations_micrometer_MicrometerSupport",
            "text": " Type: io.helidon.integrations.micrometer.MicrometerSupport <markup lang=\"text\" title=\"Config key\" >micrometer ",
            "title": "preambule"
        },
        {
            "location": "config/io_helidon_integrations_micrometer_MicrometerSupport",
            "text": " Optional configuration options key type default value description cors CrossOriginConfig &#160; Sets the cross-origin config builder for use in establishing CORS support for the service endpoints. routing string &#160; Sets the routing name to use for setting up the service&#8217;s endpoint. web-context string &#160; Sets the web context to use for the service&#8217;s endpoint. ",
            "title": "Configuration options"
        },
        {
            "location": "config/io_helidon_media_common_MediaContext",
            "text": " Type: io.helidon.media.common.MediaContext ",
            "title": "preambule"
        },
        {
            "location": "config/io_helidon_media_common_MediaContext",
            "text": " Required configuration options key type default value description services io.helidon.media.common.spi.MediaSupportProvider[&#93; (service provider interface) &#160; Configures this Builder from the supplied Config. &lt;table class=\"config\"&gt; &lt;caption&gt;Optional configuration parameters&lt;/caption&gt; &lt;tr&gt; &lt;th&gt;key&lt;/th&gt; &lt;th&gt;description&lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;register-defaults&lt;/td&gt; &lt;td&gt;Whether to register default reader and writers&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;discover-services&lt;/td&gt; &lt;td&gt;Whether to discover services via service loader&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;filter-services&lt;/td&gt; &lt;td&gt;Whether to filter discovered services by service names in services section&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;services&lt;/td&gt; &lt;td&gt;Configuration section for each service. Each entry has to have \"name\" parameter. It is also used for filtering of loaded services.&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; Optional configuration options key type default value description discover-services boolean false Whether Java Service Loader should be used to load MediaSupportProvider. filter-services boolean false Whether services loaded by Java Service Loader should be filtered. All of the services which should pass the filter, have to be present under services section of configuration. register-defaults boolean true Whether default readers and writers should be registered. ",
            "title": "Configuration options"
        },
        {
            "location": "config/io_helidon_metrics_api_BaseMetricsSettings",
            "text": " Type: io.helidon.metrics.api.BaseMetricsSettings <markup lang=\"text\" title=\"Config key\" >metrics.base ",
            "title": "preambule"
        },
        {
            "location": "config/io_helidon_metrics_api_BaseMetricsSettings",
            "text": " Optional configuration options key type default value description enabled boolean true Sets whether base metrics should be enabled. x.y.enabled boolean true Sets whether a specific base metric should be enabled. ",
            "title": "Configuration options"
        },
        {
            "location": "config/io_helidon_metrics_api_ComponentMetricsSettings",
            "text": " Type: io.helidon.metrics.api.ComponentMetricsSettings <markup lang=\"text\" title=\"Config key\" >metrics ",
            "title": "preambule"
        },
        {
            "location": "config/io_helidon_metrics_api_ComponentMetricsSettings",
            "text": " Optional configuration options key type default value description enabled boolean &#160; Sets whether metrics should be enabled for the component. ",
            "title": "Configuration options"
        },
        {
            "location": "config/io_helidon_metrics_api_KeyPerformanceIndicatorMetricsSettings",
            "text": " Type: io.helidon.metrics.api.KeyPerformanceIndicatorMetricsSettings <markup lang=\"text\" title=\"Config key\" >metrics.key-performance-indicators ",
            "title": "preambule"
        },
        {
            "location": "config/io_helidon_metrics_api_KeyPerformanceIndicatorMetricsSettings",
            "text": " Optional configuration options key type default value description extended boolean &#160; Sets whether exntended KPI metrics should be enabled in the settings. long-running-requests.threshold-ms long 10000 Sets the long-running request threshold (in ms). ",
            "title": "Configuration options"
        },
        {
            "location": "config/io_helidon_metrics_api_MetricsSettings",
            "text": " Type: io.helidon.metrics.api.MetricsSettings <markup lang=\"text\" title=\"Config key\" >metrics ",
            "title": "preambule"
        },
        {
            "location": "config/io_helidon_metrics_api_MetricsSettings",
            "text": " Optional configuration options key type default value description appName string &#160; Sets the value for the _app tag to be applied to all metrics. base BaseMetricsSettings &#160; Set the base metrics settings. enabled boolean &#160; Sets whether metrics should be enabled. key-performance-indicators KeyPerformanceIndicatorMetricsSettings &#160; Set the KPI metrics settings. registries Map&lt;string, RegistrySettings&gt; &#160; Sets the registry settings for the specified registry type. tags Map&lt;string, string&gt; &#160; Sets the global tags to be applied to all metrics. ",
            "title": "Configuration options"
        },
        {
            "location": "config/io_helidon_metrics_api_RegistryFilterSettings",
            "text": " Type: io.helidon.metrics.api.RegistryFilterSettings ",
            "title": "preambule"
        },
        {
            "location": "config/io_helidon_metrics_api_RegistryFilterSettings",
            "text": " Optional configuration options key type default value description exclude string &#160; Regular expression matching metric names to exclude include string &#160; Regular expression matching metrics names to include ",
            "title": "Configuration options"
        },
        {
            "location": "config/io_helidon_metrics_api_RegistrySettings",
            "text": " Type: io.helidon.metrics.api.RegistrySettings <markup lang=\"text\" title=\"Config key\" >metrics.&amp;lt;metric-type&amp;gt; ",
            "title": "preambule"
        },
        {
            "location": "config/io_helidon_metrics_api_RegistrySettings",
            "text": " Optional configuration options key type default value description enabled boolean true Sets whether the metric type should be enabled. filter RegistryFilterSettings &#160; Name filtering, featuring optional exclude and include settings ",
            "title": "Configuration options"
        },
        {
            "location": "config/io_helidon_metrics_serviceapi_MetricsSupport",
            "text": " Type: io.helidon.metrics.serviceapi.MetricsSupport ",
            "title": "preambule"
        },
        {
            "location": "config/io_helidon_metrics_serviceapi_MetricsSupport",
            "text": " Optional configuration options key type default value description appName string &#160; Sets the value for the _app tag to be applied to all metrics. base BaseMetricsSettings &#160; Set the base metrics settings. cors CrossOriginConfig &#160; Sets the cross-origin config builder for use in establishing CORS support for the service endpoints. enabled boolean &#160; Sets whether metrics should be enabled. key-performance-indicators KeyPerformanceIndicatorMetricsSettings &#160; Set the KPI metrics settings. registries Map&lt;string, RegistrySettings&gt; &#160; Sets the registry settings for the specified registry type. routing string &#160; Sets the routing name to use for setting up the service&#8217;s endpoint. tags Map&lt;string, string&gt; &#160; Sets the global tags to be applied to all metrics. web-context string &#160; Sets the web context to use for the service&#8217;s endpoint. ",
            "title": "Configuration options"
        },
        {
            "location": "config/io_helidon_microprofile_jwt",
            "text": " MicroProfile configuration options: key type default value description mp.jwt.verify.publickey string &#160; The property allows the Public Verification Key text itself to be supplied as a string. mp.jwt.verify.publickey.location string &#160; The property allows for an external or internal location of Public Verification Key to be specified. The value may be a relative path or a URL. mp.jwt.verify.publickey.algorithm string &#160; The configuration property allows for specifying which Public Key Signature Algorithm is supported by the MP JWT endpoint. This property can be set to either RS256 or ES256 . Default value is RS256 . Support for the other asymmetric signature algorithms such as RS512 , ES512 and others is optional. Optional configuration options: key type default value description optional boolean false If set to true , failure to authenticate will return ABSTAIN result instead of FAILURE . This is an important distinction when more than one provider is used authenticate boolean true Whether to attempt authentication propagate boolean true Whether to attempt identity propagation/JWT creation principal-type string USER Whether we authenticate a user or a service (other option is SERVICE) atn-token string A group for configuring authentication of the request atn-token.verify-signature boolean true Whether to verify signature in incoming JWT. If disabled, ANY JWT will be accepted atn-token.jwt-audience string &#160; Expected audience of the JWT. If not defined, any audience is accepted (and we may accept JWT not inteded for us) atn-token.jwk.resource.* string &#160; Configuration of the JWK to obtain key(s) to validate signatures of inbound token. The JWK should contain public keys. This may be: jwk.resource.path, jwk.resource.resource-path, jwk.resource.url, jwk.resource.content-plain (actual JSON string), jwk.resource.content (base64) atn-token.handler string Authorization header with `bearer ` prefix A handler configuration for inbound token - e.g. how to extract it atn-token.handler.header string &#160; Name of a header the token is expected in atn-token.handler.prefix string &#160; Prefix before the token value (optional) atn-token.handler.regexp string &#160; Regular expression to obtain the token, first matching group is used (optional) sign-token string &#160; A group for configuring outbound security sign-token.jwk.resource.* &#160; Configuration of the JWK to use when generating tokens (follows same rules as atn-token.jwk above), this JWK must contain private keys when using asymmetric ciphers sign-token.jwt-issuer string &#160; When we issue a new token, this is the issuer to be placed into it (validated by target service) sign-token.outbound string &#160; A group for configuring outbound rules (based on transport, host and.or path) sign-token.outbound.*.name string &#160; A short descriptive name for configured target service(s) sign-token.outbound.*.transports string any An array of transports this outbound matches (e.g. https) sign-token.outbound.*.hosts string any An array of hosts this outbound matches, may use * as a wild-card (e.g. *.oracle.com) sign-token.outbound.*.paths string any An array of paths on the host this outbound matches, may use * as a wild-card (e.g. /some/path/*) sign-token.outbound.*.outbound-token string Authorization header with `bearer ` prefix Configuration of outbound token handler (same as atn-token.handler) sign-token.outbound.*.outbound-token.format string &#160; Java text format for generating the value of outbound token header (e.g. \"bearer %1$s\") sign-token.outbound.*.jwk-kid string &#160; If this key is defined, we are generating a new token, otherwise we propagate existing. Defines the key id of a key definition in the JWK file to use for signing the outbound token sign-token.outbound.*.jwt-kid string &#160; A key to use in the generated JWT - this is for the other service to locate the verification key in their JWK sign-token.outbound.*.jwt-audience string &#160; Audience this key is generated for (e.g. http://www.example.org/api/myService ) - validated by the other service sign-token.outbound.*.jwt-not-before-seconds string 5 Makes this key valid this amount of seconds into the past. Allows a certain time-skew for the generated token to be valid before current time (e.g. when we expect a certain misalignment of clocks) sign-token.outbound.*.jwt-validity-seconds ",
            "title": "Configuration Options"
        },
        {
            "location": "config/io_helidon_microprofile_openapi_MPOpenAPISupport",
            "text": " Type: io.helidon.microprofile.openapi.MPOpenAPISupport <markup lang=\"text\" title=\"Config key\" >mp.openapi ",
            "title": "preambule"
        },
        {
            "location": "config/io_helidon_microprofile_openapi_MPOpenAPISupport",
            "text": " Optional configuration options key type default value description application-path-disable boolean false Sets whether the app path search should be disabled. cors CrossOriginConfig &#160; Assigns the CORS settings for the OpenAPI endpoint. custom-schema-registry-class string &#160; Sets the custom schema registry class. filter string &#160; Sets the developer-provided OpenAPI filter class name. model.reader string &#160; Sets the developer-provided OpenAPI model reader class name. scan.classes string[&#93; &#160; Specify the list of classes to scan. scan.disable boolean false Disable annotation scanning. scan.exclude.classes string[&#93; &#160; Specify the list of classes to exclude from scans. scan.exclude.packages string[&#93; &#160; Specify the list of packages to exclude from scans. scan.packages string[&#93; &#160; Specify the list of packages to scan. schema.* string &#160; Sets the schema for the indicated fully-qualified class name (represented here by '*'); value is the schema in JSON format. Repeat for multiple classes. servers string[&#93; &#160; Sets servers. servers.operation.* string[&#93; &#160; Sets alternative servers to service the indicated operation (represented here by '*'). Repeat for multiple operations. servers.path.* string[&#93; &#160; Sets alternative servers to service all operations at the indicated path (represented here by '*'). Repeat for multiple paths. static-file string META-INF/openapi.* Sets the file system path of the static OpenAPI document file. Default types are json , yaml , and yml . web-context string /openapi Sets the web context path for the OpenAPI endpoint. ",
            "title": "Configuration options"
        },
        {
            "location": "config/io_helidon_microprofile_server_Server",
            "text": " Configuration of Helidon Microprofile Server Type: io.helidon.microprofile.server.Server This is a standalone configuration type, prefix from configuration root: server ",
            "title": "preambule"
        },
        {
            "location": "config/io_helidon_microprofile_server_Server",
            "text": " Optional configuration options key type default value description executor-service ExecutorService&gt; &#160; Set a supplier of an executor service to use for tasks connected with application processing (JAX-RS). host string &#160; Configure listen host. port int &#160; Configure listen port. ",
            "title": "Configuration Options"
        },
        {
            "location": "config/io_helidon_openapi_OpenAPISupport",
            "text": " OpenAPI support configuration Type: io.helidon.openapi.OpenAPISupport ",
            "title": "preambule"
        },
        {
            "location": "config/io_helidon_openapi_OpenAPISupport",
            "text": " Optional configuration options key type default value description cors CrossOriginConfig &#160; Assigns the CORS settings for the OpenAPI endpoint. static-file string META-INF/openapi.* Sets the file system path of the static OpenAPI document file. Default types are json , yaml , and yml . web-context string /openapi Sets the web context path for the OpenAPI endpoint. ",
            "title": "Configuration options"
        },
        {
            "location": "config/io_helidon_openapi_SEOpenAPISupport",
            "text": " Type: io.helidon.openapi.SEOpenAPISupport <markup lang=\"text\" title=\"Config key\" >openapi ",
            "title": "preambule"
        },
        {
            "location": "config/io_helidon_openapi_SEOpenAPISupport",
            "text": " Optional configuration options key type default value description application-path-disable boolean false Sets whether the app path search should be disabled. cors CrossOriginConfig &#160; Assigns the CORS settings for the OpenAPI endpoint. custom-schema-registry-class string &#160; Sets the custom schema registry class. filter string &#160; Sets the developer-provided OpenAPI filter class name. model.reader string &#160; Sets the developer-provided OpenAPI model reader class name. schema.* string &#160; Sets the schema for the indicated fully-qualified class name (represented here by '*'); value is the schema in JSON format. Repeat for multiple classes. servers string[&#93; &#160; Sets servers. servers.operation.* string[&#93; &#160; Sets alternative servers to service the indicated operation (represented here by '*'). Repeat for multiple operations. servers.path.* string[&#93; &#160; Sets alternative servers to service all operations at the indicated path (represented here by '*'). Repeat for multiple paths. static-file string META-INF/openapi.* Sets the file system path of the static OpenAPI document file. Default types are json , yaml , and yml . web-context string /openapi Sets the web context path for the OpenAPI endpoint. ",
            "title": "Configuration options"
        },
        {
            "location": "config/io_helidon_security_Security",
            "text": " Configuration of security providers, integration and other security options Type: io.helidon.security.Security This is a standalone configuration type, prefix from configuration root: security ",
            "title": "preambule"
        },
        {
            "location": "config/io_helidon_security_Security",
            "text": " Required configuration options key type default value description providers io.helidon.security.spi.SecurityProvider[&#93; (service provider interface) Such as: http-basic-auth (HttpBasicAuthProvider) google-login (GoogleTokenProvider) oidc (OidcProvider) http-digest-auth (HttpDigestAuthProvider) idcs-role-mapper (IdcsMtRoleMapperRxProvider) jwt (JwtProvider) header-atn (HeaderAtnProvider) idcs-role-mapper (IdcsRoleMapperRxProvider) abac (AbacProvider) &#160; Add a provider, works as #addProvider(io.helidon.security.spi.SecurityProvider, String), where the name is set to Class#getSimpleName() . Optional configuration options key type default value description default-authentication-provider string (service provider interface) &#160; ID of the default authentication provider default-authorization-provider string &#160; ID of the default authorization provider enabled boolean true Security can be disabled using configuration, or explicitly. By default, security instance is enabled. Disabled security instance will not perform any checks and allow all requests. environment.executor-service ThreadPoolSupplier &#160; Configure executor service to be used for blocking operations within security. environment.server-time SecurityTime &#160; Server time to use when evaluating security policies that depend on time. provider-policy.class-name Class &#160; Provider selection policy class name, only used when type is set to CLASS provider-policy.type ProviderSelectionPolicyType (FIRST, COMPOSITE, CLASS) FIRST Type of the policy. secrets Map&lt;string, string&gt; (documented for specific cases) &#160; Configured secrets secrets.*.config io.helidon.security.SecretsProviderConfig (service provider interface) &#160; Configuration specific to the secret provider secrets.*.name string &#160; Name of the secret, used for lookup secrets.*.provider string &#160; Name of the secret provider tracing.enabled boolean true Whether or not tracing should be enabled. If set to false, security tracer will be a no-op tracer. ",
            "title": "Configuration options"
        },
        {
            "location": "config/io_helidon_security_SecurityTime",
            "text": " Type: io.helidon.security.SecurityTime ",
            "title": "preambule"
        },
        {
            "location": "config/io_helidon_security_SecurityTime",
            "text": " Optional configuration options key type default value description day-of-month long &#160; Set an explicit value for one of the time fields (such as ChronoField#YEAR). hour-of-day long &#160; Set an explicit value for one of the time fields (such as ChronoField#YEAR). millisecond long &#160; Set an explicit value for one of the time fields (such as ChronoField#YEAR). minute long &#160; Set an explicit value for one of the time fields (such as ChronoField#YEAR). month long &#160; Set an explicit value for one of the time fields (such as ChronoField#YEAR). second long &#160; Set an explicit value for one of the time fields (such as ChronoField#YEAR). shift-by-seconds long 0 Configure a time-shift in seconds, to move the current time to past or future. time-zone ZoneId &#160; Override current time zone. The time will represent the SAME instant, in an explicit timezone. If we are in a UTC time zone and you set the timezone to \"Europe/Prague\", the time will be shifted by the offset of Prague (e.g. if it is noon right now in UTC, you would get 14:00). year long &#160; Set an explicit value for one of the time fields (such as ChronoField#YEAR). ",
            "title": "Configuration options"
        },
        {
            "location": "config/io_helidon_security_providers_abac_AbacProvider",
            "text": " Attribute Based Access Control provider Type: io.helidon.security.providers.abac.AbacProvider <markup lang=\"text\" title=\"Config key\" >abac This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthorizationProvider ",
            "title": "preambule"
        },
        {
            "location": "config/io_helidon_security_providers_abac_AbacProvider",
            "text": " Optional configuration options key type default value description fail-if-none-validated boolean true Whether to fail if NONE of the attributes is validated. fail-on-unvalidated boolean true Whether to fail if any attribute is left unvalidated. ",
            "title": "Configuration options"
        },
        {
            "location": "config/io_helidon_security_providers_common_EvictableCache",
            "text": " Type: io.helidon.security.providers.common.EvictableCache ",
            "title": "preambule"
        },
        {
            "location": "config/io_helidon_security_providers_common_EvictableCache",
            "text": " Optional configuration options key type default value description cache-enabled boolean true If the cacheEnabled is set to false, no caching will be done. Otherwise (default behavior) evictable caching will be used. cache-evict-delay-millis long 60000 Delay from the creation of the cache to first eviction cache-evict-period-millis long 300000 How often to evict records cache-overall-timeout-millis long 3600000 Configure record timeout since its creation. cache-timeout-millis long 3600000 Configure record timeout since last access. evictor-class Class &#160; Configure evictor to check if a record is still valid. This should be a fast way to check, as it is happening in a ConcurrentHashMap#forEachKey(long, Consumer). This is also called during all get and remove operations to only return valid records. max-size long 100000 Configure maximal cache size. parallelism-threshold long 10000 Configure parallelism threshold. ",
            "title": "Configuration options"
        },
        {
            "location": "config/io_helidon_security_providers_common_OutboundConfig",
            "text": " Outbound configuration for outbound security Type: io.helidon.security.providers.common.OutboundConfig ",
            "title": "preambule"
        },
        {
            "location": "config/io_helidon_security_providers_common_OutboundConfig",
            "text": " Optional configuration options key type default value description outbound OutboundTarget[&#93; &#160; Add a new target configuration. ",
            "title": "Configuration options"
        },
        {
            "location": "config/io_helidon_security_providers_common_OutboundTarget",
            "text": " Type: io.helidon.security.providers.common.OutboundTarget ",
            "title": "preambule"
        },
        {
            "location": "config/io_helidon_security_providers_common_OutboundTarget",
            "text": " Required configuration options key type default value description name string &#160; Configure the name of this outbound target. Optional configuration options key type default value description hosts string[&#93; &#160; Add supported host for this target. May be called more than once to add more hosts. Valid examples: localhost www.google.com 127.0.0.1 *.oracle.com 192.169. . .google. methods string[&#93; &#160; Add supported method for this target. May be called more than once to add more methods. The method is tested as is ignoring case against the used method. paths string[&#93; &#160; Add supported paths for this target. May be called more than once to add more paths. The path is tested as is against called path, and also tested as a regular expression. transport string[&#93; &#160; Add supported transports for this target. May be called more than once to add more transports. Valid examples: http https There is no wildcard support ",
            "title": "Configuration options"
        },
        {
            "location": "config/io_helidon_security_providers_google_login_GoogleTokenProvider",
            "text": " Google Authentication provider Type: io.helidon.security.providers.google.login.GoogleTokenProvider <markup lang=\"text\" title=\"Config key\" >google-login This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthenticationProvider ",
            "title": "preambule"
        },
        {
            "location": "config/io_helidon_security_providers_google_login_GoogleTokenProvider",
            "text": " Optional configuration options key type default value description client-id string &#160; Google application client id, to validate that the token was generated by Google for us. optional boolean false If set to true, this provider will return io.helidon.security.SecurityResponse.SecurityStatus#ABSTAIN instead of failing in case of invalid request. outbound OutboundConfig &#160; Outbound configuration - a set of outbound targets that will have the token propagated. proxy-host string &#160; Set proxy host when talking to Google. proxy-port int 80 Set proxy port when talking to Google. realm string helidon Set the authentication realm to build challenge, defaults to \"helidon\". token TokenHandler &#x60;Authorization&#x60; header with &#x60;bearer&#x60; prefix Token provider to extract Google access token from request, defaults to \"Authorization\" header with a \"bearer \" prefix. ",
            "title": "Configuration options"
        },
        {
            "location": "config/io_helidon_security_providers_header_HeaderAtnProvider",
            "text": " Security provider that extracts a username (or service name) from a header. Type: io.helidon.security.providers.header.HeaderAtnProvider <markup lang=\"text\" title=\"Config key\" >header-atn This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthenticationProvider ",
            "title": "preambule"
        },
        {
            "location": "config/io_helidon_security_providers_header_HeaderAtnProvider",
            "text": " Optional configuration options key type default value description atn-token TokenHandler &#160; Token handler to extract username from request. authenticate boolean true Whether to authenticate requests. optional boolean false Whether authentication is required. By default, request will fail if the username cannot be extracted. If set to false, request will process and this provider will abstain. outbound OutboundTarget[&#93; &#160; Configure outbound target for identity propagation. outbound-token TokenHandler &#160; Token handler to create outbound headers to propagate identity. If not defined, #atnTokenHandler will be used. principal-type SubjectType (USER, SERVICE) USER Principal type this provider extracts (and also propagates). propagate boolean false Whether to propagate identity. ",
            "title": "Configuration options"
        },
        {
            "location": "config/io_helidon_security_providers_httpauth_ConfigUserStore_ConfigUser",
            "text": " Type: io.helidon.security.providers.httpauth.ConfigUserStore.ConfigUser ",
            "title": "preambule"
        },
        {
            "location": "config/io_helidon_security_providers_httpauth_ConfigUserStore_ConfigUser",
            "text": " Optional configuration options key type default value description login string &#160; User&#8217;s login password string &#160; User&#8217;s password roles string[&#93; &#160; List of roles the user is in ",
            "title": "Configuration options"
        },
        {
            "location": "config/io_helidon_security_providers_httpauth_HttpBasicAuthProvider",
            "text": " HTTP Basic Authentication provider Type: io.helidon.security.providers.httpauth.HttpBasicAuthProvider <markup lang=\"text\" title=\"Config key\" >http-basic-auth This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthenticationProvider ",
            "title": "preambule"
        },
        {
            "location": "config/io_helidon_security_providers_httpauth_HttpBasicAuthProvider",
            "text": " Optional configuration options key type default value description optional boolean false Whether authentication is required. By default, request will fail if the authentication cannot be verified. If set to false, request will process and this provider will abstain. outbound OutboundTarget[&#93; &#160; Add a new outbound target to configure identity propagation or explicit username/password. principal-type SubjectType (USER, SERVICE) USER Principal type this provider extracts (and also propagates). realm string helidon Set the realm to use when challenging users. users ConfigUser[&#93; &#160; Set user store to validate users. Removes any other stores added through #addUserStore(SecureUserStore). ",
            "title": "Configuration options"
        },
        {
            "location": "config/io_helidon_security_providers_httpauth_HttpDigestAuthProvider",
            "text": " Http digest authentication security provider Type: io.helidon.security.providers.httpauth.HttpDigestAuthProvider <markup lang=\"text\" title=\"Config key\" >http-digest-auth This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthenticationProvider ",
            "title": "preambule"
        },
        {
            "location": "config/io_helidon_security_providers_httpauth_HttpDigestAuthProvider",
            "text": " Optional configuration options key type default value description algorithm Algorithm (MD5) MD5 Digest algorithm to use. nonce-timeout-millis long 86400000 How long will the nonce value be valid. When timed-out, browser will re-request username/password. optional boolean false Whether authentication is required. By default, request will fail if the authentication cannot be verified. If set to false, request will process and this provider will abstain. principal-type SubjectType (USER, SERVICE) USER Principal type this provider extracts (and also propagates). qop Qop (NONE, AUTH) NONE Only AUTH supported. If left empty, uses the legacy approach (older RFC version). AUTH-INT is not supported. realm string Helidon Set the realm to use when challenging users. server-secret string &#160; The nonce is encrypted using this secret - to make sure the nonce we get back was generated by us and to make sure we can safely time-out nonce values. This secret must be the same for all service instances (or all services that want to share the same authentication). Defaults to a random password - e.g. if deployed to multiple servers, the authentication WILL NOT WORK. You MUST provide your own password to work in a distributed environment with non-sticky load balancing. users ConfigUser[&#93; &#160; Set user store to obtain passwords and roles based on logins. ",
            "title": "Configuration options"
        },
        {
            "location": "config/io_helidon_security_providers_httpsign_HttpSignProvider",
            "text": " HTTP header signature provider. Type: io.helidon.security.providers.httpsign.HttpSignProvider <markup lang=\"text\" title=\"Config key\" >http-signatures This type provides the following service implementations: io.helidon.security.spi.AuthenticationProvider ",
            "title": "preambule"
        },
        {
            "location": "config/io_helidon_security_providers_httpsign_HttpSignProvider",
            "text": " Optional configuration options key type default value description backward-compatible-eol boolean false Enable support for Helidon versions before 3.0.0 (exclusive). Until version 3.0.0 (exclusive) there was a trailing end of line added to the signed data. To be able to communicate cross versions, we must configure this when talking to older versions of Helidon. Default value is `false`. In Helidon 2.x, this switch exists as well and the default is `true`, to allow communication between versions as needed. headers HttpSignHeader[&#93; (SIGNATURE, AUTHORIZATION, CUSTOM) &#160; Add a header that is validated on inbound requests. Provider may support more than one header to validate. inbound.keys InboundClientDefinition[&#93; &#160; Add inbound configuration. This is used to validate signature and authenticate the party. The same can be done through configuration: &lt;pre&gt; { name = \"http-signatures\" class = \"HttpSignProvider\" http-signatures { inbound { # This configures the InboundClientDefinition keys: [ { key-id = \"service1\" hmac.secret = \"${CLEAR=password}\" }] } } } &lt;/pre&gt; optional boolean true Set whether the signature is optional. If set to true (default), this provider will SecurityResponse.SecurityStatus#ABSTAIN from this request if signature is not present. If set to false, this provider will SecurityResponse.SecurityStatus#FAILURE fail if signature is not present. outbound OutboundConfig &#160; Add outbound targets to this builder. The targets are used to chose what to do for outbound communication. The targets should have OutboundTargetDefinition attached through OutboundTarget.Builder#customObject(Class, Object) to tell us how to sign the request. The same can be done through configuration: &lt;pre&gt; { name = \"http-signatures\" class = \"HttpSignProvider\" http-signatures { targets: [ { name = \"service2\" hosts = [\"localhost\"] paths = [\"/service2/.*\"] # This configures the OutboundTargetDefinition signature { key-id = \"service1\" hmac.secret = \"${CLEAR=password}\" } }] } } &lt;/pre&gt; realm string helidon Realm to use for challenging inbound requests that do not have \"Authorization\" header in case header is HttpSignHeader#AUTHORIZATION and singatures are not optional. sign-headers HeadersConfig[&#93; &#160; Override the default inbound required headers (e.g. headers that MUST be signed and headers that MUST be signed IF present). Defaults: get, head, delete methods: date, (request-target), host are mandatory; authorization if present (unless we are creating/validating the HttpSignHeader#AUTHORIZATION ourselves put, post: same as above, with addition of: content-length, content-type and digest if present for other methods: date, (request-target) Note that this provider DOES NOT validate the \"Digest\" HTTP header, only the signature. ",
            "title": "Configuration options"
        },
        {
            "location": "config/io_helidon_security_providers_httpsign_InboundClientDefinition",
            "text": " Type: io.helidon.security.providers.httpsign.InboundClientDefinition ",
            "title": "preambule"
        },
        {
            "location": "config/io_helidon_security_providers_httpsign_InboundClientDefinition",
            "text": " Optional configuration options key type default value description algorithm string &#160; Algorithm of signature used by this client. Currently supported: rsa-sha256 - asymmetric based on public/private keys hmac-sha256 - symmetric based on a shared secret hmac.secret string &#160; Helper method to configure a password-like secret (instead of byte based #hmacSecret(byte[]). The password is transformed to bytes with StandardCharsets#UTF_8 charset. key-id string &#160; The key id of this client to map to this signature validation configuration. principal-name string &#160; The principal name of the client, defaults to keyId if not configured. principal-type SubjectType (USER, SERVICE) SERVICE The type of principal we have authenticated (either user or service, defaults to service). public-key KeyConfig &#160; For algorithms based on public/private key (such as rsa-sha256), this provides access to the public key of the client. ",
            "title": "Configuration options"
        },
        {
            "location": "config/io_helidon_security_providers_httpsign_SignedHeadersConfig_HeadersConfig",
            "text": " Type: io.helidon.security.providers.httpsign.SignedHeadersConfig.HeadersConfig ",
            "title": "preambule"
        },
        {
            "location": "config/io_helidon_security_providers_httpsign_SignedHeadersConfig_HeadersConfig",
            "text": " Optional configuration options key type default value description always string[&#93; &#160; Headers that must be signed (and signature validation or creation should fail if not signed or present) if-present string[&#93; &#160; Headers that must be signed if present in request. method string &#160; HTTP method this header configuration is bound to. If not present, it is considered default header configuration. ",
            "title": "Configuration options"
        },
        {
            "location": "config/io_helidon_security_providers_idcs_mapper_IdcsMtRoleMapperRxProvider",
            "text": " Multitenant IDCS role mapping provider Type: io.helidon.security.providers.idcs.mapper.IdcsMtRoleMapperRxProvider <markup lang=\"text\" title=\"Config key\" >idcs-role-mapper This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.SubjectMappingProvider ",
            "title": "preambule"
        },
        {
            "location": "config/io_helidon_security_providers_idcs_mapper_IdcsMtRoleMapperRxProvider",
            "text": " Optional configuration options key type default value description cache-config EvictableCache &#160; Use explicit io.helidon.security.providers.common.EvictableCache for role caching. default-idcs-subject-type string user Configure subject type to use when requesting roles from IDCS. Can be either #IDCS_SUBJECT_TYPE_USER or #IDCS_SUBJECT_TYPE_CLIENT. Defaults to #IDCS_SUBJECT_TYPE_USER. idcs-app-name-handler TokenHandler &#160; Configure token handler for IDCS Application name. By default the header IdcsMtRoleMapperRxProvider#IDCS_APP_HEADER is used. idcs-tenant-handler TokenHandler &#160; Configure token handler for IDCS Tenant ID. By default the header IdcsMtRoleMapperRxProvider#IDCS_TENANT_HEADER is used. oidc-config OidcConfig &#160; Use explicit io.helidon.security.providers.oidc.common.OidcConfig instance, e.g. when using it also for OIDC provider. subject-types SubjectType[&#93; (USER, SERVICE) USER Add a supported subject type. If none added, io.helidon.security.SubjectType#USER is used. If any added, only the ones added will be used (e.g. if you want to use both io.helidon.security.SubjectType#USER and io.helidon.security.SubjectType#SERVICE, both need to be added. ",
            "title": "Configuration options"
        },
        {
            "location": "config/io_helidon_security_providers_idcs_mapper_IdcsRoleMapperRxProvider",
            "text": " IDCS role mapping provider Type: io.helidon.security.providers.idcs.mapper.IdcsRoleMapperRxProvider <markup lang=\"text\" title=\"Config key\" >idcs-role-mapper This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.SubjectMappingProvider ",
            "title": "preambule"
        },
        {
            "location": "config/io_helidon_security_providers_idcs_mapper_IdcsRoleMapperRxProvider",
            "text": " Optional configuration options key type default value description cache-config EvictableCache &#160; Use explicit io.helidon.security.providers.common.EvictableCache for role caching. default-idcs-subject-type string user Configure subject type to use when requesting roles from IDCS. Can be either #IDCS_SUBJECT_TYPE_USER or #IDCS_SUBJECT_TYPE_CLIENT. Defaults to #IDCS_SUBJECT_TYPE_USER. oidc-config OidcConfig &#160; Use explicit io.helidon.security.providers.oidc.common.OidcConfig instance, e.g. when using it also for OIDC provider. subject-types SubjectType[&#93; (USER, SERVICE) USER Add a supported subject type. If none added, io.helidon.security.SubjectType#USER is used. If any added, only the ones added will be used (e.g. if you want to use both io.helidon.security.SubjectType#USER and io.helidon.security.SubjectType#SERVICE, both need to be added. ",
            "title": "Configuration options"
        },
        {
            "location": "config/io_helidon_security_providers_jwt_JwtProvider",
            "text": " JWT authentication provider Type: io.helidon.security.providers.jwt.JwtProvider <markup lang=\"text\" title=\"Config key\" >jwt This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthenticationProvider ",
            "title": "preambule"
        },
        {
            "location": "config/io_helidon_security_providers_jwt_JwtProvider",
            "text": " Optional configuration options key type default value description allow-impersonation boolean false Whether to allow impersonation by explicitly overriding username from outbound requests using #EP_PROPERTY_OUTBOUND_USER property. By default this is not allowed and identity can only be propagated. allow-unsigned boolean false Configure support for unsigned JWT. If this is set to true any JWT that has algorithm set to none and no kid defined will be accepted. Note that this has serious security impact - if JWT can be sent from a third party, this allows the third party to send ANY JWT and it would be accpted as valid. atn-token.handler TokenHandler &#160; Token handler to extract username from request. atn-token.jwk.resource Resource &#160; JWK resource used to verify JWTs created by other parties. atn-token.jwt-audience string &#160; Audience expected in inbound JWTs. atn-token.verify-signature boolean true Configure whether to verify signatures. Signatures verification is enabled by default. You can configure the provider not to verify signatures. &lt;b&gt;Make sure your service is properly secured on network level and only accessible from a secure endpoint that provides the JWTs when signature verification is disabled. If signature verification is disabled, this service will accept &lt;i&gt;ANY&lt;/i&gt; JWT&lt;/b&gt; authenticate boolean true Whether to authenticate requests. optional boolean false Whether authentication is required. By default, request will fail if the username cannot be extracted. If set to false, request will process and this provider will abstain. principal-type SubjectType (USER, SERVICE) USER Principal type this provider extracts (and also propagates). propagate boolean true Whether to propagate identity. sign-token OutboundConfig &#160; Configuration of outbound rules. sign-token.jwk.resource Resource &#160; JWK resource used to sign JWTs created by us. sign-token.jwt-issuer string &#160; Issuer used to create new JWTs. use-jwt-groups boolean true Claim groups from JWT will be used to automatically add groups to current subject (may be used with jakarta.annotation.security.RolesAllowed annotation). ",
            "title": "Configuration options"
        },
        {
            "location": "config/io_helidon_security_providers_oidc_OidcProvider",
            "text": " Open ID Connect security provider Type: io.helidon.security.providers.oidc.OidcProvider <markup lang=\"text\" title=\"Config key\" >oidc This type provides the following service implementations: io.helidon.security.spi.AuthenticationProvider io.helidon.security.spi.SecurityProvider ",
            "title": "preambule"
        },
        {
            "location": "config/io_helidon_security_providers_oidc_OidcProvider",
            "text": " Optional configuration options key type default value description audience string &#160; Audience of issued tokens. authorization-endpoint-uri URI &#160; URI of an authorization endpoint used to redirect users to for logging-in. If not defined, it is obtained from #oidcMetadata(Resource), if that is not defined an attempt is made to use #identityUri(URI)/oauth2/v1/authorize. base-scopes string openid Configure base scopes. By default this is DEFAULT_BASE_SCOPES . If scope has a qualifier, it must be used here. client-id string &#160; Client ID as generated by OIDC server. client-secret string &#160; Client secret as generated by OIDC server. Used to authenticate this application with the server when requesting JWT based on a code. client-timeout-millis Duration 30000 Timeout of calls using web client. cookie-domain string &#160; Domain the cookie is valid for. Not used by default. cookie-http-only boolean true When using cookie, if set to true, the HttpOnly attribute will be configured. Defaults to OidcCookieHandler.Builder#DEFAULT_HTTP_ONLY . cookie-max-age-seconds long &#160; When using cookie, used to set MaxAge attribute of the cookie, defining how long the cookie is valid. Not used by default. cookie-name string JSESSIONID Name of the cookie to use. Defaults to DEFAULT_COOKIE_NAME . cookie-path string / Path the cookie is valid for. Defaults to \"/\". cookie-same-site SameSite (LAX, STRICT, NONE) LAX When using cookie, used to set the SameSite cookie value. Can be \"Strict\" or \"Lax\". cookie-secure boolean false When using cookie, if set to true, the Secure attribute will be configured. Defaults to false. cookie-use boolean true Whether to use cookie to store JWT between requests. Defaults to DEFAULT_COOKIE_USE . cors CrossOriginConfig &#160; Assign cross-origin resource sharing settings. force-https-redirects boolean false Force HTTPS for redirects to identity provider. Defaults to false . frontend-uri string &#160; Full URI of this application that is visible from user browser. Used to redirect request back from identity server after successful login. header-token TokenHandler &#160; A TokenHandler to process header containing a JWT. Default is \"Authorization\" header with a prefix \"bearer \". header-use boolean true Whether to expect JWT in a header field. identity-uri URI &#160; URI of the identity server, base used to retrieve OIDC metadata. introspect-endpoint-uri URI &#160; Endpoint to use to validate JWT. Either use this or set #signJwk(JwkKeys) or #signJwk(Resource). issuer string &#160; Issuer of issued tokens. max-redirects int 5 Configure maximal number of redirects when redirecting to an OIDC provider within a single authentication attempt. Defaults to `DEFAULT_MAX_REDIRECTS` oidc-metadata-well-known boolean true If set to true, metadata will be loaded from default (well known) location, unless it is explicitly defined using oidc-metadata-resource. If set to false, it would not be loaded even if oidc-metadata-resource is not defined. In such a case all URIs must be explicitly defined (e.g. token-endpoint-uri). oidc-metadata.resource Resource &#160; Resource configuration for OIDC Metadata containing endpoints to various identity services, as well as information about the identity server. optional boolean false Whether authentication is required. By default, request will fail if the authentication cannot be verified. If set to true, request will process and this provider will abstain. outbound OutboundTarget[&#93; &#160; Add a new target configuration. propagate boolean false Whether to propagate identity. proxy-host string &#160; Proxy host to use. When defined, triggers usage of proxy for HTTP requests. Setting to empty String has the same meaning as setting to null - disables proxy. proxy-port int 80 Proxy port. Defaults to DEFAULT_PROXY_PORT proxy-protocol string http Proxy protocol to use when proxy is used. Defaults to DEFAULT_PROXY_PROTOCOL . query-param-name string accessToken Name of a query parameter that contains the JWT token when parameter is used. query-param-use boolean false Whether to use a query parameter to send JWT token from application to this server. redirect boolean false By default the client should redirect to the identity server for the user to log in. This behavior can be overridden by setting redirect to false. When token is not present in the request, the client will not redirect and just return appropriate error response code. redirect-attempt-param string h_ra Configure the parameter used to store the number of attempts in redirect. Defaults to `DEFAULT_ATTEMPT_PARAM` redirect-uri string /oidc/redirect URI to register web server component on, used by the OIDC server to redirect authorization requests to after a user logs in or approves scopes. Note that usually the redirect URI configured here must be the same one as configured on OIDC server. Defaults to `DEFAULT_REDIRECT_URI` scope-audience string &#160; Audience of the scope required by this application. This is prefixed to the scope name when requesting scopes from the identity server. Defaults to empty string. server-type string @default Configure one of the supported types of identity servers. If the type does not have an explicit mapping, a warning is logged and the default implementation is used. sign-jwk.resource Resource &#160; A resource pointing to JWK with public keys of signing certificates used to validate JWT. token-endpoint-auth ClientAuthentication (CLIENT_SECRET_BASIC, CLIENT_SECRET_POST, CLIENT_SECRET_JWT, PRIVATE_KEY_JWT, NONE) CLIENT_SECRET_BASIC Type of authentication to use when invoking the token endpoint. Current supported options: io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#CLIENT_SECRET_BASIC io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#CLIENT_SECRET_POST io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#NONE token-endpoint-uri URI &#160; URI of a token endpoint used to obtain a JWT based on the authentication code. If not defined, it is obtained from #oidcMetadata(Resource), if that is not defined an attempt is made to use #identityUri(URI)/oauth2/v1/token. use-jwt-groups boolean true Claim groups from JWT will be used to automatically add groups to current subject (may be used with jakarta.annotation.security.RolesAllowed annotation). validate-jwt-with-jwk boolean true Use JWK (a set of keys to validate signatures of JWT) to validate tokens. Use this method when you want to use default values for JWK or introspection endpoint URI. ",
            "title": "Configuration options"
        },
        {
            "location": "config/io_helidon_security_providers_oidc_common_OidcConfig",
            "text": " Open ID Connect configuration Type: io.helidon.security.providers.oidc.common.OidcConfig ",
            "title": "preambule"
        },
        {
            "location": "config/io_helidon_security_providers_oidc_common_OidcConfig",
            "text": " Optional configuration options key type default value description audience string &#160; Audience of issued tokens. authorization-endpoint-uri URI &#160; URI of an authorization endpoint used to redirect users to for logging-in. If not defined, it is obtained from #oidcMetadata(Resource), if that is not defined an attempt is made to use #identityUri(URI)/oauth2/v1/authorize. base-scopes string openid Configure base scopes. By default this is DEFAULT_BASE_SCOPES . If scope has a qualifier, it must be used here. client-id string &#160; Client ID as generated by OIDC server. client-secret string &#160; Client secret as generated by OIDC server. Used to authenticate this application with the server when requesting JWT based on a code. client-timeout-millis Duration 30000 Timeout of calls using web client. cookie-domain string &#160; Domain the cookie is valid for. Not used by default. cookie-http-only boolean true When using cookie, if set to true, the HttpOnly attribute will be configured. Defaults to OidcCookieHandler.Builder#DEFAULT_HTTP_ONLY . cookie-max-age-seconds long &#160; When using cookie, used to set MaxAge attribute of the cookie, defining how long the cookie is valid. Not used by default. cookie-name string JSESSIONID Name of the cookie to use. Defaults to DEFAULT_COOKIE_NAME . cookie-path string / Path the cookie is valid for. Defaults to \"/\". cookie-same-site SameSite (LAX, STRICT, NONE) LAX When using cookie, used to set the SameSite cookie value. Can be \"Strict\" or \"Lax\". cookie-secure boolean false When using cookie, if set to true, the Secure attribute will be configured. Defaults to false. cookie-use boolean true Whether to use cookie to store JWT between requests. Defaults to DEFAULT_COOKIE_USE . cors CrossOriginConfig &#160; Assign cross-origin resource sharing settings. force-https-redirects boolean false Force HTTPS for redirects to identity provider. Defaults to false . frontend-uri string &#160; Full URI of this application that is visible from user browser. Used to redirect request back from identity server after successful login. header-token TokenHandler &#160; A TokenHandler to process header containing a JWT. Default is \"Authorization\" header with a prefix \"bearer \". header-use boolean true Whether to expect JWT in a header field. identity-uri URI &#160; URI of the identity server, base used to retrieve OIDC metadata. introspect-endpoint-uri URI &#160; Endpoint to use to validate JWT. Either use this or set #signJwk(JwkKeys) or #signJwk(Resource). issuer string &#160; Issuer of issued tokens. max-redirects int 5 Configure maximal number of redirects when redirecting to an OIDC provider within a single authentication attempt. Defaults to `DEFAULT_MAX_REDIRECTS` oidc-metadata-well-known boolean true If set to true, metadata will be loaded from default (well known) location, unless it is explicitly defined using oidc-metadata-resource. If set to false, it would not be loaded even if oidc-metadata-resource is not defined. In such a case all URIs must be explicitly defined (e.g. token-endpoint-uri). oidc-metadata.resource Resource &#160; Resource configuration for OIDC Metadata containing endpoints to various identity services, as well as information about the identity server. proxy-host string &#160; Proxy host to use. When defined, triggers usage of proxy for HTTP requests. Setting to empty String has the same meaning as setting to null - disables proxy. proxy-port int 80 Proxy port. Defaults to DEFAULT_PROXY_PORT proxy-protocol string http Proxy protocol to use when proxy is used. Defaults to DEFAULT_PROXY_PROTOCOL . query-param-name string accessToken Name of a query parameter that contains the JWT token when parameter is used. query-param-use boolean false Whether to use a query parameter to send JWT token from application to this server. redirect boolean false By default the client should redirect to the identity server for the user to log in. This behavior can be overridden by setting redirect to false. When token is not present in the request, the client will not redirect and just return appropriate error response code. redirect-attempt-param string h_ra Configure the parameter used to store the number of attempts in redirect. Defaults to `DEFAULT_ATTEMPT_PARAM` redirect-uri string /oidc/redirect URI to register web server component on, used by the OIDC server to redirect authorization requests to after a user logs in or approves scopes. Note that usually the redirect URI configured here must be the same one as configured on OIDC server. Defaults to `DEFAULT_REDIRECT_URI` scope-audience string &#160; Audience of the scope required by this application. This is prefixed to the scope name when requesting scopes from the identity server. Defaults to empty string. server-type string @default Configure one of the supported types of identity servers. If the type does not have an explicit mapping, a warning is logged and the default implementation is used. sign-jwk.resource Resource &#160; A resource pointing to JWK with public keys of signing certificates used to validate JWT. token-endpoint-auth ClientAuthentication (CLIENT_SECRET_BASIC, CLIENT_SECRET_POST, CLIENT_SECRET_JWT, PRIVATE_KEY_JWT, NONE) CLIENT_SECRET_BASIC Type of authentication to use when invoking the token endpoint. Current supported options: io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#CLIENT_SECRET_BASIC io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#CLIENT_SECRET_POST io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#NONE token-endpoint-uri URI &#160; URI of a token endpoint used to obtain a JWT based on the authentication code. If not defined, it is obtained from #oidcMetadata(Resource), if that is not defined an attempt is made to use #identityUri(URI)/oauth2/v1/token. validate-jwt-with-jwk boolean true Use JWK (a set of keys to validate signatures of JWT) to validate tokens. Use this method when you want to use default values for JWK or introspection endpoint URI. ",
            "title": "Configuration options"
        },
        {
            "location": "config/io_helidon_security_util_TokenHandler",
            "text": " Type: io.helidon.security.util.TokenHandler ",
            "title": "preambule"
        },
        {
            "location": "config/io_helidon_security_util_TokenHandler",
            "text": " Optional configuration options key type default value description format string &#160; Token format for creating outbound tokens. header string &#160; Set the name of header to look into to extract the token. prefix string &#160; Set the prefix of header value to extract the token. regexp string &#160; Set the token pattern (Regular expression) to extract the token. ",
            "title": "Configuration options"
        },
        {
            "location": "config/io_helidon_servicecommon_rest_HelidonRestServiceSupport",
            "text": " Type: io.helidon.servicecommon.rest.HelidonRestServiceSupport ",
            "title": "preambule"
        },
        {
            "location": "config/io_helidon_servicecommon_rest_HelidonRestServiceSupport",
            "text": " Optional configuration options key type default value description cors CrossOriginConfig &#160; Sets the cross-origin config builder for use in establishing CORS support for the service endpoints. routing string &#160; Sets the routing name to use for setting up the service&#8217;s endpoint. web-context string &#160; Sets the web context to use for the service&#8217;s endpoint. ",
            "title": "Configuration options"
        },
        {
            "location": "config/io_helidon_servicecommon_rest_RestServiceSettings",
            "text": " Type: io.helidon.servicecommon.rest.RestServiceSettings ",
            "title": "preambule"
        },
        {
            "location": "config/io_helidon_servicecommon_rest_RestServiceSettings",
            "text": " Optional configuration options key type default value description cors CrossOriginConfig &#160; Sets the cross-origin config builder for use in establishing CORS support for the service endpoints. routing string &#160; Sets the routing name to use for setting up the service&#8217;s endpoint. web-context string &#160; Sets the web context to use for the service&#8217;s endpoint. ",
            "title": "Configuration options"
        },
        {
            "location": "config/io_helidon_tracing_Tracer",
            "text": " Jaeger tracer configuration. Type: io.helidon.tracing.Tracer This is a standalone configuration type, prefix from configuration root: tracing ",
            "title": "preambule"
        },
        {
            "location": "config/io_helidon_tracing_Tracer",
            "text": " Optional configuration options key type default value description boolean-tags Map&lt;string, boolean&gt; &#160; Tracer level tags that get added to all reported spans. client-cert-pem Resource &#160; Certificate of client in PEM format. enabled boolean true When enabled, tracing will be sent. If enabled is false, tracing should use a no-op tracer. exporter-timeout-millis Duration 10000 Timeout of exporter requests. global boolean true When enabled, the created instance is also registered as a global tracer. host string &#160; Host to use to connect to tracing collector. Default is defined by each tracing integration. int-tags Map&lt;string, int&gt; &#160; Tracer level tags that get added to all reported spans. path string &#160; Path on the collector host to use when sending data to tracing collector. Default is defined by each tracing integration. port int &#160; Port to use to connect to tracing collector. Default is defined by each tracing integration. private-key-pem Resource &#160; Private key in PEM format. protocol string &#160; Protocol to use (such as http or https ) to connect to tracing collector. Default is defined by each tracing integration. sampler-param Number 1 The sampler parameter (number). sampler-type SamplerType (CONSTANT, RATIO) CONSTANT Sampler type. See &lt;a href=\"https://www.jaegertracing.io/docs/latest/sampling/#client-sampling-configuration\"&gt;Sampler types&lt;/a&gt;. service string &#160; Service name of the traced service. tags Map&lt;string, string&gt; &#160; Tracer level tags that get added to all reported spans. trusted-cert-pem Resource &#160; Trusted certificates in PEM format. ",
            "title": "Configuration options"
        },
        {
            "location": "config/io_helidon_tracing_TracerBuilder",
            "text": " Tracer configuration. Type: io.helidon.tracing.TracerBuilder ",
            "title": "preambule"
        },
        {
            "location": "config/io_helidon_tracing_TracerBuilder",
            "text": " Optional configuration options key type default value description boolean-tags Map&lt;string, boolean&gt; &#160; Tracer level tags that get added to all reported spans. enabled boolean true When enabled, tracing will be sent. If enabled is false, tracing should use a no-op tracer. global boolean true When enabled, the created instance is also registered as a global tracer. host string &#160; Host to use to connect to tracing collector. Default is defined by each tracing integration. int-tags Map&lt;string, int&gt; &#160; Tracer level tags that get added to all reported spans. path string &#160; Path on the collector host to use when sending data to tracing collector. Default is defined by each tracing integration. port int &#160; Port to use to connect to tracing collector. Default is defined by each tracing integration. protocol string &#160; Protocol to use (such as http or https ) to connect to tracing collector. Default is defined by each tracing integration. service string &#160; Service name of the traced service. tags Map&lt;string, string&gt; &#160; Tracer level tags that get added to all reported spans. ",
            "title": "Configuration options"
        },
        {
            "location": "config/io_helidon_tracing_jaeger_JaegerTracerBuilder",
            "text": " Jaeger tracer configuration. Type: io.helidon.tracing.Tracer This is a standalone configuration type, prefix from configuration root: tracing ",
            "title": "preambule"
        },
        {
            "location": "config/io_helidon_tracing_jaeger_JaegerTracerBuilder",
            "text": " Optional configuration options key type default value description boolean-tags Map&lt;string, boolean&gt; &#160; Tracer level tags that get added to all reported spans. client-cert-pem Resource &#160; Certificate of client in PEM format. enabled boolean true When enabled, tracing will be sent. If enabled is false, tracing should use a no-op tracer. exporter-timeout-millis Duration 10000 Timeout of exporter requests. global boolean true When enabled, the created instance is also registered as a global tracer. host string &#160; Host to use to connect to tracing collector. Default is defined by each tracing integration. int-tags Map&lt;string, int&gt; &#160; Tracer level tags that get added to all reported spans. path string &#160; Path on the collector host to use when sending data to tracing collector. Default is defined by each tracing integration. port int &#160; Port to use to connect to tracing collector. Default is defined by each tracing integration. private-key-pem Resource &#160; Private key in PEM format. protocol string &#160; Protocol to use (such as http or https ) to connect to tracing collector. Default is defined by each tracing integration. sampler-param Number 1 The sampler parameter (number). sampler-type SamplerType (CONSTANT, RATIO) CONSTANT Sampler type. See &lt;a href=\"https://www.jaegertracing.io/docs/latest/sampling/#client-sampling-configuration\"&gt;Sampler types&lt;/a&gt;. service string &#160; Service name of the traced service. tags Map&lt;string, string&gt; &#160; Tracer level tags that get added to all reported spans. trusted-cert-pem Resource &#160; Trusted certificates in PEM format. ",
            "title": "Configuration options"
        },
        {
            "location": "config/io_helidon_tracing_zipkin_ZipkinTracerBuilder",
            "text": " Zipkin tracer configuration Type: io.opentracing.Tracer This is a standalone configuration type, prefix from configuration root: tracing ",
            "title": "preambule"
        },
        {
            "location": "config/io_helidon_tracing_zipkin_ZipkinTracerBuilder",
            "text": " Optional configuration options key type default value description api-version Version (V1, V2) V2 Version of Zipkin API to use. Defaults to Version#V2. boolean-tags Map&lt;string, boolean&gt; &#160; Tracer level tags that get added to all reported spans. enabled boolean true When enabled, tracing will be sent. If enabled is false, tracing should use a no-op tracer. global boolean true When enabled, the created instance is also registered as a global tracer. host string &#160; Host to use to connect to tracing collector. Default is defined by each tracing integration. int-tags Map&lt;string, int&gt; &#160; Tracer level tags that get added to all reported spans. path string &#160; Path on the collector host to use when sending data to tracing collector. Default is defined by each tracing integration. port int &#160; Port to use to connect to tracing collector. Default is defined by each tracing integration. protocol string &#160; Protocol to use (such as http or https ) to connect to tracing collector. Default is defined by each tracing integration. service string &#160; Service name of the traced service. tags Map&lt;string, string&gt; &#160; Tracer level tags that get added to all reported spans. ",
            "title": "Configuration options"
        },
        {
            "location": "config/io_helidon_webclient_Proxy",
            "text": " Type: io.helidon.webclient.Proxy ",
            "title": "preambule"
        },
        {
            "location": "config/io_helidon_webclient_Proxy",
            "text": " Optional configuration options key type default value description host string &#160; Sets a new host value. no-proxy string[&#93; &#160; Configure a host pattern that is not going through a proxy. Options are: IP Address, such as 192.168.1.1 IP V6 Address, such as [2001:db8:85a3:8d3:1319:8a2e:370:7348] Hostname, such as localhost Domain name, such as helidon.io Domain name and all sub-domains, such as .helidon.io (leading dot) Combination of all options from above with a port, such as .helidon.io:80 password string &#160; Sets a new password for the proxy. port int &#160; Sets a port value. type ProxyType (NONE, SYSTEM, HTTP, SOCKS_4, SOCKS_5) HTTP Sets a new proxy type. use-system-selector boolean false Configure proxy from environment variables and system properties. username string &#160; Sets a new username for the proxy. ",
            "title": "Configuration options"
        },
        {
            "location": "config/io_helidon_webclient_WebClientConfiguration",
            "text": " Configuration of the HTTP client Type: io.helidon.webclient.WebClientConfiguration This is a standalone configuration type, prefix from configuration root: client ",
            "title": "preambule"
        },
        {
            "location": "config/io_helidon_webclient_WebClientConfiguration",
            "text": " Optional configuration options key type default value description connect-timeout-millis long 60000 Sets new connection timeout of the request. cookies.automatic-store-enabled boolean &#160; Whether to allow automatic cookie storing cookies.default-cookies Map &#160; Default cookies to be used in each request. Each list entry has to have \"name\" and \"value\" node follow-redirects boolean false Whether to follow any response redirections or not. headers Map &#160; Default headers to be used in each request. Each list entry has to have \"name\" and \"value\" node max-redirects int 5 Sets max number of followed redirects. media-support MediaContext &#160; proxy Proxy &#160; Sets new request proxy. read-timeout-millis long 600000 Sets new read timeout of the response. relative-uris boolean false Can be set to true to force the use of relative URIs in all requests, regardless of the presence or absence of proxies or no-proxy lists. tls WebClientTls &#160; New TLS configuration. uri string &#160; Base uri for each request. @return updated builder instance user-agent string &#160; Name of the user agent which should be used. ",
            "title": "Configuration options"
        },
        {
            "location": "config/io_helidon_webclient_WebClientTls",
            "text": " Type: io.helidon.webclient.WebClientTls ",
            "title": "preambule"
        },
        {
            "location": "config/io_helidon_webclient_WebClientTls",
            "text": " Optional configuration options key type default value description client.keystore KeyConfig &#160; Client key store which contains client private key and certificate server.cipher-suite string[&#93; &#160; List of allowed ciphers. If set, replaces those present by default server.disable-hostname-verification boolean false Whether this client should perform hostname verification server.trust-all boolean false Whether this client should trust all certificates server.truststore KeyConfig &#160; Trust store which contains trusted certificates. If set, replaces those present by default ",
            "title": "Configuration options"
        },
        {
            "location": "config/io_helidon_webserver_SocketConfiguration",
            "text": " Type: io.helidon.webserver.SocketConfiguration ",
            "title": "preambule"
        },
        {
            "location": "config/io_helidon_webserver_SocketConfiguration",
            "text": " Required configuration options key type default value description name string &#160; Configure a socket name, to bind named routings to. Optional configuration options key type default value description backlog int 1024 Configures a maximum length of the queue of incoming connections on the server socket. Default value is #DEFAULT_BACKLOG_SIZE. bind-address string &#160; Deprecated Configures local address where the server listens on with the server socket. If not configured, then listens an all local addresses. enable-compression boolean false Enable negotiation for gzip/deflate content encodings. Clients can request compression using the \"Accept-Encoding\" header. Default is `false` host string &#160; A helper method that just calls #bindAddress(String). max-header-size int 16384 Maximal number of bytes of all header values combined. When a bigger value is received, a io.helidon.common.http.Http.Status#BAD_REQUEST_400 is returned. Default is `8192` max-initial-line-length int 4096 Maximal number of characters in the initial HTTP line. Default is `4096` max-payload-size long &#160; Set a maximum payload size for a client request. Can prevent DoS attacks. max-upgrade-content-length int 65536 Set a maximum length of the content of an upgrade request. Default is `64*1024` port int 0 Configures a server port to listen on with the server socket. If port is 0 then any available ephemeral port will be used. receive-buffer-size int &#160; Configures proposed value of the TCP receive window that is advertised to the remote peer on the server socket. If `0` then use implementation default. timeout-millis long 0 Socket timeout in milliseconds tls WebServerTls &#160; Configures SSL for this socket. When configured, the server enforces SSL configuration. If this method is called, any other method except for #tls(java.util.function.Supplier)¨ and repeated invocation of this method would be ignored. If this method is called again, the previous configuration would be ignored. ",
            "title": "Configuration options"
        },
        {
            "location": "config/io_helidon_webserver_SocketConfiguration_SocketConfigurationBuilder",
            "text": " Type: io.helidon.webserver.SocketConfiguration.SocketConfigurationBuilder ",
            "title": "preambule"
        },
        {
            "location": "config/io_helidon_webserver_SocketConfiguration_SocketConfigurationBuilder",
            "text": " Optional configuration options key type default value description backlog int 1024 Configures a maximum length of the queue of incoming connections on the server socket. Default value is #DEFAULT_BACKLOG_SIZE. bind-address string &#160; Deprecated Configures local address where the server listens on with the server socket. If not configured, then listens an all local addresses. enable-compression boolean false Enable negotiation for gzip/deflate content encodings. Clients can request compression using the \"Accept-Encoding\" header. Default is `false` host string &#160; A helper method that just calls #bindAddress(String). max-header-size int 16384 Maximal number of bytes of all header values combined. When a bigger value is received, a io.helidon.common.http.Http.Status#BAD_REQUEST_400 is returned. Default is `8192` max-initial-line-length int 4096 Maximal number of characters in the initial HTTP line. Default is `4096` max-payload-size long &#160; Set a maximum payload size for a client request. Can prevent DoS attacks. max-upgrade-content-length int 65536 Set a maximum length of the content of an upgrade request. Default is `64*1024` port int 0 Configures a server port to listen on with the server socket. If port is 0 then any available ephemeral port will be used. receive-buffer-size int &#160; Configures proposed value of the TCP receive window that is advertised to the remote peer on the server socket. If `0` then use implementation default. timeout-millis long 0 Socket timeout in milliseconds tls WebServerTls &#160; Configures SSL for this socket. When configured, the server enforces SSL configuration. If this method is called, any other method except for #tls(java.util.function.Supplier)¨ and repeated invocation of this method would be ignored. If this method is called again, the previous configuration would be ignored. ",
            "title": "Configuration options"
        },
        {
            "location": "config/io_helidon_webserver_WebServer",
            "text": " Configuration of the HTTP server. Type: io.helidon.webserver.WebServer This is a standalone configuration type, prefix from configuration root: server ",
            "title": "preambule"
        },
        {
            "location": "config/io_helidon_webserver_WebServer",
            "text": " Optional configuration options key type default value description backlog int 1024 Configures a maximum length of the queue of incoming connections on the server socket. Default value is #DEFAULT_BACKLOG_SIZE. bind-address string &#160; Deprecated Configures local address where the server listens on with the server socket. If not configured, then listens an all local addresses. enable-compression boolean false Enable negotiation for gzip/deflate content encodings. Clients can request compression using the \"Accept-Encoding\" header. Default is `false` features.print-details boolean false Set to true to print detailed feature information on startup. host string &#160; A helper method that just calls #bindAddress(String). max-header-size int 16384 Maximal number of bytes of all header values combined. When a bigger value is received, a io.helidon.common.http.Http.Status#BAD_REQUEST_400 is returned. Default is `8192` max-initial-line-length int 4096 Maximal number of characters in the initial HTTP line. Default is `4096` max-payload-size long &#160; Set a maximum payload size for a client request. Can prevent DoS attacks. max-upgrade-content-length int 65536 Set a maximum length of the content of an upgrade request. Default is `64*1024` backpressure-buffer-size long 5242880 Set a maximum length of the unflushed response data sending buffer can keep without applying backpressure. Depends on backpressure-policy what happens if max buffer size is reached. Default is `5*1024*1024` - 5Mb backpressure-policy String LINEAR Sets the strategy for applying backpressure to the reactive stream of response data. LINEAR - Data chunks are requested one-by-one after previous data chunk has been written to Netty&#8217;s buffer, when backpressure-buffer-size watermark is reached, new chunks are not requested until buffer size decrease under the watermark value. PREFETCH - After first data chunk arrives, expected number of chunks needed to fill the buffer up to watermark is calculated and requested. AUTO_FLUSH - Data are requested one-by-one, in case buffer reaches watermark, no other data is requested and extra flush is initiated. UNBOUNDED - No backpressure is applied, Long.MAX_VALUE(unbounded) is requested from upstream. Default is `LINEAR` port int 0 Configures a server port to listen on with the server socket. If port is 0 then any available ephemeral port will be used. receive-buffer-size int &#160; Configures proposed value of the TCP receive window that is advertised to the remote peer on the server socket. If `0` then use implementation default. sockets SocketConfiguration[&#93; &#160; Adds an additional named server socket configuration. As a result, the server will listen on multiple ports. An additional named server socket may have a dedicated Routing configured through io.helidon.webserver.WebServer.Builder#addNamedRouting(String, Routing). timeout-millis long 0 Socket timeout in milliseconds tls WebServerTls &#160; Configures SSL for this socket. When configured, the server enforces SSL configuration. If this method is called, any other method except for #tls(java.util.function.Supplier)¨ and repeated invocation of this method would be ignored. If this method is called again, the previous configuration would be ignored. worker-count int &#160; Sets a count of threads in pool used to process HTTP requests. Default value is CPU_COUNT * 2 . Configuration key: `workers` ",
            "title": "Configuration options"
        },
        {
            "location": "config/io_helidon_webserver_WebServerTls",
            "text": " Type: io.helidon.webserver.WebServerTls ",
            "title": "preambule"
        },
        {
            "location": "config/io_helidon_webserver_WebServerTls",
            "text": " Required configuration options key type default value description private-key KeyConfig &#160; Configure private key to use for SSL context. Optional configuration options key type default value description cipher-suite string[&#93; &#160; Set allowed cipher suite. If an empty collection is set, an exception is thrown since it is required to support at least some ciphers. client-auth ClientAuthentication (REQUIRE, OPTIONAL, NONE) none Configures whether client authentication will be required or not. enabled boolean true Can be used to disable TLS even if keys are configured. session-cache-size long &#160; Set the size of the cache used for storing SSL session objects. 0 to use the default value. session-timeout-seconds long &#160; Set the timeout for the cached SSL session objects, in seconds. 0 to use the default value. trust KeyConfig &#160; Set the trust key configuration to be used to validate certificates. ",
            "title": "Configuration options"
        },
        {
            "location": "config/io_helidon_webserver_cors_CrossOriginConfig",
            "text": " Type: io.helidon.webserver.cors.CrossOriginConfig ",
            "title": "preambule"
        },
        {
            "location": "config/io_helidon_webserver_cors_CrossOriginConfig",
            "text": " Optional configuration options key type default value description allow-credentials boolean false Sets the allow credentials flag. allow-headers string[&#93; * Sets the allow headers. allow-methods string[&#93; * Sets the allow methods. allow-origins string[&#93; * Sets the allowOrigins. enabled boolean true Sets whether this config should be enabled or not. expose-headers string[&#93; &#160; Sets the expose headers. max-age-seconds long 3600 Sets the maximum age. path-pattern string {+} Updates the path prefix for this cross-origin config. ",
            "title": "Configuration options"
        },
        {
            "location": "config/io_smallrye_openapi_api_OpenApiConfig",
            "text": " Type: io.smallrye.openapi.api.OpenApiConfig ",
            "title": "preambule"
        },
        {
            "location": "config/io_smallrye_openapi_api_OpenApiConfig",
            "text": " Optional configuration options key type default value description application-path-disable boolean false Sets whether the app path search should be disabled. custom-schema-registry-class string &#160; Sets the custom schema registry class. filter string &#160; Sets the developer-provided OpenAPI filter class name. model.reader string &#160; Sets the developer-provided OpenAPI model reader class name. schema.* string &#160; Sets the schema for the indicated fully-qualified class name (represented here by '*'); value is the schema in JSON format. Repeat for multiple classes. servers string[&#93; &#160; Sets servers. servers.operation.* string[&#93; &#160; Sets alternative servers to service the indicated operation (represented here by '*'). Repeat for multiple operations. servers.path.* string[&#93; &#160; Sets alternative servers to service all operations at the indicated path (represented here by '*'). Repeat for multiple paths. ",
            "title": "Configuration options"
        },
        {
            "location": "guides/jib",
            "text": " This guide describes how to build container images for Helidon applications using Jib and Maven. ",
            "title": "preambule"
        },
        {
            "location": "guides/jib",
            "text": " About 10 minutes Helidon Prerequisites ",
            "title": "What You Need"
        },
        {
            "location": "guides/jib",
            "text": " Jib is a java tool chain for building Docker images for Java applications. It is integrated with Maven and Gradle and uses a distro-less base image to produce small images. Jib does not require the docker command or the Docker daemon, there is no need to solve the Docker-in-Docker problem in order to build Docker images as part of your continuous integration. The docker command is only required for local usage when registering images in your local Docker registry. The example below shows how to build an image and register it in the local registry using the jib-maven-plugin . Add the following plugin declaration to your pom.xml: <markup lang=\"xml\" >&lt;plugin&gt; &lt;groupId&gt;com.google.cloud.tools&lt;/groupId&gt; &lt;artifactId&gt;jib-maven-plugin&lt;/artifactId&gt; &lt;version&gt;0.10.1&lt;/version&gt; &lt;configuration&gt; &lt;to&gt; &lt;image&gt;jib-${project.artifactId}&lt;/image&gt; &lt;tags&gt; &lt;tag&gt;${project.version}&lt;/tag&gt; &lt;tag&gt;latest&lt;/tag&gt; &lt;/tags&gt; &lt;/to&gt; &lt;container&gt; &lt;!-- good defaults intended for containers --&gt; &lt;jvmFlags&gt; &lt;jmxFlag&gt;-server&lt;/jmxFlag&gt; &lt;jmxFlag&gt;-Djava.awt.headless=true&lt;/jmxFlag&gt; &lt;jmxFlag&gt;-XX:+UnlockExperimentalVMOptions&lt;/jmxFlag&gt; &lt;jmxFlag&gt;-XX:+UseCGroupMemoryLimitForHeap&lt;/jmxFlag&gt; &lt;jmxFlag&gt;-XX:InitialRAMFraction=2&lt;/jmxFlag&gt; &lt;jmxFlag&gt;-XX:MinRAMFraction=2&lt;/jmxFlag&gt; &lt;jmxFlag&gt;-XX:MaxRAMFraction=2&lt;/jmxFlag&gt; &lt;jmxFlag&gt;-XX:+UseG1GC&lt;/jmxFlag&gt; &lt;/jvmFlags&gt; &lt;mainClass&gt;${mainClass}&lt;/mainClass&gt; &lt;ports&gt; &lt;port&gt;8080&lt;/port&gt; &lt;/ports&gt; &lt;/container&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;dockerBuild&lt;/goal&gt; &lt;/goals&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; By default, Jib uses distroless/java as the base image. You can override the default with configuration see the documentation <markup lang=\"bash\" title=\"Package the updated application\" >mvn package <markup lang=\"bash\" title=\"Run the image\" >docker run --rm -p 8080:8080 jib-helidon-quickstart-se <markup lang=\"bash\" title=\"Ping the application\" >curl -X GET http://localhost:8080/greet <markup lang=\"bash\" title=\"Take a look at the image size\" >docker images jib-quickstart-se:latest <markup lang=\"bash\" >REPOSITORY TAG IMAGE ID CREATED SIZE jib-quickstart-se latest 384aebda5594 48 years ago 124MB Ignore the fact that it says the image was created 48 years ago. Refer to the Jib FAQ for explanations. the Jib image is smaller because of the use of a distroless base image. ",
            "title": "Creating a Docker Image Using Jib"
        },
        {
            "location": "guides/oke",
            "text": " Push a Docker image of your Helidon application to Oracle Cloud Infrastructure Registry (OCIR), and deploy the image from the registry to Oracle Cloud Infrastructure Container Engine for Kubernetes (OKE). ",
            "title": "preambule"
        },
        {
            "location": "guides/oke",
            "text": " About 10 minutes Helidon prerequisites An OKE cluster. See the OKE documentation . A Helidon project created from the quickstart Maven archetype. See quickstart Maven archetype . ",
            "title": "What You Need"
        },
        {
            "location": "guides/oke",
            "text": " Your account must be in the Administrators group or another group that has the REPOSITORY_CREATE permission. Sign in to the Oracle Cloud Infrastructure (OCI) web console and generate an authentication token. See Getting an Auth Token . Remember to copy the generated token. You won&#8217;t be able to access it again. <markup lang=\"bash\" title=\"Log in to the OCIR Docker registry:\" >docker login \\ -u &lt;username&gt; \\ -p &lt;password&gt; \\ &lt;region-code&gt;.ocir.io The user name in the format &lt;tenancy_name&gt;/&lt;username&gt; . The password is the generated token. &lt;region-code&gt; is the code for the OCI region that you&#8217;re using. For example, the region code for Phoenix is phx . See Regions and Availability Domains . <markup lang=\"bash\" title=\"Tag the image that you want to push to the registry:\" >docker tag \\ helidon-quickstart-se:latest \\ &lt;region-code&gt;.ocir.io/&lt;tenancy-name&gt;/&lt;repo-name&gt;/&lt;image-name&gt;:&lt;tag&gt; the local image to tag &lt;repo-name&gt; is optional. It is the name of a repository to which you want to push the image (for example, project01 ). <markup lang=\"bash\" title=\"Push the image to the Registry:\" >docker push \\ &lt;region-code&gt;.ocir.io/&lt;tenancy-name&gt;/&lt;repo-name&gt;/&lt;image-name&gt;:&lt;tag&gt; You can pull your image with the image path used above, for example: phx.ocir.io/helidon/example/helidon-quickstart-se:latest ",
            "title": "Push Your Image to OCIR"
        },
        {
            "location": "guides/oke",
            "text": " First, change to the helidon-quickstart-se directory. Then edit app.yaml and add the following under spec in the deployment section: <markup lang=\"yaml\" >spec: imagePullSecrets: - name: ocirsecret containers: - name: helidon-quickstart-se image: phx.ocir.io/helidon/example/helidon-quickstart-se:latest imagePullPolicy: Always ports: - containerPort: 8080 The config secret name The image path <markup lang=\"bash\" title=\"Deploy the application:\" >kubectl create -f app.yaml -n helidon <markup lang=\"bash\" title=\"Get the NodePort number for your new pod:\" >kubectl get svc -n helidon <markup lang=\"bash\" title=\"Get the IP address for your cluster nodes:\" >kubectl get nodes You can now access the application at http://&lt;NodeIpAddress&gt;:&lt;NodePort&gt;/greet . ",
            "title": "Deploy the Image to Kubernetes"
        },
        {
            "location": "guides/oke",
            "text": " Create a namespace (for example, helidon ) for the project: <markup lang=\"bash\" >kubectl create namespace helidon The repository that you created is private. To allow Kubernetes to authenticate with the container registry and pull the private image, you must create and use an image-pull secret. <markup lang=\"bash\" title=\"Create an image-pull secret:\" >kubectl create secret docker-registry \\ ocirsecret \\ --docker-server=&lt;region-code&gt;.ocir.io \\ --docker-username='&lt;tenancy-name&gt;/&lt;oci-username&gt;' \\ --docker-password='&lt;oci-auth-token&gt;' \\ --docker-email='&lt;email-address&gt;' \\ --namespace helidon The name of the config secret The docker registry (see docker tag step above) The user name (see docker login step above) The password (see docker login step above) The namespace created in the previous step Deploy the Image to Kubernetes First, change to the helidon-quickstart-se directory. Then edit app.yaml and add the following under spec in the deployment section: <markup lang=\"yaml\" >spec: imagePullSecrets: - name: ocirsecret containers: - name: helidon-quickstart-se image: phx.ocir.io/helidon/example/helidon-quickstart-se:latest imagePullPolicy: Always ports: - containerPort: 8080 The config secret name The image path <markup lang=\"bash\" title=\"Deploy the application:\" >kubectl create -f app.yaml -n helidon <markup lang=\"bash\" title=\"Get the NodePort number for your new pod:\" >kubectl get svc -n helidon <markup lang=\"bash\" title=\"Get the IP address for your cluster nodes:\" >kubectl get nodes You can now access the application at http://&lt;NodeIpAddress&gt;:&lt;NodePort&gt;/greet . ",
            "title": "Setup your K8s Cluster"
        },
        {
            "location": "mp/aot",
            "text": " Helidon applications can be compiled into a native executable using GraalVM native image. When using applications created using the CLI, or when you configure Helidon application pom as a parent of your module, you can use the following steps to build a native image from your application: Create an environment variable GRAALVM_HOME pointing to your installation of GraalVM with native-image installed Run Maven command mvn clean package -Pnative-image Execute the native executable created in target directory of your project ",
            "title": "preambule"
        },
        {
            "location": "mp/aot",
            "text": " Some Helidon components are not (yet) supported in native image, some have restrictions. The following table lists all Helidon features and their support for native image. Helidon MP features in AOT &#160; Feature Component AOT note ✅ CDI CDI &#160; ✅ Config Config &#160; ✅ &#160; Encryption &#160; ✅ &#160; YAML &#160; ✅ Fault Tolerance Fault Tolerance &#160; ✅ Health Health &#160; ✅ &#160; Built-ins &#160; ✅ JAX-RS JAX-RS &#160; ✅ JPA JPA &#160; ❓ &#160; EclipseLink Not yet tested. 🔶 &#160; Hibernate Experimental support, tested on limited use cases with Helidon Oracle and H2 JDBC modules 🔶 JTA JTA Experimental support, tested on limited use cases ✅ Messaging Messaging &#160; ✅ Metrics Metrics &#160; ✅ Open API Open API &#160; 🔶 REST Client REST Client Does not support execution of default methods on interfaces. ✅ Security Security &#160; ✅ &#160; Integration: Jersey &#160; ✅ &#160; Integration: WebServer &#160; ✅ &#160; Integration: gRPC &#160; ✅ &#160; JWT Auth &#160; ✅ &#160; OIDC &#160; ✅ &#160; Provider: ABAC &#160; ✅ &#160; Provider/ABAC/Policy: EL Requires reflection configuration for used classes. ✅ &#160; Provider/ABAC: Role &#160; ✅ &#160; Provider/ABAC: Scope &#160; ✅ &#160; Provider/ABAC: Time &#160; ❓ &#160; Provider: Google Login Not yet tested. ✅ &#160; Provider: Header &#160; ✅ &#160; Provider: HTTP Basic &#160; ✅ &#160; Provider: HTTP Digest &#160; ✅ &#160; Provider: HTTP Signatures &#160; ❓ &#160; Provider: IDCS Role Mapper Not yet tested. ✅ &#160; Provider: JWT &#160; ✅ Server Server &#160; ✅ &#160; Access Log &#160; ✅ &#160; CORS &#160; ✅ Tracing Tracing &#160; ✅ &#160; Integration: Jersey Server &#160; ✅ &#160; Integration: Jersey Client &#160; ✅ &#160; Jaeger &#160; ✅ &#160; Zipkin &#160; ✅ Web Client Web Client &#160; ✅ &#160; Metrics &#160; ✅ &#160; Security &#160; ✅ &#160; Tracing &#160; ✅ &#160; Websocket Server only. ✅ gRPC Server gRPC Server Since GraalVM 21.0.0 ✅ &#160; Metrics &#160; ✅ gRPC Client gRPC Client Since GraalVM 21.0.0 ✅ &#160; Metrics &#160; ✅ Scheduling Scheduling &#160; ✅ OCI OCI Integration Modules with group id io.helidon.integrations.oci ✅ Vault Hashicorp Vault Integration &#160; ✅ Long Running Actions Client &#160; ✅ &#160; Coordinator Only with external database ",
            "title": "AOT supported modules"
        },
        {
            "location": "mp/beanvalidation",
            "text": " Overview Maven Coordinates API Configuration Examples Additional Information Reference ",
            "title": "Contents"
        },
        {
            "location": "mp/beanvalidation",
            "text": " Helidon supports Bean Validation via its integration with JAX-RS/Jersey. The Jakarta Bean Validation specification defines an API to validate Java beans. Bean Validation is supported in REST resource classes as well as in regular application beans. If bean validation is required outside JAX-RS/Jersey use cases, it is also available in Helidon. It follows the standard Jakarta Bean Validation specification which defines an API to validate Java beans. ",
            "title": "Overview"
        },
        {
            "location": "mp/beanvalidation",
            "text": " To enable Bean Validation add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;org.glassfish.jersey.ext&lt;/groupId&gt; &lt;artifactId&gt;jersey-bean-validation&lt;/artifactId&gt; &lt;/dependency&gt; For general validation, please add to your pom.xml : <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.bean-validation&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-bean-validation&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "mp/beanvalidation",
            "text": " The specification defines a small set of built-in constraints. Their usage is encouraged both in regular constraint declarations and as composing constraints. Using this set of constraints will enhance portability of your constraints across constraint-consuming frameworks relying on the metadata API (such as client side validation frameworks or database schema generation frameworks). Built-in annotations are annotated with an empty @Constraint annotation to avoid any dependency between the specification API and a specific implementation. Each Jakarta Bean Validation provider must recognize built-in constraint annotations as valid constraint definitions and provide compliant constraint implementations for each. The built-in constraint validation implementation is having a lower priority than an XML mapping definition. In other words ConstraintValidator implementations for built-in constraints can be overridden by using the XML mapping (see Overriding constraint definitions in XML). All built-in constraints are in the jakarta.validation.constraints package. Here is the list of constraints and their declaration. <div class=\"table__overflow elevation-1 flex sm10 \"> Annotation Description @Null The annotated element must be null . Accepts any type. @NotNull The annotated element must not be null . Accepts any type. @AssertTrue The annotated element must be true. Supported types are boolean and Boolean . Null elements are considered valid. @AssertFalse The annotated element must be false. Supported types are boolean and Boolean . Null elements are considered valid. @Min The annotated element must be a number whose value must be higher or equal to the specified minimum. Supported types are: BigDecimal BigInteger byte , short , int , long , and their respective wrappers Note that double and float are not supported due to rounding errors (some providers might provide some approximative support). Null elements are considered valid. @Max The annotated element must be a number whose value must be higher or equal to the specified minimum. Supported types are: BigDecimal BigInteger byte , short , int , long , and their respective wrappers Note that double and float are not supported due to rounding errors (some providers might provide some approximative support). Null elements are considered valid. @DecimalMin The annotated element must be a number whose value must be lower or equal to the specified maximum. Supported types are: BigDecimal BigInteger byte , short , int , long , and their respective wrappers Note that double and float are not supported due to rounding errors (some providers might provide some approximative support). Null elements are considered valid. @DecimalMax The annotated element must be a number whose value must be lower or equal to the specified maximum. Supported types are: BigDecimal BigInteger byte , short , int , long , and their respective wrappers Note that double and float are not supported due to rounding errors (some providers might provide some approximative support). Null elements are considered valid. @Negative The annotated element must be a strictly negative number (i.e. 0 is considered as an invalid value). Supported types are: BigDecimal BigInteger byte , short , int , long , and their respective wrappers Null elements are considered valid. @NegativeOrZero The annotated element must be a negative number or 0. Supported types are: BigDecimal BigInteger byte , short , int , long , float , or double and their respective wrappers Null elements are considered valid. @Positive The annotated element must be a strictly positive number (i.e. 0 is considered as an invalid value). Supported types are: BigDecimal BigInteger byte , short , int , long , float , or double and their respective wrappers Null elements are considered valid. @PositiveOrZero The annotated element must be a positive number or 0. Supported types are: BigDecimal BigInteger byte , short , int , long , float , or double and their respective wrappers Null elements are considered valid. @Size The annotated element size must be between the specified boundaries (included). Supported types are: * CharSequence - length of character sequence is evaluated * Collection - collection size is evaluated * Map - map size is evaluated * Array (array length is evaluated) Null elements are considered valid. @Digits The annotated element must be a number within accepted range. Supported types are: BigDecimal BigInteger CharSequence byte , short , int , long , and their respective wrapper types Null elements are considered valid. @Past The annotated element must be an instant, date or time in the past or in the present. Now is defined by the ClockProvider attached to the Validator or ValidatorFactory . The default clockProvider defines the current time according to the virtual machine, applying the current default time zone if needed. Supported types are: java.util.Date java.util.Calendar java.time.Instant java.time.LocalDate java.time.LocalDateTime java.time.LocalTime java.time.MonthDay java.time.OffsetDateTime java.time.OffsetTime java.time.Year java.time.YearMonth java.time.ZonedDateTime java.time.chrono.HijrahDate java.time.chrono.JapaneseDate java.time.chrono.MinguoDate java.time.chrono.ThaiBuddhistDate Null elements are considered valid. @PastOrPresent The annotated element must be an instant, date or time in the past or in the present. Now is defined by the ClockProvider attached to the Validator or ValidatorFactory . The default clockProvider defines the current time according to the virtual machine, applying the current default time zone if needed. Supported types are: java.util.Date java.util.Calendar java.time.Instant java.time.LocalDate java.time.LocalDateTime java.time.LocalTime java.time.MonthDay java.time.OffsetDateTime java.time.OffsetTime java.time.Year java.time.YearMonth java.time.ZonedDateTime java.time.chrono.HijrahDate java.time.chrono.JapaneseDate java.time.chrono.MinguoDate java.time.chrono.ThaiBuddhistDate Null elements are considered valid. @PastOrPresent The annotated element must be an instant, date or time in the future. Now is defined by the ClockProvider attached to the Validator or ValidatorFactory . The default clockProvider defines the current time according to the virtual machine, applying the current default time zone if needed. Supported types are: java.util.Date java.util.Calendar java.time.Instant java.time.LocalDate java.time.LocalDateTime java.time.LocalTime java.time.MonthDay java.time.OffsetDateTime java.time.OffsetTime java.time.Year java.time.YearMonth java.time.ZonedDateTime java.time.chrono.HijrahDate java.time.chrono.JapaneseDate java.time.chrono.MinguoDate java.time.chrono.ThaiBuddhistDate Null elements are considered valid. @FutureOrPresent The annotated element must be an instant, date or time in the present or in the future. Now is defined by the ClockProvider attached to the Validator or ValidatorFactory . The default clockProvider defines the current time according to the virtual machine, applying the current default time zone if needed. Supported types are: java.util.Date java.util.Calendar java.time.Instant java.time.LocalDate java.time.LocalDateTime java.time.LocalTime java.time.MonthDay java.time.OffsetDateTime java.time.OffsetTime java.time.Year java.time.YearMonth java.time.ZonedDateTime java.time.chrono.HijrahDate java.time.chrono.JapaneseDate java.time.chrono.MinguoDate java.time.chrono.ThaiBuddhistDate Null elements are considered valid. @FutureOrPresent The annotated CharSequence must match the specified regular expression. The regular expression follows the Java regular expression conventions see java.util.regex.Pattern . Accepts CharSequence . Null elements are considered valid. @NotEmpty The annotated element must not be null nor empty. Supported types are: * CharSequence - length of character sequence is evaluated * Collection - collection size is evaluated * Map - map size is evaluated * Array (array length is evaluated) @NotBlank The annotated element must not be null and must contain at least one non-whitespace character. Accepts CharSequence . @Email The string has to be a well-formed email address. Exact semantics of what makes up a valid email address are left to Jakarta Bean Validation providers. Accepts CharSequence . Null elements are considered valid. ",
            "title": "API"
        },
        {
            "location": "mp/beanvalidation",
            "text": " Bean Validation can be configured using META-INF/validation.xml . For more information about configuring the validator factory in validation.xml, see Hibernate Validator Documentation . ",
            "title": "Configuration"
        },
        {
            "location": "mp/beanvalidation",
            "text": " The following example shows a simple resource method annotated with @POST whose parameter must be not null and valid . Validating a parameter in this case implies making sure that any constraint annotations in the Greeting class are satisfied. The resource method shall never be called if the validation fails, with a 400 (Bad Request) status code returned instead. <markup lang=\"java\" >@Path(\"helloworld\") public class HelloWorld { @POST @Consumes(MediaType.APPLICATION_JSON) public void post(@NotNull @Valid Greeting greeting) { // ... } } The following example shows a simple application with one field declared as not null using @NotNull annotation: <markup lang=\"java\" >public class GreetingHolder { @NotNull private String greeting; //... } If the bean contains a method parameter annotated with @Valid, and GreetingHolder with null_greeting is passed, then a _ValidationException will be thrown: <markup lang=\"java\" >@ApplicationScoped public class GreetingProvider { private GreetingHolder greetingHolder; //.. void setGreeting(@Valid GreetingHolder greetingHolder) { this.greetingHolder = greetingHolder; } } beans.xml is required to identify beans and for bean validation to work properly. Examples are available in our official GitHub repository . ",
            "title": "Examples"
        },
        {
            "location": "mp/beanvalidation",
            "text": " Helidon uses Hibernate Bean Validator for general bean validation. ",
            "title": "Additional Information"
        },
        {
            "location": "mp/beanvalidation",
            "text": " Bean Validation Specification ",
            "title": "Reference"
        },
        {
            "location": "mp/config/advanced-configuration",
            "text": " Creating MicroProfile Config Sources for Manual Setup of Config Creating Custom Config Sources Creating MicroProfile Config Sources from meta-config Extending Meta-Config to Create a Custom Config Source Type Creating MicroProfile Config Source from Helidon SE Config Source Creating MicroProfile Config Source from Helidon SE Config Instance ",
            "title": "Contents"
        },
        {
            "location": "mp/config/advanced-configuration",
            "text": " You can create Microprofile Config Source from a map. <markup lang=\"java\" title=\"Create MicroProfile Config Source based on Environment Variables and Custom Map\" >ConfigProviderResolver resolver = ConfigProviderResolver.instance(); org.eclipse.microprofile.config.Config config = resolver.getBuilder() .withSources(MpConfigSources.environmentVariables()) .withSources(MpConfigSources.create(Map.of(\"key\",\"value\"))) .build(); resolver.registerConfig(config, null); Creates MicroProfile Config Source builder. Adds environment variables. Adds a custom map. Builds the MicroProfile Config Source. Registers the config, so it can be used by other components ",
            "title": "Create Custom Map MicroProfile Config Source"
        },
        {
            "location": "mp/config/advanced-configuration",
            "text": " You can create YAML Microprofile Config Source from a path or a URL. When you create a MicroProfile instance from the builder, the YamlMpConfigSource allows you to create a custom Config Source and register it with the builder. <markup lang=\"java\" title=\"Create YamlMPConfigSource from a path\" >ConfigProviderResolver.instance().newBuilder() .withSources(YamlMpConfigSource.create(path)) .build(); ",
            "title": "Create YAML MicroProfile Config Source"
        },
        {
            "location": "mp/config/advanced-configuration",
            "text": " You can use the following methods to create MicroProfile Config Sources to manually set up the Config from org.eclipse.microprofile.config.spi.ConfigProviderResolver#getBuilder() on io.helidon.config.mp.MpConfigSources class: Method Description systemProperties() System properties config source. environmentVariables() Environment variables config source. create(java.nio.file.Path) Loads a properties file from file system. To load the properties file from file system with custom name, use create(String, java.nio.file.Path) . create(java.util.Map) Creates an in-memory source from map. To create an in-memory source from map with custom name, use create(String, java.util.Map) . create(java.util.Properties) Creates an in-memory source from properties. To create an in-memory source from properties with custom name, use create(String, java.util.Properties) . Create Custom Map MicroProfile Config Source You can create Microprofile Config Source from a map. <markup lang=\"java\" title=\"Create MicroProfile Config Source based on Environment Variables and Custom Map\" >ConfigProviderResolver resolver = ConfigProviderResolver.instance(); org.eclipse.microprofile.config.Config config = resolver.getBuilder() .withSources(MpConfigSources.environmentVariables()) .withSources(MpConfigSources.create(Map.of(\"key\",\"value\"))) .build(); resolver.registerConfig(config, null); Creates MicroProfile Config Source builder. Adds environment variables. Adds a custom map. Builds the MicroProfile Config Source. Registers the config, so it can be used by other components Create YAML MicroProfile Config Source You can create YAML Microprofile Config Source from a path or a URL. When you create a MicroProfile instance from the builder, the YamlMpConfigSource allows you to create a custom Config Source and register it with the builder. <markup lang=\"java\" title=\"Create YamlMPConfigSource from a path\" >ConfigProviderResolver.instance().newBuilder() .withSources(YamlMpConfigSource.create(path)) .build(); ",
            "title": "Creating MicroProfile Config Sources for Manual Setup of Config"
        },
        {
            "location": "mp/config/advanced-configuration",
            "text": "<markup lang=\"java\" >public class CustomConfigSource implements ConfigSource { private static final String NAME = \"MyConfigSource\"; private static final int ORDINAL = 200; // Default for MP is 100 private static final Map&lt;String, String&gt; PROPERTIES = mapOf(\"app.greeting\", \"Hi\"); @Override public String getName() { return NAME; } @Override public Map&lt;String, String&gt; getProperties() { return PROPERTIES; } @Override public String getValue(String key) { return PROPERTIES.get(key); } @Override public int getOrdinal() { return ORDINAL; } } Returns the name of the Config Source to use for logging or analysis of configured values. Returns the properties in this Config Source as a map. Returns the value of the requested key, or null if the key is not available Returns the ordinal of this Config Source. ",
            "title": "Example of a Custom Config Source"
        },
        {
            "location": "mp/config/advanced-configuration",
            "text": " Custom Config Sources are loaded using the Java Service Loader pattern, by implementing either org.eclipse.microprofile.config.spi.ConfigSource , or org.eclipse.microprofile.config.spi.ConfigSourceProvider SPI and registering it as a service (Using META-INF/services/${class-name} file when using classpath, or using the provides statement in module-info.java when using module path). The interface org.eclipse.microprofile.config.spi.ConfigSource requires implementation of the following methods: String getName() Map&lt;String, String&gt; getProperties() String getValue(String key) getOrdinal() Example of a Custom Config Source <markup lang=\"java\" >public class CustomConfigSource implements ConfigSource { private static final String NAME = \"MyConfigSource\"; private static final int ORDINAL = 200; // Default for MP is 100 private static final Map&lt;String, String&gt; PROPERTIES = mapOf(\"app.greeting\", \"Hi\"); @Override public String getName() { return NAME; } @Override public Map&lt;String, String&gt; getProperties() { return PROPERTIES; } @Override public String getValue(String key) { return PROPERTIES.get(key); } @Override public int getOrdinal() { return ORDINAL; } } Returns the name of the Config Source to use for logging or analysis of configured values. Returns the properties in this Config Source as a map. Returns the value of the requested key, or null if the key is not available Returns the ordinal of this Config Source. ",
            "title": "Creating Custom Config Sources"
        },
        {
            "location": "mp/config/advanced-configuration",
            "text": " Instead of directly specifying the configuration sources in your code, you can use meta-configuration in a file that declares the configuration sources, and their attributes as mentioned in Microprofile Config . When used, the Microprofile Config uses configuration sources and flags configured in the meta configuration file. If a file named mp-meta-config.yaml , or mp-meta-config.properties is in the current directory or on the classpath, and there is no explicit setup of configuration in the code, the configuration will be loaded from the meta-config file. The location of the file can be overridden using system property io.helidon.config.mp.meta-config , or environment variable HELIDON_MP_META_CONFIG <markup lang=\"yaml\" title=\"Example of a YAML meta configuration file:\" >add-discovered-sources: true add-discovered-converters: false add-default-sources: false sources: - type: \"environment-variables\" - type: \"system-properties\" - type: \"properties\" path: \"/conf/prod.properties\" ordinal: 50 optional: true - type: \"yaml\" classpath: \"META-INF/database.yaml\" - type: \"hocon\" classpath: \"custom-application.conf\" - type: \"json\" path: \"path: conf/custom-application.json\" If configured to true , config sources discovered through service loader will be added If configured to true , converters discovered through service loader will be added If configured to true , default config sources (system properties, environment variables, and `META-INF/microprofile-config.properties) will be added Loads the environment variables config source. Loads the system properties config source. Loads a properties file Location of the file: /conf/prod.properties on the file system Custom ordinal, if not defined, the value defined in the file, or default value is used. The source precedence order is the order of appearance in the file. The file is optional (if not optional and no file is found, the bootstrap fails) Loads a YAML file Location of the file: META-INF/database.yaml on the classpath Loads a HOCON file Location of the file: custom-application.conf on the classpath Loads a JSON file Location of the file: conf/custom-application.json relative to the directory of where the app was executed on the file system. Important Note: To enable support for HOCON and JSON types, add the following dependency to your project’s pom.xml. <markup lang=\"xml\" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.config&lt;/groupId&gt; &lt;artifactId&gt;helidon-config-hocon-mp&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Creating MicroProfile Config Sources from meta-config"
        },
        {
            "location": "mp/config/advanced-configuration",
            "text": "<markup lang=\"java\" >public class CustomMpMetaConfigProvider implements MpMetaConfigProvider { @Override public Set&lt;String&gt; supportedTypes() { return Set.of(\"custom\"); } @Override public List&lt;? extends ConfigSource&gt; create(String type, Config metaConfig, String profile) { ConfigValue&lt;Path&gt; pathConfig = metaConfig.get(\"path\").as(Path.class); if (pathConfig.isPresent()) { Path path = pathConfig.get(); List&lt;ConfigSource&gt; sources = sourceFromPath(path, profile); if (sources != null &amp;&amp; !sources.isEmpty()) { return result; } location = \"path \" + path.toAbsolutePath(); } else { ConfigValue&lt;String&gt; classpathConfig = metaConfig.get(\"classpath\").as(String.class); if (classpathConfig.isPresent()) { String classpath = classpathConfig.get(); List&lt;ConfigSource&gt; sources = sourceFromClasspath(classpath, profile); if (sources != null &amp;&amp; !sources.isEmpty()) { return sources; } location = \"classpath \" + classpath; } else { ConfigValue&lt;URL&gt; urlConfig = metaConfig.get(\"url\").as(URL.class); if (urlConfig.isPresent()) { URL url = urlConfig.get(); List&lt;ConfigSource&gt; sources = sourceFromUrlMeta(url, profile); if (sources != null &amp;&amp; !sources.isEmpty()) { return sources; } location = \"url \" + url; } else { throw new ConfigException(\"No config source location for \" + config.key()); } } } } if (metaConfig.get(\"optional\").asBoolean().orElse(false);) { return List.of(); } throw new ConfigException(\"Meta configuration could not find non-optional config source on \" + location); } Returns the names of the types that will be supported in this meta-config. Processes config source from file system if path is provided. Method to parse config source from a specified path Processes config source from classpath location if classpath is provided. Method to parse config source from a specified classpath Processes config source from URL location if location is provided. Method to parse config source from a specified url Returns an empty result if set to optional and config source is not found. Throws a ConfigException if not set to optional and config source is not found. ",
            "title": "Example of a Meta-Config Custom Type"
        },
        {
            "location": "mp/config/advanced-configuration",
            "text": " Helidon meta-config by default supports the following types: environment-variables, system-properties, properties, yaml, hocon and json. Users can also extend meta-config to create a custom config source type by loading it using the Java Service Loader pattern. This is achieved by implementing io.helidon.config.mp.spi.MpMetaConfigProvider SPI and registering it as a service (Using META-INF/services/${class-name} file when using classpath, or using the provides statement in module-info.java when using module path). The interface io.helidon.config.mp.spi.MpMetaConfigProvider requires implementation of the following methods: Set&lt;String&gt; supportedTypes() List&lt;? extends ConfigSource&gt; create(String type, Config metaConfig, String profile); Example of a Meta-Config Custom Type <markup lang=\"java\" >public class CustomMpMetaConfigProvider implements MpMetaConfigProvider { @Override public Set&lt;String&gt; supportedTypes() { return Set.of(\"custom\"); } @Override public List&lt;? extends ConfigSource&gt; create(String type, Config metaConfig, String profile) { ConfigValue&lt;Path&gt; pathConfig = metaConfig.get(\"path\").as(Path.class); if (pathConfig.isPresent()) { Path path = pathConfig.get(); List&lt;ConfigSource&gt; sources = sourceFromPath(path, profile); if (sources != null &amp;&amp; !sources.isEmpty()) { return result; } location = \"path \" + path.toAbsolutePath(); } else { ConfigValue&lt;String&gt; classpathConfig = metaConfig.get(\"classpath\").as(String.class); if (classpathConfig.isPresent()) { String classpath = classpathConfig.get(); List&lt;ConfigSource&gt; sources = sourceFromClasspath(classpath, profile); if (sources != null &amp;&amp; !sources.isEmpty()) { return sources; } location = \"classpath \" + classpath; } else { ConfigValue&lt;URL&gt; urlConfig = metaConfig.get(\"url\").as(URL.class); if (urlConfig.isPresent()) { URL url = urlConfig.get(); List&lt;ConfigSource&gt; sources = sourceFromUrlMeta(url, profile); if (sources != null &amp;&amp; !sources.isEmpty()) { return sources; } location = \"url \" + url; } else { throw new ConfigException(\"No config source location for \" + config.key()); } } } } if (metaConfig.get(\"optional\").asBoolean().orElse(false);) { return List.of(); } throw new ConfigException(\"Meta configuration could not find non-optional config source on \" + location); } Returns the names of the types that will be supported in this meta-config. Processes config source from file system if path is provided. Method to parse config source from a specified path Processes config source from classpath location if classpath is provided. Method to parse config source from a specified classpath Processes config source from URL location if location is provided. Method to parse config source from a specified url Returns an empty result if set to optional and config source is not found. Throws a ConfigException if not set to optional and config source is not found. ",
            "title": "Extending Meta-Config to Create a Custom Config Source Type"
        },
        {
            "location": "mp/config/advanced-configuration",
            "text": " To use the Helidon SE features in Helidon MP, create MicroProfile Config Source from Helidon SE Config Source. The Config Source is immutable regardless of configured polling strategy or change watchers. Config config = ConfigProviderResolver.instance() .getBuilder() .withSources(MpConfigSources.create(helidonConfigSource) .build(); Creates a MicroProfile config instance using Helidon Config Source. ",
            "title": "Creating MicroProfile Config Source from Helidon SE Config Source"
        },
        {
            "location": "mp/config/advanced-configuration",
            "text": " To use advanced Helidon SE features in Helidon MP, create MicroProfile Config Source from Helidon SE Config. The Config Source is mutable if the config uses either polling strategy and change watchers, or polling strategy or change watchers. The latest config version is queried each time org.eclipse.microprofile.config.spi.ConfigSource#getValue(String) is called. io.helidon.config.Config helidonConfig = io.helidon.config.Config.builder() .addSource(ConfigSources.create(Map.of(\"key\", \"value\"))) .build(); ConfigProviderResolver.instance(); Config config = ConfigProviderResolver.instance() .getBuilder() .withSources(MpConfigSources.create(helidonConfig)) .build(); Creates a config source from Helidon Config. Creates a MicroProfile config instance using Helidon Config. ",
            "title": "Creating MicroProfile Config Source from Helidon SE Config Instance"
        },
        {
            "location": "mp/config/introduction",
            "text": " Overview Maven Coordinates Usage Configuration Reference ",
            "title": "Contents"
        },
        {
            "location": "mp/config/introduction",
            "text": " Helidon MicroProfile Config is an implementation of Eclipse MicroProfile Config . You can configure your applications using MicroProfile&#8217;s config configuration sources and APIs. You can also extend the configuration using MicroProfile SPI to add custom ConfigSource and Converter . ",
            "title": "Overview"
        },
        {
            "location": "mp/config/introduction",
            "text": " To enable MicroProfile Config either add a dependency on the helidon-microprofile bundle or add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.config&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-config&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "mp/config/introduction",
            "text": " A Config Source provides configuration values from different sources such as property files and user classes that are registered by the application. By default, the following configuration sources are used to retrieve the configuration: Source Description System properties A mutable source that uses System.getProperties() to obtain configuration values. Environment variables An immutable source that uses System.env() to obtain configuration values and resolves aliases as defined by the MicroProfile Config specification. META-INF/microprofile-config.properties The properties config source as defined by MicroProfile Config specification. MicroProfile Config uses ConfigSource SPI to load configuration data, either from default configuration sources or from custom ConfigSource located by Java Service Loader. ",
            "title": "MicroProfile Config Sources"
        },
        {
            "location": "mp/config/introduction",
            "text": " You can use MicroProfile Config API to get configuration properties by using a Config instance programmatically or injecting configuration values with @ConfigProperty . <markup lang=\"java\" title=\"Using Config \" >org.eclipse.microprofile.config.Config config = ConfigProvider.getConfig(); config.getOptionalValue(\"app.greeting\", String.class).orElse(\"Hello\"); <markup lang=\"java\" title=\"Injecting configured properties into a constructor\" >@Inject public GreetingProvider(@ConfigProperty(name = \"app.greeting\", defaultValue = \"Hello\") String message) { this.message = message } MicroProfile Config provides typed access to configuration values, using built-in converters, and Converter implementations located by Java Service Loader. ",
            "title": "Using MicroProfile Config API"
        },
        {
            "location": "mp/config/introduction",
            "text": " In order to properly configure your application using configuration sources, you need to understand the precedence rules used to merge your configuration data. The default MicroProfile Config Sources ordering is: System properties (ordinal=400) Environment variables (ordinal=300) /META-INF/microprofile-config.properties (ordinal=100) Each Config Source has an ordinal that determines the priority of the Config Source. A Config Source with higher ordinal has higher priority as compared to the Config Source with lower ordinal. The values taken from the high-priority Config Source overrides the values from low-priority Config Source. This helps to customize the configuration of Config Sources using external Config Source if an external Config Source has higher ordinal values than the built-in Config Sources of the application. The example below shows how the MicroProfile configuration file microprofile-config.properties can be used to modify the server listen port property. <markup lang=\"properties\" >// Application properties. This is the default greeting app.greeting=Hello // Microprofile server properties server.port=8080 server.host=0.0.0.0 ",
            "title": "Ordering of Default Config Sources"
        },
        {
            "location": "mp/config/introduction",
            "text": " MicroProfile Config supports a concept of configuration profiles. You can define a profile using the configuration property mp.config.profile (when using default configuration, this can be defined as a system property, environment variable or as a property in microprofile-config.properties ). When a profile is defined, additional config source is loaded ( microprofile-config-profile.properties ) and properties from profile have precedence over default properties. Profile properties can be defined using %profile prefix, such as %dev.server.port . ",
            "title": "MicroProfile Config Profiles"
        },
        {
            "location": "mp/config/introduction",
            "text": " MicroProfile Config Sources A Config Source provides configuration values from different sources such as property files and user classes that are registered by the application. By default, the following configuration sources are used to retrieve the configuration: Source Description System properties A mutable source that uses System.getProperties() to obtain configuration values. Environment variables An immutable source that uses System.env() to obtain configuration values and resolves aliases as defined by the MicroProfile Config specification. META-INF/microprofile-config.properties The properties config source as defined by MicroProfile Config specification. MicroProfile Config uses ConfigSource SPI to load configuration data, either from default configuration sources or from custom ConfigSource located by Java Service Loader. Using MicroProfile Config API You can use MicroProfile Config API to get configuration properties by using a Config instance programmatically or injecting configuration values with @ConfigProperty . <markup lang=\"java\" title=\"Using Config \" >org.eclipse.microprofile.config.Config config = ConfigProvider.getConfig(); config.getOptionalValue(\"app.greeting\", String.class).orElse(\"Hello\"); <markup lang=\"java\" title=\"Injecting configured properties into a constructor\" >@Inject public GreetingProvider(@ConfigProperty(name = \"app.greeting\", defaultValue = \"Hello\") String message) { this.message = message } MicroProfile Config provides typed access to configuration values, using built-in converters, and Converter implementations located by Java Service Loader. Ordering of Default Config Sources In order to properly configure your application using configuration sources, you need to understand the precedence rules used to merge your configuration data. The default MicroProfile Config Sources ordering is: System properties (ordinal=400) Environment variables (ordinal=300) /META-INF/microprofile-config.properties (ordinal=100) Each Config Source has an ordinal that determines the priority of the Config Source. A Config Source with higher ordinal has higher priority as compared to the Config Source with lower ordinal. The values taken from the high-priority Config Source overrides the values from low-priority Config Source. This helps to customize the configuration of Config Sources using external Config Source if an external Config Source has higher ordinal values than the built-in Config Sources of the application. The example below shows how the MicroProfile configuration file microprofile-config.properties can be used to modify the server listen port property. <markup lang=\"properties\" >// Application properties. This is the default greeting app.greeting=Hello // Microprofile server properties server.port=8080 server.host=0.0.0.0 MicroProfile Config Profiles MicroProfile Config supports a concept of configuration profiles. You can define a profile using the configuration property mp.config.profile (when using default configuration, this can be defined as a system property, environment variable or as a property in microprofile-config.properties ). When a profile is defined, additional config source is loaded ( microprofile-config-profile.properties ) and properties from profile have precedence over default properties. Profile properties can be defined using %profile prefix, such as %dev.server.port . ",
            "title": "MicroProfile Config Features"
        },
        {
            "location": "mp/config/introduction",
            "text": " Helidon MicroProfile Config offers the following features on top of the specification: ",
            "title": "Helidon MicroProfile Config Features"
        },
        {
            "location": "mp/config/introduction",
            "text": " You can use ${reference} to reference another configuration key in a key value. This allows to configure a single key to be reused in multiple other keys. <markup lang=\"yaml\" title=\"Example\" >uri: \"http://localhost:8080\" service-1: \"${uri}/service1\" service-2: \"${uri}/service2\" ",
            "title": "References"
        },
        {
            "location": "mp/config/introduction",
            "text": " Polling (or change watching) for file based config sources (not classpath based). To enable polling for a config source created using meta configuration (see below), or using MpConfigSources.create(Path) , or YamlMpConfigSource.create(Path) , use the following properties: Property Description helidon.config.polling.enabled To enable polling file for changes, uses timestamp to identify a change. helidon.config.polling.duration Polling period duration, defaults to 10 seconds ('PT10S`) See javadoc helidon.config.watcher.enabled To enable watching file for changes using the Java WatchService . See link:https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/nio/file/WatchService.html ",
            "title": "Change support"
        },
        {
            "location": "mp/config/introduction",
            "text": " You can encrypt secrets using a master password and store them in a configuration file. The config encryption filter in MicroProfile Config is enabled by default. For more information, see Configuration Secrets . <markup lang=\"properties\" title=\"Example of encrypted secrets\" ># Password encrypted using a master password client_secret=${GCM=mYRkg+4Q4hua1kvpCCI2hg==} # Password encrypted using public key (there are length limits when using RSA) client_secret=${RSA=mYRkg+4Q4hua1kvpCCI2hg==} # Password in clear text, can be used in development # The system needs to be configured to accept clear text client_secret=${CLEAR=known_password} ",
            "title": "Encryption"
        },
        {
            "location": "mp/config/introduction",
            "text": " You can configure the Config using Helidon MP Config meta configuration feature. The meta-config allows configuration of config sources and other configuration options, including addition of discovered sources and converters. See Microprofile Config Sources for detailed information. For backward compatibility, we will support usage of Helidon SE meta-configuration until version 3.0.0. Using this approach causes behavior that is not compatible with MicroProfile Config specification. ",
            "title": "Meta Configuration"
        },
        {
            "location": "mp/config/introduction",
            "text": " Helidon configuration sources can use different formats for the configuration data. You can specify the format on a per source bases, mixing and matching formats as required. The following configuration sources can be used to retrieve the configuration: Source Description File Creates the source from a properties file on the file system with MpConfigSources.create(Path) . URL Creates the source from properties from a URL with MpConfigSources.create(URL) . Map&lt;String, String&gt; Creates the source from a Map with MpConfigSources.create(Map) . Properties Creates the source directly from Properties with MpConfigSources.create(Properties) . File on classpath Creates the source from a properties file on classpath with MpConfigSources.classpath(String) . YAML Creates the source from YAML using YamlMpConfigSource.create(Path) or YamlMpConfigSource.create(URL) . See manual setup of config section for more information. References You can use ${reference} to reference another configuration key in a key value. This allows to configure a single key to be reused in multiple other keys. <markup lang=\"yaml\" title=\"Example\" >uri: \"http://localhost:8080\" service-1: \"${uri}/service1\" service-2: \"${uri}/service2\" Change support Polling (or change watching) for file based config sources (not classpath based). To enable polling for a config source created using meta configuration (see below), or using MpConfigSources.create(Path) , or YamlMpConfigSource.create(Path) , use the following properties: Property Description helidon.config.polling.enabled To enable polling file for changes, uses timestamp to identify a change. helidon.config.polling.duration Polling period duration, defaults to 10 seconds ('PT10S`) See javadoc helidon.config.watcher.enabled To enable watching file for changes using the Java WatchService . See link:https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/nio/file/WatchService.html Encryption You can encrypt secrets using a master password and store them in a configuration file. The config encryption filter in MicroProfile Config is enabled by default. For more information, see Configuration Secrets . <markup lang=\"properties\" title=\"Example of encrypted secrets\" ># Password encrypted using a master password client_secret=${GCM=mYRkg+4Q4hua1kvpCCI2hg==} # Password encrypted using public key (there are length limits when using RSA) client_secret=${RSA=mYRkg+4Q4hua1kvpCCI2hg==} # Password in clear text, can be used in development # The system needs to be configured to accept clear text client_secret=${CLEAR=known_password} Meta Configuration You can configure the Config using Helidon MP Config meta configuration feature. The meta-config allows configuration of config sources and other configuration options, including addition of discovered sources and converters. See Microprofile Config Sources for detailed information. For backward compatibility, we will support usage of Helidon SE meta-configuration until version 3.0.0. Using this approach causes behavior that is not compatible with MicroProfile Config specification. ",
            "title": "Helidon MicroProfile Config Sources"
        },
        {
            "location": "mp/config/introduction",
            "text": " MicroProfile Config Features MicroProfile Config Sources A Config Source provides configuration values from different sources such as property files and user classes that are registered by the application. By default, the following configuration sources are used to retrieve the configuration: Source Description System properties A mutable source that uses System.getProperties() to obtain configuration values. Environment variables An immutable source that uses System.env() to obtain configuration values and resolves aliases as defined by the MicroProfile Config specification. META-INF/microprofile-config.properties The properties config source as defined by MicroProfile Config specification. MicroProfile Config uses ConfigSource SPI to load configuration data, either from default configuration sources or from custom ConfigSource located by Java Service Loader. Using MicroProfile Config API You can use MicroProfile Config API to get configuration properties by using a Config instance programmatically or injecting configuration values with @ConfigProperty . <markup lang=\"java\" title=\"Using Config \" >org.eclipse.microprofile.config.Config config = ConfigProvider.getConfig(); config.getOptionalValue(\"app.greeting\", String.class).orElse(\"Hello\"); <markup lang=\"java\" title=\"Injecting configured properties into a constructor\" >@Inject public GreetingProvider(@ConfigProperty(name = \"app.greeting\", defaultValue = \"Hello\") String message) { this.message = message } MicroProfile Config provides typed access to configuration values, using built-in converters, and Converter implementations located by Java Service Loader. Ordering of Default Config Sources In order to properly configure your application using configuration sources, you need to understand the precedence rules used to merge your configuration data. The default MicroProfile Config Sources ordering is: System properties (ordinal=400) Environment variables (ordinal=300) /META-INF/microprofile-config.properties (ordinal=100) Each Config Source has an ordinal that determines the priority of the Config Source. A Config Source with higher ordinal has higher priority as compared to the Config Source with lower ordinal. The values taken from the high-priority Config Source overrides the values from low-priority Config Source. This helps to customize the configuration of Config Sources using external Config Source if an external Config Source has higher ordinal values than the built-in Config Sources of the application. The example below shows how the MicroProfile configuration file microprofile-config.properties can be used to modify the server listen port property. <markup lang=\"properties\" >// Application properties. This is the default greeting app.greeting=Hello // Microprofile server properties server.port=8080 server.host=0.0.0.0 MicroProfile Config Profiles MicroProfile Config supports a concept of configuration profiles. You can define a profile using the configuration property mp.config.profile (when using default configuration, this can be defined as a system property, environment variable or as a property in microprofile-config.properties ). When a profile is defined, additional config source is loaded ( microprofile-config-profile.properties ) and properties from profile have precedence over default properties. Profile properties can be defined using %profile prefix, such as %dev.server.port . Helidon MicroProfile Config Features Helidon MicroProfile Config offers the following features on top of the specification: Helidon MicroProfile Config Sources Helidon configuration sources can use different formats for the configuration data. You can specify the format on a per source bases, mixing and matching formats as required. The following configuration sources can be used to retrieve the configuration: Source Description File Creates the source from a properties file on the file system with MpConfigSources.create(Path) . URL Creates the source from properties from a URL with MpConfigSources.create(URL) . Map&lt;String, String&gt; Creates the source from a Map with MpConfigSources.create(Map) . Properties Creates the source directly from Properties with MpConfigSources.create(Properties) . File on classpath Creates the source from a properties file on classpath with MpConfigSources.classpath(String) . YAML Creates the source from YAML using YamlMpConfigSource.create(Path) or YamlMpConfigSource.create(URL) . See manual setup of config section for more information. References You can use ${reference} to reference another configuration key in a key value. This allows to configure a single key to be reused in multiple other keys. <markup lang=\"yaml\" title=\"Example\" >uri: \"http://localhost:8080\" service-1: \"${uri}/service1\" service-2: \"${uri}/service2\" Change support Polling (or change watching) for file based config sources (not classpath based). To enable polling for a config source created using meta configuration (see below), or using MpConfigSources.create(Path) , or YamlMpConfigSource.create(Path) , use the following properties: Property Description helidon.config.polling.enabled To enable polling file for changes, uses timestamp to identify a change. helidon.config.polling.duration Polling period duration, defaults to 10 seconds ('PT10S`) See javadoc helidon.config.watcher.enabled To enable watching file for changes using the Java WatchService . See link:https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/nio/file/WatchService.html Encryption You can encrypt secrets using a master password and store them in a configuration file. The config encryption filter in MicroProfile Config is enabled by default. For more information, see Configuration Secrets . <markup lang=\"properties\" title=\"Example of encrypted secrets\" ># Password encrypted using a master password client_secret=${GCM=mYRkg+4Q4hua1kvpCCI2hg==} # Password encrypted using public key (there are length limits when using RSA) client_secret=${RSA=mYRkg+4Q4hua1kvpCCI2hg==} # Password in clear text, can be used in development # The system needs to be configured to accept clear text client_secret=${CLEAR=known_password} Meta Configuration You can configure the Config using Helidon MP Config meta configuration feature. The meta-config allows configuration of config sources and other configuration options, including addition of discovered sources and converters. See Microprofile Config Sources for detailed information. For backward compatibility, we will support usage of Helidon SE meta-configuration until version 3.0.0. Using this approach causes behavior that is not compatible with MicroProfile Config specification. ",
            "title": "Usage"
        },
        {
            "location": "mp/config/introduction",
            "text": " Optional configuration options key type default value description profile string &#160; Configure an explicit profile name. Current properties may be set in application.yaml or in microprofile-config.properties with mp.config prefix. See Config Profiles for more information. ",
            "title": "Configuration options"
        },
        {
            "location": "mp/config/introduction",
            "text": " Config sources can be configured using the following properties. The class responsible for configuration is: Type: org.eclipse.microprofile.config.Config This is a standalone configuration type, prefix from configuration root: mp.config Configuration options Optional configuration options key type default value description profile string &#160; Configure an explicit profile name. Current properties may be set in application.yaml or in microprofile-config.properties with mp.config prefix. See Config Profiles for more information. ",
            "title": "Configuration"
        },
        {
            "location": "mp/config/introduction",
            "text": " MP Config Guide Step-by-step guide about using MicroProfile Config in your Helidon MP application. ",
            "title": "Additional Information"
        },
        {
            "location": "mp/config/introduction",
            "text": " MicroProfile Config Specifications MicroProfile Config Javadocs ",
            "title": "Reference"
        },
        {
            "location": "mp/cors/cors",
            "text": " Overview Maven Coordinates Usage API Configuration Examples Additional Information ",
            "title": "Contents"
        },
        {
            "location": "mp/cors/cors",
            "text": " Before you revise your application to add CORS support, you need to decide what type of cross-origin sharing you want to allow for each resource your application exposes. For example, suppose for a given resource you want to allow unrestricted sharing for GET, HEAD, and POST requests (what CORS refers to as \"simple\" requests), but permit other types of requests only from the two origins foo.com and there.com . Your application would implement two types of CORS sharing: more relaxed for the simple requests and stricter for others. Once you know the type of sharing you want to allow for each of your resources&#8201;&#8212;&#8201;including any from built-in services&#8201;&#8212;&#8201;you can change your application accordingly. ",
            "title": "Before You Begin"
        },
        {
            "location": "mp/cors/cors",
            "text": " The cross-origin resource sharing (CORS) protocol helps developers control if and how REST resources served by their applications can be shared across origins. Helidon MP includes an implementation of CORS that you can use to add CORS behavior to the services you develop. You can define your application&#8217;s CORS behavior programmatically using the Helidon CORS API alone, or together with configuration. Helidon also provides three built-in services that add their own endpoints to your application&#8201;&#8212;&#8201;health, metrics, and OpenAPI&#8201;&#8212;&#8201;that have integrated CORS support. By adding very little code to your application, you control how all the resources in your application&#8201;&#8212;&#8201;the ones you write and the ones provided by the Helidon built-in services&#8201;&#8212;&#8201;can be shared across origins. Before You Begin Before you revise your application to add CORS support, you need to decide what type of cross-origin sharing you want to allow for each resource your application exposes. For example, suppose for a given resource you want to allow unrestricted sharing for GET, HEAD, and POST requests (what CORS refers to as \"simple\" requests), but permit other types of requests only from the two origins foo.com and there.com . Your application would implement two types of CORS sharing: more relaxed for the simple requests and stricter for others. Once you know the type of sharing you want to allow for each of your resources&#8201;&#8212;&#8201;including any from built-in services&#8201;&#8212;&#8201;you can change your application accordingly. ",
            "title": "Overview"
        },
        {
            "location": "mp/cors/cors",
            "text": " To enable CORS add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-cors&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "mp/cors/cors",
            "text": " Once you have planned how each of your resources should support CORS, you specify the CORS behavior in one of two ways: add @CrossOrigin annotations to the Java code for the resources, or add configuration. You can do both. CORS configuration for a resource overrides any CORS settings declared using @CrossOrigin in the Java class for the resource. ",
            "title": "Usage"
        },
        {
            "location": "mp/cors/cors",
            "text": " Adding CORS behavior to your Helidon MP application involves just a few simple steps. For reach resource class in your application: Identify the resources and subresources&#8212;&#8203;in other words, the paths&#8212;&#8203;declared in the resource class which you want to support CORS. For each of those resources and subresources which should support CORS: Find or create a Java method annotated with @OPTIONS and with the correct @Path . To that @OPTIONS Java method add a Helidon @CrossOrigin annotation that describes the cross-origin sharing you want for that resource. Using @CrossOrigin Correctly Use the @CrossOrigin annotation only on methods which also have the @OPTIONS annotation. Remember that the @CrossOrigin settings apply to a given path and therefore to all Java resource methods which share that path. Helidon MP aborts the server start-up if you use the @CrossOrigin annotation on a resource method other than an @OPTIONS method. For an informal look at the reasons for applying the @CrossOrigin annotation to the @OPTIONS method, instead of another method, see Why @OPTIONS ? . The configuration table below describes the attributes of the @CrossOrigin annotation. ",
            "title": "The @CrossOrigin Annotation"
        },
        {
            "location": "mp/cors/cors",
            "text": " The @CrossOrigin Annotation Adding CORS behavior to your Helidon MP application involves just a few simple steps. For reach resource class in your application: Identify the resources and subresources&#8212;&#8203;in other words, the paths&#8212;&#8203;declared in the resource class which you want to support CORS. For each of those resources and subresources which should support CORS: Find or create a Java method annotated with @OPTIONS and with the correct @Path . To that @OPTIONS Java method add a Helidon @CrossOrigin annotation that describes the cross-origin sharing you want for that resource. Using @CrossOrigin Correctly Use the @CrossOrigin annotation only on methods which also have the @OPTIONS annotation. Remember that the @CrossOrigin settings apply to a given path and therefore to all Java resource methods which share that path. Helidon MP aborts the server start-up if you use the @CrossOrigin annotation on a resource method other than an @OPTIONS method. For an informal look at the reasons for applying the @CrossOrigin annotation to the @OPTIONS method, instead of another method, see Why @OPTIONS ? . The configuration table below describes the attributes of the @CrossOrigin annotation. ",
            "title": "API"
        },
        {
            "location": "mp/cors/cors",
            "text": " You can define CORS behavior&#8212;&#8203;and you or your users can override behavior declared in your code&#8212;&#8203;using configuration. For each resource you want to configure, add a section to META-INF/microprofile-config.properties file: <markup lang=\"properties\" title=\"General form of CORS configuration\" >cors.enabled= # cors.paths. i .path-pattern= cors.paths. i .allow-headers= cors.paths. i .max-age-seconds= cors.paths. i .allow-credentials= cors.paths. i .allow-origins= cors.paths. i .expose-headers= cors.paths. i .allow-methods= cors.paths. i .enabled= You can disable CORS processing for all resources by setting cors.enabled to false . Defaults to true . Add a block for each resource you want to configure. The index i is an integer (0, 1, 2, etc.). Specify the settings as needed to define the CORS behavior you want for that resource. The enabled setting lets you control whether the system uses that set of CORS configuration. Defaults to true . The system uses the index i , not the position in the config file, to identify the settings for a particular resource. Path patterns can be any expression accepted by the PathMatcher class. Helidon scans the cross-origin entries in index order (0, 1, 2, etc.) until it finds an entry that matches an incoming request&#8217;s path and HTTP method, so be sure to assign index values to the entries so Helidon will check them in the order you want. In particular, use lower index values for entries with more specific path patterns. The table below describes the attributes on the @CrossOrigin annotation and the configuration keys that map to the headers defined in the CORS protocol. annotation attribute config key type default description CORS header name allowCredentials allow-credentials boolean false Sets the allow credentials flag. Access-Control-Allow-Credentials allowHeaders allow-headers string[] * Sets the allowed headers. Access-Control-Allow-Headers allowMethods allow-methods string[] * Sets the allowed methods. Access-Control-Allow-Methods allowOrigins allow-origins string[] * Sets the allowed origins. Access-Control-Allow-Origins exposeHeaders expose-headers string[] &#160; Sets the expose headers. Access-Control-Expose-Headers maxAgeSeconds max-age-seconds long 3600 Sets the maximum age. Access-Control-Max-Age enabled enabled boolean true Sets whether this config should be enabled or not. n/a If the cross-origin configuration is disabled ( enabled = false), then the Helidon CORS implementation ignores the cross-origin configuration entry. ",
            "title": "Configuration"
        },
        {
            "location": "mp/cors/cors",
            "text": "<markup lang=\"java\" title=\"Using annotations to declare CORS behavior\" >@Path(\"/greet\") public class GreetResource { @GET public JsonObject getDefaultMessage() {...} @Path(\"/greeting\") @PUT public Response updateGreeting(JsonObject jsonObject) {...} @OPTIONS @CrossOrigin() public void optionsForRetrievingUnnamedGreeting() {} @OPTIONS @Path(\"/greeting\") @CrossOrigin({\"http://foo.com\", \"http://there.com\"}, allowMethods = {HttpMethod.PUT}) public void optionsForUpdatingGreeting() {} } Existing GreetResource resource class with path /greet . Existing @GET method for resource /greet . Existing @PUT method for resource /greet/greeting . New @OPTIONS method for /greet . (Just like the @GET method getDefaultMessage , this @OPTIONS method does not have a @Path annotation; both \"inherit\" the class-level @Path setting /greet .) The @CrossOrigin annotation declares default cross-origin sharing which permits sharing via all HTTP methods to all origins. New @OPTIONS method for /greet/greeting . The @CrossOrigin annotation specifies sharing only via the PUT HTTP method and only to the two listed origins. ",
            "title": "Adding Annotations"
        },
        {
            "location": "mp/cors/cors",
            "text": " You could use the following configuration in place of using annotations to set up the same CORS behavior. <markup lang=\"properties\" title=\"Using configuration to set up the same CORS behavior\" >cors.paths.0.path-pattern=/greet cors.paths.1.path-pattern=/greet/greeting cors.paths.1.allow-origins=http://foo.com,http://there.com cors.paths.1.allow-methods=PUT Enables default CORS settings for the /greet resource. Sets up sharing for the /greet/greeting resource only via PUT requests and only from the specified origins. Or, alternatively, the following configuration example augments the settings from the @CrossOrigin annotations in the code. <markup lang=\"properties\" title=\"Using configuration to augment or override declared CORS behavior\" >cors.paths.0.path-pattern=/greet cors.paths.0.allow-methods=GET cors.paths.0.allow-origins=http://here.com,http://foo.com,http://there.com cors.paths.1.path-patterh=/greet/greeting cors.paths.1.allow-methods=PUT cors.paths.1.allow-origins=http://foo.com Changes the declared settings to restrict cross-origin use of /greet to only GET and only from foo.com and there.com . Changes the settings for /greet/greeting from what they were declared; with this configuration, only the origin foo.com is permitted. (The declared setting also allowed there.com ). ",
            "title": "Adding Configuration"
        },
        {
            "location": "mp/cors/cors",
            "text": " The Helidon MP Quickstart application allows users to: obtain greetings by sending GET requests to the /greet resource, and change the greeting message by sending a PUT request to the /greet/greeting resource. The Helidon MP CORS Example shows the basic quickstart example enhanced for CORS. The discussion below describes the changes in the application which: permit unrestricted sharing of the resource /greet , and restrict sharing of the resource /greet/greeting so that only the origins http://foo.com and http://there.com can change the greeting. Adding Annotations <markup lang=\"java\" title=\"Using annotations to declare CORS behavior\" >@Path(\"/greet\") public class GreetResource { @GET public JsonObject getDefaultMessage() {...} @Path(\"/greeting\") @PUT public Response updateGreeting(JsonObject jsonObject) {...} @OPTIONS @CrossOrigin() public void optionsForRetrievingUnnamedGreeting() {} @OPTIONS @Path(\"/greeting\") @CrossOrigin({\"http://foo.com\", \"http://there.com\"}, allowMethods = {HttpMethod.PUT}) public void optionsForUpdatingGreeting() {} } Existing GreetResource resource class with path /greet . Existing @GET method for resource /greet . Existing @PUT method for resource /greet/greeting . New @OPTIONS method for /greet . (Just like the @GET method getDefaultMessage , this @OPTIONS method does not have a @Path annotation; both \"inherit\" the class-level @Path setting /greet .) The @CrossOrigin annotation declares default cross-origin sharing which permits sharing via all HTTP methods to all origins. New @OPTIONS method for /greet/greeting . The @CrossOrigin annotation specifies sharing only via the PUT HTTP method and only to the two listed origins. Adding Configuration You could use the following configuration in place of using annotations to set up the same CORS behavior. <markup lang=\"properties\" title=\"Using configuration to set up the same CORS behavior\" >cors.paths.0.path-pattern=/greet cors.paths.1.path-pattern=/greet/greeting cors.paths.1.allow-origins=http://foo.com,http://there.com cors.paths.1.allow-methods=PUT Enables default CORS settings for the /greet resource. Sets up sharing for the /greet/greeting resource only via PUT requests and only from the specified origins. Or, alternatively, the following configuration example augments the settings from the @CrossOrigin annotations in the code. <markup lang=\"properties\" title=\"Using configuration to augment or override declared CORS behavior\" >cors.paths.0.path-pattern=/greet cors.paths.0.allow-methods=GET cors.paths.0.allow-origins=http://here.com,http://foo.com,http://there.com cors.paths.1.path-patterh=/greet/greeting cors.paths.1.allow-methods=PUT cors.paths.1.allow-origins=http://foo.com Changes the declared settings to restrict cross-origin use of /greet to only GET and only from foo.com and there.com . Changes the settings for /greet/greeting from what they were declared; with this configuration, only the origin foo.com is permitted. (The declared setting also allowed there.com ). ",
            "title": "Examples"
        },
        {
            "location": "mp/cors/cors",
            "text": " To use built-in services with CORS support and customize the CORS behavior: Add the built-in service or services to your application. The health, metrics, and OpenAPI services automatically include default CORS support. Add a dependency on the Helidon MP CORS artifact to your Maven pom.xml file. If you want the built-in services to support CORS, then you need to add the CORS dependency even if your own endpoints do not use CORS. Use configuration to customize the CORS behavior as needed. The documentation for the individual built-in services describes how to add each service to your application, including adding a Maven dependency. In your application&#8217;s configuration file, the configuration for each service appears under its own key. Helidon Service Documentation Configuration Key health health metrics metrics OpenAPI openapi The Helidon MP QuickStart example uses these services, so you can use that as a template for your own application, or use the example project itself to experiment with customizing the CORS behavior in the built-in services. ",
            "title": "Built-in Services with CORS"
        },
        {
            "location": "mp/cors/cors",
            "text": " You can use configuration to control whether and how each of the built-in services works with CORS. In the configuration for the health, metrics, and OpenAPI services, you can add a section for CORS. You have full control over the CORS configuration for a built-in Helidon service. Use a CORS config section as described in the configuration table . The following example restricts sharing of the /health resource, provided by the health built-in service, to only the origin http://there.com , and the /metrics resource, provided by the metrics built-in service, to only the origin http://foo.com . <markup lang=\"properties\" title=\"Configuration which restricts sharing of the health and metrics resources\" >health.cors.allow-origins=http://there.com metrics.cors.allow-origins=http://foo.com ",
            "title": "Configuring CORS for Built-in Services"
        },
        {
            "location": "mp/cors/cors",
            "text": " Build and run the QuickStart application as usual. <markup lang=\"bash\" >mvn package java -jar target/helidon-quickstart-mp.jar ... 2020.05.12 05:44:08 INFO io.helidon.microprofile.server.ServerCdiExtension Thread[main,5,main]: Server started on http://localhost:8080 (and all other host addresses) in 5280 milliseconds (since JVM startup). ... ",
            "title": "Build and Run the Application"
        },
        {
            "location": "mp/cors/cors",
            "text": " The metrics service rejects attempts to access metrics on behalf of a disallowed origin. <markup lang=\"bash\" >curl -i -H \"Origin: http://other.com\" http://localhost:8080/metrics <markup lang=\"listing\" >HTTP/1.1 403 Forbidden Date: Mon, 11 May 2020 11:08:09 -0500 transfer-encoding: chunked connection: keep-alive But accesses from foo.com succeed. <markup lang=\"bash\" >curl -i -H \"Origin: http://foo.com\" http://localhost:8080/metrics <markup lang=\"listing\" >HTTP/1.1 200 OK Access-Control-Allow-Origin: http://foo.com Content-Type: text/plain Date: Mon, 11 May 2020 11:08:16 -0500 Vary: Origin connection: keep-alive content-length: 6065 # TYPE base_classloader_loadedClasses_count gauge # HELP base_classloader_loadedClasses_count Displays the number of classes that are currently loaded in the Java virtual machine. base_classloader_loadedClasses_count 3568 ",
            "title": "Retrieve Metrics"
        },
        {
            "location": "mp/cors/cors",
            "text": " The health service rejects requests from origins not specifically approved. <markup lang=\"bash\" >curl -i -H \"Origin: http://foo.com\" http://localhost:8080/health <markup lang=\"listing\" >HTTP/1.1 403 Forbidden Date: Mon, 11 May 2020 12:06:55 -0500 transfer-encoding: chunked connection: keep-alive And responds successfully only to cross-origin requests from http://there.com . <markup lang=\"bash\" >curl -i -H \"Origin: http://there.com\" http://localhost:8080/health <markup lang=\"listing\" >HTTP/1.1 200 OK Access-Control-Allow-Origin: http://there.com Content-Type: application/json Date: Mon, 11 May 2020 12:07:32 -0500 Vary: Origin connection: keep-alive content-length: 461 {\"outcome\":\"UP\",...} ",
            "title": "Retrieve Health"
        },
        {
            "location": "mp/cors/cors",
            "text": " If you have edited the Helidon MP QuickStart application as described in the previous topics and saved your changes, you can build and run the application. Once you do so you can execute curl commands to demonstrate the behavior changes in the metric and health services with the addition of the CORS functionality. Note the addition of the Origin header value in the curl commands, and the Access-Control-Allow-Origin in the successful responses. Build and Run the Application Build and run the QuickStart application as usual. <markup lang=\"bash\" >mvn package java -jar target/helidon-quickstart-mp.jar ... 2020.05.12 05:44:08 INFO io.helidon.microprofile.server.ServerCdiExtension Thread[main,5,main]: Server started on http://localhost:8080 (and all other host addresses) in 5280 milliseconds (since JVM startup). ... Retrieve Metrics The metrics service rejects attempts to access metrics on behalf of a disallowed origin. <markup lang=\"bash\" >curl -i -H \"Origin: http://other.com\" http://localhost:8080/metrics <markup lang=\"listing\" >HTTP/1.1 403 Forbidden Date: Mon, 11 May 2020 11:08:09 -0500 transfer-encoding: chunked connection: keep-alive But accesses from foo.com succeed. <markup lang=\"bash\" >curl -i -H \"Origin: http://foo.com\" http://localhost:8080/metrics <markup lang=\"listing\" >HTTP/1.1 200 OK Access-Control-Allow-Origin: http://foo.com Content-Type: text/plain Date: Mon, 11 May 2020 11:08:16 -0500 Vary: Origin connection: keep-alive content-length: 6065 # TYPE base_classloader_loadedClasses_count gauge # HELP base_classloader_loadedClasses_count Displays the number of classes that are currently loaded in the Java virtual machine. base_classloader_loadedClasses_count 3568 Retrieve Health The health service rejects requests from origins not specifically approved. <markup lang=\"bash\" >curl -i -H \"Origin: http://foo.com\" http://localhost:8080/health <markup lang=\"listing\" >HTTP/1.1 403 Forbidden Date: Mon, 11 May 2020 12:06:55 -0500 transfer-encoding: chunked connection: keep-alive And responds successfully only to cross-origin requests from http://there.com . <markup lang=\"bash\" >curl -i -H \"Origin: http://there.com\" http://localhost:8080/health <markup lang=\"listing\" >HTTP/1.1 200 OK Access-Control-Allow-Origin: http://there.com Content-Type: application/json Date: Mon, 11 May 2020 12:07:32 -0500 Vary: Origin connection: keep-alive content-length: 461 {\"outcome\":\"UP\",...} ",
            "title": "Accessing the Shared Resources"
        },
        {
            "location": "mp/cors/cors",
            "text": " Several built-in Helidon services&#8212;&#8203; health , metrics , and OpenAPI --have integrated CORS support. You can include these services in your application and control how those resources can be shared across origins. For example, several websites related to OpenAPI run a web application in your browser. You provide the URL for your application to the browser application. The browser application uses the URL to retrieve the OpenAPI document that describes the application&#8217;s endpoints directly from your application. The browser application then displays a user interface that you use to \"drive\" your application. That is, you provide input, have the web application send requests to your application endpoints, and then view the responses. This scenario is exactly the situation CORS addresses: an application in the browser from one origin&#8201;&#8212;&#8201;the user interface downloaded from the website&#8201;&#8212;&#8201;requests a resource from another origin&#8201;&#8212;&#8201;the /openapi endpoint which Helidon&#8217;s OpenAPI built-in service automatically adds to your application. Integrating CORS support into these built-in services allows such third-party web sites and their browser applications&#8201;&#8212;&#8201;or more generally, apps from any other origin&#8201;&#8212;&#8201;to work with your Helidon application. Because all three of these built-in Helidon services serve only GET endpoints, by default the integrated CORS support in all three services permits any origin to share their resources using GET , HEAD , and OPTIONS HTTP requests. You can customize the CORS set-up for these built-in services independently from each other using configuration. You can use this override feature to control the CORS behavior of the built-in services even if you do not add CORS behavior to your own endpoints. Built-in Services with CORS To use built-in services with CORS support and customize the CORS behavior: Add the built-in service or services to your application. The health, metrics, and OpenAPI services automatically include default CORS support. Add a dependency on the Helidon MP CORS artifact to your Maven pom.xml file. If you want the built-in services to support CORS, then you need to add the CORS dependency even if your own endpoints do not use CORS. Use configuration to customize the CORS behavior as needed. The documentation for the individual built-in services describes how to add each service to your application, including adding a Maven dependency. In your application&#8217;s configuration file, the configuration for each service appears under its own key. Helidon Service Documentation Configuration Key health health metrics metrics OpenAPI openapi The Helidon MP QuickStart example uses these services, so you can use that as a template for your own application, or use the example project itself to experiment with customizing the CORS behavior in the built-in services. Configuring CORS for Built-in Services You can use configuration to control whether and how each of the built-in services works with CORS. In the configuration for the health, metrics, and OpenAPI services, you can add a section for CORS. You have full control over the CORS configuration for a built-in Helidon service. Use a CORS config section as described in the configuration table . The following example restricts sharing of the /health resource, provided by the health built-in service, to only the origin http://there.com , and the /metrics resource, provided by the metrics built-in service, to only the origin http://foo.com . <markup lang=\"properties\" title=\"Configuration which restricts sharing of the health and metrics resources\" >health.cors.allow-origins=http://there.com metrics.cors.allow-origins=http://foo.com Accessing the Shared Resources If you have edited the Helidon MP QuickStart application as described in the previous topics and saved your changes, you can build and run the application. Once you do so you can execute curl commands to demonstrate the behavior changes in the metric and health services with the addition of the CORS functionality. Note the addition of the Origin header value in the curl commands, and the Access-Control-Allow-Origin in the successful responses. Build and Run the Application Build and run the QuickStart application as usual. <markup lang=\"bash\" >mvn package java -jar target/helidon-quickstart-mp.jar ... 2020.05.12 05:44:08 INFO io.helidon.microprofile.server.ServerCdiExtension Thread[main,5,main]: Server started on http://localhost:8080 (and all other host addresses) in 5280 milliseconds (since JVM startup). ... Retrieve Metrics The metrics service rejects attempts to access metrics on behalf of a disallowed origin. <markup lang=\"bash\" >curl -i -H \"Origin: http://other.com\" http://localhost:8080/metrics <markup lang=\"listing\" >HTTP/1.1 403 Forbidden Date: Mon, 11 May 2020 11:08:09 -0500 transfer-encoding: chunked connection: keep-alive But accesses from foo.com succeed. <markup lang=\"bash\" >curl -i -H \"Origin: http://foo.com\" http://localhost:8080/metrics <markup lang=\"listing\" >HTTP/1.1 200 OK Access-Control-Allow-Origin: http://foo.com Content-Type: text/plain Date: Mon, 11 May 2020 11:08:16 -0500 Vary: Origin connection: keep-alive content-length: 6065 # TYPE base_classloader_loadedClasses_count gauge # HELP base_classloader_loadedClasses_count Displays the number of classes that are currently loaded in the Java virtual machine. base_classloader_loadedClasses_count 3568 Retrieve Health The health service rejects requests from origins not specifically approved. <markup lang=\"bash\" >curl -i -H \"Origin: http://foo.com\" http://localhost:8080/health <markup lang=\"listing\" >HTTP/1.1 403 Forbidden Date: Mon, 11 May 2020 12:06:55 -0500 transfer-encoding: chunked connection: keep-alive And responds successfully only to cross-origin requests from http://there.com . <markup lang=\"bash\" >curl -i -H \"Origin: http://there.com\" http://localhost:8080/health <markup lang=\"listing\" >HTTP/1.1 200 OK Access-Control-Allow-Origin: http://there.com Content-Type: application/json Date: Mon, 11 May 2020 12:07:32 -0500 Vary: Origin connection: keep-alive content-length: 461 {\"outcome\":\"UP\",...} ",
            "title": "Using CORS Support in Built-in Helidon Services"
        },
        {
            "location": "mp/cors/cors",
            "text": " Using CORS Support in Built-in Helidon Services Several built-in Helidon services&#8212;&#8203; health , metrics , and OpenAPI --have integrated CORS support. You can include these services in your application and control how those resources can be shared across origins. For example, several websites related to OpenAPI run a web application in your browser. You provide the URL for your application to the browser application. The browser application uses the URL to retrieve the OpenAPI document that describes the application&#8217;s endpoints directly from your application. The browser application then displays a user interface that you use to \"drive\" your application. That is, you provide input, have the web application send requests to your application endpoints, and then view the responses. This scenario is exactly the situation CORS addresses: an application in the browser from one origin&#8201;&#8212;&#8201;the user interface downloaded from the website&#8201;&#8212;&#8201;requests a resource from another origin&#8201;&#8212;&#8201;the /openapi endpoint which Helidon&#8217;s OpenAPI built-in service automatically adds to your application. Integrating CORS support into these built-in services allows such third-party web sites and their browser applications&#8201;&#8212;&#8201;or more generally, apps from any other origin&#8201;&#8212;&#8201;to work with your Helidon application. Because all three of these built-in Helidon services serve only GET endpoints, by default the integrated CORS support in all three services permits any origin to share their resources using GET , HEAD , and OPTIONS HTTP requests. You can customize the CORS set-up for these built-in services independently from each other using configuration. You can use this override feature to control the CORS behavior of the built-in services even if you do not add CORS behavior to your own endpoints. Built-in Services with CORS To use built-in services with CORS support and customize the CORS behavior: Add the built-in service or services to your application. The health, metrics, and OpenAPI services automatically include default CORS support. Add a dependency on the Helidon MP CORS artifact to your Maven pom.xml file. If you want the built-in services to support CORS, then you need to add the CORS dependency even if your own endpoints do not use CORS. Use configuration to customize the CORS behavior as needed. The documentation for the individual built-in services describes how to add each service to your application, including adding a Maven dependency. In your application&#8217;s configuration file, the configuration for each service appears under its own key. Helidon Service Documentation Configuration Key health health metrics metrics OpenAPI openapi The Helidon MP QuickStart example uses these services, so you can use that as a template for your own application, or use the example project itself to experiment with customizing the CORS behavior in the built-in services. Configuring CORS for Built-in Services You can use configuration to control whether and how each of the built-in services works with CORS. In the configuration for the health, metrics, and OpenAPI services, you can add a section for CORS. You have full control over the CORS configuration for a built-in Helidon service. Use a CORS config section as described in the configuration table . The following example restricts sharing of the /health resource, provided by the health built-in service, to only the origin http://there.com , and the /metrics resource, provided by the metrics built-in service, to only the origin http://foo.com . <markup lang=\"properties\" title=\"Configuration which restricts sharing of the health and metrics resources\" >health.cors.allow-origins=http://there.com metrics.cors.allow-origins=http://foo.com Accessing the Shared Resources If you have edited the Helidon MP QuickStart application as described in the previous topics and saved your changes, you can build and run the application. Once you do so you can execute curl commands to demonstrate the behavior changes in the metric and health services with the addition of the CORS functionality. Note the addition of the Origin header value in the curl commands, and the Access-Control-Allow-Origin in the successful responses. Build and Run the Application Build and run the QuickStart application as usual. <markup lang=\"bash\" >mvn package java -jar target/helidon-quickstart-mp.jar ... 2020.05.12 05:44:08 INFO io.helidon.microprofile.server.ServerCdiExtension Thread[main,5,main]: Server started on http://localhost:8080 (and all other host addresses) in 5280 milliseconds (since JVM startup). ... Retrieve Metrics The metrics service rejects attempts to access metrics on behalf of a disallowed origin. <markup lang=\"bash\" >curl -i -H \"Origin: http://other.com\" http://localhost:8080/metrics <markup lang=\"listing\" >HTTP/1.1 403 Forbidden Date: Mon, 11 May 2020 11:08:09 -0500 transfer-encoding: chunked connection: keep-alive But accesses from foo.com succeed. <markup lang=\"bash\" >curl -i -H \"Origin: http://foo.com\" http://localhost:8080/metrics <markup lang=\"listing\" >HTTP/1.1 200 OK Access-Control-Allow-Origin: http://foo.com Content-Type: text/plain Date: Mon, 11 May 2020 11:08:16 -0500 Vary: Origin connection: keep-alive content-length: 6065 # TYPE base_classloader_loadedClasses_count gauge # HELP base_classloader_loadedClasses_count Displays the number of classes that are currently loaded in the Java virtual machine. base_classloader_loadedClasses_count 3568 Retrieve Health The health service rejects requests from origins not specifically approved. <markup lang=\"bash\" >curl -i -H \"Origin: http://foo.com\" http://localhost:8080/health <markup lang=\"listing\" >HTTP/1.1 403 Forbidden Date: Mon, 11 May 2020 12:06:55 -0500 transfer-encoding: chunked connection: keep-alive And responds successfully only to cross-origin requests from http://there.com . <markup lang=\"bash\" >curl -i -H \"Origin: http://there.com\" http://localhost:8080/health <markup lang=\"listing\" >HTTP/1.1 200 OK Access-Control-Allow-Origin: http://there.com Content-Type: application/json Date: Mon, 11 May 2020 12:07:32 -0500 Vary: Origin connection: keep-alive content-length: 461 {\"outcome\":\"UP\",...} ",
            "title": "Additional Information"
        },
        {
            "location": "mp/cors/why-options",
            "text": " There are some good reasons why it is @OPTIONS methods that you decorate with the Helidon MP @CrossOrigin annotation. Take an informal look at the rationale for this choice. ",
            "title": "preambule"
        },
        {
            "location": "mp/cors/why-options",
            "text": " At the heart of cross-origin resource sharing is the resource itself. CORS lets you control how a given resource should be shared among various origins. All the attributes of CORS&#8201;&#8212;&#8201;whether authentication should be used, what headers can be passed through on CORS-controlled requests, and so on&#8201;&#8212;&#8201;pertain to a given resource. In Helidon MP, the parameters defined on the @CrossOrigin annotation map directly to those CORS sharing attributes. It would be natural, then, to use @CrossOrigin to annotate the single Java element in the application that represents a resource. ",
            "title": "The Resource"
        },
        {
            "location": "mp/cors/why-options",
            "text": " Unfortunately, there is no single Java element that is sure to correspond one-to-one with a JAX-RS resource, for two reasons. JAX-RS allows a resource class to define one or more subresources, denoted by the @Path annotation on methods. So a resource class does not necessarily represent only a single resource. A JAX-RS resource class can contain multiple endpoints for the same resource. A common example is two methods, annotated with @GET and @PUT respectively, that have the same path. Although no single endpoint method by itself fully represents the resource, at least each endpoint method maps to exactly one resource. So we could annotate any one of those endpoint methods with @CrossOrigin and unambiguously link the CORS behavior that the annotation defines to the resource. But which endpoint method, and why? ",
            "title": "Methods, Resources, and Subresources in JAX-RS Resource Classes"
        },
        {
            "location": "mp/cors/why-options",
            "text": " The OPTIONS HTTP method plays an important role in CORS. While the CORS protocol applies to all HTTP methods, it relies on OPTIONS &#8201;&#8212;&#8201;with suitable headers&#8201;&#8212;&#8201;to represent CORS pre-flight requests. From that point of view, the OPTIONS HTTP method has a more prominent place in CORS than the other methods. In a JAX-RS resource class, the @OPTIONS annotation denotes which endpoint method should receive incoming OPTIONS HTTP requests for a resource. Therefore, we could view a Java method annotated with @OPTIONS as somewhat distinguished in the same way that we think of the OPTIONS HTTP method as distinguished within the CORS protocol. Furthermore, there is this technical detail: Helidon MP uses a JAX-RS filter internally to gather information about each @CrossOrigin annotation. Some JAX-RS implementations do not provide the filter with what it needs to find and introspect the @CrossOrigin annotation unless the application itself implements the @OPTIONS endpoint for the resource. ",
            "title": " OPTIONS in CORS, @OPTIONS in JAX-RS, and Technical Reality"
        },
        {
            "location": "mp/cors/why-options",
            "text": " If you want a resource to participate in CORS, Helidon MP needs you to implement the @OPTIONS endpoint method for the resource, even if the method does nothing. Given that you have to write that method, and given that any endpoint method uniquely identifies its resource, the @OPTIONS method is a reasonable place to ask you to annotate with @CrossOrigin . ",
            "title": "The Bottom Line"
        },
        {
            "location": "mp/fault-tolerance",
            "text": " Overview Maven Coordinates API Configuration Examples Additional Information Reference ",
            "title": "Contents"
        },
        {
            "location": "mp/fault-tolerance",
            "text": " Fault Tolerance is part of the MicroProfile set of specifications. This API defines mostly annotations that improve application robustness by providing support to conveniently handle error conditions (faults) that may occur in real-world applications. Examples include service restarts, network delays, temporal infrastructure instabilities, etc. ",
            "title": "Overview"
        },
        {
            "location": "mp/fault-tolerance",
            "text": " To enable MicroProfile Fault Tolerance either add a dependency on the helidon-microprofile bundle or add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-fault-tolerance&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "mp/fault-tolerance",
            "text": " The MicroProfile Fault Tolerance specification defines a set of annotations to decorate classes and methods in your application for the purpose of improving its robustness. Many of these annotations can be applied at the class or method level: if applied at the class level, they will impact all methods in the class; if applied both at the class and method level, the latter will take precedence over the former. The following table provides a brief description of each of these annotations, including its parameters and default values. <div class=\"table__overflow elevation-1 flex sm10 \"> Annotation Description @Retry( maxRetries=3, delay=0, delayUnit=ChronoUnit.MILLIS, maxDuration=180000, durationUnit=ChronoUnit.MILLIS, jitter=200, jitterDelayUnit=ChronoUnit.MILLIS, retryOn={Exception.class}, abortOn={} ) Retries the execution of a method if a failure is encountered. Annotation attributes can be used to control the number of retries, delay between retries and which exceptions to retry or abort on. @Timeout( value=1000, unit=ChronoUnit.MILLIS ) Defines an upper bound on a method&#8217;s execution time. Default value is 1 second. @CircuitBreaker( failOn={Throwable.class}, skipOn={}, delay=5000, delayUnit=ChronoUnit.MILLIS, requestVolumeThreshold=20, failureRation=.50, successThreshold=1 ) Defines a policy to avoid repeated execution of logic that is likely to fail. A circuit breaker can be closed , open or half-open . In closed state a circuit breaker will execute logic normally. In open state a circuit breaker will prevent execution of logic that has been seen to fail. Finally, in half-open state a circuit breaker will allow trial executions in an attempt to switch its internal state to closed . The other annotation parameters are used to control how these state transitions are triggered. @Bulkhead( value=10, waitingTaskQueue=10 ) Defines a policy to limit the number of concurrent executions allowed over some application logic. A queue is used to park tasks awaiting execution after the limit has been reached. A queue is only active when invocations are @Asynchronous . @Fallback( value=DEFAULT.class, fallbackMethod=\"\", applyOn={Throwable.class}, skipOn={} ) Establishes a handler to be executed upon encountering an invocation failure. A handler is either a class that implements FallbackHandler&lt;T&gt; or just a simple method in the same class. Additional properties are used to control the conditions under which these handlers are called. @Asynchronous Executes an invocation asynchronously without blocking the calling thread. Annotated method must return Future or CompletionStage . Typically used to avoid blocking the calling thread on I/O or on a long-running computation. ",
            "title": "API"
        },
        {
            "location": "mp/fault-tolerance",
            "text": " Helidon&#8217;s implementation uses two types of thread pools: normal and scheduled. The default core size of these executors is 20; however, that can be configured using an application.yaml file as follows: <markup lang=\"yaml\" >executor: core-pool-size: 32 scheduled-executor: core-pool-size: 32 There is currently no support to configure these executor properties via a microprofile-config.properties file. For a complete set of properties available to configure these executors, see ServerThreadPoolSupplier and ScheduledThreadPoolSupplier . ",
            "title": "Configuration"
        },
        {
            "location": "mp/fault-tolerance",
            "text": " The method retryWithFallback shall be called at most 3 times, first call plus 2 retries, with a delay of 400 milliseconds between calls. If none of the calls is successful, the onFailure method shall be called as a fallback mechanism. <markup lang=\"java\" >@Retry(maxRetries = 2, delay = 400L) @Fallback(fallbackMethod = \"onFailure\") String retryWithFallback() { //... } The method timedCircuitBreaker defines a rolling window of size 10 and a policy to open the circuit breaker after 4 or more failures occur in that window, and to transition back to half-open state after 3 consecutive and successful runs. Additionally, it sets an overall timeout for the invocation of 1.5 seconds. <markup lang=\"java\" >@Timeout(1500) @CircuitBreaker(requestVolumeThreshold = 10, failureRatio = .4 successThreshold = 3) void timedCircuitBreaker() throws InterruptedException { //... } The method executeWithQueueAndFallback defines a bulkhead that will limit the number of concurrent calls to a maximum of 2; any additional tasks shall be queued up to a maximum of 10. Finally, if an error occurs the onFailure method shall be called as a fallback mechanism. The @Asynchronous annotation is needed to enable queueing of bulkhead tasks. <markup lang=\"java\" >@Asynchronous @Fallback(fallbackMethod = \"onFailure\") @Bulkhead(value = 2, waitingTaskQueue = 10) CompletableFuture&lt;String&gt; executeWithQueueAndFallback() { //... } ",
            "title": "Examples"
        },
        {
            "location": "mp/fault-tolerance",
            "text": " For additional information about this API, see the MicroProfile Fault Tolerance Javadocs . ",
            "title": "Additional Information"
        },
        {
            "location": "mp/fault-tolerance",
            "text": " MicroProfile Fault Tolerance ",
            "title": "Reference"
        },
        {
            "location": "mp/graphql",
            "text": " Overview Maven Coordinates API Configuration Examples Additional Information Reference ",
            "title": "Contents"
        },
        {
            "location": "mp/graphql",
            "text": " Helidon MP implements the MicroProfile GraphQL specification . This specifcation describes how applications can be built to expose an endpoint for GraphQL. GraphQL is an open-source data query and manipulation language for APIs, and a runtime for fulfilling data queries. It provides an alternative to, though not necessarily a replacement for, REST. ",
            "title": "Overview"
        },
        {
            "location": "mp/graphql",
            "text": " To enable MicroProfile GraphQL add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.graphql&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-graphql-server&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "mp/graphql",
            "text": " As part of building your application, you must create a Jandex index using the jandex-maven-plugin for all API and POJO classes. <markup lang=\"xml\" title=\"Generate Jandex index\" >&lt;plugin&gt; &lt;groupId&gt;org.jboss.jandex&lt;/groupId&gt; &lt;artifactId&gt;jandex-maven-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;make-index&lt;/id&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; As per the instructions here ensure you have added a src/main/resources/META-INF/beans.xml file, so the CDI implementation can pick up your classes. ",
            "title": "Building your application"
        },
        {
            "location": "mp/graphql",
            "text": " After starting your application you should see a log message indicating that GraphQL is in the list of features. You can access the GraphQL endpoint at http://host:port/graphql , and the corresponding schema at http://host:port/graphql/schema.graphql . See for additional information on how to change the location of these resources. If you wish to use the GraphQL UI then please see the GraphQL MP Example . ",
            "title": "Accessing the GraphQL endpoints"
        },
        {
            "location": "mp/graphql",
            "text": " The MicroProfile GraphQL specification defines a number of key annotations to be used when writing a GraphQL endpoint: @GraphQLApi - identifies a CDI Bean as a GraphQL endpoint @Query - identifies a method as returning one or more entities @Mutation - identifies a method which creates, deletes or updates entities For example, the following defines a GraphQL endpoint with a number of queries and mutations that work against a fictional CustomerService service and Customer class. <markup lang=\"java\" title=\"Simple ContactGraphQLApi\" >@ApplicationScoped @GraphQLApi public class ContactGraphQLApi { @Inject private CustomerService customerService; @Query public Collection&lt;Customer&gt; findAllCustomers() { return customerService.getAllCustomers(); } @Query public Customer findCustomer(@Name(\"customerId\") int id) { return customerService.getCustomer(id); } @Query public Collection&lt;Customer&gt; findCustomersByName(@Name(\"name\") String name) { return customerService.getAllCustomers(name); } @Mutation public Contact createCustomer(@Name(\"customerId\") int id, @Name(\"name\") String name, @Name(\"balance\") float balance) { return customerService.createCustomer(id, name, balance); } } public class customer { private int id; @NonNull private String name; private float balance; // getters and setters omitted for brevity } a query with no-arguments that will return all Customer s a query that takes an argument to return a specific Customer a query that optionally takes a name and returns a collection of Customer s a mutation that creates a Customer and returns the newly created Customer The example above would generate a GraphQL schema as shown below: <markup lang=\"graphql\" title=\"Sample GraphQL schema\" >type Query { findAllCustomers: [Customer] findCustomer(customerId: Int!): Customer findCustomersByName(name: String): [Customers] } type Mutation { createCustomer(customerId: Int!, name: String!, balance: Float!): Customer } type Customer { id: Int! name: String! balance: Float } After application startup, a GraphQL schema will be generated from your annotated API classes and POJO&#8217;s and you will be able to access these via the URLs described below. Building your application As part of building your application, you must create a Jandex index using the jandex-maven-plugin for all API and POJO classes. <markup lang=\"xml\" title=\"Generate Jandex index\" >&lt;plugin&gt; &lt;groupId&gt;org.jboss.jandex&lt;/groupId&gt; &lt;artifactId&gt;jandex-maven-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;make-index&lt;/id&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; As per the instructions here ensure you have added a src/main/resources/META-INF/beans.xml file, so the CDI implementation can pick up your classes. Accessing the GraphQL endpoints After starting your application you should see a log message indicating that GraphQL is in the list of features. You can access the GraphQL endpoint at http://host:port/graphql , and the corresponding schema at http://host:port/graphql/schema.graphql . See for additional information on how to change the location of these resources. If you wish to use the GraphQL UI then please see the GraphQL MP Example . ",
            "title": "API"
        },
        {
            "location": "mp/graphql",
            "text": " The specification defines the following configuration options: key default value description mp.graphql.defaultErrorMessage Server Error Error message to send to caller in case of error mp.graphql.exceptionsBlackList &#160; Array of checked exception classes that should return default error message mp.graphql.exceptionsWhiteList &#160; Array of unchecked exception classes that should return message to caller (instead of default error message) The following configuration keys can be used to set up integration with WebServer: key default value description graphql.web-context /graphql Context that serves the GraphQL endpoint. graphql.schema-uri /schema.graphql URI that serves the schema (under web context) graphql.cors &#160; CORS configuration for this service graphql.executor-service &#160; Configuration of ServerThreadPoolSupplier used to set up executor service The following configuration keys can be used to set up GraphQL invocation: key default value description graphql.default-error-message Server Error Error message to send to caller in case of error graphql.exception-white-list &#160; Array of checked exception classes that should return default error message graphql.exception-black-list &#160; Array of unchecked exception classes that should return message to caller (instead of default error message) ",
            "title": "Configuration"
        },
        {
            "location": "mp/graphql",
            "text": " For a complete example, see GraphQL MP Example . ",
            "title": "Examples"
        },
        {
            "location": "mp/graphql",
            "text": " GraphQL . ",
            "title": "Additional Information"
        },
        {
            "location": "mp/graphql",
            "text": " MicroProfile GraphQL Javadocs . ",
            "title": "Reference"
        },
        {
            "location": "mp/grpc/client",
            "text": " Overview Maven Coordinates API Configuration Usage Examples ",
            "title": "Contents"
        },
        {
            "location": "mp/grpc/client",
            "text": " Building Java-based gRPC clients using the Helidon MP gRPC APIs is very simple and removes a lot of the boilerplate code typically associated to more traditional approaches of writing gRPC Java clients. At its simplest, a gRPC Java client can be written using nothing more than a suitably annotated interface. ",
            "title": "Overview"
        },
        {
            "location": "mp/grpc/client",
            "text": " To enable gRPC MicroProfile Clients add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.grpc&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-grpc-client&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "mp/grpc/client",
            "text": " The following annotations are used to work with Helidon MP gRPC clients: @GrpcChannel - an annotation used to inject a gRPC channel. @InProcessGrpcChannel - an annotation used to tell the Helidon MP gRPC API to inject an in-process channel. @GrpcProxy - an annotation used to mark an injection point for a gRPC service client proxy. @Grpc - an annotation used to mark a class as representing a gRPC service. ",
            "title": "API"
        },
        {
            "location": "mp/grpc/client",
            "text": " Optional configuration options key type default value description host string localhost Set the host name to connect. port int 1408 Set the port that will be used to connect to the server. target string &#160; Set the target string, which can be either a valid io.grpc.NameResolver compliant URI, or an authority string. tls GrpcTlsDescriptor &#160; Set the GrpcTlsDescriptor. If tlsDescriptor is null or if the tlsDescriptor.isEnabled() is false, then no TLS will be used. Channels are configured in the grpc section of the Helidon application configuration. The examples below use an application.yaml file but there are many other ways to use and override configuration in Helidon <markup lang=\"yaml\" title=\"General form of a gRPC channels configuration\" >grpc: channels: test-server: host: localhost port: 1408 Channels are configured in the channels section. Each subsection is the channel name that is then used to refer to this channel in the application code. Each channel contains a host name. It also contains a port. While most client application only connect to a single server, it is possible to configure multiple named channels if the client needs to connect to multiple servers. <markup lang=\"yaml\" title=\"Multiple gRPC Channels configuration example\" >grpc: channels: london: host: london.foo.com port: 1408 new-york: host: ny.foo.com port: 1408 The above example shows two channel configurations, one named london and the other new-york . ",
            "title": "Configuration options"
        },
        {
            "location": "mp/grpc/client",
            "text": " Optional configuration options key type default value description enabled boolean true Enable or disable TLS. If enabled is false, then the rest of the TLS configuration properties are ignored. jdk-ssl boolean false Sets the type of SSL implementation to be used. tls-ca-cert Resource &#160; Set the CA (certificate authority) certificate path. tls-cert Resource &#160; Set the client tlsCert path. Required only if mutual auth is desired. tls-key Resource &#160; Set the client private key path. Required only if mutual auth is desired. <markup lang=\"yaml\" title=\"TLS on gRPC Channels configuration example\" >grpc: channels: test-server: host: localhost port: 1408 tls: enabled: true tls-cert-path: /certs/foo.cert tls-key-path: /certs/foo.key tls-ca-cert-path: /certs/ca.cert The tls section of the channel configuration is used to configure TLS. The enabled value is used to enable or disable TLS for this channel. The tls-cert value is the location of the TLS certificate file. The tls-key value is the location of the TLS key file. The tls-ca-cert value is the location of the TLS CA certificate file. The SSL configuration uses the Helidon Resource class to locate configured keys and certificates. In the example above the tls-cert-path config key has the -path suffix which tells the configuration to load /certs/foo.cert as a file. If /certs/foo.cert was a resource on the classpath, the configuration key could have been changed to tls-cert-resource-path to load /certs/foo.cert from the classpath. The same applies to the tls-key and tls-ca-cert configuration keys. See the io.helidon.common.configurable.Resource class for details. ",
            "title": "Configuration options"
        },
        {
            "location": "mp/grpc/client",
            "text": " Type: io.helidon.grpc.core.GrpcTlsDescriptor Configuration options Optional configuration options key type default value description enabled boolean true Enable or disable TLS. If enabled is false, then the rest of the TLS configuration properties are ignored. jdk-ssl boolean false Sets the type of SSL implementation to be used. tls-ca-cert Resource &#160; Set the CA (certificate authority) certificate path. tls-cert Resource &#160; Set the client tlsCert path. Required only if mutual auth is desired. tls-key Resource &#160; Set the client private key path. Required only if mutual auth is desired. <markup lang=\"yaml\" title=\"TLS on gRPC Channels configuration example\" >grpc: channels: test-server: host: localhost port: 1408 tls: enabled: true tls-cert-path: /certs/foo.cert tls-key-path: /certs/foo.key tls-ca-cert-path: /certs/ca.cert The tls section of the channel configuration is used to configure TLS. The enabled value is used to enable or disable TLS for this channel. The tls-cert value is the location of the TLS certificate file. The tls-key value is the location of the TLS key file. The tls-ca-cert value is the location of the TLS CA certificate file. The SSL configuration uses the Helidon Resource class to locate configured keys and certificates. In the example above the tls-cert-path config key has the -path suffix which tells the configuration to load /certs/foo.cert as a file. If /certs/foo.cert was a resource on the classpath, the configuration key could have been changed to tls-cert-resource-path to load /certs/foo.cert from the classpath. The same applies to the tls-key and tls-ca-cert configuration keys. See the io.helidon.common.configurable.Resource class for details. ",
            "title": "GrpcTlsDescriptor (grpc.core) Configuration"
        },
        {
            "location": "mp/grpc/client",
            "text": " It is also possible to configure a Channel to use TLS if the server is using TLS. GrpcTlsDescriptor (grpc.core) Configuration Type: io.helidon.grpc.core.GrpcTlsDescriptor Configuration options Optional configuration options key type default value description enabled boolean true Enable or disable TLS. If enabled is false, then the rest of the TLS configuration properties are ignored. jdk-ssl boolean false Sets the type of SSL implementation to be used. tls-ca-cert Resource &#160; Set the CA (certificate authority) certificate path. tls-cert Resource &#160; Set the client tlsCert path. Required only if mutual auth is desired. tls-key Resource &#160; Set the client private key path. Required only if mutual auth is desired. <markup lang=\"yaml\" title=\"TLS on gRPC Channels configuration example\" >grpc: channels: test-server: host: localhost port: 1408 tls: enabled: true tls-cert-path: /certs/foo.cert tls-key-path: /certs/foo.key tls-ca-cert-path: /certs/ca.cert The tls section of the channel configuration is used to configure TLS. The enabled value is used to enable or disable TLS for this channel. The tls-cert value is the location of the TLS certificate file. The tls-key value is the location of the TLS key file. The tls-ca-cert value is the location of the TLS CA certificate file. The SSL configuration uses the Helidon Resource class to locate configured keys and certificates. In the example above the tls-cert-path config key has the -path suffix which tells the configuration to load /certs/foo.cert as a file. If /certs/foo.cert was a resource on the classpath, the configuration key could have been changed to tls-cert-resource-path to load /certs/foo.cert from the classpath. The same applies to the tls-key and tls-ca-cert configuration keys. See the io.helidon.common.configurable.Resource class for details. ",
            "title": "Configuring TLS"
        },
        {
            "location": "mp/grpc/client",
            "text": " For a gRPC client to connect to a server, it requires a Channel. The Helidon MP gRPC APIs provide a way to inject channels into CDI beans that require them. Type: io.helidon.grpc.client.GrpcChannelDescriptor Configuration options Optional configuration options key type default value description host string localhost Set the host name to connect. port int 1408 Set the port that will be used to connect to the server. target string &#160; Set the target string, which can be either a valid io.grpc.NameResolver compliant URI, or an authority string. tls GrpcTlsDescriptor &#160; Set the GrpcTlsDescriptor. If tlsDescriptor is null or if the tlsDescriptor.isEnabled() is false, then no TLS will be used. Channels are configured in the grpc section of the Helidon application configuration. The examples below use an application.yaml file but there are many other ways to use and override configuration in Helidon <markup lang=\"yaml\" title=\"General form of a gRPC channels configuration\" >grpc: channels: test-server: host: localhost port: 1408 Channels are configured in the channels section. Each subsection is the channel name that is then used to refer to this channel in the application code. Each channel contains a host name. It also contains a port. While most client application only connect to a single server, it is possible to configure multiple named channels if the client needs to connect to multiple servers. <markup lang=\"yaml\" title=\"Multiple gRPC Channels configuration example\" >grpc: channels: london: host: london.foo.com port: 1408 new-york: host: ny.foo.com port: 1408 The above example shows two channel configurations, one named london and the other new-york . Configuring TLS It is also possible to configure a Channel to use TLS if the server is using TLS. GrpcTlsDescriptor (grpc.core) Configuration Type: io.helidon.grpc.core.GrpcTlsDescriptor Configuration options Optional configuration options key type default value description enabled boolean true Enable or disable TLS. If enabled is false, then the rest of the TLS configuration properties are ignored. jdk-ssl boolean false Sets the type of SSL implementation to be used. tls-ca-cert Resource &#160; Set the CA (certificate authority) certificate path. tls-cert Resource &#160; Set the client tlsCert path. Required only if mutual auth is desired. tls-key Resource &#160; Set the client private key path. Required only if mutual auth is desired. <markup lang=\"yaml\" title=\"TLS on gRPC Channels configuration example\" >grpc: channels: test-server: host: localhost port: 1408 tls: enabled: true tls-cert-path: /certs/foo.cert tls-key-path: /certs/foo.key tls-ca-cert-path: /certs/ca.cert The tls section of the channel configuration is used to configure TLS. The enabled value is used to enable or disable TLS for this channel. The tls-cert value is the location of the TLS certificate file. The tls-key value is the location of the TLS key file. The tls-ca-cert value is the location of the TLS CA certificate file. The SSL configuration uses the Helidon Resource class to locate configured keys and certificates. In the example above the tls-cert-path config key has the -path suffix which tells the configuration to load /certs/foo.cert as a file. If /certs/foo.cert was a resource on the classpath, the configuration key could have been changed to tls-cert-resource-path to load /certs/foo.cert from the classpath. The same applies to the tls-key and tls-ca-cert configuration keys. See the io.helidon.common.configurable.Resource class for details. ",
            "title": "Configuration"
        },
        {
            "location": "mp/grpc/client",
            "text": " If code is running in an application that is executing as part of the Helidon MP gRPC server, there is a special in-process channel available. This allows code executing on the server to make calls to gRPC services deployed on that server in the same way an external client does. To inject an in-process channel, a different qualifier annotation is used. <markup lang=\"java\" title=\"gRPC in-Process Channel Injection\" > @Inject @InProcessGrpcChannel private Channel channel; The @Inject annotation tells CDI to identify the injectable qualifiers. The @InProcessGrpcChannel is the qualifier that is used to tell the Helidon MP gRPC API to inject an in-process channel. ",
            "title": "The In-Process Channel"
        },
        {
            "location": "mp/grpc/client",
            "text": " Once one or more channels have been configured, then they can be used by the client code. The simplest way to use a channel is to inject it into beans using CDI. The Helidon gRPC client APIs have CDI producers that can provide io.grpc.Channel instances. For example, a class might have an injectable io.grpc.Channel field: <markup lang=\"java\" title=\"gRPC Channel Injection\" > @Inject @GrpcChannel(name = \"test-server\") private Channel channel; The @Inject annotation tells CDI to inject the channel. The @GrpcChannel annotation is the qualifier that supplies the Channel name. This is the same name as used in the channel configuration in the examples provided in the configuration section . When an instance of the CDI bean with the channel field is instantiated, a channel will be injected into it. The In-Process Channel If code is running in an application that is executing as part of the Helidon MP gRPC server, there is a special in-process channel available. This allows code executing on the server to make calls to gRPC services deployed on that server in the same way an external client does. To inject an in-process channel, a different qualifier annotation is used. <markup lang=\"java\" title=\"gRPC in-Process Channel Injection\" > @Inject @InProcessGrpcChannel private Channel channel; The @Inject annotation tells CDI to identify the injectable qualifiers. The @InProcessGrpcChannel is the qualifier that is used to tell the Helidon MP gRPC API to inject an in-process channel. ",
            "title": "Using Channels"
        },
        {
            "location": "mp/grpc/client",
            "text": " Now that there is a client interface and a Channel configuration, we can then use these in the client application. The simplest way is to use the client in a CDI microprofile application. We can declare a field of the same type as the client service interface in the application class that requires the client. The field is then annotated so that CDI will inject the client proxy into the field. <markup lang=\"java\" title=\"Simple gRPC Service\" >@ApplicationScoped public class Client { @Inject @GrpcProxy @GrpcChannel(name = \"test-server\") private StringService stringService; } The @Inject annotation tells the CDI to inject the client implementation. The @GrpcProxy annotation is used by the CDI container to match the injection point to the gRPC MP APIs provider. The @GrpcChannel annotation identifies the gRPC channel to be used by the client. The name used in the annotation refers to a channel name in the application configuration. When the CDI container instantiates instances of the Client , it will inject a dynamic proxy into the stringService field and then any code in methods in the Client class can call methods on the StringService which will be translated to gRPC calls. In the example above, there is no need to use a Channel directly. The correct channel is added to the dynamic client proxy internally by the Helidon MP gRPC APIs. ",
            "title": "Using the Client Interface in an Application"
        },
        {
            "location": "mp/grpc/client",
            "text": " The next step is to produce an interface with the service methods that the client requires. For example, suppose we have a simple server side service that has a unary method to convert a string to uppercase. <markup lang=\"java\" title=\"Simple gRPC Service\" >@ApplicationScoped @io.helidon.microprofile.grpc.core.Grpc public interface StringService { @io.helidon.microprofile.grpc.core.Unary public String upper(String s) { return s == null ? null : s.toUpperCase(); } } The service has been written using the Helidon MP APIs but could just as easily be a traditional gRPC Java service generated from Protobuf files. The client API is agnostic of the server side implementation, it only cares about the method types, the request and response types and the type of Marshaller used to serialize the request and response. To write a client for the StringService, all that is required is an interface. <markup lang=\"java\" title=\"Simple gRPC Service\" >@ApplicationScoped @io.helidon.microprofile.grpc.core.Grpc public interface StringService { @io.helidon.microprofile.grpc.core.Unary public String upper(String s); } There is no need to write any code to implement the client. The Helidon MP gRPC APIs will create a dynamic proxy for the interface using the information from the annotations and method signatures. The interface in the example above used the same method signature as the server but this does not have to be the case. It could have used any supported signature for a unary method. For example, it could just have easily been written using the standard unary method signature: <markup lang=\"java\" title=\"Simple gRPC Service\" >@ApplicationScoped @io.helidon.microprofile.grpc.core.Grpc public interface StringService { @io.helidon.microprofile.grpc.core.Unary public void upper(String s, StreamObserver&lt;String&gt; response); } We could also have made the client asynchronous by using one of the async method signatures: <markup lang=\"java\" title=\"Simple gRPC Service\" >@ApplicationScoped @io.helidon.microprofile.grpc.core.Grpc public interface StringService { @io.helidon.microprofile.grpc.core.Unary public CompletableFuture&lt;String&gt; upper(String s); } ",
            "title": "The Client Service Interface"
        },
        {
            "location": "mp/grpc/client",
            "text": " There are a few steps to building and using a gRPC client in Helidon MP. As discussed in the Defining Service methods section of the Server-Side Services , there are four different types of gRPC method. Unary - a simple method with at most a single request value and returning at most a single response value. Server Streaming - a method that takes at most a single request value but may return zero or more response values. Client Streaming - a request that takes one or more request values and returns at most one response value. Bi-directional Streaming - a method that can take one or more request values and return zero or more response values. And as with the server-side APIs, the Helidon MP gRPC client APIs support a number of different method signatures for each of the different gRPC method types. The Client Service Interface The next step is to produce an interface with the service methods that the client requires. For example, suppose we have a simple server side service that has a unary method to convert a string to uppercase. <markup lang=\"java\" title=\"Simple gRPC Service\" >@ApplicationScoped @io.helidon.microprofile.grpc.core.Grpc public interface StringService { @io.helidon.microprofile.grpc.core.Unary public String upper(String s) { return s == null ? null : s.toUpperCase(); } } The service has been written using the Helidon MP APIs but could just as easily be a traditional gRPC Java service generated from Protobuf files. The client API is agnostic of the server side implementation, it only cares about the method types, the request and response types and the type of Marshaller used to serialize the request and response. To write a client for the StringService, all that is required is an interface. <markup lang=\"java\" title=\"Simple gRPC Service\" >@ApplicationScoped @io.helidon.microprofile.grpc.core.Grpc public interface StringService { @io.helidon.microprofile.grpc.core.Unary public String upper(String s); } There is no need to write any code to implement the client. The Helidon MP gRPC APIs will create a dynamic proxy for the interface using the information from the annotations and method signatures. The interface in the example above used the same method signature as the server but this does not have to be the case. It could have used any supported signature for a unary method. For example, it could just have easily been written using the standard unary method signature: <markup lang=\"java\" title=\"Simple gRPC Service\" >@ApplicationScoped @io.helidon.microprofile.grpc.core.Grpc public interface StringService { @io.helidon.microprofile.grpc.core.Unary public void upper(String s, StreamObserver&lt;String&gt; response); } We could also have made the client asynchronous by using one of the async method signatures: <markup lang=\"java\" title=\"Simple gRPC Service\" >@ApplicationScoped @io.helidon.microprofile.grpc.core.Grpc public interface StringService { @io.helidon.microprofile.grpc.core.Unary public CompletableFuture&lt;String&gt; upper(String s); } ",
            "title": "Building a gRPC Client"
        },
        {
            "location": "mp/grpc/client",
            "text": " Using Channels Once one or more channels have been configured, then they can be used by the client code. The simplest way to use a channel is to inject it into beans using CDI. The Helidon gRPC client APIs have CDI producers that can provide io.grpc.Channel instances. For example, a class might have an injectable io.grpc.Channel field: <markup lang=\"java\" title=\"gRPC Channel Injection\" > @Inject @GrpcChannel(name = \"test-server\") private Channel channel; The @Inject annotation tells CDI to inject the channel. The @GrpcChannel annotation is the qualifier that supplies the Channel name. This is the same name as used in the channel configuration in the examples provided in the configuration section . When an instance of the CDI bean with the channel field is instantiated, a channel will be injected into it. The In-Process Channel If code is running in an application that is executing as part of the Helidon MP gRPC server, there is a special in-process channel available. This allows code executing on the server to make calls to gRPC services deployed on that server in the same way an external client does. To inject an in-process channel, a different qualifier annotation is used. <markup lang=\"java\" title=\"gRPC in-Process Channel Injection\" > @Inject @InProcessGrpcChannel private Channel channel; The @Inject annotation tells CDI to identify the injectable qualifiers. The @InProcessGrpcChannel is the qualifier that is used to tell the Helidon MP gRPC API to inject an in-process channel. Using the Client Interface in an Application Now that there is a client interface and a Channel configuration, we can then use these in the client application. The simplest way is to use the client in a CDI microprofile application. We can declare a field of the same type as the client service interface in the application class that requires the client. The field is then annotated so that CDI will inject the client proxy into the field. <markup lang=\"java\" title=\"Simple gRPC Service\" >@ApplicationScoped public class Client { @Inject @GrpcProxy @GrpcChannel(name = \"test-server\") private StringService stringService; } The @Inject annotation tells the CDI to inject the client implementation. The @GrpcProxy annotation is used by the CDI container to match the injection point to the gRPC MP APIs provider. The @GrpcChannel annotation identifies the gRPC channel to be used by the client. The name used in the annotation refers to a channel name in the application configuration. When the CDI container instantiates instances of the Client , it will inject a dynamic proxy into the stringService field and then any code in methods in the Client class can call methods on the StringService which will be translated to gRPC calls. In the example above, there is no need to use a Channel directly. The correct channel is added to the dynamic client proxy internally by the Helidon MP gRPC APIs. Building a gRPC Client There are a few steps to building and using a gRPC client in Helidon MP. As discussed in the Defining Service methods section of the Server-Side Services , there are four different types of gRPC method. Unary - a simple method with at most a single request value and returning at most a single response value. Server Streaming - a method that takes at most a single request value but may return zero or more response values. Client Streaming - a request that takes one or more request values and returns at most one response value. Bi-directional Streaming - a method that can take one or more request values and return zero or more response values. And as with the server-side APIs, the Helidon MP gRPC client APIs support a number of different method signatures for each of the different gRPC method types. The Client Service Interface The next step is to produce an interface with the service methods that the client requires. For example, suppose we have a simple server side service that has a unary method to convert a string to uppercase. <markup lang=\"java\" title=\"Simple gRPC Service\" >@ApplicationScoped @io.helidon.microprofile.grpc.core.Grpc public interface StringService { @io.helidon.microprofile.grpc.core.Unary public String upper(String s) { return s == null ? null : s.toUpperCase(); } } The service has been written using the Helidon MP APIs but could just as easily be a traditional gRPC Java service generated from Protobuf files. The client API is agnostic of the server side implementation, it only cares about the method types, the request and response types and the type of Marshaller used to serialize the request and response. To write a client for the StringService, all that is required is an interface. <markup lang=\"java\" title=\"Simple gRPC Service\" >@ApplicationScoped @io.helidon.microprofile.grpc.core.Grpc public interface StringService { @io.helidon.microprofile.grpc.core.Unary public String upper(String s); } There is no need to write any code to implement the client. The Helidon MP gRPC APIs will create a dynamic proxy for the interface using the information from the annotations and method signatures. The interface in the example above used the same method signature as the server but this does not have to be the case. It could have used any supported signature for a unary method. For example, it could just have easily been written using the standard unary method signature: <markup lang=\"java\" title=\"Simple gRPC Service\" >@ApplicationScoped @io.helidon.microprofile.grpc.core.Grpc public interface StringService { @io.helidon.microprofile.grpc.core.Unary public void upper(String s, StreamObserver&lt;String&gt; response); } We could also have made the client asynchronous by using one of the async method signatures: <markup lang=\"java\" title=\"Simple gRPC Service\" >@ApplicationScoped @io.helidon.microprofile.grpc.core.Grpc public interface StringService { @io.helidon.microprofile.grpc.core.Unary public CompletableFuture&lt;String&gt; upper(String s); } ",
            "title": "Usage"
        },
        {
            "location": "mp/grpc/client",
            "text": " Basic gRPC Client example demonstrates a simple gRPC client that invokes services from deployed gRPC server applications provided in the Basic gRPC Server and gRPC Server metrics examples. ",
            "title": "Examples"
        },
        {
            "location": "mp/grpc/server",
            "text": " Overview Maven Coordinates API Usage Configuration Examples ",
            "title": "Contents"
        },
        {
            "location": "mp/grpc/server",
            "text": " The gRPC Microprofile APIs are an extension to Helidon MP to allow building of gRPC services and clients that integrate with the Microprofile APIs. Using Helidon gRPC MP makes building gRPC services and clients an easier process compared to the traditional approach using Protobuf files and code generation. Services can be built using POJOs that are then discovered and deployed at runtime in the same way the Helidon MP discovers and deploys web resources in the MP HTTP server. Building gRPC services using Helidon gRPC MP is very simple and allows the developer to concentrate on their application logic without needing to write a lot of boilerplate gRPC code. ",
            "title": "Overview"
        },
        {
            "location": "mp/grpc/server",
            "text": " To enable gRPC MicroProfile Server add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.grpc&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-grpc-server&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "mp/grpc/server",
            "text": " The following annotations are used to implement Helidon MP gRPC Services: @Grpc - an annotation used to mark a class as representing a gRPC service. @GrpcMarshaller - an annotation used to annotate a type or method to specify the named marshaller supplier to use for rpc method calls. gRPC method types: @Unary - a simple method with at most a single request value and returning at most a single response value. @ServerStreaming - a method that takes at most a single request value but may return zero or more response values. @ClientStreaming - a request that takes one or more request values and returns at most one response value. @Bidirectional - a method that can take one or more request values and return zero or more response values. ",
            "title": "API"
        },
        {
            "location": "mp/grpc/server",
            "text": " The traditional approach to building Java gRPC services is to write Protobuf files describing the service, use these files to generate service stubs, and then implement the service methods by extending the generated stub classes. Using Helidon gRPC MP, all you need to do is write an annotated service implementation class that is just a normal POJO. For example: <markup lang=\"java\" title=\"Simple gRPC Service\" >@ApplicationScoped @io.helidon.microprofile.grpc.core.Grpc public class StringService { @io.helidon.microprofile.grpc.core.Unary public String upper(String s) { return s == null ? null : s.toUpperCase(); } } The code above is a simple service with a single unary method that just converts a String to uppercase. The important parts in the example are the @ApplicationScoped , @Grpc and @Unary annotations. These, along with other annotations discussed later, allow the gRPC MP APIs to discover, configure and deploy the service. Of course Helidon gRPC MP does not preclude you from using the Protobuf files approach as traditional gRPC Java services also work in a gRPC MP server. As already shown above, a Helidon gRPC MP service is just an annotated POJO. To make a class a service, it requires two annotations. <markup lang=\"java\" >@ApplicationScoped @io.helidon.microprofile.grpc.core.Grpc public class StringService { /* code is omitted */ } The ApplicationScoped annotation is what makes the service implementation a CDI bean and hence discoverable. The Grpc annotation is what defines the class as a gRPC service so that when the bean is discovered, it is then deployed by the gRPC MP server. ",
            "title": "Defining a Service"
        },
        {
            "location": "mp/grpc/server",
            "text": " By default when a class is annotated with Grpc , the class name will be used as the gRPC service name. So in the example above, the service name will be StringService . This can be changed by supplying a name to the annotation. <markup lang=\"java\" >@ApplicationScoped @io.helidon.microprofile.grpc.core.Grpc(name=\"Strings\") public class StringService { The name of the deployed service will be Strings . ",
            "title": "Service Name"
        },
        {
            "location": "mp/grpc/server",
            "text": " A gRPC service method typically takes a request parameter and returns a response value ( streaming methods may take or return multiple requests or responses). In traditional gRPC Java, the types used for the request and response values must be Protobuf serializable classes but this is not the case with Helidon gRPC. Helidon supports pluggable Marshallers and by default will support Protobuf types. Any type that can be marshalled by the built-in marshallers or custom supplied marshaller may be used as a request or response type. ",
            "title": "Request and Response Types"
        },
        {
            "location": "mp/grpc/server",
            "text": " A unary gRPC method is the simplest type of service method. Typically a unary method takes a request value and returns a response value, but this is not always the case. A unary method could just as easily take no request parameter and/or return no response. All of the signatures below are valid unary methods in Helidon gRPC MP. <markup lang=\"java\" >// A unary method with a simple request and response @io.helidon.microprofile.grpc.core.Unary public ResponseType invoke(RequestType req) // A unary method that just returns a response @io.helidon.microprofile.grpc.core.Unary public ResponseType invoke() // A unary method that takes a request but returns no response @io.helidon.microprofile.grpc.core.Unary public void invoke(RequestType req) // A unary method that takes no request and returns no response @io.helidon.microprofile.grpc.core.Unary public void invoke() // An async unary request that takes a request and returns a future // that will complete when the response is ready @io.helidon.microprofile.grpc.core.Unary public CompletableFuture&lt;ResponseType&gt; invoke(RequestType req) // An async unary request that takes no request and returns a future // that will complete when the response is ready @io.helidon.microprofile.grpc.core.Unary public CompletableFuture&lt;ResponseType&gt; invoke() // The standard gRPC Java unary method signature @io.helidon.microprofile.grpc.core.Unary public void invoke(RequestType req, StreamObserver&lt;ResponseType&gt; observer) // The standard gRPC Java unary method signature but without a request type @io.helidon.microprofile.grpc.core.Unary public void invoke(StreamObserver&lt;ResponseType&gt; observer) // A unary method that takes a request type and a future to complete // with the response type @io.helidon.microprofile.grpc.core.Unary public void invoke(RequestType req, CompletableFuture&lt;ResponseType&gt; observer) // A unary method that takes no request type but just takes a future // to complete with the response type @io.helidon.microprofile.grpc.core.Unary public void invoke(CompletableFuture&lt;ResponseType&gt; observer) The various signatures supported above allow the service developer to choose the method signature that best fits their application business logic without needing to worry about handling standard gRPC Java requests and StreamObservers. The standard gRPC Java method signature is in the list above so it can still be used if required. ",
            "title": "Unary Methods"
        },
        {
            "location": "mp/grpc/server",
            "text": " A server streaming method receives a requests from the client and when the request stream is complete, it sends back a stream of response values. A traditional gRPC Java server streaming method takes two parameters, the request and a StreamObserver that is used to send back the single response in the same way that a unary method sends a response. As with unary methods, Helidon gRPC MP supports different method signatures for server streaming methods. All of the signatures below are valid server streaming methods in Helidon gRPC MP. <markup lang=\"java\" >// The standard gRPC Java server streaming method signature @io.helidon.microprofile.grpc.core.ServerStreaming public void invoke(RequestType req, StreamObserver&lt;ResponseType&gt; observer) // A server streaming method that uses a Stream to send the responses to the client @io.helidon.microprofile.grpc.core.ServerStreaming public Stream&lt;ResponseType&gt; invoke(RequestType req) // The server streaming method without a request parameter @io.helidon.microprofile.grpc.core.ServerStreaming public void invoke(StreamObserver&lt;ResponseType&gt; observer) // A server streaming method without a request parameter // that uses a Stream to send the responses to the client @io.helidon.microprofile.grpc.core.ServerStreaming public Stream&lt;ResponseType&gt; invoke(RequestType req) As with unary methods, the Helidon gRPC MP API supports multiple different method signatures for implementing server streaming methods. ",
            "title": "ServerStreaming Methods"
        },
        {
            "location": "mp/grpc/server",
            "text": " A client streaming method receives a stream of requests from the client and when the request stream is complete, it sends back a response. A traditional gRPC Java client streaming method takes two StreamObserver parameters, one is the stream of client requests and the other is used to send back the single response in the same way that a unary method sends a response. As with unary methods, Helidon gRPC MP supports different method signatures for client streaming methods. All of the signatures below are valid client streaming methods in Helidon gRPC MP. <markup lang=\"java\" >// The standard gRPC Java client streaming method signature @io.helidon.microprofile.grpc.core.ClientStreaming public StreamObserver&lt;RequestType&gt; invoke(StreamObserver&lt;ResponseType&gt; observer) // The gRPC Java client streaming method with an asynchronous response @io.helidon.microprofile.grpc.core.ClientStreaming public StreamObserver&lt;RequestType&gt; invoke(CompletableFuture&lt;ResponseType&gt; observer) ",
            "title": "ClientStreaming Methods"
        },
        {
            "location": "mp/grpc/server",
            "text": " A bidirectional streaming method is a method that is a constant stream of client requests and server responses. Other than the standard gRPC Java StreamObserver , there are no other built-in types that make sense to use to implement different method signatures for a bidirectional method so the only supported signature is the standard gRPC Java method. <markup lang=\"java\" >@io.helidon.microprofile.grpc.core.Bidirectional public StreamObserver&lt;RequestType&gt; invoke(StreamObserver&lt;ResponseType&gt; observer) ",
            "title": "Bi-Directional Streaming Methods"
        },
        {
            "location": "mp/grpc/server",
            "text": " Once a class is properly annotated to make it a gRPC MP service, it needs to have service methods that implement the application business logic. In gRPC there are four different types of method: Unary - a simple method with at most a single request value and returning at most a single response value. Server Streaming - a method that takes at most a single request value but may return zero or more response values. Client Streaming - a request that takes one or more request values and returns at most one response value. Bi-directional Streaming - a method that can take one or more request values and return zero or more response values. The Helidon gRPC MP API determines a method type by its annotation, which should be one of the following: <markup lang=\"java\" >@io.helidon.microprofile.grpc.core.Unary @io.helidon.microprofile.grpc.core.ServerStreaming @io.helidon.microprofile.grpc.core.ClientStreaming @io.helidon.microprofile.grpc.core.Bidirectional Request and Response Types A gRPC service method typically takes a request parameter and returns a response value ( streaming methods may take or return multiple requests or responses). In traditional gRPC Java, the types used for the request and response values must be Protobuf serializable classes but this is not the case with Helidon gRPC. Helidon supports pluggable Marshallers and by default will support Protobuf types. Any type that can be marshalled by the built-in marshallers or custom supplied marshaller may be used as a request or response type. Unary Methods A unary gRPC method is the simplest type of service method. Typically a unary method takes a request value and returns a response value, but this is not always the case. A unary method could just as easily take no request parameter and/or return no response. All of the signatures below are valid unary methods in Helidon gRPC MP. <markup lang=\"java\" >// A unary method with a simple request and response @io.helidon.microprofile.grpc.core.Unary public ResponseType invoke(RequestType req) // A unary method that just returns a response @io.helidon.microprofile.grpc.core.Unary public ResponseType invoke() // A unary method that takes a request but returns no response @io.helidon.microprofile.grpc.core.Unary public void invoke(RequestType req) // A unary method that takes no request and returns no response @io.helidon.microprofile.grpc.core.Unary public void invoke() // An async unary request that takes a request and returns a future // that will complete when the response is ready @io.helidon.microprofile.grpc.core.Unary public CompletableFuture&lt;ResponseType&gt; invoke(RequestType req) // An async unary request that takes no request and returns a future // that will complete when the response is ready @io.helidon.microprofile.grpc.core.Unary public CompletableFuture&lt;ResponseType&gt; invoke() // The standard gRPC Java unary method signature @io.helidon.microprofile.grpc.core.Unary public void invoke(RequestType req, StreamObserver&lt;ResponseType&gt; observer) // The standard gRPC Java unary method signature but without a request type @io.helidon.microprofile.grpc.core.Unary public void invoke(StreamObserver&lt;ResponseType&gt; observer) // A unary method that takes a request type and a future to complete // with the response type @io.helidon.microprofile.grpc.core.Unary public void invoke(RequestType req, CompletableFuture&lt;ResponseType&gt; observer) // A unary method that takes no request type but just takes a future // to complete with the response type @io.helidon.microprofile.grpc.core.Unary public void invoke(CompletableFuture&lt;ResponseType&gt; observer) The various signatures supported above allow the service developer to choose the method signature that best fits their application business logic without needing to worry about handling standard gRPC Java requests and StreamObservers. The standard gRPC Java method signature is in the list above so it can still be used if required. ServerStreaming Methods A server streaming method receives a requests from the client and when the request stream is complete, it sends back a stream of response values. A traditional gRPC Java server streaming method takes two parameters, the request and a StreamObserver that is used to send back the single response in the same way that a unary method sends a response. As with unary methods, Helidon gRPC MP supports different method signatures for server streaming methods. All of the signatures below are valid server streaming methods in Helidon gRPC MP. <markup lang=\"java\" >// The standard gRPC Java server streaming method signature @io.helidon.microprofile.grpc.core.ServerStreaming public void invoke(RequestType req, StreamObserver&lt;ResponseType&gt; observer) // A server streaming method that uses a Stream to send the responses to the client @io.helidon.microprofile.grpc.core.ServerStreaming public Stream&lt;ResponseType&gt; invoke(RequestType req) // The server streaming method without a request parameter @io.helidon.microprofile.grpc.core.ServerStreaming public void invoke(StreamObserver&lt;ResponseType&gt; observer) // A server streaming method without a request parameter // that uses a Stream to send the responses to the client @io.helidon.microprofile.grpc.core.ServerStreaming public Stream&lt;ResponseType&gt; invoke(RequestType req) As with unary methods, the Helidon gRPC MP API supports multiple different method signatures for implementing server streaming methods. ClientStreaming Methods A client streaming method receives a stream of requests from the client and when the request stream is complete, it sends back a response. A traditional gRPC Java client streaming method takes two StreamObserver parameters, one is the stream of client requests and the other is used to send back the single response in the same way that a unary method sends a response. As with unary methods, Helidon gRPC MP supports different method signatures for client streaming methods. All of the signatures below are valid client streaming methods in Helidon gRPC MP. <markup lang=\"java\" >// The standard gRPC Java client streaming method signature @io.helidon.microprofile.grpc.core.ClientStreaming public StreamObserver&lt;RequestType&gt; invoke(StreamObserver&lt;ResponseType&gt; observer) // The gRPC Java client streaming method with an asynchronous response @io.helidon.microprofile.grpc.core.ClientStreaming public StreamObserver&lt;RequestType&gt; invoke(CompletableFuture&lt;ResponseType&gt; observer) Bi-Directional Streaming Methods A bidirectional streaming method is a method that is a constant stream of client requests and server responses. Other than the standard gRPC Java StreamObserver , there are no other built-in types that make sense to use to implement different method signatures for a bidirectional method so the only supported signature is the standard gRPC Java method. <markup lang=\"java\" >@io.helidon.microprofile.grpc.core.Bidirectional public StreamObserver&lt;RequestType&gt; invoke(StreamObserver&lt;ResponseType&gt; observer) ",
            "title": "Defining Service Methods"
        },
        {
            "location": "mp/grpc/server",
            "text": " When the gRPC MP server is starting, it will discover all CDI beans of type io.grpc.BindableService . Service sub-classes implemented the traditional way with code generation are instances of BindableService so by annotating the implementation class with the @ApplicationScoped annotation, they become discoverable and will be deployed into the gRPC server. <markup lang=\"java\" >@ApplicationScoped public class StringService extends StringServiceGrpc.StringServiceImplBase { In exactly the same way, if a class is an implementation of io.helidon.grpc.server.GrpcService , then it will be discovered and deployed when the MP gRPC server starts by simply annotating the class with the @ApplicationScoped annotation. <markup lang=\"java\" >@ApplicationScoped public class StringService implements GrpcService { ",
            "title": "Annotate the Service Implementation"
        },
        {
            "location": "mp/grpc/server",
            "text": " If it is not possible to annotate the service class (for example the code is built by a third party), another way to deploy non-CDI bean services is to implement a gRPC MP server extension. The extension will then be called when the MP server is starting and be given the chance to add additional services for deployment. An extension should implement the io.helidon.microprofile.grpc.server.spi.GrpcMpExtension interface. For example, assuming that there was a gRPC service class called StringService that needed to be deployed, an extension class might look like this: <markup lang=\"java\" >public class MyExtension implements GrpcMpExtension { @Override public void configure(GrpcMpContext context) { context.routing() .register(new ServiceService()); } } The configure method of the extension will be called to allow the extension to add extra configuration to the server. In this example, an instance of the StringService is registered with the routing (as described in the gRPC server routing documentation). The GrpcMpExtension instances are discovered and loaded using the service loader so for the example above to work, a file META-INF/services/io.helidon.microprofile.grpc.server.spi.GrpcMpExtension would need to be created that contained the names of the service implementations. ",
            "title": "Implement a GrpcMpExtension"
        },
        {
            "location": "mp/grpc/server",
            "text": " The examples above show how simple it is to write gRPC services with basic POJOs. There may be cases, however, where there is a requirement to deploy services built the traditional way using gRPC Java generated classes or built as non-microprofile Helidon gRPC services . Annotate the Service Implementation When the gRPC MP server is starting, it will discover all CDI beans of type io.grpc.BindableService . Service sub-classes implemented the traditional way with code generation are instances of BindableService so by annotating the implementation class with the @ApplicationScoped annotation, they become discoverable and will be deployed into the gRPC server. <markup lang=\"java\" >@ApplicationScoped public class StringService extends StringServiceGrpc.StringServiceImplBase { In exactly the same way, if a class is an implementation of io.helidon.grpc.server.GrpcService , then it will be discovered and deployed when the MP gRPC server starts by simply annotating the class with the @ApplicationScoped annotation. <markup lang=\"java\" >@ApplicationScoped public class StringService implements GrpcService { Implement a GrpcMpExtension If it is not possible to annotate the service class (for example the code is built by a third party), another way to deploy non-CDI bean services is to implement a gRPC MP server extension. The extension will then be called when the MP server is starting and be given the chance to add additional services for deployment. An extension should implement the io.helidon.microprofile.grpc.server.spi.GrpcMpExtension interface. For example, assuming that there was a gRPC service class called StringService that needed to be deployed, an extension class might look like this: <markup lang=\"java\" >public class MyExtension implements GrpcMpExtension { @Override public void configure(GrpcMpContext context) { context.routing() .register(new ServiceService()); } } The configure method of the extension will be called to allow the extension to add extra configuration to the server. In this example, an instance of the StringService is registered with the routing (as described in the gRPC server routing documentation). The GrpcMpExtension instances are discovered and loaded using the service loader so for the example above to work, a file META-INF/services/io.helidon.microprofile.grpc.server.spi.GrpcMpExtension would need to be created that contained the names of the service implementations. ",
            "title": "Deploying Protobuf Services"
        },
        {
            "location": "mp/grpc/server",
            "text": " Helidon gRPC supports Protobuf out of the box. The Protobuf marshaller will be used by default for any request and response classes that extend com.google.protobuf.MessageLite , which is the case for all classes generated from a proto file using protoc compiler. That means that you don&#8217;t need any special handling or configuration in order to support Protobuf serialization of requests and responses. ",
            "title": "Default Marshalling Support"
        },
        {
            "location": "mp/grpc/server",
            "text": " You can annotate your service&#8217;s class or interface with @GrpcMarshaller: <markup lang=\"java\" title=\"Sample code with @GrpcMarshaller annotation\" >@Grpc @ApplicationScoped @GrpcMarshaller(\"jsonb\") public class AsyncStringService { // code is omitted } Set the named marshaller supplier via the @GrpcMarshaller annotation. ",
            "title": "Setting the custom marshaller"
        },
        {
            "location": "mp/grpc/server",
            "text": " Helidon makes the use of custom marshallers trivial and provides one custom implementation, JsonbMarshaller , out of the box. You can also easily implement your own marshaller to support serialization formats that are not supported natively by Helidon, by implementing Marshaller and MarshallerSupplier interfaces. As an example, check out the source code of the built-in marshaller: JsonbMarshaller.java . Furthermore, Oracle Coherence CE provides a marshaller for a highly optimized, binary, platform independent Portable Object Format (POF). You can find more information about POF in Coherence documentation Setting the custom marshaller You can annotate your service&#8217;s class or interface with @GrpcMarshaller: <markup lang=\"java\" title=\"Sample code with @GrpcMarshaller annotation\" >@Grpc @ApplicationScoped @GrpcMarshaller(\"jsonb\") public class AsyncStringService { // code is omitted } Set the named marshaller supplier via the @GrpcMarshaller annotation. ",
            "title": "Custom Marshalling"
        },
        {
            "location": "mp/grpc/server",
            "text": " Default Marshalling Support Helidon gRPC supports Protobuf out of the box. The Protobuf marshaller will be used by default for any request and response classes that extend com.google.protobuf.MessageLite , which is the case for all classes generated from a proto file using protoc compiler. That means that you don&#8217;t need any special handling or configuration in order to support Protobuf serialization of requests and responses. Custom Marshalling Helidon makes the use of custom marshallers trivial and provides one custom implementation, JsonbMarshaller , out of the box. You can also easily implement your own marshaller to support serialization formats that are not supported natively by Helidon, by implementing Marshaller and MarshallerSupplier interfaces. As an example, check out the source code of the built-in marshaller: JsonbMarshaller.java . Furthermore, Oracle Coherence CE provides a marshaller for a highly optimized, binary, platform independent Portable Object Format (POF). You can find more information about POF in Coherence documentation Setting the custom marshaller You can annotate your service&#8217;s class or interface with @GrpcMarshaller: <markup lang=\"java\" title=\"Sample code with @GrpcMarshaller annotation\" >@Grpc @ApplicationScoped @GrpcMarshaller(\"jsonb\") public class AsyncStringService { // code is omitted } Set the named marshaller supplier via the @GrpcMarshaller annotation. ",
            "title": "Marshalling"
        },
        {
            "location": "mp/grpc/server",
            "text": " Defining a Service The traditional approach to building Java gRPC services is to write Protobuf files describing the service, use these files to generate service stubs, and then implement the service methods by extending the generated stub classes. Using Helidon gRPC MP, all you need to do is write an annotated service implementation class that is just a normal POJO. For example: <markup lang=\"java\" title=\"Simple gRPC Service\" >@ApplicationScoped @io.helidon.microprofile.grpc.core.Grpc public class StringService { @io.helidon.microprofile.grpc.core.Unary public String upper(String s) { return s == null ? null : s.toUpperCase(); } } The code above is a simple service with a single unary method that just converts a String to uppercase. The important parts in the example are the @ApplicationScoped , @Grpc and @Unary annotations. These, along with other annotations discussed later, allow the gRPC MP APIs to discover, configure and deploy the service. Of course Helidon gRPC MP does not preclude you from using the Protobuf files approach as traditional gRPC Java services also work in a gRPC MP server. As already shown above, a Helidon gRPC MP service is just an annotated POJO. To make a class a service, it requires two annotations. <markup lang=\"java\" >@ApplicationScoped @io.helidon.microprofile.grpc.core.Grpc public class StringService { /* code is omitted */ } The ApplicationScoped annotation is what makes the service implementation a CDI bean and hence discoverable. The Grpc annotation is what defines the class as a gRPC service so that when the bean is discovered, it is then deployed by the gRPC MP server. Service Name By default when a class is annotated with Grpc , the class name will be used as the gRPC service name. So in the example above, the service name will be StringService . This can be changed by supplying a name to the annotation. <markup lang=\"java\" >@ApplicationScoped @io.helidon.microprofile.grpc.core.Grpc(name=\"Strings\") public class StringService { The name of the deployed service will be Strings . Defining Service Methods Once a class is properly annotated to make it a gRPC MP service, it needs to have service methods that implement the application business logic. In gRPC there are four different types of method: Unary - a simple method with at most a single request value and returning at most a single response value. Server Streaming - a method that takes at most a single request value but may return zero or more response values. Client Streaming - a request that takes one or more request values and returns at most one response value. Bi-directional Streaming - a method that can take one or more request values and return zero or more response values. The Helidon gRPC MP API determines a method type by its annotation, which should be one of the following: <markup lang=\"java\" >@io.helidon.microprofile.grpc.core.Unary @io.helidon.microprofile.grpc.core.ServerStreaming @io.helidon.microprofile.grpc.core.ClientStreaming @io.helidon.microprofile.grpc.core.Bidirectional Request and Response Types A gRPC service method typically takes a request parameter and returns a response value ( streaming methods may take or return multiple requests or responses). In traditional gRPC Java, the types used for the request and response values must be Protobuf serializable classes but this is not the case with Helidon gRPC. Helidon supports pluggable Marshallers and by default will support Protobuf types. Any type that can be marshalled by the built-in marshallers or custom supplied marshaller may be used as a request or response type. Unary Methods A unary gRPC method is the simplest type of service method. Typically a unary method takes a request value and returns a response value, but this is not always the case. A unary method could just as easily take no request parameter and/or return no response. All of the signatures below are valid unary methods in Helidon gRPC MP. <markup lang=\"java\" >// A unary method with a simple request and response @io.helidon.microprofile.grpc.core.Unary public ResponseType invoke(RequestType req) // A unary method that just returns a response @io.helidon.microprofile.grpc.core.Unary public ResponseType invoke() // A unary method that takes a request but returns no response @io.helidon.microprofile.grpc.core.Unary public void invoke(RequestType req) // A unary method that takes no request and returns no response @io.helidon.microprofile.grpc.core.Unary public void invoke() // An async unary request that takes a request and returns a future // that will complete when the response is ready @io.helidon.microprofile.grpc.core.Unary public CompletableFuture&lt;ResponseType&gt; invoke(RequestType req) // An async unary request that takes no request and returns a future // that will complete when the response is ready @io.helidon.microprofile.grpc.core.Unary public CompletableFuture&lt;ResponseType&gt; invoke() // The standard gRPC Java unary method signature @io.helidon.microprofile.grpc.core.Unary public void invoke(RequestType req, StreamObserver&lt;ResponseType&gt; observer) // The standard gRPC Java unary method signature but without a request type @io.helidon.microprofile.grpc.core.Unary public void invoke(StreamObserver&lt;ResponseType&gt; observer) // A unary method that takes a request type and a future to complete // with the response type @io.helidon.microprofile.grpc.core.Unary public void invoke(RequestType req, CompletableFuture&lt;ResponseType&gt; observer) // A unary method that takes no request type but just takes a future // to complete with the response type @io.helidon.microprofile.grpc.core.Unary public void invoke(CompletableFuture&lt;ResponseType&gt; observer) The various signatures supported above allow the service developer to choose the method signature that best fits their application business logic without needing to worry about handling standard gRPC Java requests and StreamObservers. The standard gRPC Java method signature is in the list above so it can still be used if required. ServerStreaming Methods A server streaming method receives a requests from the client and when the request stream is complete, it sends back a stream of response values. A traditional gRPC Java server streaming method takes two parameters, the request and a StreamObserver that is used to send back the single response in the same way that a unary method sends a response. As with unary methods, Helidon gRPC MP supports different method signatures for server streaming methods. All of the signatures below are valid server streaming methods in Helidon gRPC MP. <markup lang=\"java\" >// The standard gRPC Java server streaming method signature @io.helidon.microprofile.grpc.core.ServerStreaming public void invoke(RequestType req, StreamObserver&lt;ResponseType&gt; observer) // A server streaming method that uses a Stream to send the responses to the client @io.helidon.microprofile.grpc.core.ServerStreaming public Stream&lt;ResponseType&gt; invoke(RequestType req) // The server streaming method without a request parameter @io.helidon.microprofile.grpc.core.ServerStreaming public void invoke(StreamObserver&lt;ResponseType&gt; observer) // A server streaming method without a request parameter // that uses a Stream to send the responses to the client @io.helidon.microprofile.grpc.core.ServerStreaming public Stream&lt;ResponseType&gt; invoke(RequestType req) As with unary methods, the Helidon gRPC MP API supports multiple different method signatures for implementing server streaming methods. ClientStreaming Methods A client streaming method receives a stream of requests from the client and when the request stream is complete, it sends back a response. A traditional gRPC Java client streaming method takes two StreamObserver parameters, one is the stream of client requests and the other is used to send back the single response in the same way that a unary method sends a response. As with unary methods, Helidon gRPC MP supports different method signatures for client streaming methods. All of the signatures below are valid client streaming methods in Helidon gRPC MP. <markup lang=\"java\" >// The standard gRPC Java client streaming method signature @io.helidon.microprofile.grpc.core.ClientStreaming public StreamObserver&lt;RequestType&gt; invoke(StreamObserver&lt;ResponseType&gt; observer) // The gRPC Java client streaming method with an asynchronous response @io.helidon.microprofile.grpc.core.ClientStreaming public StreamObserver&lt;RequestType&gt; invoke(CompletableFuture&lt;ResponseType&gt; observer) Bi-Directional Streaming Methods A bidirectional streaming method is a method that is a constant stream of client requests and server responses. Other than the standard gRPC Java StreamObserver , there are no other built-in types that make sense to use to implement different method signatures for a bidirectional method so the only supported signature is the standard gRPC Java method. <markup lang=\"java\" >@io.helidon.microprofile.grpc.core.Bidirectional public StreamObserver&lt;RequestType&gt; invoke(StreamObserver&lt;ResponseType&gt; observer) Deploying Protobuf Services The examples above show how simple it is to write gRPC services with basic POJOs. There may be cases, however, where there is a requirement to deploy services built the traditional way using gRPC Java generated classes or built as non-microprofile Helidon gRPC services . Annotate the Service Implementation When the gRPC MP server is starting, it will discover all CDI beans of type io.grpc.BindableService . Service sub-classes implemented the traditional way with code generation are instances of BindableService so by annotating the implementation class with the @ApplicationScoped annotation, they become discoverable and will be deployed into the gRPC server. <markup lang=\"java\" >@ApplicationScoped public class StringService extends StringServiceGrpc.StringServiceImplBase { In exactly the same way, if a class is an implementation of io.helidon.grpc.server.GrpcService , then it will be discovered and deployed when the MP gRPC server starts by simply annotating the class with the @ApplicationScoped annotation. <markup lang=\"java\" >@ApplicationScoped public class StringService implements GrpcService { Implement a GrpcMpExtension If it is not possible to annotate the service class (for example the code is built by a third party), another way to deploy non-CDI bean services is to implement a gRPC MP server extension. The extension will then be called when the MP server is starting and be given the chance to add additional services for deployment. An extension should implement the io.helidon.microprofile.grpc.server.spi.GrpcMpExtension interface. For example, assuming that there was a gRPC service class called StringService that needed to be deployed, an extension class might look like this: <markup lang=\"java\" >public class MyExtension implements GrpcMpExtension { @Override public void configure(GrpcMpContext context) { context.routing() .register(new ServiceService()); } } The configure method of the extension will be called to allow the extension to add extra configuration to the server. In this example, an instance of the StringService is registered with the routing (as described in the gRPC server routing documentation). The GrpcMpExtension instances are discovered and loaded using the service loader so for the example above to work, a file META-INF/services/io.helidon.microprofile.grpc.server.spi.GrpcMpExtension would need to be created that contained the names of the service implementations. Marshalling Default Marshalling Support Helidon gRPC supports Protobuf out of the box. The Protobuf marshaller will be used by default for any request and response classes that extend com.google.protobuf.MessageLite , which is the case for all classes generated from a proto file using protoc compiler. That means that you don&#8217;t need any special handling or configuration in order to support Protobuf serialization of requests and responses. Custom Marshalling Helidon makes the use of custom marshallers trivial and provides one custom implementation, JsonbMarshaller , out of the box. You can also easily implement your own marshaller to support serialization formats that are not supported natively by Helidon, by implementing Marshaller and MarshallerSupplier interfaces. As an example, check out the source code of the built-in marshaller: JsonbMarshaller.java . Furthermore, Oracle Coherence CE provides a marshaller for a highly optimized, binary, platform independent Portable Object Format (POF). You can find more information about POF in Coherence documentation Setting the custom marshaller You can annotate your service&#8217;s class or interface with @GrpcMarshaller: <markup lang=\"java\" title=\"Sample code with @GrpcMarshaller annotation\" >@Grpc @ApplicationScoped @GrpcMarshaller(\"jsonb\") public class AsyncStringService { // code is omitted } Set the named marshaller supplier via the @GrpcMarshaller annotation. ",
            "title": "Usage"
        },
        {
            "location": "mp/grpc/server",
            "text": " Optional configuration options key type default value description name string grpc.server Set the name of the gRPC server. Configuration key: `name` native boolean false Specify if native transport should be used. port int 1408 Sets server port. If port is 0 or less then any available ephemeral port will be used. Configuration key: `port` workers int Number of processors available to the JVM Sets a count of threads in pool used to process HTTP requests. Default value is CPU_COUNT * 2 . Configuration key: `workers` <markup lang=\"yaml\" title=\"GrpcServer configuration file example using application.yaml \" >grpc: name: test.server port: 3333 Specifies the name of the gRPC server. Sets the server port. ",
            "title": "Configuration options"
        },
        {
            "location": "mp/grpc/server",
            "text": " Configure the gRPC server using the Helidon microprofile configuration framework by which the ConfigSource defaults to microprofile-config.properties . Alternatively, you can also use other ConfigSources such as application.yaml . Refer to MicroProfile Config for more details about the different options for ConfigSources. Type: io.helidon.grpc.server.GrpcServerConfiguration Configuration options Optional configuration options key type default value description name string grpc.server Set the name of the gRPC server. Configuration key: `name` native boolean false Specify if native transport should be used. port int 1408 Sets server port. If port is 0 or less then any available ephemeral port will be used. Configuration key: `port` workers int Number of processors available to the JVM Sets a count of threads in pool used to process HTTP requests. Default value is CPU_COUNT * 2 . Configuration key: `workers` <markup lang=\"yaml\" title=\"GrpcServer configuration file example using application.yaml \" >grpc: name: test.server port: 3333 Specifies the name of the gRPC server. Sets the server port. ",
            "title": "Configuration"
        },
        {
            "location": "mp/grpc/server",
            "text": " Helidon MP includes some examples that demonstrate the gRPC server usage: Basic gRPC Server example provides a simple gRPC application that deploys a gRPC service that will be discovered by CDI. Two additional services are included that are not normally CDI managed beans, but are manually added as CDI managed beans so that they can also be discovered by Helidon MP. gRPC Server Metrics example demonstrates a Helidon MP application that enables metrics and tracing on a gRPC Service. ",
            "title": "Examples"
        },
        {
            "location": "mp/guides/config",
            "text": " This guide describes how to create a sample MicroProfile (MP) project that can be used to run some basic examples using both default and custom configuration with Helidon MP. ",
            "title": "preambule"
        },
        {
            "location": "mp/guides/config",
            "text": " For this 20 minute tutorial, you will need the following: <div class=\"table__overflow elevation-1 flex sm7 \"> A Helidon MP Application You can use your own application or use the Helidon MP Quickstart to create a sample application. Java&#160;SE&#160;17 ( Open&#160;JDK&#160;17 ) Helidon requires Java 17+. Maven 3.6.1+ Helidon requires Maven 3.6.1+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop . <markup lang=\"bash\" title=\"Verify Prerequisites\" >java -version mvn --version docker --version kubectl version --short <markup lang=\"bash\" title=\"Setting JAVA_HOME\" ># On Mac export JAVA_HOME=`/usr/libexec/java_home -v 17` # On Linux # Use the appropriate path to your JDK export JAVA_HOME=/usr/lib/jvm/jdk-17 ",
            "title": "What You Need"
        },
        {
            "location": "mp/guides/config",
            "text": " Use the Helidon MP Maven archetype to create a simple project that can be used for the examples in this guide. <markup lang=\"bash\" title=\"Run the Maven archetype:\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-mp \\ -DarchetypeVersion=3.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-mp \\ -Dpackage=io.helidon.examples.quickstart.mp <markup lang=\"bash\" title=\"The project will be built and run from the helidon-quickstart-mp directory:\" >cd helidon-quickstart-mp ",
            "title": "Create a Sample Helidon MP Project"
        },
        {
            "location": "mp/guides/config",
            "text": " Helidon has an internal configuration, so you are not required to provide any configuration data for your application, though in practice you most likely would. By default, that configuration can be overridden from three sources: system properties, environment variables, and the contents of META-INF/microprofile-config.properties . For example, if you specify a custom server port in META-INF/microprofile-config.properties then your server will listen on that port. A main class is also required to start up the server and run the application. By default, the Quickstart sample project uses the built-in Helidon main class. In this guide you want to use your own main class, so you have more control over the server initialization. First define your own Main : <markup lang=\"java\" title=\"src/main/java/io/helidon/examples/quickstart/mp/Main.java\" >package io.helidon.examples.quickstart.mp; import io.helidon.microprofile.server.Server; import java.io.IOException; public final class Main { private Main() { } public static void main(final String[] args) { Server server = startServer(); System.out.println(\"http://localhost:\" + server.port() + \"/greet\"); } static Server startServer() { return Server.create().start(); } } In this class, a main method is defined which starts the Helidon MP server and prints out a message with the listen address. Notice that this class has an empty no-args constructor to make sure this class cannot be instantiated. The MicroProfile server is started with the default configuration. Next change the project&#8217;s pom.xml to use your main class: <markup lang=\"xml\" title=\"pom.xml\" > &lt;properties&gt; &lt;mainClass&gt;io.helidon.examples.quickstart.mp.Main&lt;/mainClass&gt; &lt;/properties&gt; This property will be used to set the Main-Class attribute in the application jar&#8217;s MANIFEST. In your application code, Helidon uses the default configuration when you create a Server object without a custom Config object. See the following code from the project you created. <markup lang=\"Java\" title=\"View Main.startServer :\" > static Server startServer() { return Server.create().start(); } There is no Config object being used during server creation, so the default configuration is used. ",
            "title": "Default Configuration"
        },
        {
            "location": "mp/guides/config",
            "text": " An environment variable has a higher precedence than the configuration properties file. <markup lang=\"bash\" title=\"Set the environment variable and restart the application:\" >export APP_GREETING=HelloFromEnvironment java -jar target/helidon-quickstart-mp.jar <markup lang=\"bash\" title=\"Invoke the endpoint below and check the response:\" >curl http://localhost:8080/greet <markup lang=\"json\" >{ \"message\": \"HelloFromEnvironment World!\" } The environment variable took precedence over the value in META-INF/microprofile-config.properties . ",
            "title": "Environment Variable Override"
        },
        {
            "location": "mp/guides/config",
            "text": " A system property has a higher precedence than environment variables. <markup lang=\"bash\" title=\"Restart the application with a system property. The app.greeting environment variable is still set:\" >java -Dapp.greeting=\"HelloFromSystemProperty\" -jar target/helidon-quickstart-mp.jar <markup lang=\"bash\" title=\"Invoke the endpoint below and check the response:\" >curl http://localhost:8080/greet <markup lang=\"json\" >{ \"message\": \"HelloFromSystemProperty World!\" } The system property took precedence over both the environment variable and META-INF/microprofile-config.properties . ",
            "title": "System Property Override"
        },
        {
            "location": "mp/guides/config",
            "text": " Change a configuration parameter in the default configuration resource file, META-INF/microprofile-config.properties . There are no environment variable or system property overrides defined. <markup lang=\"bash\" title=\"Change app.greeting in the META-INF/microprofile-config.properties from Hello to HelloFromMPConfig :\" >app.greeting=HelloFromMPConfig <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-mp.jar <markup lang=\"bash\" title=\"Run the curl command in a new terminal window and check the response:\" >curl http://localhost:8080/greet <markup lang=\"json\" >{ \"message\": \"HelloFromMPConfig World!\" } The new app.greeting value in META-INF/microprofile-config.properties is used. Environment Variable Override An environment variable has a higher precedence than the configuration properties file. <markup lang=\"bash\" title=\"Set the environment variable and restart the application:\" >export APP_GREETING=HelloFromEnvironment java -jar target/helidon-quickstart-mp.jar <markup lang=\"bash\" title=\"Invoke the endpoint below and check the response:\" >curl http://localhost:8080/greet <markup lang=\"json\" >{ \"message\": \"HelloFromEnvironment World!\" } The environment variable took precedence over the value in META-INF/microprofile-config.properties . System Property Override A system property has a higher precedence than environment variables. <markup lang=\"bash\" title=\"Restart the application with a system property. The app.greeting environment variable is still set:\" >java -Dapp.greeting=\"HelloFromSystemProperty\" -jar target/helidon-quickstart-mp.jar <markup lang=\"bash\" title=\"Invoke the endpoint below and check the response:\" >curl http://localhost:8080/greet <markup lang=\"json\" >{ \"message\": \"HelloFromSystemProperty World!\" } The system property took precedence over both the environment variable and META-INF/microprofile-config.properties . ",
            "title": "Default Configuration Resource"
        },
        {
            "location": "mp/guides/config",
            "text": " In order to properly configure your application using configuration sources, you need to understand the precedence rules that Helidon uses to merge your configuration data. By default, Helidon will use the following sources in precedence order: Java system properties Environment variables Properties specified in META-INF/microprofile-config.properties Each of these sources specify configuration properties in Java Property format (key/value), like color=red . If any of the Helidon required properties are not specified in one of these source, like server.port , then Helidon will use a default value. Because environment variable names are restricted to alphanumeric characters and underscores, Helidon adds aliases to the environment configuration source, allowing entries with dotted and/or hyphenated keys to be overridden. For example, this mapping allows an environment variable named \"APP_GREETING\" to override an entry key named \"app.greeting\". In the same way, an environment variable named \"APP_dash_GREETING\" will map to \"app-greeting\". See Microprofile Config Specifications for more information. The following examples will demonstrate the default precedence order. Default Configuration Resource Change a configuration parameter in the default configuration resource file, META-INF/microprofile-config.properties . There are no environment variable or system property overrides defined. <markup lang=\"bash\" title=\"Change app.greeting in the META-INF/microprofile-config.properties from Hello to HelloFromMPConfig :\" >app.greeting=HelloFromMPConfig <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-mp.jar <markup lang=\"bash\" title=\"Run the curl command in a new terminal window and check the response:\" >curl http://localhost:8080/greet <markup lang=\"json\" >{ \"message\": \"HelloFromMPConfig World!\" } The new app.greeting value in META-INF/microprofile-config.properties is used. Environment Variable Override An environment variable has a higher precedence than the configuration properties file. <markup lang=\"bash\" title=\"Set the environment variable and restart the application:\" >export APP_GREETING=HelloFromEnvironment java -jar target/helidon-quickstart-mp.jar <markup lang=\"bash\" title=\"Invoke the endpoint below and check the response:\" >curl http://localhost:8080/greet <markup lang=\"json\" >{ \"message\": \"HelloFromEnvironment World!\" } The environment variable took precedence over the value in META-INF/microprofile-config.properties . System Property Override A system property has a higher precedence than environment variables. <markup lang=\"bash\" title=\"Restart the application with a system property. The app.greeting environment variable is still set:\" >java -Dapp.greeting=\"HelloFromSystemProperty\" -jar target/helidon-quickstart-mp.jar <markup lang=\"bash\" title=\"Invoke the endpoint below and check the response:\" >curl http://localhost:8080/greet <markup lang=\"json\" >{ \"message\": \"HelloFromSystemProperty World!\" } The system property took precedence over both the environment variable and META-INF/microprofile-config.properties . ",
            "title": "Source Precedence for Default Configuration"
        },
        {
            "location": "mp/guides/config",
            "text": " Helidon provides a very flexible and comprehensive configuration system, offering you many application configuration choices. You can include configuration data from a variety of sources using different formats, like JSON and YAML. Furthermore, you can customize the precedence of sources and make them optional or mandatory. This guide introduces Helidon MP configuration and demonstrates the fundamental concepts using several examples. Refer to Helidon Config for the full configuration concepts documentation. Create a Sample Helidon MP Project Use the Helidon MP Maven archetype to create a simple project that can be used for the examples in this guide. <markup lang=\"bash\" title=\"Run the Maven archetype:\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-mp \\ -DarchetypeVersion=3.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-mp \\ -Dpackage=io.helidon.examples.quickstart.mp <markup lang=\"bash\" title=\"The project will be built and run from the helidon-quickstart-mp directory:\" >cd helidon-quickstart-mp Default Configuration Helidon has an internal configuration, so you are not required to provide any configuration data for your application, though in practice you most likely would. By default, that configuration can be overridden from three sources: system properties, environment variables, and the contents of META-INF/microprofile-config.properties . For example, if you specify a custom server port in META-INF/microprofile-config.properties then your server will listen on that port. A main class is also required to start up the server and run the application. By default, the Quickstart sample project uses the built-in Helidon main class. In this guide you want to use your own main class, so you have more control over the server initialization. First define your own Main : <markup lang=\"java\" title=\"src/main/java/io/helidon/examples/quickstart/mp/Main.java\" >package io.helidon.examples.quickstart.mp; import io.helidon.microprofile.server.Server; import java.io.IOException; public final class Main { private Main() { } public static void main(final String[] args) { Server server = startServer(); System.out.println(\"http://localhost:\" + server.port() + \"/greet\"); } static Server startServer() { return Server.create().start(); } } In this class, a main method is defined which starts the Helidon MP server and prints out a message with the listen address. Notice that this class has an empty no-args constructor to make sure this class cannot be instantiated. The MicroProfile server is started with the default configuration. Next change the project&#8217;s pom.xml to use your main class: <markup lang=\"xml\" title=\"pom.xml\" > &lt;properties&gt; &lt;mainClass&gt;io.helidon.examples.quickstart.mp.Main&lt;/mainClass&gt; &lt;/properties&gt; This property will be used to set the Main-Class attribute in the application jar&#8217;s MANIFEST. In your application code, Helidon uses the default configuration when you create a Server object without a custom Config object. See the following code from the project you created. <markup lang=\"Java\" title=\"View Main.startServer :\" > static Server startServer() { return Server.create().start(); } There is no Config object being used during server creation, so the default configuration is used. Source Precedence for Default Configuration In order to properly configure your application using configuration sources, you need to understand the precedence rules that Helidon uses to merge your configuration data. By default, Helidon will use the following sources in precedence order: Java system properties Environment variables Properties specified in META-INF/microprofile-config.properties Each of these sources specify configuration properties in Java Property format (key/value), like color=red . If any of the Helidon required properties are not specified in one of these source, like server.port , then Helidon will use a default value. Because environment variable names are restricted to alphanumeric characters and underscores, Helidon adds aliases to the environment configuration source, allowing entries with dotted and/or hyphenated keys to be overridden. For example, this mapping allows an environment variable named \"APP_GREETING\" to override an entry key named \"app.greeting\". In the same way, an environment variable named \"APP_dash_GREETING\" will map to \"app-greeting\". See Microprofile Config Specifications for more information. The following examples will demonstrate the default precedence order. Default Configuration Resource Change a configuration parameter in the default configuration resource file, META-INF/microprofile-config.properties . There are no environment variable or system property overrides defined. <markup lang=\"bash\" title=\"Change app.greeting in the META-INF/microprofile-config.properties from Hello to HelloFromMPConfig :\" >app.greeting=HelloFromMPConfig <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-mp.jar <markup lang=\"bash\" title=\"Run the curl command in a new terminal window and check the response:\" >curl http://localhost:8080/greet <markup lang=\"json\" >{ \"message\": \"HelloFromMPConfig World!\" } The new app.greeting value in META-INF/microprofile-config.properties is used. Environment Variable Override An environment variable has a higher precedence than the configuration properties file. <markup lang=\"bash\" title=\"Set the environment variable and restart the application:\" >export APP_GREETING=HelloFromEnvironment java -jar target/helidon-quickstart-mp.jar <markup lang=\"bash\" title=\"Invoke the endpoint below and check the response:\" >curl http://localhost:8080/greet <markup lang=\"json\" >{ \"message\": \"HelloFromEnvironment World!\" } The environment variable took precedence over the value in META-INF/microprofile-config.properties . System Property Override A system property has a higher precedence than environment variables. <markup lang=\"bash\" title=\"Restart the application with a system property. The app.greeting environment variable is still set:\" >java -Dapp.greeting=\"HelloFromSystemProperty\" -jar target/helidon-quickstart-mp.jar <markup lang=\"bash\" title=\"Invoke the endpoint below and check the response:\" >curl http://localhost:8080/greet <markup lang=\"json\" >{ \"message\": \"HelloFromSystemProperty World!\" } The system property took precedence over both the environment variable and META-INF/microprofile-config.properties . ",
            "title": "Getting Started with Configuration"
        },
        {
            "location": "mp/guides/config",
            "text": " You can inject configuration at the field level as shown below. Use the volatile keyword since you cannot use AtomicReference with field level injection. <markup lang=\"yaml\" title=\"Update the meta-config.yaml with the following contents:\" >sources: - type: \"classpath\" properties: resource: \"META-INF/microprofile-config.properties\" This example only uses the default classpath source. <markup lang=\"java\" title=\"Update the following code from GreetingProvider.java :\" >@ApplicationScoped public class GreetingProvider { @Inject @ConfigProperty(name = \"app.greeting\") private volatile String message; String getMessage() { return message; } void setMessage(String message) { this.message = message; } } Inject the value of app.greeting into the GreetingProvider object. Define a class member variable to hold the greeting. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet <markup lang=\"json\" >{ \"message\": \"HelloFromMPConfig World!\" } ",
            "title": "Injecting at Field Level"
        },
        {
            "location": "mp/guides/config",
            "text": " You can inject the Config object into the class and access it directly as shown below. <markup lang=\"java\" title=\"Update the GreetingProvider.java file; 1) Add new imports and 2) Replace the GreetingProvider class:\" > import io.helidon.config.Config; import jakarta.enterprise.context.Initialized; import jakarta.enterprise.event.Observes; @ApplicationScoped public class GreetingProvider { private final AtomicReference&lt;String&gt; message = new AtomicReference&lt;&gt;(); @Inject public GreetingProvider(Config config) { String message = config.get(\"app.greeting\").asString().get(); this.message.set(message); } String getMessage() { return message.get(); } void setMessage(String message) { this.message.set(message); } } Add three new imports. Inject the Config object into the GreetingProvider object. Get the app.greeting value from the Config object and set the member variable. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet <markup lang=\"json\" >{ \"message\": \"HelloFromMPConfig World!\" } ",
            "title": "Injecting the Config Object"
        },
        {
            "location": "mp/guides/config",
            "text": " Helidon offers a variety of methods to access in-memory configuration. These can be categorized as key access or tree navigation . You have been using key access for all the examples to this point. For example app.greeting is accessing the greeting child node of the app parent node. This simple example below demonstrates how to access a child node as a detached configuration subtree. <markup lang=\"yaml\" title=\"Create a file config-file.yaml in the helidon-quickstart-mp directory and add the following contents:\" >app: greeting: sender: Joe message: Hello-from-config-file.yaml <markup lang=\"yaml\" title=\"Update the meta-config.yaml with the following contents:\" >sources: - type: \"classpath\" properties: resource: \"META-INF/microprofile-config.properties\" - type: \"file\" properties: path: \"./config-file.yaml\" <markup lang=\"java\" title=\"Replace GreetingProvider class with the following code:\" >@ApplicationScoped public class GreetingProvider { private final AtomicReference&lt;String&gt; message = new AtomicReference&lt;&gt;(); private final AtomicReference&lt;String&gt; sender = new AtomicReference&lt;&gt;(); @Inject Config config; public void onStartUp(@Observes @Initialized(ApplicationScoped.class) Object init) { Config appNode = config.get(\"app.greeting\"); message.set(appNode.get(\"message\").asString().get()); sender.set(appNode.get(\"sender\").asString().get()); } String getMessage() { return sender.get() + \" says \" + message.get(); } void setMessage(String message) { this.message.set(message); } } Get the configuration subtree where the app.greeting node is the root. Get the value from the message Config node. Get the value from the sender Config node. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet <markup lang=\"json\" >{ \"message\": \"Joe says Hello-from-config-file.yaml World!\" } ",
            "title": "Navigating the Config Tree"
        },
        {
            "location": "mp/guides/config",
            "text": " The examples in this section will demonstrate how to access that config data at runtime. Your application uses the Config object to access the in-memory tree, retrieving config data. The generated project already accesses configuration data in the GreetingProvider class as follows: <markup lang=\"java\" title=\"View the following code from GreetingProvider.java :\" >@ApplicationScoped public class GreetingProvider { private final AtomicReference&lt;String&gt; message = new AtomicReference&lt;&gt;(); @Inject public GreetingProvider(@ConfigProperty(name = \"app.greeting\") String message) { this.message.set(message); } String getMessage() { return message.get(); } void setMessage(String message) { this.message.set(message); } } This class is application scoped so a single instance of GreetingProvider will be shared across the entire application. Define a thread-safe reference that will refer to the message member variable. The value of the configuration property app.greeting is injected into the GreetingProvider . constructor as a String parameter named message . Injecting at Field Level You can inject configuration at the field level as shown below. Use the volatile keyword since you cannot use AtomicReference with field level injection. <markup lang=\"yaml\" title=\"Update the meta-config.yaml with the following contents:\" >sources: - type: \"classpath\" properties: resource: \"META-INF/microprofile-config.properties\" This example only uses the default classpath source. <markup lang=\"java\" title=\"Update the following code from GreetingProvider.java :\" >@ApplicationScoped public class GreetingProvider { @Inject @ConfigProperty(name = \"app.greeting\") private volatile String message; String getMessage() { return message; } void setMessage(String message) { this.message = message; } } Inject the value of app.greeting into the GreetingProvider object. Define a class member variable to hold the greeting. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet <markup lang=\"json\" >{ \"message\": \"HelloFromMPConfig World!\" } Injecting the Config Object You can inject the Config object into the class and access it directly as shown below. <markup lang=\"java\" title=\"Update the GreetingProvider.java file; 1) Add new imports and 2) Replace the GreetingProvider class:\" > import io.helidon.config.Config; import jakarta.enterprise.context.Initialized; import jakarta.enterprise.event.Observes; @ApplicationScoped public class GreetingProvider { private final AtomicReference&lt;String&gt; message = new AtomicReference&lt;&gt;(); @Inject public GreetingProvider(Config config) { String message = config.get(\"app.greeting\").asString().get(); this.message.set(message); } String getMessage() { return message.get(); } void setMessage(String message) { this.message.set(message); } } Add three new imports. Inject the Config object into the GreetingProvider object. Get the app.greeting value from the Config object and set the member variable. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet <markup lang=\"json\" >{ \"message\": \"HelloFromMPConfig World!\" } Navigating the Config Tree Helidon offers a variety of methods to access in-memory configuration. These can be categorized as key access or tree navigation . You have been using key access for all the examples to this point. For example app.greeting is accessing the greeting child node of the app parent node. This simple example below demonstrates how to access a child node as a detached configuration subtree. <markup lang=\"yaml\" title=\"Create a file config-file.yaml in the helidon-quickstart-mp directory and add the following contents:\" >app: greeting: sender: Joe message: Hello-from-config-file.yaml <markup lang=\"yaml\" title=\"Update the meta-config.yaml with the following contents:\" >sources: - type: \"classpath\" properties: resource: \"META-INF/microprofile-config.properties\" - type: \"file\" properties: path: \"./config-file.yaml\" <markup lang=\"java\" title=\"Replace GreetingProvider class with the following code:\" >@ApplicationScoped public class GreetingProvider { private final AtomicReference&lt;String&gt; message = new AtomicReference&lt;&gt;(); private final AtomicReference&lt;String&gt; sender = new AtomicReference&lt;&gt;(); @Inject Config config; public void onStartUp(@Observes @Initialized(ApplicationScoped.class) Object init) { Config appNode = config.get(\"app.greeting\"); message.set(appNode.get(\"message\").asString().get()); sender.set(appNode.get(\"sender\").asString().get()); } String getMessage() { return sender.get() + \" says \" + message.get(); } void setMessage(String message) { this.message.set(message); } } Get the configuration subtree where the app.greeting node is the root. Get the value from the message Config node. Get the value from the sender Config node. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet <markup lang=\"json\" >{ \"message\": \"Joe says Hello-from-config-file.yaml World!\" } ",
            "title": "Accessing Config within an Application"
        },
        {
            "location": "mp/guides/config",
            "text": " The following example uses a Kubernetes ConfigMap to pass the configuration data to your Helidon application deployed to Kubernetes. When the pod is created, Kubernetes will automatically create a local file within the container that has the contents of the configuration file used for the ConfigMap. This example will create the file at /etc/config/config-file.properties . <markup lang=\"java\" title=\"Update the Main class and replace the buildConfig method:\" >private static Config buildConfig() { return Config.builder() .sources( file(\"/etc/config/config-file.properties\").optional(), classpath(\"META-INF/microprofile-config.properties\")) .build(); } The app.greeting value will be fetched from /etc/config/config-file.properties within the container. The server port is specified in META-INF/microprofile-config.properties within the helidon-quickstart-mp.jar . <markup lang=\"java\" title=\"Update the following code from GreetingProvider.java :\" >@ApplicationScoped public class GreetingProvider { @Inject @ConfigProperty(name = \"app.greeting\") private volatile String message; String getMessage() { return message; } void setMessage(String message) { this.message = message; } } <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet <markup lang=\"json\" >{ \"message\": \"HelloFromConfigFile World!\" } <markup lang=\"bash\" title=\"Stop the application and build the docker image:\" >docker build -t helidon-config-mp . <markup lang=\"bash\" title=\"Generate a ConfigMap from config-file.properties :\" >kubectl create configmap helidon-configmap --from-file config-file.properties <markup lang=\"bash\" title=\"View the contents of the ConfigMap:\" >kubectl get configmap helidon-configmap -o yaml <markup lang=\"yaml\" >apiVersion: v1 data: config-file.properties: | app.greeting=HelloFromConfigFile kind: ConfigMap The file config-file.properties will be created within the Kubernetes container. The config-file.properties file will have this single property defined. <markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named k8s-config.yaml , with the following contents:\" >kind: Service apiVersion: v1 metadata: name: helidon-config labels: app: helidon-config spec: type: NodePort selector: app: helidon-config ports: - port: 8080 targetPort: 8080 name: http --- kind: Deployment apiVersion: apps/v1 metadata: name: helidon-config spec: replicas: 1 selector: matchLabels: app: helidon-config template: metadata: labels: app: helidon-config version: v1 spec: containers: - name: helidon-config image: helidon-config-mp imagePullPolicy: IfNotPresent ports: - containerPort: 8080 volumeMounts: - name: config-volume mountPath: /etc/config volumes: - name: config-volume configMap: # Provide the name of the ConfigMap containing the files you want # to add to the container name: helidon-configmap A service of type NodePort that serves the default routes on port 8080 . A deployment with one replica of a pod. Mount the ConfigMap as a volume at /etc/config . This is where Kubernetes will create config-file.properties . Specify the ConfigMap which contains the configuration data. <markup lang=\"bash\" title=\"Create and deploy the application into Kubernetes:\" >kubectl apply -f ./k8s-config.yaml <markup lang=\"bash\" title=\"Get the service information:\" >kubectl get service/helidon-config <markup lang=\"bash\" >NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE helidon-config NodePort 10.99.159.2 &lt;none&gt; 8080:31143/TCP 8s A service of type NodePort that serves the default routes on port 31143 . <markup lang=\"bash\" title=\"Verify the configuration endpoint using port 31143 , your port will likely be different:\" >curl http://localhost:31143/greet <markup lang=\"json\" >{ \"message\": \"HelloFromConfigFile World!\" } The greeting value from /etc/config/config-file.properties within the container was used. You can now delete the Kubernetes resources that were just created during this example. <markup lang=\"bash\" title=\"Delete the Kubernetes resources:\" >kubectl delete -f ./k8s-config.yaml kubectl delete configmap helidon-configmap ",
            "title": "Integration with Kubernetes"
        },
        {
            "location": "mp/guides/config",
            "text": " This guide has demonstrated how to use basic Helidon configuration features. For more information about using the advanced Helidon configuration features, including mutability support and extensions, see Helidon Configuration . ",
            "title": "Summary"
        },
        {
            "location": "mp/guides/config",
            "text": " Refer to the following references for additional information: MicroProfile Config specification MicroProfile Config Javadoc Helidon Javadoc ",
            "title": "References"
        },
        {
            "location": "mp/guides/graalnative",
            "text": " This guide describes how to build a GraalVM native image for a Helidon MP application. ",
            "title": "preambule"
        },
        {
            "location": "mp/guides/graalnative",
            "text": " Native images are ahead-of-time compiled Java code that result in a self contained native executable. When used appropriately native images have dramatically faster startup and lower runtime memory overhead compared to a Java VM. In this guide you will learn how to build a native image locally on your machine, as well as using Docker. ",
            "title": "Introduction"
        },
        {
            "location": "mp/guides/graalnative",
            "text": " For this 10 minute tutorial, you will need the following: <div class=\"table__overflow elevation-1 flex sm7 \"> A Helidon MP Application You can use your own application or use the Helidon MP Quickstart to create a sample application. Java&#160;SE&#160;17 ( Open&#160;JDK&#160;17 ) Helidon requires Java 17+. Maven 3.6.1+ Helidon requires Maven 3.6.1+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop . GraalVM CE 21.0.0 <markup lang=\"bash\" title=\"Verify Prerequisites\" >java -version mvn --version docker --version kubectl version --short <markup lang=\"bash\" title=\"Setting JAVA_HOME\" ># On Mac export JAVA_HOME=`/usr/libexec/java_home -v 17` # On Linux # Use the appropriate path to your JDK export JAVA_HOME=/usr/lib/jvm/jdk-17 ",
            "title": "What You Need"
        },
        {
            "location": "mp/guides/graalnative",
            "text": " After downloading and installing GraalVM, set the GRAALVM_HOME environment variable to point at your GraalVM installation. <markup lang=\"bash\" ># Your path might be different export GRAALVM_HOME=/usr/local/graalvm-ce-21.3.0/Contents/Home/ Then install the optional native-image command: <markup lang=\"bash\" >$GRAALVM_HOME/bin/gu install native-image And verify: <markup lang=\"bash\" >$GRAALVM_HOME/bin/java -version $GRAALVM_HOME/bin/native-image --version ",
            "title": "Install GraalVM and the Native Image Command"
        },
        {
            "location": "mp/guides/graalnative",
            "text": " Generate the project using the Helidon MP Quickstart Maven archetype. <markup lang=\"bash\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-mp \\ -DarchetypeVersion=3.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-mp \\ -Dpackage=io.helidon.examples.quickstart.mp The archetype generates a Maven project in your current directory (for example, helidon-quickstart-mp ). Change into this directory and build. <markup lang=\"bash\" >cd helidon-quickstart-mp mvn package At this point you can run the application using the JVM: <markup lang=\"bash\" >java -jar target/helidon-quickstart-mp.jar In another shell test an endpoint: <markup lang=\"bash\" >curl -X GET http://localhost:8080/greet The application should respond with {\"message\":\"Hello World!\"} Now stop the running application (by pressing Ctrl+C). For more information about the Quickstart application and other endpoints it supports see the Helidon MP Quickstart Guide . ",
            "title": "Generate the Project"
        },
        {
            "location": "mp/guides/graalnative",
            "text": " Make sure you have GraalVM locally installed: <markup lang=\"bash\" >$GRAALVM_HOME/bin/native-image --version Build the native image using the native image profile: <markup lang=\"bash\" >mvn package -Pnative-image Tip This uses the helidon-maven-plugin to perform the native compilation using your installed copy of GraalVM. It might take a while to complete. Once it completes start the application using the native executable (no JVM!): <markup lang=\"bash\" >./target/helidon-quickstart-mp Yep, it starts fast. You can exercise the application&#8217;s endpoints as before. ",
            "title": "Local build"
        },
        {
            "location": "mp/guides/graalnative",
            "text": " Build the \"native\" Docker image <markup lang=\"bash\" >docker build -t helidon-quickstart-mp-native -f Dockerfile.native . Tip This does a full build inside the Docker container. The first time you run it, it will take a while because it is downloading all of the Maven dependencies and caching them in a Docker layer. Subsequent builds will be much faster as long as you don&#8217;t change the pom.xml file. If the pom is modified then the dependencies will be re-downloaded. Start the application: <markup lang=\"bash\" >docker run --rm -p 8080:8080 helidon-quickstart-mp-native:latest Again, it starts fast. You can exercise the application&#8217;s endpoints as before. ",
            "title": "Multi-stage Docker build"
        },
        {
            "location": "mp/guides/graalnative",
            "text": " You can build a native executable in 2 different ways: With a local installation of GraalVM Using Docker Local build Make sure you have GraalVM locally installed: <markup lang=\"bash\" >$GRAALVM_HOME/bin/native-image --version Build the native image using the native image profile: <markup lang=\"bash\" >mvn package -Pnative-image Tip This uses the helidon-maven-plugin to perform the native compilation using your installed copy of GraalVM. It might take a while to complete. Once it completes start the application using the native executable (no JVM!): <markup lang=\"bash\" >./target/helidon-quickstart-mp Yep, it starts fast. You can exercise the application&#8217;s endpoints as before. Multi-stage Docker build Build the \"native\" Docker image <markup lang=\"bash\" >docker build -t helidon-quickstart-mp-native -f Dockerfile.native . Tip This does a full build inside the Docker container. The first time you run it, it will take a while because it is downloading all of the Maven dependencies and caching them in a Docker layer. Subsequent builds will be much faster as long as you don&#8217;t change the pom.xml file. If the pom is modified then the dependencies will be re-downloaded. Start the application: <markup lang=\"bash\" >docker run --rm -p 8080:8080 helidon-quickstart-mp-native:latest Again, it starts fast. You can exercise the application&#8217;s endpoints as before. ",
            "title": "Building a Native Image"
        },
        {
            "location": "mp/guides/graalnative",
            "text": " Native images are ideal for applications with high horizontal scalability requirements where the ability to rapidly scale out to numerous instances is important. That said, native images do have some limitations , and for long running applications where startup and footprint are less of a priority, the Java SE HotSpot VM might be more appropriate. For information about creating custom Java runtime images see Custom Runtime Images with jlink . ",
            "title": "When should I use Native Images?"
        },
        {
            "location": "mp/guides/gradle-build",
            "text": " This guide describes Helidon&#8217;s support for Gradle projects. ",
            "title": "preambule"
        },
        {
            "location": "mp/guides/gradle-build",
            "text": " While most of Helidon&#8217;s examples use Maven, you can also use Helidon with a Gradle project. We recommend Gradle 6+. ",
            "title": "Introduction"
        },
        {
            "location": "mp/guides/gradle-build",
            "text": " The Helidon Quickstart Example contains a build.gradle file that you can use as an example for building your Helidon application using Gradle. ",
            "title": "Gradle Example"
        },
        {
            "location": "mp/guides/gradle-build",
            "text": " Gradle supports using a Maven POM to perform dependency management. You can use the Helidon Dependencies POM for this purpose. Once you import the Helidon dependency management POM you can specify dependencies without providing a version. <markup lang=\"xml\" title=\"Using the Helidon Dependencies POM\" >dependencies { // import Helidon dependency management implementation platform(\"io.helidon:helidon-dependencies:${project.helidonversion}\") implementation 'io.helidon.microprofile.bundles:helidon-microprofile' implementation 'org.glassfish.jersey.media:jersey-media-json-binding' runtimeOnly 'org.jboss:jandex' runtimeOnly 'javax.activation:javax.activation-api' testCompileOnly 'org.junit.jupiter:junit-jupiter-api:' } ",
            "title": "Dependency Management"
        },
        {
            "location": "mp/guides/health",
            "text": " This guide describes how to create a sample MicroProfile (MP) project that can be used to run some basic examples using both built-in and custom health checks with Helidon MP. ",
            "title": "preambule"
        },
        {
            "location": "mp/guides/health",
            "text": " Generate the project sources using the Helidon MP Maven archetype. The result is a simple project that can be used for the examples in this guide. <markup lang=\"bash\" title=\"Run the Maven archetype:\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-mp \\ -DarchetypeVersion=3.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-mp \\ -Dpackage=io.helidon.examples.quickstart.mp ",
            "title": "Create a Sample MP Project"
        },
        {
            "location": "mp/guides/health",
            "text": " Helidon has a set of built-in health checks that are automatically enabled to report various health check statuses that are commonly used: deadlock detection available disk space available heap memory The following example will demonstrate how to use the built-in health checks. These examples are all executed from the root directory of your project (helidon-quickstart-mp). <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-mp.jar <markup lang=\"bash\" title=\"Verify the health endpoint in a new terminal window:\" >curl http://localhost:8080/health <markup lang=\"json\" title=\"JSON response:\" >{ \"status\": \"UP\", \"checks\": [ { \"name\": \"deadlock\", \"status\": \"UP\" }, { \"name\": \"diskSpace\", \"status\": \"UP\", \"data\": { \"free\": \"325.54 GB\", \"freeBytes\": 349543358464, \"percentFree\": \"69.91%\", \"total\": \"465.63 GB\", \"totalBytes\": 499963174912 } }, { \"name\": \"heapMemory\", \"status\": \"UP\", \"data\": { \"free\": \"230.87 MB\", \"freeBytes\": 242085696, \"max\": \"3.56 GB\", \"maxBytes\": 3817865216, \"percentFree\": \"98.90%\", \"total\": \"271.00 MB\", \"totalBytes\": 284164096 } } ] } ",
            "title": "Using the Built-In Health Checks"
        },
        {
            "location": "mp/guides/health",
            "text": " You can create application-specific custom health checks and integrate them with Helidon using CDI. The following example shows how to add a custom liveness health check. <markup lang=\"java\" title=\"Create a new GreetLivenessCheck class with the following content:\" >package io.helidon.examples.quickstart.mp; import jakarta.enterprise.context.ApplicationScoped; import org.eclipse.microprofile.health.HealthCheck; import org.eclipse.microprofile.health.HealthCheckResponse; import org.eclipse.microprofile.health.Liveness; @Liveness @ApplicationScoped public class GreetLivenessCheck implements HealthCheck { private GreetingProvider provider; @Override public HealthCheckResponse call() { return HealthCheckResponse.named(\"LivenessCheck\") .up() .withData(\"time\", System.currentTimeMillis()) .build(); } } Annotation indicating this is a liveness health check. Annotation indicating there is a single liveness HealthCheck object during the lifetime of the application. Build the HealthCheckResponse with status UP and the current time. <markup lang=\"bash\" title=\"Build and run the application, then verify the custom liveness health endpoint:\" >curl http://localhost:8080/health/live <markup lang=\"json\" title=\"JSON response:\" >{ \"status\": \"UP\", \"checks\": [ { \"name\": \"LivenessCheck\", \"status\": \"UP\", \"data\": { \"time\": 1566338255331 } } ] } ",
            "title": "Custom Liveness Health Checks"
        },
        {
            "location": "mp/guides/health",
            "text": " You can add a readiness check to indicate that the application is ready to be used. In this example, the server will wait five seconds before it becomes ready. <markup lang=\"java\" title=\"Create a new GreetReadinessCheck class with the following content:\" >package io.helidon.examples.quickstart.mp; import java.time.Duration; import java.util.concurrent.atomic.AtomicLong; import jakarta.enterprise.context.ApplicationScoped; import jakarta.enterprise.context.Initialized; import jakarta.enterprise.event.Observes; import org.eclipse.microprofile.health.HealthCheck; import org.eclipse.microprofile.health.HealthCheckResponse; import org.eclipse.microprofile.health.Readiness; @Readiness @ApplicationScoped public class GreetReadinessCheck implements HealthCheck { private final AtomicLong readyTime = new AtomicLong(0); @Override public HealthCheckResponse call() { return HealthCheckResponse.named(\"ReadinessCheck\") .status(isReady()) .withData(\"time\", readyTime.get()) .build(); } public void onStartUp( @Observes @Initialized(ApplicationScoped.class) Object init) { readyTime.set(System.currentTimeMillis()); } /** * Become ready after 5 seconds * * @return true if application ready */ private boolean isReady() { return Duration.ofMillis(System.currentTimeMillis() - readyTime.get()).getSeconds() &gt;= 5; } } Include additional imports. Annotation indicating that this is a readiness health check. Build the HealthCheckResponse with status UP after five seconds, else DOWN . Record the time at startup. <markup lang=\"bash\" title=\"Build and run the application. Issue the curl command with -v within five seconds and you will see that the application is not ready:\" >curl -v http://localhost:8080/health/ready <markup lang=\"listing\" title=\"HTTP response status\" >&lt; HTTP/1.1 503 Service Unavailable The HTTP status is 503 since the application is not ready. <markup lang=\"json\" title=\"Response body\" >{ \"status\": \"DOWN\", \"checks\": [ { \"name\": \"ReadinessCheck\", \"status\": \"DOWN\", \"data\": { \"time\": 1566399775700 } } ] } <markup lang=\"bash\" title=\"After five seconds you will see the application is ready:\" >curl -v http://localhost:8080/health/ready <markup lang=\"listing\" title=\"HTTP response status\" >&lt; HTTP/1.1 200 OK The HTTP status is 200 indicating that the application is ready. <markup lang=\"json\" title=\"Response body\" >{ \"status\": \"UP\", \"checks\": [ { \"name\": \"ReadinessCheck\", \"status\": \"UP\", \"data\": { \"time\": 1566399775700 } } ] } ",
            "title": "Custom Readiness Health Checks"
        },
        {
            "location": "mp/guides/health",
            "text": " You can add a startup check to indicate whether or not the application has initialized to the point that the other health checks make sense. In this example, the server will wait eight seconds before it declares itself started. <markup lang=\"java\" title=\"Create a new GreetStartedCheck class with the following content:\" >package io.helidon.examples.quickstart.mp; import java.time.Duration; import java.util.concurrent.atomic.AtomicLong; import jakarta.enterprise.context.ApplicationScoped; import jakarta.enterprise.context.Initialized; import jakarta.enterprise.event.Observes; import org.eclipse.microprofile.health.HealthCheck; import org.eclipse.microprofile.health.HealthCheckResponse; import org.eclipse.microprofile.health.Started; @Started @ApplicationScoped public class GreetStartedCheck implements HealthCheck { private final AtomicLong readyTime = new AtomicLong(0); @Override public HealthCheckResponse call() { return HealthCheckResponse.named(\"StartedCheck\") .status(isStarted()) .withData(\"time\", readyTime.get()) .build(); } public void onStartUp( @Observes @Initialized(ApplicationScoped.class) Object init) { readyTime.set(System.currentTimeMillis()); } /** * Become ready after 5 seconds * * @return true if application ready */ private boolean isStarted() { return Duration.ofMillis(System.currentTimeMillis() - readyTime.get()).getSeconds() &gt;= 8; } } Include additional imports. Annotation indicating that this is a startup health check. Build the HealthCheckResponse with status UP after eight seconds, else DOWN . Record the time at startup of Helidon; the application will declare itself as started eight seconds later. <markup lang=\"bash\" title=\"Build and run the application. Issue the curl command with -v within five seconds and you will see that the application has not yet started:\" >curl -v http://localhost:8080/health/started <markup lang=\"listing\" title=\"HTTP response status\" >&lt; HTTP/1.1 503 Service Unavailable The HTTP status is 503 since the application has not started. <markup lang=\"json\" title=\"Response body\" >{ \"status\": \"DOWN\", \"checks\": [ { \"name\": \"StartedCheck\", \"status\": \"DOWN\", \"data\": { \"time\": 1566399775700 } } ] } <markup lang=\"bash\" title=\"After eight seconds you will see the application has started:\" >curl -v http://localhost:8080/health/started <markup lang=\"listing\" title=\"HTTP response status\" >&lt; HTTP/1.1 200 OK The HTTP status is 200 indicating that the application is started. <markup lang=\"json\" title=\"Response body\" >{ \"status\": \"UP\", \"checks\": [ { \"name\": \"StartedCheck\", \"status\": \"UP\", \"data\": { \"time\": 1566399775700 } } ] } When using the health check URLs, you can get the following health check data: liveness only - http://localhost:8080/health/live readiness only - http://localhost:8080/health/ready startup checks only - http://localhost:8080/health/started all health check data - http://localhost:8080/health <markup lang=\"bash\" title=\"Get all the health check data, including custom data:\" >curl http://localhost:8080/health <markup lang=\"json\" title=\"JSON response:\" >{ \"status\": \"UP\", \"checks\": [ { \"name\": \"LivenessCheck\", \"status\": \"UP\", \"data\": { \"time\": 1566403431536 } }, { \"name\": \"ReadinessCheck\", \"status\": \"UP\", \"data\": { \"time\": 1566403280639 } }, { \"name\": \"StartedCheck\", \"status\": \"UP\", \"data\": { \"time\": 1566403280639 } }, { \"name\": \"deadlock\", \"state\": \"UP\", \"status\": \"UP\" }, { \"name\": \"diskSpace\", \"state\": \"UP\", \"status\": \"UP\", \"data\": { \"free\": \"325.50 GB\", \"freeBytes\": 349500698624, \"percentFree\": \"69.91%\", \"total\": \"465.63 GB\", \"totalBytes\": 499963174912 } }, { \"name\": \"heapMemory\", \"state\": \"UP\", \"status\": \"UP\", \"data\": { \"free\": \"231.01 MB\", \"freeBytes\": 242235928, \"max\": \"3.56 GB\", \"maxBytes\": 3817865216, \"percentFree\": \"98.79%\", \"total\": \"275.00 MB\", \"totalBytes\": 288358400 } } ] } ",
            "title": "Custom Startup Health Checks"
        },
        {
            "location": "mp/guides/health",
            "text": " You can specify a custom port and root context for the root health endpoint path. However, you cannot use different ports, such as http://localhost:8080/myhealth and http://localhost:8081/myhealth/live . Likewise, you cannot use different paths, such as http://localhost:8080/health and http://localhost:8080/probe/live . The example below will change the root path. <markup lang=\"yaml\" title=\"Create a file named application.yaml in the resources directory with the following contents:\" >health: web-context: \"myhealth\" The web-context specifies a new root path for the health endpoint. <markup lang=\"bash\" title=\"Build and run the application, then verify that the health endpoint is using the new /myhealth root:\" >curl http://localhost:8080/myhealth curl http://localhost:8080/myhealth/live curl http://localhost:8080/myhealth/ready curl http://localhost:8080/myhealth/started The following example will change the root path and the health port. <markup lang=\"yaml\" title=\"Update application.yaml to use a different port and root path for the health endpoint:\" >server: port: 8080 host: \"localhost\" sockets: health: port: 8081 bind-address: \"localhost\" health: routing: \"health\" web-context: \"myhealth\" The default port for the application. The name of the new socket, it can be any name, this example uses health . The port for the new health socket. The health endpoint routing uses the new socket health . <markup lang=\"bash\" title=\"Build and run the application, then verify the health endpoint using port 8081 and /myhealth :\" >curl http://localhost:8081/myhealth curl http://localhost:8081/myhealth/live curl http://localhost:8081/myhealth/ready curl http://localhost:8081/myhealth/started ",
            "title": "Custom Health Root Path and Port"
        },
        {
            "location": "mp/guides/health",
            "text": " The following example shows how to integrate the Helidon health check API with an application that implements health endpoints for the Kubernetes liveness, readiness, and startup probes. Delete the contents of application.yaml so that the default health endpoint path and port are used. <markup lang=\"bash\" title=\"Rebuild and start the application, then verify the health endpoint:\" >curl http://localhost:8080/health <markup lang=\"bash\" title=\"Stop the application and build the docker image:\" >docker build -t helidon-quickstart-mp . <markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named health.yaml , with the following content:\" >kind: Service apiVersion: v1 metadata: name: helidon-health labels: app: helidon-health spec: type: NodePort selector: app: helidon-health ports: - port: 8080 targetPort: 8080 name: http --- kind: Deployment apiVersion: apps/v1 metadata: name: helidon-health spec: replicas: 1 selector: matchLabels: app: helidon-health template: metadata: labels: app: helidon-health version: v1 spec: containers: - name: helidon-health image: helidon-quickstart-mp imagePullPolicy: IfNotPresent ports: - containerPort: 8080 livenessProbe: httpGet: path: /health/live port: 8080 initialDelaySeconds: 5 periodSeconds: 10 timeoutSeconds: 3 failureThreshold: 3 readinessProbe: httpGet: path: /health/ready port: 8080 initialDelaySeconds: 5 periodSeconds: 2 timeoutSeconds: 3 startupProbe: httpGet: path: /health/started port: 8080 initialDelaySeconds: 8 periodSeconds: 10 timeoutSeconds: 3 failureThreshold: 3 --- A service of type NodePort that serves the default routes on port 8080 . A deployment with one replica of a pod. The HTTP endpoint for the liveness probe. The liveness probe configuration. The HTTP endpoint for the readiness probe. The readiness probe configuration. The HTTP endpoint for the startup probe. The startup probe configuration. <markup lang=\"bash\" title=\"Create and deploy the application into Kubernetes:\" >kubectl apply -f ./health.yaml <markup lang=\"bash\" title=\"Get the service information:\" >kubectl get service/helidon-health <markup lang=\"bash\" >NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE helidon-health NodePort 10.107.226.62 &lt;none&gt; 8080:30116/TCP 4s A service of type NodePort that serves the default routes on port 30116 . <markup lang=\"bash\" title=\"Verify the health endpoints using port '30116', your port may be different. The JSON response will be the same as your previous test:\" >curl http://localhost:30116/health <markup lang=\"bash\" title=\"Delete the application, cleaning up Kubernetes resources:\" >kubectl delete -f ./health.yaml ",
            "title": "Using Liveness, Readiness, and Startup Health Checks with Kubernetes"
        },
        {
            "location": "mp/guides/health",
            "text": " This guide demonstrated how to use health checks in a Helidon MP application as follows: Access the default health checks Create and use custom readiness, liveness, and startup checks Customize the health check root path and port Integrate Helidon health check API with Kubernetes Refer to the following references for additional information: MicroProfile health check specification MicroProfile health check Javadoc Helidon Javadoc ",
            "title": "Summary"
        },
        {
            "location": "mp/guides/health",
            "text": " For this 15 minute tutorial, you will need the following: <div class=\"table__overflow elevation-1 flex sm7 \"> A Helidon MP Application You can use your own application or use the Helidon MP Quickstart to create a sample application. Java&#160;SE&#160;17 ( Open&#160;JDK&#160;17 ) Helidon requires Java 17+. Maven 3.6.1+ Helidon requires Maven 3.6.1+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop . <markup lang=\"bash\" title=\"Verify Prerequisites\" >java -version mvn --version docker --version kubectl version --short <markup lang=\"bash\" title=\"Setting JAVA_HOME\" ># On Mac export JAVA_HOME=`/usr/libexec/java_home -v 17` # On Linux # Use the appropriate path to your JDK export JAVA_HOME=/usr/lib/jvm/jdk-17 Create a Sample MP Project Generate the project sources using the Helidon MP Maven archetype. The result is a simple project that can be used for the examples in this guide. <markup lang=\"bash\" title=\"Run the Maven archetype:\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-mp \\ -DarchetypeVersion=3.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-mp \\ -Dpackage=io.helidon.examples.quickstart.mp Using the Built-In Health Checks Helidon has a set of built-in health checks that are automatically enabled to report various health check statuses that are commonly used: deadlock detection available disk space available heap memory The following example will demonstrate how to use the built-in health checks. These examples are all executed from the root directory of your project (helidon-quickstart-mp). <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-mp.jar <markup lang=\"bash\" title=\"Verify the health endpoint in a new terminal window:\" >curl http://localhost:8080/health <markup lang=\"json\" title=\"JSON response:\" >{ \"status\": \"UP\", \"checks\": [ { \"name\": \"deadlock\", \"status\": \"UP\" }, { \"name\": \"diskSpace\", \"status\": \"UP\", \"data\": { \"free\": \"325.54 GB\", \"freeBytes\": 349543358464, \"percentFree\": \"69.91%\", \"total\": \"465.63 GB\", \"totalBytes\": 499963174912 } }, { \"name\": \"heapMemory\", \"status\": \"UP\", \"data\": { \"free\": \"230.87 MB\", \"freeBytes\": 242085696, \"max\": \"3.56 GB\", \"maxBytes\": 3817865216, \"percentFree\": \"98.90%\", \"total\": \"271.00 MB\", \"totalBytes\": 284164096 } } ] } Custom Liveness Health Checks You can create application-specific custom health checks and integrate them with Helidon using CDI. The following example shows how to add a custom liveness health check. <markup lang=\"java\" title=\"Create a new GreetLivenessCheck class with the following content:\" >package io.helidon.examples.quickstart.mp; import jakarta.enterprise.context.ApplicationScoped; import org.eclipse.microprofile.health.HealthCheck; import org.eclipse.microprofile.health.HealthCheckResponse; import org.eclipse.microprofile.health.Liveness; @Liveness @ApplicationScoped public class GreetLivenessCheck implements HealthCheck { private GreetingProvider provider; @Override public HealthCheckResponse call() { return HealthCheckResponse.named(\"LivenessCheck\") .up() .withData(\"time\", System.currentTimeMillis()) .build(); } } Annotation indicating this is a liveness health check. Annotation indicating there is a single liveness HealthCheck object during the lifetime of the application. Build the HealthCheckResponse with status UP and the current time. <markup lang=\"bash\" title=\"Build and run the application, then verify the custom liveness health endpoint:\" >curl http://localhost:8080/health/live <markup lang=\"json\" title=\"JSON response:\" >{ \"status\": \"UP\", \"checks\": [ { \"name\": \"LivenessCheck\", \"status\": \"UP\", \"data\": { \"time\": 1566338255331 } } ] } Custom Readiness Health Checks You can add a readiness check to indicate that the application is ready to be used. In this example, the server will wait five seconds before it becomes ready. <markup lang=\"java\" title=\"Create a new GreetReadinessCheck class with the following content:\" >package io.helidon.examples.quickstart.mp; import java.time.Duration; import java.util.concurrent.atomic.AtomicLong; import jakarta.enterprise.context.ApplicationScoped; import jakarta.enterprise.context.Initialized; import jakarta.enterprise.event.Observes; import org.eclipse.microprofile.health.HealthCheck; import org.eclipse.microprofile.health.HealthCheckResponse; import org.eclipse.microprofile.health.Readiness; @Readiness @ApplicationScoped public class GreetReadinessCheck implements HealthCheck { private final AtomicLong readyTime = new AtomicLong(0); @Override public HealthCheckResponse call() { return HealthCheckResponse.named(\"ReadinessCheck\") .status(isReady()) .withData(\"time\", readyTime.get()) .build(); } public void onStartUp( @Observes @Initialized(ApplicationScoped.class) Object init) { readyTime.set(System.currentTimeMillis()); } /** * Become ready after 5 seconds * * @return true if application ready */ private boolean isReady() { return Duration.ofMillis(System.currentTimeMillis() - readyTime.get()).getSeconds() &gt;= 5; } } Include additional imports. Annotation indicating that this is a readiness health check. Build the HealthCheckResponse with status UP after five seconds, else DOWN . Record the time at startup. <markup lang=\"bash\" title=\"Build and run the application. Issue the curl command with -v within five seconds and you will see that the application is not ready:\" >curl -v http://localhost:8080/health/ready <markup lang=\"listing\" title=\"HTTP response status\" >&lt; HTTP/1.1 503 Service Unavailable The HTTP status is 503 since the application is not ready. <markup lang=\"json\" title=\"Response body\" >{ \"status\": \"DOWN\", \"checks\": [ { \"name\": \"ReadinessCheck\", \"status\": \"DOWN\", \"data\": { \"time\": 1566399775700 } } ] } <markup lang=\"bash\" title=\"After five seconds you will see the application is ready:\" >curl -v http://localhost:8080/health/ready <markup lang=\"listing\" title=\"HTTP response status\" >&lt; HTTP/1.1 200 OK The HTTP status is 200 indicating that the application is ready. <markup lang=\"json\" title=\"Response body\" >{ \"status\": \"UP\", \"checks\": [ { \"name\": \"ReadinessCheck\", \"status\": \"UP\", \"data\": { \"time\": 1566399775700 } } ] } Custom Startup Health Checks You can add a startup check to indicate whether or not the application has initialized to the point that the other health checks make sense. In this example, the server will wait eight seconds before it declares itself started. <markup lang=\"java\" title=\"Create a new GreetStartedCheck class with the following content:\" >package io.helidon.examples.quickstart.mp; import java.time.Duration; import java.util.concurrent.atomic.AtomicLong; import jakarta.enterprise.context.ApplicationScoped; import jakarta.enterprise.context.Initialized; import jakarta.enterprise.event.Observes; import org.eclipse.microprofile.health.HealthCheck; import org.eclipse.microprofile.health.HealthCheckResponse; import org.eclipse.microprofile.health.Started; @Started @ApplicationScoped public class GreetStartedCheck implements HealthCheck { private final AtomicLong readyTime = new AtomicLong(0); @Override public HealthCheckResponse call() { return HealthCheckResponse.named(\"StartedCheck\") .status(isStarted()) .withData(\"time\", readyTime.get()) .build(); } public void onStartUp( @Observes @Initialized(ApplicationScoped.class) Object init) { readyTime.set(System.currentTimeMillis()); } /** * Become ready after 5 seconds * * @return true if application ready */ private boolean isStarted() { return Duration.ofMillis(System.currentTimeMillis() - readyTime.get()).getSeconds() &gt;= 8; } } Include additional imports. Annotation indicating that this is a startup health check. Build the HealthCheckResponse with status UP after eight seconds, else DOWN . Record the time at startup of Helidon; the application will declare itself as started eight seconds later. <markup lang=\"bash\" title=\"Build and run the application. Issue the curl command with -v within five seconds and you will see that the application has not yet started:\" >curl -v http://localhost:8080/health/started <markup lang=\"listing\" title=\"HTTP response status\" >&lt; HTTP/1.1 503 Service Unavailable The HTTP status is 503 since the application has not started. <markup lang=\"json\" title=\"Response body\" >{ \"status\": \"DOWN\", \"checks\": [ { \"name\": \"StartedCheck\", \"status\": \"DOWN\", \"data\": { \"time\": 1566399775700 } } ] } <markup lang=\"bash\" title=\"After eight seconds you will see the application has started:\" >curl -v http://localhost:8080/health/started <markup lang=\"listing\" title=\"HTTP response status\" >&lt; HTTP/1.1 200 OK The HTTP status is 200 indicating that the application is started. <markup lang=\"json\" title=\"Response body\" >{ \"status\": \"UP\", \"checks\": [ { \"name\": \"StartedCheck\", \"status\": \"UP\", \"data\": { \"time\": 1566399775700 } } ] } When using the health check URLs, you can get the following health check data: liveness only - http://localhost:8080/health/live readiness only - http://localhost:8080/health/ready startup checks only - http://localhost:8080/health/started all health check data - http://localhost:8080/health <markup lang=\"bash\" title=\"Get all the health check data, including custom data:\" >curl http://localhost:8080/health <markup lang=\"json\" title=\"JSON response:\" >{ \"status\": \"UP\", \"checks\": [ { \"name\": \"LivenessCheck\", \"status\": \"UP\", \"data\": { \"time\": 1566403431536 } }, { \"name\": \"ReadinessCheck\", \"status\": \"UP\", \"data\": { \"time\": 1566403280639 } }, { \"name\": \"StartedCheck\", \"status\": \"UP\", \"data\": { \"time\": 1566403280639 } }, { \"name\": \"deadlock\", \"state\": \"UP\", \"status\": \"UP\" }, { \"name\": \"diskSpace\", \"state\": \"UP\", \"status\": \"UP\", \"data\": { \"free\": \"325.50 GB\", \"freeBytes\": 349500698624, \"percentFree\": \"69.91%\", \"total\": \"465.63 GB\", \"totalBytes\": 499963174912 } }, { \"name\": \"heapMemory\", \"state\": \"UP\", \"status\": \"UP\", \"data\": { \"free\": \"231.01 MB\", \"freeBytes\": 242235928, \"max\": \"3.56 GB\", \"maxBytes\": 3817865216, \"percentFree\": \"98.79%\", \"total\": \"275.00 MB\", \"totalBytes\": 288358400 } } ] } Custom Health Root Path and Port You can specify a custom port and root context for the root health endpoint path. However, you cannot use different ports, such as http://localhost:8080/myhealth and http://localhost:8081/myhealth/live . Likewise, you cannot use different paths, such as http://localhost:8080/health and http://localhost:8080/probe/live . The example below will change the root path. <markup lang=\"yaml\" title=\"Create a file named application.yaml in the resources directory with the following contents:\" >health: web-context: \"myhealth\" The web-context specifies a new root path for the health endpoint. <markup lang=\"bash\" title=\"Build and run the application, then verify that the health endpoint is using the new /myhealth root:\" >curl http://localhost:8080/myhealth curl http://localhost:8080/myhealth/live curl http://localhost:8080/myhealth/ready curl http://localhost:8080/myhealth/started The following example will change the root path and the health port. <markup lang=\"yaml\" title=\"Update application.yaml to use a different port and root path for the health endpoint:\" >server: port: 8080 host: \"localhost\" sockets: health: port: 8081 bind-address: \"localhost\" health: routing: \"health\" web-context: \"myhealth\" The default port for the application. The name of the new socket, it can be any name, this example uses health . The port for the new health socket. The health endpoint routing uses the new socket health . <markup lang=\"bash\" title=\"Build and run the application, then verify the health endpoint using port 8081 and /myhealth :\" >curl http://localhost:8081/myhealth curl http://localhost:8081/myhealth/live curl http://localhost:8081/myhealth/ready curl http://localhost:8081/myhealth/started Using Liveness, Readiness, and Startup Health Checks with Kubernetes The following example shows how to integrate the Helidon health check API with an application that implements health endpoints for the Kubernetes liveness, readiness, and startup probes. Delete the contents of application.yaml so that the default health endpoint path and port are used. <markup lang=\"bash\" title=\"Rebuild and start the application, then verify the health endpoint:\" >curl http://localhost:8080/health <markup lang=\"bash\" title=\"Stop the application and build the docker image:\" >docker build -t helidon-quickstart-mp . <markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named health.yaml , with the following content:\" >kind: Service apiVersion: v1 metadata: name: helidon-health labels: app: helidon-health spec: type: NodePort selector: app: helidon-health ports: - port: 8080 targetPort: 8080 name: http --- kind: Deployment apiVersion: apps/v1 metadata: name: helidon-health spec: replicas: 1 selector: matchLabels: app: helidon-health template: metadata: labels: app: helidon-health version: v1 spec: containers: - name: helidon-health image: helidon-quickstart-mp imagePullPolicy: IfNotPresent ports: - containerPort: 8080 livenessProbe: httpGet: path: /health/live port: 8080 initialDelaySeconds: 5 periodSeconds: 10 timeoutSeconds: 3 failureThreshold: 3 readinessProbe: httpGet: path: /health/ready port: 8080 initialDelaySeconds: 5 periodSeconds: 2 timeoutSeconds: 3 startupProbe: httpGet: path: /health/started port: 8080 initialDelaySeconds: 8 periodSeconds: 10 timeoutSeconds: 3 failureThreshold: 3 --- A service of type NodePort that serves the default routes on port 8080 . A deployment with one replica of a pod. The HTTP endpoint for the liveness probe. The liveness probe configuration. The HTTP endpoint for the readiness probe. The readiness probe configuration. The HTTP endpoint for the startup probe. The startup probe configuration. <markup lang=\"bash\" title=\"Create and deploy the application into Kubernetes:\" >kubectl apply -f ./health.yaml <markup lang=\"bash\" title=\"Get the service information:\" >kubectl get service/helidon-health <markup lang=\"bash\" >NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE helidon-health NodePort 10.107.226.62 &lt;none&gt; 8080:30116/TCP 4s A service of type NodePort that serves the default routes on port 30116 . <markup lang=\"bash\" title=\"Verify the health endpoints using port '30116', your port may be different. The JSON response will be the same as your previous test:\" >curl http://localhost:30116/health <markup lang=\"bash\" title=\"Delete the application, cleaning up Kubernetes resources:\" >kubectl delete -f ./health.yaml Summary This guide demonstrated how to use health checks in a Helidon MP application as follows: Access the default health checks Create and use custom readiness, liveness, and startup checks Customize the health check root path and port Integrate Helidon health check API with Kubernetes Refer to the following references for additional information: MicroProfile health check specification MicroProfile health check Javadoc Helidon Javadoc ",
            "title": "What You Need"
        },
        {
            "location": "mp/guides/jbatch",
            "text": " This guide describes how Helidon and Jakarta Batch (JBatch) can be used together to execute batch jobs in environments that do not fully support EE environments. ",
            "title": "preambule"
        },
        {
            "location": "mp/guides/jbatch",
            "text": " For this 20 minute tutorial, you will need the following: <div class=\"table__overflow elevation-1 flex sm7 \"> A Helidon MP Application You can use your own application or use the Helidon MP Quickstart to create a sample application. Java&#160;SE&#160;17 ( Open&#160;JDK&#160;17 ) Helidon requires Java 17+. Maven 3.6.1+ Helidon requires Maven 3.6.1+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop . <markup lang=\"bash\" title=\"Verify Prerequisites\" >java -version mvn --version docker --version kubectl version --short <markup lang=\"bash\" title=\"Setting JAVA_HOME\" ># On Mac export JAVA_HOME=`/usr/libexec/java_home -v 17` # On Linux # Use the appropriate path to your JDK export JAVA_HOME=/usr/lib/jvm/jdk-17 This guide assumes you are familiar with the Jakarta Batch project specification from the Eclipse Foundation project site. ",
            "title": "What You Need"
        },
        {
            "location": "mp/guides/jbatch",
            "text": " For this example, add the IBM JBatch implementation and the derby embedded DB (since JPA and JPA are not available by default) dependencies to the testing module: <markup lang=\"xml\" title=\"Maven dependencies\" >&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.imb.jbatch&lt;/groupId&gt; &lt;artifactId&gt;com.ibm.jbatch.container&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.derby&lt;/groupId&gt; &lt;artifactId&gt;derby&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; ",
            "title": "Dependencies"
        },
        {
            "location": "mp/guides/jbatch",
            "text": "<markup lang=\"java\" title=\"MyOutputRecord\" >public class MyOutputRecord { private int id; public MyOutputRecord(int id) { this.id = id; } public int getId() { return id; } public void setId(int id) { this.id = id; } @Override public String toString() { return \"MyOutputRecord: \" + id; } } ",
            "title": "2. Create a unit of output information"
        },
        {
            "location": "mp/guides/jbatch",
            "text": " MyItemReader should look like this: <markup lang=\"java\" title=\"MyItemReader\" >public class MyItemReader extends AbstractItemReader { private final StringTokenizer tokens; public MyItemReader() { tokens = new StringTokenizer(\"1,2,3,4,5,6,7,8,9,10\", \",\"); } /** * Perform read Item. * @return Stage result. */ @Override public MyInputRecord readItem() { if (tokens.hasMoreTokens()) { return new MyInputRecord(Integer.valueOf(tokens.nextToken())); } return null; } } ",
            "title": "3. Create MyItemReader to extend AbstractItemReader "
        },
        {
            "location": "mp/guides/jbatch",
            "text": " The MyItemProcessor will perform some simple operations: <markup lang=\"java\" title=\"MyItemProcessor\" >public class MyItemProcessor implements ItemProcessor { @Override public MyOutputRecord processItem(Object t) { System.out.println(\"processItem: \" + t); return (((MyInputRecord) t).getId() % 2 == 0) ? null : new MyOutputRecord(((MyInputRecord) t).getId() * 2); } } ",
            "title": "4. Create MyItemProcessor to implement ItemProcessor "
        },
        {
            "location": "mp/guides/jbatch",
            "text": " MyItemWriter prints the result: <markup lang=\"java\" title=\"MyItemWriter\" >public class MyItemWriter extends AbstractItemWriter { @Override public void writeItems(List list) { System.out.println(\"writeItems: \" + list); } } ",
            "title": "5. Create MyItemWriter to extend AbstractItemWriter "
        },
        {
            "location": "mp/guides/jbatch",
            "text": " MyBatchlet simply completes the process: <markup lang=\"java\" title=\"MyBatchlet\" >public class MyBatchlet extends AbstractBatchlet { @Override public String process() { System.out.println(\"Running inside a batchlet\"); return \"COMPLETED\"; } } ",
            "title": "6. Create MyBatchlet to extend AbstractBatchlet "
        },
        {
            "location": "mp/guides/jbatch",
            "text": "<markup lang=\"java\" title=\"MyInputRecord\" >public class MyInputRecord { private int id; public MyInputRecord(int id) { this.id = id; } public int getId() { return id; } public void setId(int id) { this.id = id; } @Override public String toString() { return \"MyInputRecord: \" + id; } } 2. Create a unit of output information <markup lang=\"java\" title=\"MyOutputRecord\" >public class MyOutputRecord { private int id; public MyOutputRecord(int id) { this.id = id; } public int getId() { return id; } public void setId(int id) { this.id = id; } @Override public String toString() { return \"MyOutputRecord: \" + id; } } 3. Create MyItemReader to extend AbstractItemReader MyItemReader should look like this: <markup lang=\"java\" title=\"MyItemReader\" >public class MyItemReader extends AbstractItemReader { private final StringTokenizer tokens; public MyItemReader() { tokens = new StringTokenizer(\"1,2,3,4,5,6,7,8,9,10\", \",\"); } /** * Perform read Item. * @return Stage result. */ @Override public MyInputRecord readItem() { if (tokens.hasMoreTokens()) { return new MyInputRecord(Integer.valueOf(tokens.nextToken())); } return null; } } 4. Create MyItemProcessor to implement ItemProcessor The MyItemProcessor will perform some simple operations: <markup lang=\"java\" title=\"MyItemProcessor\" >public class MyItemProcessor implements ItemProcessor { @Override public MyOutputRecord processItem(Object t) { System.out.println(\"processItem: \" + t); return (((MyInputRecord) t).getId() % 2 == 0) ? null : new MyOutputRecord(((MyInputRecord) t).getId() * 2); } } 5. Create MyItemWriter to extend AbstractItemWriter MyItemWriter prints the result: <markup lang=\"java\" title=\"MyItemWriter\" >public class MyItemWriter extends AbstractItemWriter { @Override public void writeItems(List list) { System.out.println(\"writeItems: \" + list); } } 6. Create MyBatchlet to extend AbstractBatchlet MyBatchlet simply completes the process: <markup lang=\"java\" title=\"MyBatchlet\" >public class MyBatchlet extends AbstractBatchlet { @Override public String process() { System.out.println(\"Running inside a batchlet\"); return \"COMPLETED\"; } } ",
            "title": "1. Create a unit of input information"
        },
        {
            "location": "mp/guides/jbatch",
            "text": " In this demonstration you will first create sample input and output records and then the following jobs: MyItemReader MyItemProcessor MyItemWriter Finally you will create MyBatchlet to demonstrate all possible usages of JBatch. 1. Create a unit of input information <markup lang=\"java\" title=\"MyInputRecord\" >public class MyInputRecord { private int id; public MyInputRecord(int id) { this.id = id; } public int getId() { return id; } public void setId(int id) { this.id = id; } @Override public String toString() { return \"MyInputRecord: \" + id; } } 2. Create a unit of output information <markup lang=\"java\" title=\"MyOutputRecord\" >public class MyOutputRecord { private int id; public MyOutputRecord(int id) { this.id = id; } public int getId() { return id; } public void setId(int id) { this.id = id; } @Override public String toString() { return \"MyOutputRecord: \" + id; } } 3. Create MyItemReader to extend AbstractItemReader MyItemReader should look like this: <markup lang=\"java\" title=\"MyItemReader\" >public class MyItemReader extends AbstractItemReader { private final StringTokenizer tokens; public MyItemReader() { tokens = new StringTokenizer(\"1,2,3,4,5,6,7,8,9,10\", \",\"); } /** * Perform read Item. * @return Stage result. */ @Override public MyInputRecord readItem() { if (tokens.hasMoreTokens()) { return new MyInputRecord(Integer.valueOf(tokens.nextToken())); } return null; } } 4. Create MyItemProcessor to implement ItemProcessor The MyItemProcessor will perform some simple operations: <markup lang=\"java\" title=\"MyItemProcessor\" >public class MyItemProcessor implements ItemProcessor { @Override public MyOutputRecord processItem(Object t) { System.out.println(\"processItem: \" + t); return (((MyInputRecord) t).getId() % 2 == 0) ? null : new MyOutputRecord(((MyInputRecord) t).getId() * 2); } } 5. Create MyItemWriter to extend AbstractItemWriter MyItemWriter prints the result: <markup lang=\"java\" title=\"MyItemWriter\" >public class MyItemWriter extends AbstractItemWriter { @Override public void writeItems(List list) { System.out.println(\"writeItems: \" + list); } } 6. Create MyBatchlet to extend AbstractBatchlet MyBatchlet simply completes the process: <markup lang=\"java\" title=\"MyBatchlet\" >public class MyBatchlet extends AbstractBatchlet { @Override public String process() { System.out.println(\"Running inside a batchlet\"); return \"COMPLETED\"; } } ",
            "title": "Add Sample Jobs"
        },
        {
            "location": "mp/guides/jbatch",
            "text": " Add this code to your job descriptor.xml file: <markup lang=\"xml\" title=\"Updated descriptor file\" >&lt;job id=\"myJob\" xmlns=\"https://jakarta.ee/xml/ns/jakartaee\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"https://jakarta.ee/xml/ns/jakartaee https://jakarta.ee/xml/ns/jakartaee/jobXML_2_0.xsd\" version=\"2.0\"&gt; &lt;step id=\"step1\" next=\"step2\"&gt; &lt;chunk item-count=\"3\"&gt; &lt;reader ref=\"io.helidon.jbatch.example.jobs.MyItemReader\"/&gt; &lt;processor ref=\"io.helidon.jbatch.example.jobs.MyItemProcessor\"/&gt; &lt;writer ref=\"io.helidon.jbatch.example.jobs.MyItemWriter\"/&gt; &lt;/chunk&gt; &lt;/step&gt; &lt;step id=\"step2\"&gt; &lt;batchlet ref=\"io.helidon.jbatch.example.jobs.MyBatchlet\"/&gt; &lt;/step&gt; &lt;/job&gt; The first step of the job includes MyItemReader , MyItemProcessor and MyItemWriter . The second step of the job includes MyBatchlet . You must specify the fully qualified names in the ref properties, like “io.helidon.jbatch.example.jobs.MyItemReader”, otherwise it will not work. ",
            "title": "Update the Descriptor File"
        },
        {
            "location": "mp/guides/jbatch",
            "text": " Create a small endpoint to activate the job: <markup lang=\"java\" title=\"new endpoint\" >@Path(\"/batch\") @ApplicationScoped public class BatchResource { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); private JobOperator jobOperator; @GET @Produces(MediaType.APPLICATION_JSON) public JsonObject executeBatch() { BatchSPIManager batchSPIManager = BatchSPIManager.getInstance(); batchSPIManager.registerPlatformMode(BatchSPIManager.PlatformMode.SE); batchSPIManager.registerExecutorServiceProvider(new HelidonExecutorServiceProvider()); jobOperator = getJobOperator(); Long executionId = jobOperator.start(\"myJob\", new Properties()); return JSON.createObjectBuilder() .add(\"Started a job with Execution ID: \", executionId) .build(); } @GET @Path(\"/status/{execution-id}\") public JsonObject status(@PathParam(\"execution-id\") Long executionId){ JobExecution jobExecution = jobOperator.getJobExecution(executionId); List&lt;StepExecution&gt; stepExecutions = jobOperator.getStepExecutions(executionId); List&lt;String&gt; executedSteps = new ArrayList&lt;&gt;(); for (StepExecution stepExecution : stepExecutions) { executedSteps.add(stepExecution.getStepName()); } return JSON.createObjectBuilder() .add(\"Steps executed\", Arrays.toString(executedSteps.toArray())) .add(\"Status\", jobExecution.getBatchStatus().toString()) .build(); } } Helidon specifies to JBatch that it should run in Standalone (SE) mode. It will also register the HelidonExecutorServiceProvider which is actually relatively small. For our example we need something really small, like a FixedTheadPool with 2 threads. This provider is used to tell our JBatch engine exactly which ExecutorService to use. <markup lang=\"java\" title=\"HelidonExecutorServiceProvider\" >public class HelidonExecutorServiceProvider implements ExecutorServiceProvider { @Override public ExecutorService getExecutorService() { return ThreadPoolSupplier.builder().corePoolSize(2).build().get(); } } ",
            "title": "Create an Endpoint"
        },
        {
            "location": "mp/guides/jbatch",
            "text": "<markup lang=\"bash\" >mvn package java -jar target/helidon-jbatch-example.jar ",
            "title": "Run the Code"
        },
        {
            "location": "mp/guides/jbatch",
            "text": "<markup lang=\"bash\" >curl -X GET http://localhost:8080/batch/status/1 In this example the job ID is 1, but make sure that you enter your specific job ID in the string. The results should look something like this: <markup lang=\"bash\" >{\"Steps executed\":\"[step1, step2]\",\"Status\":\"COMPLETED\"} ",
            "title": "Check the Status"
        },
        {
            "location": "mp/guides/jbatch",
            "text": "<markup lang=\"bash\" >curl -X GET http://localhost:8080/batch You should receive the following log: <markup lang=\"bash\" >processItem: MyInputRecord: 1 processItem: MyInputRecord: 2 processItem: MyInputRecord: 3 writeItems: [MyOutputRecord: 2, MyOutputRecord: 6] processItem: MyInputRecord: 4 processItem: MyInputRecord: 5 processItem: MyInputRecord: 6 writeItems: [MyOutputRecord: 10] processItem: MyInputRecord: 7 processItem: MyInputRecord: 8 processItem: MyInputRecord: 9 writeItems: [MyOutputRecord: 14, MyOutputRecord: 18] processItem: MyInputRecord: 10 Running inside a batchlet and the following result: <markup lang=\"bash\" >{\"Started a job with Execution ID: \":1} This indicates that the batch job was called and executed successfully. Check the Status <markup lang=\"bash\" >curl -X GET http://localhost:8080/batch/status/1 In this example the job ID is 1, but make sure that you enter your specific job ID in the string. The results should look something like this: <markup lang=\"bash\" >{\"Steps executed\":\"[step1, step2]\",\"Status\":\"COMPLETED\"} ",
            "title": "Call the Endpoint"
        },
        {
            "location": "mp/guides/jbatch",
            "text": " This guide demonstrated how to use Helidon with JBatch even though Helidon is not a full EE container. ",
            "title": "Summary"
        },
        {
            "location": "mp/guides/jlink-image",
            "text": " This guide describes how to build a custom runtime image for your Helidon application using Helidon&#8217;s support for the JDK&#8217;s jlink tool. ",
            "title": "preambule"
        },
        {
            "location": "mp/guides/jlink-image",
            "text": " JDK 9 introduced the jlink command that supports assembling a set of modules and their dependencies into a custom runtime image. The helidon-maven-plugin has support for easily creating a custom runtime image for your Helidon application resulting in a smaller, better performing runtime. In this guide you will learn how to build a custom runtime image locally on your machine, as well as how to build it in a Docker image. ",
            "title": "Introduction"
        },
        {
            "location": "mp/guides/jlink-image",
            "text": " For this 10 minute tutorial, you will need the following: <div class=\"table__overflow elevation-1 flex sm7 \"> A Helidon MP Application You can use your own application or use the Helidon MP Quickstart to create a sample application. Java&#160;SE&#160;17 ( Open&#160;JDK&#160;17 ) Helidon requires Java 17+. Maven 3.6.1+ Helidon requires Maven 3.6.1+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop . <markup lang=\"bash\" title=\"Verify Prerequisites\" >java -version mvn --version docker --version kubectl version --short <markup lang=\"bash\" title=\"Setting JAVA_HOME\" ># On Mac export JAVA_HOME=`/usr/libexec/java_home -v 17` # On Linux # Use the appropriate path to your JDK export JAVA_HOME=/usr/lib/jvm/jdk-17 ",
            "title": "What You Need"
        },
        {
            "location": "mp/guides/jlink-image",
            "text": " As noted in the prerequisites above, JDK 11 or newer is required. <markup lang=\"bash\" >$JAVA_HOME/bin/java --version Creating a custom runtime image requires that the JDK modules are present as *.jmod files, and some distributions do not provide them by default. Check the jmods directory to ensure they are present: <markup lang=\"bash\" >ls $JAVA_HOME/jmods OpenJDK on Linux RPM based distributions provide *.jmod files in separate java-*-openjdk-jmods packages. Debian based distributions provide *.jmod files only in the openjdk-*-jdk-headless packages. ",
            "title": "Verify JDK"
        },
        {
            "location": "mp/guides/jlink-image",
            "text": " Generate the project using the Helidon MP Quickstart Maven archetype. <markup lang=\"bash\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-mp \\ -DarchetypeVersion=3.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-mp \\ -Dpackage=io.helidon.examples.quickstart.mp The archetype generates a Maven project in your current directory (for example, helidon-quickstart-mp ). Change into this directory and build. <markup lang=\"bash\" >cd helidon-quickstart-mp mvn package At this point you can run the application using the JVM: <markup lang=\"bash\" >java -jar target/helidon-quickstart-mp.jar In another shell test an endpoint: <markup lang=\"bash\" >curl -X GET http://localhost:8080/greet The application should respond with {\"message\":\"Hello World!\"} Now stop the running application (by pressing Ctrl+C). For more information about the Quickstart application and other endpoints it supports see the Helidon MP quickstart Guide . ",
            "title": "Generate the Project"
        },
        {
            "location": "mp/guides/jlink-image",
            "text": " Build the custom runtime image using the jlink image profile: <markup lang=\"bash\" >mvn package -Pjlink-image Tip This uses the helidon-maven-plugin to perform the custom image generation. After the build completes it will report some statistics about the build including the reduction in image size. The target/helidon-quickstart-mp-jri directory is a self contained custom image of your application. It contains your application, its runtime dependencies and the JDK modules it depends on. You can start your application using the provide start script: <markup lang=\"bash\" >./target/helidon-quickstart-mp-jri/bin/start ",
            "title": "Local Build"
        },
        {
            "location": "mp/guides/jlink-image",
            "text": " Also included in the custom image is a Class Data Sharing (CDS) archive that improves your application&#8217;s startup performance and in-memory footprint. You can learn more about Class Data Sharing in the JDK documentation . The CDS archive increases your image size to get these performance optimizations. It can be of significant size (tens of MB). The size of the CDS archive is reported at the end of the build output. If you&#8217;d rather have a smaller image size (with a slightly increased startup time) you can skip the creation of the CDS archive by executing your build like this: <markup lang=\"bash\" >mvn package -Pjlink-image -Djlink.image.addClassDataSharingArchive=false For more information on available configuration options see the helidon-maven-plugin documentation . ",
            "title": "Class Data Sharing (CDS) Archive"
        },
        {
            "location": "mp/guides/jlink-image",
            "text": " To build a Docker image with a custom Java runtime image use the jlink Dockerfile included with the quickstart. <markup lang=\"bash\" >docker build -t helidon-quickstart-mp-jri -f Dockerfile.jlink . Tip This does a full build inside the Docker container. The first time you run it, it will take a while because it is downloading all of the Maven dependencies and caching them in a Docker layer. Subsequent builds will be much faster as long as you don&#8217;t change the pom.xml file. If the pom is modified then the dependencies will be re-downloaded. Start the application: <markup lang=\"bash\" >docker run --rm -p 8080:8080 helidon-quickstart-mp-jri:latest You can exercise the application&#8217;s endpoints as before. ",
            "title": "Multi-Stage Docker Build"
        },
        {
            "location": "mp/guides/jlink-image",
            "text": " You can build a custom runtime image in 2 different ways: Locally, on your desktop Using Docker Local Build Build the custom runtime image using the jlink image profile: <markup lang=\"bash\" >mvn package -Pjlink-image Tip This uses the helidon-maven-plugin to perform the custom image generation. After the build completes it will report some statistics about the build including the reduction in image size. The target/helidon-quickstart-mp-jri directory is a self contained custom image of your application. It contains your application, its runtime dependencies and the JDK modules it depends on. You can start your application using the provide start script: <markup lang=\"bash\" >./target/helidon-quickstart-mp-jri/bin/start Class Data Sharing (CDS) Archive Also included in the custom image is a Class Data Sharing (CDS) archive that improves your application&#8217;s startup performance and in-memory footprint. You can learn more about Class Data Sharing in the JDK documentation . The CDS archive increases your image size to get these performance optimizations. It can be of significant size (tens of MB). The size of the CDS archive is reported at the end of the build output. If you&#8217;d rather have a smaller image size (with a slightly increased startup time) you can skip the creation of the CDS archive by executing your build like this: <markup lang=\"bash\" >mvn package -Pjlink-image -Djlink.image.addClassDataSharingArchive=false For more information on available configuration options see the helidon-maven-plugin documentation . Multi-Stage Docker Build To build a Docker image with a custom Java runtime image use the jlink Dockerfile included with the quickstart. <markup lang=\"bash\" >docker build -t helidon-quickstart-mp-jri -f Dockerfile.jlink . Tip This does a full build inside the Docker container. The first time you run it, it will take a while because it is downloading all of the Maven dependencies and caching them in a Docker layer. Subsequent builds will be much faster as long as you don&#8217;t change the pom.xml file. If the pom is modified then the dependencies will be re-downloaded. Start the application: <markup lang=\"bash\" >docker run --rm -p 8080:8080 helidon-quickstart-mp-jri:latest You can exercise the application&#8217;s endpoints as before. ",
            "title": "Building a Custom Runtime Image"
        },
        {
            "location": "mp/guides/jlink-image",
            "text": " Custom runtime images are ideal for use when you want all of the runtime performance of the JDK JVM in a reasonably compact form. For cases where absolute minimal startup time and image size are required, then consider using GraalVM Native Images . ",
            "title": "Using Custom Runtime Images"
        },
        {
            "location": "mp/guides/maven-build",
            "text": " This guide describes Helidon&#8217;s support for Maven projects. ",
            "title": "preambule"
        },
        {
            "location": "mp/guides/maven-build",
            "text": " Helidon supports Maven by providing the following: The Helidon Application parent POM Dependency management via the Helidon BOM and Dependencies POMs The helidon-maven-plugin ",
            "title": "Introduction"
        },
        {
            "location": "mp/guides/maven-build",
            "text": " Helidon examples and projects generated using the Helidon Quickstart use a Helidon application POM as their parent. This parent POM provides the following: Helidon dependency management. Maven plugin configurations to help in the building and packaging of your Helidon application. If you want to use your own parent POM, then take a look at the standalone quickstart example . This example has a stand-alone POM that you can pattern your own application POM after. For more details on Helidon application POMs see the Helidon&#8217;s Application POMS ",
            "title": "The Helidon Application POM"
        },
        {
            "location": "mp/guides/maven-build",
            "text": " In Maven you use Dependency Management to manage the versions of the dependencies used by your project so that you do not need to specify versions when declaring project dependencies. Helidon provides two POMs that are used together for dependency management: The Helidon Bill of Materials (BOM) POM ( io.helidon:helidon-bom ): manages the version of Helidon artifacts (to align with the Helidon version). The Helidon Dependencies POM ( io.helidon:helidon-dependencies ): manages the versions of third party dependencies to ensure consistency across Helidon and your Helidon application. Inherits the Helidon BOM POM. When you use a Helidon Application POM as your project&#8217;s parent pom, you inherit Helidon&#8217;s dependency management. If you have your own parent, then you can import Helidon dependency management like this: <markup lang=\"xml\" title=\"Import Helidon Dependency Management\" >&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon&lt;/groupId&gt; &lt;artifactId&gt;helidon-dependencies&lt;/artifactId&gt; &lt;version&gt;3.0.2&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; You then declare dependencies on Helidon (and other) components without specifying a version. <markup lang=\"xml\" title=\"Component dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webserver&lt;/groupId&gt; &lt;artifactId&gt;helidon-webserver&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Dependency Management"
        },
        {
            "location": "mp/guides/maven-build",
            "text": " You can override many of the plugin attributes by passing a system property to the mvn command: <markup lang=\"bash\" >mvn -Djlink.image.addClassDataSharingArchive=false package ",
            "title": "Pass Property on Command Line"
        },
        {
            "location": "mp/guides/maven-build",
            "text": " Or you can set the properties in your project&#8217;s pom.xml: <markup lang=\"xml\" >&lt;properties&gt; &lt;jlink.image.addClassDataSharingArchive&gt;false&lt;/jlink.image.addClassDataSharingArchive&gt; &lt;native.image.reportExceptionStackTraces&gt;true&lt;/native.image.reportExceptionStackTraces&gt; &lt;/properties&gt; ",
            "title": "Set Property in pom.xml"
        },
        {
            "location": "mp/guides/maven-build",
            "text": " For full control you can override the plugin&#8217;s configuration using pluginManagement : <markup lang=\"xml\" title=\"Turn off generation of the CDS Archive when generating a custom Java runtime image\" > &lt;build&gt; &lt;pluginManagement&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;io.helidon.build-tools&lt;/groupId&gt; &lt;artifactId&gt;helidon-maven-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;jlink-image&lt;/id&gt; &lt;configuration&gt; &lt;addClassDataSharingArchive&gt;false&lt;/addClassDataSharingArchive&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;/build&gt; <markup lang=\"xml\" title=\"Override final name of native image binary\" > &lt;build&gt; &lt;pluginManagement&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;io.helidon.build-tools&lt;/groupId&gt; &lt;artifactId&gt;helidon-maven-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;native-image&lt;/id&gt; &lt;configuration&gt; &lt;finalName&gt;my-fantastic-service&lt;/finalName&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;/build&gt; ",
            "title": "Override Plugin Configuration using pluginManagement "
        },
        {
            "location": "mp/guides/maven-build",
            "text": " Helidon provides a Maven plugin that, among other things, provides the following goals: native-image: Build a GraalVM native image . jlink-image: Build a custom runtime Java image . For full documentation of the plugin please see the Helidon Maven Plugin README . If you use the Helidon application parent POM you will have this plugin configured for you. If you need to customize the helidon-maven-plugin you can do so in a few ways: Passing system properties to Maven on the command line. Setting system properties in your project&#8217;s pom.xml Overriding the plugin configuration by using pluginManagment Pass Property on Command Line You can override many of the plugin attributes by passing a system property to the mvn command: <markup lang=\"bash\" >mvn -Djlink.image.addClassDataSharingArchive=false package Set Property in pom.xml Or you can set the properties in your project&#8217;s pom.xml: <markup lang=\"xml\" >&lt;properties&gt; &lt;jlink.image.addClassDataSharingArchive&gt;false&lt;/jlink.image.addClassDataSharingArchive&gt; &lt;native.image.reportExceptionStackTraces&gt;true&lt;/native.image.reportExceptionStackTraces&gt; &lt;/properties&gt; Override Plugin Configuration using pluginManagement For full control you can override the plugin&#8217;s configuration using pluginManagement : <markup lang=\"xml\" title=\"Turn off generation of the CDS Archive when generating a custom Java runtime image\" > &lt;build&gt; &lt;pluginManagement&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;io.helidon.build-tools&lt;/groupId&gt; &lt;artifactId&gt;helidon-maven-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;jlink-image&lt;/id&gt; &lt;configuration&gt; &lt;addClassDataSharingArchive&gt;false&lt;/addClassDataSharingArchive&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;/build&gt; <markup lang=\"xml\" title=\"Override final name of native image binary\" > &lt;build&gt; &lt;pluginManagement&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;io.helidon.build-tools&lt;/groupId&gt; &lt;artifactId&gt;helidon-maven-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;native-image&lt;/id&gt; &lt;configuration&gt; &lt;finalName&gt;my-fantastic-service&lt;/finalName&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;/build&gt; ",
            "title": "The helidon-maven-plugin "
        },
        {
            "location": "mp/guides/metrics",
            "text": " This guide describes how to create a sample Helidon MicroProfile (MP) project that can be used to run some basic examples using both built-in and custom metrics with Helidon. ",
            "title": "preambule"
        },
        {
            "location": "mp/guides/metrics",
            "text": " Use the Helidon MP Maven archetype to create a simple project that can be used for the examples in this guide. <markup lang=\"bash\" title=\"Run the Maven archetype\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-mp \\ -DarchetypeVersion=3.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-mp \\ -Dpackage=io.helidon.examples.quickstart.mp ",
            "title": "Create a Sample Helidon MP Project"
        },
        {
            "location": "mp/guides/metrics",
            "text": " Helidon provides three scopes of metrics: base, vendor, and application. Here are the metric endpoints: /metrics/base - Base metrics data as specified by the MicroProfile Metrics specification. /metrics/vendor - Helidon-specific metrics data. /metrics/application - Application-specific metrics data. The /metrics endpoint will return data for all scopes. The built-in metrics fall into three categories: JVM behavior (in the base registry), basic key performance indicators for request handling (in the vendor registry), and thread pool utilization (also in the vendor registry). A later section describes the key performance indicator metrics in detail. The following example demonstrates how to use the other built-in metrics. All examples are executed from the root directory of your project (helidon-quickstart-mp). <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-mp.jar Metrics can be returned in either text format (the default), or JSON. The text format uses OpenMetrics (Prometheus) Text Format, see https://prometheus.io/docs/instrumenting/exposition_formats/#text-format-details . <markup lang=\"bash\" title=\"Verify the metrics endpoint in a new terminal window:\" >curl http://localhost:8080/metrics <markup lang=\"text\" title=\"Text response:\" ># TYPE base_REST_request_total counter # HELP base_REST_request_total The number of invocations and total response time of this RESTful resource method since the start of the server. The metric will not record the elapsed time nor count of a REST request if it resulted in an unmapped exception. Also tracks the highest recorded time duration within the previous completed full minute and lowest recorded time duration within the previous completed full minute. base_REST_request_total{class=\"io.helidon.examples.quickstart.mp.GreetResource\",method=\"getDefaultMessage\"} 0 # TYPE base_REST_request_elapsedTime_seconds gauge base_REST_request_elapsedTime_seconds{class=\"io.helidon.examples.quickstart.mp.GreetResource\",method=\"getDefaultMessage\"} 0.0 # TYPE base_REST_request_maxTimeDuration_seconds gauge base_REST_request_maxTimeDuration_seconds{class=\"io.helidon.examples.quickstart.mp.GreetResource\",method=\"getDefaultMessage\"} NaN # TYPE base_REST_request_minTimeDuration_seconds gauge base_REST_request_minTimeDuration_seconds{class=\"io.helidon.examples.quickstart.mp.GreetResource\",method=\"getDefaultMessage\"} NaN base_REST_request_total{class=\"io.helidon.examples.quickstart.mp.GreetResource\",method=\"getMessage_java.lang.String\"} 0 base_REST_request_elapsedTime_seconds{class=\"io.helidon.examples.quickstart.mp.GreetResource\",method=\"getMessage_java.lang.String\"} 0.0 base_REST_request_maxTimeDuration_seconds{class=\"io.helidon.examples.quickstart.mp.GreetResource\",method=\"getMessage_java.lang.String\"} NaN base_REST_request_minTimeDuration_seconds{class=\"io.helidon.examples.quickstart.mp.GreetResource\",method=\"getMessage_java.lang.String\"} NaN # TYPE base_REST_request_unmappedException_total counter # HELP base_REST_request_unmappedException_total The total number of unmapped exceptions that occur from this RESTful resouce method since the start of the server. base_REST_request_unmappedException_total{class=\"io.helidon.examples.quickstart.mp.GreetResource\",method=\"getDefaultMessage\"} 0 base_REST_request_unmappedException_total{class=\"io.helidon.examples.quickstart.mp.GreetResource\",method=\"getMessage_java.lang.String\"} 0 # TYPE base:classloader_current_loaded_class_count counter # HELP base:classloader_current_loaded_class_count Displays the number of classes that are currently loaded in the Java virtual machine. base:classloader_current_loaded_class_count 7511 # TYPE base:classloader_total_loaded_class_count counter # HELP base:classloader_total_loaded_class_count Displays the total number of classes that have been loaded since the Java virtual machine has started execution. base:classloader_total_loaded_class_count 7512 You can get the same data in JSON format. <markup lang=\"bash\" title=\"Verify the metrics endpoint with an HTTP accept header:\" >curl -H \"Accept: application/json\" http://localhost:8080/metrics <markup lang=\"json\" title=\"JSON response:\" >{ \"base\": { \"REST.request\": { \"count;class=io.helidon.examples.quickstart.mp.GreetResource;method=getDefaultMessage\": 0, \"elapsedTime;class=io.helidon.examples.quickstart.mp.GreetResource;method=getDefaultMessage\": 0, \"maxTimeDuration;class=io.helidon.examples.quickstart.mp.GreetResource;method=getDefaultMessage\": null, \"minTimeDuration;class=io.helidon.examples.quickstart.mp.GreetResource;method=getDefaultMessage\": null, \"count;class=io.helidon.examples.quickstart.mp.GreetResource;method=getMessage_java.lang.String\": 0, \"elapsedTime;class=io.helidon.examples.quickstart.mp.GreetResource;method=getMessage_java.lang.String\": 0, \"maxTimeDuration;class=io.helidon.examples.quickstart.mp.GreetResource;method=getMessage_java.lang.String\": null, \"minTimeDuration;class=io.helidon.examples.quickstart.mp.GreetResource;method=getMessage_java.lang.String\": null, }, \"classloader.currentLoadedClass.count\": 7534, \"classloader.totalLoadedClass.count\": 7538, \"classloader.totalUnloadedClass.count\": 1, \"cpu.availableProcessors\": 4, \"cpu.systemLoadAverage\": 2.83349609375, \"gc.PS MarkSweep.count\": 2, \"gc.PS MarkSweep.time\": 77, \"gc.PS Scavenge.count\": 5, \"gc.PS Scavenge.time\": 37, \"jvm.uptime\": 727588, \"memory.committedHeap\": 284164096, \"memory.maxHeap\": 3817865216, \"memory.usedHeap\": 53283088, \"thread.count\": 44, \"thread.daemon.count\": 35, \"thread.max.count\": 44 }, \"vendor\": { \"executor-service.active-count;poolIndex=0;supplierCategory=helidon-thread-pool-2;supplierIndex=0\": 0, \"executor-service.completed-task-count;poolIndex=0;supplierCategory=helidon-thread-pool-2;supplierIndex=0\": 0, \"executor-service.largest-pool-size;poolIndex=0;supplierCategory=helidon-thread-pool-2;supplierIndex=0\": 5, \"executor-service.pool-size;poolIndex=0;supplierCategory=helidon-thread-pool-2;supplierIndex=0\": 5, \"executor-service.queue.remaining-capacity;poolIndex=0;supplierCategory=helidon-thread-pool-2;supplierIndex=0\": 10000, \"executor-service.queue.size;poolIndex=0;supplierCategory=helidon-thread-pool-2;supplierIndex=0\": 0, \"executor-service.task-count;poolIndex=0;supplierCategory=helidon-thread-pool-2;supplierIndex=0\": 0, \"requests.count\": 6, \"requests.meter\": { \"count\": 6, \"meanRate\": 0.008275992296704147, \"oneMinRate\": 0.01576418632772332, \"fiveMinRate\": 0.006695060022357365, \"fifteenMinRate\": 0.0036382699664488415 } } } You can get a single metric by specifying the name in the URL path. <markup lang=\"bash\" title=\"Get the Helidon requests.meter metric:\" >curl -H \"Accept: application/json\" http://localhost:8080/metrics/vendor/requests.meter <markup lang=\"json\" title=\"JSON response:\" >{ \"requests.meter\": { \"count\": 6, \"meanRate\": 0.008275992296704147, \"oneMinRate\": 0.01576418632772332, \"fiveMinRate\": 0.006695060022357365, \"fifteenMinRate\": 0.0036382699664488415 } } You cannot get the individual fields of a metric. For example, you cannot target http://localhost:8080/metrics/vendor/requests.meter.count . The base metrics illustrated above provide some insight into the behavior of the JVM in which the server runs. The vendor metrics shown above appear in two groups: Helidon thread pools Helidon uses these thread pools for its own internal work, and your application can also use Helidon-managed thread pools if it needs to do work asynchronously. (See this example .) The metrics in this group show information about the thread pools which can help you assess how efficiently they are utilized. Helidon uses tags to distinguish the metrics which describe different thread pools. In some cases the specific metrics exposed depend on the particular type of thread pool. basic key performance indicators These metrics give an idea of the request traffic the server is handling. See the later section for more information on the basic and extended key performance indicator metrics. ",
            "title": "Using the Built-In Metrics"
        },
        {
            "location": "mp/guides/metrics",
            "text": " By default, if your application depends on the helidon-metrics Maven module then full-featured metrics are enabled. You can disable the metrics subsystem entirely using configuration: <markup lang=\"properties\" title=\"Configuration properties file disabling metrics\" >metrics.enabled=false With metrics processing disabled, Helidon never updates any metrics and the /metrics endpoints respond with 404 plus a message that the metrics subsystem is disabled. ",
            "title": "Disabling Metrics Subsystem Entirely"
        },
        {
            "location": "mp/guides/metrics",
            "text": " Any time you include the Helidon metrics module in your application, Helidon tracks two basic performance indicator metrics: a Counter of all requests received ( requests.count ), and a Meter of all requests received ( requests.meter ). Helidon MP also includes additional, extended KPI metrics which are disabled by default: current number of requests in-flight - a ConcurrentGauge ( requests.inFlight ) of requests currently being processed long-running requests - a Meter ( requests.longRunning ) measuring the rate at which Helidon processes requests which take at least a given amount of time to complete; configurable, defaults to 10000 milliseconds (10 seconds) load - a Meter ( requests.load ) measuring the rate at which requests are worked on (as opposed to received) deferred - a Meter ( requests.deferred ) measuring the rate at which a request&#8217;s processing is delayed after Helidon receives the request You can enable and control these metrics using configuration: <markup lang=\"properties\" title=\"Configuration properties file controlling extended KPI metrics\" >metrics.key-performance-indicators.extended = true metrics.key-performance-indicators.long-running.threshold-ms = 2000 ",
            "title": "Collecting Basic and Extended Key Performance Indicator (KPI) Metrics"
        },
        {
            "location": "mp/guides/metrics",
            "text": " Helidon implements the optional family of metrics, all with the name REST.request , as described in the MicroProfile Metrics specification . Each instance is a SimpleTimer with tags class and method identifying exactly which REST endpoint Java method that instance measures. By default, Helidon MP does not enable this feature. Enable it by editing your application configuration to set metrics.rest-request.enabled to true . Note that the applications you generate using the full Helidon archetype do enable this feature in the generated config file. You can see the results in the sample output shown in earlier example runs. ",
            "title": "Controlling REST.request Metrics"
        },
        {
            "location": "mp/guides/metrics",
            "text": " Helidon contains several components and integrations which register and update metrics. Depending on how the component is written, you might be able to disable just that component&#8217;s use of metrics: <markup lang=\"properties\" title=\"Configuration properties file disabling a component&#8217;s use of metrics\" >some-component.metrics.enabled=false Check the documentation for a specific component to find out whether that component uses metrics and whether it allows you to disable that use. If you disable a component&#8217;s use of metrics, Helidon does not register the component&#8217;s metrics in the visible metrics registries nor do those metrics ever update their values. The response from the /metrics endpoint excludes that component&#8217;s metrics. Note that if you disable metrics processing entirely, no component updates its metrics regardless of any component-level metrics settings. ",
            "title": "Enabling and Disabling Metrics Usage by a Component"
        },
        {
            "location": "mp/guides/metrics",
            "text": " To disable all metrics in a given registry type (application, vendor, or base), add one or more groups to the configuration: <markup lang=\"properties\" title=\"Disabling base and vendor metrics (properties format)\" >metrics.registries.0.type = base metrics.registries.0.enabled = false metrics.registries.1.type = vendor metrics.registries.1.enabled = false <markup lang=\"yaml\" title=\"Disabling base and vendor metrics (YAML format)\" >metrics: registries: - type: base enabled: false - type: vendor enables: false ",
            "title": "Disabling All Metrics of a Given Registry Type"
        },
        {
            "location": "mp/guides/metrics",
            "text": " You can be even more selective. Within a registry type you can configure up to two regular expression patterns: one matching metric names to exclude , and one matching metric names to include . Helidon updates and reports a metric only if two conditions hold: the metric name does not match the exclude regex pattern (if you define one), and either there is no include regex pattern, or the metric name matches the include pattern. Caution Make sure any include regex pattern you specify matches all the metric names you want to capture. Suppose your application creates and updates a group of metrics with names such as myapp.xxx.queries , myapp.xxx.creates , myapp.xxx.updates , and myapp.xxx.deletes where xxx can be either supplier or customer . The following example gathers all metrics except those from your application regarding suppliers: <markup lang=\"properties\" title=\"Disabling metrics by name (properties format)\" >metrics.registries.0.type = application metrics.registries.0.filter.exclude = myapp\\.supplier\\..* The following settings select the particular subset of the metrics created in your application code representing updates of customers and suppliers: <markup lang=\"properties\" title=\"Enabling metrics by name (properties format)\" >metrics.registries.0.type = application metrics.registries.0.filter.include = myapp\\..*\\.updates If you use the YAML configuration format, enclose the regex patterns in single-quote marks: <markup lang=\"yaml\" title=\"Enabling metrics by name (YAML format)\" >metrics: registries: - type: application filter: include: 'myapp\\..*\\.updates' The next example selects only your application&#8217;s metrics while excluding those which refer to deletions: <markup lang=\"properties\" title=\"Combining include and exclude \" >metrics.registries.0.type = application metrics.registries.0.filter.include = myapp\\..* metrics.registries.0.filter.exclude = myapp\\..*/deletes Helidon would not update or report the metric myapp.supplier.queries , for example. To include metrics from your application for both updates and queries (but not for other operations), you could change the settings in the previous example to this: <markup >metrics.registries.0.type = application metrics.registries.0.filter.include = myapp\\..*\\.updates|myapp\\..*\\.queries metrics.registries.0.filter.exclude = myapp\\..*/deletes ",
            "title": "Controlling Metrics by Metric Name"
        },
        {
            "location": "mp/guides/metrics",
            "text": " You can control the collection and reporting of metrics by registry type and metric name within registry type. Disabling All Metrics of a Given Registry Type To disable all metrics in a given registry type (application, vendor, or base), add one or more groups to the configuration: <markup lang=\"properties\" title=\"Disabling base and vendor metrics (properties format)\" >metrics.registries.0.type = base metrics.registries.0.enabled = false metrics.registries.1.type = vendor metrics.registries.1.enabled = false <markup lang=\"yaml\" title=\"Disabling base and vendor metrics (YAML format)\" >metrics: registries: - type: base enabled: false - type: vendor enables: false Controlling Metrics by Metric Name You can be even more selective. Within a registry type you can configure up to two regular expression patterns: one matching metric names to exclude , and one matching metric names to include . Helidon updates and reports a metric only if two conditions hold: the metric name does not match the exclude regex pattern (if you define one), and either there is no include regex pattern, or the metric name matches the include pattern. Caution Make sure any include regex pattern you specify matches all the metric names you want to capture. Suppose your application creates and updates a group of metrics with names such as myapp.xxx.queries , myapp.xxx.creates , myapp.xxx.updates , and myapp.xxx.deletes where xxx can be either supplier or customer . The following example gathers all metrics except those from your application regarding suppliers: <markup lang=\"properties\" title=\"Disabling metrics by name (properties format)\" >metrics.registries.0.type = application metrics.registries.0.filter.exclude = myapp\\.supplier\\..* The following settings select the particular subset of the metrics created in your application code representing updates of customers and suppliers: <markup lang=\"properties\" title=\"Enabling metrics by name (properties format)\" >metrics.registries.0.type = application metrics.registries.0.filter.include = myapp\\..*\\.updates If you use the YAML configuration format, enclose the regex patterns in single-quote marks: <markup lang=\"yaml\" title=\"Enabling metrics by name (YAML format)\" >metrics: registries: - type: application filter: include: 'myapp\\..*\\.updates' The next example selects only your application&#8217;s metrics while excluding those which refer to deletions: <markup lang=\"properties\" title=\"Combining include and exclude \" >metrics.registries.0.type = application metrics.registries.0.filter.include = myapp\\..* metrics.registries.0.filter.exclude = myapp\\..*/deletes Helidon would not update or report the metric myapp.supplier.queries , for example. To include metrics from your application for both updates and queries (but not for other operations), you could change the settings in the previous example to this: <markup >metrics.registries.0.type = application metrics.registries.0.filter.include = myapp\\..*\\.updates|myapp\\..*\\.queries metrics.registries.0.filter.exclude = myapp\\..*/deletes ",
            "title": "Controlling Metrics By Registry Type and Metric Name"
        },
        {
            "location": "mp/guides/metrics",
            "text": " By adding a metrics section to your application configuration you can control how the Helidon metrics subsystem behaves in any of several ways. Disable metrics subsystem entirely . Control REST.request metrics. Identify groups of metrics to control: registered by a particular component , and by metric registry (application, vendor, and base) and within a registry by metric names which match patterns you provide. Select whether to collect extended key performance indicator metrics . Disabling Metrics Subsystem Entirely By default, if your application depends on the helidon-metrics Maven module then full-featured metrics are enabled. You can disable the metrics subsystem entirely using configuration: <markup lang=\"properties\" title=\"Configuration properties file disabling metrics\" >metrics.enabled=false With metrics processing disabled, Helidon never updates any metrics and the /metrics endpoints respond with 404 plus a message that the metrics subsystem is disabled. Collecting Basic and Extended Key Performance Indicator (KPI) Metrics Any time you include the Helidon metrics module in your application, Helidon tracks two basic performance indicator metrics: a Counter of all requests received ( requests.count ), and a Meter of all requests received ( requests.meter ). Helidon MP also includes additional, extended KPI metrics which are disabled by default: current number of requests in-flight - a ConcurrentGauge ( requests.inFlight ) of requests currently being processed long-running requests - a Meter ( requests.longRunning ) measuring the rate at which Helidon processes requests which take at least a given amount of time to complete; configurable, defaults to 10000 milliseconds (10 seconds) load - a Meter ( requests.load ) measuring the rate at which requests are worked on (as opposed to received) deferred - a Meter ( requests.deferred ) measuring the rate at which a request&#8217;s processing is delayed after Helidon receives the request You can enable and control these metrics using configuration: <markup lang=\"properties\" title=\"Configuration properties file controlling extended KPI metrics\" >metrics.key-performance-indicators.extended = true metrics.key-performance-indicators.long-running.threshold-ms = 2000 Controlling REST.request Metrics Helidon implements the optional family of metrics, all with the name REST.request , as described in the MicroProfile Metrics specification . Each instance is a SimpleTimer with tags class and method identifying exactly which REST endpoint Java method that instance measures. By default, Helidon MP does not enable this feature. Enable it by editing your application configuration to set metrics.rest-request.enabled to true . Note that the applications you generate using the full Helidon archetype do enable this feature in the generated config file. You can see the results in the sample output shown in earlier example runs. Enabling and Disabling Metrics Usage by a Component Helidon contains several components and integrations which register and update metrics. Depending on how the component is written, you might be able to disable just that component&#8217;s use of metrics: <markup lang=\"properties\" title=\"Configuration properties file disabling a component&#8217;s use of metrics\" >some-component.metrics.enabled=false Check the documentation for a specific component to find out whether that component uses metrics and whether it allows you to disable that use. If you disable a component&#8217;s use of metrics, Helidon does not register the component&#8217;s metrics in the visible metrics registries nor do those metrics ever update their values. The response from the /metrics endpoint excludes that component&#8217;s metrics. Note that if you disable metrics processing entirely, no component updates its metrics regardless of any component-level metrics settings. Controlling Metrics By Registry Type and Metric Name You can control the collection and reporting of metrics by registry type and metric name within registry type. Disabling All Metrics of a Given Registry Type To disable all metrics in a given registry type (application, vendor, or base), add one or more groups to the configuration: <markup lang=\"properties\" title=\"Disabling base and vendor metrics (properties format)\" >metrics.registries.0.type = base metrics.registries.0.enabled = false metrics.registries.1.type = vendor metrics.registries.1.enabled = false <markup lang=\"yaml\" title=\"Disabling base and vendor metrics (YAML format)\" >metrics: registries: - type: base enabled: false - type: vendor enables: false Controlling Metrics by Metric Name You can be even more selective. Within a registry type you can configure up to two regular expression patterns: one matching metric names to exclude , and one matching metric names to include . Helidon updates and reports a metric only if two conditions hold: the metric name does not match the exclude regex pattern (if you define one), and either there is no include regex pattern, or the metric name matches the include pattern. Caution Make sure any include regex pattern you specify matches all the metric names you want to capture. Suppose your application creates and updates a group of metrics with names such as myapp.xxx.queries , myapp.xxx.creates , myapp.xxx.updates , and myapp.xxx.deletes where xxx can be either supplier or customer . The following example gathers all metrics except those from your application regarding suppliers: <markup lang=\"properties\" title=\"Disabling metrics by name (properties format)\" >metrics.registries.0.type = application metrics.registries.0.filter.exclude = myapp\\.supplier\\..* The following settings select the particular subset of the metrics created in your application code representing updates of customers and suppliers: <markup lang=\"properties\" title=\"Enabling metrics by name (properties format)\" >metrics.registries.0.type = application metrics.registries.0.filter.include = myapp\\..*\\.updates If you use the YAML configuration format, enclose the regex patterns in single-quote marks: <markup lang=\"yaml\" title=\"Enabling metrics by name (YAML format)\" >metrics: registries: - type: application filter: include: 'myapp\\..*\\.updates' The next example selects only your application&#8217;s metrics while excluding those which refer to deletions: <markup lang=\"properties\" title=\"Combining include and exclude \" >metrics.registries.0.type = application metrics.registries.0.filter.include = myapp\\..* metrics.registries.0.filter.exclude = myapp\\..*/deletes Helidon would not update or report the metric myapp.supplier.queries , for example. To include metrics from your application for both updates and queries (but not for other operations), you could change the settings in the previous example to this: <markup >metrics.registries.0.type = application metrics.registries.0.filter.include = myapp\\..*\\.updates|myapp\\..*\\.queries metrics.registries.0.filter.exclude = myapp\\..*/deletes ",
            "title": "Controlling Metrics Behavior"
        },
        {
            "location": "mp/guides/metrics",
            "text": " Each metric has associated metadata that describes: name: The name of the metric. units: The unit of the metric such as time (seconds, millisecond), size (bytes, megabytes), etc. type: The type of metric: Counter , Timer , Meter , Histogram , SimpleTimer , or Gauge . You can get the metadata for any scope, such as /metrics/base , as shown below: <markup lang=\"bash\" title=\"Get the metrics metadata using HTTP OPTIONS method:\" > curl -X OPTIONS -H \"Accept: application/json\" http://localhost:8080/metrics/base <markup lang=\"json\" title=\"JSON response (truncated):\" >{ \"classloader.currentLoadedClass.count\": { \"unit\": \"none\", \"type\": \"counter\", \"description\": \"Displays the number of classes that are currently loaded in the Java virtual machine.\", \"displayName\": \"Current Loaded Class Count\" }, \"jvm.uptime\": { \"unit\": \"milliseconds\", \"type\": \"gauge\", \"description\": \"Displays the start time of the Java virtual machine in milliseconds. This attribute displays the approximate time when the Java virtual machine started.\", \"displayName\": \"JVM Uptime\" }, \"memory.usedHeap\": { \"unit\": \"bytes\", \"type\": \"gauge\", \"description\": \"Displays the amount of used heap memory in bytes.\", \"displayName\": \"Used Heap Memory\" } } ",
            "title": "Metrics Metadata"
        },
        {
            "location": "mp/guides/metrics",
            "text": " There are four metrics that you can use by annotating a method: @Counted - Register a Counter metric @Timed - Register a Timer metric @Metered - Register a Meter metric @SimplyTimed - Register a SimpleTimer metric The following example will demonstrate how to use the @Counted annotation to track the number of times the /cards endpoint is called. <markup lang=\"java\" title=\"Create a new class GreetingCards with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import jakarta.enterprise.context.RequestScoped; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.annotation.Counted; @Path(\"/cards\") @RequestScoped public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"any-card\") public JsonObject anyCard() throws InterruptedException { return createResponse(\"Here are some random cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } } This class is annotated with Path which sets the path for this resource as /cards . The @RequestScoped annotation defines that this bean is request scoped. The request scope is active only for the duration of one web service invocation and it is destroyed at the end of that invocation. The annotation @Counted will register a Counter metric for this method, creating it if needed. The counter is incremented each time the anyCards method is called. The name attribute is optional. For Metrics 1.1, you must set monotonic field to true to force the count to increment when entering the method. The default behavior is to decrement when exiting the method. Here is an example: @Counted(name = \"any-card\", monotonic = true) . <markup lang=\"bash\" title=\"Build and run the application, then invoke the application endpoints below:\" >curl http://localhost:8080/cards curl http://localhost:8080/cards curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response:\" >{ \"io.helidon.examples.quickstart.mp.GreetingCards.any-card\":2 } The any-card count is two, since you invoked the endpoint twice. Notice the counter is fully qualified. You can remove the package prefix by using the absolute=true field in the @Counted annotation. You must use absolute=false for class-level annotations. ",
            "title": "Method Level Metrics"
        },
        {
            "location": "mp/guides/metrics",
            "text": " The @Timed , @Metered , and @SimplyTimed annotations can also be used with a method. For the following example. you can just annotate the same method with @Metered and @Timed . These metrics collect significant information about the measured methods, but at a cost of some overhead and more complicated output. Use @SimplyTimed in cases where capturing the invocation count and the total elapsed time spent in a block of code is sufficient. Note that when using multiple annotations on a method, you must give the metrics different names as shown below. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import jakarta.enterprise.context.RequestScoped; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.MetricUnits; import org.eclipse.microprofile.metrics.annotation.Counted; import org.eclipse.microprofile.metrics.annotation.Metered; import org.eclipse.microprofile.metrics.annotation.Timed; @Path(\"/cards\") @RequestScoped public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"cardCount\", absolute = true) @Metered(name = \"cardMeter\", absolute = true, unit = MetricUnits.MILLISECONDS) @Timed(name = \"cardTimer\", absolute = true, unit = MetricUnits.MILLISECONDS) public JsonObject anyCard() { return createResponse(\"Here are some random cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } } Specify a custom name for the Counter metric and set absolute=true to remove the path prefix from the name. Add the @Metered annotation to get a Meter metric. Add the @Timed annotation to get a Timer metric. <markup lang=\"bash\" title=\"Build and run the application, then invoke the application endpoints below:\" >curl http://localhost:8080/cards curl http://localhost:8080/cards curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response:\" >{ \"cardCount\": 2, \"cardMeter\": { \"count\": 2, \"meanRate\": 0.15653506570241812, \"oneMinRate\": 0, \"fiveMinRate\": 0, \"fifteenMinRate\": 0 }, \"cardTimer\": { \"count\": 2, \"elapsedTime\": 2, \"meanRate\": 0.15651866263362785, \"oneMinRate\": 0, \"fiveMinRate\": 0, \"fifteenMinRate\": 0, \"min\": 0, \"max\": 2, \"mean\": 1.0506565, \"stddev\": 1.0405735, \"p50\": 2.09123, \"p75\": 2.09123, \"p95\": 2.09123, \"p98\": 2.09123, \"p99\": 2.09123, \"p999\": 2.09123 } } The Meter metric includes the count field (it is a superset of Counter ). The Timer metric includes the Meter fields (it is a superset of Meter ). ",
            "title": "Additional Method Level Metrics"
        },
        {
            "location": "mp/guides/metrics",
            "text": " You can share a metric across multiple endpoints simply by specifying the same metric annotation as demonstrated below. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import jakarta.enterprise.context.RequestScoped; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.annotation.Counted; @Path(\"/cards\") @RequestScoped public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"anyCard\", absolute = true) public JsonObject anyCard() throws InterruptedException { return createResponse(\"Here are some cards ...\"); } @GET @Path(\"/birthday\") @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"specialEventCard\", absolute = true) public JsonObject birthdayCard() throws InterruptedException { return createResponse(\"Here are some birthday cards ...\"); } @GET @Path(\"/wedding\") @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"specialEventCard\", absolute = true) public JsonObject weddingCard() throws InterruptedException { return createResponse(\"Here are some wedding cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } } The /birthday endpoint uses a Counter metric, named specialEventCard . The /wedding endpoint uses the same Counter metric, named specialEventCard . <markup lang=\"bash\" title=\"Build and run the application, then invoke the following endpoints:\" >curl http://localhost:8080/cards/wedding curl http://localhost:8080/cards/birthday curl http://localhost:8080/cards curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response from /metrics/application :\" >{ \"anyCard\": 1, \"specialEventCard\": 2 } Notice that specialEventCard count is two, since you accessed /cards/wedding and /cards/birthday . ",
            "title": "Reusing Metrics"
        },
        {
            "location": "mp/guides/metrics",
            "text": " You can collect metrics at the class-level to aggregate data from all methods in that class using the same metric. The following example introduces a metric to count all card queries. In the following example, the method-level metrics are not needed to aggregate the counts, but they are left in the example to demonstrate the combined output of all three metrics. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import jakarta.enterprise.context.RequestScoped; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.annotation.Counted; @Path(\"/cards\") @RequestScoped @Counted(name = \"totalCards\") public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) @Counted(absolute = true) public JsonObject anyCard() throws InterruptedException { return createResponse(\"Here are some random cards ...\"); } @Path(\"/birthday\") @GET @Produces(MediaType.APPLICATION_JSON) @Counted(absolute = true) public JsonObject birthdayCard() throws InterruptedException { return createResponse(\"Here are some birthday cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } } This class is annotated with @Counted , which aggregates count data from all the method that have a Count annotation. Use absolute=true to remove path prefix for method-level annotations. Add a method with a Counter metric to get birthday cards. <markup lang=\"bash\" title=\"Build and run the application, then invoke the following endpoints:\" >curl http://localhost:8080/cards curl http://localhost:8080/cards/birthday curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response from /metrics/application :\" >{ \"anyCard\": 1, \"birthdayCard\": 1, \"io.helidon.examples.quickstart.mp.totalCards.GreetingCards\": 2 } The totalCards count is a total of all the method-level Counter metrics. Class level metric names are always fully qualified. ",
            "title": "Class Level Metrics"
        },
        {
            "location": "mp/guides/metrics",
            "text": " Field level metrics can be injected into managed objects, but they need to be updated by the application code. This annotation can be used on fields of type Meter , Timer , Counter , and Histogram . The following example shows how to use a field-level Counter metric to track cache hits. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import java.util.Random; import jakarta.enterprise.context.RequestScoped; import jakarta.inject.Inject; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.Counter; import org.eclipse.microprofile.metrics.annotation.Counted; import org.eclipse.microprofile.metrics.annotation.Metric; @Path(\"/cards\") @RequestScoped @Counted(name = \"totalCards\") public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @Inject @Metric(name = \"cacheHits\", absolute = true) private Counter cacheHits; @GET @Produces(MediaType.APPLICATION_JSON) @Counted(absolute = true) public JsonObject anyCard() throws InterruptedException { updateStats(); return createResponse(\"Here are some random cards ...\"); } @Path(\"/birthday\") @GET @Produces(MediaType.APPLICATION_JSON) @Counted(absolute = true) public JsonObject birthdayCard() throws InterruptedException { updateStats(); return createResponse(\"Here are some birthday cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } private void updateStats() { if (new Random().nextInt(3) == 1) { cacheHits.inc(); } } } A Counter metric field, cacheHits , is automatically injected by Helidon. Call updateStats() to update the cache hits. Call updateStats() to update the cache hits. Randomly increment the cacheHits counter. <markup lang=\"bash\" title=\"Build and run the application, then invoke the following endpoints:\" >curl http://localhost:8080/cards curl http://localhost:8080/cards curl http://localhost:8080/cards/birthday curl http://localhost:8080/cards/birthday curl http://localhost:8080/cards/birthday curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response from /metrics/application :\" >{ \"anyCard\": 2, \"birthdayCard\": 3, \"cacheHits\": 2, \"io.helidon.examples.quickstart.mp.totalCards.GreetingCards\": 5 } The cache was hit two times out of five queries. ",
            "title": "Field Level Metrics"
        },
        {
            "location": "mp/guides/metrics",
            "text": " The metrics you have tested so far are updated in response to an application REST request, i.e GET /cards . These metrics can be declared in a request scoped class and Helidon will store the metric in the MetricRegistry , so the value persists across requests. When GET /metrics/application is invoked, Helidon will return the current value of the metric stored in the MetricRegistry . The Gauge metric is different from all the other metrics. The application must provide a getter to return the gauge value in an application scoped class. When GET /metrics/application is invoked, Helidon will call the Gauge getter, store that value in the MetricsRegistry , and return it as part of the metrics response payload. So, the Gauge metric value is updated real-time, in response to the get metrics request. The following example demonstrates how to use a Gauge to track application up-time. <markup lang=\"java\" title=\"Create a new GreetingCardsAppMetrics class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.time.Duration; import java.util.concurrent.atomic.AtomicLong; import jakarta.enterprise.context.ApplicationScoped; import jakarta.enterprise.context.Initialized; import jakarta.enterprise.event.Observes; import org.eclipse.microprofile.metrics.annotation.Gauge; @ApplicationScoped public class GreetingCardsAppMetrics { private AtomicLong startTime = new AtomicLong(0); public void onStartUp(@Observes @Initialized(ApplicationScoped.class) Object init) { startTime = new AtomicLong(System.currentTimeMillis()); } @Gauge(unit = \"TimeSeconds\") public long appUpTimeSeconds() { return Duration.ofMillis(System.currentTimeMillis() - startTime.get()).getSeconds(); } } This managed object must be application scoped to properly register and use the Gauge metric. Declare an AtomicLong field to hold the start time of the application. Initialize the application start time. Return the application appUpTimeSeconds metric, which will be included in the application metrics. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code to simplify the metrics output:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import jakarta.enterprise.context.RequestScoped; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.annotation.Counted; @Path(\"/cards\") @RequestScoped public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"cardCount\", absolute = true) public JsonObject anyCard() throws InterruptedException { return createResponse(\"Here are some random cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } } <markup lang=\"bash\" title=\"Build and run the application, then invoke the application metrics endpoint:\" >curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response from /metrics/application :\" >{ \"cardCount\": 0, \"io.helidon.examples.quickstart.mp.GreetingCardsAppMetrics.appUpTimeSeconds\": 6 } The application has been running for 6 seconds. ",
            "title": "Gauge Metric"
        },
        {
            "location": "mp/guides/metrics",
            "text": " You can create application-specific metrics and integrate them with Helidon using CDI. To add a new metric, simply annotate the JAX-RS resource with one of the metric annotations. Metrics can be injected at the class, method, and field-levels. This document shows examples of all three. Helidon will automatically create and register annotated application metrics and store them in the application MetricRegistry , which also contains the metric metadata. The metrics will exist for the lifetime of the application. Each metric annotation has mandatory and optional fields. The name field, for example, is optional. Method Level Metrics There are four metrics that you can use by annotating a method: @Counted - Register a Counter metric @Timed - Register a Timer metric @Metered - Register a Meter metric @SimplyTimed - Register a SimpleTimer metric The following example will demonstrate how to use the @Counted annotation to track the number of times the /cards endpoint is called. <markup lang=\"java\" title=\"Create a new class GreetingCards with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import jakarta.enterprise.context.RequestScoped; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.annotation.Counted; @Path(\"/cards\") @RequestScoped public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"any-card\") public JsonObject anyCard() throws InterruptedException { return createResponse(\"Here are some random cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } } This class is annotated with Path which sets the path for this resource as /cards . The @RequestScoped annotation defines that this bean is request scoped. The request scope is active only for the duration of one web service invocation and it is destroyed at the end of that invocation. The annotation @Counted will register a Counter metric for this method, creating it if needed. The counter is incremented each time the anyCards method is called. The name attribute is optional. For Metrics 1.1, you must set monotonic field to true to force the count to increment when entering the method. The default behavior is to decrement when exiting the method. Here is an example: @Counted(name = \"any-card\", monotonic = true) . <markup lang=\"bash\" title=\"Build and run the application, then invoke the application endpoints below:\" >curl http://localhost:8080/cards curl http://localhost:8080/cards curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response:\" >{ \"io.helidon.examples.quickstart.mp.GreetingCards.any-card\":2 } The any-card count is two, since you invoked the endpoint twice. Notice the counter is fully qualified. You can remove the package prefix by using the absolute=true field in the @Counted annotation. You must use absolute=false for class-level annotations. Additional Method Level Metrics The @Timed , @Metered , and @SimplyTimed annotations can also be used with a method. For the following example. you can just annotate the same method with @Metered and @Timed . These metrics collect significant information about the measured methods, but at a cost of some overhead and more complicated output. Use @SimplyTimed in cases where capturing the invocation count and the total elapsed time spent in a block of code is sufficient. Note that when using multiple annotations on a method, you must give the metrics different names as shown below. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import jakarta.enterprise.context.RequestScoped; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.MetricUnits; import org.eclipse.microprofile.metrics.annotation.Counted; import org.eclipse.microprofile.metrics.annotation.Metered; import org.eclipse.microprofile.metrics.annotation.Timed; @Path(\"/cards\") @RequestScoped public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"cardCount\", absolute = true) @Metered(name = \"cardMeter\", absolute = true, unit = MetricUnits.MILLISECONDS) @Timed(name = \"cardTimer\", absolute = true, unit = MetricUnits.MILLISECONDS) public JsonObject anyCard() { return createResponse(\"Here are some random cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } } Specify a custom name for the Counter metric and set absolute=true to remove the path prefix from the name. Add the @Metered annotation to get a Meter metric. Add the @Timed annotation to get a Timer metric. <markup lang=\"bash\" title=\"Build and run the application, then invoke the application endpoints below:\" >curl http://localhost:8080/cards curl http://localhost:8080/cards curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response:\" >{ \"cardCount\": 2, \"cardMeter\": { \"count\": 2, \"meanRate\": 0.15653506570241812, \"oneMinRate\": 0, \"fiveMinRate\": 0, \"fifteenMinRate\": 0 }, \"cardTimer\": { \"count\": 2, \"elapsedTime\": 2, \"meanRate\": 0.15651866263362785, \"oneMinRate\": 0, \"fiveMinRate\": 0, \"fifteenMinRate\": 0, \"min\": 0, \"max\": 2, \"mean\": 1.0506565, \"stddev\": 1.0405735, \"p50\": 2.09123, \"p75\": 2.09123, \"p95\": 2.09123, \"p98\": 2.09123, \"p99\": 2.09123, \"p999\": 2.09123 } } The Meter metric includes the count field (it is a superset of Counter ). The Timer metric includes the Meter fields (it is a superset of Meter ). Reusing Metrics You can share a metric across multiple endpoints simply by specifying the same metric annotation as demonstrated below. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import jakarta.enterprise.context.RequestScoped; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.annotation.Counted; @Path(\"/cards\") @RequestScoped public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"anyCard\", absolute = true) public JsonObject anyCard() throws InterruptedException { return createResponse(\"Here are some cards ...\"); } @GET @Path(\"/birthday\") @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"specialEventCard\", absolute = true) public JsonObject birthdayCard() throws InterruptedException { return createResponse(\"Here are some birthday cards ...\"); } @GET @Path(\"/wedding\") @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"specialEventCard\", absolute = true) public JsonObject weddingCard() throws InterruptedException { return createResponse(\"Here are some wedding cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } } The /birthday endpoint uses a Counter metric, named specialEventCard . The /wedding endpoint uses the same Counter metric, named specialEventCard . <markup lang=\"bash\" title=\"Build and run the application, then invoke the following endpoints:\" >curl http://localhost:8080/cards/wedding curl http://localhost:8080/cards/birthday curl http://localhost:8080/cards curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response from /metrics/application :\" >{ \"anyCard\": 1, \"specialEventCard\": 2 } Notice that specialEventCard count is two, since you accessed /cards/wedding and /cards/birthday . Class Level Metrics You can collect metrics at the class-level to aggregate data from all methods in that class using the same metric. The following example introduces a metric to count all card queries. In the following example, the method-level metrics are not needed to aggregate the counts, but they are left in the example to demonstrate the combined output of all three metrics. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import jakarta.enterprise.context.RequestScoped; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.annotation.Counted; @Path(\"/cards\") @RequestScoped @Counted(name = \"totalCards\") public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) @Counted(absolute = true) public JsonObject anyCard() throws InterruptedException { return createResponse(\"Here are some random cards ...\"); } @Path(\"/birthday\") @GET @Produces(MediaType.APPLICATION_JSON) @Counted(absolute = true) public JsonObject birthdayCard() throws InterruptedException { return createResponse(\"Here are some birthday cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } } This class is annotated with @Counted , which aggregates count data from all the method that have a Count annotation. Use absolute=true to remove path prefix for method-level annotations. Add a method with a Counter metric to get birthday cards. <markup lang=\"bash\" title=\"Build and run the application, then invoke the following endpoints:\" >curl http://localhost:8080/cards curl http://localhost:8080/cards/birthday curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response from /metrics/application :\" >{ \"anyCard\": 1, \"birthdayCard\": 1, \"io.helidon.examples.quickstart.mp.totalCards.GreetingCards\": 2 } The totalCards count is a total of all the method-level Counter metrics. Class level metric names are always fully qualified. Field Level Metrics Field level metrics can be injected into managed objects, but they need to be updated by the application code. This annotation can be used on fields of type Meter , Timer , Counter , and Histogram . The following example shows how to use a field-level Counter metric to track cache hits. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import java.util.Random; import jakarta.enterprise.context.RequestScoped; import jakarta.inject.Inject; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.Counter; import org.eclipse.microprofile.metrics.annotation.Counted; import org.eclipse.microprofile.metrics.annotation.Metric; @Path(\"/cards\") @RequestScoped @Counted(name = \"totalCards\") public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @Inject @Metric(name = \"cacheHits\", absolute = true) private Counter cacheHits; @GET @Produces(MediaType.APPLICATION_JSON) @Counted(absolute = true) public JsonObject anyCard() throws InterruptedException { updateStats(); return createResponse(\"Here are some random cards ...\"); } @Path(\"/birthday\") @GET @Produces(MediaType.APPLICATION_JSON) @Counted(absolute = true) public JsonObject birthdayCard() throws InterruptedException { updateStats(); return createResponse(\"Here are some birthday cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } private void updateStats() { if (new Random().nextInt(3) == 1) { cacheHits.inc(); } } } A Counter metric field, cacheHits , is automatically injected by Helidon. Call updateStats() to update the cache hits. Call updateStats() to update the cache hits. Randomly increment the cacheHits counter. <markup lang=\"bash\" title=\"Build and run the application, then invoke the following endpoints:\" >curl http://localhost:8080/cards curl http://localhost:8080/cards curl http://localhost:8080/cards/birthday curl http://localhost:8080/cards/birthday curl http://localhost:8080/cards/birthday curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response from /metrics/application :\" >{ \"anyCard\": 2, \"birthdayCard\": 3, \"cacheHits\": 2, \"io.helidon.examples.quickstart.mp.totalCards.GreetingCards\": 5 } The cache was hit two times out of five queries. Gauge Metric The metrics you have tested so far are updated in response to an application REST request, i.e GET /cards . These metrics can be declared in a request scoped class and Helidon will store the metric in the MetricRegistry , so the value persists across requests. When GET /metrics/application is invoked, Helidon will return the current value of the metric stored in the MetricRegistry . The Gauge metric is different from all the other metrics. The application must provide a getter to return the gauge value in an application scoped class. When GET /metrics/application is invoked, Helidon will call the Gauge getter, store that value in the MetricsRegistry , and return it as part of the metrics response payload. So, the Gauge metric value is updated real-time, in response to the get metrics request. The following example demonstrates how to use a Gauge to track application up-time. <markup lang=\"java\" title=\"Create a new GreetingCardsAppMetrics class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.time.Duration; import java.util.concurrent.atomic.AtomicLong; import jakarta.enterprise.context.ApplicationScoped; import jakarta.enterprise.context.Initialized; import jakarta.enterprise.event.Observes; import org.eclipse.microprofile.metrics.annotation.Gauge; @ApplicationScoped public class GreetingCardsAppMetrics { private AtomicLong startTime = new AtomicLong(0); public void onStartUp(@Observes @Initialized(ApplicationScoped.class) Object init) { startTime = new AtomicLong(System.currentTimeMillis()); } @Gauge(unit = \"TimeSeconds\") public long appUpTimeSeconds() { return Duration.ofMillis(System.currentTimeMillis() - startTime.get()).getSeconds(); } } This managed object must be application scoped to properly register and use the Gauge metric. Declare an AtomicLong field to hold the start time of the application. Initialize the application start time. Return the application appUpTimeSeconds metric, which will be included in the application metrics. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code to simplify the metrics output:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import jakarta.enterprise.context.RequestScoped; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.annotation.Counted; @Path(\"/cards\") @RequestScoped public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"cardCount\", absolute = true) public JsonObject anyCard() throws InterruptedException { return createResponse(\"Here are some random cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } } <markup lang=\"bash\" title=\"Build and run the application, then invoke the application metrics endpoint:\" >curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response from /metrics/application :\" >{ \"cardCount\": 0, \"io.helidon.examples.quickstart.mp.GreetingCardsAppMetrics.appUpTimeSeconds\": 6 } The application has been running for 6 seconds. ",
            "title": "Application-Specific Metrics Data"
        },
        {
            "location": "mp/guides/metrics",
            "text": " The following example shows how to integrate the Helidon MP application with Kubernetes. <markup lang=\"bash\" title=\"Stop the application and build the docker image:\" >docker build -t helidon-metrics-mp . <markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named metrics.yaml , with the following content:\" >kind: Service apiVersion: v1 metadata: name: helidon-metrics labels: app: helidon-metrics annotations: prometheus.io/scrape: true spec: type: NodePort selector: app: helidon-metrics ports: - port: 8080 targetPort: 8080 name: http --- kind: Deployment apiVersion: apps/v1 metadata: name: helidon-metrics spec: replicas: 1 selector: matchLabels: app: helidon-metrics template: metadata: labels: app: helidon-metrics version: v1 spec: containers: - name: helidon-metrics image: helidon-metrics-mp imagePullPolicy: IfNotPresent ports: - containerPort: 8080 A service of type NodePort that serves the default routes on port 8080 . An annotation that will allow Prometheus to discover and scrape the application pod. A deployment with one replica of a pod. <markup lang=\"bash\" title=\"Create and deploy the application into Kubernetes:\" >kubectl apply -f ./metrics.yaml <markup lang=\"bash\" title=\"Get the service information:\" >kubectl get service/helidon-metrics <markup lang=\"bash\" >NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE helidon-metrics NodePort 10.99.159.2 &lt;none&gt; 8080:31143/TCP 8s A service of type NodePort that serves the default routes on port 31143 . <markup lang=\"bash\" title=\"Verify the metrics endpoint using port 30116 , your port will likely be different:\" >curl http://localhost:31143/metrics Leave the application running in Kubernetes since it will be used for Prometheus integration. ",
            "title": "Kubernetes Integration"
        },
        {
            "location": "mp/guides/metrics",
            "text": " The metrics service that you just deployed into Kubernetes is already annotated with prometheus.io/scrape: . This will allow Prometheus to discover the service and scrape the metrics. This example shows how to install Prometheus into Kubernetes, then verify that it discovered the Helidon metrics in your application. <markup lang=\"bash\" title=\"Install Prometheus and wait until the pod is ready:\" >helm install stable/prometheus --name metrics export POD_NAME=$(kubectl get pods --namespace default -l \"app=prometheus,component=server\" -o jsonpath=\"{.items[0].metadata.name}\") kubectl get pod $POD_NAME You will see output similar to the following. Repeat the kubectl get pod command until you see 2/2 and Running . This may take up to one minute. <markup lang=\"bash\" >metrics-prometheus-server-5fc5dc86cb-79lk4 2/2 Running 0 46s <markup lang=\"bash\" title=\"Create a port-forward so you can access the server URL:\" >kubectl --namespace default port-forward $POD_NAME 7090:9090 Now open your browser and navigate to http://localhost:7090/targets . Search for helidon on the page and you will see your Helidon application as one of the Prometheus targets. ",
            "title": "Prometheus Integration"
        },
        {
            "location": "mp/guides/metrics",
            "text": " You can now delete the Kubernetes resources that were just created during this example. <markup lang=\"bash\" title=\"Delete the Prometheus Kubernetes resources:\" >helm delete --purge metrics <markup lang=\"bash\" title=\"Delete the application Kubernetes resources:\" >kubectl delete -f ./metrics.yaml ",
            "title": "Final Cleanup"
        },
        {
            "location": "mp/guides/metrics",
            "text": " Kubernetes Integration The following example shows how to integrate the Helidon MP application with Kubernetes. <markup lang=\"bash\" title=\"Stop the application and build the docker image:\" >docker build -t helidon-metrics-mp . <markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named metrics.yaml , with the following content:\" >kind: Service apiVersion: v1 metadata: name: helidon-metrics labels: app: helidon-metrics annotations: prometheus.io/scrape: true spec: type: NodePort selector: app: helidon-metrics ports: - port: 8080 targetPort: 8080 name: http --- kind: Deployment apiVersion: apps/v1 metadata: name: helidon-metrics spec: replicas: 1 selector: matchLabels: app: helidon-metrics template: metadata: labels: app: helidon-metrics version: v1 spec: containers: - name: helidon-metrics image: helidon-metrics-mp imagePullPolicy: IfNotPresent ports: - containerPort: 8080 A service of type NodePort that serves the default routes on port 8080 . An annotation that will allow Prometheus to discover and scrape the application pod. A deployment with one replica of a pod. <markup lang=\"bash\" title=\"Create and deploy the application into Kubernetes:\" >kubectl apply -f ./metrics.yaml <markup lang=\"bash\" title=\"Get the service information:\" >kubectl get service/helidon-metrics <markup lang=\"bash\" >NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE helidon-metrics NodePort 10.99.159.2 &lt;none&gt; 8080:31143/TCP 8s A service of type NodePort that serves the default routes on port 31143 . <markup lang=\"bash\" title=\"Verify the metrics endpoint using port 30116 , your port will likely be different:\" >curl http://localhost:31143/metrics Leave the application running in Kubernetes since it will be used for Prometheus integration. Prometheus Integration The metrics service that you just deployed into Kubernetes is already annotated with prometheus.io/scrape: . This will allow Prometheus to discover the service and scrape the metrics. This example shows how to install Prometheus into Kubernetes, then verify that it discovered the Helidon metrics in your application. <markup lang=\"bash\" title=\"Install Prometheus and wait until the pod is ready:\" >helm install stable/prometheus --name metrics export POD_NAME=$(kubectl get pods --namespace default -l \"app=prometheus,component=server\" -o jsonpath=\"{.items[0].metadata.name}\") kubectl get pod $POD_NAME You will see output similar to the following. Repeat the kubectl get pod command until you see 2/2 and Running . This may take up to one minute. <markup lang=\"bash\" >metrics-prometheus-server-5fc5dc86cb-79lk4 2/2 Running 0 46s <markup lang=\"bash\" title=\"Create a port-forward so you can access the server URL:\" >kubectl --namespace default port-forward $POD_NAME 7090:9090 Now open your browser and navigate to http://localhost:7090/targets . Search for helidon on the page and you will see your Helidon application as one of the Prometheus targets. Final Cleanup You can now delete the Kubernetes resources that were just created during this example. <markup lang=\"bash\" title=\"Delete the Prometheus Kubernetes resources:\" >helm delete --purge metrics <markup lang=\"bash\" title=\"Delete the application Kubernetes resources:\" >kubectl delete -f ./metrics.yaml ",
            "title": "Integration with Kubernetes and Prometheus"
        },
        {
            "location": "mp/guides/metrics",
            "text": " This guide demonstrated how to use metrics in a Helidon MP application using various combinations of metrics and scopes. Access metrics for all three scopes: base, vendor, and application Configure application metrics at the class, method, and field-level Integrate Helidon metrics with Kubernetes and Prometheus Refer to the following references for additional information: MicroProfile Metrics specification MicroProfile Metrics Javadoc Helidon Javadoc at ./apidocs/index.html?overview-summary.html ",
            "title": "Summary"
        },
        {
            "location": "mp/guides/metrics",
            "text": " For this 30 minute tutorial, you will need the following: <div class=\"table__overflow elevation-1 flex sm7 \"> A Helidon MP Application You can use your own application or use the Helidon MP Quickstart to create a sample application. Java&#160;SE&#160;17 ( Open&#160;JDK&#160;17 ) Helidon requires Java 17+. Maven 3.6.1+ Helidon requires Maven 3.6.1+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop . Helm To manage Kubernetes applications. <markup lang=\"bash\" title=\"Verify Prerequisites\" >java -version mvn --version docker --version kubectl version --short <markup lang=\"bash\" title=\"Setting JAVA_HOME\" ># On Mac export JAVA_HOME=`/usr/libexec/java_home -v 17` # On Linux # Use the appropriate path to your JDK export JAVA_HOME=/usr/lib/jvm/jdk-17 Create a Sample Helidon MP Project Use the Helidon MP Maven archetype to create a simple project that can be used for the examples in this guide. <markup lang=\"bash\" title=\"Run the Maven archetype\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-mp \\ -DarchetypeVersion=3.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-mp \\ -Dpackage=io.helidon.examples.quickstart.mp Using the Built-In Metrics Helidon provides three scopes of metrics: base, vendor, and application. Here are the metric endpoints: /metrics/base - Base metrics data as specified by the MicroProfile Metrics specification. /metrics/vendor - Helidon-specific metrics data. /metrics/application - Application-specific metrics data. The /metrics endpoint will return data for all scopes. The built-in metrics fall into three categories: JVM behavior (in the base registry), basic key performance indicators for request handling (in the vendor registry), and thread pool utilization (also in the vendor registry). A later section describes the key performance indicator metrics in detail. The following example demonstrates how to use the other built-in metrics. All examples are executed from the root directory of your project (helidon-quickstart-mp). <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-mp.jar Metrics can be returned in either text format (the default), or JSON. The text format uses OpenMetrics (Prometheus) Text Format, see https://prometheus.io/docs/instrumenting/exposition_formats/#text-format-details . <markup lang=\"bash\" title=\"Verify the metrics endpoint in a new terminal window:\" >curl http://localhost:8080/metrics <markup lang=\"text\" title=\"Text response:\" ># TYPE base_REST_request_total counter # HELP base_REST_request_total The number of invocations and total response time of this RESTful resource method since the start of the server. The metric will not record the elapsed time nor count of a REST request if it resulted in an unmapped exception. Also tracks the highest recorded time duration within the previous completed full minute and lowest recorded time duration within the previous completed full minute. base_REST_request_total{class=\"io.helidon.examples.quickstart.mp.GreetResource\",method=\"getDefaultMessage\"} 0 # TYPE base_REST_request_elapsedTime_seconds gauge base_REST_request_elapsedTime_seconds{class=\"io.helidon.examples.quickstart.mp.GreetResource\",method=\"getDefaultMessage\"} 0.0 # TYPE base_REST_request_maxTimeDuration_seconds gauge base_REST_request_maxTimeDuration_seconds{class=\"io.helidon.examples.quickstart.mp.GreetResource\",method=\"getDefaultMessage\"} NaN # TYPE base_REST_request_minTimeDuration_seconds gauge base_REST_request_minTimeDuration_seconds{class=\"io.helidon.examples.quickstart.mp.GreetResource\",method=\"getDefaultMessage\"} NaN base_REST_request_total{class=\"io.helidon.examples.quickstart.mp.GreetResource\",method=\"getMessage_java.lang.String\"} 0 base_REST_request_elapsedTime_seconds{class=\"io.helidon.examples.quickstart.mp.GreetResource\",method=\"getMessage_java.lang.String\"} 0.0 base_REST_request_maxTimeDuration_seconds{class=\"io.helidon.examples.quickstart.mp.GreetResource\",method=\"getMessage_java.lang.String\"} NaN base_REST_request_minTimeDuration_seconds{class=\"io.helidon.examples.quickstart.mp.GreetResource\",method=\"getMessage_java.lang.String\"} NaN # TYPE base_REST_request_unmappedException_total counter # HELP base_REST_request_unmappedException_total The total number of unmapped exceptions that occur from this RESTful resouce method since the start of the server. base_REST_request_unmappedException_total{class=\"io.helidon.examples.quickstart.mp.GreetResource\",method=\"getDefaultMessage\"} 0 base_REST_request_unmappedException_total{class=\"io.helidon.examples.quickstart.mp.GreetResource\",method=\"getMessage_java.lang.String\"} 0 # TYPE base:classloader_current_loaded_class_count counter # HELP base:classloader_current_loaded_class_count Displays the number of classes that are currently loaded in the Java virtual machine. base:classloader_current_loaded_class_count 7511 # TYPE base:classloader_total_loaded_class_count counter # HELP base:classloader_total_loaded_class_count Displays the total number of classes that have been loaded since the Java virtual machine has started execution. base:classloader_total_loaded_class_count 7512 You can get the same data in JSON format. <markup lang=\"bash\" title=\"Verify the metrics endpoint with an HTTP accept header:\" >curl -H \"Accept: application/json\" http://localhost:8080/metrics <markup lang=\"json\" title=\"JSON response:\" >{ \"base\": { \"REST.request\": { \"count;class=io.helidon.examples.quickstart.mp.GreetResource;method=getDefaultMessage\": 0, \"elapsedTime;class=io.helidon.examples.quickstart.mp.GreetResource;method=getDefaultMessage\": 0, \"maxTimeDuration;class=io.helidon.examples.quickstart.mp.GreetResource;method=getDefaultMessage\": null, \"minTimeDuration;class=io.helidon.examples.quickstart.mp.GreetResource;method=getDefaultMessage\": null, \"count;class=io.helidon.examples.quickstart.mp.GreetResource;method=getMessage_java.lang.String\": 0, \"elapsedTime;class=io.helidon.examples.quickstart.mp.GreetResource;method=getMessage_java.lang.String\": 0, \"maxTimeDuration;class=io.helidon.examples.quickstart.mp.GreetResource;method=getMessage_java.lang.String\": null, \"minTimeDuration;class=io.helidon.examples.quickstart.mp.GreetResource;method=getMessage_java.lang.String\": null, }, \"classloader.currentLoadedClass.count\": 7534, \"classloader.totalLoadedClass.count\": 7538, \"classloader.totalUnloadedClass.count\": 1, \"cpu.availableProcessors\": 4, \"cpu.systemLoadAverage\": 2.83349609375, \"gc.PS MarkSweep.count\": 2, \"gc.PS MarkSweep.time\": 77, \"gc.PS Scavenge.count\": 5, \"gc.PS Scavenge.time\": 37, \"jvm.uptime\": 727588, \"memory.committedHeap\": 284164096, \"memory.maxHeap\": 3817865216, \"memory.usedHeap\": 53283088, \"thread.count\": 44, \"thread.daemon.count\": 35, \"thread.max.count\": 44 }, \"vendor\": { \"executor-service.active-count;poolIndex=0;supplierCategory=helidon-thread-pool-2;supplierIndex=0\": 0, \"executor-service.completed-task-count;poolIndex=0;supplierCategory=helidon-thread-pool-2;supplierIndex=0\": 0, \"executor-service.largest-pool-size;poolIndex=0;supplierCategory=helidon-thread-pool-2;supplierIndex=0\": 5, \"executor-service.pool-size;poolIndex=0;supplierCategory=helidon-thread-pool-2;supplierIndex=0\": 5, \"executor-service.queue.remaining-capacity;poolIndex=0;supplierCategory=helidon-thread-pool-2;supplierIndex=0\": 10000, \"executor-service.queue.size;poolIndex=0;supplierCategory=helidon-thread-pool-2;supplierIndex=0\": 0, \"executor-service.task-count;poolIndex=0;supplierCategory=helidon-thread-pool-2;supplierIndex=0\": 0, \"requests.count\": 6, \"requests.meter\": { \"count\": 6, \"meanRate\": 0.008275992296704147, \"oneMinRate\": 0.01576418632772332, \"fiveMinRate\": 0.006695060022357365, \"fifteenMinRate\": 0.0036382699664488415 } } } You can get a single metric by specifying the name in the URL path. <markup lang=\"bash\" title=\"Get the Helidon requests.meter metric:\" >curl -H \"Accept: application/json\" http://localhost:8080/metrics/vendor/requests.meter <markup lang=\"json\" title=\"JSON response:\" >{ \"requests.meter\": { \"count\": 6, \"meanRate\": 0.008275992296704147, \"oneMinRate\": 0.01576418632772332, \"fiveMinRate\": 0.006695060022357365, \"fifteenMinRate\": 0.0036382699664488415 } } You cannot get the individual fields of a metric. For example, you cannot target http://localhost:8080/metrics/vendor/requests.meter.count . The base metrics illustrated above provide some insight into the behavior of the JVM in which the server runs. The vendor metrics shown above appear in two groups: Helidon thread pools Helidon uses these thread pools for its own internal work, and your application can also use Helidon-managed thread pools if it needs to do work asynchronously. (See this example .) The metrics in this group show information about the thread pools which can help you assess how efficiently they are utilized. Helidon uses tags to distinguish the metrics which describe different thread pools. In some cases the specific metrics exposed depend on the particular type of thread pool. basic key performance indicators These metrics give an idea of the request traffic the server is handling. See the later section for more information on the basic and extended key performance indicator metrics. Controlling Metrics Behavior By adding a metrics section to your application configuration you can control how the Helidon metrics subsystem behaves in any of several ways. Disable metrics subsystem entirely . Control REST.request metrics. Identify groups of metrics to control: registered by a particular component , and by metric registry (application, vendor, and base) and within a registry by metric names which match patterns you provide. Select whether to collect extended key performance indicator metrics . Disabling Metrics Subsystem Entirely By default, if your application depends on the helidon-metrics Maven module then full-featured metrics are enabled. You can disable the metrics subsystem entirely using configuration: <markup lang=\"properties\" title=\"Configuration properties file disabling metrics\" >metrics.enabled=false With metrics processing disabled, Helidon never updates any metrics and the /metrics endpoints respond with 404 plus a message that the metrics subsystem is disabled. Collecting Basic and Extended Key Performance Indicator (KPI) Metrics Any time you include the Helidon metrics module in your application, Helidon tracks two basic performance indicator metrics: a Counter of all requests received ( requests.count ), and a Meter of all requests received ( requests.meter ). Helidon MP also includes additional, extended KPI metrics which are disabled by default: current number of requests in-flight - a ConcurrentGauge ( requests.inFlight ) of requests currently being processed long-running requests - a Meter ( requests.longRunning ) measuring the rate at which Helidon processes requests which take at least a given amount of time to complete; configurable, defaults to 10000 milliseconds (10 seconds) load - a Meter ( requests.load ) measuring the rate at which requests are worked on (as opposed to received) deferred - a Meter ( requests.deferred ) measuring the rate at which a request&#8217;s processing is delayed after Helidon receives the request You can enable and control these metrics using configuration: <markup lang=\"properties\" title=\"Configuration properties file controlling extended KPI metrics\" >metrics.key-performance-indicators.extended = true metrics.key-performance-indicators.long-running.threshold-ms = 2000 Controlling REST.request Metrics Helidon implements the optional family of metrics, all with the name REST.request , as described in the MicroProfile Metrics specification . Each instance is a SimpleTimer with tags class and method identifying exactly which REST endpoint Java method that instance measures. By default, Helidon MP does not enable this feature. Enable it by editing your application configuration to set metrics.rest-request.enabled to true . Note that the applications you generate using the full Helidon archetype do enable this feature in the generated config file. You can see the results in the sample output shown in earlier example runs. Enabling and Disabling Metrics Usage by a Component Helidon contains several components and integrations which register and update metrics. Depending on how the component is written, you might be able to disable just that component&#8217;s use of metrics: <markup lang=\"properties\" title=\"Configuration properties file disabling a component&#8217;s use of metrics\" >some-component.metrics.enabled=false Check the documentation for a specific component to find out whether that component uses metrics and whether it allows you to disable that use. If you disable a component&#8217;s use of metrics, Helidon does not register the component&#8217;s metrics in the visible metrics registries nor do those metrics ever update their values. The response from the /metrics endpoint excludes that component&#8217;s metrics. Note that if you disable metrics processing entirely, no component updates its metrics regardless of any component-level metrics settings. Controlling Metrics By Registry Type and Metric Name You can control the collection and reporting of metrics by registry type and metric name within registry type. Disabling All Metrics of a Given Registry Type To disable all metrics in a given registry type (application, vendor, or base), add one or more groups to the configuration: <markup lang=\"properties\" title=\"Disabling base and vendor metrics (properties format)\" >metrics.registries.0.type = base metrics.registries.0.enabled = false metrics.registries.1.type = vendor metrics.registries.1.enabled = false <markup lang=\"yaml\" title=\"Disabling base and vendor metrics (YAML format)\" >metrics: registries: - type: base enabled: false - type: vendor enables: false Controlling Metrics by Metric Name You can be even more selective. Within a registry type you can configure up to two regular expression patterns: one matching metric names to exclude , and one matching metric names to include . Helidon updates and reports a metric only if two conditions hold: the metric name does not match the exclude regex pattern (if you define one), and either there is no include regex pattern, or the metric name matches the include pattern. Caution Make sure any include regex pattern you specify matches all the metric names you want to capture. Suppose your application creates and updates a group of metrics with names such as myapp.xxx.queries , myapp.xxx.creates , myapp.xxx.updates , and myapp.xxx.deletes where xxx can be either supplier or customer . The following example gathers all metrics except those from your application regarding suppliers: <markup lang=\"properties\" title=\"Disabling metrics by name (properties format)\" >metrics.registries.0.type = application metrics.registries.0.filter.exclude = myapp\\.supplier\\..* The following settings select the particular subset of the metrics created in your application code representing updates of customers and suppliers: <markup lang=\"properties\" title=\"Enabling metrics by name (properties format)\" >metrics.registries.0.type = application metrics.registries.0.filter.include = myapp\\..*\\.updates If you use the YAML configuration format, enclose the regex patterns in single-quote marks: <markup lang=\"yaml\" title=\"Enabling metrics by name (YAML format)\" >metrics: registries: - type: application filter: include: 'myapp\\..*\\.updates' The next example selects only your application&#8217;s metrics while excluding those which refer to deletions: <markup lang=\"properties\" title=\"Combining include and exclude \" >metrics.registries.0.type = application metrics.registries.0.filter.include = myapp\\..* metrics.registries.0.filter.exclude = myapp\\..*/deletes Helidon would not update or report the metric myapp.supplier.queries , for example. To include metrics from your application for both updates and queries (but not for other operations), you could change the settings in the previous example to this: <markup >metrics.registries.0.type = application metrics.registries.0.filter.include = myapp\\..*\\.updates|myapp\\..*\\.queries metrics.registries.0.filter.exclude = myapp\\..*/deletes Metrics Metadata Each metric has associated metadata that describes: name: The name of the metric. units: The unit of the metric such as time (seconds, millisecond), size (bytes, megabytes), etc. type: The type of metric: Counter , Timer , Meter , Histogram , SimpleTimer , or Gauge . You can get the metadata for any scope, such as /metrics/base , as shown below: <markup lang=\"bash\" title=\"Get the metrics metadata using HTTP OPTIONS method:\" > curl -X OPTIONS -H \"Accept: application/json\" http://localhost:8080/metrics/base <markup lang=\"json\" title=\"JSON response (truncated):\" >{ \"classloader.currentLoadedClass.count\": { \"unit\": \"none\", \"type\": \"counter\", \"description\": \"Displays the number of classes that are currently loaded in the Java virtual machine.\", \"displayName\": \"Current Loaded Class Count\" }, \"jvm.uptime\": { \"unit\": \"milliseconds\", \"type\": \"gauge\", \"description\": \"Displays the start time of the Java virtual machine in milliseconds. This attribute displays the approximate time when the Java virtual machine started.\", \"displayName\": \"JVM Uptime\" }, \"memory.usedHeap\": { \"unit\": \"bytes\", \"type\": \"gauge\", \"description\": \"Displays the amount of used heap memory in bytes.\", \"displayName\": \"Used Heap Memory\" } } Application-Specific Metrics Data You can create application-specific metrics and integrate them with Helidon using CDI. To add a new metric, simply annotate the JAX-RS resource with one of the metric annotations. Metrics can be injected at the class, method, and field-levels. This document shows examples of all three. Helidon will automatically create and register annotated application metrics and store them in the application MetricRegistry , which also contains the metric metadata. The metrics will exist for the lifetime of the application. Each metric annotation has mandatory and optional fields. The name field, for example, is optional. Method Level Metrics There are four metrics that you can use by annotating a method: @Counted - Register a Counter metric @Timed - Register a Timer metric @Metered - Register a Meter metric @SimplyTimed - Register a SimpleTimer metric The following example will demonstrate how to use the @Counted annotation to track the number of times the /cards endpoint is called. <markup lang=\"java\" title=\"Create a new class GreetingCards with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import jakarta.enterprise.context.RequestScoped; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.annotation.Counted; @Path(\"/cards\") @RequestScoped public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"any-card\") public JsonObject anyCard() throws InterruptedException { return createResponse(\"Here are some random cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } } This class is annotated with Path which sets the path for this resource as /cards . The @RequestScoped annotation defines that this bean is request scoped. The request scope is active only for the duration of one web service invocation and it is destroyed at the end of that invocation. The annotation @Counted will register a Counter metric for this method, creating it if needed. The counter is incremented each time the anyCards method is called. The name attribute is optional. For Metrics 1.1, you must set monotonic field to true to force the count to increment when entering the method. The default behavior is to decrement when exiting the method. Here is an example: @Counted(name = \"any-card\", monotonic = true) . <markup lang=\"bash\" title=\"Build and run the application, then invoke the application endpoints below:\" >curl http://localhost:8080/cards curl http://localhost:8080/cards curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response:\" >{ \"io.helidon.examples.quickstart.mp.GreetingCards.any-card\":2 } The any-card count is two, since you invoked the endpoint twice. Notice the counter is fully qualified. You can remove the package prefix by using the absolute=true field in the @Counted annotation. You must use absolute=false for class-level annotations. Additional Method Level Metrics The @Timed , @Metered , and @SimplyTimed annotations can also be used with a method. For the following example. you can just annotate the same method with @Metered and @Timed . These metrics collect significant information about the measured methods, but at a cost of some overhead and more complicated output. Use @SimplyTimed in cases where capturing the invocation count and the total elapsed time spent in a block of code is sufficient. Note that when using multiple annotations on a method, you must give the metrics different names as shown below. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import jakarta.enterprise.context.RequestScoped; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.MetricUnits; import org.eclipse.microprofile.metrics.annotation.Counted; import org.eclipse.microprofile.metrics.annotation.Metered; import org.eclipse.microprofile.metrics.annotation.Timed; @Path(\"/cards\") @RequestScoped public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"cardCount\", absolute = true) @Metered(name = \"cardMeter\", absolute = true, unit = MetricUnits.MILLISECONDS) @Timed(name = \"cardTimer\", absolute = true, unit = MetricUnits.MILLISECONDS) public JsonObject anyCard() { return createResponse(\"Here are some random cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } } Specify a custom name for the Counter metric and set absolute=true to remove the path prefix from the name. Add the @Metered annotation to get a Meter metric. Add the @Timed annotation to get a Timer metric. <markup lang=\"bash\" title=\"Build and run the application, then invoke the application endpoints below:\" >curl http://localhost:8080/cards curl http://localhost:8080/cards curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response:\" >{ \"cardCount\": 2, \"cardMeter\": { \"count\": 2, \"meanRate\": 0.15653506570241812, \"oneMinRate\": 0, \"fiveMinRate\": 0, \"fifteenMinRate\": 0 }, \"cardTimer\": { \"count\": 2, \"elapsedTime\": 2, \"meanRate\": 0.15651866263362785, \"oneMinRate\": 0, \"fiveMinRate\": 0, \"fifteenMinRate\": 0, \"min\": 0, \"max\": 2, \"mean\": 1.0506565, \"stddev\": 1.0405735, \"p50\": 2.09123, \"p75\": 2.09123, \"p95\": 2.09123, \"p98\": 2.09123, \"p99\": 2.09123, \"p999\": 2.09123 } } The Meter metric includes the count field (it is a superset of Counter ). The Timer metric includes the Meter fields (it is a superset of Meter ). Reusing Metrics You can share a metric across multiple endpoints simply by specifying the same metric annotation as demonstrated below. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import jakarta.enterprise.context.RequestScoped; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.annotation.Counted; @Path(\"/cards\") @RequestScoped public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"anyCard\", absolute = true) public JsonObject anyCard() throws InterruptedException { return createResponse(\"Here are some cards ...\"); } @GET @Path(\"/birthday\") @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"specialEventCard\", absolute = true) public JsonObject birthdayCard() throws InterruptedException { return createResponse(\"Here are some birthday cards ...\"); } @GET @Path(\"/wedding\") @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"specialEventCard\", absolute = true) public JsonObject weddingCard() throws InterruptedException { return createResponse(\"Here are some wedding cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } } The /birthday endpoint uses a Counter metric, named specialEventCard . The /wedding endpoint uses the same Counter metric, named specialEventCard . <markup lang=\"bash\" title=\"Build and run the application, then invoke the following endpoints:\" >curl http://localhost:8080/cards/wedding curl http://localhost:8080/cards/birthday curl http://localhost:8080/cards curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response from /metrics/application :\" >{ \"anyCard\": 1, \"specialEventCard\": 2 } Notice that specialEventCard count is two, since you accessed /cards/wedding and /cards/birthday . Class Level Metrics You can collect metrics at the class-level to aggregate data from all methods in that class using the same metric. The following example introduces a metric to count all card queries. In the following example, the method-level metrics are not needed to aggregate the counts, but they are left in the example to demonstrate the combined output of all three metrics. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import jakarta.enterprise.context.RequestScoped; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.annotation.Counted; @Path(\"/cards\") @RequestScoped @Counted(name = \"totalCards\") public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) @Counted(absolute = true) public JsonObject anyCard() throws InterruptedException { return createResponse(\"Here are some random cards ...\"); } @Path(\"/birthday\") @GET @Produces(MediaType.APPLICATION_JSON) @Counted(absolute = true) public JsonObject birthdayCard() throws InterruptedException { return createResponse(\"Here are some birthday cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } } This class is annotated with @Counted , which aggregates count data from all the method that have a Count annotation. Use absolute=true to remove path prefix for method-level annotations. Add a method with a Counter metric to get birthday cards. <markup lang=\"bash\" title=\"Build and run the application, then invoke the following endpoints:\" >curl http://localhost:8080/cards curl http://localhost:8080/cards/birthday curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response from /metrics/application :\" >{ \"anyCard\": 1, \"birthdayCard\": 1, \"io.helidon.examples.quickstart.mp.totalCards.GreetingCards\": 2 } The totalCards count is a total of all the method-level Counter metrics. Class level metric names are always fully qualified. Field Level Metrics Field level metrics can be injected into managed objects, but they need to be updated by the application code. This annotation can be used on fields of type Meter , Timer , Counter , and Histogram . The following example shows how to use a field-level Counter metric to track cache hits. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import java.util.Random; import jakarta.enterprise.context.RequestScoped; import jakarta.inject.Inject; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.Counter; import org.eclipse.microprofile.metrics.annotation.Counted; import org.eclipse.microprofile.metrics.annotation.Metric; @Path(\"/cards\") @RequestScoped @Counted(name = \"totalCards\") public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @Inject @Metric(name = \"cacheHits\", absolute = true) private Counter cacheHits; @GET @Produces(MediaType.APPLICATION_JSON) @Counted(absolute = true) public JsonObject anyCard() throws InterruptedException { updateStats(); return createResponse(\"Here are some random cards ...\"); } @Path(\"/birthday\") @GET @Produces(MediaType.APPLICATION_JSON) @Counted(absolute = true) public JsonObject birthdayCard() throws InterruptedException { updateStats(); return createResponse(\"Here are some birthday cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } private void updateStats() { if (new Random().nextInt(3) == 1) { cacheHits.inc(); } } } A Counter metric field, cacheHits , is automatically injected by Helidon. Call updateStats() to update the cache hits. Call updateStats() to update the cache hits. Randomly increment the cacheHits counter. <markup lang=\"bash\" title=\"Build and run the application, then invoke the following endpoints:\" >curl http://localhost:8080/cards curl http://localhost:8080/cards curl http://localhost:8080/cards/birthday curl http://localhost:8080/cards/birthday curl http://localhost:8080/cards/birthday curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response from /metrics/application :\" >{ \"anyCard\": 2, \"birthdayCard\": 3, \"cacheHits\": 2, \"io.helidon.examples.quickstart.mp.totalCards.GreetingCards\": 5 } The cache was hit two times out of five queries. Gauge Metric The metrics you have tested so far are updated in response to an application REST request, i.e GET /cards . These metrics can be declared in a request scoped class and Helidon will store the metric in the MetricRegistry , so the value persists across requests. When GET /metrics/application is invoked, Helidon will return the current value of the metric stored in the MetricRegistry . The Gauge metric is different from all the other metrics. The application must provide a getter to return the gauge value in an application scoped class. When GET /metrics/application is invoked, Helidon will call the Gauge getter, store that value in the MetricsRegistry , and return it as part of the metrics response payload. So, the Gauge metric value is updated real-time, in response to the get metrics request. The following example demonstrates how to use a Gauge to track application up-time. <markup lang=\"java\" title=\"Create a new GreetingCardsAppMetrics class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.time.Duration; import java.util.concurrent.atomic.AtomicLong; import jakarta.enterprise.context.ApplicationScoped; import jakarta.enterprise.context.Initialized; import jakarta.enterprise.event.Observes; import org.eclipse.microprofile.metrics.annotation.Gauge; @ApplicationScoped public class GreetingCardsAppMetrics { private AtomicLong startTime = new AtomicLong(0); public void onStartUp(@Observes @Initialized(ApplicationScoped.class) Object init) { startTime = new AtomicLong(System.currentTimeMillis()); } @Gauge(unit = \"TimeSeconds\") public long appUpTimeSeconds() { return Duration.ofMillis(System.currentTimeMillis() - startTime.get()).getSeconds(); } } This managed object must be application scoped to properly register and use the Gauge metric. Declare an AtomicLong field to hold the start time of the application. Initialize the application start time. Return the application appUpTimeSeconds metric, which will be included in the application metrics. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code to simplify the metrics output:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import jakarta.enterprise.context.RequestScoped; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.annotation.Counted; @Path(\"/cards\") @RequestScoped public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"cardCount\", absolute = true) public JsonObject anyCard() throws InterruptedException { return createResponse(\"Here are some random cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } } <markup lang=\"bash\" title=\"Build and run the application, then invoke the application metrics endpoint:\" >curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response from /metrics/application :\" >{ \"cardCount\": 0, \"io.helidon.examples.quickstart.mp.GreetingCardsAppMetrics.appUpTimeSeconds\": 6 } The application has been running for 6 seconds. Integration with Kubernetes and Prometheus Kubernetes Integration The following example shows how to integrate the Helidon MP application with Kubernetes. <markup lang=\"bash\" title=\"Stop the application and build the docker image:\" >docker build -t helidon-metrics-mp . <markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named metrics.yaml , with the following content:\" >kind: Service apiVersion: v1 metadata: name: helidon-metrics labels: app: helidon-metrics annotations: prometheus.io/scrape: true spec: type: NodePort selector: app: helidon-metrics ports: - port: 8080 targetPort: 8080 name: http --- kind: Deployment apiVersion: apps/v1 metadata: name: helidon-metrics spec: replicas: 1 selector: matchLabels: app: helidon-metrics template: metadata: labels: app: helidon-metrics version: v1 spec: containers: - name: helidon-metrics image: helidon-metrics-mp imagePullPolicy: IfNotPresent ports: - containerPort: 8080 A service of type NodePort that serves the default routes on port 8080 . An annotation that will allow Prometheus to discover and scrape the application pod. A deployment with one replica of a pod. <markup lang=\"bash\" title=\"Create and deploy the application into Kubernetes:\" >kubectl apply -f ./metrics.yaml <markup lang=\"bash\" title=\"Get the service information:\" >kubectl get service/helidon-metrics <markup lang=\"bash\" >NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE helidon-metrics NodePort 10.99.159.2 &lt;none&gt; 8080:31143/TCP 8s A service of type NodePort that serves the default routes on port 31143 . <markup lang=\"bash\" title=\"Verify the metrics endpoint using port 30116 , your port will likely be different:\" >curl http://localhost:31143/metrics Leave the application running in Kubernetes since it will be used for Prometheus integration. Prometheus Integration The metrics service that you just deployed into Kubernetes is already annotated with prometheus.io/scrape: . This will allow Prometheus to discover the service and scrape the metrics. This example shows how to install Prometheus into Kubernetes, then verify that it discovered the Helidon metrics in your application. <markup lang=\"bash\" title=\"Install Prometheus and wait until the pod is ready:\" >helm install stable/prometheus --name metrics export POD_NAME=$(kubectl get pods --namespace default -l \"app=prometheus,component=server\" -o jsonpath=\"{.items[0].metadata.name}\") kubectl get pod $POD_NAME You will see output similar to the following. Repeat the kubectl get pod command until you see 2/2 and Running . This may take up to one minute. <markup lang=\"bash\" >metrics-prometheus-server-5fc5dc86cb-79lk4 2/2 Running 0 46s <markup lang=\"bash\" title=\"Create a port-forward so you can access the server URL:\" >kubectl --namespace default port-forward $POD_NAME 7090:9090 Now open your browser and navigate to http://localhost:7090/targets . Search for helidon on the page and you will see your Helidon application as one of the Prometheus targets. Final Cleanup You can now delete the Kubernetes resources that were just created during this example. <markup lang=\"bash\" title=\"Delete the Prometheus Kubernetes resources:\" >helm delete --purge metrics <markup lang=\"bash\" title=\"Delete the application Kubernetes resources:\" >kubectl delete -f ./metrics.yaml Summary This guide demonstrated how to use metrics in a Helidon MP application using various combinations of metrics and scopes. Access metrics for all three scopes: base, vendor, and application Configure application metrics at the class, method, and field-level Integrate Helidon metrics with Kubernetes and Prometheus Refer to the following references for additional information: MicroProfile Metrics specification MicroProfile Metrics Javadoc Helidon Javadoc at ./apidocs/index.html?overview-summary.html ",
            "title": "What You Need"
        },
        {
            "location": "mp/guides/migration",
            "text": " In Helidon 2.x we have made some changes to APIs and runtime behavior. This guide will help you migrate a Helidon MP 1.x application to 2.x. ",
            "title": "preambule"
        },
        {
            "location": "mp/guides/migration",
            "text": " Java 11 is no longer supported in Helidon 3. Java 17 or newer is required. ",
            "title": "Java 11 Runtime"
        },
        {
            "location": "mp/guides/migration",
            "text": " We have upgraded to OpenTracing version 0.33.0 that is not backward compatible. OpenTracing introduced the following breaking changes: Removed Replacement ScopeManager.active() Tracer.activeSpan() ScopeManager.activate(Span, boolean) ScopeManager.activate(Span) - second parameter is now always false SpanBuilder.startActive() Tracer.activateSpan(Span) TextMapExtractAdapter and TextMapInjectAdapter TextMapAdapter Module name changed opentracing.api io.opentracing.api (same for noop and util ) If you use the TracerBuilder abstraction in Helidon and have no custom Spans, there is no change required ",
            "title": "Tracing"
        },
        {
            "location": "mp/guides/migration",
            "text": " When the OIDC provider is configured to use cookie (default configuration) to carry authentication information, the cookie Same-Site is now set to Lax (used to be Strict ). This is to prevent infinite redirects, as browsers would refuse to set the cookie on redirected requests (due to this setting). Only in the case of the frontend host and identity host match, we leave Strict as the default ",
            "title": "Security: OIDC"
        },
        {
            "location": "mp/guides/migration",
            "text": " We have removed the versioned MicroProfile bundles (i.e. helidon-microprofile-x.x ), and introduced unversioned core and full bundles: io.helidon.microprofile.bundles:helidon-microprofile-core - contains only MP Server and Config. Allows you to add only the specifications needed by your application. io.helidon.microprofile.bundles:helidon-microprofile - contains the latest full MicroProfile version implemented by Helidon ",
            "title": "MicroProfile Bundles"
        },
        {
            "location": "mp/guides/migration",
            "text": " io.helidon.microprofile.server.Main has been deprecated. Use io.helidon.microprofile.cdi.Main instead. io.helidon.microprofile.server.Server is still available, although the features are much reduced. You no longer need to initialize Java Util Logging explicitly. Put logging.properties on the classpath or in the current directory to be automatically picked up to configure Java Util Logging. ",
            "title": "Application Main and Startup"
        },
        {
            "location": "mp/guides/migration",
            "text": " Helidon 1.x usually required that you have an Application subclass that returned the Application classes to scan. For common cases this is no longer necessary, and you might be able to remove your Application class. JAX-RS applications now work similarly to how they work in application servers: if there is an Application subclass that returns anything from getClasses or getSingletons , it is used as is if there is an Application subclass that returns empty sets from these methods, all available resource classes will be part of such an application if there is no Application subclass, a synthetic application will be created with all available resource classes Application subclasses MUST be annotated with @ApplicationScoped , otherwise they are ignored ",
            "title": "JAX-RS Applications"
        },
        {
            "location": "mp/guides/migration",
            "text": " If a JAX-RS application exists that is annotated with @LoginConfig with value MP-JWT, the correct authentication provider is added to security. The startup would fail if the provider is required yet not configured. ",
            "title": "MicroProfile JWT-Auth"
        },
        {
            "location": "mp/guides/migration",
            "text": " If there is no authentication provider configured, authentication will now fail. If there is no authorization provider configured, the ABAC provider will be configured. In Helidon 1.x these were configured if there was no provider configured overall. ",
            "title": "Security in Helidon MP"
        },
        {
            "location": "mp/guides/migration",
            "text": " In order to support GraalVM native-image we have had to re-implement how CDI is initialized and started. This has resulted in some changes in APIs and behavior: You can no longer start the CDI container yourself. You can only run a single instance of Server in a JVM. If you use SeContainerInitializer you will get an exception. This can be worked around by configuration property mp.initializer.allow=true , and warning can be removed using mp.initializer.no-warn=true Once SeContainerInitializer is used you can no longer use MP with native-image You can no longer provide a Context instance. The root context is now built-in. MpService and MpServiceContext have been removed. Methods from context have been moved to JaxRsCdiExtension and ServerCdiExtension . These can be accessed from CDI extension through BeanManager.getExtension . Methods register can be used on current io.helidon.context.Context MpService equivalent is a CDI extension. All Helidon services were refactored to CDI extension (you can use these for reference). Server.cdiContainer is removed, use CDI.current() instead. ",
            "title": "CDI and MicroProfile Server"
        },
        {
            "location": "mp/guides/migration",
            "text": " Helidon now supports only MicroProfile Metrics 2.x. Support for Metrics 1.x has been removed, and modules for 2.x have been renamed from metrics2 to metrics . ",
            "title": "Metrics"
        },
        {
            "location": "mp/guides/migration",
            "text": " We have moved from dependencies in groupId javax (Java EE modules) to dependencies in groupId jakarta (Jakarta EE modules). In case you declared a dependency on a javax module, you should change it to a jakarta one. Example: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;javax.activation&lt;/groupId&gt; &lt;artifactId&gt;javax.activation-api&lt;/artifactId&gt; &lt;/dependency&gt; should be changed to <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;jakarta.activation&lt;/groupId&gt; &lt;artifactId&gt;jakarta.activation-api&lt;/artifactId&gt; &lt;/dependency&gt; As the javax module is no longer in dependency management of Helidon parent pom files. ",
            "title": "Java EE dependencies"
        },
        {
            "location": "mp/guides/migration_3x",
            "text": " In Helidon 3.x we have made some changes to APIs and runtime behavior. This guide will help you upgrade a Helidon MP 2.x application to 3.x. ",
            "title": "preambule"
        },
        {
            "location": "mp/guides/migration_3x",
            "text": " Java 11 is no longer supported in Helidon 3. Java 17 or newer is required. Please follow the instructions in Prerequisites for proper installation. ",
            "title": "Java 17 Runtime"
        },
        {
            "location": "mp/guides/migration_3x",
            "text": " Helidon 3 supports MicroProfile 5.0 and selected Jakarta EE 9.1 APIs. In Jakarta EE 9.1 the Java package namespace was changed from javax to jakarta . Therefore, you must change your application to use jakarta instead of corresponding javax for Jakarta EE packages. In version 3.x Helidon supports MicroProfile 5.0 specification, which now is fully migrated to jakarta namespace. As a result, javax module is no longer in dependency management of Helidon parent pom files. ",
            "title": " javax namespace to jakarta namespace"
        },
        {
            "location": "mp/guides/migration_3x",
            "text": " The migration from javax to jakarta namespace makes this release backward incompatible with previous versions of MicroProfile. For each specification there are also API and functional changes that are described below. ",
            "title": "Incompatible changes for each specification"
        },
        {
            "location": "mp/guides/migration_3x",
            "text": " MicroProfile Config 3.0.1 : Incompatible changes described in MicroProfile Config 3.0.1 Specification MicroProfile Fault Tolerance 4.0 : Incompatible changes described in MicroProfile Fault Tolerance 4.0 Specification MicroProfile Health 4.0 : Incompatible changes described in MicroProfile Health 4.0 Specification MicroProfile JWT Authentication 2.0 : Incompatible changes described in MicroProfile JWT Authentication 2.0 Specification MicroProfile Metrics 4.0 : Incompatible changes described in MicroProfile Metrics 4.0 Specification MicroProfile OpenAPI 3.0 : Incompatible changes described in MicroProfile OpenAPI 3.0 Specification MicroProfile OpenTracing 3.0 : Incompatible changes described in MicroProfile OpenTracing 3.0 Specification MicroProfile Rest Client 3.0 : Incompatible changes described in MicroProfile Rest Client 3.0 Specification ",
            "title": "MicroProfile specifications"
        },
        {
            "location": "mp/guides/migration_3x",
            "text": " CDI (Jakarta Contexts and Dependency Injection) 3.0 : Changes described in CDI (Jakarta Contexts and Dependency Injection) 3.0 Specification JAX-RS (Jakarta RESTful Web Services) 3.0 : Moved to jakarta namespace. Changes described in JAX-RS (Jakarta RESTful Web Services) 3.0Specification JSON-B (Jakarta JSON Binding) 2.0 : Moved to jakarta namespace. Changes described in JSON-B (Jakarta JSON Binding) 2.0 Specification JSON-P (Jakarta JSON Processing) 2.0.1 : Moved to jakarta namespace. Jakarta Annotations 2.0 : Moved to jakarta namespace. Moved to jakarta namespace. Full information in Jakarta Annotations 2.0 Specification Jakarta Persistence API 3.0 : Moved to jakarta namespace. Changes described in Jakarta Persistence API 3.0 Specification Jakarta Transactions API 2.0 : Moved to jakarta namespace. Changes described in Jakarta Transactions API 2.0 Specification Jakarta WebSocket API 2.0 : Moved to jakarta namespace. Changes described in Jakarta WebSocket API 2.0 Specification Jakarta Bean Validation 2.0 : Moved to jakarta namespace. Changes described in Jakarta Bean Validation 2.0 Specification Before you migrate to Helidon 3.x, make sure that you have read each specification for a complete list of incompatible changes. ",
            "title": "Supported Jakarta EE specifications"
        },
        {
            "location": "mp/guides/migration_3x",
            "text": " MicroProfile 5.0 enables MicroProfile APIs to be used together with Jakarta EE 9.1 (Jakarta EE namespace). This release was mainly focused on updating dependencies from javax to jakarta , as well as overall stability and usability improvements. MicroProfile 5.0 lays the foundation for the rapid innovation of MicroProfile APIs for its 2022 releases. MicroProfile 5.0 is an umbrella for the following specifications and their corresponding versions: MicroProfile Config 3.0.1 MicroProfile Fault Tolerance 4.0 MicroProfile Health 4.0 MicroProfile JWT Authentication 2.0 MicroProfile Metrics 4.0 MicroProfile OpenAPI 3.0 MicroProfile OpenTracing 3.0 MicroProfile Rest Client 3.0 Helidon 3.x supports the following Jakarta EE specifications: CDI (Jakarta Contexts and Dependency Injection) 3.0 JAX-RS (Jakarta RESTful Web Services) 3.0 JSON-B (Jakarta JSON Binding) 2.0 JSON-P (Jakarta JSON Processing) 2.0.1 Jakarta Annotations 2.0 Jakarta Persistence API 3.0 Jakarta Transactions API 2.0 Jakarta WebSocket API 2.0 Jakarta Bean Validation 2.0 Helidon code was modified to support the corresponding specification&#8217;s versions. Incompatible changes for each specification The migration from javax to jakarta namespace makes this release backward incompatible with previous versions of MicroProfile. For each specification there are also API and functional changes that are described below. MicroProfile specifications MicroProfile Config 3.0.1 : Incompatible changes described in MicroProfile Config 3.0.1 Specification MicroProfile Fault Tolerance 4.0 : Incompatible changes described in MicroProfile Fault Tolerance 4.0 Specification MicroProfile Health 4.0 : Incompatible changes described in MicroProfile Health 4.0 Specification MicroProfile JWT Authentication 2.0 : Incompatible changes described in MicroProfile JWT Authentication 2.0 Specification MicroProfile Metrics 4.0 : Incompatible changes described in MicroProfile Metrics 4.0 Specification MicroProfile OpenAPI 3.0 : Incompatible changes described in MicroProfile OpenAPI 3.0 Specification MicroProfile OpenTracing 3.0 : Incompatible changes described in MicroProfile OpenTracing 3.0 Specification MicroProfile Rest Client 3.0 : Incompatible changes described in MicroProfile Rest Client 3.0 Specification Supported Jakarta EE specifications CDI (Jakarta Contexts and Dependency Injection) 3.0 : Changes described in CDI (Jakarta Contexts and Dependency Injection) 3.0 Specification JAX-RS (Jakarta RESTful Web Services) 3.0 : Moved to jakarta namespace. Changes described in JAX-RS (Jakarta RESTful Web Services) 3.0Specification JSON-B (Jakarta JSON Binding) 2.0 : Moved to jakarta namespace. Changes described in JSON-B (Jakarta JSON Binding) 2.0 Specification JSON-P (Jakarta JSON Processing) 2.0.1 : Moved to jakarta namespace. Jakarta Annotations 2.0 : Moved to jakarta namespace. Moved to jakarta namespace. Full information in Jakarta Annotations 2.0 Specification Jakarta Persistence API 3.0 : Moved to jakarta namespace. Changes described in Jakarta Persistence API 3.0 Specification Jakarta Transactions API 2.0 : Moved to jakarta namespace. Changes described in Jakarta Transactions API 2.0 Specification Jakarta WebSocket API 2.0 : Moved to jakarta namespace. Changes described in Jakarta WebSocket API 2.0 Specification Jakarta Bean Validation 2.0 : Moved to jakarta namespace. Changes described in Jakarta Bean Validation 2.0 Specification Before you migrate to Helidon 3.x, make sure that you have read each specification for a complete list of incompatible changes. ",
            "title": "MicroProfile 5.0 Support"
        },
        {
            "location": "mp/guides/migration_3x",
            "text": " Deprecations in the following classes: Resource - old configuration approach (since 2.0) Method Optional&lt;Resource&gt; create(Config, String) is removed. Use create(Config) instead; ThreadPoolSupplier - Named thread pools (since 2.4.2) Method ThreadPoolSupplier create(Config) is removed. Use create(Config, String) instead; Method ThreadPoolSupplier create() is removed. Use create(String) instead; Configuration changes: <markup lang=\"yaml\" ># old (deprecated approach) - kept so existing applications may work resources-prefix: test-1.resource-path: \"src/test/resources/sample.txt\" test-2.resource-resource-path: \"sample.txt\" test-3.resource-url: \"file:./src/test/resources/sample.txt\" test-4.resource-content-plain: \"content\" test-5.resource-content: \"YWJjZGVmZ8SNxZnFvsO6xa8=\" # new approach that does not use a prefix resources: test-1.resource.path: \"src/test/resources/sample.txt\" test-2.resource.resource-path: \"sample.txt\" ",
            "title": "Helidon Common"
        },
        {
            "location": "mp/guides/migration_3x",
            "text": " Deprecations in the following classes: ContentReaders - Methods with alternatives (since 2.0) ContentTypeCharset - Class with alternative (since 2.0) ContentWriters - Methods with alternatives (since 2.0) MessageBodyReaderContext - Methods with alternatives (since 2.0) MessageBodyWriterContext - Methods with alternatives (since 2.0) ReadableByteChannelPublisher - Class with alternative (since 2.0) ",
            "title": "Media Common"
        },
        {
            "location": "mp/guides/migration_3x",
            "text": " Deprecations in the following classes: MetricsSupport - 3 methods, replacing Config with metrics settings Method MetricsSupport create(MetricsSettings, RestServiceSettings) has new parameter; New method MetricsSupport create(MetricsSettings) ; New method MetricsSupport.Builder&lt;?&gt; builder() ; KeyPerformanceIndicatorMetricsSettings - new class in metrics API, for backward compatibility only Interface KeyPerformanceIndicatorMetricsSettings - marked for removal ; Interface KeyPerformanceIndicatorMetricsSettingsCompatibility - marked for removal ; RegistryFactory - New class in metrics API, for backward compatibility only Method RegistryFactory create() - marked for removal ; Method RegistryFactory create(Config config) - marked for removal ; Method RegistryFactory getInstance() - marked for removal ; Method RegistryFactory getInstance(Config config) - marked for removal ; ",
            "title": "Metrics"
        },
        {
            "location": "mp/guides/migration_3x",
            "text": " Deprecations in the following class: DataPropagationProvider - clearData should use new method Method void clearData() - marked for removal, use void clearData(T data) instead; ",
            "title": "Common Context"
        },
        {
            "location": "mp/guides/migration_3x",
            "text": " Deprecations: JavaMarshaller - removed support for JavaMarshaller New default marshaller supplier will throw an exception if the code falls to where the JavaMarshaller was returned before to inform developer of the change ",
            "title": "GRPC Core"
        },
        {
            "location": "mp/guides/migration_3x",
            "text": " Deprecations in the following class: CoordinatorClient - multiple methods removed Method Single&lt;URI&gt; start(String, long) - removed; Method Single&lt;URI&gt; start(URI, String, long) - removed; Method Single&lt;Optional&lt;URI&gt;&gt; join(URI, long, Participant) - removed; Method Single&lt;Void&gt; cancel(URI) - removed; Method Single&lt;Void&gt; close(URI) - removed; Method Single&lt;Void&gt; leave(URI, Participant) - removed; Method Single&lt;LRAStatus&gt; status(URI) - removed; Headers - class removed ",
            "title": "LRA"
        },
        {
            "location": "mp/guides/migration_3x",
            "text": " Deprecations in the following class: FormerHealthProbe - class marked for removal MessagingCdiExtension - Alternative methods used Method Map&lt;String, Boolean&gt; channelsLiveness() - marked for removal; Method Map&lt;String, Boolean&gt; channelsReadiness() - marked for removal; ",
            "title": "MP Messaging"
        },
        {
            "location": "mp/guides/migration_3x",
            "text": " Deprecations in the following class: Jwt - Audience can be a list (since 2.4.0) Method Builder audience(String) - removed, use addAudience(String) instead; ",
            "title": "JWT"
        },
        {
            "location": "mp/guides/migration_3x",
            "text": " Deprecations in the following class: MetricUtil - multiple methods removed Method public static &lt;E extends Member &amp; AnnotatedElement, A extends Annotation&gt; LookupResult&lt;A&gt; lookupAnnotation(E, Class&lt;? extends Annotation&gt;, Class&lt;?&gt;) - removed; Method &lt;A extends Annotation&gt; LookupResult&lt;A&gt; lookupAnnotation(AnnotatedType&lt;?&gt;, AnnotatedMethod&lt;?&gt;, Class&lt;A&gt;) - removed; Method &lt;E extends Member &amp; AnnotatedElement&gt; void registerMetric(MetricRegistry, E, Class&lt;?&gt;, Annotation, MatchingType) - removed; Method &lt;E extends Member &amp; AnnotatedElement&gt; void registerMetric(E, Class&lt;?&gt;, LookupResult&lt;? extends Annotation&gt;) - removed; Method &lt;E extends Member &amp; AnnotatedElement&gt; void registerMetric(E, Class&lt;?&gt;, Annotation, MatchingType) - removed; Method MetricsCdiExtension - multiple methods removed Method &lt;E extends Member &amp; AnnotatedElement&gt; void registerMetric(E, Class&lt;?&gt;, LookupResult&lt;? extends Annotation&gt;) - removed; Method &lt;E extends Member &amp; AnnotatedElement&gt; void registerMetricInternal(List&lt;RegistrationPrep&gt;, E, Class&lt;?&gt;, LookupResult&lt;? extends Annotation&gt;, Executable) - removed; Method void registerMetricsForAnnotatedSitesFromGrpcTest() - removed; Method recordMetricAnnotatedClass(@Observes @WithAnnotations({Counted.class, Metered.class, Timed.class, ConcurrentGauge.class, SimplyTimed.class, Gauge.class}) ProcessAnnotatedType&lt;?&gt;) - removed; Method &lt;T extends org.eclipse.microprofile.metrics.Metric&gt; MetricType getMetricType(T) - removed; ",
            "title": "MP Metrics"
        },
        {
            "location": "mp/guides/migration_3x",
            "text": " backwardCompatibleEol - set to false ",
            "title": "HTTP Signature Security Provider"
        },
        {
            "location": "mp/guides/migration_3x",
            "text": " Deprecations in the following class: HelidonRestServiceSupport - method configureEndpoint(Rules) deprecated. ",
            "title": "Service Common"
        },
        {
            "location": "mp/guides/migration_3x",
            "text": " io.helidon.webserver.staticcontent.* in WebServer - moved to a separate module. Fully removed from WebServer module. ",
            "title": "WebServer"
        },
        {
            "location": "mp/guides/migration_3x",
            "text": " The custom Helidon OCI clients have been deprecated. Use the OCI Java SDK instead. If you use Helidon MP you can inject OCI SDK clients by adding the dependency io.helidon.integrations.oci.sdk:helidon-integrations-oci-sdk-cdi . See Resolving compatibility issue with OCI SDK for detailed information on how to work around this issue. The MultiPart buffered readers have been deprecated. Use the MultiPart stream readers instead. Helidon Common Deprecations in the following classes: Resource - old configuration approach (since 2.0) Method Optional&lt;Resource&gt; create(Config, String) is removed. Use create(Config) instead; ThreadPoolSupplier - Named thread pools (since 2.4.2) Method ThreadPoolSupplier create(Config) is removed. Use create(Config, String) instead; Method ThreadPoolSupplier create() is removed. Use create(String) instead; Configuration changes: <markup lang=\"yaml\" ># old (deprecated approach) - kept so existing applications may work resources-prefix: test-1.resource-path: \"src/test/resources/sample.txt\" test-2.resource-resource-path: \"sample.txt\" test-3.resource-url: \"file:./src/test/resources/sample.txt\" test-4.resource-content-plain: \"content\" test-5.resource-content: \"YWJjZGVmZ8SNxZnFvsO6xa8=\" # new approach that does not use a prefix resources: test-1.resource.path: \"src/test/resources/sample.txt\" test-2.resource.resource-path: \"sample.txt\" Media Common Deprecations in the following classes: ContentReaders - Methods with alternatives (since 2.0) ContentTypeCharset - Class with alternative (since 2.0) ContentWriters - Methods with alternatives (since 2.0) MessageBodyReaderContext - Methods with alternatives (since 2.0) MessageBodyWriterContext - Methods with alternatives (since 2.0) ReadableByteChannelPublisher - Class with alternative (since 2.0) Metrics Deprecations in the following classes: MetricsSupport - 3 methods, replacing Config with metrics settings Method MetricsSupport create(MetricsSettings, RestServiceSettings) has new parameter; New method MetricsSupport create(MetricsSettings) ; New method MetricsSupport.Builder&lt;?&gt; builder() ; KeyPerformanceIndicatorMetricsSettings - new class in metrics API, for backward compatibility only Interface KeyPerformanceIndicatorMetricsSettings - marked for removal ; Interface KeyPerformanceIndicatorMetricsSettingsCompatibility - marked for removal ; RegistryFactory - New class in metrics API, for backward compatibility only Method RegistryFactory create() - marked for removal ; Method RegistryFactory create(Config config) - marked for removal ; Method RegistryFactory getInstance() - marked for removal ; Method RegistryFactory getInstance(Config config) - marked for removal ; Common Context Deprecations in the following class: DataPropagationProvider - clearData should use new method Method void clearData() - marked for removal, use void clearData(T data) instead; GRPC Core Deprecations: JavaMarshaller - removed support for JavaMarshaller New default marshaller supplier will throw an exception if the code falls to where the JavaMarshaller was returned before to inform developer of the change LRA Deprecations in the following class: CoordinatorClient - multiple methods removed Method Single&lt;URI&gt; start(String, long) - removed; Method Single&lt;URI&gt; start(URI, String, long) - removed; Method Single&lt;Optional&lt;URI&gt;&gt; join(URI, long, Participant) - removed; Method Single&lt;Void&gt; cancel(URI) - removed; Method Single&lt;Void&gt; close(URI) - removed; Method Single&lt;Void&gt; leave(URI, Participant) - removed; Method Single&lt;LRAStatus&gt; status(URI) - removed; Headers - class removed MP Messaging Deprecations in the following class: FormerHealthProbe - class marked for removal MessagingCdiExtension - Alternative methods used Method Map&lt;String, Boolean&gt; channelsLiveness() - marked for removal; Method Map&lt;String, Boolean&gt; channelsReadiness() - marked for removal; JWT Deprecations in the following class: Jwt - Audience can be a list (since 2.4.0) Method Builder audience(String) - removed, use addAudience(String) instead; MP Metrics Deprecations in the following class: MetricUtil - multiple methods removed Method public static &lt;E extends Member &amp; AnnotatedElement, A extends Annotation&gt; LookupResult&lt;A&gt; lookupAnnotation(E, Class&lt;? extends Annotation&gt;, Class&lt;?&gt;) - removed; Method &lt;A extends Annotation&gt; LookupResult&lt;A&gt; lookupAnnotation(AnnotatedType&lt;?&gt;, AnnotatedMethod&lt;?&gt;, Class&lt;A&gt;) - removed; Method &lt;E extends Member &amp; AnnotatedElement&gt; void registerMetric(MetricRegistry, E, Class&lt;?&gt;, Annotation, MatchingType) - removed; Method &lt;E extends Member &amp; AnnotatedElement&gt; void registerMetric(E, Class&lt;?&gt;, LookupResult&lt;? extends Annotation&gt;) - removed; Method &lt;E extends Member &amp; AnnotatedElement&gt; void registerMetric(E, Class&lt;?&gt;, Annotation, MatchingType) - removed; Method MetricsCdiExtension - multiple methods removed Method &lt;E extends Member &amp; AnnotatedElement&gt; void registerMetric(E, Class&lt;?&gt;, LookupResult&lt;? extends Annotation&gt;) - removed; Method &lt;E extends Member &amp; AnnotatedElement&gt; void registerMetricInternal(List&lt;RegistrationPrep&gt;, E, Class&lt;?&gt;, LookupResult&lt;? extends Annotation&gt;, Executable) - removed; Method void registerMetricsForAnnotatedSitesFromGrpcTest() - removed; Method recordMetricAnnotatedClass(@Observes @WithAnnotations({Counted.class, Metered.class, Timed.class, ConcurrentGauge.class, SimplyTimed.class, Gauge.class}) ProcessAnnotatedType&lt;?&gt;) - removed; Method &lt;T extends org.eclipse.microprofile.metrics.Metric&gt; MetricType getMetricType(T) - removed; HTTP Signature Security Provider backwardCompatibleEol - set to false Service Common Deprecations in the following class: HelidonRestServiceSupport - method configureEndpoint(Rules) deprecated. WebServer io.helidon.webserver.staticcontent.* in WebServer - moved to a separate module. Fully removed from WebServer module. ",
            "title": "Deprecations and API Changes"
        },
        {
            "location": "mp/guides/mp-tutorial",
            "text": " This tutorial describes how to build a Helidon MicroProfile (MP) application from scratch including JSON REST endpoints, metrics, health check, and configuration. ",
            "title": "preambule"
        },
        {
            "location": "mp/guides/mp-tutorial",
            "text": " For this 30 minute tutorial, you will need the following: <div class=\"table__overflow elevation-1 flex sm7 \"> A Helidon MP Application You can use your own application or use the Helidon MP Quickstart to create a sample application. Java&#160;SE&#160;17 ( Open&#160;JDK&#160;17 ) Helidon requires Java 17+. Maven 3.6.1+ Helidon requires Maven 3.6.1+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop . curl (Optional) for testing <markup lang=\"bash\" title=\"Verify Prerequisites\" >java -version mvn --version docker --version kubectl version --short <markup lang=\"bash\" title=\"Setting JAVA_HOME\" ># On Mac export JAVA_HOME=`/usr/libexec/java_home -v 17` # On Linux # Use the appropriate path to your JDK export JAVA_HOME=/usr/lib/jvm/jdk-17 ",
            "title": "What You Need"
        },
        {
            "location": "mp/guides/mp-tutorial",
            "text": " This tutorial demonstrates how to create the application from scratch, without using the Maven archetypes as a quickstart. Create a new empty directory for the project (for example, helidon-mp-tutorial ). Change into this directory. Create a new Maven POM file (called pom.xml ) and add the following content: <markup lang=\"xml\" title=\"Initial Maven POM file\" >&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;io.helidon.applications&lt;/groupId&gt; &lt;artifactId&gt;helidon-mp&lt;/artifactId&gt; &lt;version&gt;3.0.2&lt;/version&gt; &lt;relativePath/&gt; &lt;/parent&gt; &lt;groupId&gt;io.helidon.examples&lt;/groupId&gt; &lt;artifactId&gt;helidon-mp-tutorial&lt;/artifactId&gt; &lt;name&gt;${project.artifactId}&lt;/name&gt; &lt;properties&gt; &lt;mainClass&gt;io.helidon.examples.Main&lt;/mainClass&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.bundles&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-dependency-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;copy-libs&lt;/id&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.jboss.jandex&lt;/groupId&gt; &lt;artifactId&gt;jandex-maven-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;make-index&lt;/id&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/project&gt; The POM file contains the basic project information and configurations needed to get started and does the following: Includes the Helidon MP application parent pom. This parent pom contains dependency and plugin management to keep your application&#8217;s pom simple and clean. Establishes the Maven coordinates for the new project. Sets the mainClass which will be used later when building a JAR file. The class will be created later in this tutorial. Adds a dependency for the MicroProfile bundle which allows the use of MicroProfile features in the application. The helidon-mp parent pom includes dependency management, so you don&#8217;t need to include a version number here. You will automatically use the version of Helidon that matches the version of the parent pom ({helidon.version} in this case). Adds plugins to be executed during the build. The maven-dependency-plugin is used to copy the runtime dependencies into your target directory. The jandex-maven-plugin builds an index of your class files for faster loading. The Helidon parent pom handles the details of configuring these plugins. But you can modify the configuration here. MicroProfile contains features like Metrics, Health Check, Streams Operators, Open Tracing, OpenAPI, REST client, and fault tolerance. You can find detailed information about MicroProfile on the Eclipse MicroProfile site. With this pom.xml , the application can be built successfully with Maven: <markup lang=\"bash\" >mvn clean package This will create a JAR file in the target directory. The warning message JAR will be empty - no content was marked for inclusion! can be ignored for now because there is no actual content in the application yet. ",
            "title": "Create the Maven Project"
        },
        {
            "location": "mp/guides/mp-tutorial",
            "text": " The actual application logic can be created now. Create a directory for your source code, and then create directories for the package hierarchy: <markup lang=\"bash\" title=\"Create directories for source code\" >mkdir -p src/main/java/io/helidon/examples The application will be a simple REST service that will return a greeting to the caller. The first iteration of the application will contain a resource class and a Main class which will be used to start up the Helidon server and the application. Technically, your own main class is not needed unless you want to control the startup sequence. You can set the mainClass property to io.helidon.microprofile.cdi.Main and it will use Helidon&#8217;s default main class. The GreetResource is defined in the GreetResource.java class as shown below: <markup lang=\"java\" title=\"src/main/java/io/helidon/examples/GreetResource.java\" >package io.helidon.examples; import jakarta.enterprise.context.RequestScoped; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.core.MediaType; import java.util.Collections; @Path(\"/greet\") @RequestScoped public class GreetResource { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) public JsonObject getDefaultMessage() { return JSON.createObjectBuilder() .add(\"message\", \"Hello World\") .build(); } } This class is annotated with Path which sets the path for this resource as /greet . The RequestScoped annotation defines that this bean is request scoped. The request scope is active only for the duration of one web service invocation and it is destroyed at the end of that invocation. You can learn more about scopes and contexts, and how they are used from the Specification . A public JsonObject getDefaultMessage() method is defined which is annotated with GET , meaning it will accept the HTTP GET method. It is also annotated with Produces(MediaType.APPLICATION_JSON) which declares that this method will return JSON data. The method body creates a JSON object containing a single object named \"message\" with the content \"Hello World\". This method will be expanded and improved later in the tutorial. So far this is just a JAX-RS application, with no Helidon or MicroProfile specific code in it. There are many JAX-RS tutorials available if you want to learn more about this kind of application. A main class is also required to start up the server and run the application. If you don&#8217;t use Helidon&#8217;s built-in main class you can define your own: <markup lang=\"java\" title=\"src/main/java/io/helidon/examples/Main.java\" >package io.helidon.examples; import io.helidon.microprofile.server.Server; import java.io.IOException; public final class Main { private Main() { } public static void main(final String[] args) throws IOException { Server server = startServer(); System.out.println(\"http://localhost:\" + server.port() + \"/greet\"); } static Server startServer() { return Server.create().start(); } } In this class, a main method is defined which starts the Helidon MP server and prints out a message with the listen address. Notice that this class has an empty no-args constructor to make sure this class cannot be instantiated. The MicroProfile server is started with the default configuration. Helidon MP applications also require a beans.xml resource file to tell Helidon to use the annotations discussed above to discover Java beans in the application. Create a beans.xml in the src/main/resources/META-INF directory with the following content: <markup lang=\"xml\" title=\"src/main/resources/META-INF/beans.xml\" >&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;beans xmlns=\"http://xmlns.jcp.org/xml/ns/javaee\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/beans_2_0.xsd\" version=\"2.0\" bean-discovery-mode=\"annotated\"&gt; &lt;/beans&gt; The bean-discovery-mode tells Helidon to look for the annotations to discover Java beans in the application. ",
            "title": "Start Implementing the MicroProfile Application"
        },
        {
            "location": "mp/guides/mp-tutorial",
            "text": " Helidon MP applications are packaged into a JAR file and the dependencies are copied into a libs directory. You can now build the application. <markup lang=\"bash\" title=\"Build the Application\" >mvn package This will build the application jar and save all runtime dependencies in the target/libs directory. This means you can easily start the application by running the application jar file: <markup lang=\"bash\" title=\"Run the application\" >java -jar target/helidon-mp-tutorial.jar At this stage, the application is a very simple \"Hello World\" greeting service. It supports a single GET request for generating a greeting message. The response is encoded using JSON. For example: <markup lang=\"bash\" title=\"Try the Application\" >curl -X GET http://localhost:7001/greet {\"message\":\"Hello World!\"} In the output you can see the JSON output from the getDefaultMessage() method that was discussed earlier. The server has used a default port 7001 . The application can be stopped cleanly by pressing Ctrl+C. ",
            "title": "Build the Application"
        },
        {
            "location": "mp/guides/mp-tutorial",
            "text": " Helidon MP applications can use the META-INF/microprofile-config.properties file to specify configuration data. This file (resource) is read by default if it is present on the classpath. Create this file in src/main/resources/META-INF with the following content: <markup lang=\"bash\" title=\"Initial microprofile-config.properties\" ># Microprofile server properties server.port=8080 server.host=0.0.0.0 Rebuild the application and run it again. Notice that it now uses port 8080 as specified in the configuration file. You can learn more about options for configuring the Helidon Server on the Server Configuration page. In addition to predefined server properties, application-specific configuration information can be added to this file. Add the app.greeting property to the file as shown below. This property will be used to set the content of greeting message. <markup lang=\"bash\" title=\"Updated META-INF/microprofile-config.properties\" ># Microprofile server properties server.port=8080 server.host=0.0.0.0 # Application properties app.greeting=Hello Add a new \"provider\" class to read this property and make it available to the application. The class will be called GreetingProvider.java and have the following content: <markup lang=\"java\" title=\"src/main/java/io/helidon/examples/GreetingProvider.java\" >package io.helidon.examples; import org.eclipse.microprofile.config.inject.ConfigProperty; import jakarta.enterprise.context.ApplicationScoped; import jakarta.inject.Inject; import java.util.concurrent.atomic.AtomicReference; @ApplicationScoped public class GreetingProvider { private final AtomicReference&lt;String&gt; message = new AtomicReference&lt;&gt;(); @Inject public GreetingProvider(@ConfigProperty(name = \"app.greeting\") String message) { this.message.set(message); } String getMessage() { return message.get(); } void setMessage(String message) { this.message.set(message); } } This class also has the ApplicationScoped annotation, so it will persist for the life of the application. The class contains an AtomicReference to a String where the greeting will be stored. The AtomicReference provides lock-free thread-safe access to the underlying String . The public GreetingProvider(&#8230;&#8203;) constructor is annotated with Inject which tells Helidon to use Contexts and Dependency Injection to provide the needed values. In this case, the String message is annotated with ConfigProperty(name = \"app.greeting\") so Helidon will inject the property from the configuration file with the key app.greeting . This method demonstrates how to read configuration information into the application. A getter and setter are also included in this class. The GreetResource must be updated to use this value instead of the hard coded response. Make the following updates to that class: <markup lang=\"java\" title=\"Updated GreetResource class\" >package io.helidon.examples; import jakarta.enterprise.context.RequestScoped; import jakarta.inject.Inject; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.core.MediaType; import java.util.Collections; @Path(\"/greet\") @RequestScoped public class GreetResource { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); private final GreetingProvider greetingProvider; @Inject public GreetResource(GreetingProvider greetingConfig) { this.greetingProvider = greetingConfig; } @GET @Produces(MediaType.APPLICATION_JSON) public JsonObject getDefaultMessage() { return createResponse(\"World\"); } private JsonObject createResponse(String who) { String msg = String.format(\"%s %s!\", greetingProvider.getMessage(), who); return JSON.createObjectBuilder() .add(\"message\", msg) .build(); } } This updated class adds a GreetingProvider and uses constructor injection to get the value from the configuration file. The logic to create the response message is refactored into a createResponse method and the getDefaultMessage() method is updated to use this new method. In createResponse() the message is obtained from the GreetingProvider which in turn got it from the configuration files. Rebuild and run the application. Notice that it now uses the greeting from the configuration file. Change the configuration file and restart the application, notice that it uses the changed value. To learn more about Helidon MP configuration please see the Config section of the documentation. ",
            "title": "Configuration"
        },
        {
            "location": "mp/guides/mp-tutorial",
            "text": " In this section, the application will be extended to add a PUT resource method which will allow users to update the greeting and a second GET resource method which will accept a parameter. Here are the two new methods to add to GreetResource.java : <markup lang=\"java\" title=\"New methods for GreetResource.java\" >import jakarta.ws.rs.Consumes; import jakarta.ws.rs.PUT; import jakarta.ws.rs.PathParam; import jakarta.ws.rs.core.Response; // some lines omitted @Path(\"/{name}\") @GET @Produces(MediaType.APPLICATION_JSON) public JsonObject getMessage(@PathParam(\"name\") String name) { return createResponse(name); } @Path(\"/greeting\") @PUT @Consumes(MediaType.APPLICATION_JSON) @Produces(MediaType.APPLICATION_JSON) public Response updateGreeting(JsonObject jsonObject) { if (!jsonObject.containsKey(\"greeting\")) { JsonObject entity = JSON.createObjectBuilder() .add(\"error\", \"No greeting provided\") .build(); return Response.status(Response.Status.BAD_REQUEST).entity(entity).build(); } String newGreeting = jsonObject.getString(\"greeting\"); greetingProvider.setMessage(newGreeting); return Response.status(Response.Status.NO_CONTENT).build(); } The first of these two methods implements a new HTTP GET service that returns JSON and it has a path parameter. The Path annotation defines the next part of the path to be a parameter named name . In the method arguments the PathParam(\"name\") annotation on String name has the effect of passing the parameter from the URL into this method as name . The second method implements a new HTTP PUT service which produces and consumes JSON, note the Consumes and PUT annotations. It also defines a path of \"/greeting\". Notice that the method argument is a JsonObject . Inside the method body there is code to check for the expected JSON, extract the value and update the message in the GreetingProvider . Rebuild and run the application. Test the new services using curl commands similar to those shown below: <markup lang=\"bash\" title=\"Testing the new services\" >curl -X GET http://localhost:8080/greet {\"message\":\"Hello World!\"} curl -X GET http://localhost:8080/greet/Joe {\"message\":\"Hello Joe!\"} curl -X PUT -H \"Content-Type: application/json\" -d '{\"greeting\" : \"Hola\"}' http://localhost:8080/greet/greeting curl -X GET http://localhost:8080/greet/Jose {\"message\":\"Hola Jose!\"} Helidon MP provides many other features which can be added to the application. ",
            "title": "Extending the Application"
        },
        {
            "location": "mp/guides/mp-tutorial",
            "text": " The application logging can be customized. The default logging provider is java.util.logging , however it is possible to use other providers. In this tutorial the default provider is used. Create a logging.properties file in src/main/resources with the following content: <markup lang=\"properties\" title=\"Example logging.properties file\" ># Send messages to the console handlers=io.helidon.common.HelidonConsoleHandler # HelidonConsoleHandler uses a SimpleFormatter subclass that replaces \"!thread!\" with the current thread java.util.logging.SimpleFormatter.format=%1$tY.%1$tm.%1$td %1$tH:%1$tM:%1$tS %4$s %3$s !thread!: %5$s%6$s%n # Global logging level. Can be overridden by specific loggers .level=INFO The Helidon console logging handler is configured. This handler writes to System.out , does not filter by level and uses a custom SimpleFormatter that supports thread names. The format string is set using the standard options to include the timestamp, thread name and message. The global logging level is set to INFO . The Helidon MicroProfile server will detect the new logging.properties file and configure the LogManager for you. Rebuild and run the application and notice the new logging format takes effect. <markup lang=\"bash\" title=\"Log output\" >// before Aug 22, 2019 11:10:11 AM io.helidon.webserver.NettyWebServer lambda$start$8 INFO: Channel '@default' started: [id: 0xd0afba31, L:/0:0:0:0:0:0:0:0:8080] Aug 22, 2019 11:10:11 AM io.helidon.microprofile.server.ServerImpl lambda$start$10 INFO: Server started on http://localhost:8080 (and all other host addresses) in 182 milliseconds. http://localhost:8080/greet // after 2019.08.22 11:24:42 INFO io.helidon.webserver.NettyWebServer Thread[main,5,main]: Version: 1.2.0 2019.08.22 11:24:42 INFO io.helidon.webserver.NettyWebServer Thread[nioEventLoopGroup-2-1,10,main]: Channel '@default' started: [id: 0x8f652dfe, L:/0:0:0:0:0:0:0:0:8080] 2019.08.22 11:24:42 INFO io.helidon.microprofile.server.ServerImpl Thread[nioEventLoopGroup-2-1,10,main]: Server started on http://localhost:8080 (and all other host addresses) in 237 milliseconds. http://localhost:8080/greet ",
            "title": "Logging"
        },
        {
            "location": "mp/guides/mp-tutorial",
            "text": " Helidon provides built-in support for metrics endpoints. <markup lang=\"bash\" title=\"Metrics in Prometheus Format\" >curl -s -X GET http://localhost:8080/metrics <markup lang=\"bash\" title=\"Metrics in JSON Format\" >curl -H 'Accept: application/json' -X GET http://localhost:8080/metrics It is possible to disable metrics by adding properties to the microprofile-config.properties file, for example: <markup lang=\"bash\" title=\"Disable a metric\" >metrics.base.classloader.currentLoadedClass.count.enabled=false Call the metrics endpoint before adding this change to confirm that the metric is included, then add the property to disable the metric, rebuild and restart the application and check again: <markup lang=\"bash\" title=\"Checking metrics before and after disabling the metric\" ># before curl -s http://localhost:8080/metrics | grep classloader_current # TYPE base:classloader_current_loaded_class_count counter # HELP base:classloader_current_loaded_class_count Displays the number of classes that are currently loaded in the Java virtual machine. base:classloader_current_loaded_class_count 7936 # after curl -s http://localhost:8080/metrics | grep classloader_current # (no output) Helidon also support custom metrics. To add a new metric, annotate the JAX-RS resource with one of the metric annotations as shown in the example below: You can find details of the available annotations in the MicroProfile Metrics Specification . <markup lang=\"java\" title=\"Updated GreetResource.java with custom metrics\" >import org.eclipse.microprofile.metrics.annotation.Timed; // some lines omitted @GET @Produces(MediaType.APPLICATION_JSON) @Timed public JsonObject getDefaultMessage() { return createResponse(\"World\"); } The Timed annotation is added to the getDefaultMessage() method. Rebuild and run the application. Make some calls to the endpoint ( http://localhost:8080/greet ) so there will be some data to report. Then obtain the application metrics as follows: <markup lang=\"bash\" title=\"Checking the application metrics\" >curl -H \"Accept: application/json\" http://localhost:8080/metrics/application { \"io.helidon.examples.GreetResource.getDefaultMessage\": { \"count\": 2, \"meanRate\": 0.036565171873527716, \"oneMinRate\": 0.015991117074135343, \"fiveMinRate\": 0.0033057092356765017, \"fifteenMinRate\": 0.0011080303990206543, \"min\": 78658, \"max\": 1614077, \"mean\": 811843.8728029992, \"stddev\": 766932.8494434259, \"p50\": 78658, \"p75\": 1614077, \"p95\": 1614077, \"p98\": 1614077, \"p99\": 1614077, \"p999\": 1614077 } } Learn more about using Helidon and MicroProfile metrics in the Metrics Guide . ",
            "title": "Metrics"
        },
        {
            "location": "mp/guides/mp-tutorial",
            "text": " Helidon provides built-in support for health check endpoints. Obtain the built-in health check using the following URL: <markup lang=\"bash\" title=\"Health check\" >curl -s -X GET http://localhost:8080/health { \"outcome\": \"UP\", \"status\": \"UP\", \"checks\": [ { \"name\": \"deadlock\", \"state\": \"UP\", \"status\": \"UP\" }, { \"name\": \"diskSpace\", \"state\": \"UP\", \"status\": \"UP\", \"data\": { \"free\": \"381.23 GB\", \"freeBytes\": 409340088320, \"percentFree\": \"43.39%\", \"total\": \"878.70 GB\", \"totalBytes\": 943491723264 } }, { \"name\": \"heapMemory\", \"state\": \"UP\", \"status\": \"UP\", \"data\": { \"free\": \"324.90 MB\", \"freeBytes\": 340682920, \"max\": \"3.46 GB\", \"maxBytes\": 3715629056, \"percentFree\": \"97.65%\", \"total\": \"408.00 MB\", \"totalBytes\": 427819008 } } ] } Endpoints for readiness and liveness checks are also provided by default. Obtain the default results using these URLs, which return the same result as the previous example.: <markup lang=\"bash\" title=\"Default readiness and liveness endpoints\" ># readiness curl -i -X GET http://localhost:8080/health/ready # liveness curl -i -X GET http://localhost:8080/health/live Helidon allows the addition of custom health checks to applications. Create a new class GreetHealthcheck.java with the following content: <markup lang=\"java\" title=\"src/main/java/io/helidon/examples/GreetHealthcheck.java\" >package io.helidon.examples; import jakarta.enterprise.context.ApplicationScoped; import jakarta.inject.Inject; import org.eclipse.microprofile.health.HealthCheck; import org.eclipse.microprofile.health.HealthCheckResponse; import org.eclipse.microprofile.health.Liveness; @Liveness @ApplicationScoped public class GreetHealthcheck implements HealthCheck { private GreetingProvider provider; @Inject public GreetHealthcheck(GreetingProvider provider) { this.provider = provider; } @Override public HealthCheckResponse call() { String message = provider.getMessage(); return HealthCheckResponse.named(\"greeting\") .state(\"Hello\".equals(message)) .withData(\"greeting\", message) .build(); } } This class has the MicroProfile Liveness annotation which tells Helidon that this class provides a custom health check. You can learn more about the available annotations in the MicroProfile Health Protocol and Wireformat document. This class also has the ApplicationScoped annotation, as seen previously. The GreetingProvider is injected using Context and Dependency Injection. This example will use the greeting to determine whether the application is healthy, this is a contrived example for demonstration purposes. Health checks must implement the HealthCheck functional interface, which includes the method HealthCheckResponse call() . Helidon will invoke the call() method to verify the healthiness of the application. In this example, the application is deemed to be healthy if the GreetingProvider,getMessage() method returns the string \"Hello\" and unhealthy otherwise. Rebuild the application, make sure that the mp.conf has the greeting set to something other than \"Hello\" and then run the application and check the health: <markup lang=\"bash\" title=\"Custom health check reporting unhealthy state\" >curl -i -X GET http://localhost:8080/health/live HTTP/1.1 503 Service Unavailable Content-Type: application/json Date: Fri, 23 Aug 2019 10:07:23 -0400 transfer-encoding: chunked connection: keep-alive {\"outcome\":\"DOWN\",\"status\":\"DOWN\",\"checks\":[{\"name\":\"deadlock\",\"state\":\"UP\",\"status\":\"UP\"},{\"name\":\"diskSpace\",\"state\":\"UP\",\"status\":\"UP\",\"data\":{\"free\":\"381.08 GB\",\"freeBytes\":409182306304,\"percentFree\":\"43.37%\",\"total\":\"878.70 GB\",\"totalBytes\":943491723264}},{\"name\":\"greeting\",\"state\":\"DOWN\",\"status\":\"DOWN\",\"data\":{\"greeting\":\"Hey\"}},{\"name\":\"heapMemory\",\"state\":\"UP\",\"status\":\"UP\",\"data\":{\"free\":\"243.81 MB\",\"freeBytes\":255651048,\"max\":\"3.46 GB\",\"maxBytes\":3715629056,\"percentFree\":\"98.58%\",\"total\":\"294.00 MB\",\"totalBytes\":308281344}}]} The HTTP return code is now 503 Service Unavailable. The status is reported as \"DOWN\" and the custom check is included in the output. Now update the greeting to \"Hello\" using the following request, and then check health again: <markup lang=\"bash\" title=\"Update the greeting and check health again\" ># update greeting curl -i -X PUT -H \"Content-Type: application/json\" -d '{\"greeting\": \"Hello\"}' http://localhost:8080/greet/greeting HTTP/1.1 204 No Content Date: Thu, 22 Aug 2019 13:29:57 -0400 connection: keep-alive # check health curl -i -X GET http://localhost:8080/health/live HTTP/1.1 200 OK Content-Type: application/json Date: Fri, 23 Aug 2019 10:08:09 -0400 connection: keep-alive content-length: 536 {\"outcome\":\"UP\",\"status\":\"UP\",\"checks\":[{\"name\":\"deadlock\",\"state\":\"UP\",\"status\":\"UP\"},{\"name\":\"diskSpace\",\"state\":\"UP\",\"status\":\"UP\",\"data\":{\"free\":\"381.08 GB\",\"freeBytes\":409179811840,\"percentFree\":\"43.37%\",\"total\":\"878.70 GB\",\"totalBytes\":943491723264}},{\"name\":\"greeting\",\"state\":\"UP\",\"status\":\"UP\",\"data\":{\"greeting\":\"Hello\"}},{\"name\":\"heapMemory\",\"state\":\"UP\",\"status\":\"UP\",\"data\":{\"free\":\"237.25 MB\",\"freeBytes\":248769720,\"max\":\"3.46 GB\",\"maxBytes\":3715629056,\"percentFree\":\"98.40%\",\"total\":\"294.00 MB\",\"totalBytes\":308281344}}]} The PUT returns a HTTP 204. The health check now returns a HTTP 200. The status is now reported as \"UP\" and the details are provided in the checks. Learn more about health checks in the Health Check Guide . ",
            "title": "Health Check"
        },
        {
            "location": "mp/guides/mp-tutorial",
            "text": " To run the application in Docker (or Kubernetes), a Dockerfile is needed to build a Docker image. To build the Docker image, you need to have Docker installed and running on your system. Add a new Dockerfile in the project root directory with the following content: <markup lang=\"bash\" title=\"Dockerfile content\" >FROM maven:3.8.4-openjdk-17-slim as build WORKDIR /helidon ADD pom.xml . RUN mvn package -DskipTests ADD src src RUN mvn package -DskipTests RUN echo \"done!\" FROM openjdk:17-jdk-slim WORKDIR /helidon COPY --from=build /helidon/target/helidon-mp-tutorial.jar ./ COPY --from=build /helidon/target/libs ./libs CMD [\"java\", \"-jar\", \"helidon-mp-tutorial.jar\"] EXPOSE 8080 This Dockerfile uses Docker&#8217;s multi-stage build feature. The FROM keyword creates the first stage. In this stage, the base container has the build tools needed to build the application. These are not required to run the application, so the second stage uses a smaller container. Add the pom.xml and running an \"empty\" maven build will download all of the dependencies and plugins in this layer. This will make future builds faster because they will use this cached layer rather than downloading everything again. Add the source code and do the real build. Start a second stage using a much smaller runtime image. Copy the binary and libraries from the first stage. Set the initial command and expose port 8080. To create the Docker image, use the following command: <markup lang=\"bash\" title=\"Docker build\" >docker build -t helidon-mp-tutorial . Make sure the application is shutdown if it was still running locally so that port 8080 will not be in use, then start the application in Docker using the following command: <markup lang=\"bash\" title=\"Run Docker Image\" >docker run --rm -p 8080:8080 helidon-mp-tutorial:latest Try the application as before. <markup lang=\"bash\" title=\"Try the application\" >curl http://localhost:8080/greet/bob {\"message\":\"Howdee bob!\"} curl http://localhost:8080/health/ready {\"outcome\":\"UP\",\"status\":\"UP\",\"checks\":[]} ",
            "title": "Build a Docker Image"
        },
        {
            "location": "mp/guides/mp-tutorial",
            "text": " If you don&#8217;t have access to a Kubernetes cluster, you can install one on your desktop . Then deploy the example: <markup lang=\"bash\" title=\"Verify connectivity to cluster\" >kubectl cluster-info kubectl get nodes To deploy the application to Kubernetes, a Kubernetes YAML file that defines the deployment and associated resources is needed. In this case all that is required is the deployment and a service. Create a file called app.yaml in the project&#8217;s root directory with the following content: <markup lang=\"yaml\" title=\"Kubernetes YAML file\" >--- kind: Service apiVersion: v1 metadata: name: helidon-mp-tutorial labels: app: helidon-mp-tutorial spec: type: NodePort selector: app: helidon-mp-tutorial ports: - port: 8080 targetPort: 8080 name: http --- kind: Deployment apiVersion: apps/v1 metadata: name: helidon-mp-tutorial spec: replicas: 1 selector: matchLabels: app: helidon-mp-tutorial template: metadata: labels: app: helidon-mp-tutorial version: v1 spec: containers: - name: helidon-mp-tutorial image: helidon-mp-tutorial imagePullPolicy: IfNotPresent ports: - containerPort: 8080 Define a Service to provide access to the application. Define a NodePort to expose the application outside the Kubernetes cluster. Define a Deployment of the application. Define how many replicas of the application to run. Define the Docker image to use - this must be the one that was built in the previous step. If the image was built on a different machine to the one where Kubernetes is running, or if Kubernetes is running on multiple machines (worker nodes) then the image must either be manually copied to each node or otherwise pushed to a Docker registry that is accessible to the worker nodes. This Kubernetes YAML file can be used to deploy the application to Kubernetes: <markup lang=\"bash\" title=\"Deploy the application to Kubernetes\" >kubectl create -f app.yaml kubectl get pods # Wait for quickstart pod to be RUNNING Remember, if Kubernetes is running on a different machine, or inside a VM (as in Docker for Desktop) then the Docker image must either be manually copied to the Kubernetes worker nodes or pushed to a Docker registry that is accessible to those worker nodes. Update the image entry in the example above to include the Docker registry name. If the registry is private a Docker registry secret will also be required. The step above created a service that is exposed using any available node port. Kubernetes allocates a free port. Lookup the service to find the port. <markup lang=\"bash\" title=\"Lookup the service\" >kubectl get service helidon-mp-tutorial Note the PORTs. The application can be exercised as before but use the second port number (the NodePort) instead of 8080. For example: <markup lang=\"bash\" title=\"Access the application\" >curl -X GET http://localhost:31431/greet If desired, the Kubernetes YAML file can also be used to remove the application from Kubernetes as follows: <markup lang=\"bash\" title=\"Remove the application from Kubernetes\" >kubectl delete -f app.yaml ",
            "title": "Deploy the application to Kubernetes"
        },
        {
            "location": "mp/guides/mp-tutorial",
            "text": " This tutorial demonstrated how to build a new Helidon MP application, how to use Helidon and MicroProfile configuration, logging, metrics, and health checks. It also demonstrated how to package the application in a Docker image and run it in Kubernetes. There were several links to more detailed information included in the tutorial. These links are repeated below and can be explored to learn more details about Helidon application development. ",
            "title": "Summary"
        },
        {
            "location": "mp/guides/mp-tutorial",
            "text": " Eclipse MicroProfile Contexts and Dependency Injection Specification Server Configuration Config MicroProfile Metrics Specification Metrics Guide MicroProfile Health Protocol and Wireformat Install Kubernetes on your desktop ",
            "title": "Related links"
        },
        {
            "location": "mp/guides/overview",
            "text": " Quickstart MP Create your first Helidon MP application in under 5 minutes. ",
            "title": "Getting Started"
        },
        {
            "location": "mp/guides/overview",
            "text": " MP Config Guide Learn how to configure a Helidon MP application. MP Health Check Guide Learn how to use Helidon MP built-in and custom health checks. MP Metrics Guide Learn how to use Helidon MP built-in and application metrics. MP Tracing Guide Learn how to trace a Helidon MP application. Helidon MP Tutorial Learn how to build a Helidon MicroProfile (MP) application from scratch. Helidon MP Upgrade guide Learn how to upgrade your Helidon MP application from 1.x to 2.x. OIDC Tutorial Learn how to set up OIDC security in your Helidon MP application. Helidon MP Tracing Learn how to use tracing in your Helidon MP application. Testing with JUnit 5 Learn how to use JUnit5 for testing your applications. Helidon MP and JBatch Learn how to use JBatch with Helidon MP. Performance tuning in Helidon MP Learn how to improve performance of your application. ",
            "title": "Helidon MP Guides"
        },
        {
            "location": "mp/guides/overview",
            "text": " Maven Guide Using Helidon in your Maven project. Gradle Guide Using Helidon in your Gradle project. GraalVM Native Images Learn how to build a GraalVM native image for your Helidon application both on your desktop and as part of a Docker image. Custom Runtime Images using jlink Learn how to build a custom runtime Java image for your Helidon application both on your desktop and as part of a Docker image. Building Container Images with Jib Learn how to use Jib to create a container image without Docker. Deploying to OKE Learn how to deploy your application to Oracle Cloud Infrastructure Container Engine for Kubernetes (OKE). ",
            "title": "Build and Deploy"
        },
        {
            "location": "mp/guides/performance-tuning",
            "text": " In this guide you fill find basic advice for performance tuning of your Helidon application. Most of them target Netty tuning, as Helidon is based on it. You should also consider configuring/tuning Java heap size as per any Java application. ",
            "title": "preambule"
        },
        {
            "location": "mp/guides/performance-tuning",
            "text": " Use helidon-microprofile-core dependency (and not the helidon-microprofile dependency) and add only what you use. For example: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.bundles&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-core&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-metrics&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.health&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-health&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.media&lt;/groupId&gt; &lt;artifactId&gt;helidon-media-jsonp&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Use io.helidon.microprofile.bundles:helidon-microprofile-core "
        },
        {
            "location": "mp/guides/performance-tuning",
            "text": " The Helidon server thread-pool takes requests from Netty and invokes your JAX-RS endpoints. You can control lts configuration in microprofile-config.properties . This is Helidon MP specific only. <markup lang=\"properties\" >server.executor-service.core-pool-size: 2 server.executor-service.max-pool-size: 4 To verify settings increase the log level for Helidon&#8217;s executor service by adding this to your logging.properties : <markup lang=\"properties\" >io.helidon.common.configurable.ThreadPool.level=FINE ",
            "title": "Configure Helidon server pool size"
        },
        {
            "location": "mp/guides/performance-tuning",
            "text": " In some situations Netty can aggressively allocate memory per request. This has been addressed in recent versions of Helidon and Netty, but if you are running an earlier version set this system property when you start your Helidon application: <markup >-Dio.netty.allocator.maxOrder=6 You can try smaller numbers. ",
            "title": "Configure Netty&#8217;s maxOrder (Helidon 2.4.1 or earlier)"
        },
        {
            "location": "mp/guides/performance-tuning",
            "text": " The Netty worker thread-pool is what handles your incoming requests. It defaults to 2*NCPU. To set it to something else you can set this property in microprofile-config.properties : <markup lang=\"properties\" >server.worker-count=4 Configure Helidon server pool size The Helidon server thread-pool takes requests from Netty and invokes your JAX-RS endpoints. You can control lts configuration in microprofile-config.properties . This is Helidon MP specific only. <markup lang=\"properties\" >server.executor-service.core-pool-size: 2 server.executor-service.max-pool-size: 4 To verify settings increase the log level for Helidon&#8217;s executor service by adding this to your logging.properties : <markup lang=\"properties\" >io.helidon.common.configurable.ThreadPool.level=FINE Configure Netty&#8217;s maxOrder (Helidon 2.4.1 or earlier) In some situations Netty can aggressively allocate memory per request. This has been addressed in recent versions of Helidon and Netty, but if you are running an earlier version set this system property when you start your Helidon application: <markup >-Dio.netty.allocator.maxOrder=6 You can try smaller numbers. ",
            "title": "Configure Netty worker thread pool size"
        },
        {
            "location": "mp/guides/quickstart",
            "text": " This guide describes a basic example of an Helidon MP application using Docker and Kubernetes. ",
            "title": "preambule"
        },
        {
            "location": "mp/guides/quickstart",
            "text": " For this 5 minute tutorial, you will need the following: <div class=\"table__overflow elevation-1 flex sm7 \"> A Helidon MP Application You can use your own application or use the Helidon MP Quickstart to create a sample application. Java&#160;SE&#160;17 ( Open&#160;JDK&#160;17 ) Helidon requires Java 17+. Maven 3.6.1+ Helidon requires Maven 3.6.1+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop . <markup lang=\"bash\" title=\"Verify Prerequisites\" >java -version mvn --version docker --version kubectl version --short <markup lang=\"bash\" title=\"Setting JAVA_HOME\" ># On Mac export JAVA_HOME=`/usr/libexec/java_home -v 17` # On Linux # Use the appropriate path to your JDK export JAVA_HOME=/usr/lib/jvm/jdk-17 ",
            "title": "What You Need"
        },
        {
            "location": "mp/guides/quickstart",
            "text": " Generate the project sources using one (or both) of the Helidon Maven archetypes. The result is a simple project that shows the basics of configuring the WebServer and implementing basic routing rules. <markup lang=\"bash\" title=\"Run the Maven archetype\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-mp \\ -DarchetypeVersion=3.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-mp \\ -Dpackage=io.helidon.examples.quickstart.mp The archetype generates a Maven project in your current directory (for example, helidon-quickstart-mp ). Change into this directory. <markup lang=\"bash\" >cd helidon-quickstart-mp If you want to use the generated project as a starter for your own application, then you can replace groupId, artifactId and package with values appropriate for your application. <markup lang=\"bash\" title=\"Build the Application\" >mvn package The project builds an application jar for the example and saves all runtime dependencies in the target/libs directory. This means you can easily start the application by running the application jar file: <markup lang=\"bash\" title=\"Run the application\" >java -jar target/helidon-quickstart-mp.jar The example is a very simple \"Hello World\" greeting service. It supports GET requests for generating a greeting message, and a PUT request for changing the greeting itself. The response is encoded using JSON. For example: <markup lang=\"bash\" title=\"Try the Application\" >curl -X GET http://localhost:8080/greet {\"message\":\"Hello World!\"} curl -X GET http://localhost:8080/greet/Joe {\"message\":\"Hello Joe!\"} curl -X PUT -H \"Content-Type: application/json\" -d '{\"greeting\" : \"Hola\"}' http://localhost:8080/greet/greeting curl -X GET http://localhost:8080/greet/Jose {\"message\":\"Hola Jose!\"} ",
            "title": "Generate the Project"
        },
        {
            "location": "mp/guides/quickstart",
            "text": " Helidon provides built-in support for health and metrics endpoints. <markup lang=\"bash\" title=\"Health\" >curl -s -X GET http://localhost:8080/health <markup lang=\"bash\" title=\"Metrics in Prometheus Format\" >curl -s -X GET http://localhost:8080/metrics <markup lang=\"bash\" title=\"Metrics in JSON Format\" >curl -H 'Accept: application/json' -X GET http://localhost:8080/metrics ",
            "title": "Health and Metrics"
        },
        {
            "location": "mp/guides/quickstart",
            "text": " The project also contains a Dockerfile so that you can easily build and run a Docker image. To build the Docker image, you need to have Docker installed and running on your system. <markup lang=\"bash\" title=\"Docker build\" >docker build -t helidon-quickstart-mp . <markup lang=\"bash\" title=\"Run Docker Image\" >docker run --rm -p 8080:8080 helidon-quickstart-mp:latest Then you can try the application as you did before. ",
            "title": "Build a Docker Image"
        },
        {
            "location": "mp/guides/quickstart",
            "text": " If you don&#8217;t have access to a Kubernetes cluster, you can install one on your desktop . Then deploy the example: <markup lang=\"bash\" title=\"Verify connectivity to cluster\" >kubectl cluster-info kubectl get nodes <markup lang=\"bash\" title=\"Deploy the application to Kubernetes\" >kubectl create -f app.yaml kubectl get pods # Wait for quickstart pod to be RUNNING The step above created a service that is exposed into any node port. Lookup the service to find the port. <markup lang=\"bash\" title=\"Lookup the service\" >kubectl get service helidon-quickstart-mp Note the PORTs. You can now exercise the application as you did before but use the second port number (the NodePort) instead of 8080. For example: <markup lang=\"bash\" >curl -X GET http://localhost:31431/greet After you&#8217;re done, cleanup. <markup lang=\"bash\" title=\"Remove the application from Kubernetes\" >kubectl delete -f app.yaml ",
            "title": "Deploy the Application to Kubernetes"
        },
        {
            "location": "mp/guides/quickstart",
            "text": " Helidon also includes support for GraalVM Native Images and Java Custom Runtime Images. For more information see: GraalVM Native Images Custom Runtime Images using jlink ",
            "title": "Building Native and Custom Runtime Images"
        },
        {
            "location": "mp/guides/quickstart",
            "text": " With the Helidon CLI you can create additional types of Helidon applications and use the \"dev loop\" to do fast, iterative development. Try it now . ",
            "title": "The Helidon CLI"
        },
        {
            "location": "mp/guides/se-services",
            "text": " This guide shows how reuse Helidon SE Service in your Helidon MP application. ",
            "title": "preambule"
        },
        {
            "location": "mp/guides/se-services",
            "text": " For this 10 minute tutorial, you will need the following: <div class=\"table__overflow elevation-1 flex sm7 \"> A Helidon MP Application You can use your own application or use the Helidon MP Quickstart to create a sample application. Java&#160;SE&#160;17 ( Open&#160;JDK&#160;17 ) Helidon requires Java 17+. Maven 3.6.1+ Helidon requires Maven 3.6.1+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop . <markup lang=\"bash\" title=\"Verify Prerequisites\" >java -version mvn --version docker --version kubectl version --short <markup lang=\"bash\" title=\"Setting JAVA_HOME\" ># On Mac export JAVA_HOME=`/usr/libexec/java_home -v 17` # On Linux # Use the appropriate path to your JDK export JAVA_HOME=/usr/lib/jvm/jdk-17 Helidon MP supports Reactive routing which brings possibility for reusing io.helidon.webserver.Service implementations in Helidon MP. Such feature can be quite useful for common solutions for filtering, auditing, logging or augmenting REST endpoints in hybrid Helidon SE/MP environment. Let&#8217;s define simple Helidon SE Service for adding special header to every REST response: <markup lang=\"java\" >public class CoolingService implements Service, Handler { public static final String COOL_HEADER_NAME = \"Cool-Header\"; public static final String COOLING_VALUE = \"This is way cooler response than \"; @Override public void update(Routing.Rules rules) { rules.any(this); } @Override public void accept(ServerRequest req, ServerResponse res) { res.headers().add(COOL_HEADER_NAME, COOLING_VALUE); req.next(); } } Its easy to use it with Helidon SE: <markup lang=\"java\" >WebServer.builder(Routing.builder() // register service with routing path .register(\"/cool\", new CoolingService()) .build()) .config(config) .addMediaSupport(JsonpSupport.create()) .build() .start(); And not much harder to use it with Helidon MP: <markup lang=\"java\" >@ApplicationScoped public class MyBean { @Produces @ApplicationScoped @RoutingPath(\"/cool\") public Service coolService() { return new CoolingService(); } } You can leverage annotations: @RoutingPath - path of the WebServer service @RoutingName - select routing when serving requests on multiple ports ",
            "title": "What You Need"
        },
        {
            "location": "mp/guides/security-oidc",
            "text": " This guide describes how to set up Keycloak and Helidon to secure an application with OIDC security provider. ",
            "title": "preambule"
        },
        {
            "location": "mp/guides/security-oidc",
            "text": " For this 20 minute tutorial, you will need the following: <div class=\"table__overflow elevation-1 flex sm7 \"> A Helidon MP Application You can use your own application or use the Helidon MP Quickstart to create a sample application. Java&#160;SE&#160;17 ( Open&#160;JDK&#160;17 ) Helidon requires Java 17+. Maven 3.6.1+ Helidon requires Maven 3.6.1+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop . <markup lang=\"bash\" title=\"Verify Prerequisites\" >java -version mvn --version docker --version kubectl version --short <markup lang=\"bash\" title=\"Setting JAVA_HOME\" ># On Mac export JAVA_HOME=`/usr/libexec/java_home -v 17` # On Linux # Use the appropriate path to your JDK export JAVA_HOME=/usr/lib/jvm/jdk-17 ",
            "title": "What You Need"
        },
        {
            "location": "mp/guides/security-oidc",
            "text": " This guide describes the steps required to protect your whole application or a specific area with Open ID Connect (OIDC) security. OIDC is a secure mechanism for an application to contact an identity service. Its built on top of OAuth 2.0 and provides full-fledged authentication and authorization protocols. ",
            "title": "Introduction"
        },
        {
            "location": "mp/guides/security-oidc",
            "text": " To install Keycloak with Docker, open a terminal and make sure the port 8080 is free. <markup lang=\"bash\" title=\"Enter the following command\" >docker run -p 8080:8080 -e KEYCLOAK_USER=admin -e KEYCLOAK_PASSWORD=admin quay.io/keycloak/keycloak:11.0.2 This will start Keycloak on local port 8080. It will create the admin user with username admin and password admin Feel free to modify 11.0.2 by any keycloak version of your wish. If you are running docker behind a proxy server, make sure it is either configured into docker or disabled. Otherwise, you might face a connection timeout because docker cannot download the required data. To verify that Keycloak is running correctly, go to the admin console : http://localhost:8080/auth/admin Log in using the username and password mentioned above: admin . You should be logged in successfully, and it prompts the admin console. ",
            "title": "On Docker"
        },
        {
            "location": "mp/guides/security-oidc",
            "text": " Download the last version of Keycloak from Keycloak website : https://www.keycloak.org/downloads In the table Server choose Standalone server distribution. ZIP or Tar format are available, click on either to download Keycloak. After extracting the archive file, you should have a directory named keycloak followed by the version. For example, if you chose version 11.0.2, the folder must be named keycloak-11.0.2. Open keycloak folder to make it your current directory. <markup lang=\"bash\" title=\"Run this command from command prompt to open the directory:\" >cd keycloak-11.0.2 ",
            "title": "On JDK"
        },
        {
            "location": "mp/guides/security-oidc",
            "text": " On Docker To install Keycloak with Docker, open a terminal and make sure the port 8080 is free. <markup lang=\"bash\" title=\"Enter the following command\" >docker run -p 8080:8080 -e KEYCLOAK_USER=admin -e KEYCLOAK_PASSWORD=admin quay.io/keycloak/keycloak:11.0.2 This will start Keycloak on local port 8080. It will create the admin user with username admin and password admin Feel free to modify 11.0.2 by any keycloak version of your wish. If you are running docker behind a proxy server, make sure it is either configured into docker or disabled. Otherwise, you might face a connection timeout because docker cannot download the required data. To verify that Keycloak is running correctly, go to the admin console : http://localhost:8080/auth/admin Log in using the username and password mentioned above: admin . You should be logged in successfully, and it prompts the admin console. On JDK Download the last version of Keycloak from Keycloak website : https://www.keycloak.org/downloads In the table Server choose Standalone server distribution. ZIP or Tar format are available, click on either to download Keycloak. After extracting the archive file, you should have a directory named keycloak followed by the version. For example, if you chose version 11.0.2, the folder must be named keycloak-11.0.2. Open keycloak folder to make it your current directory. <markup lang=\"bash\" title=\"Run this command from command prompt to open the directory:\" >cd keycloak-11.0.2 ",
            "title": "Install Keycloak"
        },
        {
            "location": "mp/guides/security-oidc",
            "text": " You need to create an admin user because it does not come by default when installing Keycloak. To do this, open http://localhost:8080/auth in your favorite browser. A window Welcome to Keycloak should be prompted. If not, check if any error appear in the terminal. Fill the form by adding Username and Password. Click on Create to create the admin user. Above Administration Console should be printed \"User created\" in a green rectangle. To check that the admin user was created correctly, click on Administration user which should redirect you to a Login form. Enter the Username and Password created earlier to log in. After successfully logged in, the admin console is prompted. ",
            "title": "Create an Admin User"
        },
        {
            "location": "mp/guides/security-oidc",
            "text": " To start keycloak and have it ready for further steps, run the following command. <markup lang=\"bash\" title=\"On Linux run:\" >bin/standalone.sh <markup lang=\"bash\" title=\"On Windows run:\" >bin/standalone.bat Keycloak runs on localhost:8080 by default. Create an Admin User You need to create an admin user because it does not come by default when installing Keycloak. To do this, open http://localhost:8080/auth in your favorite browser. A window Welcome to Keycloak should be prompted. If not, check if any error appear in the terminal. Fill the form by adding Username and Password. Click on Create to create the admin user. Above Administration Console should be printed \"User created\" in a green rectangle. To check that the admin user was created correctly, click on Administration user which should redirect you to a Login form. Enter the Username and Password created earlier to log in. After successfully logged in, the admin console is prompted. ",
            "title": "Start Keycloak"
        },
        {
            "location": "mp/guides/security-oidc",
            "text": " A realm is the place where groups of applications, and their environment, can be created. It gathers : One or several applications One or several users Sessions Events Clients and their scopes By default, there is a realm called Master . It is used to manage Keycloak. It is not recommended to associate your application with this realm as it could disturb Keycloak functioning. To create a new realm to manage your application: Open Keycloak admin console http://localhost:8080/auth/admin . Hover the mouse over the dropdown in the top-left corner where it says Master , and press Add realm . Fill the form by adding the realm name, myRealm for example. Click on Create to create the new realm. To verify that your realm is created, on the top-left corner where it said Master previously should be now your realm name or myRealm is you followed the example. To switch from a realm to another, hover the realm name, and the other realm created appear in the dropdown. Click on any realm name to change the current realm. Make sure all configuration or modification are saved before changing the current realm or be subject to lose your configuration. ",
            "title": "Create a Realm"
        },
        {
            "location": "mp/guides/security-oidc",
            "text": " Initially there are no users in a new realm. An unlimited number of user can be created per realm. A realm contains resources such as client which can be accessed by users. To create a new user: Open the Keycloak admin console: http://localhost:8080/auth/admin Click on Users in the left menu Press Add user Fill the form (Username is the only mandatory field) with this value Username: myUser Click Save A new user is just created but it needs a password to be able to login. To initialize it, do this: Click on Credentials at the top of the page, under Myuser . Fill Password and Password confirmation with the user password of your choice. If the Temporary field is set to ON , the user has to update password on next login. Click ON to make it OFF and prevent it. Press Set Password . A pop-up window is popping off. Click on Set Password to confirm the new password. To verify that the new user is created correctly: Open the Keycloak account console: http://localhost:8080/auth/realms/myRealm/account . Login with myUser and password chosen earlier. You should now be logged-in to the account console where users can manage their accounts. ",
            "title": "Create a User"
        },
        {
            "location": "mp/guides/security-oidc",
            "text": " To create your first client: Open the Keycloak admin console: http://localhost:8080/auth/admin . Make sure the current realm is myRealm and not Master . Navigate to the left menu, into configure section, click on Clients . This window displays a table with every client from the realm. Click on Create . Fill the following: Client ID : myClientID Client Protocol : openid-connect Press Save Modify Access type : confidential Update Valid Redirect URIs : http://localhost:7987/* Click on + to add the new URI. Click on Save . A new tab named Credentials is created. Click on it to access this new tab. Select Client Authenticator : Client ID and Secret Click on generate secret to generate client secret. Keycloak is now configured and ready. Keep keycloak running on your terminal and open a new tab to set up Helidon. ",
            "title": "Create a Client"
        },
        {
            "location": "mp/guides/security-oidc",
            "text": " To set up Keycloak properly, go to the admin console: http://localhost:8080/auth/admin If you are using Docker, use Username admin and password admin as it is the default admin user. Otherwise, use the username and password you used to create the admin user. Create a Realm A realm is the place where groups of applications, and their environment, can be created. It gathers : One or several applications One or several users Sessions Events Clients and their scopes By default, there is a realm called Master . It is used to manage Keycloak. It is not recommended to associate your application with this realm as it could disturb Keycloak functioning. To create a new realm to manage your application: Open Keycloak admin console http://localhost:8080/auth/admin . Hover the mouse over the dropdown in the top-left corner where it says Master , and press Add realm . Fill the form by adding the realm name, myRealm for example. Click on Create to create the new realm. To verify that your realm is created, on the top-left corner where it said Master previously should be now your realm name or myRealm is you followed the example. To switch from a realm to another, hover the realm name, and the other realm created appear in the dropdown. Click on any realm name to change the current realm. Make sure all configuration or modification are saved before changing the current realm or be subject to lose your configuration. Create a User Initially there are no users in a new realm. An unlimited number of user can be created per realm. A realm contains resources such as client which can be accessed by users. To create a new user: Open the Keycloak admin console: http://localhost:8080/auth/admin Click on Users in the left menu Press Add user Fill the form (Username is the only mandatory field) with this value Username: myUser Click Save A new user is just created but it needs a password to be able to login. To initialize it, do this: Click on Credentials at the top of the page, under Myuser . Fill Password and Password confirmation with the user password of your choice. If the Temporary field is set to ON , the user has to update password on next login. Click ON to make it OFF and prevent it. Press Set Password . A pop-up window is popping off. Click on Set Password to confirm the new password. To verify that the new user is created correctly: Open the Keycloak account console: http://localhost:8080/auth/realms/myRealm/account . Login with myUser and password chosen earlier. You should now be logged-in to the account console where users can manage their accounts. Create a Client To create your first client: Open the Keycloak admin console: http://localhost:8080/auth/admin . Make sure the current realm is myRealm and not Master . Navigate to the left menu, into configure section, click on Clients . This window displays a table with every client from the realm. Click on Create . Fill the following: Client ID : myClientID Client Protocol : openid-connect Press Save Modify Access type : confidential Update Valid Redirect URIs : http://localhost:7987/* Click on + to add the new URI. Click on Save . A new tab named Credentials is created. Click on it to access this new tab. Select Client Authenticator : Client ID and Secret Click on generate secret to generate client secret. Keycloak is now configured and ready. Keep keycloak running on your terminal and open a new tab to set up Helidon. ",
            "title": "Set up Keycloak"
        },
        {
            "location": "mp/guides/security-oidc",
            "text": " Update the pom.xml file and add the following Helidon dependency to the &lt;dependencies&gt; section. <markup lang=\"xml\" title=\"Add the following dependency to pom.xml :\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-oidc&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Update Project Dependencies"
        },
        {
            "location": "mp/guides/security-oidc",
            "text": " The OIDC security provider configuration can be joined to helidon configuration file. This file is located here: src/main/resources/application.yaml . It can be easily used to configure the web server without modifying application code. <markup lang=\"yaml\" title=\"Create application.yaml file and add the following line\" >security: providers: - abac: # Adds ABAC Provider - it does not require any configuration - oidc: redirect-uri: \"/oidc/redirect\" audience: \"account\" client-id: \"myClientID\" header-use: true client-secret: \"Client secret generated into Keycloak client credential\" identity-uri: \"http://localhost:8080/auth/realms/myRealm\" frontend-uri: \"http://localhost:7987\" client-id must be the same as the one configure in keycloak. The client secret generate by Keycloak during Create a client section. identity-uri is used to redirect the user to keycloak. frontend-uri will direct you back to the application. The client secret is the one generate into Keycloak Client Credentials. It must be copy past into client-id variable from application.yaml. Make sure keycloak and the application are not running on the same port. The application port value can be changed into microprofile-config.properties. <markup lang=\"properties\" title=\"Change these properties to configure the server host and port\" >server.port=7987 server.host=localhost If the port 7987 is already used, check what port is free on your machine. <markup lang=\"properties\" title=\"Replace the old port into microprofile-config.properties\" >server.port=\"{Your-new-port}\" <markup lang=\"yaml\" title=\"Replace the old port into application.yaml\" >frontend-uri: \"http://localhost:{Your-new-port}\" ",
            "title": "Add OIDC Security Properties"
        },
        {
            "location": "mp/guides/security-oidc",
            "text": " The GreetResource class is a JAX-RS resource available at the endpoint /greet . Use @Authenticated annotation to protect any method or endpoint. Modify the getDefaultMessage method with the @Authenticated to limit its access. <markup lang=\"java\" title=\"Import Authenticated annotation:\" >import io.helidon.security.annotations.Authenticated; <markup lang=\"java\" title=\"Add @Authenticated to secure getDefaultMessage \" > @Authenticated @GET @Produces(MediaType.APPLICATION_JSON) public JsonObject getDefaultMessage() { return createResponse(\"World\"); } When a client will send an HTTP GET request at the endpoint http://localhost:7987/greet , he will be redirected to keycloak. Keycloak will check if the client has the required authorisation to access this endpoint. If the client can log in successfully, keycloak redirect it to the wished endpoint. If the client cannot log in, or the required access data are incomplete, Keycloak refuses the access. ",
            "title": "Secure Your Application"
        },
        {
            "location": "mp/guides/security-oidc",
            "text": " Use the Helidon MP Maven archetype to create a simple project. It will be used as an example to show how to set up Helidon. Replace 3.0.2 by the latest helidon version. It will download the quickstart project into the current directory. <markup lang=\"bash\" title=\"Run the Maven archetype\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-mp \\ -DarchetypeVersion=3.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-mp \\ -Dpackage=io.helidon.examples.quickstart.mp <markup lang=\"bash\" title=\"The project will be built and run from the helidon-quickstart-mp directory:\" >cd helidon-quickstart-mp Update Project Dependencies Update the pom.xml file and add the following Helidon dependency to the &lt;dependencies&gt; section. <markup lang=\"xml\" title=\"Add the following dependency to pom.xml :\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-oidc&lt;/artifactId&gt; &lt;/dependency&gt; Add OIDC Security Properties The OIDC security provider configuration can be joined to helidon configuration file. This file is located here: src/main/resources/application.yaml . It can be easily used to configure the web server without modifying application code. <markup lang=\"yaml\" title=\"Create application.yaml file and add the following line\" >security: providers: - abac: # Adds ABAC Provider - it does not require any configuration - oidc: redirect-uri: \"/oidc/redirect\" audience: \"account\" client-id: \"myClientID\" header-use: true client-secret: \"Client secret generated into Keycloak client credential\" identity-uri: \"http://localhost:8080/auth/realms/myRealm\" frontend-uri: \"http://localhost:7987\" client-id must be the same as the one configure in keycloak. The client secret generate by Keycloak during Create a client section. identity-uri is used to redirect the user to keycloak. frontend-uri will direct you back to the application. The client secret is the one generate into Keycloak Client Credentials. It must be copy past into client-id variable from application.yaml. Make sure keycloak and the application are not running on the same port. The application port value can be changed into microprofile-config.properties. <markup lang=\"properties\" title=\"Change these properties to configure the server host and port\" >server.port=7987 server.host=localhost If the port 7987 is already used, check what port is free on your machine. <markup lang=\"properties\" title=\"Replace the old port into microprofile-config.properties\" >server.port=\"{Your-new-port}\" <markup lang=\"yaml\" title=\"Replace the old port into application.yaml\" >frontend-uri: \"http://localhost:{Your-new-port}\" Secure Your Application The GreetResource class is a JAX-RS resource available at the endpoint /greet . Use @Authenticated annotation to protect any method or endpoint. Modify the getDefaultMessage method with the @Authenticated to limit its access. <markup lang=\"java\" title=\"Import Authenticated annotation:\" >import io.helidon.security.annotations.Authenticated; <markup lang=\"java\" title=\"Add @Authenticated to secure getDefaultMessage \" > @Authenticated @GET @Produces(MediaType.APPLICATION_JSON) public JsonObject getDefaultMessage() { return createResponse(\"World\"); } When a client will send an HTTP GET request at the endpoint http://localhost:7987/greet , he will be redirected to keycloak. Keycloak will check if the client has the required authorisation to access this endpoint. If the client can log in successfully, keycloak redirect it to the wished endpoint. If the client cannot log in, or the required access data are incomplete, Keycloak refuses the access. ",
            "title": "Set up Helidon"
        },
        {
            "location": "mp/guides/security-oidc",
            "text": " At this stage of the application, tests cannot pass because of OIDC security. The only way to authenticate a user is through the front end of that server which can be accessed with the browser for example. In order to keep security and test the application locally, a new security provider must be provided. By adding specific configuration to the test, it is possible to override the application configuration. The following explains how to set a basic authentication instead of oidc security provider only for the tests. Which means, at the end of this guide, the application will be secured by oidc and the tests will use basic authentication. In the test folder helidon-quickstart-mp/src/test : <markup lang=\"bash\" title=\"Create a new directory and another one inside\" >mkdir resources cd resources touch application.yaml Open the application.yaml file you just created. <markup lang=\"yaml\" title=\"Copy these properties into the new application.yaml\" >app: greeting: \"Hello\" server: port: 7987 host: localhost security: providers: - abac: - http-basic-auth: users: - login: \"jack\" password: \"jackIsGreat\" By adding this new application.yaml, it will append the properties to the application.yaml located into java/resources . The oidc properties are not overridden, and the server cannot decide which security provider to choose. Excluding oidc dependency during the test leaves only basic authentication security available for the tests. <markup lang=\"xml\" title=\"Add this plugin to the build\" >&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;classpathDependencyExcludes&gt; &lt;classpathDependencyExclude&gt;io.helidon.microprofile:helidon-microprofile-oidc&lt;/classpathDependencyExclude&gt; &lt;/classpathDependencyExcludes&gt; &lt;/configuration&gt; &lt;/plugin&gt; In the MainTest.java file, tests need to be modified to check the application security when accessing /greet path with a GET method. First step is to configure the server with the new application.yaml. <markup lang=\"java\" title=\"Import the Config class\" >import io.helidon.config.Config; <markup lang=\"java\" title=\"Replace the startTheServer method by this one:\" >@BeforeAll public static void startTheServer() { server = Server.builder() .config(Config.create()) .build() .start(); serverUrl = \"http://localhost:\" + server.port(); } The server has now one security provider, basic authentication configured. Next step is to modify the test to check that the application is correctly protected. <markup lang=\"java\" title=\"Replace the JsonObject declaration into testHelloWorld method by this code:\" >JsonObject jsonObject; Response response = client .target(serverUrl) .path(\"/greet\") .request() .get(Response.class); Assertions.assertEquals(401, response.getStatus()); This piece of code uses the webclient to access the application on /greet path with a GET method. The http basic authentication security provider protects this path, so the client should receive an HTTP 401 code for unauthorized. Only jack user has access to this part of the application. <markup lang=\"java\" title=\"Add new check to the testHelloWorld method:\" >String encoding = Base64.getEncoder().encodeToString(\"jack:jackIsGreat\".getBytes()); jsonObject = client .target(serverUrl) .path(\"/greet\") .request() .header(Http.Header.AUTHORIZATION, \"Basic \" + encoding) .get(JsonObject.class); Assertions.assertEquals(\"Hello World!\", jsonObject.getString(\"message\"), \"default message\"); The username and password are encoded and placed inside the header in order to authenticate as jack to access the application. If the authentication is successful, the application send the Hello World back as a JsonObject . Now, the project can be build without skiping test. <markup lang=\"bash\" title=\"Build the project\" >mvn clean install ",
            "title": "Update Tests to the Secure Environment"
        },
        {
            "location": "mp/guides/security-oidc",
            "text": " The Authorization Code flow is suitable for browser-based applications. It is composed of three main steps: The browser visits the application. The user is not logged in, so it redirects the browser to Keycloak which requires username and password for authentication. Keycloak authenticates the user and returns a temporary authorization code as a query parameter in the URL. The authorization code is used to get access and refresh token from Keycloak token endpoint. For the first step, paste the following URL into your browser: http://localhost:8080/auth/realms/myRealm/protocol/openid-connect/auth?client_id=myClientID&amp;response_type=code . The first part of the url http:/../auth is the Keycloak endpoint to request an authorization code. Two query parameters are provided, the client id and the response type. Press enter and Keycloak responds with different URL containing a query parameter code . You successfully received the authorization code. In order to achieve the third step, we can use Postman to exchange the authorization code for tokens. In Postman, select the Http POST method. Keycloak endpoint to get token is the following: http://localhost:8080/auth/realms/myRealm/protocol/openid-connect/token . In the body of the request, select x-www-form-urlencoded type. Add the following data: <markup lang=\"json\" title=\"Enter the key:value\" >[{\"key\":\"grant_type\",\"value\":\"authorization_code\"}, {\"key\":\"client_id\",\"value\":\"myClientID\"}, {\"key\":\"client_secret\",\"value\":\"client secret\"}, {\"key\":\"code\",\"value\":\"authorization code\"}] Do not forget to replace the client secret by its value (generated during Create a Client), and authorization code by the code value in the query parameter. Send the request by pressing Send . Keycloak returns an access token and a refresh token. ",
            "title": "Authorization Code Flow"
        },
        {
            "location": "mp/guides/security-oidc",
            "text": " The Direct Access Grants flow is used by REST clients that want to request tokens on behalf of a user. To use Postman to make this request on behalf of myuser , select the GET method and enter this URL: http://localhost:7987/greet/ . Under Authorization tab, select authorization type`OAuth 2.0`. Under it, complete the sentence Add authorization data to with Request Headers , and complete the required fields. <markup lang=\"json\" title=\"Enter the following information:\" >[{\"key\":\"Header Prefix\",\"value\":\"bearer\"}, {\"key\":\"Grant type\",\"value\":\"Password Credentials\"}, {\"key\":\"Access Token URL\",\"value\":\"http://localhost:8080/auth/realms/myRealm/protocol/openid-connect/token\"}, {\"key\":\"Client ID\",\"value\":\"myClientID\"}, {\"key\":\"Client Secret\",\"value\":\"client secret\"}, {\"key\":\"Username\",\"value\":\"myuser\"}, {\"key\":\"Password\",\"value\":\"password\"}, {\"key\":\"Scope\",\"value\":\"openid\"}, {\"key\":\"Client Authentication\",\"value\":\"Send as Basic Auth Header\"}] Again, make sure to replace client secret by the actual client secret. Click on Get New Access Token . A popup window appears with Authentication complete, click on proceed to display access, refresh and identity token. Copy and paste the access token to Access Token field and press Send . Helidon greeting application sends back Hello World ! . ",
            "title": "Resource Owner Password Credentials Grant (Direct Access Grants)"
        },
        {
            "location": "mp/guides/security-oidc",
            "text": " Keycloak supports many authentication and authorization flows, but only two of them will be shown. This section describes another way you can get an access token or refresh a token or identity token. The identity token contains information about the user. The access token contains access information that the application can use to determine what resources the user is allowed to access. Once expired, the refresh token allows the application to obtain a new access token. As these tokens contain sensitive information, they are valid for a very short period. It is possible to make them last longer in order to let you manipulate them with Postman. To do so: Open the Postman Console. Click on the Realm Setting in the left menu. Navigate to the Tokens tab. You can increase the access token lifespan. Authorization Code Flow The Authorization Code flow is suitable for browser-based applications. It is composed of three main steps: The browser visits the application. The user is not logged in, so it redirects the browser to Keycloak which requires username and password for authentication. Keycloak authenticates the user and returns a temporary authorization code as a query parameter in the URL. The authorization code is used to get access and refresh token from Keycloak token endpoint. For the first step, paste the following URL into your browser: http://localhost:8080/auth/realms/myRealm/protocol/openid-connect/auth?client_id=myClientID&amp;response_type=code . The first part of the url http:/../auth is the Keycloak endpoint to request an authorization code. Two query parameters are provided, the client id and the response type. Press enter and Keycloak responds with different URL containing a query parameter code . You successfully received the authorization code. In order to achieve the third step, we can use Postman to exchange the authorization code for tokens. In Postman, select the Http POST method. Keycloak endpoint to get token is the following: http://localhost:8080/auth/realms/myRealm/protocol/openid-connect/token . In the body of the request, select x-www-form-urlencoded type. Add the following data: <markup lang=\"json\" title=\"Enter the key:value\" >[{\"key\":\"grant_type\",\"value\":\"authorization_code\"}, {\"key\":\"client_id\",\"value\":\"myClientID\"}, {\"key\":\"client_secret\",\"value\":\"client secret\"}, {\"key\":\"code\",\"value\":\"authorization code\"}] Do not forget to replace the client secret by its value (generated during Create a Client), and authorization code by the code value in the query parameter. Send the request by pressing Send . Keycloak returns an access token and a refresh token. Resource Owner Password Credentials Grant (Direct Access Grants) The Direct Access Grants flow is used by REST clients that want to request tokens on behalf of a user. To use Postman to make this request on behalf of myuser , select the GET method and enter this URL: http://localhost:7987/greet/ . Under Authorization tab, select authorization type`OAuth 2.0`. Under it, complete the sentence Add authorization data to with Request Headers , and complete the required fields. <markup lang=\"json\" title=\"Enter the following information:\" >[{\"key\":\"Header Prefix\",\"value\":\"bearer\"}, {\"key\":\"Grant type\",\"value\":\"Password Credentials\"}, {\"key\":\"Access Token URL\",\"value\":\"http://localhost:8080/auth/realms/myRealm/protocol/openid-connect/token\"}, {\"key\":\"Client ID\",\"value\":\"myClientID\"}, {\"key\":\"Client Secret\",\"value\":\"client secret\"}, {\"key\":\"Username\",\"value\":\"myuser\"}, {\"key\":\"Password\",\"value\":\"password\"}, {\"key\":\"Scope\",\"value\":\"openid\"}, {\"key\":\"Client Authentication\",\"value\":\"Send as Basic Auth Header\"}] Again, make sure to replace client secret by the actual client secret. Click on Get New Access Token . A popup window appears with Authentication complete, click on proceed to display access, refresh and identity token. Copy and paste the access token to Access Token field and press Send . Helidon greeting application sends back Hello World ! . ",
            "title": "Test Keycloak process with Postman"
        },
        {
            "location": "mp/guides/security-oidc",
            "text": " To give less access to a specific endpoint, it is possible to configure user role. So the application will grant access only the user with the required role. Navigate to the GreetResource and find the getDefaultMessage with @Authenticate annotation. <markup lang=\"java\" title=\"Import the RolesAllowed annotation\" >import jakarta.annotation.security.RolesAllowed; <markup lang=\"java\" title=\"Add the @RolesAllowed annotation under the @Authenticate annotation:\" >@RolesAllowed(\"admin\") The annotation parameter is the role with access to the method. In this case, only user with admin role can have access. Then, add a user and roles to the helidon-quickstart-mp/src/test/resources/application.yaml file. <markup lang=\"yaml\" title=\"Add jack roles and create a new user named john:\" >- http-basic-auth: users: - login: \"jack\" password: \"jackIsGreat\" roles: [ \"admin\", \"user\" ] - login: \"john\" password: \"johnPassword\" roles: [ \"user\" ] Now, only Jack has access to secure endpoint as he has an admin role. Jhon, as a simple user, can not access it. Once it is done, go to the tests to check the application behavior. The test from previous section is still passing because jack has access. The user john has only the user role so when accessing protected endpoint, a 403 (Forbidden) http code is returned. <markup lang=\"java\" title=\"Check that jhon does not have access\" >encoding = Base64.getEncoder().encodeToString(\"john:johnPassword\".getBytes()); response = client .target(serverUrl) .path(\"/greet\") .request() .header(Http.Header.AUTHORIZATION, \"Basic \" + encoding) .get(Response.class); Assertions.assertEquals(403, response.getStatus()); <markup lang=\"bash\" title=\"Build the project\" >mvn clean install The tests pass, and your application is secured with specific roles in addition to user IDs. ",
            "title": "Restrict Access to a Specific Role"
        },
        {
            "location": "mp/guides/security-oidc",
            "text": " Helidon and Keycloak are now correctly configured and your application is safe. <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-mp.jar The tests must be skipped, otherwise it produces test failure. As the /greet endpoint for GET request is now protected, its access is limited, and the tests are not built to take oidc security in account. Open your favourite browser and try to access http://localhost:7987/greet/Michael . You should not be redirected and receive greeting from the application. Enter the following into URL : http://localhost:7987/greet . Keycloak redirect you to its login page. Enter the username and associated password: Username : myUser Password : password After successful log in, keycloak redirect you to the http://localhost:7987/greet endpoint and print Hello word. Press Ctrl+C to stop the application. From the actual settings, the user needs to log in only once, then Keycloak saves all the connection data. Update Tests to the Secure Environment At this stage of the application, tests cannot pass because of OIDC security. The only way to authenticate a user is through the front end of that server which can be accessed with the browser for example. In order to keep security and test the application locally, a new security provider must be provided. By adding specific configuration to the test, it is possible to override the application configuration. The following explains how to set a basic authentication instead of oidc security provider only for the tests. Which means, at the end of this guide, the application will be secured by oidc and the tests will use basic authentication. In the test folder helidon-quickstart-mp/src/test : <markup lang=\"bash\" title=\"Create a new directory and another one inside\" >mkdir resources cd resources touch application.yaml Open the application.yaml file you just created. <markup lang=\"yaml\" title=\"Copy these properties into the new application.yaml\" >app: greeting: \"Hello\" server: port: 7987 host: localhost security: providers: - abac: - http-basic-auth: users: - login: \"jack\" password: \"jackIsGreat\" By adding this new application.yaml, it will append the properties to the application.yaml located into java/resources . The oidc properties are not overridden, and the server cannot decide which security provider to choose. Excluding oidc dependency during the test leaves only basic authentication security available for the tests. <markup lang=\"xml\" title=\"Add this plugin to the build\" >&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;classpathDependencyExcludes&gt; &lt;classpathDependencyExclude&gt;io.helidon.microprofile:helidon-microprofile-oidc&lt;/classpathDependencyExclude&gt; &lt;/classpathDependencyExcludes&gt; &lt;/configuration&gt; &lt;/plugin&gt; In the MainTest.java file, tests need to be modified to check the application security when accessing /greet path with a GET method. First step is to configure the server with the new application.yaml. <markup lang=\"java\" title=\"Import the Config class\" >import io.helidon.config.Config; <markup lang=\"java\" title=\"Replace the startTheServer method by this one:\" >@BeforeAll public static void startTheServer() { server = Server.builder() .config(Config.create()) .build() .start(); serverUrl = \"http://localhost:\" + server.port(); } The server has now one security provider, basic authentication configured. Next step is to modify the test to check that the application is correctly protected. <markup lang=\"java\" title=\"Replace the JsonObject declaration into testHelloWorld method by this code:\" >JsonObject jsonObject; Response response = client .target(serverUrl) .path(\"/greet\") .request() .get(Response.class); Assertions.assertEquals(401, response.getStatus()); This piece of code uses the webclient to access the application on /greet path with a GET method. The http basic authentication security provider protects this path, so the client should receive an HTTP 401 code for unauthorized. Only jack user has access to this part of the application. <markup lang=\"java\" title=\"Add new check to the testHelloWorld method:\" >String encoding = Base64.getEncoder().encodeToString(\"jack:jackIsGreat\".getBytes()); jsonObject = client .target(serverUrl) .path(\"/greet\") .request() .header(Http.Header.AUTHORIZATION, \"Basic \" + encoding) .get(JsonObject.class); Assertions.assertEquals(\"Hello World!\", jsonObject.getString(\"message\"), \"default message\"); The username and password are encoded and placed inside the header in order to authenticate as jack to access the application. If the authentication is successful, the application send the Hello World back as a JsonObject . Now, the project can be build without skiping test. <markup lang=\"bash\" title=\"Build the project\" >mvn clean install Test Keycloak process with Postman Keycloak supports many authentication and authorization flows, but only two of them will be shown. This section describes another way you can get an access token or refresh a token or identity token. The identity token contains information about the user. The access token contains access information that the application can use to determine what resources the user is allowed to access. Once expired, the refresh token allows the application to obtain a new access token. As these tokens contain sensitive information, they are valid for a very short period. It is possible to make them last longer in order to let you manipulate them with Postman. To do so: Open the Postman Console. Click on the Realm Setting in the left menu. Navigate to the Tokens tab. You can increase the access token lifespan. Authorization Code Flow The Authorization Code flow is suitable for browser-based applications. It is composed of three main steps: The browser visits the application. The user is not logged in, so it redirects the browser to Keycloak which requires username and password for authentication. Keycloak authenticates the user and returns a temporary authorization code as a query parameter in the URL. The authorization code is used to get access and refresh token from Keycloak token endpoint. For the first step, paste the following URL into your browser: http://localhost:8080/auth/realms/myRealm/protocol/openid-connect/auth?client_id=myClientID&amp;response_type=code . The first part of the url http:/../auth is the Keycloak endpoint to request an authorization code. Two query parameters are provided, the client id and the response type. Press enter and Keycloak responds with different URL containing a query parameter code . You successfully received the authorization code. In order to achieve the third step, we can use Postman to exchange the authorization code for tokens. In Postman, select the Http POST method. Keycloak endpoint to get token is the following: http://localhost:8080/auth/realms/myRealm/protocol/openid-connect/token . In the body of the request, select x-www-form-urlencoded type. Add the following data: <markup lang=\"json\" title=\"Enter the key:value\" >[{\"key\":\"grant_type\",\"value\":\"authorization_code\"}, {\"key\":\"client_id\",\"value\":\"myClientID\"}, {\"key\":\"client_secret\",\"value\":\"client secret\"}, {\"key\":\"code\",\"value\":\"authorization code\"}] Do not forget to replace the client secret by its value (generated during Create a Client), and authorization code by the code value in the query parameter. Send the request by pressing Send . Keycloak returns an access token and a refresh token. Resource Owner Password Credentials Grant (Direct Access Grants) The Direct Access Grants flow is used by REST clients that want to request tokens on behalf of a user. To use Postman to make this request on behalf of myuser , select the GET method and enter this URL: http://localhost:7987/greet/ . Under Authorization tab, select authorization type`OAuth 2.0`. Under it, complete the sentence Add authorization data to with Request Headers , and complete the required fields. <markup lang=\"json\" title=\"Enter the following information:\" >[{\"key\":\"Header Prefix\",\"value\":\"bearer\"}, {\"key\":\"Grant type\",\"value\":\"Password Credentials\"}, {\"key\":\"Access Token URL\",\"value\":\"http://localhost:8080/auth/realms/myRealm/protocol/openid-connect/token\"}, {\"key\":\"Client ID\",\"value\":\"myClientID\"}, {\"key\":\"Client Secret\",\"value\":\"client secret\"}, {\"key\":\"Username\",\"value\":\"myuser\"}, {\"key\":\"Password\",\"value\":\"password\"}, {\"key\":\"Scope\",\"value\":\"openid\"}, {\"key\":\"Client Authentication\",\"value\":\"Send as Basic Auth Header\"}] Again, make sure to replace client secret by the actual client secret. Click on Get New Access Token . A popup window appears with Authentication complete, click on proceed to display access, refresh and identity token. Copy and paste the access token to Access Token field and press Send . Helidon greeting application sends back Hello World ! . Restrict Access to a Specific Role To give less access to a specific endpoint, it is possible to configure user role. So the application will grant access only the user with the required role. Navigate to the GreetResource and find the getDefaultMessage with @Authenticate annotation. <markup lang=\"java\" title=\"Import the RolesAllowed annotation\" >import jakarta.annotation.security.RolesAllowed; <markup lang=\"java\" title=\"Add the @RolesAllowed annotation under the @Authenticate annotation:\" >@RolesAllowed(\"admin\") The annotation parameter is the role with access to the method. In this case, only user with admin role can have access. Then, add a user and roles to the helidon-quickstart-mp/src/test/resources/application.yaml file. <markup lang=\"yaml\" title=\"Add jack roles and create a new user named john:\" >- http-basic-auth: users: - login: \"jack\" password: \"jackIsGreat\" roles: [ \"admin\", \"user\" ] - login: \"john\" password: \"johnPassword\" roles: [ \"user\" ] Now, only Jack has access to secure endpoint as he has an admin role. Jhon, as a simple user, can not access it. Once it is done, go to the tests to check the application behavior. The test from previous section is still passing because jack has access. The user john has only the user role so when accessing protected endpoint, a 403 (Forbidden) http code is returned. <markup lang=\"java\" title=\"Check that jhon does not have access\" >encoding = Base64.getEncoder().encodeToString(\"john:johnPassword\".getBytes()); response = client .target(serverUrl) .path(\"/greet\") .request() .header(Http.Header.AUTHORIZATION, \"Basic \" + encoding) .get(Response.class); Assertions.assertEquals(403, response.getStatus()); <markup lang=\"bash\" title=\"Build the project\" >mvn clean install The tests pass, and your application is secured with specific roles in addition to user IDs. ",
            "title": "Try it!"
        },
        {
            "location": "mp/guides/testing-junit5",
            "text": " This guide describes how to write and execute tests for your MicroProfile applications in a JUnit 5 environment using optimized customizations. ",
            "title": "preambule"
        },
        {
            "location": "mp/guides/testing-junit5",
            "text": " For this 20 minute tutorial, you will need the following: <div class=\"table__overflow elevation-1 flex sm7 \"> A Helidon MP Application You can use your own application or use the Helidon MP Quickstart to create a sample application. Java&#160;SE&#160;17 ( Open&#160;JDK&#160;17 ) Helidon requires Java 17+. Maven 3.6.1+ Helidon requires Maven 3.6.1+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop . <markup lang=\"bash\" title=\"Verify Prerequisites\" >java -version mvn --version docker --version kubectl version --short <markup lang=\"bash\" title=\"Setting JAVA_HOME\" ># On Mac export JAVA_HOME=`/usr/libexec/java_home -v 17` # On Linux # Use the appropriate path to your JDK export JAVA_HOME=/usr/lib/jvm/jdk-17 ",
            "title": "What You Need"
        },
        {
            "location": "mp/guides/testing-junit5",
            "text": " To start using this feature, add the following dependencies to the testing module: <markup lang=\"xml\" title=\"Maven dependencies\" >&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.tests&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-tests-junit5&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.junit.jupiter&lt;/groupId&gt; &lt;artifactId&gt;junit-jupiter-engine&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; ",
            "title": "Dependencies"
        },
        {
            "location": "mp/guides/testing-junit5",
            "text": " First you&#8217;ll need to create a test class with an empty test method, and annotate it with @HelidonTest : <markup lang=\"java\" title=\"Test Class\" >import io.helidon.microprofile.tests.junit5.HelidonTest; import org.junit.jupiter.api.Test; @HelidonTest class GreetTest { @Test void testDefaultGreeting() { } } The @HelidonTest annotation will cause the test extension to start a Helidon MicroProfile server so that you do not need to manage the server lifecycle in your test. The container is initialized once before the test class is instantiated, and shut down after the last test runs. You can see this in the test output: <markup lang=\"listing\" >`INFO io.helidon.microprofile.server.ServerCdiExtension: Server started on http://localhost:56293 (and all other host addresses) in 1893 milliseconds (since JVM startup)`. [source,java] The @HelidonTest annotation uses a random port regardless of the port configured in the application.yaml. ",
            "title": "Create a Test Class"
        },
        {
            "location": "mp/guides/testing-junit5",
            "text": " The test is only useful if it invokes the server and verifies the result. To support testing, you can inject a WebTarget that is configured for the currently running server (it can also be a parameter to a test method). We can use the target to invoke our endpoint and validate the result. <markup lang=\"java\" title=\"Updated Class with webTarget\" >import static org.junit.jupiter.api.Assertions.assertEquals; @HelidonTest class GreetTest { @Inject WebTarget webTarget; @Test void testDefaultGreeting() { JsonObject jsonObject = webTarget.path(\"/greet\") .request() .get(JsonObject.class); String expected = \"Hello World!\"; String actual = jsonObject.getString(\"message\"); assertEquals(expected, actual, \"Message in JSON\"); } } The test is now complete and verifies the message. ",
            "title": "Inject a WebTarget"
        },
        {
            "location": "mp/guides/testing-junit5",
            "text": " The testing extension supports a few additional annotations that allow for finer control of the test execution. Optional Extension Annotations Annotation Description @HelidonTest(resetPerTest = true) Resets the container for each method. This is useful when we want to modify configuration or beans between executions. In such a case, injection into fields is not possible, as we would need a different instance for each test. @AddConfig(key = \"app.greeting\", value = \"Unite\") Defines a new configuration (either on class level, or method level) by adding a single configuration key/value. @Configuration(configSources = \"test-config.properties\") Adds a whole config source from classpath. Here&#8217;s an example showing how these approaches are used to execute the same endpoint with different configuration: <markup lang=\"java\" >@HelidonTest(resetPerTest = true) class GreetTest { @Test void testDefaultGreeting(WebTarget webTarget) { validate(webTarget, \"/greet\", \"Hello World!\"); } @Test @AddConfig(key = \"app.greeting\", value = \"Unite\") void testConfiguredGreeting(WebTarget webTarget) { validate(webTarget, \"/greet\", \"Unite World!\"); } private void validate(WebTarget webTarget, String path, String expected) { JsonObject jsonObject = webTarget.path(path) .request() .get(JsonObject.class); String actual = jsonObject.getString(\"message\"); assertEquals(expected, actual, \"Message in JSON\"); } } ",
            "title": "Customize the Testing Extension"
        },
        {
            "location": "mp/guides/testing-junit5",
            "text": " If you prefer to use only beans for testing, and want to add a different bean for each test, then you must use the @AddBean annotation. This cannot be achieved by CDI discovery because if we place META-INF/beans.xml on the classpath, then all of our beans would be added. <markup lang=\"java\" >@AddBean(TestBean.class) By default the bean is added to the container with scope set to ApplicationScoped . You can customize scope either by annotating the bean class with another scope or through the annotation: <markup lang=\"java\" >@AddBean(value = TestBean.class, scope = Dependent.class) This annotation can also be placed on a method when running in resetPerTest mode. ",
            "title": "Use Beans for Testing"
        },
        {
            "location": "mp/guides/testing-junit5",
            "text": " When a custom bean is not enough, you may want to extend the CDI with a test-only Extension . Once again, if we use the standard way of doing this, we would need to create a META-INF/services record that would be picked up by every test class. For this purpose, we provide the following annotation which adds the extension to the container and allows you to modify its behavior as a usual CDI Portable Extension: <markup lang=\"java\" >@AddExtension(TestExtension.class) ",
            "title": "Add Test Extension"
        },
        {
            "location": "mp/guides/testing-junit5",
            "text": " If you want to disable discovery and only add custom extensions and beans, then use the following annotation: <markup lang=\"java\" >@DisableDiscovery This annotation is typically used in conjunction with @AddBeans and/or @AddExtension . As you have seen in standard test output, by default Helidon starts with the dependencies defined in pom.xml. ",
            "title": "Disable Discovery"
        },
        {
            "location": "mp/guides/testing-junit5",
            "text": " In this guide we will use the Helidon MP Quickstart project in our examples. This application provides an endpoint /greet , and we want to make sure this endpoint is available and returns expected value. Create a Test Class First you&#8217;ll need to create a test class with an empty test method, and annotate it with @HelidonTest : <markup lang=\"java\" title=\"Test Class\" >import io.helidon.microprofile.tests.junit5.HelidonTest; import org.junit.jupiter.api.Test; @HelidonTest class GreetTest { @Test void testDefaultGreeting() { } } The @HelidonTest annotation will cause the test extension to start a Helidon MicroProfile server so that you do not need to manage the server lifecycle in your test. The container is initialized once before the test class is instantiated, and shut down after the last test runs. You can see this in the test output: <markup lang=\"listing\" >`INFO io.helidon.microprofile.server.ServerCdiExtension: Server started on http://localhost:56293 (and all other host addresses) in 1893 milliseconds (since JVM startup)`. [source,java] The @HelidonTest annotation uses a random port regardless of the port configured in the application.yaml. Inject a WebTarget The test is only useful if it invokes the server and verifies the result. To support testing, you can inject a WebTarget that is configured for the currently running server (it can also be a parameter to a test method). We can use the target to invoke our endpoint and validate the result. <markup lang=\"java\" title=\"Updated Class with webTarget\" >import static org.junit.jupiter.api.Assertions.assertEquals; @HelidonTest class GreetTest { @Inject WebTarget webTarget; @Test void testDefaultGreeting() { JsonObject jsonObject = webTarget.path(\"/greet\") .request() .get(JsonObject.class); String expected = \"Hello World!\"; String actual = jsonObject.getString(\"message\"); assertEquals(expected, actual, \"Message in JSON\"); } } The test is now complete and verifies the message. Customize the Testing Extension The testing extension supports a few additional annotations that allow for finer control of the test execution. Optional Extension Annotations Annotation Description @HelidonTest(resetPerTest = true) Resets the container for each method. This is useful when we want to modify configuration or beans between executions. In such a case, injection into fields is not possible, as we would need a different instance for each test. @AddConfig(key = \"app.greeting\", value = \"Unite\") Defines a new configuration (either on class level, or method level) by adding a single configuration key/value. @Configuration(configSources = \"test-config.properties\") Adds a whole config source from classpath. Here&#8217;s an example showing how these approaches are used to execute the same endpoint with different configuration: <markup lang=\"java\" >@HelidonTest(resetPerTest = true) class GreetTest { @Test void testDefaultGreeting(WebTarget webTarget) { validate(webTarget, \"/greet\", \"Hello World!\"); } @Test @AddConfig(key = \"app.greeting\", value = \"Unite\") void testConfiguredGreeting(WebTarget webTarget) { validate(webTarget, \"/greet\", \"Unite World!\"); } private void validate(WebTarget webTarget, String path, String expected) { JsonObject jsonObject = webTarget.path(path) .request() .get(JsonObject.class); String actual = jsonObject.getString(\"message\"); assertEquals(expected, actual, \"Message in JSON\"); } } Use Beans for Testing If you prefer to use only beans for testing, and want to add a different bean for each test, then you must use the @AddBean annotation. This cannot be achieved by CDI discovery because if we place META-INF/beans.xml on the classpath, then all of our beans would be added. <markup lang=\"java\" >@AddBean(TestBean.class) By default the bean is added to the container with scope set to ApplicationScoped . You can customize scope either by annotating the bean class with another scope or through the annotation: <markup lang=\"java\" >@AddBean(value = TestBean.class, scope = Dependent.class) This annotation can also be placed on a method when running in resetPerTest mode. Add Test Extension When a custom bean is not enough, you may want to extend the CDI with a test-only Extension . Once again, if we use the standard way of doing this, we would need to create a META-INF/services record that would be picked up by every test class. For this purpose, we provide the following annotation which adds the extension to the container and allows you to modify its behavior as a usual CDI Portable Extension: <markup lang=\"java\" >@AddExtension(TestExtension.class) Disable Discovery If you want to disable discovery and only add custom extensions and beans, then use the following annotation: <markup lang=\"java\" >@DisableDiscovery This annotation is typically used in conjunction with @AddBeans and/or @AddExtension . As you have seen in standard test output, by default Helidon starts with the dependencies defined in pom.xml. ",
            "title": "Create a Sample Helidon MP Project"
        },
        {
            "location": "mp/guides/testing-junit5",
            "text": " If you want just the basic test features enabled, then you only have to add a few required extensions and classes to your test. The following example uses only those extensions and classes required to run a bean that injects configuration value: <markup lang=\"java\" >import jakarta.inject.Inject; import io.helidon.microprofile.config.ConfigCdiExtension; import io.helidon.microprofile.tests.junit5.AddBean; import io.helidon.microprofile.tests.junit5.AddConfig; import io.helidon.microprofile.tests.junit5.AddExtension; import io.helidon.microprofile.tests.junit5.DisableDiscovery; import io.helidon.microprofile.tests.junit5.HelidonTest; import org.eclipse.microprofile.config.inject.ConfigProperty; import org.junit.jupiter.api.Test; import static org.junit.jupiter.api.Assertions.assertEquals; @HelidonTest @DisableDiscovery @AddExtension(ConfigCdiExtension.class) @AddBean(GreetTest.ConfiguredBean.class) @AddConfig(key = \"test.message\", value = \"Hello Guide!\") class GreetTest { @Inject ConfiguredBean bean; @Test void testBean() { assertEquals(\"Hello Guide!\", bean.message()); } public static class ConfiguredBean { @Inject @ConfigProperty(name = \"test.message\") private String message; String message() { return message; } } } ",
            "title": "Write a Basic Test"
        },
        {
            "location": "mp/guides/testing-junit5",
            "text": " This guide demonstrated how to create tests for MicroProfile applications in a JUnit 5 environment. It described some useful customizations that can be added to your testing extension and allow you to configure test outcomes for your Helidon MP applications. Refer to the following references for additional information: JUnit 5 User Guide Testing with JUnit 5 ",
            "title": "Summary"
        },
        {
            "location": "mp/guides/tracing",
            "text": " This guide describes how to create a sample MicroProfile (MP) project that can be used to run some basic examples using tracing with Helidon MP. ",
            "title": "preambule"
        },
        {
            "location": "mp/guides/tracing",
            "text": " For this 30 minute tutorial, you will need the following: <div class=\"table__overflow elevation-1 flex sm7 \"> A Helidon MP Application You can use your own application or use the Helidon MP Quickstart to create a sample application. Java&#160;SE&#160;17 ( Open&#160;JDK&#160;17 ) Helidon requires Java 17+. Maven 3.6.1+ Helidon requires Maven 3.6.1+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop . <markup lang=\"bash\" title=\"Verify Prerequisites\" >java -version mvn --version docker --version kubectl version --short <markup lang=\"bash\" title=\"Setting JAVA_HOME\" ># On Mac export JAVA_HOME=`/usr/libexec/java_home -v 17` # On Linux # Use the appropriate path to your JDK export JAVA_HOME=/usr/lib/jvm/jdk-17 ",
            "title": "What You Need"
        },
        {
            "location": "mp/guides/tracing",
            "text": " This section explains a few concepts that you need to understand before you get started with tracing. In the context of this document, a service is synonymous with an application. A span is the basic unit of work done within a single service, on a single host. Every span has a name, starting timestamp, and duration. For example, the work done by a REST endpoint is a span. A span is associated to a single service, but its descendants can belong to different services and hosts. A trace contains a collection of spans from one or more services, running on one or more hosts. For example, if you trace a service endpoint that calls another service, then the trace would contain spans from both services. Within a trace, spans are organized as a directed acyclic graph (DAG) and can belong to multiple services, running on multiple hosts. The OpenTracing Data Model describes the details at The OpenTracing Semantic Specification . Spans are automatically created by Helidon as needed during execution of the REST request. ",
            "title": "Tracing Concepts"
        },
        {
            "location": "mp/guides/tracing",
            "text": " Distributed tracing is a critical feature of micro-service based applications, since it traces workflow both within a service and across multiple services. This provides insight to sequence and timing data for specific blocks of work, which helps you identify performance and operational issues. Helidon MP includes support for distributed tracing through the OpenTracing API . Tracing is integrated with WebServer, gRPC Server, and Security using either the Zipkin or Jaeger tracers. Tracing Concepts This section explains a few concepts that you need to understand before you get started with tracing. In the context of this document, a service is synonymous with an application. A span is the basic unit of work done within a single service, on a single host. Every span has a name, starting timestamp, and duration. For example, the work done by a REST endpoint is a span. A span is associated to a single service, but its descendants can belong to different services and hosts. A trace contains a collection of spans from one or more services, running on one or more hosts. For example, if you trace a service endpoint that calls another service, then the trace would contain spans from both services. Within a trace, spans are organized as a directed acyclic graph (DAG) and can belong to multiple services, running on multiple hosts. The OpenTracing Data Model describes the details at The OpenTracing Semantic Specification . Spans are automatically created by Helidon as needed during execution of the REST request. ",
            "title": "Introduction"
        },
        {
            "location": "mp/guides/tracing",
            "text": " Use the Helidon MP Maven archetype to create a simple project that can be used for the examples in this guide. <markup lang=\"bash\" title=\"Run the Maven archetype:\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-mp \\ -DarchetypeVersion=3.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-mp \\ -Dpackage=io.helidon.examples.quickstart.mp <markup lang=\"bash\" title=\"The project will be built and run from the helidon-quickstart-mp directory:\" >cd helidon-quickstart-mp ",
            "title": "Create a Sample Helidon MP project"
        },
        {
            "location": "mp/guides/tracing",
            "text": " First, you need to run the Zipkin tracer. Helidon will communicate with this tracer at runtime. <markup lang=\"bash\" title=\"Run Zipkin within a docker container, then check the Zipkin server health:\" >docker run -d --name zipkin -p 9411:9411 openzipkin/zipkin Run the Zipkin docker image named openzipkin/zipkin . <markup lang=\"bash\" title=\"Check the Zipkin server health:\" >curl http://localhost:9411/health <markup lang=\"json\" >{ \"status\": \"UP\", \"zipkin\": { \"status\": \"UP\", \"details\": { \"InMemoryStorage{}\": { \"status\": \"UP\" } } } } Invoke the Zipkin REST API to check the Zipkin server health. All status fields should be UP . ",
            "title": "Set up Zipkin"
        },
        {
            "location": "mp/guides/tracing",
            "text": " Update the pom.xml file and add the following Helidon and Zipkin dependencies to the &lt;dependencies&gt; section ( not &lt;dependencyManagement&gt; ). This will enable Helidon to use Zipkin at the default host and port, localhost:9411 . <markup lang=\"xml\" title=\"Add the following dependencies to pom.xml :\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-tracing&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-zipkin&lt;/artifactId&gt; &lt;/dependency&gt; All spans sent by Helidon to Zipkin need to be associated with a service. Specify the service name below. <markup lang=\"bash\" title=\"Add the following line to META-INF/microprofile-config.properties :\" >tracing.service=helidon-mp-1 <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-mp.jar <markup lang=\"bash\" title=\"Run the curl command in a new terminal window and check the response:\" >curl http://localhost:8080/greet <markup lang=\"json\" >{ \"message\": \"Hello World!\" } ",
            "title": "Enable Tracing in the Helidon Application"
        },
        {
            "location": "mp/guides/tracing",
            "text": " Because tracing is now enabled, the previous /greet endpoint invocation resulted in a new trace being created. Let&#8217;s get the trace data that was generated using the Zipkin API. First, get the service information. Helidon automatically enables tracing for JAX-RS resources methods so you don&#8217;t need to use annotations with JAX-RS. See MicroProfile OpenTracing for more details. <markup lang=\"bash\" title=\"Run the curl command and check the response:\" >curl http://localhost:9411/api/v2/services <markup lang=\"json\" >[\"helidon-mp-1\"] This is the tracing service name specified in META-INF/microprofile-config.properties . Each span used by a service has a name, which is unique within a trace. If you invoke the /greet endpoint multiple times, you will still get the same set of names. <markup lang=\"bash\" title=\"Invoke the endpoint below and check the response:\" > curl -X GET \"http://localhost:9411/api/v2/spans?serviceName=helidon-mp-1\" -H \"accept: application/json\" Get the span names for the helidon-mp-1 service. <markup lang=\"json\" >[ \"content-read\", \"content-write\", \"get:io.helidon.examples.quickstart.mp.greetresource.getdefaultmessage\", \"security\", \"security:atn\", \"security:atz\", \"security:response\" ] These are the span names. If you invoke the /greet endpoint again, then invoke the /spans endpoint, you will get the same response. Next, get the contents of the trace as shown below. Notice that each span has a parentId field, except the get:io.helidon.examples.quickstart.mp.greetresource.getdefaultmessage span, which is the root. <markup lang=\"bash\" title=\"Invoke the endpoint below and check the response:\" >curl -X GET \"http://localhost:9411/api/v2/traces?serviceName=helidon-mp-1&amp;limit=1\" -H \"accept: application/json\" Get the newest trace only, using the limit=1 query param. There are other query params that let you restrict results to a specific time window. <markup lang=\"json\" >[ [ { \"traceId\": \"2e0af8866efdef35\", \"parentId\": \"2e0af8866efdef35\", \"id\": \"b5d61690f230fde4\", \"kind\": \"SERVER\", \"name\": \"content-read\", \"timestamp\": 1568077339998659, \"duration\": 41, \"localEndpoint\": { \"serviceName\": \"helidon-mp-1\", \"ipv4\": \"192.168.1.115\" }, \"tags\": { \"requested.type\": \"java.io.InputStream\" } } ] ] The request will return seven spans, one for each name, along with an unnamed JSON node, which has the status. ",
            "title": "View Tracing Using Zipkin REST API"
        },
        {
            "location": "mp/guides/tracing",
            "text": " The tracing output data is verbose and can be difficult to interpret using the REST API, especially since it represents a structure of spans. Zipkin provides a web-based UI at http://localhost:9411/zipkin , where you can see a visual representation of the same data and the relationship between spans within a trace. If you see a Lens UI button at the top center then click on it and it will take you to the specific UI used by this guide. Click on the UI refresh button (the search icon) as shown in the image below. Notice that you can change the look-back time to restrict the trace list. Trace refresh The image below shows the trace summary, including start time and duration of each trace. There are two traces, each one generated in response to a curl http://localhost:8080/greet invocation. The oldest trace will have a much longer duration since there is one-time initialization that occurs. Tracing list view Click on a trace and you will see the trace detail page where the spans are listed. You can clearly see the root span and the relationship among all the spans in the trace, along with timing information. Trace detail page A parent span might not depend on the result of the child. This is called a FollowsFrom reference, see Open Tracing Semantic Spec . Note that the last span that writes the response after the root span ends falls into this category. You can examine span details by clicking on the span row. Refer to the image below, which shows the security span details, including timing information. You can see times for each space relative to the root span. These rows are annotated with Server Start and Server Finish , as shown in the third column. Span detail page ",
            "title": "View Tracing Using Zipkin UI"
        },
        {
            "location": "mp/guides/tracing",
            "text": " To trace at the method level, you just annotate a method with @Traced. <markup lang=\"java\" title=\"Update the GreetingProvider class; 1) Add a new import and 2) Add the @Traced annotation to the getMessage method:\" >import org.eclipse.microprofile.opentracing.Traced; class MyClass{ @Traced String getMessage() { return message.get(); } } Import the Traced annotation. Enable tracing for getMessage. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints and check the response:\" >curl http://localhost:8080/greet curl -X GET \"http://localhost:9411/api/v2/spans?serviceName=helidon-mp-1\" -H \"accept: application/json\" <markup lang=\"json\" >[ \"content-read\", \"content-write\", \"dosomework\", \"get:io.helidon.examples.quickstart.mp.greetresource.getdefaultmessage\", \"io.helidon.examples.quickstart.mp.greetingprovider.getmessage\", \"security\", \"security:atn\", \"security:atz\", \"security:response\" ] There is new span name for the getmessage method, since your code called that method during the invocation of /greet . Click the back button on your browser, then click on the UI refresh button to see the new trace. Select the newest trace in the list to see the trace detail page like the one below. Notice the new span named io.helidon.examples.quickstart.mp.greetingprovider.getmessage . Trace detail page with new span getmessage ",
            "title": "Tracing at the Method Level"
        },
        {
            "location": "mp/guides/tracing",
            "text": " To trace at the class level, annotate the class with @Traced. This will enable tracing for all class methods, except for the constructor and private methods. <markup lang=\"java\" title=\"Update the GreetingProvider class; 1) Add @Traced to the GreetingProvider class and 2) Remove @Traced from the getMessage method:\" >@Traced @ApplicationScoped public class GreetingProvider { String getMessage() { return message.get(); } } This will enable tracing for all class methods, except for the constructor and methods that are private. Remove @Traced for the getMessage method. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints and check the response:\" >curl http://localhost:8080/greet curl -X GET \"http://localhost:9411/api/v2/spans?serviceName=helidon-mp-1\" -H \"accept: application/json\" <markup lang=\"json\" >[ \"io.helidon.examples.quickstart.mp.greetingprovider.getmessage\" ] The service has the same set of span names as above, since getmessage was the only method called in this bean. Next, invoke HTTP PUT to change the greeting, which will cause setMessage to be called. <markup lang=\"bash\" title=\"Invoke the endpoints and check the response:\" >curl -i -X PUT -H \"Content-Type: application/json\" -d '{\"greeting\": \"Hi\"}' http://localhost:8080/greet/greeting curl -X GET \"http://localhost:9411/api/v2/spans?serviceName=helidon-mp-1\" -H \"accept: application/json\" Invoke the endpoint to change the greeting. <markup lang=\"json\" >[ \"content-read\", \"content-write\", \"get:io.helidon.examples.quickstart.mp.greetresource.getdefaultmessage\", \"io.helidon.examples.quickstart.mp.greetingprovider.getmessage\", \"io.helidon.examples.quickstart.mp.greetingprovider.setmessage\", \"put:io.helidon.examples.quickstart.mp.greetresource.updategreeting\", \"security\", \"security:atn\", \"security:atz\", \"security:response\" ] The GreetingProvider.setmessage method was traced since you enabled class level tracing. The JAX-RS method GreetResource.updategreeting was traced automatically by Helidon. You can refresh the UI view and drill down the trace to see the new spans. Methods invoked directly by your code are not enabled for tracing, even if you explicitly annotate them with @Traced. Tracing only works for methods invoked on CDI beans. See the example below. <markup lang=\"java\" title=\"Update the GreetingProvider class with the following code:\" >@ApplicationScoped public class GreetingProvider { private final AtomicReference&lt;String&gt; message = new AtomicReference&lt;&gt;(); @Inject public GreetingProvider(@ConfigProperty(name = \"app.greeting\") String message) { this.message.set(message); } @Traced String getMessage() { return getMessage2(); } @Traced String getMessage2() { return message.get(); } void setMessage(String message) { this.message.set(message); } } The getMessage method will be traced since it is externally invoked by GreetResource . The getMessage2 method will not be traced, even with the @Traced annotation, since it is called internally by getMessage . <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints and check the response:\" >curl http://localhost:8080/greet curl -X GET \"http://localhost:9411/api/v2/spans?serviceName=helidon-mp-1\" -H \"accept: application/json\" <markup lang=\"json\" >[ \"io.helidon.examples.quickstart.mp.greetingprovider.getmessage\" ] The getMessage method is traced, but getMessage2 is not. ",
            "title": "Tracing at the Class Level"
        },
        {
            "location": "mp/guides/tracing",
            "text": " So far in this tutorial you have used tracing with JAX-RS without needing to annotate. You can enable tracing on other CDI beans, either at the class level or at the method level, as shown by the following examples. Tracing at the Method Level To trace at the method level, you just annotate a method with @Traced. <markup lang=\"java\" title=\"Update the GreetingProvider class; 1) Add a new import and 2) Add the @Traced annotation to the getMessage method:\" >import org.eclipse.microprofile.opentracing.Traced; class MyClass{ @Traced String getMessage() { return message.get(); } } Import the Traced annotation. Enable tracing for getMessage. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints and check the response:\" >curl http://localhost:8080/greet curl -X GET \"http://localhost:9411/api/v2/spans?serviceName=helidon-mp-1\" -H \"accept: application/json\" <markup lang=\"json\" >[ \"content-read\", \"content-write\", \"dosomework\", \"get:io.helidon.examples.quickstart.mp.greetresource.getdefaultmessage\", \"io.helidon.examples.quickstart.mp.greetingprovider.getmessage\", \"security\", \"security:atn\", \"security:atz\", \"security:response\" ] There is new span name for the getmessage method, since your code called that method during the invocation of /greet . Click the back button on your browser, then click on the UI refresh button to see the new trace. Select the newest trace in the list to see the trace detail page like the one below. Notice the new span named io.helidon.examples.quickstart.mp.greetingprovider.getmessage . Trace detail page with new span getmessage Tracing at the Class Level To trace at the class level, annotate the class with @Traced. This will enable tracing for all class methods, except for the constructor and private methods. <markup lang=\"java\" title=\"Update the GreetingProvider class; 1) Add @Traced to the GreetingProvider class and 2) Remove @Traced from the getMessage method:\" >@Traced @ApplicationScoped public class GreetingProvider { String getMessage() { return message.get(); } } This will enable tracing for all class methods, except for the constructor and methods that are private. Remove @Traced for the getMessage method. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints and check the response:\" >curl http://localhost:8080/greet curl -X GET \"http://localhost:9411/api/v2/spans?serviceName=helidon-mp-1\" -H \"accept: application/json\" <markup lang=\"json\" >[ \"io.helidon.examples.quickstart.mp.greetingprovider.getmessage\" ] The service has the same set of span names as above, since getmessage was the only method called in this bean. Next, invoke HTTP PUT to change the greeting, which will cause setMessage to be called. <markup lang=\"bash\" title=\"Invoke the endpoints and check the response:\" >curl -i -X PUT -H \"Content-Type: application/json\" -d '{\"greeting\": \"Hi\"}' http://localhost:8080/greet/greeting curl -X GET \"http://localhost:9411/api/v2/spans?serviceName=helidon-mp-1\" -H \"accept: application/json\" Invoke the endpoint to change the greeting. <markup lang=\"json\" >[ \"content-read\", \"content-write\", \"get:io.helidon.examples.quickstart.mp.greetresource.getdefaultmessage\", \"io.helidon.examples.quickstart.mp.greetingprovider.getmessage\", \"io.helidon.examples.quickstart.mp.greetingprovider.setmessage\", \"put:io.helidon.examples.quickstart.mp.greetresource.updategreeting\", \"security\", \"security:atn\", \"security:atz\", \"security:response\" ] The GreetingProvider.setmessage method was traced since you enabled class level tracing. The JAX-RS method GreetResource.updategreeting was traced automatically by Helidon. You can refresh the UI view and drill down the trace to see the new spans. Methods invoked directly by your code are not enabled for tracing, even if you explicitly annotate them with @Traced. Tracing only works for methods invoked on CDI beans. See the example below. <markup lang=\"java\" title=\"Update the GreetingProvider class with the following code:\" >@ApplicationScoped public class GreetingProvider { private final AtomicReference&lt;String&gt; message = new AtomicReference&lt;&gt;(); @Inject public GreetingProvider(@ConfigProperty(name = \"app.greeting\") String message) { this.message.set(message); } @Traced String getMessage() { return getMessage2(); } @Traced String getMessage2() { return message.get(); } void setMessage(String message) { this.message.set(message); } } The getMessage method will be traced since it is externally invoked by GreetResource . The getMessage2 method will not be traced, even with the @Traced annotation, since it is called internally by getMessage . <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints and check the response:\" >curl http://localhost:8080/greet curl -X GET \"http://localhost:9411/api/v2/spans?serviceName=helidon-mp-1\" -H \"accept: application/json\" <markup lang=\"json\" >[ \"io.helidon.examples.quickstart.mp.greetingprovider.getmessage\" ] The getMessage method is traced, but getMessage2 is not. ",
            "title": "Enable Tracing on CDI Beans"
        },
        {
            "location": "mp/guides/tracing",
            "text": "<markup lang=\"bash\" title=\"Run the Maven archetype:\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-mp \\ -DarchetypeVersion=3.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-mp-2 \\ -Dpackage=io.helidon.examples.quickstart.mp <markup lang=\"bash\" title=\"The project will be built and run from the helidon-quickstart-mp directory:\" >cd helidon-quickstart-mp-2 <markup lang=\"xml\" title=\"Add the following dependency to pom.xml :\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-zipkin&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"bash\" title=\"Replace META-INF/microprofile-config.properties with the following:\" >app.greeting=Hello From MP-2 tracing.service=helidon-mp-2 # Microprofile server properties server.port=8081 server.host=0.0.0.0 <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-mp-2.jar <markup lang=\"bash\" title=\"Run the curl command in a new terminal window and check the response ( notice the port is 8081 ) :\" >curl http://localhost:8081/greet <markup lang=\"json\" >{ \"message\": \"Hello From MP-2 World!\" } ",
            "title": "Create a second service"
        },
        {
            "location": "mp/guides/tracing",
            "text": " Once you have validated that the second service is running correctly, you need to modify the original application to call it. <markup lang=\"java\" title=\"Replace the GreetResource class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import jakarta.enterprise.context.RequestScoped; import jakarta.inject.Inject; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.client.WebTarget; import jakarta.ws.rs.core.MediaType; import org.glassfish.jersey.server.Uri; @Path(\"/greet\") @RequestScoped public class GreetResource { @Uri(\"http://localhost:8081/greet\") private WebTarget target; private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); private final GreetingProvider greetingProvider; @Inject public GreetResource(GreetingProvider greetingConfig) { this.greetingProvider = greetingConfig; } @SuppressWarnings(\"checkstyle:designforextension\") @GET @Produces(MediaType.APPLICATION_JSON) public JsonObject getDefaultMessage() { return createResponse(\"World\"); } @GET @Path(\"/outbound\") public JsonObject outbound() { return target.request().accept(MediaType.APPLICATION_JSON_TYPE).get(JsonObject.class); } private JsonObject createResponse(String who) { String msg = String.format(\"%s %s!\", greetingProvider.getMessage(), who); return JSON.createObjectBuilder().add(\"message\", msg).build(); } } This is the WebTarget needed to send a request to the second service at port 8081 . This is the new endpoint that will call the second service. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl -i http://localhost:8080/greet/outbound The request went to the service on 8080 , which then invoked the service at 8081 to get the greeting. <markup lang=\"json\" >{ \"message\": \"Hello From MP-2 World!\" } Notice the greeting came from the second service. Refresh the Zipkin UI trace listing page and notice that there is a trace across two services. Tracing multiple service list view Click on the trace with two services to see the detail view. Tracing across multiple services detail view In the image above, you can see that the trace includes spans from two services. You will notice there is a gap before the sixth span, which is a get operation. This is a one-time client initialization delay. Run the /outbound curl command again and look at the new trace to see that the delay no longer exists. You can now stop your second service, it is no longer used in this guide. ",
            "title": "Modify the first service"
        },
        {
            "location": "mp/guides/tracing",
            "text": " Helidon automatically traces across services as long as the services use the same tracer, for example, the same instance of Zipkin. This means a single trace can include spans from multiple services and hosts. OpenTracing uses a SpanContext to propagate tracing information across process boundaries. When you make client API calls, Helidon will internally call OpenTracing APIs to propagate the SpanContext . There is nothing you need to do in your application to make this work. To demonstrate distributed tracing, you will need to create a second project, where the server listens on port 8081. Create a new root directory to hold this new project, then do the following steps, similar to what you did at the start of this guide: Create a second service <markup lang=\"bash\" title=\"Run the Maven archetype:\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-mp \\ -DarchetypeVersion=3.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-mp-2 \\ -Dpackage=io.helidon.examples.quickstart.mp <markup lang=\"bash\" title=\"The project will be built and run from the helidon-quickstart-mp directory:\" >cd helidon-quickstart-mp-2 <markup lang=\"xml\" title=\"Add the following dependency to pom.xml :\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-zipkin&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"bash\" title=\"Replace META-INF/microprofile-config.properties with the following:\" >app.greeting=Hello From MP-2 tracing.service=helidon-mp-2 # Microprofile server properties server.port=8081 server.host=0.0.0.0 <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-mp-2.jar <markup lang=\"bash\" title=\"Run the curl command in a new terminal window and check the response ( notice the port is 8081 ) :\" >curl http://localhost:8081/greet <markup lang=\"json\" >{ \"message\": \"Hello From MP-2 World!\" } Modify the first service Once you have validated that the second service is running correctly, you need to modify the original application to call it. <markup lang=\"java\" title=\"Replace the GreetResource class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import jakarta.enterprise.context.RequestScoped; import jakarta.inject.Inject; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.client.WebTarget; import jakarta.ws.rs.core.MediaType; import org.glassfish.jersey.server.Uri; @Path(\"/greet\") @RequestScoped public class GreetResource { @Uri(\"http://localhost:8081/greet\") private WebTarget target; private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); private final GreetingProvider greetingProvider; @Inject public GreetResource(GreetingProvider greetingConfig) { this.greetingProvider = greetingConfig; } @SuppressWarnings(\"checkstyle:designforextension\") @GET @Produces(MediaType.APPLICATION_JSON) public JsonObject getDefaultMessage() { return createResponse(\"World\"); } @GET @Path(\"/outbound\") public JsonObject outbound() { return target.request().accept(MediaType.APPLICATION_JSON_TYPE).get(JsonObject.class); } private JsonObject createResponse(String who) { String msg = String.format(\"%s %s!\", greetingProvider.getMessage(), who); return JSON.createObjectBuilder().add(\"message\", msg).build(); } } This is the WebTarget needed to send a request to the second service at port 8081 . This is the new endpoint that will call the second service. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl -i http://localhost:8080/greet/outbound The request went to the service on 8080 , which then invoked the service at 8081 to get the greeting. <markup lang=\"json\" >{ \"message\": \"Hello From MP-2 World!\" } Notice the greeting came from the second service. Refresh the Zipkin UI trace listing page and notice that there is a trace across two services. Tracing multiple service list view Click on the trace with two services to see the detail view. Tracing across multiple services detail view In the image above, you can see that the trace includes spans from two services. You will notice there is a gap before the sixth span, which is a get operation. This is a one-time client initialization delay. Run the /outbound curl command again and look at the new trace to see that the delay no longer exists. You can now stop your second service, it is no longer used in this guide. ",
            "title": "Trace Across Services"
        },
        {
            "location": "mp/guides/tracing",
            "text": " The examples in this guide demonstrate how to integrate tracing with Helidon, how to view traces, how to trace across multiple services, and how to integrate tracing with Kubernetes. All examples use Zipkin and traces will be viewed using both the Zipkin API and UI. Create a Sample Helidon MP project Use the Helidon MP Maven archetype to create a simple project that can be used for the examples in this guide. <markup lang=\"bash\" title=\"Run the Maven archetype:\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-mp \\ -DarchetypeVersion=3.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-mp \\ -Dpackage=io.helidon.examples.quickstart.mp <markup lang=\"bash\" title=\"The project will be built and run from the helidon-quickstart-mp directory:\" >cd helidon-quickstart-mp Set up Zipkin First, you need to run the Zipkin tracer. Helidon will communicate with this tracer at runtime. <markup lang=\"bash\" title=\"Run Zipkin within a docker container, then check the Zipkin server health:\" >docker run -d --name zipkin -p 9411:9411 openzipkin/zipkin Run the Zipkin docker image named openzipkin/zipkin . <markup lang=\"bash\" title=\"Check the Zipkin server health:\" >curl http://localhost:9411/health <markup lang=\"json\" >{ \"status\": \"UP\", \"zipkin\": { \"status\": \"UP\", \"details\": { \"InMemoryStorage{}\": { \"status\": \"UP\" } } } } Invoke the Zipkin REST API to check the Zipkin server health. All status fields should be UP . Enable Tracing in the Helidon Application Update the pom.xml file and add the following Helidon and Zipkin dependencies to the &lt;dependencies&gt; section ( not &lt;dependencyManagement&gt; ). This will enable Helidon to use Zipkin at the default host and port, localhost:9411 . <markup lang=\"xml\" title=\"Add the following dependencies to pom.xml :\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-tracing&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-zipkin&lt;/artifactId&gt; &lt;/dependency&gt; All spans sent by Helidon to Zipkin need to be associated with a service. Specify the service name below. <markup lang=\"bash\" title=\"Add the following line to META-INF/microprofile-config.properties :\" >tracing.service=helidon-mp-1 <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-mp.jar <markup lang=\"bash\" title=\"Run the curl command in a new terminal window and check the response:\" >curl http://localhost:8080/greet <markup lang=\"json\" >{ \"message\": \"Hello World!\" } View Tracing Using Zipkin REST API Because tracing is now enabled, the previous /greet endpoint invocation resulted in a new trace being created. Let&#8217;s get the trace data that was generated using the Zipkin API. First, get the service information. Helidon automatically enables tracing for JAX-RS resources methods so you don&#8217;t need to use annotations with JAX-RS. See MicroProfile OpenTracing for more details. <markup lang=\"bash\" title=\"Run the curl command and check the response:\" >curl http://localhost:9411/api/v2/services <markup lang=\"json\" >[\"helidon-mp-1\"] This is the tracing service name specified in META-INF/microprofile-config.properties . Each span used by a service has a name, which is unique within a trace. If you invoke the /greet endpoint multiple times, you will still get the same set of names. <markup lang=\"bash\" title=\"Invoke the endpoint below and check the response:\" > curl -X GET \"http://localhost:9411/api/v2/spans?serviceName=helidon-mp-1\" -H \"accept: application/json\" Get the span names for the helidon-mp-1 service. <markup lang=\"json\" >[ \"content-read\", \"content-write\", \"get:io.helidon.examples.quickstart.mp.greetresource.getdefaultmessage\", \"security\", \"security:atn\", \"security:atz\", \"security:response\" ] These are the span names. If you invoke the /greet endpoint again, then invoke the /spans endpoint, you will get the same response. Next, get the contents of the trace as shown below. Notice that each span has a parentId field, except the get:io.helidon.examples.quickstart.mp.greetresource.getdefaultmessage span, which is the root. <markup lang=\"bash\" title=\"Invoke the endpoint below and check the response:\" >curl -X GET \"http://localhost:9411/api/v2/traces?serviceName=helidon-mp-1&amp;limit=1\" -H \"accept: application/json\" Get the newest trace only, using the limit=1 query param. There are other query params that let you restrict results to a specific time window. <markup lang=\"json\" >[ [ { \"traceId\": \"2e0af8866efdef35\", \"parentId\": \"2e0af8866efdef35\", \"id\": \"b5d61690f230fde4\", \"kind\": \"SERVER\", \"name\": \"content-read\", \"timestamp\": 1568077339998659, \"duration\": 41, \"localEndpoint\": { \"serviceName\": \"helidon-mp-1\", \"ipv4\": \"192.168.1.115\" }, \"tags\": { \"requested.type\": \"java.io.InputStream\" } } ] ] The request will return seven spans, one for each name, along with an unnamed JSON node, which has the status. View Tracing Using Zipkin UI The tracing output data is verbose and can be difficult to interpret using the REST API, especially since it represents a structure of spans. Zipkin provides a web-based UI at http://localhost:9411/zipkin , where you can see a visual representation of the same data and the relationship between spans within a trace. If you see a Lens UI button at the top center then click on it and it will take you to the specific UI used by this guide. Click on the UI refresh button (the search icon) as shown in the image below. Notice that you can change the look-back time to restrict the trace list. Trace refresh The image below shows the trace summary, including start time and duration of each trace. There are two traces, each one generated in response to a curl http://localhost:8080/greet invocation. The oldest trace will have a much longer duration since there is one-time initialization that occurs. Tracing list view Click on a trace and you will see the trace detail page where the spans are listed. You can clearly see the root span and the relationship among all the spans in the trace, along with timing information. Trace detail page A parent span might not depend on the result of the child. This is called a FollowsFrom reference, see Open Tracing Semantic Spec . Note that the last span that writes the response after the root span ends falls into this category. You can examine span details by clicking on the span row. Refer to the image below, which shows the security span details, including timing information. You can see times for each space relative to the root span. These rows are annotated with Server Start and Server Finish , as shown in the third column. Span detail page Enable Tracing on CDI Beans So far in this tutorial you have used tracing with JAX-RS without needing to annotate. You can enable tracing on other CDI beans, either at the class level or at the method level, as shown by the following examples. Tracing at the Method Level To trace at the method level, you just annotate a method with @Traced. <markup lang=\"java\" title=\"Update the GreetingProvider class; 1) Add a new import and 2) Add the @Traced annotation to the getMessage method:\" >import org.eclipse.microprofile.opentracing.Traced; class MyClass{ @Traced String getMessage() { return message.get(); } } Import the Traced annotation. Enable tracing for getMessage. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints and check the response:\" >curl http://localhost:8080/greet curl -X GET \"http://localhost:9411/api/v2/spans?serviceName=helidon-mp-1\" -H \"accept: application/json\" <markup lang=\"json\" >[ \"content-read\", \"content-write\", \"dosomework\", \"get:io.helidon.examples.quickstart.mp.greetresource.getdefaultmessage\", \"io.helidon.examples.quickstart.mp.greetingprovider.getmessage\", \"security\", \"security:atn\", \"security:atz\", \"security:response\" ] There is new span name for the getmessage method, since your code called that method during the invocation of /greet . Click the back button on your browser, then click on the UI refresh button to see the new trace. Select the newest trace in the list to see the trace detail page like the one below. Notice the new span named io.helidon.examples.quickstart.mp.greetingprovider.getmessage . Trace detail page with new span getmessage Tracing at the Class Level To trace at the class level, annotate the class with @Traced. This will enable tracing for all class methods, except for the constructor and private methods. <markup lang=\"java\" title=\"Update the GreetingProvider class; 1) Add @Traced to the GreetingProvider class and 2) Remove @Traced from the getMessage method:\" >@Traced @ApplicationScoped public class GreetingProvider { String getMessage() { return message.get(); } } This will enable tracing for all class methods, except for the constructor and methods that are private. Remove @Traced for the getMessage method. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints and check the response:\" >curl http://localhost:8080/greet curl -X GET \"http://localhost:9411/api/v2/spans?serviceName=helidon-mp-1\" -H \"accept: application/json\" <markup lang=\"json\" >[ \"io.helidon.examples.quickstart.mp.greetingprovider.getmessage\" ] The service has the same set of span names as above, since getmessage was the only method called in this bean. Next, invoke HTTP PUT to change the greeting, which will cause setMessage to be called. <markup lang=\"bash\" title=\"Invoke the endpoints and check the response:\" >curl -i -X PUT -H \"Content-Type: application/json\" -d '{\"greeting\": \"Hi\"}' http://localhost:8080/greet/greeting curl -X GET \"http://localhost:9411/api/v2/spans?serviceName=helidon-mp-1\" -H \"accept: application/json\" Invoke the endpoint to change the greeting. <markup lang=\"json\" >[ \"content-read\", \"content-write\", \"get:io.helidon.examples.quickstart.mp.greetresource.getdefaultmessage\", \"io.helidon.examples.quickstart.mp.greetingprovider.getmessage\", \"io.helidon.examples.quickstart.mp.greetingprovider.setmessage\", \"put:io.helidon.examples.quickstart.mp.greetresource.updategreeting\", \"security\", \"security:atn\", \"security:atz\", \"security:response\" ] The GreetingProvider.setmessage method was traced since you enabled class level tracing. The JAX-RS method GreetResource.updategreeting was traced automatically by Helidon. You can refresh the UI view and drill down the trace to see the new spans. Methods invoked directly by your code are not enabled for tracing, even if you explicitly annotate them with @Traced. Tracing only works for methods invoked on CDI beans. See the example below. <markup lang=\"java\" title=\"Update the GreetingProvider class with the following code:\" >@ApplicationScoped public class GreetingProvider { private final AtomicReference&lt;String&gt; message = new AtomicReference&lt;&gt;(); @Inject public GreetingProvider(@ConfigProperty(name = \"app.greeting\") String message) { this.message.set(message); } @Traced String getMessage() { return getMessage2(); } @Traced String getMessage2() { return message.get(); } void setMessage(String message) { this.message.set(message); } } The getMessage method will be traced since it is externally invoked by GreetResource . The getMessage2 method will not be traced, even with the @Traced annotation, since it is called internally by getMessage . <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints and check the response:\" >curl http://localhost:8080/greet curl -X GET \"http://localhost:9411/api/v2/spans?serviceName=helidon-mp-1\" -H \"accept: application/json\" <markup lang=\"json\" >[ \"io.helidon.examples.quickstart.mp.greetingprovider.getmessage\" ] The getMessage method is traced, but getMessage2 is not. Trace Across Services Helidon automatically traces across services as long as the services use the same tracer, for example, the same instance of Zipkin. This means a single trace can include spans from multiple services and hosts. OpenTracing uses a SpanContext to propagate tracing information across process boundaries. When you make client API calls, Helidon will internally call OpenTracing APIs to propagate the SpanContext . There is nothing you need to do in your application to make this work. To demonstrate distributed tracing, you will need to create a second project, where the server listens on port 8081. Create a new root directory to hold this new project, then do the following steps, similar to what you did at the start of this guide: Create a second service <markup lang=\"bash\" title=\"Run the Maven archetype:\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-mp \\ -DarchetypeVersion=3.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-mp-2 \\ -Dpackage=io.helidon.examples.quickstart.mp <markup lang=\"bash\" title=\"The project will be built and run from the helidon-quickstart-mp directory:\" >cd helidon-quickstart-mp-2 <markup lang=\"xml\" title=\"Add the following dependency to pom.xml :\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-zipkin&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"bash\" title=\"Replace META-INF/microprofile-config.properties with the following:\" >app.greeting=Hello From MP-2 tracing.service=helidon-mp-2 # Microprofile server properties server.port=8081 server.host=0.0.0.0 <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-mp-2.jar <markup lang=\"bash\" title=\"Run the curl command in a new terminal window and check the response ( notice the port is 8081 ) :\" >curl http://localhost:8081/greet <markup lang=\"json\" >{ \"message\": \"Hello From MP-2 World!\" } Modify the first service Once you have validated that the second service is running correctly, you need to modify the original application to call it. <markup lang=\"java\" title=\"Replace the GreetResource class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import jakarta.enterprise.context.RequestScoped; import jakarta.inject.Inject; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.client.WebTarget; import jakarta.ws.rs.core.MediaType; import org.glassfish.jersey.server.Uri; @Path(\"/greet\") @RequestScoped public class GreetResource { @Uri(\"http://localhost:8081/greet\") private WebTarget target; private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); private final GreetingProvider greetingProvider; @Inject public GreetResource(GreetingProvider greetingConfig) { this.greetingProvider = greetingConfig; } @SuppressWarnings(\"checkstyle:designforextension\") @GET @Produces(MediaType.APPLICATION_JSON) public JsonObject getDefaultMessage() { return createResponse(\"World\"); } @GET @Path(\"/outbound\") public JsonObject outbound() { return target.request().accept(MediaType.APPLICATION_JSON_TYPE).get(JsonObject.class); } private JsonObject createResponse(String who) { String msg = String.format(\"%s %s!\", greetingProvider.getMessage(), who); return JSON.createObjectBuilder().add(\"message\", msg).build(); } } This is the WebTarget needed to send a request to the second service at port 8081 . This is the new endpoint that will call the second service. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl -i http://localhost:8080/greet/outbound The request went to the service on 8080 , which then invoked the service at 8081 to get the greeting. <markup lang=\"json\" >{ \"message\": \"Hello From MP-2 World!\" } Notice the greeting came from the second service. Refresh the Zipkin UI trace listing page and notice that there is a trace across two services. Tracing multiple service list view Click on the trace with two services to see the detail view. Tracing across multiple services detail view In the image above, you can see that the trace includes spans from two services. You will notice there is a gap before the sixth span, which is a get operation. This is a one-time client initialization delay. Run the /outbound curl command again and look at the new trace to see that the delay no longer exists. You can now stop your second service, it is no longer used in this guide. ",
            "title": "Getting Started with Tracing"
        },
        {
            "location": "mp/guides/tracing",
            "text": "<markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named zipkin.yaml , with the following contents:\" >apiVersion: v1 kind: Service metadata: name: zipkin spec: ports: - port: 9411 protocol: TCP selector: app: zipkin --- kind: Pod apiVersion: v1 metadata: name: zipkin labels: app: zipkin spec: containers: - name: zipkin image: openzipkin/zipkin imagePullPolicy: IfNotPresent ports: - containerPort: 9411 <markup lang=\"bash\" title=\"Create the Zipkin pod and ClusterIP service:\" >kubectl apply -f ./zipkin.yaml <markup lang=\"bash\" title=\"Create a Zipkin external server and expose it on port 9142:\" >kubectl expose pod zipkin --name=zipkin-external --port=9412 --target-port=9411 --type=LoadBalancer Create a service so that you can access the Zipkin UI. Navigate to http://localhost:9412/zipkin to validate that you can access Zipkin running in Kubernetes. It may take a few seconds before it is ready. ",
            "title": "Deploy Zipkin into Kubernetes"
        },
        {
            "location": "mp/guides/tracing",
            "text": "<markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named tracing.yaml , with the following contents:\" >kind: Service apiVersion: v1 metadata: name: helidon-tracing labels: app: helidon-tracing spec: type: NodePort selector: app: helidon-tracing ports: - port: 8080 targetPort: 8080 name: http --- kind: Deployment apiVersion: apps/v1 metadata: name: helidon-tracing spec: replicas: 1 selector: matchLabels: app: helidon-tracing template: metadata: labels: app: helidon-tracing version: v1 spec: containers: - name: helidon-tracing image: helidon-tracing-mp imagePullPolicy: IfNotPresent ports: - containerPort: 8080 A service of type NodePort that serves the default routes on port 8080 . A deployment with one replica of a pod. <markup lang=\"bash\" title=\"Create and deploy the application into Kubernetes:\" >kubectl apply -f ./tracing.yaml ",
            "title": "Deploy Your Helidon Application into Kubernetes"
        },
        {
            "location": "mp/guides/tracing",
            "text": "<markup lang=\"bash\" title=\"Get the application service information:\" >kubectl get service/helidon-tracing <markup lang=\"bash\" >NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE helidon-tracing NodePort 10.99.159.2 &lt;none&gt; 8080:31143/TCP 8s A service of type NodePort that serves the default routes on port 31143 . <markup lang=\"bash\" title=\"Verify the tracing endpoint using port 31143 , your port will likely be different:\" >curl http://localhost:31143/greet <markup lang=\"json\" >{ \"message\": \"Hello World!\" } Access the Zipkin UI at http://localhost:9412/zipkin and click on the refresh icon to see the trace that was just created. ",
            "title": "Access Your Application and the Zipkin Trace"
        },
        {
            "location": "mp/guides/tracing",
            "text": " You can now delete the Kubernetes resources that were just created during this example. <markup lang=\"bash\" title=\"Delete the Kubernetes resources:\" >kubectl delete -f ./zipkin.yaml kubectl delete -f ./tracing.yaml kubectl delete service zipkin-external docker rm -f zipkin ",
            "title": "Cleanup"
        },
        {
            "location": "mp/guides/tracing",
            "text": " The following example demonstrate how to use Zipkin from a Helidon application running in Kubernetes. <markup lang=\"bash\" title=\"Add the following line to META-INF/microprofile-config.properties :\" >tracing.host=zipkin <markup lang=\"bash\" title=\"Stop the application and build the docker image for your application:\" >docker build -t helidon-tracing-mp . Deploy Zipkin into Kubernetes <markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named zipkin.yaml , with the following contents:\" >apiVersion: v1 kind: Service metadata: name: zipkin spec: ports: - port: 9411 protocol: TCP selector: app: zipkin --- kind: Pod apiVersion: v1 metadata: name: zipkin labels: app: zipkin spec: containers: - name: zipkin image: openzipkin/zipkin imagePullPolicy: IfNotPresent ports: - containerPort: 9411 <markup lang=\"bash\" title=\"Create the Zipkin pod and ClusterIP service:\" >kubectl apply -f ./zipkin.yaml <markup lang=\"bash\" title=\"Create a Zipkin external server and expose it on port 9142:\" >kubectl expose pod zipkin --name=zipkin-external --port=9412 --target-port=9411 --type=LoadBalancer Create a service so that you can access the Zipkin UI. Navigate to http://localhost:9412/zipkin to validate that you can access Zipkin running in Kubernetes. It may take a few seconds before it is ready. Deploy Your Helidon Application into Kubernetes <markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named tracing.yaml , with the following contents:\" >kind: Service apiVersion: v1 metadata: name: helidon-tracing labels: app: helidon-tracing spec: type: NodePort selector: app: helidon-tracing ports: - port: 8080 targetPort: 8080 name: http --- kind: Deployment apiVersion: apps/v1 metadata: name: helidon-tracing spec: replicas: 1 selector: matchLabels: app: helidon-tracing template: metadata: labels: app: helidon-tracing version: v1 spec: containers: - name: helidon-tracing image: helidon-tracing-mp imagePullPolicy: IfNotPresent ports: - containerPort: 8080 A service of type NodePort that serves the default routes on port 8080 . A deployment with one replica of a pod. <markup lang=\"bash\" title=\"Create and deploy the application into Kubernetes:\" >kubectl apply -f ./tracing.yaml Access Your Application and the Zipkin Trace <markup lang=\"bash\" title=\"Get the application service information:\" >kubectl get service/helidon-tracing <markup lang=\"bash\" >NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE helidon-tracing NodePort 10.99.159.2 &lt;none&gt; 8080:31143/TCP 8s A service of type NodePort that serves the default routes on port 31143 . <markup lang=\"bash\" title=\"Verify the tracing endpoint using port 31143 , your port will likely be different:\" >curl http://localhost:31143/greet <markup lang=\"json\" >{ \"message\": \"Hello World!\" } Access the Zipkin UI at http://localhost:9412/zipkin and click on the refresh icon to see the trace that was just created. Cleanup You can now delete the Kubernetes resources that were just created during this example. <markup lang=\"bash\" title=\"Delete the Kubernetes resources:\" >kubectl delete -f ./zipkin.yaml kubectl delete -f ./tracing.yaml kubectl delete service zipkin-external docker rm -f zipkin ",
            "title": "Integration with Kubernetes"
        },
        {
            "location": "mp/guides/tracing",
            "text": " This guide has demonstrated how to use the Helidon MP tracing feature with Zipkin. You have learned to do the following: Enable tracing within a service Use tracing with JAX-RS and CDI beans Use the Zipkin REST API and UI Use tracing across multiple services Integrate tracing with Kubernetes Refer to the following references for additional information: MicroProfile OpenTracing specification MicroProfile OpenTracing Javadoc Helidon Javadoc ",
            "title": "Summary"
        },
        {
            "location": "mp/health",
            "text": " Overview Maven Coordinates Usage REST Endpoints Configuration Examples Reference ",
            "title": "Contents"
        },
        {
            "location": "mp/health",
            "text": " Microservices expose their health status primarily so external tools (for example, an orchestrator such as Kubernetes) can monitor each service and take action, such as restarting a service instance if it has failed or temporarily shunting traffic away from the instance if the service is unable to process incoming requests normally. ",
            "title": "Overview"
        },
        {
            "location": "mp/health",
            "text": " To enable MicroProfile Health add the helidon-microprofile bundle dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.bundles&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile&lt;/artifactId&gt; &lt;/dependency&gt; MicroProfile Health is already included in the bundle. If full control over the dependencies is required, and you want to minimize the quantity of the dependencies - Helidon MicroProfile Core budnle should be used. In this case the following dependencies should be included in your project&#8217;s pom.xml : <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.bundles&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-core&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.health&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-health&lt;/artifactId&gt; &lt;/dependency&gt; To enable built-in health checks add the following dependency (or use the helidon-microprofile bundle ) <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.health&lt;/groupId&gt; &lt;artifactId&gt;helidon-health-checks&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "mp/health",
            "text": " MicroProfile Health supports three types of health checks: Liveness checks report whether the runtime environment in which the service is running is sufficient to support the work the service performs. The environment is beyond the control of the service itself and typically cannot improve without outside intervention. If a microservice instance reports a DOWN liveness check, it should never report UP later. It will need to be stopped and a replacement instance created. Readiness checks report whether the service is currently capable of performing its work. A service that reports DOWN for its readiness cannot at the moment do its job, but at some future point it might become able to do so without requiring a restart. Startup checks indicate whether the service has started to the point where liveness and readiness checks even make sense. A service reporting DOWN for a startup check is still initializing itself and normally will report UP soon, assuming it is able to start successfully. ",
            "title": "Concepts - Liveness, Readiness, and Startup Checks"
        },
        {
            "location": "mp/health",
            "text": " Helidon implements MicroProfile Health Specification. The spec prescribes how external tools probe a service&#8217;s health checks and how you implement health checks as part of your microservice that are specific to your service&#8217;s needs. Concepts - Liveness, Readiness, and Startup Checks MicroProfile Health supports three types of health checks: Liveness checks report whether the runtime environment in which the service is running is sufficient to support the work the service performs. The environment is beyond the control of the service itself and typically cannot improve without outside intervention. If a microservice instance reports a DOWN liveness check, it should never report UP later. It will need to be stopped and a replacement instance created. Readiness checks report whether the service is currently capable of performing its work. A service that reports DOWN for its readiness cannot at the moment do its job, but at some future point it might become able to do so without requiring a restart. Startup checks indicate whether the service has started to the point where liveness and readiness checks even make sense. A service reporting DOWN for a startup check is still initializing itself and normally will report UP soon, assuming it is able to start successfully. ",
            "title": "Usage"
        },
        {
            "location": "mp/health",
            "text": " A MicroProfile-compliant service reports its health via known REST endpoints. Helidon MP provides these endpoints automatically as part of every MP microservice that includes health support.. External management tools (or curl or browsers) retrieve health checks using the REST endpoints in the table below which summarizes the types of health checks in MicroProfile Health. Responses from the health endpoints report 200 (OK), 204 (no content), or 503 (service unavailable) depending on the outcome of running the health checks. HTTP GET responses include JSON content showing the detailed results of all the health checks which the server executed after receiving the request. HTTP HEAD requests return only the status with no payload. Types of Health Checks Type Meaning REST endpoint Kubernetes response on failure liveness whether the runtime environment is suitable /health/live Restarts container. readiness whether the microservice is currently capable of doing its work /health/ready Diverts requests away from the instance; periodically rechecks readiness and resumes traffic once the microservice reports itself as ready. startup whether the microservice has initialized to the point where liveness and readiness checks might pass /health/started Treats the instance as still starting up; does not check liveness or readiness until the startup probe reports success or times out according to its configuration. ",
            "title": "REST Endpoints"
        },
        {
            "location": "mp/health",
            "text": " Optional configuration options key type default value description cors CrossOriginConfig &#160; Sets the cross-origin config builder for use in establishing CORS support for the service endpoints. enabled boolean true HealthSupport can be disabled by invoking this method. exclude string[&#93; &#160; Add health checks to a black list. Health check results that match by name with a blacklisted records will not be part of the result. exclude-classes Class&lt;?&gt;[&#93; &#160; A class may be excluded from invoking health checks on it. This allows configurable approach to disabling broken health-checks. include string[&#93; &#160; Add health checks to a white list (in case #includeAll is set to false . routing string &#160; Sets the routing name to use for setting up the service&#8217;s endpoint. timeout-millis long 10000 health endpoint timeout (ms) web-context string &#160; Sets the web context to use for the service&#8217;s endpoint. Current properties may be set in application.yaml or in microprofile-config.properties with health prefix. For example, you can specify a custom port and root context for the root health endpoint path. However, you cannot use different ports, such as http://localhost:8080/myhealth and http://localhost:8081/myhealth/live . Likewise, you cannot use different paths, such as http://localhost:8080/health and http://localhost:8080/probe/live . The example below will change the root path. <markup lang=\"properties\" title=\"Create a file named microprofile-config.properties in the resources/META-INF directory with the following contents:\" >health.web-context=myhealth The web-context specifies a new root path for the health endpoint. ",
            "title": "Configuration options"
        },
        {
            "location": "mp/health",
            "text": " Health checks may be configured using the following properties. The class responsible for configuration is: Type: io.helidon.health.HealthSupport This is a standalone configuration type, prefix from configuration root: health Configuration options Optional configuration options key type default value description cors CrossOriginConfig &#160; Sets the cross-origin config builder for use in establishing CORS support for the service endpoints. enabled boolean true HealthSupport can be disabled by invoking this method. exclude string[&#93; &#160; Add health checks to a black list. Health check results that match by name with a blacklisted records will not be part of the result. exclude-classes Class&lt;?&gt;[&#93; &#160; A class may be excluded from invoking health checks on it. This allows configurable approach to disabling broken health-checks. include string[&#93; &#160; Add health checks to a white list (in case #includeAll is set to false . routing string &#160; Sets the routing name to use for setting up the service&#8217;s endpoint. timeout-millis long 10000 health endpoint timeout (ms) web-context string &#160; Sets the web context to use for the service&#8217;s endpoint. Current properties may be set in application.yaml or in microprofile-config.properties with health prefix. For example, you can specify a custom port and root context for the root health endpoint path. However, you cannot use different ports, such as http://localhost:8080/myhealth and http://localhost:8081/myhealth/live . Likewise, you cannot use different paths, such as http://localhost:8080/health and http://localhost:8080/probe/live . The example below will change the root path. <markup lang=\"properties\" title=\"Create a file named microprofile-config.properties in the resources/META-INF directory with the following contents:\" >health.web-context=myhealth The web-context specifies a new root path for the health endpoint. ",
            "title": "Configuration"
        },
        {
            "location": "mp/health",
            "text": " Helidon has a set of built-in health checks that are enabled to report various health check statuses that are commonly used: deadlock detection available disk space available heap memory The following example will demonstrate how to use the built-in health checks. These examples are all executed from the root directory of your project (helidon-quickstart-mp). <markup lang=\"bash\" title=\"Build the application, then run it:\" >mvn package java -jar target/helidon-quickstart-mp.jar <markup lang=\"bash\" title=\"Verify the health endpoint in a new terminal window:\" >curl http://localhost:8080/health <markup lang=\"json\" title=\"JSON response:\" >{ \"status\": \"UP\", \"checks\": [ { \"name\": \"deadlock\", \"status\": \"UP\" }, { \"name\": \"diskSpace\", \"status\": \"UP\", \"data\": { \"free\": \"325.54 GB\", \"freeBytes\": 349543358464, \"percentFree\": \"69.91%\", \"total\": \"465.63 GB\", \"totalBytes\": 499963174912 } }, { \"name\": \"heapMemory\", \"status\": \"UP\", \"data\": { \"free\": \"230.87 MB\", \"freeBytes\": 242085696, \"max\": \"3.56 GB\", \"maxBytes\": 3817865216, \"percentFree\": \"98.90%\", \"total\": \"271.00 MB\", \"totalBytes\": 284164096 } } ] } ",
            "title": "Using the Built-In Health Checks"
        },
        {
            "location": "mp/health",
            "text": " You can create application-specific custom health checks and integrate them with Helidon using CDI. The following example shows how to add a custom liveness health check. <markup lang=\"java\" title=\"Create a new GreetLivenessCheck class with the following content:\" >@Liveness @ApplicationScoped public class GreetLivenessCheck implements HealthCheck { @Override public HealthCheckResponse call() { return HealthCheckResponse.named(\"LivenessCheck\") .up() .withData(\"time\", System.currentTimeMillis()) .build(); } } Annotation indicating this is a liveness health check. Annotation indicating this is a bean instantiated once per application (in Helidon this means just once per runtime). Build the HealthCheckResponse with status UP and the current time. <markup lang=\"bash\" title=\"Build and run the application, then verify the custom liveness health endpoint:\" >curl http://localhost:8080/health/live <markup lang=\"json\" title=\"JSON response:\" >{ \"status\": \"UP\", \"checks\": [ { \"name\": \"LivenessCheck\", \"status\": \"UP\", \"data\": { \"time\": 1566338255331 } } ] } Full example code is available here . ",
            "title": "Custom Liveness Health Checks"
        },
        {
            "location": "mp/health",
            "text": " You can add a readiness check to indicate that the application is ready to be used. In this example, the server will wait five seconds before it becomes ready. <markup lang=\"java\" title=\"Create a new GreetReadinessCheck class with the following content:\" >@Readiness @ApplicationScoped public class GreetReadinessCheck implements HealthCheck { private final AtomicLong readyTime = new AtomicLong(0); @Override public HealthCheckResponse call() { return HealthCheckResponse.named(\"ReadinessCheck\") .status(isReady()) .withData(\"time\", readyTime.get()) .build(); } public void onStartUp( @Observes @Initialized(ApplicationScoped.class) Object init) { readyTime.set(System.currentTimeMillis()); } private boolean isReady() { return Duration.ofMillis(System.currentTimeMillis() - readyTime.get()).getSeconds() &gt;= 5; } } Annotation indicating that this is a readiness health check. Build the HealthCheckResponse with status UP after five seconds, else DOWN . Record the time at startup. Become ready after 5 seconds. <markup lang=\"bash\" title=\"Build and run the application. Issue the curl command with -v within five seconds and you will see that the application is not ready:\" >curl -v http://localhost:8080/health/ready <markup title=\"HTTP response status\" >&lt; HTTP/1.1 503 Service Unavailable The HTTP status is 503 since the application is not ready. <markup lang=\"json\" title=\"JSON response body:\" >{ \"status\": \"DOWN\", \"checks\": [ { \"name\": \"ReadinessCheck\", \"status\": \"DOWN\", \"data\": { \"time\": 1566399775700 } } ] } <markup lang=\"bash\" title=\"After five seconds you will see the application is ready:\" >curl -v http://localhost:8080/health/ready <markup title=\"HTTP response status\" >&lt; HTTP/1.1 200 OK The HTTP status is 200 indicating that the application is ready. <markup lang=\"json\" title=\"JSON response body:\" >{ \"status\": \"UP\", \"checks\": [ { \"name\": \"ReadinessCheck\", \"status\": \"UP\", \"data\": { \"time\": 1566399775700 } } ] } Full example code is available here . ",
            "title": "Custom Readiness Health Checks"
        },
        {
            "location": "mp/health",
            "text": " You can add a startup check to indicate whether or not the application has initialized to the point that the other health checks make sense. In this example, the server will wait eight seconds before it declares itself started. <markup lang=\"java\" title=\"Create a new GreetStartedCheck class with the following content:\" >@Startup @ApplicationScoped public class GreetStartedCheck implements HealthCheck { private final AtomicLong readyTime = new AtomicLong(0); @Override public HealthCheckResponse call() { return HealthCheckResponse.named(\"StartedCheck\") .status(isStarted()) .withData(\"time\", readyTime.get()) .build(); } public void onStartUp( @Observes @Initialized(ApplicationScoped.class) Object init) { readyTime.set(System.currentTimeMillis()); } private boolean isStarted() { return Duration.ofMillis(System.currentTimeMillis() - readyTime.get()).getSeconds() &gt;= 8; } } Annotation indicating that this is a startup health check. Build the HealthCheckResponse with status UP after eight seconds, else DOWN . Record the time at startup of Helidon; the application will declare itself as started eight seconds later. Become ready after 5 seconds. <markup lang=\"bash\" title=\"Build and run the application. Issue the curl command with -v within five seconds and you will see that the application has not yet started:\" >curl -v http://localhost:8080/health/started <markup title=\"HTTP response status:\" >&lt; HTTP/1.1 503 Service Unavailable The HTTP status is 503 since the application has not started. <markup lang=\"json\" title=\"JSON response body:\" >{ \"status\": \"DOWN\", \"checks\": [ { \"name\": \"StartedCheck\", \"status\": \"DOWN\", \"data\": { \"time\": 1566399775700 } } ] } <markup lang=\"bash\" title=\"After eight seconds you will see the application has started:\" >curl -v http://localhost:8080/health/started <markup title=\"HTTP response status:\" >&lt; HTTP/1.1 200 OK The HTTP status is 200 indicating that the application is started. <markup lang=\"json\" title=\"JSON response body:\" >{ \"status\": \"UP\", \"checks\": [ { \"name\": \"StartedCheck\", \"status\": \"UP\", \"data\": { \"time\": 1566399775700 } } ] } When using the health check URLs, you can get the following health check data: liveness only - http://localhost:8080/health/live readiness only - http://localhost:8080/health/ready startup checks only - http://localhost:8080/health/started all health check data - http://localhost:8080/health <markup lang=\"bash\" title=\"Get all the health check data, including custom data:\" >curl http://localhost:8080/health <markup lang=\"json\" title=\"JSON response:\" >{ \"status\": \"UP\", \"checks\": [ { \"name\": \"LivenessCheck\", \"status\": \"UP\", \"data\": { \"time\": 1566403431536 } } ] } Full example code is available here . ",
            "title": "Custom Startup Health Checks"
        },
        {
            "location": "mp/health",
            "text": " Generate Helidon MP Quickstart project following these Instruction Using the Built-In Health Checks Helidon has a set of built-in health checks that are enabled to report various health check statuses that are commonly used: deadlock detection available disk space available heap memory The following example will demonstrate how to use the built-in health checks. These examples are all executed from the root directory of your project (helidon-quickstart-mp). <markup lang=\"bash\" title=\"Build the application, then run it:\" >mvn package java -jar target/helidon-quickstart-mp.jar <markup lang=\"bash\" title=\"Verify the health endpoint in a new terminal window:\" >curl http://localhost:8080/health <markup lang=\"json\" title=\"JSON response:\" >{ \"status\": \"UP\", \"checks\": [ { \"name\": \"deadlock\", \"status\": \"UP\" }, { \"name\": \"diskSpace\", \"status\": \"UP\", \"data\": { \"free\": \"325.54 GB\", \"freeBytes\": 349543358464, \"percentFree\": \"69.91%\", \"total\": \"465.63 GB\", \"totalBytes\": 499963174912 } }, { \"name\": \"heapMemory\", \"status\": \"UP\", \"data\": { \"free\": \"230.87 MB\", \"freeBytes\": 242085696, \"max\": \"3.56 GB\", \"maxBytes\": 3817865216, \"percentFree\": \"98.90%\", \"total\": \"271.00 MB\", \"totalBytes\": 284164096 } } ] } Custom Liveness Health Checks You can create application-specific custom health checks and integrate them with Helidon using CDI. The following example shows how to add a custom liveness health check. <markup lang=\"java\" title=\"Create a new GreetLivenessCheck class with the following content:\" >@Liveness @ApplicationScoped public class GreetLivenessCheck implements HealthCheck { @Override public HealthCheckResponse call() { return HealthCheckResponse.named(\"LivenessCheck\") .up() .withData(\"time\", System.currentTimeMillis()) .build(); } } Annotation indicating this is a liveness health check. Annotation indicating this is a bean instantiated once per application (in Helidon this means just once per runtime). Build the HealthCheckResponse with status UP and the current time. <markup lang=\"bash\" title=\"Build and run the application, then verify the custom liveness health endpoint:\" >curl http://localhost:8080/health/live <markup lang=\"json\" title=\"JSON response:\" >{ \"status\": \"UP\", \"checks\": [ { \"name\": \"LivenessCheck\", \"status\": \"UP\", \"data\": { \"time\": 1566338255331 } } ] } Full example code is available here . Custom Readiness Health Checks You can add a readiness check to indicate that the application is ready to be used. In this example, the server will wait five seconds before it becomes ready. <markup lang=\"java\" title=\"Create a new GreetReadinessCheck class with the following content:\" >@Readiness @ApplicationScoped public class GreetReadinessCheck implements HealthCheck { private final AtomicLong readyTime = new AtomicLong(0); @Override public HealthCheckResponse call() { return HealthCheckResponse.named(\"ReadinessCheck\") .status(isReady()) .withData(\"time\", readyTime.get()) .build(); } public void onStartUp( @Observes @Initialized(ApplicationScoped.class) Object init) { readyTime.set(System.currentTimeMillis()); } private boolean isReady() { return Duration.ofMillis(System.currentTimeMillis() - readyTime.get()).getSeconds() &gt;= 5; } } Annotation indicating that this is a readiness health check. Build the HealthCheckResponse with status UP after five seconds, else DOWN . Record the time at startup. Become ready after 5 seconds. <markup lang=\"bash\" title=\"Build and run the application. Issue the curl command with -v within five seconds and you will see that the application is not ready:\" >curl -v http://localhost:8080/health/ready <markup title=\"HTTP response status\" >&lt; HTTP/1.1 503 Service Unavailable The HTTP status is 503 since the application is not ready. <markup lang=\"json\" title=\"JSON response body:\" >{ \"status\": \"DOWN\", \"checks\": [ { \"name\": \"ReadinessCheck\", \"status\": \"DOWN\", \"data\": { \"time\": 1566399775700 } } ] } <markup lang=\"bash\" title=\"After five seconds you will see the application is ready:\" >curl -v http://localhost:8080/health/ready <markup title=\"HTTP response status\" >&lt; HTTP/1.1 200 OK The HTTP status is 200 indicating that the application is ready. <markup lang=\"json\" title=\"JSON response body:\" >{ \"status\": \"UP\", \"checks\": [ { \"name\": \"ReadinessCheck\", \"status\": \"UP\", \"data\": { \"time\": 1566399775700 } } ] } Full example code is available here . Custom Startup Health Checks You can add a startup check to indicate whether or not the application has initialized to the point that the other health checks make sense. In this example, the server will wait eight seconds before it declares itself started. <markup lang=\"java\" title=\"Create a new GreetStartedCheck class with the following content:\" >@Startup @ApplicationScoped public class GreetStartedCheck implements HealthCheck { private final AtomicLong readyTime = new AtomicLong(0); @Override public HealthCheckResponse call() { return HealthCheckResponse.named(\"StartedCheck\") .status(isStarted()) .withData(\"time\", readyTime.get()) .build(); } public void onStartUp( @Observes @Initialized(ApplicationScoped.class) Object init) { readyTime.set(System.currentTimeMillis()); } private boolean isStarted() { return Duration.ofMillis(System.currentTimeMillis() - readyTime.get()).getSeconds() &gt;= 8; } } Annotation indicating that this is a startup health check. Build the HealthCheckResponse with status UP after eight seconds, else DOWN . Record the time at startup of Helidon; the application will declare itself as started eight seconds later. Become ready after 5 seconds. <markup lang=\"bash\" title=\"Build and run the application. Issue the curl command with -v within five seconds and you will see that the application has not yet started:\" >curl -v http://localhost:8080/health/started <markup title=\"HTTP response status:\" >&lt; HTTP/1.1 503 Service Unavailable The HTTP status is 503 since the application has not started. <markup lang=\"json\" title=\"JSON response body:\" >{ \"status\": \"DOWN\", \"checks\": [ { \"name\": \"StartedCheck\", \"status\": \"DOWN\", \"data\": { \"time\": 1566399775700 } } ] } <markup lang=\"bash\" title=\"After eight seconds you will see the application has started:\" >curl -v http://localhost:8080/health/started <markup title=\"HTTP response status:\" >&lt; HTTP/1.1 200 OK The HTTP status is 200 indicating that the application is started. <markup lang=\"json\" title=\"JSON response body:\" >{ \"status\": \"UP\", \"checks\": [ { \"name\": \"StartedCheck\", \"status\": \"UP\", \"data\": { \"time\": 1566399775700 } } ] } When using the health check URLs, you can get the following health check data: liveness only - http://localhost:8080/health/live readiness only - http://localhost:8080/health/ready startup checks only - http://localhost:8080/health/started all health check data - http://localhost:8080/health <markup lang=\"bash\" title=\"Get all the health check data, including custom data:\" >curl http://localhost:8080/health <markup lang=\"json\" title=\"JSON response:\" >{ \"status\": \"UP\", \"checks\": [ { \"name\": \"LivenessCheck\", \"status\": \"UP\", \"data\": { \"time\": 1566403431536 } } ] } Full example code is available here . ",
            "title": "Examples"
        },
        {
            "location": "mp/health",
            "text": " Helidon MicroProfile Health JavaDoc Helidon Built-in Checks JavaDoc MicroProfile Health Specification MicroProfile Health on GitHub ",
            "title": "Reference"
        },
        {
            "location": "mp/integrations/hcv",
            "text": " Overview Maven Coordinates Usage Examples Local Testing References ",
            "title": "Contents"
        },
        {
            "location": "mp/integrations/hcv",
            "text": " HashiCorp Vault is a commonly used Vault in many microservices. The APIs are REST-based and Helidon implements them using reactive client. ",
            "title": "Overview"
        },
        {
            "location": "mp/integrations/hcv",
            "text": " To enable HashiCorp Vault add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.vault&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-vault-cdi&lt;/artifactId&gt; &lt;/dependency&gt; The following is a list of maven coordinates of all Vault modules available: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.vault.auths&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-vault-auths-token&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.vault.auths&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-vault-auths-approle&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.vault.auths&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-vault-auths-k8s&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.vault.secrets&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-vault-secrets-kv1&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.vault.secrets&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-vault-secrets-kv2&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.vault.secrets&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-vault-secrets-cubbyhole&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.vault.secrets&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-vault-secrets-transit&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.vault.secrets&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-vault-secrets-database&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.vault.sys&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-vault-sys&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "mp/integrations/hcv",
            "text": " New secret engines and authentication methods can be implemented quite easily, as the integration is based on service providers (using ServiceLoader). This gives us (or you, as the users) the option to add new secret engines and/or authentication methods without adding a plethora of methods to the Vault class. See the following SPIs: <markup lang=\"listing\" >io.helidon.integrations.vault.spi.AuthMethodProvider io.helidon.integrations.vault.spi.SecretsEngineProvider io.helidon.integrations.vault.spi.SysProvider io.helidon.integrations.vault.spi.VaultAuth io.helidon.integrations.vault.spi.InjectionProvider ",
            "title": "Extensibility"
        },
        {
            "location": "mp/integrations/hcv",
            "text": " Vault integration supports the following: Secret Engines : Key/Value version 2, Key/Value version 1, Cubbyhole, PKI, Transit, Database Authentication Methods : Token, Kubernetes (k8s), AppRole Other Sys Operations and Configurations Each of these features is implemented as a separate module, with the Vault class binding them together. In Helidon MP, with injection, this binding is done automatically, and you can simply inject your favorite secret engine. The following classes can be injected into any CDI bean (if appropriate module is on the classpath): Kv2Secrets - Key/Value Version 2 Secrets (versioned secrets, default) Kv1Secrets - Key/Value Version 1 Secrets (un-versioned secrets, legacy) CubbyholeSecrets - Cubbyhole secrets (token bound secrets) DbSecrets - Database secrets (for generating temporary DB credentials) PkiSecrets - PKI secrets (for generating keys and X.509 certificates) TransitSecrets - Transit operations (encryption, signatures, HMAC) AppRoleAuth - AppRole authentication method (management operations) K8sAuth - Kubernetes authentication method (management operations) TokenAuth - Token authentication method (management operations) Sys - System operations (management of Vault - enabling/disabling secret engines and authentication methods) *Rx - reactive counterparts to the classes defined above, usually not recommended in CDI, as it is a blocking environment In addition to these features, Vault itself can be authenticated as follows: Token authentication - token is configured when connecting to Vault vault.address=http://localhost:8200 vault.token=my-token AppRole authentication - AppRole ID and secret ID are configured, integration exchanges these for a temporary token that is used to connect to Vault vault.auth.app-role.role-id=app-role-id vault.auth.app-role.secret-id=app-role-secret-id K8s authentication - the k8s JWT token is discovered on current node and used to obtain a temporary token that is used to connect to Vault vault.auth.k8s.token-role=my-role The token role must be configured in Vault Extensibility New secret engines and authentication methods can be implemented quite easily, as the integration is based on service providers (using ServiceLoader). This gives us (or you, as the users) the option to add new secret engines and/or authentication methods without adding a plethora of methods to the Vault class. See the following SPIs: <markup lang=\"listing\" >io.helidon.integrations.vault.spi.AuthMethodProvider io.helidon.integrations.vault.spi.SecretsEngineProvider io.helidon.integrations.vault.spi.SysProvider io.helidon.integrations.vault.spi.VaultAuth io.helidon.integrations.vault.spi.InjectionProvider ",
            "title": "Usage"
        },
        {
            "location": "mp/integrations/hcv",
            "text": " Cubbyhole example: <markup lang=\"java\" >@Path(\"/cubbyhole\") public class CubbyholeResource { private final CubbyholeSecrets secrets; @Inject CubbyholeResource(CubbyholeSecrets secrets) { this.secrets = secrets; } @POST @Path(\"/secrets/{path: .*}\") public Response createSecret(@PathParam(\"path\") String path, String secret) { CreateCubbyhole.Response response = secrets.create(path, Map.of(\"secret\", secret)); return Response.ok() .entity(\"Created secret on path: \" + path + \", key is \\\"secret\\\", original status: \" + response.status().code()) .build(); } @DELETE @Path(\"/secrets/{path: .*}\") public Response deleteSecret(@PathParam(\"path\") String path) { DeleteCubbyhole.Response response = secrets.delete(path); return Response.ok() .entity(\"Deleted secret on path: \" + path + \". Original status: \" + response.status().code()) .build(); } @GET @Path(\"/secrets/{path: .*}\") public Response getSecret(@PathParam(\"path\") String path) { Optional&lt;Secret&gt; secret = secrets.get(path); if (secret.isPresent()) { Secret kv1Secret = secret.get(); return Response.ok() .entity(\"Secret: \" + secret.get().values().toString()) .build(); } else { return Response.status(Response.Status.NOT_FOUND).build(); } } } Create a secret from request entity, the name of the value is {@code secret}. Delete the secret on a specified path. Get the secret on a specified path. ",
            "title": "Cubbyhole secrets"
        },
        {
            "location": "mp/integrations/hcv",
            "text": " Key/Value version 1 secrets engine operations: <markup lang=\"java\" >@Path(\"/kv1\") public class Kv1Resource { private final Sys sys; private final Kv1Secrets secrets; @Inject Kv1Resource(Sys sys, Kv1Secrets secrets) { this.sys = sys; this.secrets = secrets; } @Path(\"/engine\") @GET public Response enableEngine() { EnableEngine.Response response = sys.enableEngine(Kv1SecretsRx.ENGINE); return Response.ok() .entity(\"Key/value version 1 secret engine is now enabled. Original status: \" + response.status().code()) .build(); } @Path(\"/engine\") @DELETE public Response disableEngine() { DisableEngine.Response response = sys.disableEngine(Kv1SecretsRx.ENGINE); return Response.ok() .entity(\"Key/value version 1 secret engine is now disabled. Original status: \" + response.status().code()) .build(); } @POST @Path(\"/secrets/{path: .*}\") public Response createSecret(@PathParam(\"path\") String path, String secret) { CreateKv&lt;1&gt;Response response = secrets.create(path, Map.of(\"secret\", secret)); return Response.ok() .entity(\"Created secret on path: \" + path + \", key is \\\"secret\\\", original status: \" + response.status().code()) .build(); } @DELETE @Path(\"/secrets/{path: .*}\") public Response deleteSecret(@PathParam(\"path\") String path) { DeleteKv&lt;1&gt;Response response = secrets.delete(path); return Response.ok() .entity(\"Deleted secret on path: \" + path + \". Original status: \" + response.status().code()) .build(); } @GET @Path(\"/secrets/{path: .*}\") public Response getSecret(@PathParam(\"path\") String path) { Optional&lt;Secret&gt; secret = secrets.get(path); if (secret.isPresent()) { Secret kv1Secret = secret.get(); return Response.ok() .entity(\"Secret: \" + secret.get().values().toString()) .build(); } else { return Response.status(Response.Status.NOT_FOUND).build(); } } } Enable the secrets engine on the default path. Disable the secrets engine on the default path. Create a secret from request entity, the name of the value is secret . Delete the secret on a specified path. Get the secret on a specified path. ",
            "title": "KV1 secrets"
        },
        {
            "location": "mp/integrations/hcv",
            "text": " Key/Value version 2 secrets engine operations: <markup lang=\"java\" >@Path(\"/kv2\") public class Kv2Resource { private final Kv2Secrets secrets; @Inject Kv2Resource(@VaultName(\"app-role\") @VaultPath(\"custom\") Kv2Secrets secrets) { this.secrets = secrets; } @POST @Path(\"/secrets/{path: .*}\") public Response createSecret(@PathParam(\"path\") String path, String secret) { CreateKv&lt;2&gt;Response response = secrets.create(path, Map.of(\"secret\", secret)); return Response.ok() .entity(\"Created secret on path: \" + path + \", key is \\\"secret\\\", original status: \" + response.status().code()) .build(); } @DELETE @Path(\"/secrets/{path: .*}\") public Response deleteSecret(@PathParam(\"path\") String path) { DeleteAllKv&lt;2&gt;Response response = secrets.deleteAll(path); return Response.ok() .entity(\"Deleted secret on path: \" + path + \". Original status: \" + response.status().code()) .build(); } @GET @Path(\"/secrets/{path: .*}\") public Response getSecret(@PathParam(\"path\") String path) { Optional&lt;Kv2Secret&gt; secret = secrets.get(path); if (secret.isPresent()) { Kv2Secret kv2Secret = secret.get(); return Response.ok() .entity(\"Version \" + kv2Secret.metadata().version() + \", secret: \" + kv2Secret.values().toString()) .build(); } else { return Response.status(Response.Status.NOT_FOUND).build(); } } } Create a secret from request entity, the name of the value is secret . Delete the secret on a specified path. Get the secret on a specified path. ",
            "title": "KV2 secrets"
        },
        {
            "location": "mp/integrations/hcv",
            "text": " Transit secrets engine operations: <markup lang=\"java\" >@Path(\"/transit\") public class TransitResource { private static final String ENCRYPTION_KEY = \"encryption-key\"; private static final String SIGNATURE_KEY = \"signature-key\"; private final Sys sys; private final TransitSecrets secrets; @Inject TransitResource(Sys sys, TransitSecrets secrets) { this.sys = sys; this.secrets = secrets; } @Path(\"/engine\") @GET public Response enableEngine() { EnableEngine.Response response = sys.enableEngine(TransitSecretsRx.ENGINE); return Response.ok() .entity(\"Transit secret engine is now enabled. Original status: \" + response.status().code()) .build(); } @Path(\"/engine\") @DELETE public Response disableEngine() { DisableEngine.Response response = sys.disableEngine(TransitSecretsRx.ENGINE); return Response.ok() .entity(\"Transit secret engine is now disabled. Original status: \" + response.status()) .build(); } @Path(\"/keys\") @GET public Response createKeys() { secrets.createKey(CreateKey.Request.builder() .name(ENCRYPTION_KEY)); secrets.createKey(CreateKey.Request.builder() .name(SIGNATURE_KEY) .type(\"rsa-2048\")); return Response.ok() .entity(\"Created encryption (and HMAC), and signature keys\") .build(); } @Path(\"/keys\") @DELETE public Response deleteKeys() { // we must first enable deletion of the key (by default it cannot be deleted) secrets.updateKeyConfig(UpdateKeyConfig.Request.builder() .name(ENCRYPTION_KEY) .allowDeletion(true)); secrets.updateKeyConfig(UpdateKeyConfig.Request.builder() .name(SIGNATURE_KEY) .allowDeletion(true)); secrets.deleteKey(DeleteKey.Request.create(ENCRYPTION_KEY)); secrets.deleteKey(DeleteKey.Request.create(SIGNATURE_KEY)); return Response.ok() .entity(\"Deleted encryption (and HMAC), and signature keys\") .build(); } @Path(\"/encrypt/{secret: .*}\") @GET public String encryptSecret(@PathParam(\"secret\") String secret) { return secrets.encrypt(Encrypt.Request.builder() .encryptionKeyName(ENCRYPTION_KEY) .data(Base64Value.create(secret))) .encrypted() .cipherText(); } @Path(\"/decrypt/{cipherText: .*}\") @GET public String decryptSecret(@PathParam(\"cipherText\") String cipherText) { return secrets.decrypt(Decrypt.Request.builder() .encryptionKeyName(ENCRYPTION_KEY) .cipherText(cipherText)) .decrypted() .toDecodedString(); } @Path(\"/hmac/{text}\") @GET public String hmac(@PathParam(\"text\") String text) { return secrets.hmac(Hmac.Request.builder() .hmacKeyName(ENCRYPTION_KEY) .data(Base64Value.create(text))) .hmac(); } @Path(\"/sign/{text}\") @GET public String sign(@PathParam(\"text\") String text) { return secrets.sign(Sign.Request.builder() .signatureKeyName(SIGNATURE_KEY) .data(Base64Value.create(text))) .signature(); } @Path(\"/verify/hmac/{secret}/{hmac: .*}\") @GET public String verifyHmac(@PathParam(\"secret\") String secret, @PathParam(\"hmac\") String hmac) { boolean isValid = secrets.verify(Verify.Request.builder() .digestKeyName(ENCRYPTION_KEY) .data(Base64Value.create(secret)) .hmac(hmac)) .isValid(); return (isValid ? \"HMAC Valid\" : \"HMAC Invalid\"); } @Path(\"/verify/sign/{secret}/{signature: .*}\") @GET public String verifySignature(@PathParam(\"secret\") String secret, @PathParam(\"signature\") String signature) { boolean isValid = secrets.verify(Verify.Request.builder() .digestKeyName(SIGNATURE_KEY) .data(Base64Value.create(secret)) .signature(signature)) .isValid(); return (isValid ? \"Signature Valid\" : \"Signature Invalid\"); } } Enable the secrets engine on the default path. Disable the secrets engine on the default path. Create the encrypting and signature keys. Delete the encryption and signature keys. Encrypt a secret. Decrypt a secret. Create an HMAC for text. Create a signature for text. Verify HMAC. Verify signature. ",
            "title": "Transit secrets"
        },
        {
            "location": "mp/integrations/hcv",
            "text": " The following example shows usage of Vault to encrypt a secret using the default Vault configuration (in a JAX-RS resource): <markup lang=\"java\" >@Path(\"/transit\") class TransitResource { private final TransitSecrets secrets; @Inject TransitResource(TransitSecrets secrets) { this.secrets = secrets; } @Path(\"/encrypt/{secret: .*}\") @GET public String encrypt(@PathParam(\"secret\") String secret) { return secrets.encrypt(Encrypt.Request.builder() .encryptionKeyName(ENCRYPTION_KEY) .data(Base64Value.create(secret))) .encrypted() .cipherText(); } } Cubbyhole secrets Cubbyhole example: <markup lang=\"java\" >@Path(\"/cubbyhole\") public class CubbyholeResource { private final CubbyholeSecrets secrets; @Inject CubbyholeResource(CubbyholeSecrets secrets) { this.secrets = secrets; } @POST @Path(\"/secrets/{path: .*}\") public Response createSecret(@PathParam(\"path\") String path, String secret) { CreateCubbyhole.Response response = secrets.create(path, Map.of(\"secret\", secret)); return Response.ok() .entity(\"Created secret on path: \" + path + \", key is \\\"secret\\\", original status: \" + response.status().code()) .build(); } @DELETE @Path(\"/secrets/{path: .*}\") public Response deleteSecret(@PathParam(\"path\") String path) { DeleteCubbyhole.Response response = secrets.delete(path); return Response.ok() .entity(\"Deleted secret on path: \" + path + \". Original status: \" + response.status().code()) .build(); } @GET @Path(\"/secrets/{path: .*}\") public Response getSecret(@PathParam(\"path\") String path) { Optional&lt;Secret&gt; secret = secrets.get(path); if (secret.isPresent()) { Secret kv1Secret = secret.get(); return Response.ok() .entity(\"Secret: \" + secret.get().values().toString()) .build(); } else { return Response.status(Response.Status.NOT_FOUND).build(); } } } Create a secret from request entity, the name of the value is {@code secret}. Delete the secret on a specified path. Get the secret on a specified path. KV1 secrets Key/Value version 1 secrets engine operations: <markup lang=\"java\" >@Path(\"/kv1\") public class Kv1Resource { private final Sys sys; private final Kv1Secrets secrets; @Inject Kv1Resource(Sys sys, Kv1Secrets secrets) { this.sys = sys; this.secrets = secrets; } @Path(\"/engine\") @GET public Response enableEngine() { EnableEngine.Response response = sys.enableEngine(Kv1SecretsRx.ENGINE); return Response.ok() .entity(\"Key/value version 1 secret engine is now enabled. Original status: \" + response.status().code()) .build(); } @Path(\"/engine\") @DELETE public Response disableEngine() { DisableEngine.Response response = sys.disableEngine(Kv1SecretsRx.ENGINE); return Response.ok() .entity(\"Key/value version 1 secret engine is now disabled. Original status: \" + response.status().code()) .build(); } @POST @Path(\"/secrets/{path: .*}\") public Response createSecret(@PathParam(\"path\") String path, String secret) { CreateKv&lt;1&gt;Response response = secrets.create(path, Map.of(\"secret\", secret)); return Response.ok() .entity(\"Created secret on path: \" + path + \", key is \\\"secret\\\", original status: \" + response.status().code()) .build(); } @DELETE @Path(\"/secrets/{path: .*}\") public Response deleteSecret(@PathParam(\"path\") String path) { DeleteKv&lt;1&gt;Response response = secrets.delete(path); return Response.ok() .entity(\"Deleted secret on path: \" + path + \". Original status: \" + response.status().code()) .build(); } @GET @Path(\"/secrets/{path: .*}\") public Response getSecret(@PathParam(\"path\") String path) { Optional&lt;Secret&gt; secret = secrets.get(path); if (secret.isPresent()) { Secret kv1Secret = secret.get(); return Response.ok() .entity(\"Secret: \" + secret.get().values().toString()) .build(); } else { return Response.status(Response.Status.NOT_FOUND).build(); } } } Enable the secrets engine on the default path. Disable the secrets engine on the default path. Create a secret from request entity, the name of the value is secret . Delete the secret on a specified path. Get the secret on a specified path. KV2 secrets Key/Value version 2 secrets engine operations: <markup lang=\"java\" >@Path(\"/kv2\") public class Kv2Resource { private final Kv2Secrets secrets; @Inject Kv2Resource(@VaultName(\"app-role\") @VaultPath(\"custom\") Kv2Secrets secrets) { this.secrets = secrets; } @POST @Path(\"/secrets/{path: .*}\") public Response createSecret(@PathParam(\"path\") String path, String secret) { CreateKv&lt;2&gt;Response response = secrets.create(path, Map.of(\"secret\", secret)); return Response.ok() .entity(\"Created secret on path: \" + path + \", key is \\\"secret\\\", original status: \" + response.status().code()) .build(); } @DELETE @Path(\"/secrets/{path: .*}\") public Response deleteSecret(@PathParam(\"path\") String path) { DeleteAllKv&lt;2&gt;Response response = secrets.deleteAll(path); return Response.ok() .entity(\"Deleted secret on path: \" + path + \". Original status: \" + response.status().code()) .build(); } @GET @Path(\"/secrets/{path: .*}\") public Response getSecret(@PathParam(\"path\") String path) { Optional&lt;Kv2Secret&gt; secret = secrets.get(path); if (secret.isPresent()) { Kv2Secret kv2Secret = secret.get(); return Response.ok() .entity(\"Version \" + kv2Secret.metadata().version() + \", secret: \" + kv2Secret.values().toString()) .build(); } else { return Response.status(Response.Status.NOT_FOUND).build(); } } } Create a secret from request entity, the name of the value is secret . Delete the secret on a specified path. Get the secret on a specified path. Transit secrets Transit secrets engine operations: <markup lang=\"java\" >@Path(\"/transit\") public class TransitResource { private static final String ENCRYPTION_KEY = \"encryption-key\"; private static final String SIGNATURE_KEY = \"signature-key\"; private final Sys sys; private final TransitSecrets secrets; @Inject TransitResource(Sys sys, TransitSecrets secrets) { this.sys = sys; this.secrets = secrets; } @Path(\"/engine\") @GET public Response enableEngine() { EnableEngine.Response response = sys.enableEngine(TransitSecretsRx.ENGINE); return Response.ok() .entity(\"Transit secret engine is now enabled. Original status: \" + response.status().code()) .build(); } @Path(\"/engine\") @DELETE public Response disableEngine() { DisableEngine.Response response = sys.disableEngine(TransitSecretsRx.ENGINE); return Response.ok() .entity(\"Transit secret engine is now disabled. Original status: \" + response.status()) .build(); } @Path(\"/keys\") @GET public Response createKeys() { secrets.createKey(CreateKey.Request.builder() .name(ENCRYPTION_KEY)); secrets.createKey(CreateKey.Request.builder() .name(SIGNATURE_KEY) .type(\"rsa-2048\")); return Response.ok() .entity(\"Created encryption (and HMAC), and signature keys\") .build(); } @Path(\"/keys\") @DELETE public Response deleteKeys() { // we must first enable deletion of the key (by default it cannot be deleted) secrets.updateKeyConfig(UpdateKeyConfig.Request.builder() .name(ENCRYPTION_KEY) .allowDeletion(true)); secrets.updateKeyConfig(UpdateKeyConfig.Request.builder() .name(SIGNATURE_KEY) .allowDeletion(true)); secrets.deleteKey(DeleteKey.Request.create(ENCRYPTION_KEY)); secrets.deleteKey(DeleteKey.Request.create(SIGNATURE_KEY)); return Response.ok() .entity(\"Deleted encryption (and HMAC), and signature keys\") .build(); } @Path(\"/encrypt/{secret: .*}\") @GET public String encryptSecret(@PathParam(\"secret\") String secret) { return secrets.encrypt(Encrypt.Request.builder() .encryptionKeyName(ENCRYPTION_KEY) .data(Base64Value.create(secret))) .encrypted() .cipherText(); } @Path(\"/decrypt/{cipherText: .*}\") @GET public String decryptSecret(@PathParam(\"cipherText\") String cipherText) { return secrets.decrypt(Decrypt.Request.builder() .encryptionKeyName(ENCRYPTION_KEY) .cipherText(cipherText)) .decrypted() .toDecodedString(); } @Path(\"/hmac/{text}\") @GET public String hmac(@PathParam(\"text\") String text) { return secrets.hmac(Hmac.Request.builder() .hmacKeyName(ENCRYPTION_KEY) .data(Base64Value.create(text))) .hmac(); } @Path(\"/sign/{text}\") @GET public String sign(@PathParam(\"text\") String text) { return secrets.sign(Sign.Request.builder() .signatureKeyName(SIGNATURE_KEY) .data(Base64Value.create(text))) .signature(); } @Path(\"/verify/hmac/{secret}/{hmac: .*}\") @GET public String verifyHmac(@PathParam(\"secret\") String secret, @PathParam(\"hmac\") String hmac) { boolean isValid = secrets.verify(Verify.Request.builder() .digestKeyName(ENCRYPTION_KEY) .data(Base64Value.create(secret)) .hmac(hmac)) .isValid(); return (isValid ? \"HMAC Valid\" : \"HMAC Invalid\"); } @Path(\"/verify/sign/{secret}/{signature: .*}\") @GET public String verifySignature(@PathParam(\"secret\") String secret, @PathParam(\"signature\") String signature) { boolean isValid = secrets.verify(Verify.Request.builder() .digestKeyName(SIGNATURE_KEY) .data(Base64Value.create(secret)) .signature(signature)) .isValid(); return (isValid ? \"Signature Valid\" : \"Signature Invalid\"); } } Enable the secrets engine on the default path. Disable the secrets engine on the default path. Create the encrypting and signature keys. Delete the encryption and signature keys. Encrypt a secret. Decrypt a secret. Create an HMAC for text. Create a signature for text. Verify HMAC. Verify signature. ",
            "title": "Examples"
        },
        {
            "location": "mp/integrations/hcv",
            "text": " Vault is available as a docker image, so to test locally, you can simply: <markup lang=\"bash\" >docker run -e VAULT_DEV_ROOT_TOKEN_ID=my-token -d --name=vault -p8200:8200 vault This will create a Vault docker image, run it in background and open it on localhost:8200 with a custom root token my-token, using name vault. This is of course only suitable for local testing, as the root token has too many rights, but it can be easily used with the examples below. ",
            "title": "Local Testing"
        },
        {
            "location": "mp/integrations/hcv",
            "text": " Hashicorp Vault Usage Examples ",
            "title": "References"
        },
        {
            "location": "mp/integrations/jedis",
            "text": " Overview Maven Coordinates Usage Configuration References ",
            "title": "Contents"
        },
        {
            "location": "mp/integrations/jedis",
            "text": " Jedis is a Java client for Redis . This CDI portable extension provides support for injecting Jedis clients in your Helidon MicroProfile applications. ",
            "title": "Overview"
        },
        {
            "location": "mp/integrations/jedis",
            "text": " To enable Jedis add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.cdi&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-cdi-jedis&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "mp/integrations/jedis",
            "text": " After you have added the above dependency to your project you can inject a Jedis client in your application. The following examples show how to create and inject a Jedis pool named orders in your application code. <markup lang=\"java\" title=\"Field-injection example\" > @Inject @Named(\"orders\") private JedisPool ordersPool; <markup lang=\"java\" title=\"Constructor-injection example\" > private final JedisPool ordersPool; @Inject public YourConstructor(@Named(\"orders\") JedisPool pool) { super(); this.ordersPool = pool; } Helidon implements this injection point by creating a JedisPool object in the application scope . ",
            "title": "Usage"
        },
        {
            "location": "mp/integrations/jedis",
            "text": " You can configure the object using MicroProfile config . For example, the Jedis pool created above can be configured as follows: <markup lang=\"properties\" title=\"META-INF/microprofile-config.properties\" >redis.clients.jedis.JedisPool.orders.port=6379 The Jedis client can be configured using the following properties. Property names that start with redis.clients.jedis.JedisPoolConfig.instanceName. are parsed, and the remaining portion of each name is treated as a Java Bean property of JedisPoolConfig . Because the JedisPoolConfig class inherits from Apache commons-pool&#8217;s GenericObjectPoolConfig class and from Apache commons-pool&#8217;s BaseObjectPoolConfig class, those writable Java Bean properties are available as well. Accordingly, the JedisPoolConfig Java Bean properties that can be set are as follows, where instanceName should be replaced with the actual name used in application code: <div class=\"table__overflow elevation-1 flex md7 \"> redis.clients.jedis.JedisPoolConfig.instanceName.blockWhenExhausted redis.clients.jedis.JedisPoolConfig.instanceName.evictionPolicyClassName redis.clients.jedis.JedisPoolConfig.instanceName.fairness redis.clients.jedis.JedisPoolConfig.instanceName.jmxEnabled redis.clients.jedis.JedisPoolConfig.instanceName.jmxNameBase redis.clients.jedis.JedisPoolConfig.instanceName.jmxNamePrefix redis.clients.jedis.JedisPoolConfig.instanceName.lifo redis.clients.jedis.JedisPoolConfig.instanceName.maxIdle redis.clients.jedis.JedisPoolConfig.instanceName.maxTotal redis.clients.jedis.JedisPoolConfig.instanceName.maxWaitMillis redis.clients.jedis.JedisPoolConfig.instanceName.minEvictableTimeMillis redis.clients.jedis.JedisPoolConfig.instanceName.minIdle redis.clients.jedis.JedisPoolConfig.instanceName.numTestsPerEvictionRun redis.clients.jedis.JedisPoolConfig.instanceName.softMinEvictableIdleTimeMillis redis.clients.jedis.JedisPoolConfig.instanceName.testOnBorrow redis.clients.jedis.JedisPoolConfig.instanceName.testOnCreate redis.clients.jedis.JedisPoolConfig.instanceName.testOnReturn redis.clients.jedis.JedisPoolConfig.instanceName.testWhileIdle redis.clients.jedis.JedisPoolConfig.instanceName.timeBetweenEvictionRunsMillis Any documentation for these properties that exists may be found in the javadocs for the JedisPoolConfig , GenericObjectPoolConfig and BaseObjectPoolConfig classes. Property names that start with redis.clients.jedis.JedisPool.instanceName. are parsed, and the remaining portion of each name is treated as a Java Bean property of JedisPool , or as a primitive value accepted by its constructor . Because the JedisPool class inherits from the Pool class, its writable Java Bean properties are available as well. Accordingly, the JedisPool properties that can be set are as follows, where instanceName should be replaced with the actual named used in application code: <div class=\"table__overflow elevation-1 flex md7 \"> redis.clients.jedis.JedisPool.instanceName.clientName redis.clients.jedis.JedisPool.instanceName.connectionTimeout redis.clients.jedis.JedisPool.instanceName.database redis.clients.jedis.JedisPool.instanceName.host redis.clients.jedis.JedisPool.instanceName.password redis.clients.jedis.JedisPool.instanceName.port redis.clients.jedis.JedisPool.instanceName.socketTimeout redis.clients.jedis.JedisPool.instanceName.ssl Any documentation for these properties that exists may be found in the javadocs for the JedisPool and Pool classes. Injection without a @Named annotation is also possible: <markup lang=\"java\" > @Inject private JedisPool ordersPool; In this case, the properties for JedisPoolConfig and JedisPool that can be set will start with redis.clients.jedis.JedisPoolConfig.default and redis.clients.jedis.JedisPool.default respectively. ",
            "title": "Configuration"
        },
        {
            "location": "mp/integrations/jedis",
            "text": " Helidon Jedis Example Jedis Javadoc Jedis Redis ",
            "title": "References"
        },
        {
            "location": "mp/integrations/neo4j",
            "text": " Overview Maven Coordinates Usage Configuration Examples Additional Information References ",
            "title": "Contents"
        },
        {
            "location": "mp/integrations/neo4j",
            "text": " Neo4j is a graph database management system developed by Neo4j, Inc. It is an ACID-compliant transactional database with native graph storage and processing. Neo4j is available in a GPL3-licensed open-source “community edition”. ",
            "title": "Overview"
        },
        {
            "location": "mp/integrations/neo4j",
            "text": " To enable Neo4j add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.neo4j&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-neo4j&lt;/artifactId&gt; &lt;/dependency&gt; Check Neo4j Metrics propagation and Neo4j Health Checks for additional dependencies for Neo4j Metrics and Health Checks integration. ",
            "title": "Maven Coordinates"
        },
        {
            "location": "mp/integrations/neo4j",
            "text": " The support for Neo4j is implemented in Neo4j driver level. Just add the dependency, add configuration in microprofile-config.properties file and Neo4j driver will be configured by Helidon and can be injected using CDI. To implement Neo4j, you must first provide the connection properties as shown below: <markup lang=\"properties\" ># Neo4j settings neo4j.uri=bolt://localhost:7687 neo4j.authentication.username=neo4j neo4j.authentication.password: secret neo4j.pool.metricsEnabled: true Then just inject the driver: <markup lang=\"java\" >@Inject public MovieRepository(Driver driver) { this.driver = driver; } The driver can be used according to the Neo4j documentation . ",
            "title": "Usage"
        },
        {
            "location": "mp/integrations/neo4j",
            "text": " MicroProfile configuration options: key type default value description mp.jwt.verify.publickey string &#160; The property allows the Public Verification Key text itself to be supplied as a string. authentication.username string &#160; Neo4j authentication user name authentication.password string &#160; Neo4j authentication password authentication.enabled boolean TRUE If Neo4j authentication is enabled encrypted boolean FALSE If Neo4j encryption is enabled pool.metricsEnabled boolean FALSE If Neo4J metrics is enabled pool.logLeakedSessions boolean &#160; Log leaking sessions pool.maxConnectionPoolSize string &#160; Maximum connection pool size pool.idleTimeBeforeConnectionTest string &#160; Idle time before connection test pool.maxConnectionLifetime string &#160; Connection lifetime in seconds pool.connectionAcquisitionTimeout string &#160; Connection Acquisition Timeout trustsettings.trustStrategy string &#160; Trust Strategy: Trust All certificates, TRUST_ALL_CERTIFICATES , Trust custom certificates - TRUST_CUSTOM_CA_SIGNED_CERTIFICATES , Trust system CA - TRUST_SYSTEM_CA_SIGNED_CERTIFICATES trustsettings.certificate string &#160; Path to trusted certificate trustsettings.hostnameVerificationEnabled string FALSE If hostname verification is enabled. ",
            "title": "Configuration"
        },
        {
            "location": "mp/integrations/neo4j",
            "text": " This example implements a simple Neo4j REST service using MicroProfile. For this example a working Neo4j database is required. The Neo4j Movie database is used for this example. Bring up a Neo4j instance via Docker <markup lang=\"bash\" >docker run --publish=7474:7474 --publish=7687:7687 -e 'NEO4J_AUTH=neo4j/secret' neo4j:latest Go to the Neo4j browser and play the first step of the movies graph: :play movies Now go to the pom.xml and add the following dependencies: <markup lang=\"xml\" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.neo4j&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-neo4j&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.neo4j&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-neo4j-metrics&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.neo4j&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-neo4j-health&lt;/artifactId&gt; &lt;/dependency&gt; Next add the connection configuration properties for Neo4j: <markup lang=\"properties\" ># Neo4j settings neo4j.uri=bolt://localhost:7687 neo4j.authentication.username=neo4j neo4j.authentication.password: secret neo4j.pool.metricsEnabled: true # Enable the optional MicroProfile Metrics REST.request metrics metrics.rest-request.enabled=true This includes both connection information and enables Neo4j metrics propagation. Finally, we are able to inject and use the Neo4j driver. <markup lang=\"java\" >@ApplicationScoped public class MovieRepository { private final Driver driver; @Inject public MovieRepository(Driver driver) { this.driver = driver; } public List&lt;Movie&gt; findAll() { try (var session = driver.session()) { var query = \"\" + \"match (m:Movie) \" + \"match (m) &lt;- [:DIRECTED] - (d:Person) \" + \"match (m) &lt;- [r:ACTED_IN] - (a:Person) \" + \"return m, collect(d) as directors, collect({name:a.name, roles: r.roles}) as actors\"; return session.readTransaction(tx -&gt; tx.run(query).list(r -&gt; { var movieNode = r.get(\"m\").asNode(); var directors = r.get(\"directors\").asList(v -&gt; { var personNode = v.asNode(); return new Person(personNode.get(\"born\").asInt(), personNode.get(\"name\").asString()); }); var actors = r.get(\"actors\").asList(v -&gt; { return new Actor(v.get(\"name\").asString(), v.get(\"roles\").asList(Value::asString)); }); var m = new Movie(movieNode.get(\"title\").asString(), movieNode.get(\"tagline\").asString()); m.setReleased(movieNode.get(\"released\").asInt()); m.setDirectorss(directors); m.setActors(actors); return m; })); } } } Neo4j driver constructor injection Use of Neo4j driver to extract all Movies Movies can now be returned as JSON objects: <markup lang=\"java\" >@GET @Produces(MediaType.APPLICATION_JSON) public List&lt;Movie&gt; getAllMovies() { return movieRepository.findAll(); } Now build and run with JDK17+ <markup lang=\"bash\" >mvn package java -jar target/helidon-examples-integration-neo4j-mp.jar Exercise the application: <markup lang=\"bash\" >curl -X GET http://localhost:8080/movies {. . .} # Try health and metrics curl -s -X GET http://localhost:8080/health {\"outcome\":\"UP\",... . . . # Prometheus Format curl -s -X GET http://localhost:8080/metrics # TYPE base:gc_g1_young_generation_count gauge . . . # JSON Format curl -H 'Accept: application/json' -X GET http://localhost:8080/metrics {\"base\":... . . . Full example code is available in Helidon GitHub Repository . ",
            "title": "Examples"
        },
        {
            "location": "mp/integrations/neo4j",
            "text": " Neo4j metrics can be propagated to the user as MicroProfile metrics. This is implemented in a separate Maven module. Just add <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.neo4j&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-neo4j-metrics&lt;/artifactId&gt; &lt;/dependency&gt; Works with Neo4j Integration main dependency described in Maven Coordinates . To enable metrics in Neo4j, add the following property to microprofile-config.properties : <markup lang=\"properties\" >neo4j.pool.metricsEnabled=true By applying these two actions, Neo4j metrics will be automatically added to the output of the /metrics endpoint. ",
            "title": "Neo4j Metrics propagation"
        },
        {
            "location": "mp/integrations/neo4j",
            "text": " If your application is highly dependent on Neo4j database, health and liveness checks are essential for this application to work correctly. MicroProfile Health checks for Neo4j are implemented in a separate Maven module: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.neo4j&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-neo4j-health&lt;/artifactId&gt; &lt;/dependency&gt; Works with Neo4j Integration main dependency described in Maven Coordinates . Health checks for Neo4j will be included in /health endpoint output. ",
            "title": "Neo4j Health Checks"
        },
        {
            "location": "mp/integrations/neo4j",
            "text": " Neo4j Metrics propagation Neo4j metrics can be propagated to the user as MicroProfile metrics. This is implemented in a separate Maven module. Just add <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.neo4j&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-neo4j-metrics&lt;/artifactId&gt; &lt;/dependency&gt; Works with Neo4j Integration main dependency described in Maven Coordinates . To enable metrics in Neo4j, add the following property to microprofile-config.properties : <markup lang=\"properties\" >neo4j.pool.metricsEnabled=true By applying these two actions, Neo4j metrics will be automatically added to the output of the /metrics endpoint. Neo4j Health Checks If your application is highly dependent on Neo4j database, health and liveness checks are essential for this application to work correctly. MicroProfile Health checks for Neo4j are implemented in a separate Maven module: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.neo4j&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-neo4j-health&lt;/artifactId&gt; &lt;/dependency&gt; Works with Neo4j Integration main dependency described in Maven Coordinates . Health checks for Neo4j will be included in /health endpoint output. ",
            "title": "Additional Information"
        },
        {
            "location": "mp/integrations/neo4j",
            "text": " Neo4j official website Neo4j Java developer guide ",
            "title": "References"
        },
        {
            "location": "mp/integrations/oci",
            "text": " Overview Maven Coordinates Usage Examples References ",
            "title": "Contents"
        },
        {
            "location": "mp/integrations/oci",
            "text": " Helidon MP OCI Integration provides easy access to Oracle Cloud Infrastructure using the OCI Java SDK. OCI SDK uses JAX-RS Client 2.1.6 (javax package names), which makes it incompatible with Helidon 3 applications and any application that uses JAX-RS 3 (jakarta package naming). See Resolving compatibility issue with OCI SDK for detailed information on how to work around this issue. ",
            "title": "Overview"
        },
        {
            "location": "mp/integrations/oci",
            "text": " To enable OCI Integration add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.oci.sdk&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-oci-sdk-cdi&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "mp/integrations/oci",
            "text": " When you inject an OCI SDK Client object, the Helidon OCI SDK extension configures and constructs the object for you. The configuration primarily consists of initializing an OCI AuthenticationDetailsProvider . By default, the extension will examine your environment and select the best AuthenticationDetailsProvider and configure it for you. This means if your environment is already set up to work with the OCI SDK or the OCI command line, then it is very likely you do not need to do any additional configuration of the extension. Just add it as a dependency, and it will self-configure. If for some reason you require full control over the OCI configuration you have that as well. For more information concerning the extension and its configuration and authentication options see the OciExtension javadocs. In particular the oci.auth-strategies property lets you control which AuthenticationDetailsProvider will be used. ",
            "title": "Configuring the Helidon OCI SDK Extension"
        },
        {
            "location": "mp/integrations/oci",
            "text": " Since the Helidon OCI SDK extension supports injecting any OCI client from the OCI SDK, you can use it to access any OCI service supported by the OCI SDK. In addition to adding the Helidon OCI SDK Extension dependency (as described above) you will need to add dependencies for the specific ODI SDK clients you will use. You will also need to configure your environment to authenticate with OCI. It is recommended that you do this first, and verify your configuration by using the OCI CLI to access the service. ",
            "title": "Accessing OCI Services"
        },
        {
            "location": "mp/integrations/oci",
            "text": " When added to your application Helidon OCI SDK CDI portable extension provides support for injecting Oracle Cloud Infrastructure SDK Clients in your Helidon MicroProfile application. The extension also handles authenticating with OCI by automatically picking up OCI credentials from your environment. Configuring the Helidon OCI SDK Extension When you inject an OCI SDK Client object, the Helidon OCI SDK extension configures and constructs the object for you. The configuration primarily consists of initializing an OCI AuthenticationDetailsProvider . By default, the extension will examine your environment and select the best AuthenticationDetailsProvider and configure it for you. This means if your environment is already set up to work with the OCI SDK or the OCI command line, then it is very likely you do not need to do any additional configuration of the extension. Just add it as a dependency, and it will self-configure. If for some reason you require full control over the OCI configuration you have that as well. For more information concerning the extension and its configuration and authentication options see the OciExtension javadocs. In particular the oci.auth-strategies property lets you control which AuthenticationDetailsProvider will be used. Accessing OCI Services Since the Helidon OCI SDK extension supports injecting any OCI client from the OCI SDK, you can use it to access any OCI service supported by the OCI SDK. In addition to adding the Helidon OCI SDK Extension dependency (as described above) you will need to add dependencies for the specific ODI SDK clients you will use. You will also need to configure your environment to authenticate with OCI. It is recommended that you do this first, and verify your configuration by using the OCI CLI to access the service. ",
            "title": "Usage"
        },
        {
            "location": "mp/integrations/oci",
            "text": " Now you can inject OCI SDK Clients. <markup lang=\"java\" title=\"Field-injection example\" >@Inject private ObjectStorage client; <markup lang=\"java\" title=\"Constructor-injection example\" >public class MyClass { private final ObjectStorage client; @Inject public YourConstructor(@Named(\"orders\") ObjectStorage client) { this.client = client; } } The extension implements this injection point by creating an Object Storage client object in the singleton scope . ",
            "title": "Injecting an Object Storage Client"
        },
        {
            "location": "mp/integrations/oci",
            "text": " Once you have injected an ObjectStorage client you can use it as described in: OCI SDK Object Storage Javadocs OCI Object Storage Overview ",
            "title": "Using the Object Storage client"
        },
        {
            "location": "mp/integrations/oci",
            "text": " With Helidon 3.x, we are now implementing the MicroProfile 5.0 Platform and selected Jakarta EE 9.1 specifications. We are also going away from javax.* packages and fully embracing jakarta.* package. However, the current release 2.37.0 of OCI Java SDK is still using javax.* packages which created compatibility issues e.g. Helidon 3 uses JAX-RS 3.0.0 (jakarta package names) and the corresponding Jersey implementation. OCI SDK 2.37.0 uses JAX-RS Client 2.1.6 (javax package names) and the corresponding Jersey implementation. Therefore, the OCI SDK is incompatible with Helidon 3 applications and any application that uses JAX-RS 3. We have filed an issue with OCI SDK team, see https://github.com/oracle/oci-java-sdk/issues/371 for details on this. OCI SDK team has provided us with shaded jar as workaround as mentioned in the issue. Now, when you want to use modules from OCI SDK in your application, instead of using individual modules as defined in our OCI integration documentation, you need to use full shaded jar. <markup lang=\"xml\" > &lt;dependency&gt; &lt;groupId&gt;com.oracle.oci.sdk&lt;/groupId&gt; &lt;artifactId&gt;oci-java-sdk-shaded-full&lt;/artifactId&gt; &lt;version&gt;2.37.0&lt;/version&gt; &lt;/dependency&gt; Since the full shaded jar doesn&#8217;t bring in its transitive dependencies, you will also need to define following dependencies in your application so that it works at runtime. <markup lang=\"xml\" > &lt;dependency&gt; &lt;groupId&gt;org.bouncycastle&lt;/groupId&gt; &lt;artifactId&gt;bcpkix-jdk15on&lt;/artifactId&gt; &lt;version&gt;1.70&lt;/version&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-jdk14&lt;/artifactId&gt; &lt;version&gt;1.7.32&lt;/version&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; Please refer to our OCI SDK Usage Examples to see this in action. ",
            "title": "Resolving javax and jakarta package compatibility issue with OCI SDK"
        },
        {
            "location": "mp/integrations/oci",
            "text": " This example describes how to use Helidon OCI SDK Extension to access OCI Object Storage. As mentioned above in , you need to add a dependency on the OCI SDK Object Storage API: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;com.oracle.oci.sdk&lt;/groupId&gt; &lt;artifactId&gt;oci-java-sdk-objectstorage&lt;/artifactId&gt; &lt;/dependency&gt; Injecting an Object Storage Client Now you can inject OCI SDK Clients. <markup lang=\"java\" title=\"Field-injection example\" >@Inject private ObjectStorage client; <markup lang=\"java\" title=\"Constructor-injection example\" >public class MyClass { private final ObjectStorage client; @Inject public YourConstructor(@Named(\"orders\") ObjectStorage client) { this.client = client; } } The extension implements this injection point by creating an Object Storage client object in the singleton scope . Using the Object Storage client Once you have injected an ObjectStorage client you can use it as described in: OCI SDK Object Storage Javadocs OCI Object Storage Overview Resolving javax and jakarta package compatibility issue with OCI SDK With Helidon 3.x, we are now implementing the MicroProfile 5.0 Platform and selected Jakarta EE 9.1 specifications. We are also going away from javax.* packages and fully embracing jakarta.* package. However, the current release 2.37.0 of OCI Java SDK is still using javax.* packages which created compatibility issues e.g. Helidon 3 uses JAX-RS 3.0.0 (jakarta package names) and the corresponding Jersey implementation. OCI SDK 2.37.0 uses JAX-RS Client 2.1.6 (javax package names) and the corresponding Jersey implementation. Therefore, the OCI SDK is incompatible with Helidon 3 applications and any application that uses JAX-RS 3. We have filed an issue with OCI SDK team, see https://github.com/oracle/oci-java-sdk/issues/371 for details on this. OCI SDK team has provided us with shaded jar as workaround as mentioned in the issue. Now, when you want to use modules from OCI SDK in your application, instead of using individual modules as defined in our OCI integration documentation, you need to use full shaded jar. <markup lang=\"xml\" > &lt;dependency&gt; &lt;groupId&gt;com.oracle.oci.sdk&lt;/groupId&gt; &lt;artifactId&gt;oci-java-sdk-shaded-full&lt;/artifactId&gt; &lt;version&gt;2.37.0&lt;/version&gt; &lt;/dependency&gt; Since the full shaded jar doesn&#8217;t bring in its transitive dependencies, you will also need to define following dependencies in your application so that it works at runtime. <markup lang=\"xml\" > &lt;dependency&gt; &lt;groupId&gt;org.bouncycastle&lt;/groupId&gt; &lt;artifactId&gt;bcpkix-jdk15on&lt;/artifactId&gt; &lt;version&gt;1.70&lt;/version&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-jdk14&lt;/artifactId&gt; &lt;version&gt;1.7.32&lt;/version&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; Please refer to our OCI SDK Usage Examples to see this in action. ",
            "title": "Examples"
        },
        {
            "location": "mp/integrations/oci",
            "text": " OciExtension Javadocs OCI SDK Usage Examples ",
            "title": "References"
        },
        {
            "location": "mp/introduction",
            "text": " Helidon MP includes a compatible implementation of Eclipse MicroProfile 5.0 . MicroProfile is a set of specifications created by the Eclipse Foundation, MicroProfile Community that support application portability between different compatible implementation providers. Additionally, MicroProfile requires compatible implementations of certain component specifications from the Eclipse Jakarta EE community as well. ",
            "title": "Introduction"
        },
        {
            "location": "mp/introduction",
            "text": " Specification Version Description Jakarta Bean Validation 2.0 Object level constraint declaration and validation facility Jakarta Context and Dependency Injection (CDI) 3.0 Declarative dependency injection and supporting services Jakarta JSON Processing (JSON-P) 2.0.1 API to parse, generate, transform, and query JSON docs Jakarta JSON Binding (JSON-B) 2.0 Binding framework for converting POJOs to/from JSON docs Jakarta RESTful Web Services (JAX-RS) 3.0 API to develop web services following the REST pattern Jakarta Persistence (JPA) 3.0 Management of persistence and object/relational mapping Jakarta Transactions (JTA) 2.0 Allows handling transactions consistent with X/Open XA-spec Jakarta WebSocket 2.0 API for Server and Client Endpoints for WebSocket protocol ",
            "title": "Supported Jakarta EE Specifications"
        },
        {
            "location": "mp/introduction",
            "text": " Specification Version Description MicroProfile Config 3.0.1 A flexible configuration framework with support for multiple sources and formats MicroProfile Fault Tolerance 4.0 Common strategies for various system problems such as time-outs, retries, Circuit Breaker, etc. MicroProfile GraphQL 2.0 API for working with GraphQL MicroProfile Health 4.0 Health checks for automatic service restart/shutdown MicroProfile JWT Auth 2.0 Defines a compact and self-contained way for securely transmitting information between parties as a JSON object MicroProfile Long-Running Actions (LRA) 2.0-RC1 Distributed transactions for microservices following SAGA pattern MicroProfile Metrics 4.0 Defining and exposing telemetry data in Prometheus and JSON formats MicroProfile Open API 3.0 Annotations for documenting your application endpoints MicroProfile OpenTracing 3.0 Profile and monitor your applications across multiple services MicroProfile Reactive Messaging 3.0-RC2 Standard API for sending and receiving messages/events using streams MicroProfile Reactive Streams Operators 3.0-RC1 Control flow and error processing for event streams MicroProfile REST Client 3.0 Type-safe API for RESTful Web Services ",
            "title": "Supported MicroProfile Specifications"
        },
        {
            "location": "mp/introduction",
            "text": " Component Description CORS Cross Origin Resource Sharing – API to control if and how REST resources served by their applications can be shared across origins gRPC gRPC server and client OCI SDK Full set of APIs for working with OCI services Scheduling Scheduling functionality based on Cron-utils Security A tool-chain to handle authentication, authorization and context propagation ",
            "title": "Other Components"
        },
        {
            "location": "mp/introduction",
            "text": " Use the following migration guides to upgrade your current Helidon version. To migrate from Helidon 1.x to 2.x: Helidon MP 2x Migration Guide To migrate from Helidon 2.x to 3.x: Helidon MP 3x Migration Guide ",
            "title": "Migration"
        },
        {
            "location": "mp/introduction",
            "text": " Try the Helidon MP quickstart guides to get your first Helidon MP application up and running in minutes. Browse the Helidon Javadocs ",
            "title": "Next Steps"
        },
        {
            "location": "mp/introduction/microprofile",
            "text": " Complete these tasks to get started with your MicroProfile application. ",
            "title": "preambule"
        },
        {
            "location": "mp/introduction/microprofile",
            "text": " The Managing Dependencies page describes how you should declare dependency management for Helidon applications. Then declare the following dependency in your project: <markup lang=\"xml\" title=\"Maven Dependency for full MicroProfile\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.bundles&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile&lt;/artifactId&gt; &lt;/dependency&gt; The above dependency adds all the features available in MicroProfile. If you want to start with a smaller core set of features then you can use the core bundle instead. This bundle includes the base feature in MicroProfile (such as JAX-RS, CDI, JSON-P/B, and Config) and leaves out some of the additional features such as Metrics and Tracing. You can add those dependencies individually if you choose. <markup lang=\"xml\" title=\"Maven Dependency for MicroProfile core features only\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.bundles&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-core&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "mp/introduction/microprofile",
            "text": " Create a JAX-RS Resource class with at least one resource method. <markup lang=\"java\" title=\"Sample JAX-RS Resource Class\" >@Path(\"/\") @RequestScoped public class HelloWorldResource { @GET @Produces(MediaType.TEXT_PLAIN) public String message() { return \"Hello World\"; } } And create a JAX-RS application. <markup lang=\"java\" title=\"Sample JAX-RS Application\" >@ApplicationScoped @ApplicationPath(\"/\") public class HelloWorldApplication extends Application { @Override public Set&lt;Class&lt;?&gt;&gt; getClasses() { return Set.of( HelloWorldResource.class ); } } Add beans.xml in src/main/resources/META-INF so the CDI implementation can pick up your classes. <markup lang=\"xml\" title=\"beans.xml\" >&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;beans/&gt; As a last step, add a main method to your application (or a dedicated Main class) to start everything up. <markup lang=\"java\" title=\"Sample JAX-RS Application\" >public static void main(String[] args) { io.helidon.microprofile.server.Main.main(args); } Run the main class. The server will start on port 7001 and serve your resources. ",
            "title": "Project files"
        },
        {
            "location": "mp/introduction/microprofile",
            "text": " Jandex is an indexing tool for Weld (the CDI implementation used by Helidon) that helps speed up the boot time of an application. To use Jandex, configure a Maven plugin that adds the index to your JAR file and a dependency on Jandex. <markup lang=\"xml\" title=\"jandex dependency\" >&lt;dependency&gt; &lt;groupId&gt;org.jboss&lt;/groupId&gt; &lt;artifactId&gt;jandex&lt;/artifactId&gt; &lt;version&gt;2.0.4.Final&lt;/version&gt; &lt;/dependency&gt; <markup lang=\"xml\" title=\"jandex plugin configuration\" >&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.jboss.jandex&lt;/groupId&gt; &lt;artifactId&gt;jandex-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.0.5&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;make-index&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;jandex&lt;/goal&gt; &lt;/goals&gt; &lt;phase&gt;process-classes&lt;/phase&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; ",
            "title": "Adding Jandex"
        },
        {
            "location": "mp/introduction/microprofile",
            "text": " Helidon provides a MicroProfile server implementation ( io.helidon.microprofile.server ) that encapsulates the Helidon WebServer. You can either instantiate the server directly as is done in the Helidon MP Quickstart example or use its built-in main as shown below. Maven Coordinates The Managing Dependencies page describes how you should declare dependency management for Helidon applications. Then declare the following dependency in your project: <markup lang=\"xml\" title=\"Maven Dependency for full MicroProfile\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.bundles&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile&lt;/artifactId&gt; &lt;/dependency&gt; The above dependency adds all the features available in MicroProfile. If you want to start with a smaller core set of features then you can use the core bundle instead. This bundle includes the base feature in MicroProfile (such as JAX-RS, CDI, JSON-P/B, and Config) and leaves out some of the additional features such as Metrics and Tracing. You can add those dependencies individually if you choose. <markup lang=\"xml\" title=\"Maven Dependency for MicroProfile core features only\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.bundles&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-core&lt;/artifactId&gt; &lt;/dependency&gt; Project files Create a JAX-RS Resource class with at least one resource method. <markup lang=\"java\" title=\"Sample JAX-RS Resource Class\" >@Path(\"/\") @RequestScoped public class HelloWorldResource { @GET @Produces(MediaType.TEXT_PLAIN) public String message() { return \"Hello World\"; } } And create a JAX-RS application. <markup lang=\"java\" title=\"Sample JAX-RS Application\" >@ApplicationScoped @ApplicationPath(\"/\") public class HelloWorldApplication extends Application { @Override public Set&lt;Class&lt;?&gt;&gt; getClasses() { return Set.of( HelloWorldResource.class ); } } Add beans.xml in src/main/resources/META-INF so the CDI implementation can pick up your classes. <markup lang=\"xml\" title=\"beans.xml\" >&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;beans/&gt; As a last step, add a main method to your application (or a dedicated Main class) to start everything up. <markup lang=\"java\" title=\"Sample JAX-RS Application\" >public static void main(String[] args) { io.helidon.microprofile.server.Main.main(args); } Run the main class. The server will start on port 7001 and serve your resources. Adding Jandex Jandex is an indexing tool for Weld (the CDI implementation used by Helidon) that helps speed up the boot time of an application. To use Jandex, configure a Maven plugin that adds the index to your JAR file and a dependency on Jandex. <markup lang=\"xml\" title=\"jandex dependency\" >&lt;dependency&gt; &lt;groupId&gt;org.jboss&lt;/groupId&gt; &lt;artifactId&gt;jandex&lt;/artifactId&gt; &lt;version&gt;2.0.4.Final&lt;/version&gt; &lt;/dependency&gt; <markup lang=\"xml\" title=\"jandex plugin configuration\" >&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.jboss.jandex&lt;/groupId&gt; &lt;artifactId&gt;jandex-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.0.5&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;make-index&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;jandex&lt;/goal&gt; &lt;/goals&gt; &lt;phase&gt;process-classes&lt;/phase&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; ",
            "title": "Getting Started with Helidon MicroProfile"
        },
        {
            "location": "mp/jaxrs/application-configuration",
            "text": " Your application can use the MicroProfile Config or Helidon Config (or both). MicroProfile Config offers portability to other MicroProfile servers. Helidon Config supports a full tree structure, including repeating elements. ",
            "title": "preambule"
        },
        {
            "location": "mp/jaxrs/application-configuration",
            "text": " You can inject values that the application can access from both MicroProfile Config and from Helidon Config. <markup lang=\"java\" title=\"JAX-RS - inject a single config property\" >@Inject public MyResource(@ConfigProperty(name=\"app.name\") String appName) { this.applicationName = appName; } You can also inject the whole configuration instance, either io.helidon.config.Config or org.eclipse.microprofile.config.Config . <markup lang=\"java\" title=\"JAX-RS - inject config\" >@Inject public MyResource(Config config) { this.config = config; } ",
            "title": "Configuring the Application"
        },
        {
            "location": "mp/jaxrs/jaxrs-applications",
            "text": " In this section we shall distinguish the notion of a JAX-RS Application subclass from a Helidon application. As we shall learn shortly, the latter may include zero or more of the former. The JAX-RS specification defines the notion of an Application subclass whose methods return resource and provider classes, singletons and properties. This is the mechanism developers can use to define what comprises a JAX-RS application. Unless otherwise stated by the runtime environment in which the JAX-RS application runs, every JAX-RS application must include exactly one Application subclass. Helidon provides an extension to JAX-RS in which 0 or more Application subclasses are allowed. If no Application subclasses are provided, then a so-called synthetic subclass will be created automatically. This synthetic subclass shall include all resource and provider classes discovered by Helidon. Most Helidon applications should simply rely on this mechanism in accordance to convention over configuration practices. ",
            "title": "JAX-RS Applications"
        },
        {
            "location": "mp/jaxrs/jaxrs-applications",
            "text": " CDI scanning is controlled by the bean-discovery-mode attribute in beans.xml files &mdash; the default value for this attribute is annotated . In the default mode, CDI scans for beans decorated by bean-defining annotations such as @ApplicationScoped , @RequestScoped , etc. With the help of CDI, Helidon looks for JAX-RS Application subclasses in your Helidon application. If none are found, a synthetic application will be created by gathering all resources and providers found during the discovery phase. Note that if your Application subclass has no bean-defining annotations, and bean discovery is set to the default annotated value, it will be ignored. The discovery phase is carried out as follows (in no particular order): Collect all beans that extend Application Collect all beans annotated with @Path Collect all beans annotated with @Provider If no Application subclasses are found, create a synthetic Application subclass that includes all beans gathered in steps (2) and (3) and set the application path to be \"/\" &mdash;this is the path normally defined using the @ApplicationPath annotation. If one or more Application subclasses are found, call the getClasses and getSingletons methods in each subclass using the collections in steps (2) and (3) only as defaults, i.e. if these methods both return empty sets. Helidon treats @Path and @Provided as bean-defining annotations but, as stated above, Application subclasses may require additional annotations depending on the discovery mode. ",
            "title": "Discovery of JAX-RS Beans"
        },
        {
            "location": "mp/jaxrs/jaxrs-applications",
            "text": " JAX-RS provides access to the Application subclass instance via injection using @Context . This form of access is still supported in Helidon but is insufficient if two or more subclasses are present. Given that support for two or more Application subclasses is a Helidon extension, a new mechanism is provided via the ServerRequest 's context object as shown next. <markup lang=\"java\" >import io.helidon.webserver.ServerRequest; @Path(\"myresource\") public class MyResource { @GET public void get(@Context ServerRequest serverRequest) { Application app = serverRequest.context().get(Application.class).get(); } } This approach effectively moves the scope of Application subclass instances to request scope in order to access the correct subclass for the resource method being executed. ",
            "title": "Access to Application Instances"
        },
        {
            "location": "mp/jaxrs/jaxrs-applications",
            "text": " Jersey does not currently provide support for multiple Application subclasses. As a result, it creates a single internal injection manager for your entire application, but this is insufficient when multiple Application subclasses are present. Helidon creates a separate injection manager for each Application subclass, and a single parent injection manager for your application. Each Application subclass injection manager delegates to the parent injection manager. Due to an implementation strategy in Jersey, ParamConverterProvider 's must be registered in the parent manager for proper registration and initialization. Thus, providers of this type will be shared and accessible by all Application subclasses, even if your code tries to limit their access. This is likely to change in future versions of Jersey/Helidon and does not typically impact how your application runs. ",
            "title": "Injection Managers in Helidon"
        },
        {
            "location": "mp/jaxrs/jaxrs-client",
            "text": " Overview Maven Coordinates API Configuration Examples Additional Information Reference ",
            "title": "Contents"
        },
        {
            "location": "mp/jaxrs/jaxrs-client",
            "text": " The Jakarta REST Client defines a programmatic API to access REST resources. This API sits at a higher level than traditional HTTP client APIs and provides full integration with server-side API concepts like providers. It differs from the Rest Client API in that it does not support annotations or proxies, but instead uses builders and a fluent API to create and execute requests. ",
            "title": "Overview"
        },
        {
            "location": "mp/jaxrs/jaxrs-client",
            "text": " To enable Jakarta REST Client add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.jersey&lt;/groupId&gt; &lt;artifactId&gt;helidon-jersey-client&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "mp/jaxrs/jaxrs-client",
            "text": " Bootstrapping the API is done by obtaining an instance of Client . A single instance of this class can be used to create multiple service requests that share the same basic configuration, e.g., the same set of providers . More precisely, from a Client we can create multiple WebTarget s, and in turn, from each WebTarget we can create multiple Invocation s. <markup lang=\"java\" >Client client = ClientBuilder.newClient(); Response res = client .target(\"http://localhost:8080/greet\") .request(\"text/plain\") .get(); In the snippet above, the call to target returns a WebTarget , and the call to request returns an Invocation.Builder ; finally, the call to get returns the Response that results from accessing the service resource. Given that this API is fully integrated with message body readers and writers, it is possible to request the response body be provided after conversion to a Java type&#8201;&#8212;&#8201;such as a String in the example below. <markup lang=\"java\" >Client client = ClientBuilder.newClient(); String res = client .target(\"http://localhost:8080/greet\") .request(\"text/plain\") .get(String.class); Alternatively, there are also methods in Response that can trigger similar conversions. Configuration can be specified at the Client or WebTarget level, as both types implement Configurable&lt;T&gt; . This enables common configuration to be inherited by a WebTarget created from a Client instance. In either case, methods such as register can be used to register providers such as filters and exception mappers. <markup lang=\"java\" >Client client = ClientBuilder.newClient(); client.register(GreetFilter.class); String res = client .target(\"http://localhost:8080/greet\") .register(GreetExceptionMapper.class) .request(\"text/plain\") .get(String.class); The example above shows registration of GreetFilter.class for all targets and registration of GreetExceptionMapper.class for just one of them. The same logic applies to other types of configuration such as properties and features. The Jakarta REST Client API has support for asynchronous invocations. Accessing a resource asynchronously prevents the calling thread from blocking for the duration of the call. By default, all invocations are synchronous but can be turned into either asynchronous or reactive calls by simply inserting the corresponding fluent method call during the creation phase. Using Future : <markup lang=\"java\" >Client client = ClientBuilder.newClient(); Future&lt;String&gt; res = client .target(\"http://localhost:8080/greet\") .request(\"text/plain\") .async() // now asynchronous .get(String.class); Or using a more modern, reactive style: <markup lang=\"java\" >Client client = ClientBuilder.newClient(); CompletionStage&lt;String&gt; res = client .target(\"http://localhost:8080/greet\") .request(\"text/plain\") .rx() // now reactive .get(String.class); In either case, the implementation will ensure the calling thread is not blocked and that the result from the invocation is available upon request or via a callback mechanism. ",
            "title": "API"
        },
        {
            "location": "mp/jaxrs/jaxrs-client",
            "text": " Configuration for this API is all done programmatically as shown in the previous sections. ",
            "title": "Configuration"
        },
        {
            "location": "mp/jaxrs/jaxrs-client",
            "text": " See for same simple examples. For additional information, refer to the Jakarta REST Client Specification . ",
            "title": "Examples"
        },
        {
            "location": "mp/jaxrs/jaxrs-client",
            "text": " For additional information, see the Jakarta REST Javadocs . ",
            "title": "Additional Information"
        },
        {
            "location": "mp/jaxrs/jaxrs-client",
            "text": " Jakarta REST Client Specification ",
            "title": "Reference"
        },
        {
            "location": "mp/jwt",
            "text": " Overview Maven Coordinates Usage API Configuration Examples Additional Information Reference ",
            "title": "Contents"
        },
        {
            "location": "mp/jwt",
            "text": " JSON Web Tokens (JWT) are an open, industry standard (RFC 7519) method for representing claims securely between two parties. JWT defines a compact and self-contained way for securely transmitting information between parties as a JSON object. With JWT Auth you can integrate security features such as single sign on into your Helidon MP applications. ",
            "title": "Overview"
        },
        {
            "location": "mp/jwt",
            "text": " To enable JWT Authentication either add a dependency on the helidon-microprofile bundle or add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.jwt&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-jwt-auth&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "mp/jwt",
            "text": " The main configuration point for JWT Auth is a JAX-RS Application class. As this class is discovered using CDI, it must have a bean defining annotation. Minimal required setup is done using @LoginConfig(authMethod = \"MP-JWT\") : <markup lang=\"java\" >@LoginConfig(authMethod = \"MP-JWT\") @ApplicationScoped public class ProtectedApplication extends Application{ } ",
            "title": "Usage"
        },
        {
            "location": "mp/jwt",
            "text": " The following interfaces and annotations are used to work with JWT in Helidon MP: JsonWebToken - an interface used in CDI beans (@RequestScoped) dependency injection to obtain the JWT of the currently executing caller. @Claim - an annotation used by CDI bean (@RequestScoped) dependency injection to obtain individual claims from the caller’s JWT. ClaimValue - a proxy interface used with @Claim annotation to оbtain the value of a claim by calling getValue() . ",
            "title": "API"
        },
        {
            "location": "mp/jwt",
            "text": " MicroProfile configuration options: key type default value description mp.jwt.verify.publickey string &#160; The property allows the Public Verification Key text itself to be supplied as a string. mp.jwt.verify.publickey.location string &#160; The property allows for an external or internal location of Public Verification Key to be specified. The value may be a relative path or a URL. mp.jwt.verify.publickey.algorithm string &#160; The configuration property allows for specifying which Public Key Signature Algorithm is supported by the MP JWT endpoint. This property can be set to either RS256 or ES256 . Default value is RS256 . Support for the other asymmetric signature algorithms such as RS512 , ES512 and others is optional. Optional configuration options: key type default value description optional boolean false If set to true , failure to authenticate will return ABSTAIN result instead of FAILURE . This is an important distinction when more than one provider is used authenticate boolean true Whether to attempt authentication propagate boolean true Whether to attempt identity propagation/JWT creation principal-type string USER Whether we authenticate a user or a service (other option is SERVICE) atn-token string A group for configuring authentication of the request atn-token.verify-signature boolean true Whether to verify signature in incoming JWT. If disabled, ANY JWT will be accepted atn-token.jwt-audience string &#160; Expected audience of the JWT. If not defined, any audience is accepted (and we may accept JWT not inteded for us) atn-token.jwk.resource.* string &#160; Configuration of the JWK to obtain key(s) to validate signatures of inbound token. The JWK should contain public keys. This may be: jwk.resource.path, jwk.resource.resource-path, jwk.resource.url, jwk.resource.content-plain (actual JSON string), jwk.resource.content (base64) atn-token.handler string Authorization header with `bearer ` prefix A handler configuration for inbound token - e.g. how to extract it atn-token.handler.header string &#160; Name of a header the token is expected in atn-token.handler.prefix string &#160; Prefix before the token value (optional) atn-token.handler.regexp string &#160; Regular expression to obtain the token, first matching group is used (optional) sign-token string &#160; A group for configuring outbound security sign-token.jwk.resource.* &#160; Configuration of the JWK to use when generating tokens (follows same rules as atn-token.jwk above), this JWK must contain private keys when using asymmetric ciphers sign-token.jwt-issuer string &#160; When we issue a new token, this is the issuer to be placed into it (validated by target service) sign-token.outbound string &#160; A group for configuring outbound rules (based on transport, host and.or path) sign-token.outbound.*.name string &#160; A short descriptive name for configured target service(s) sign-token.outbound.*.transports string any An array of transports this outbound matches (e.g. https) sign-token.outbound.*.hosts string any An array of hosts this outbound matches, may use * as a wild-card (e.g. *.oracle.com) sign-token.outbound.*.paths string any An array of paths on the host this outbound matches, may use * as a wild-card (e.g. /some/path/*) sign-token.outbound.*.outbound-token string Authorization header with `bearer ` prefix Configuration of outbound token handler (same as atn-token.handler) sign-token.outbound.*.outbound-token.format string &#160; Java text format for generating the value of outbound token header (e.g. \"bearer %1$s\") sign-token.outbound.*.jwk-kid string &#160; If this key is defined, we are generating a new token, otherwise we propagate existing. Defines the key id of a key definition in the JWK file to use for signing the outbound token sign-token.outbound.*.jwt-kid string &#160; A key to use in the generated JWT - this is for the other service to locate the verification key in their JWK sign-token.outbound.*.jwt-audience string &#160; Audience this key is generated for (e.g. http://www.example.org/api/myService ) - validated by the other service sign-token.outbound.*.jwt-not-before-seconds string 5 Makes this key valid this amount of seconds into the past. Allows a certain time-skew for the generated token to be valid before current time (e.g. when we expect a certain misalignment of clocks) sign-token.outbound.*.jwt-validity-seconds A configuration example in microprofile-config.properties : <markup lang=\"properties\" >mp.jwt.verify.issuer=https://{PublicIssuerDomain}/oauth2/default mp.jwt.verify.publickey.location=${mp.jwt.verify.issuer}/v1/keys ",
            "title": "Configuration Options"
        },
        {
            "location": "mp/jwt",
            "text": " Configuration Options MicroProfile configuration options: key type default value description mp.jwt.verify.publickey string &#160; The property allows the Public Verification Key text itself to be supplied as a string. mp.jwt.verify.publickey.location string &#160; The property allows for an external or internal location of Public Verification Key to be specified. The value may be a relative path or a URL. mp.jwt.verify.publickey.algorithm string &#160; The configuration property allows for specifying which Public Key Signature Algorithm is supported by the MP JWT endpoint. This property can be set to either RS256 or ES256 . Default value is RS256 . Support for the other asymmetric signature algorithms such as RS512 , ES512 and others is optional. Optional configuration options: key type default value description optional boolean false If set to true , failure to authenticate will return ABSTAIN result instead of FAILURE . This is an important distinction when more than one provider is used authenticate boolean true Whether to attempt authentication propagate boolean true Whether to attempt identity propagation/JWT creation principal-type string USER Whether we authenticate a user or a service (other option is SERVICE) atn-token string A group for configuring authentication of the request atn-token.verify-signature boolean true Whether to verify signature in incoming JWT. If disabled, ANY JWT will be accepted atn-token.jwt-audience string &#160; Expected audience of the JWT. If not defined, any audience is accepted (and we may accept JWT not inteded for us) atn-token.jwk.resource.* string &#160; Configuration of the JWK to obtain key(s) to validate signatures of inbound token. The JWK should contain public keys. This may be: jwk.resource.path, jwk.resource.resource-path, jwk.resource.url, jwk.resource.content-plain (actual JSON string), jwk.resource.content (base64) atn-token.handler string Authorization header with `bearer ` prefix A handler configuration for inbound token - e.g. how to extract it atn-token.handler.header string &#160; Name of a header the token is expected in atn-token.handler.prefix string &#160; Prefix before the token value (optional) atn-token.handler.regexp string &#160; Regular expression to obtain the token, first matching group is used (optional) sign-token string &#160; A group for configuring outbound security sign-token.jwk.resource.* &#160; Configuration of the JWK to use when generating tokens (follows same rules as atn-token.jwk above), this JWK must contain private keys when using asymmetric ciphers sign-token.jwt-issuer string &#160; When we issue a new token, this is the issuer to be placed into it (validated by target service) sign-token.outbound string &#160; A group for configuring outbound rules (based on transport, host and.or path) sign-token.outbound.*.name string &#160; A short descriptive name for configured target service(s) sign-token.outbound.*.transports string any An array of transports this outbound matches (e.g. https) sign-token.outbound.*.hosts string any An array of hosts this outbound matches, may use * as a wild-card (e.g. *.oracle.com) sign-token.outbound.*.paths string any An array of paths on the host this outbound matches, may use * as a wild-card (e.g. /some/path/*) sign-token.outbound.*.outbound-token string Authorization header with `bearer ` prefix Configuration of outbound token handler (same as atn-token.handler) sign-token.outbound.*.outbound-token.format string &#160; Java text format for generating the value of outbound token header (e.g. \"bearer %1$s\") sign-token.outbound.*.jwk-kid string &#160; If this key is defined, we are generating a new token, otherwise we propagate existing. Defines the key id of a key definition in the JWK file to use for signing the outbound token sign-token.outbound.*.jwt-kid string &#160; A key to use in the generated JWT - this is for the other service to locate the verification key in their JWK sign-token.outbound.*.jwt-audience string &#160; Audience this key is generated for (e.g. http://www.example.org/api/myService ) - validated by the other service sign-token.outbound.*.jwt-not-before-seconds string 5 Makes this key valid this amount of seconds into the past. Allows a certain time-skew for the generated token to be valid before current time (e.g. when we expect a certain misalignment of clocks) sign-token.outbound.*.jwt-validity-seconds A configuration example in microprofile-config.properties : <markup lang=\"properties\" >mp.jwt.verify.issuer=https://{PublicIssuerDomain}/oauth2/default mp.jwt.verify.publickey.location=${mp.jwt.verify.issuer}/v1/keys ",
            "title": "Configuration"
        },
        {
            "location": "mp/jwt",
            "text": "<markup lang=\"java\" >@Path(\"/hello\") public class HelloResource { @GET @Produces(TEXT_PLAIN) public String hello(@Context SecurityContext context) { Optional&lt;Principal&gt; userPrincipal = context.userPrincipal(); return \"Hello, \" + userPrincipal.get().getName() + \"!\"; } } Do not forget to annotate the HelloApplication class to enable JWT: <markup lang=\"java\" >@LoginConfig(authMethod = \"MP-JWT\") @ApplicationScoped public class HelloApplication extends Application { @Override public Set&lt;Class&lt;?&gt;&gt; getClasses() { return Set.of(HelloResource.class); } } Add the following configuration in microprofile-config.properties : <markup lang=\"properties\" >mp.jwt.verify.issuer=https://{IssuerPublicDomain}/oauth2/default mp.jwt.verify.publickey.location=${mp.jwt.verify.issuer}/v1/keys Obtain the Security Token from external issuer: <markup lang=\"bash\" >TOKEN=sdf4dDSWFcswdsffDSasEgv... Run the application and execute an HTTP request against it: <markup lang=\"bash\" >curl -X GET -I -H \"Authorization: Bearer $TOKEN\" http://localhost:8080/hello The result should be: <markup lang=\"bash\" >HTTP/1.1 200 OK Date: 08.06.2022 10:33:47 EEST connection: keep-alive content-length: 28 Hello, secure@helidon.io! which means that the request successfully passed authentication. ",
            "title": "Examples"
        },
        {
            "location": "mp/jwt",
            "text": " Learn more about JWT authentication at: Eclipse MicroProfile Interoperable JWT RBAC ",
            "title": "Additional Information"
        },
        {
            "location": "mp/jwt",
            "text": " MicroProfile JWT Auth Spec MicroProfile JWT Auth GitHub Repository ",
            "title": "Reference"
        },
        {
            "location": "mp/lra",
            "text": " Overview Maven Coordinates Usage API Configuration Examples Additional Information Reference ",
            "title": "Contents"
        },
        {
            "location": "mp/lra",
            "text": " Distributed transactions for microservices are known as SAGA design patterns and are defined by the {microprofile-lra-spec-url}[MicroProfile Long Running Actions specification]. Unlike well known XA protocol, LRA is asynchronous and therefore much more scalable. Every LRA JAX-RS resource ( participant ) defines endpoints to be invoked when transaction needs to be completed or compensated . ",
            "title": "Overview"
        },
        {
            "location": "mp/lra",
            "text": " To enable Long Running Actions add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.lra&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-lra&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Support for Narayana coordinator --&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.lra&lt;/groupId&gt; &lt;artifactId&gt;helidon-lra-coordinator-narayana-client&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "mp/lra",
            "text": " The LRA transactions need to be coordinated over REST API by the LRA coordinator. Coordinator keeps track of all transactions and calls the @Compensate or @Complete endpoints for all participants involved in the particular transaction. LRA transaction is first started, then joined by participant . The participant reports the successful finish of the transaction by calling it complete. The coordinator then calls the JAX-RS complete endpoint that was registered during the join of each participant . As the completed or compensated participants don&#8217;t have to be on same instance, the whole architecture is highly scalable. If an error occurs during the LRA transaction, the participant reports a cancellation of LRA to the coordinator. Coordinator calls compensate on all the joined participants. When a participant joins the LRA with timeout defined @LRA(value = LRA.Type.REQUIRES_NEW, timeLimit = 5, timeUnit = ChronoUnit.MINUTES) , the coordinator compensates if the timeout occurred before the close is reported by the participants. ",
            "title": "Usage"
        },
        {
            "location": "mp/lra",
            "text": " The Participant, or Compensator, is an LRA resource with at least one of the JAX-RS(or non-JAX-RS) methods annotated with @Compensate or @AfterLRA . ",
            "title": "Participant"
        },
        {
            "location": "mp/lra",
            "text": " javadoc Marks JAX-RS method which should run in LRA context and needs to be accompanied by at least minimal set of mandatory participant methods( Compensate or AfterLRA ). LRA options: value REQUIRED join incoming LRA or create and join new REQUIRES_NEW create and join new LRA MANDATORY join incoming LRA or fail SUPPORTS join incoming LRA or continue outside LRA context NOT_SUPPORTED always continue outside LRA context NEVER Fail with 412 if executed in LRA context NESTED create and join new LRA nested in the incoming LRA context timeLimit max time limit before LRA gets cancelled automatically by coordinator timeUnit time unit if the timeLimit value end when false LRA is not closed after successful method execution cancelOn which HTTP response codes of the method causes LRA to cancel cancelOnFamily which family of HTTP response codes causes LRA to cancel Method parameters: Header LRA_HTTP_CONTEXT_HEADER - ID of the LRA transaction <markup lang=\"java\" >@PUT @LRA(LRA.Type.REQUIRES_NEW, timeLimit = 500, timeUnit = ChronoUnit.MILLIS) @Path(\"start-example\") public Response startLra(@HeaderParam(LRA_HTTP_CONTEXT_HEADER) URI lraId, String data) ",
            "title": "@LRA"
        },
        {
            "location": "mp/lra",
            "text": " Header LRA_HTTP_CONTEXT_HEADER - ID of the LRA transaction Header LRA_HTTP_PARENT_CONTEXT_HEADER - parent LRA ID in case of nested LRA <markup lang=\"java\" >@PUT @Path(\"/compensate\") @Compensate public Response compensateWork(@HeaderParam(LRA_HTTP_CONTEXT_HEADER) URI lraId, @HeaderParam(LRA_HTTP_PARENT_CONTEXT_HEADER) URI parent){ return LRAResponse.compensated(); } ",
            "title": "JAX-RS variant with supported LRA context values:"
        },
        {
            "location": "mp/lra",
            "text": " URI with LRA ID <markup lang=\"java\" >@Compensate public void compensate(URI lraId) ",
            "title": "Non JAX-RS variant with supported LRA context values:"
        },
        {
            "location": "mp/lra",
            "text": " javadoc Expected to be called by LRA coordinator only! Compensate method is called by a coordinator when LRA is cancelled, usually by error during execution of method body of @LRA annotated method . If the method responds with 500 or 202, coordinator will eventually try the call again. If participant has @Status annotated method , coordinator retrieves the status to find out if retry should be done. JAX-RS variant with supported LRA context values: Header LRA_HTTP_CONTEXT_HEADER - ID of the LRA transaction Header LRA_HTTP_PARENT_CONTEXT_HEADER - parent LRA ID in case of nested LRA <markup lang=\"java\" >@PUT @Path(\"/compensate\") @Compensate public Response compensateWork(@HeaderParam(LRA_HTTP_CONTEXT_HEADER) URI lraId, @HeaderParam(LRA_HTTP_PARENT_CONTEXT_HEADER) URI parent){ return LRAResponse.compensated(); } Non JAX-RS variant with supported LRA context values: URI with LRA ID <markup lang=\"java\" >@Compensate public void compensate(URI lraId) ",
            "title": "@Compensate"
        },
        {
            "location": "mp/lra",
            "text": " Header LRA_HTTP_CONTEXT_HEADER - ID of the LRA transaction Header LRA_HTTP_PARENT_CONTEXT_HEADER - parent LRA ID in case of nested LRA <markup lang=\"java\" >@PUT @Path(\"/complete\") @Complete public Response complete(@HeaderParam(LRA_HTTP_CONTEXT_HEADER) URI lraId, @HeaderParam(LRA_HTTP_PARENT_CONTEXT_HEADER) URI parentLraId) ",
            "title": "JAX-RS variant with supported LRA context values:"
        },
        {
            "location": "mp/lra",
            "text": " URI with LRA ID <markup lang=\"java\" >@Complete public void complete(URI lraId) ",
            "title": "Non JAX-RS variant with supported LRA context values:"
        },
        {
            "location": "mp/lra",
            "text": " javadoc Expected to be called by LRA coordinator only! Complete method is called by coordinator when LRA is successfully closed. If the method responds with 500 or 202, coordinator will eventually try the call again. If participant has @Status annotated method , coordinator retrieves the status to find out if retry should be done. JAX-RS variant with supported LRA context values: Header LRA_HTTP_CONTEXT_HEADER - ID of the LRA transaction Header LRA_HTTP_PARENT_CONTEXT_HEADER - parent LRA ID in case of nested LRA <markup lang=\"java\" >@PUT @Path(\"/complete\") @Complete public Response complete(@HeaderParam(LRA_HTTP_CONTEXT_HEADER) URI lraId, @HeaderParam(LRA_HTTP_PARENT_CONTEXT_HEADER) URI parentLraId) Non JAX-RS variant with supported LRA context values: URI with LRA ID <markup lang=\"java\" >@Complete public void complete(URI lraId) ",
            "title": "@Complete"
        },
        {
            "location": "mp/lra",
            "text": " Header LRA_HTTP_CONTEXT_HEADER - ID of the LRA transaction Header LRA_HTTP_PARENT_CONTEXT_HEADER - parent LRA ID in case of nested LRA <markup lang=\"java\" >@DELETE @Path(\"/forget\") @Forget public Response forget(@HeaderParam(LRA_HTTP_CONTEXT_HEADER) URI lraId, @HeaderParam(LRA_HTTP_PARENT_CONTEXT_HEADER) URI parent) ",
            "title": "JAX-RS variant with supported LRA context values:"
        },
        {
            "location": "mp/lra",
            "text": " URI with LRA ID <markup lang=\"java\" >@Forget public void forget(URI lraId) } ",
            "title": "Non JAX-RS variant with supported LRA context values:"
        },
        {
            "location": "mp/lra",
            "text": " javadoc Expected to be called by LRA coordinator only! Complete and compensate methods can fail(500) or report that compensation/completion is in progress(202). In such case participant needs to be prepared to report its status over @Status annotated method to coordinator . When coordinator decides all the participants have finished, method annotated with @Forget is called. JAX-RS variant with supported LRA context values: Header LRA_HTTP_CONTEXT_HEADER - ID of the LRA transaction Header LRA_HTTP_PARENT_CONTEXT_HEADER - parent LRA ID in case of nested LRA <markup lang=\"java\" >@DELETE @Path(\"/forget\") @Forget public Response forget(@HeaderParam(LRA_HTTP_CONTEXT_HEADER) URI lraId, @HeaderParam(LRA_HTTP_PARENT_CONTEXT_HEADER) URI parent) Non JAX-RS variant with supported LRA context values: URI with LRA ID <markup lang=\"java\" >@Forget public void forget(URI lraId) } ",
            "title": "@Forget"
        },
        {
            "location": "mp/lra",
            "text": " javadoc Method annotated with @Leave called with LRA context(with header LRA_HTTP_CONTEXT_HEADER ) informs coordinator that current participant is leaving the LRA. Method body is executed after leave signal is sent. As a result, participant methods complete and compensate won&#8217;t be called when the particular LRA ends. Header LRA_HTTP_CONTEXT_HEADER - ID of the LRA transaction <markup lang=\"java\" >@PUT @Path(\"/leave\") @Leave public Response leaveLRA(@HeaderParam(LRA_HTTP_CONTEXT_HEADER) URI lraIdtoLeave) ",
            "title": "@Leave"
        },
        {
            "location": "mp/lra",
            "text": " Header LRA_HTTP_CONTEXT_HEADER - ID of the LRA transaction ParticipantStatus - Status of the participant reported to coordinator <markup lang=\"java\" >@GET @Path(\"/status\") @Status public Response reportStatus(@HeaderParam(LRA_HTTP_CONTEXT_HEADER) URI lraId) { return Response.status(ParticipantStatus.FailedToCompensate).build(); } ",
            "title": "JAX-RS variant with supported LRA context values:"
        },
        {
            "location": "mp/lra",
            "text": " URI with LRA ID ParticipantStatus - Status of the participant reported to coordinator <markup lang=\"java\" >@Status public Response reportStatus(URI lraId){ return Response.ok(ParticipantStatus.FailedToCompensate).build(); } ",
            "title": "Non JAX-RS variant with supported LRA context values:"
        },
        {
            "location": "mp/lra",
            "text": " javadoc Expected to be called by LRA coordinator only! If the coordinator&#8217;s call to the participant&#8217;s method fails, then it will retry the call. If the participant is not idempotent, then it may need to report its state to coordinator by declaring method annotated with @Status for reporting if previous call did change participant status. Coordinator can call it and decide if compensate or complete retry is needed. JAX-RS variant with supported LRA context values: Header LRA_HTTP_CONTEXT_HEADER - ID of the LRA transaction ParticipantStatus - Status of the participant reported to coordinator <markup lang=\"java\" >@GET @Path(\"/status\") @Status public Response reportStatus(@HeaderParam(LRA_HTTP_CONTEXT_HEADER) URI lraId) { return Response.status(ParticipantStatus.FailedToCompensate).build(); } Non JAX-RS variant with supported LRA context values: URI with LRA ID ParticipantStatus - Status of the participant reported to coordinator <markup lang=\"java\" >@Status public Response reportStatus(URI lraId){ return Response.ok(ParticipantStatus.FailedToCompensate).build(); } ",
            "title": "@Status"
        },
        {
            "location": "mp/lra",
            "text": " Header LRA_HTTP_ENDED_CONTEXT_HEADER - ID of the finished LRA transaction Header LRA_HTTP_PARENT_CONTEXT_HEADER - parent LRA ID in case of nested LRA LRAStatus - Final status of the LRA ( Cancelled , Closed , FailedToCancel , FailedToClose ) <markup lang=\"java\" >@PUT @Path(\"/finished\") @AfterLRA public Response whenLRAFinishes(@HeaderParam(LRA_HTTP_ENDED_CONTEXT_HEADER) URI lraId, @HeaderParam(LRA_HTTP_PARENT_CONTEXT_HEADER) URI parentLraId, LRAStatus status) ",
            "title": "JAX-RS variant with supported LRA context values:"
        },
        {
            "location": "mp/lra",
            "text": " URI with finished LRA ID LRAStatus - Final status of the LRA ( Cancelled , Closed , FailedToCancel , FailedToClose ) <markup lang=\"java\" >public void whenLRAFinishes(URI lraId, LRAStatus status) ",
            "title": "Non JAX-RS variant with supported LRA context values:"
        },
        {
            "location": "mp/lra",
            "text": " javadoc Expected to be called by LRA coordinator only! Method annotated with @AfterLRA in the same class as the one with @LRA annotation gets invoked after particular LRA finishes. JAX-RS variant with supported LRA context values: Header LRA_HTTP_ENDED_CONTEXT_HEADER - ID of the finished LRA transaction Header LRA_HTTP_PARENT_CONTEXT_HEADER - parent LRA ID in case of nested LRA LRAStatus - Final status of the LRA ( Cancelled , Closed , FailedToCancel , FailedToClose ) <markup lang=\"java\" >@PUT @Path(\"/finished\") @AfterLRA public Response whenLRAFinishes(@HeaderParam(LRA_HTTP_ENDED_CONTEXT_HEADER) URI lraId, @HeaderParam(LRA_HTTP_PARENT_CONTEXT_HEADER) URI parentLraId, LRAStatus status) Non JAX-RS variant with supported LRA context values: URI with finished LRA ID LRAStatus - Final status of the LRA ( Cancelled , Closed , FailedToCancel , FailedToClose ) <markup lang=\"java\" >public void whenLRAFinishes(URI lraId, LRAStatus status) ",
            "title": "@AfterLRA"
        },
        {
            "location": "mp/lra",
            "text": " Participant The Participant, or Compensator, is an LRA resource with at least one of the JAX-RS(or non-JAX-RS) methods annotated with @Compensate or @AfterLRA . @LRA javadoc Marks JAX-RS method which should run in LRA context and needs to be accompanied by at least minimal set of mandatory participant methods( Compensate or AfterLRA ). LRA options: value REQUIRED join incoming LRA or create and join new REQUIRES_NEW create and join new LRA MANDATORY join incoming LRA or fail SUPPORTS join incoming LRA or continue outside LRA context NOT_SUPPORTED always continue outside LRA context NEVER Fail with 412 if executed in LRA context NESTED create and join new LRA nested in the incoming LRA context timeLimit max time limit before LRA gets cancelled automatically by coordinator timeUnit time unit if the timeLimit value end when false LRA is not closed after successful method execution cancelOn which HTTP response codes of the method causes LRA to cancel cancelOnFamily which family of HTTP response codes causes LRA to cancel Method parameters: Header LRA_HTTP_CONTEXT_HEADER - ID of the LRA transaction <markup lang=\"java\" >@PUT @LRA(LRA.Type.REQUIRES_NEW, timeLimit = 500, timeUnit = ChronoUnit.MILLIS) @Path(\"start-example\") public Response startLra(@HeaderParam(LRA_HTTP_CONTEXT_HEADER) URI lraId, String data) @Compensate javadoc Expected to be called by LRA coordinator only! Compensate method is called by a coordinator when LRA is cancelled, usually by error during execution of method body of @LRA annotated method . If the method responds with 500 or 202, coordinator will eventually try the call again. If participant has @Status annotated method , coordinator retrieves the status to find out if retry should be done. JAX-RS variant with supported LRA context values: Header LRA_HTTP_CONTEXT_HEADER - ID of the LRA transaction Header LRA_HTTP_PARENT_CONTEXT_HEADER - parent LRA ID in case of nested LRA <markup lang=\"java\" >@PUT @Path(\"/compensate\") @Compensate public Response compensateWork(@HeaderParam(LRA_HTTP_CONTEXT_HEADER) URI lraId, @HeaderParam(LRA_HTTP_PARENT_CONTEXT_HEADER) URI parent){ return LRAResponse.compensated(); } Non JAX-RS variant with supported LRA context values: URI with LRA ID <markup lang=\"java\" >@Compensate public void compensate(URI lraId) @Complete javadoc Expected to be called by LRA coordinator only! Complete method is called by coordinator when LRA is successfully closed. If the method responds with 500 or 202, coordinator will eventually try the call again. If participant has @Status annotated method , coordinator retrieves the status to find out if retry should be done. JAX-RS variant with supported LRA context values: Header LRA_HTTP_CONTEXT_HEADER - ID of the LRA transaction Header LRA_HTTP_PARENT_CONTEXT_HEADER - parent LRA ID in case of nested LRA <markup lang=\"java\" >@PUT @Path(\"/complete\") @Complete public Response complete(@HeaderParam(LRA_HTTP_CONTEXT_HEADER) URI lraId, @HeaderParam(LRA_HTTP_PARENT_CONTEXT_HEADER) URI parentLraId) Non JAX-RS variant with supported LRA context values: URI with LRA ID <markup lang=\"java\" >@Complete public void complete(URI lraId) @Forget javadoc Expected to be called by LRA coordinator only! Complete and compensate methods can fail(500) or report that compensation/completion is in progress(202). In such case participant needs to be prepared to report its status over @Status annotated method to coordinator . When coordinator decides all the participants have finished, method annotated with @Forget is called. JAX-RS variant with supported LRA context values: Header LRA_HTTP_CONTEXT_HEADER - ID of the LRA transaction Header LRA_HTTP_PARENT_CONTEXT_HEADER - parent LRA ID in case of nested LRA <markup lang=\"java\" >@DELETE @Path(\"/forget\") @Forget public Response forget(@HeaderParam(LRA_HTTP_CONTEXT_HEADER) URI lraId, @HeaderParam(LRA_HTTP_PARENT_CONTEXT_HEADER) URI parent) Non JAX-RS variant with supported LRA context values: URI with LRA ID <markup lang=\"java\" >@Forget public void forget(URI lraId) } @Leave javadoc Method annotated with @Leave called with LRA context(with header LRA_HTTP_CONTEXT_HEADER ) informs coordinator that current participant is leaving the LRA. Method body is executed after leave signal is sent. As a result, participant methods complete and compensate won&#8217;t be called when the particular LRA ends. Header LRA_HTTP_CONTEXT_HEADER - ID of the LRA transaction <markup lang=\"java\" >@PUT @Path(\"/leave\") @Leave public Response leaveLRA(@HeaderParam(LRA_HTTP_CONTEXT_HEADER) URI lraIdtoLeave) @Status javadoc Expected to be called by LRA coordinator only! If the coordinator&#8217;s call to the participant&#8217;s method fails, then it will retry the call. If the participant is not idempotent, then it may need to report its state to coordinator by declaring method annotated with @Status for reporting if previous call did change participant status. Coordinator can call it and decide if compensate or complete retry is needed. JAX-RS variant with supported LRA context values: Header LRA_HTTP_CONTEXT_HEADER - ID of the LRA transaction ParticipantStatus - Status of the participant reported to coordinator <markup lang=\"java\" >@GET @Path(\"/status\") @Status public Response reportStatus(@HeaderParam(LRA_HTTP_CONTEXT_HEADER) URI lraId) { return Response.status(ParticipantStatus.FailedToCompensate).build(); } Non JAX-RS variant with supported LRA context values: URI with LRA ID ParticipantStatus - Status of the participant reported to coordinator <markup lang=\"java\" >@Status public Response reportStatus(URI lraId){ return Response.ok(ParticipantStatus.FailedToCompensate).build(); } @AfterLRA javadoc Expected to be called by LRA coordinator only! Method annotated with @AfterLRA in the same class as the one with @LRA annotation gets invoked after particular LRA finishes. JAX-RS variant with supported LRA context values: Header LRA_HTTP_ENDED_CONTEXT_HEADER - ID of the finished LRA transaction Header LRA_HTTP_PARENT_CONTEXT_HEADER - parent LRA ID in case of nested LRA LRAStatus - Final status of the LRA ( Cancelled , Closed , FailedToCancel , FailedToClose ) <markup lang=\"java\" >@PUT @Path(\"/finished\") @AfterLRA public Response whenLRAFinishes(@HeaderParam(LRA_HTTP_ENDED_CONTEXT_HEADER) URI lraId, @HeaderParam(LRA_HTTP_PARENT_CONTEXT_HEADER) URI parentLraId, LRAStatus status) Non JAX-RS variant with supported LRA context values: URI with finished LRA ID LRAStatus - Final status of the LRA ( Cancelled , Closed , FailedToCancel , FailedToClose ) <markup lang=\"java\" >public void whenLRAFinishes(URI lraId, LRAStatus status) ",
            "title": "API"
        },
        {
            "location": "mp/lra",
            "text": "<markup lang=\"text\" title=\"Type\" >io.helidon.microprofile.lra Optional configuration options: Key Type Default value Description mp.lra.coordinator.url string http://localhost:8070/lra-coordinator Url of coordinator. mp.lra.coordinator.propagation.active boolean &#160; Propagate LRA headers LRA_HTTP_CONTEXT_HEADER and LRA_HTTP_PARENT_CONTEXT_HEADER through non-LRA endpoints. mp.lara.participant.url string &#160; Url of the LRA enabled service overrides standard base uri, so coordinator can call load-balancer instead of the service. mp.lra.coordinator.timeout string &#160; Timeout for synchronous communication with coordinator. mp.lra.coordinator.timeout-unit string &#160; Timeout unit for synchronous communication with coordinator. <markup lang=\"yaml\" title=\"Example of LRA configuration\" >mp.lra: coordinator.url: http://localhost:8070/lra-coordinator propagation.active: true participant.url: http://coordinator.visible.host:80/awesomeapp Url of coordinator Propagate LRA headers LRA_HTTP_CONTEXT_HEADER and LRA_HTTP_PARENT_CONTEXT_HEADER through non-LRA endpoints Url of the LRA enabled service overrides standard base uri, so coordinator can call load-balancer instead of the service For more information continue to {microprofile-lra-spec-url}[MicroProfile Long Running Actions specification]. ",
            "title": "Configuration"
        },
        {
            "location": "mp/lra",
            "text": " The following example shows how a simple LRA participant starts and joins a transaction after calling the '/start-example' resource. When startExample method finishes successfully, close is reported to coordinator and /complete-example endpoint is called by coordinator to confirm successful closure of the LRA. If an exception occurs during startExample method execution, coordinator receives cancel call and /compensate-example is called by coordinator to compensate for cancelled LRA transaction. <markup lang=\"java\" title=\"Example of simple LRA participant\" >@PUT @LRA(LRA.Type.REQUIRES_NEW) @Path(\"start-example\") public Response startExample(@HeaderParam(LRA_HTTP_CONTEXT_HEADER) URI lraId, String data) { if (data.contains(\"BOOM\")) { throw new RuntimeException(\"BOOM 💥\"); } LOGGER.info(\"Data \" + data + \" processed 🏭\"); return Response.ok().build(); } @PUT @Complete @Path(\"complete-example\") public Response completeExample(@HeaderParam(LRA_HTTP_CONTEXT_HEADER) URI lraId) { LOGGER.log(Level.INFO, \"LRA ID: {0} completed 🎉\", lraId); return LRAResponse.completed(); } @PUT @Compensate @Path(\"compensate-example\") public Response compensateExample(@HeaderParam(LRA_HTTP_CONTEXT_HEADER) URI lraId) { LOGGER.log(Level.SEVERE, \"LRA ID: {0} compensated 🦺\", lraId); return LRAResponse.compensated(); } This JAX-RS PUT method will start new LRA transactions and join it before method body gets executed LRA ID assigned by coordinator to this LRA transaction When method execution finishes exceptionally, cancel signal for this particular LRA is sent to coordinator When method execution finishes successfully, complete signal for this particular LRA is sent to coordinator Method which will be called by coordinator when LRA is completed Method which will be called by coordinator when LRA is canceled ",
            "title": "Examples"
        },
        {
            "location": "mp/lra",
            "text": " Coordinator is a service that tracks all LRA transactions and calls the compensate REST endpoints of the participants when the LRA transaction gets cancelled or completes (in case it gets closed). In addition, participant also keeps track of timeouts, retries participant calls, and assigns LRA ids. Helidon LRA coordinator Narayana coordinator . ",
            "title": "Coordinator"
        },
        {
            "location": "mp/lra",
            "text": " Experimental tool, usage in production is not advised. <markup lang=\"bash\" title=\"Build and run Helidon LRA coordinator\" >docker build -t helidon/lra-coordinator https://github.com/oracle/helidon.git#:lra/coordinator/server docker run -dp 8070:8070 --name lra-coordinator --network=\"host\" helidon/lra-coordinator Helidon LRA coordinator is compatible with Narayana clients, you need to add an additional dependency for Narayana client: <markup lang=\"xml\" title=\"Dependency needed for using Helidon LRA with Narayana compatible coordinator\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.lra&lt;/groupId&gt; &lt;artifactId&gt;helidon-lra-coordinator-narayana-client&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Helidon LRA coordinator"
        },
        {
            "location": "mp/lra",
            "text": " Narayana is a transaction manager supporting LRA. To use Narayana LRA coordinator with Helidon LRA client you need to add an additional dependency for Narayana client: <markup lang=\"xml\" title=\"Dependency needed for using Helidon LRA with Narayana coordinator\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.lra&lt;/groupId&gt; &lt;artifactId&gt;helidon-lra-coordinator-narayana-client&lt;/artifactId&gt; &lt;/dependency&gt; The simplest way to run Narayana LRA coordinator locally: <markup lang=\"bash\" title=\"Downloading and running Narayana LRA coordinator\" >wget https://search.maven.org/remotecontent?filepath=org/jboss/narayana/rts/lra-coordinator-quarkus/5.11.1.Final/lra-coordinator-quarkus-5.11.1.Final-runner.jar \\ -O narayana-coordinator.jar \\ &amp;&amp; java -Dquarkus.http.port=8070 -jar narayana-coordinator.jar Narayana LRA coordinator is running by default under lra-coordinator context, with port 8070 defined in the snippet above you need to configure your Helidon LRA app as follows: mp.lra.coordinator.url=http://localhost:8070/lra-coordinator ",
            "title": "Narayana"
        },
        {
            "location": "mp/lra",
            "text": " Coordinator Coordinator is a service that tracks all LRA transactions and calls the compensate REST endpoints of the participants when the LRA transaction gets cancelled or completes (in case it gets closed). In addition, participant also keeps track of timeouts, retries participant calls, and assigns LRA ids. Helidon LRA coordinator Narayana coordinator . Helidon LRA coordinator Experimental tool, usage in production is not advised. <markup lang=\"bash\" title=\"Build and run Helidon LRA coordinator\" >docker build -t helidon/lra-coordinator https://github.com/oracle/helidon.git#:lra/coordinator/server docker run -dp 8070:8070 --name lra-coordinator --network=\"host\" helidon/lra-coordinator Helidon LRA coordinator is compatible with Narayana clients, you need to add an additional dependency for Narayana client: <markup lang=\"xml\" title=\"Dependency needed for using Helidon LRA with Narayana compatible coordinator\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.lra&lt;/groupId&gt; &lt;artifactId&gt;helidon-lra-coordinator-narayana-client&lt;/artifactId&gt; &lt;/dependency&gt; Narayana Narayana is a transaction manager supporting LRA. To use Narayana LRA coordinator with Helidon LRA client you need to add an additional dependency for Narayana client: <markup lang=\"xml\" title=\"Dependency needed for using Helidon LRA with Narayana coordinator\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.lra&lt;/groupId&gt; &lt;artifactId&gt;helidon-lra-coordinator-narayana-client&lt;/artifactId&gt; &lt;/dependency&gt; The simplest way to run Narayana LRA coordinator locally: <markup lang=\"bash\" title=\"Downloading and running Narayana LRA coordinator\" >wget https://search.maven.org/remotecontent?filepath=org/jboss/narayana/rts/lra-coordinator-quarkus/5.11.1.Final/lra-coordinator-quarkus-5.11.1.Final-runner.jar \\ -O narayana-coordinator.jar \\ &amp;&amp; java -Dquarkus.http.port=8070 -jar narayana-coordinator.jar Narayana LRA coordinator is running by default under lra-coordinator context, with port 8070 defined in the snippet above you need to configure your Helidon LRA app as follows: mp.lra.coordinator.url=http://localhost:8070/lra-coordinator ",
            "title": "Additional Information"
        },
        {
            "location": "mp/lra",
            "text": " MicroProfile LRA GitHub Repository {microprofile-lra-spec-url}[MicroProfile Long Running Actions specification] Microprofile LRA JavaDoc Helidon LRA Client JavaDoc ",
            "title": "Reference"
        },
        {
            "location": "mp/metrics/metrics-capable-components",
            "text": " Overview Usage Examples ",
            "title": "Contents"
        },
        {
            "location": "mp/metrics/metrics-capable-components",
            "text": " The Helidon metrics API This API allows your code to register, look-up, remove, and update metrics using the RegistryFactory , MetricRegistry , and individual metrics interfaces. The Helidon metrics REST service API This API allows your code to set up and respond to the /metrics endpoint so clients can retreive metrics information. ",
            "title": "APIs"
        },
        {
            "location": "mp/metrics/metrics-capable-components",
            "text": " Implementations of the Helidon metrics API. Helidon provides two&#8212;&#8203;minimal and full-featured&#8212;&#8203;and selects which one to use at runtime, based on what components are present on the runtime path and whether metrics is configured to be enabled or disabled. By default, Helidon MP services use the full-featured implementation. Implementations of the Helidon metrics REST service API. Helidon provides two&#8212;&#8203;minimal and full-featured&#8212;&#8203;and selects which one to use at runtime. By default, Helidon MP apps which use metrics use the full-featured metrics REST service by default. As you plan and write Helidon components and applications, you make some choices about exactly how your code will use metrics. This document gives some background information, describes each option and its effect, and provides some code examples. ",
            "title": "Implementations of the APIs"
        },
        {
            "location": "mp/metrics/metrics-capable-components",
            "text": " This document explains Helidon MP metrics-capable components and applications and describes how to create and control them. Think of Helidon metrics in several related but different parts: APIs The Helidon metrics API This API allows your code to register, look-up, remove, and update metrics using the RegistryFactory , MetricRegistry , and individual metrics interfaces. The Helidon metrics REST service API This API allows your code to set up and respond to the /metrics endpoint so clients can retreive metrics information. Implementations of the APIs Implementations of the Helidon metrics API. Helidon provides two&#8212;&#8203;minimal and full-featured&#8212;&#8203;and selects which one to use at runtime, based on what components are present on the runtime path and whether metrics is configured to be enabled or disabled. By default, Helidon MP services use the full-featured implementation. Implementations of the Helidon metrics REST service API. Helidon provides two&#8212;&#8203;minimal and full-featured&#8212;&#8203;and selects which one to use at runtime. By default, Helidon MP apps which use metrics use the full-featured metrics REST service by default. As you plan and write Helidon components and applications, you make some choices about exactly how your code will use metrics. This document gives some background information, describes each option and its effect, and provides some code examples. ",
            "title": "Overview"
        },
        {
            "location": "mp/metrics/metrics-capable-components",
            "text": " We can place each Helidon component and Helidon application into one of three categories based on how it relies on metrics. The type of module dictates the compile-time dependency you declare in the project pom.xml . Types of Metrics Usage Registers, updates, removes metrics? Refers to metrics values? Category times times metrics-independent check times metrics-capable check check metrics-dependent Whenever possible, if your component or application uses metrics, then write it as metrics-capable code. ",
            "title": "Categorizing Metrics Usage"
        },
        {
            "location": "mp/metrics/metrics-capable-components",
            "text": " Helidon provides two metrics implementations: Full-featured metrics allows registering, removing, and updating metrics and observing metrics' changing values. The helidon-metrics component contains full-featured metrics. Minimal metrics supports registering, removing, and updating metrics. The metrics objects provided by the minimal implementation are no-ops: their values never change. The minimal implementation is part of the helidon-metrics-api component. Any code compiled with helidon-metrics-api can assume that the runtime path will include the minimal implementation. Both implementations support all the operations of the RegistryFactory and the MetricRegistry . The full implementation provides fully-functional metrics instances (counters, timers, etc.). In the minimal implementations, metrics do not update their values. For Helidon to use the full implementation, two conditions must hold: The helidon-metrics component must be on the runtime path. Metrics must be enabled, using either a builder or configuration. (Enabled is the default.) Otherwise, provided that the runtime path includes helidon-metrics-api , Helidon activates the minimal implementation. ",
            "title": "Understanding the Two Metrics Implementations"
        },
        {
            "location": "mp/metrics/metrics-capable-components",
            "text": " Helidon includes two implementations of support for the metrics web service endpoint /metrics (or whatever context value is configured). The full-service implementation sends responses which describe the metadata and current values for the metrics registered in metric registries. The helidon-metrics component contains this implementation. The helidon-metrics-service-api component contains the API for the metrics web service support (the MetricsSupport interface) and also a minimal implementation. This implementation simply responds with 404 and an explanatory message that metrics are disabled. Any code compiled with helidon-metrics-service-api can assume that the runtime path will contain the minimal implementation. Helidon activates the full implementation if the runtime path includes the full implementation and metrics is configured as enabled; Helidon uses the minimal implementation otherwise. ",
            "title": "Understanding the Two Metrics Service Implementations"
        },
        {
            "location": "mp/metrics/metrics-capable-components",
            "text": " Using configuration, your component can let end users control at runtime whether Helidon should use full-featured metrics. If an end user sets metrics.enabled to false , then Helidon activates the minimal metrics and metrics service implementations provided they are in the runtime path. Further, users can set component-name.metrics.enabled to false which disables metrics for just that component so long as the component was written to check that setting and act on it accordingly. ",
            "title": "Enabling and Disabling Metrics"
        },
        {
            "location": "mp/metrics/metrics-capable-components",
            "text": " Include this dependency: <markup lang=\"xml\" title=\"Dependency for Helidon metrics API\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics-api&lt;/artifactId&gt; &lt;/dependency&gt; This module defines the metrics API: RegistryFactory , MetricRegistry , and the various metrics themselves. Declare an explicit runtime dependency on the full-featured metrics implementation: <markup lang=\"xml\" title=\"Dependency for full metrics and metrics service implementations\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; ",
            "title": "Declaring Dependencies"
        },
        {
            "location": "mp/metrics/metrics-capable-components",
            "text": " Whoever packages and deploys your application or component can control what code will be on the runtime path and whether metrics is enabled or not. As a result, wherever possible, construct your modules which use metrics so that they do not make decisions based on the values of metrics; that is, design them to be metrics-capable, not metrics-dependent. Doing so allows your code to operate regardless of whether the full-featured metrics implementation is active at runtime. Declaring Dependencies Include this dependency: <markup lang=\"xml\" title=\"Dependency for Helidon metrics API\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics-api&lt;/artifactId&gt; &lt;/dependency&gt; This module defines the metrics API: RegistryFactory , MetricRegistry , and the various metrics themselves. Declare an explicit runtime dependency on the full-featured metrics implementation: <markup lang=\"xml\" title=\"Dependency for full metrics and metrics service implementations\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; ",
            "title": "Designing and Writing Metrics-capable Applications and Components"
        },
        {
            "location": "mp/metrics/metrics-capable-components",
            "text": " When your MP application code uses @Inject for either a RegistryFactory or a MetricRegistry , Helidon injects either the full-featured instance or the minimal instance according to whether the runtime path includes the full implementation and, if so, whether metrics is enabled. By choosing and injecting the appropriate implementation, Helidon allows you to write your code without concern for which implementation is available at runtime. ",
            "title": "Writing a Helidon MP Application"
        },
        {
            "location": "mp/metrics/metrics-capable-components",
            "text": " The Helidon MP metrics implementation depends on the metrics and metrics service APIs as well as helidon-metrics which contains the full implementation of each. Therefore, by default, Helidon MP applications have full-featured metrics and endpoint support. Application code can @Inject the RegistryFactory and MetricRegistry instances. Helidon MP itself uses metrics settings in the configuration to make the correct RegistryFactory and MetricRegistry instances available at injection sites. Helidon&#8217;s MicroProfile metrics component helidon-microprofile-metrics has its own runtime dependency on the minimal implementation, so that implementation, at least, is available at runtime. By default, Helidon MP applications use the full implementation, because Helidon&#8217;s MP metrics depends also on the full metrics implementation. That said, a developer of a Helidon MP app can explicitly exclude the dependency on the full implementation: <markup lang=\"xml\" title=\"Explicit exclusion of helidon-metrics \" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.bundles&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; In the resulting Helidon MP application, Helidon will use the minimal metrics and metrics support implementations. ",
            "title": "Packaging a Metrics-capable Helidon MP Application "
        },
        {
            "location": "mp/metrics/metrics-capable-components",
            "text": " Write your non-application component to accept component-specific configuration that includes an optional metrics section which can include an optional enabled setting. Helidon defaults the value to true . The following example shows one way to accomplish this: <markup lang=\"java\" title=\"Example code to support disabling metrics usage in a component\" >import io.helidon.config.Config; import io.helidon.metrics.api.ComponentMetricsSettings; import io.helidon.metrics.api.MetricsSettings; import io.helidon.metrics.api.RegistryFactory; import org.eclipse.microprofile.metrics.MetricRegistry; public class UtilComponent { private final MetricRegistry metricRegistry; public static class Builder implements io.helidon.common.Builder&lt;UtilComponent&gt; { private ComponentMetricsSettings.Builder componentMetricsSettingsBuilder = ComponentMetricsSettings.builder(); public Builder componentMetricsSettings(ComponentMetricsSettings.Builder componentMetricsSettingsBuilder) { this.componentMetricsSettingsBuilder = componentMetricsSettingsBuilder; return this; } public Builder config(Config componentConfig) { componentConfig .get(ComponentMetricsSettings.Builder.METRICS_CONFIG_KEY) .as(ComponentMetricsSettings::create) .ifPresent(this::componentMetricsSettings); return this; } public UtilComponent build() { return new UtilComponent(this); } } private UtilComponent(Builder builder) { metricRegistry = RegistryFactory .getInstance(builder.componentMetricsSettingsBuilder.build()) .getRegistry(MetricRegistry.Type.VENDOR); } MetricRegistry metricRegistry() { return metricRegistry; } } Other code in the component uses this metric registry for registering, looking up, and removing metrics. Applications which use instances of MyComponent use this Builder to set up and create those instances. Applications which layer on your component invoke this method to set up the component-level metrics behavior they want your component to use. If an application supports configuration, it passes the util config to this method. The constructor for your component obtains the MetricRegistry which the rest of your component will use. Provides easy access to the MetricRegistry which the component&#8217;s metrics code should use. Helidon returns either a full-featured RegistryFactory or a minimal one, depending on: whether the full-featured metrics implementation is on the runtime path, whether metrics overall is enabled or disabled, and whether the component metrics settings requests enabled or disabled metrics. ",
            "title": "Writing a Non-application Component "
        },
        {
            "location": "mp/metrics/metrics-capable-components",
            "text": " The way you write a metrics-capable module depends on whether it is a component (that is, not an application) or an application . Writing a Helidon MP Application When your MP application code uses @Inject for either a RegistryFactory or a MetricRegistry , Helidon injects either the full-featured instance or the minimal instance according to whether the runtime path includes the full implementation and, if so, whether metrics is enabled. By choosing and injecting the appropriate implementation, Helidon allows you to write your code without concern for which implementation is available at runtime. Packaging a Metrics-capable Helidon MP Application The Helidon MP metrics implementation depends on the metrics and metrics service APIs as well as helidon-metrics which contains the full implementation of each. Therefore, by default, Helidon MP applications have full-featured metrics and endpoint support. Application code can @Inject the RegistryFactory and MetricRegistry instances. Helidon MP itself uses metrics settings in the configuration to make the correct RegistryFactory and MetricRegistry instances available at injection sites. Helidon&#8217;s MicroProfile metrics component helidon-microprofile-metrics has its own runtime dependency on the minimal implementation, so that implementation, at least, is available at runtime. By default, Helidon MP applications use the full implementation, because Helidon&#8217;s MP metrics depends also on the full metrics implementation. That said, a developer of a Helidon MP app can explicitly exclude the dependency on the full implementation: <markup lang=\"xml\" title=\"Explicit exclusion of helidon-metrics \" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.bundles&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; In the resulting Helidon MP application, Helidon will use the minimal metrics and metrics support implementations. Writing a Non-application Component Write your non-application component to accept component-specific configuration that includes an optional metrics section which can include an optional enabled setting. Helidon defaults the value to true . The following example shows one way to accomplish this: <markup lang=\"java\" title=\"Example code to support disabling metrics usage in a component\" >import io.helidon.config.Config; import io.helidon.metrics.api.ComponentMetricsSettings; import io.helidon.metrics.api.MetricsSettings; import io.helidon.metrics.api.RegistryFactory; import org.eclipse.microprofile.metrics.MetricRegistry; public class UtilComponent { private final MetricRegistry metricRegistry; public static class Builder implements io.helidon.common.Builder&lt;UtilComponent&gt; { private ComponentMetricsSettings.Builder componentMetricsSettingsBuilder = ComponentMetricsSettings.builder(); public Builder componentMetricsSettings(ComponentMetricsSettings.Builder componentMetricsSettingsBuilder) { this.componentMetricsSettingsBuilder = componentMetricsSettingsBuilder; return this; } public Builder config(Config componentConfig) { componentConfig .get(ComponentMetricsSettings.Builder.METRICS_CONFIG_KEY) .as(ComponentMetricsSettings::create) .ifPresent(this::componentMetricsSettings); return this; } public UtilComponent build() { return new UtilComponent(this); } } private UtilComponent(Builder builder) { metricRegistry = RegistryFactory .getInstance(builder.componentMetricsSettingsBuilder.build()) .getRegistry(MetricRegistry.Type.VENDOR); } MetricRegistry metricRegistry() { return metricRegistry; } } Other code in the component uses this metric registry for registering, looking up, and removing metrics. Applications which use instances of MyComponent use this Builder to set up and create those instances. Applications which layer on your component invoke this method to set up the component-level metrics behavior they want your component to use. If an application supports configuration, it passes the util config to this method. The constructor for your component obtains the MetricRegistry which the rest of your component will use. Provides easy access to the MetricRegistry which the component&#8217;s metrics code should use. Helidon returns either a full-featured RegistryFactory or a minimal one, depending on: whether the full-featured metrics implementation is on the runtime path, whether metrics overall is enabled or disabled, and whether the component metrics settings requests enabled or disabled metrics. ",
            "title": "Writing Metrics-capable Code"
        },
        {
            "location": "mp/metrics/metrics-capable-components",
            "text": " This section helps you decide how incorporate metrics into your software by describing the categories of metrics usage, explaining generally how Helidon implements metrics, and illustrating how to write the metrics-related code accordingly. Categorizing Metrics Usage We can place each Helidon component and Helidon application into one of three categories based on how it relies on metrics. The type of module dictates the compile-time dependency you declare in the project pom.xml . Types of Metrics Usage Registers, updates, removes metrics? Refers to metrics values? Category times times metrics-independent check times metrics-capable check check metrics-dependent Whenever possible, if your component or application uses metrics, then write it as metrics-capable code. Understanding the Two Metrics Implementations Helidon provides two metrics implementations: Full-featured metrics allows registering, removing, and updating metrics and observing metrics' changing values. The helidon-metrics component contains full-featured metrics. Minimal metrics supports registering, removing, and updating metrics. The metrics objects provided by the minimal implementation are no-ops: their values never change. The minimal implementation is part of the helidon-metrics-api component. Any code compiled with helidon-metrics-api can assume that the runtime path will include the minimal implementation. Both implementations support all the operations of the RegistryFactory and the MetricRegistry . The full implementation provides fully-functional metrics instances (counters, timers, etc.). In the minimal implementations, metrics do not update their values. For Helidon to use the full implementation, two conditions must hold: The helidon-metrics component must be on the runtime path. Metrics must be enabled, using either a builder or configuration. (Enabled is the default.) Otherwise, provided that the runtime path includes helidon-metrics-api , Helidon activates the minimal implementation. Understanding the Two Metrics Service Implementations Helidon includes two implementations of support for the metrics web service endpoint /metrics (or whatever context value is configured). The full-service implementation sends responses which describe the metadata and current values for the metrics registered in metric registries. The helidon-metrics component contains this implementation. The helidon-metrics-service-api component contains the API for the metrics web service support (the MetricsSupport interface) and also a minimal implementation. This implementation simply responds with 404 and an explanatory message that metrics are disabled. Any code compiled with helidon-metrics-service-api can assume that the runtime path will contain the minimal implementation. Helidon activates the full implementation if the runtime path includes the full implementation and metrics is configured as enabled; Helidon uses the minimal implementation otherwise. Enabling and Disabling Metrics Using configuration, your component can let end users control at runtime whether Helidon should use full-featured metrics. If an end user sets metrics.enabled to false , then Helidon activates the minimal metrics and metrics service implementations provided they are in the runtime path. Further, users can set component-name.metrics.enabled to false which disables metrics for just that component so long as the component was written to check that setting and act on it accordingly. Designing and Writing Metrics-capable Applications and Components Whoever packages and deploys your application or component can control what code will be on the runtime path and whether metrics is enabled or not. As a result, wherever possible, construct your modules which use metrics so that they do not make decisions based on the values of metrics; that is, design them to be metrics-capable, not metrics-dependent. Doing so allows your code to operate regardless of whether the full-featured metrics implementation is active at runtime. Declaring Dependencies Include this dependency: <markup lang=\"xml\" title=\"Dependency for Helidon metrics API\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics-api&lt;/artifactId&gt; &lt;/dependency&gt; This module defines the metrics API: RegistryFactory , MetricRegistry , and the various metrics themselves. Declare an explicit runtime dependency on the full-featured metrics implementation: <markup lang=\"xml\" title=\"Dependency for full metrics and metrics service implementations\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; Writing Metrics-capable Code The way you write a metrics-capable module depends on whether it is a component (that is, not an application) or an application . Writing a Helidon MP Application When your MP application code uses @Inject for either a RegistryFactory or a MetricRegistry , Helidon injects either the full-featured instance or the minimal instance according to whether the runtime path includes the full implementation and, if so, whether metrics is enabled. By choosing and injecting the appropriate implementation, Helidon allows you to write your code without concern for which implementation is available at runtime. Packaging a Metrics-capable Helidon MP Application The Helidon MP metrics implementation depends on the metrics and metrics service APIs as well as helidon-metrics which contains the full implementation of each. Therefore, by default, Helidon MP applications have full-featured metrics and endpoint support. Application code can @Inject the RegistryFactory and MetricRegistry instances. Helidon MP itself uses metrics settings in the configuration to make the correct RegistryFactory and MetricRegistry instances available at injection sites. Helidon&#8217;s MicroProfile metrics component helidon-microprofile-metrics has its own runtime dependency on the minimal implementation, so that implementation, at least, is available at runtime. By default, Helidon MP applications use the full implementation, because Helidon&#8217;s MP metrics depends also on the full metrics implementation. That said, a developer of a Helidon MP app can explicitly exclude the dependency on the full implementation: <markup lang=\"xml\" title=\"Explicit exclusion of helidon-metrics \" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.bundles&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; In the resulting Helidon MP application, Helidon will use the minimal metrics and metrics support implementations. Writing a Non-application Component Write your non-application component to accept component-specific configuration that includes an optional metrics section which can include an optional enabled setting. Helidon defaults the value to true . The following example shows one way to accomplish this: <markup lang=\"java\" title=\"Example code to support disabling metrics usage in a component\" >import io.helidon.config.Config; import io.helidon.metrics.api.ComponentMetricsSettings; import io.helidon.metrics.api.MetricsSettings; import io.helidon.metrics.api.RegistryFactory; import org.eclipse.microprofile.metrics.MetricRegistry; public class UtilComponent { private final MetricRegistry metricRegistry; public static class Builder implements io.helidon.common.Builder&lt;UtilComponent&gt; { private ComponentMetricsSettings.Builder componentMetricsSettingsBuilder = ComponentMetricsSettings.builder(); public Builder componentMetricsSettings(ComponentMetricsSettings.Builder componentMetricsSettingsBuilder) { this.componentMetricsSettingsBuilder = componentMetricsSettingsBuilder; return this; } public Builder config(Config componentConfig) { componentConfig .get(ComponentMetricsSettings.Builder.METRICS_CONFIG_KEY) .as(ComponentMetricsSettings::create) .ifPresent(this::componentMetricsSettings); return this; } public UtilComponent build() { return new UtilComponent(this); } } private UtilComponent(Builder builder) { metricRegistry = RegistryFactory .getInstance(builder.componentMetricsSettingsBuilder.build()) .getRegistry(MetricRegistry.Type.VENDOR); } MetricRegistry metricRegistry() { return metricRegistry; } } Other code in the component uses this metric registry for registering, looking up, and removing metrics. Applications which use instances of MyComponent use this Builder to set up and create those instances. Applications which layer on your component invoke this method to set up the component-level metrics behavior they want your component to use. If an application supports configuration, it passes the util config to this method. The constructor for your component obtains the MetricRegistry which the rest of your component will use. Provides easy access to the MetricRegistry which the component&#8217;s metrics code should use. Helidon returns either a full-featured RegistryFactory or a minimal one, depending on: whether the full-featured metrics implementation is on the runtime path, whether metrics overall is enabled or disabled, and whether the component metrics settings requests enabled or disabled metrics. ",
            "title": "Usage"
        },
        {
            "location": "mp/metrics/metrics-capable-components",
            "text": " The following example shows how useful metrics-capable code can be in the context of building Docker images. You (or others) could assemble a Docker image with your metrics-capable app as its top layer or your metrics-capable component in a middle layer, built on a lower layer containing several Helidon modules including the full metrics implementation. When that Docker image runs, your app will run with full-featured metrics support. Separately, someone could build a similar Docker image which does not include the Helidon metrics implementation. In this Docker image, your app or component will run successfully but will not incur the overhead of actually updating the metrics it uses. Users can create different Docker images, some with full metrics support and some without, which all use a single version of your metrics-capable app or component which runs properly in either environment without change. ",
            "title": "Examples"
        },
        {
            "location": "mp/metrics/metrics-capable-components",
            "text": " By writing a metrics-capable app or component, you give packagers and deployers of your code the flexibility to include or exclude the full metrics implementation at runtime as they see fit. Because your one module works correctly in either environment: The consumers of your app benefit by not needing to understand and choose between two different implementations of your module, or having to add both your main module and an optional add-on which adds metrics support to your module. You benefit by writing and maintaining a single module, not two: one that is metrics-independent and one that is metrics-dependent. ",
            "title": "Advantages of Writing Metrics-capable Modules"
        },
        {
            "location": "mp/metrics/metrics-capable-components",
            "text": " Advantages of Writing Metrics-capable Modules By writing a metrics-capable app or component, you give packagers and deployers of your code the flexibility to include or exclude the full metrics implementation at runtime as they see fit. Because your one module works correctly in either environment: The consumers of your app benefit by not needing to understand and choose between two different implementations of your module, or having to add both your main module and an optional add-on which adds metrics support to your module. You benefit by writing and maintaining a single module, not two: one that is metrics-independent and one that is metrics-dependent. ",
            "title": "Additional Information"
        },
        {
            "location": "mp/metrics/metrics",
            "text": " Overview Maven Coordinates Usage API Configuration Examples Additional Information ",
            "title": "Contents"
        },
        {
            "location": "mp/metrics/metrics",
            "text": " Helidon MP metrics implements the MicroProfile Metrics specification, providing: a unified way for MicroProfile servers to export monitoring data&#8212;&#8203;telemetry&#8212;&#8203;to management agents, and a unified Java API which all application programmers can use to register and update metrics to expose telemetry data from their services. support for metrics-related annotations. Learn more about the MicroProfile Metrics specification . ",
            "title": "Overview"
        },
        {
            "location": "mp/metrics/metrics",
            "text": " Helidon gives you flexibility in how you make metrics available to your service. This document explains your options. ",
            "title": "Other packaging options"
        },
        {
            "location": "mp/metrics/metrics",
            "text": " To enable metrics add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-metrics&lt;/artifactId&gt; &lt;/dependency&gt; Adding this dependency packages the full-featured metrics implementation with your service. Other packaging options Helidon gives you flexibility in how you make metrics available to your service. This document explains your options. ",
            "title": "Maven Coordinates"
        },
        {
            "location": "mp/metrics/metrics",
            "text": " You add metrics to your service in these ways: Annotate bean methods&#8212;&#8203;typically your REST resource endpoint methods (the Java code that receives incoming REST requests); Helidon automatically registers these metrics and updates them when the annotated methods are invoked via CDI. Write code which explicitly invokes the metrics API to register metrics, retrieve previously-registered metrics, and update metric values. Configure some simple REST.request metrics which Helidon automatically registers and updates for all REST resource endpoints. Later sections of this document describe how to do each of these. ",
            "title": "Instrumenting Your Service"
        },
        {
            "location": "mp/metrics/metrics",
            "text": " Helidon distinguishes among three general types , or scopes, of metrics, as described in the MP metrics specification . Types (scopes) of metrics Type/scope Typical Usage base Mandated by the MP metrics specification, such as OS or Java runtime measurements (available heap, disk space, etc.). vendor Implemented by vendors, including the REST.request metrics and other key performance indicator measurements (described in later sections). application Declared via annotations or programmatically registered by your service code. When you add metrics annotations to your service code, Helidon registers the resulting metrics as type application . ",
            "title": "Categorizing Types of Metrics"
        },
        {
            "location": "mp/metrics/metrics",
            "text": " A metric registry collects registered metrics of a given type. Helidon supports three registries, one for each of the three metrics types. When you add code to your service to create a metric programmatically, the code first locates the appropriate registry and then registers the metric with that registry. ",
            "title": "Metric Registries"
        },
        {
            "location": "mp/metrics/metrics",
            "text": " When you add the metrics dependency to your project, Helidon automatically provides a built-in REST endpoint /metrics which responds with a report of the registered metrics and their values. Clients can request a particular output format. Formats for /metrics output Format Requested by OpenMetrics (Prometheus) default ( text/plain ) JSON Header Accept: application/json Clients can also limit the report by appending the metric type to the path: /metrics/base /metrics/vendor /metrics/application Further, clients can narrow down to a specific metric name by adding the name as a subpath such as /metrics/application/myCount . <markup lang=\"bash\" title=\"Example Reporting: Prometheus format\" >curl -s -H 'Accept: text/plain' -X GET http://localhost:8080/metrics/ # TYPE base:classloader_total_loaded_class_count counter # HELP base:classloader_total_loaded_class_count Displays the total number of classes that have been loaded since the Java virtual machine has started execution. base:classloader_total_loaded_class_count 3157 <markup lang=\"bash\" title=\"Example Reporting: JSON format\" >curl -s -H 'Accept: application/json' -X GET http://localhost:8080/metrics/ { \"base\" : { \"memory.maxHeap\" : 3817865216, \"memory.committedHeap\" : 335544320, } } In addition to your application metrics, the reports contain other metrics of interest such as system and VM information. ",
            "title": "Retrieving Metrics Reports from your Service"
        },
        {
            "location": "mp/metrics/metrics",
            "text": " Instrumenting Your Service You add metrics to your service in these ways: Annotate bean methods&#8212;&#8203;typically your REST resource endpoint methods (the Java code that receives incoming REST requests); Helidon automatically registers these metrics and updates them when the annotated methods are invoked via CDI. Write code which explicitly invokes the metrics API to register metrics, retrieve previously-registered metrics, and update metric values. Configure some simple REST.request metrics which Helidon automatically registers and updates for all REST resource endpoints. Later sections of this document describe how to do each of these. Categorizing Types of Metrics Helidon distinguishes among three general types , or scopes, of metrics, as described in the MP metrics specification . Types (scopes) of metrics Type/scope Typical Usage base Mandated by the MP metrics specification, such as OS or Java runtime measurements (available heap, disk space, etc.). vendor Implemented by vendors, including the REST.request metrics and other key performance indicator measurements (described in later sections). application Declared via annotations or programmatically registered by your service code. When you add metrics annotations to your service code, Helidon registers the resulting metrics as type application . Metric Registries A metric registry collects registered metrics of a given type. Helidon supports three registries, one for each of the three metrics types. When you add code to your service to create a metric programmatically, the code first locates the appropriate registry and then registers the metric with that registry. Retrieving Metrics Reports from your Service When you add the metrics dependency to your project, Helidon automatically provides a built-in REST endpoint /metrics which responds with a report of the registered metrics and their values. Clients can request a particular output format. Formats for /metrics output Format Requested by OpenMetrics (Prometheus) default ( text/plain ) JSON Header Accept: application/json Clients can also limit the report by appending the metric type to the path: /metrics/base /metrics/vendor /metrics/application Further, clients can narrow down to a specific metric name by adding the name as a subpath such as /metrics/application/myCount . <markup lang=\"bash\" title=\"Example Reporting: Prometheus format\" >curl -s -H 'Accept: text/plain' -X GET http://localhost:8080/metrics/ # TYPE base:classloader_total_loaded_class_count counter # HELP base:classloader_total_loaded_class_count Displays the total number of classes that have been loaded since the Java virtual machine has started execution. base:classloader_total_loaded_class_count 3157 <markup lang=\"bash\" title=\"Example Reporting: JSON format\" >curl -s -H 'Accept: application/json' -X GET http://localhost:8080/metrics/ { \"base\" : { \"memory.maxHeap\" : 3817865216, \"memory.committedHeap\" : 335544320, } } In addition to your application metrics, the reports contain other metrics of interest such as system and VM information. ",
            "title": "Usage"
        },
        {
            "location": "mp/metrics/metrics",
            "text": " The MicroProfile Metrics specification describes several metric types you can create using annotations, summarized in the following table: Metrics Annotations Annotation Usage @Counted Monotonically increasing count of events. @ConcurrentGauge Increasing and decreasing measurement of currently-executing blocks of code. @Gauge Access to a value managed by other code in the service. @Metered Count of invocations and how frequently invocations have occurred. @SimplyTimed Count of invocations and the total duration consumed by those invocations. @Timed Frequency of invocations and the distribution of how long the invocations take. Place annotations on constructors or methods to measure those specific executables. If you annotate the class instead, Helidon applies that annotation to all constructors and methods which the class declares. ",
            "title": "Metric-defining Annotations"
        },
        {
            "location": "mp/metrics/metrics",
            "text": " To get a reference to a specific metric, use a metric-referencing annotation in any bean, including your REST resource classes. You can @Inject a field of the correct type. Helidon uses the MicroProfile Metrics naming conventions to select which specific metric to inject. Use the @Metric annotation to control that selection. You can also add @Metric on a constructor or method parameter to trigger injection there. Helidon automatically looks up the metric referenced from any injection site and provides a reference to the metric. Your code then simply invokes methods on the injected metric. ",
            "title": "Metric-referencing Annotations"
        },
        {
            "location": "mp/metrics/metrics",
            "text": " You can very easily instrument your service and refer to registered metrics by annotating methods to be measured and injecting metrics which your code needs to observe. Metric-defining Annotations The MicroProfile Metrics specification describes several metric types you can create using annotations, summarized in the following table: Metrics Annotations Annotation Usage @Counted Monotonically increasing count of events. @ConcurrentGauge Increasing and decreasing measurement of currently-executing blocks of code. @Gauge Access to a value managed by other code in the service. @Metered Count of invocations and how frequently invocations have occurred. @SimplyTimed Count of invocations and the total duration consumed by those invocations. @Timed Frequency of invocations and the distribution of how long the invocations take. Place annotations on constructors or methods to measure those specific executables. If you annotate the class instead, Helidon applies that annotation to all constructors and methods which the class declares. Metric-referencing Annotations To get a reference to a specific metric, use a metric-referencing annotation in any bean, including your REST resource classes. You can @Inject a field of the correct type. Helidon uses the MicroProfile Metrics naming conventions to select which specific metric to inject. Use the @Metric annotation to control that selection. You can also add @Metric on a constructor or method parameter to trigger injection there. Helidon automatically looks up the metric referenced from any injection site and provides a reference to the metric. Your code then simply invokes methods on the injected metric. ",
            "title": "Metrics Annotations"
        },
        {
            "location": "mp/metrics/metrics",
            "text": " To register or look up metrics programmatically, your service code uses one of the three MetricRegistry instances (base, vendor, and application) which Helidon furnishes automatically. To get a MetricRegistry reference @Inject the metric registry you want, perhaps also using the @RegistryType annotation to select the registry type, or Get a Helidon RegistryFactory ; either @Inject RegistryFactory or Invoke one of the static getInstance methods on RegistryFactory Then invoke getRegistry on the RegistryFactory instance. The MetricRegistry allows your code to register new metrics, look up previously-registered metrics, and remove metrics. ",
            "title": "The MetricRegistry API"
        },
        {
            "location": "mp/metrics/metrics",
            "text": " The MicroProfile Metrics API prescribes all the standard interfaces related to metrics. This section summarizes a few key points about using that API and explains some Helidon-specific interfaces. Metrics Annotations You can very easily instrument your service and refer to registered metrics by annotating methods to be measured and injecting metrics which your code needs to observe. Metric-defining Annotations The MicroProfile Metrics specification describes several metric types you can create using annotations, summarized in the following table: Metrics Annotations Annotation Usage @Counted Monotonically increasing count of events. @ConcurrentGauge Increasing and decreasing measurement of currently-executing blocks of code. @Gauge Access to a value managed by other code in the service. @Metered Count of invocations and how frequently invocations have occurred. @SimplyTimed Count of invocations and the total duration consumed by those invocations. @Timed Frequency of invocations and the distribution of how long the invocations take. Place annotations on constructors or methods to measure those specific executables. If you annotate the class instead, Helidon applies that annotation to all constructors and methods which the class declares. Metric-referencing Annotations To get a reference to a specific metric, use a metric-referencing annotation in any bean, including your REST resource classes. You can @Inject a field of the correct type. Helidon uses the MicroProfile Metrics naming conventions to select which specific metric to inject. Use the @Metric annotation to control that selection. You can also add @Metric on a constructor or method parameter to trigger injection there. Helidon automatically looks up the metric referenced from any injection site and provides a reference to the metric. Your code then simply invokes methods on the injected metric. The MetricRegistry API To register or look up metrics programmatically, your service code uses one of the three MetricRegistry instances (base, vendor, and application) which Helidon furnishes automatically. To get a MetricRegistry reference @Inject the metric registry you want, perhaps also using the @RegistryType annotation to select the registry type, or Get a Helidon RegistryFactory ; either @Inject RegistryFactory or Invoke one of the static getInstance methods on RegistryFactory Then invoke getRegistry on the RegistryFactory instance. The MetricRegistry allows your code to register new metrics, look up previously-registered metrics, and remove metrics. ",
            "title": "API"
        },
        {
            "location": "mp/metrics/metrics",
            "text": " Optional configuration options key type default value description appName string &#160; Sets the value for the _app tag to be applied to all metrics. base BaseMetricsSettings &#160; Set the base metrics settings. cors CrossOriginConfig &#160; Sets the cross-origin config builder for use in establishing CORS support for the service endpoints. enabled boolean &#160; Sets whether metrics should be enabled. key-performance-indicators KeyPerformanceIndicatorMetricsSettings &#160; Set the KPI metrics settings. registries Map&lt;string, RegistrySettings&gt; &#160; Sets the registry settings for the specified registry type. routing string &#160; Sets the routing name to use for setting up the service&#8217;s endpoint. tags Map&lt;string, string&gt; &#160; Sets the global tags to be applied to all metrics. web-context string &#160; Sets the web context to use for the service&#8217;s endpoint. ",
            "title": "Configuration options"
        },
        {
            "location": "mp/metrics/metrics",
            "text": " To control how the Helidon metrics subsystem behaves, add a metrics section to your META-INF/microprofile-config.properties file. Type: io.helidon.metrics.serviceapi.MetricsSupport Configuration options Optional configuration options key type default value description appName string &#160; Sets the value for the _app tag to be applied to all metrics. base BaseMetricsSettings &#160; Set the base metrics settings. cors CrossOriginConfig &#160; Sets the cross-origin config builder for use in establishing CORS support for the service endpoints. enabled boolean &#160; Sets whether metrics should be enabled. key-performance-indicators KeyPerformanceIndicatorMetricsSettings &#160; Set the KPI metrics settings. registries Map&lt;string, RegistrySettings&gt; &#160; Sets the registry settings for the specified registry type. routing string &#160; Sets the routing name to use for setting up the service&#8217;s endpoint. tags Map&lt;string, string&gt; &#160; Sets the global tags to be applied to all metrics. web-context string &#160; Sets the web context to use for the service&#8217;s endpoint. ",
            "title": "Configuration"
        },
        {
            "location": "mp/metrics/metrics",
            "text": " The following example adds a new resource class, GreetingCards , to the Helidon MP QuickStart example. It shows how to use the @Counted annotation to track the number of times the /cards endpoint is called. <markup lang=\"java\" title=\"Create a new class GreetingCards with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import jakarta.enterprise.context.RequestScoped; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.annotation.Counted; @Path(\"/cards\") @RequestScoped public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"any-card\") public JsonObject anyCard() throws InterruptedException { return createResponse(\"Here are some random cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } } This class is annotated with Path which sets the path for this resource as /cards . The @RequestScoped annotation defines that this bean is request scoped. The request scope is active only for the duration of one web service invocation and it is destroyed at the end of that invocation. The annotation @Counted will register a Counter metric for this method, creating it if needed. The counter is incremented each time the anyCards method is called. The name attribute is optional. <markup lang=\"bash\" title=\"Build and run the application\" >mvn package java -jar target/helidon-quickstart-mp.jar <markup lang=\"base\" title=\"Access the application endpoints\" >curl http://localhost:8080/cards curl http://localhost:8080/cards curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response:\" >{ \"io.helidon.examples.quickstart.mp.GreetingCards.any-card\":2 } The any-card count is two, since you invoked the endpoint twice. Notice the counter name is fully qualified with the class and method names. You can remove the prefix by using the absolute=true field in the @Counted annotation. You must use absolute=false (the default) for class-level annotations. ",
            "title": "Adding Method-level Annotations"
        },
        {
            "location": "mp/metrics/metrics",
            "text": " The @ConcurrentGauge , @Timed`, @Metered , and @SimplyTimed annotations can also be used with a method. For the following example. you can just annotate the same method with @Metered and @Timed . These metrics collect significant information about the measured methods, but at a cost of some overhead and more complicated output. Use @SimplyTimed in cases where capturing the invocation count and the total elapsed time spent in a block of code is sufficient. Note that when using multiple annotations on a method, you must give the metrics different names as shown below (although they do not have to be absolute). <markup lang=\"java\" title=\"Update the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import jakarta.enterprise.context.RequestScoped; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.MetricUnits; import org.eclipse.microprofile.metrics.annotation.Counted; import org.eclipse.microprofile.metrics.annotation.Metered; import org.eclipse.microprofile.metrics.annotation.Timed; @Path(\"/cards\") @RequestScoped public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"cardCount\", absolute = true) @Metered(name = \"cardMeter\", absolute = true, unit = MetricUnits.MILLISECONDS) @Timed(name = \"cardTimer\", absolute = true, unit = MetricUnits.MILLISECONDS) public JsonObject anyCard() { return createResponse(\"Here are some random cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } } Specify a custom name for the Counter metric and set absolute=true to remove the path prefix from the name. Add the @Metered annotation to get a Meter metric. Add the @Timed annotation to get a Timer metric. <markup lang=\"bash\" title=\"Build and run the application\" >mvn package java -jar target/helidon-quickstart-mp.jar <markup lang=\"base\" title=\"Access the application endpoints\" >curl http://localhost:8080/cards curl http://localhost:8080/cards curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response:\" >{ \"cardCount\": 2, \"cardMeter\": { \"count\": 2, \"meanRate\": 0.15653506570241812, \"oneMinRate\": 0, \"fiveMinRate\": 0, \"fifteenMinRate\": 0 }, \"cardTimer\": { \"count\": 2, \"elapsedTime\": 2, \"meanRate\": 0.15651866263362785, \"oneMinRate\": 0, \"fiveMinRate\": 0, \"fifteenMinRate\": 0, \"min\": 0, \"max\": 2, \"mean\": 1.0506565, \"stddev\": 1.0405735, \"p50\": 2.09123, \"p75\": 2.09123, \"p95\": 2.09123, \"p98\": 2.09123, \"p99\": 2.09123, \"p999\": 2.09123 } } The Meter metric includes the count field (it is a superset of Counter ). The Timer metric includes the Meter fields (it is a superset of Meter ). ",
            "title": "Additional Method-level Metrics"
        },
        {
            "location": "mp/metrics/metrics",
            "text": " You can collect metrics at the class-level to aggregate data from all methods in that class using the same metric. The following example introduces a metric to count all card queries. In the following example, the method-level metrics are not needed to aggregate the counts, but they are left in the example to demonstrate the combined output of all three metrics. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import jakarta.enterprise.context.RequestScoped; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.annotation.Counted; @Path(\"/cards\") @RequestScoped @Counted(name = \"totalCards\") public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) @Counted(absolute = true) public JsonObject anyCard() throws InterruptedException { return createResponse(\"Here are some random cards ...\"); } @Path(\"/birthday\") @GET @Produces(MediaType.APPLICATION_JSON) @Counted(absolute = true) public JsonObject birthdayCard() throws InterruptedException { return createResponse(\"Here are some birthday cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } } This class is annotated with @Counted , which aggregates count data from all the method that have a Count annotation. Use absolute=true to remove path prefix for method-level annotations. Add a method with a Counter metric to get birthday cards. <markup lang=\"bash\" title=\"Build and run the application\" >mvn package java -jar target/helidon-quickstart-mp.jar <markup lang=\"bash\" title=\"Access the application endpoints\" >curl http://localhost:8080/cards curl http://localhost:8080/cards/birthday curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response from /metrics/application :\" >{ \"anyCard\": 1, \"birthdayCard\": 1, \"io.helidon.examples.quickstart.mp.totalCards.GreetingCards\": 2 } The totalCards count is a total of all the method-level Counter metrics. Class level metric names are always fully qualified. ",
            "title": "Class-level Metrics"
        },
        {
            "location": "mp/metrics/metrics",
            "text": " Field level metrics can be injected into managed objects, but they need to be updated by the application code. This annotation can be used on fields of type Meter , Timer , Counter , and Histogram . The following example shows how to use a field-level Counter metric to track cache hits. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import java.util.Random; import jakarta.enterprise.context.RequestScoped; import jakarta.inject.Inject; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.Counter; import org.eclipse.microprofile.metrics.annotation.Counted; import org.eclipse.microprofile.metrics.annotation.Metric; @Path(\"/cards\") @RequestScoped @Counted(name = \"totalCards\") public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @Inject @Metric(name = \"cacheHits\", absolute = true) private Counter cacheHits; @GET @Produces(MediaType.APPLICATION_JSON) @Counted(absolute = true) public JsonObject anyCard() throws InterruptedException { updateStats(); return createResponse(\"Here are some random cards ...\"); } @Path(\"/birthday\") @GET @Produces(MediaType.APPLICATION_JSON) @Counted(absolute = true) public JsonObject birthdayCard() throws InterruptedException { updateStats(); return createResponse(\"Here are some birthday cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } private void updateStats() { if (new Random().nextInt(3) == 1) { cacheHits.inc(); } } } A Counter metric field, cacheHits , is automatically injected by Helidon. Call updateStats() to update the cache hits. Call updateStats() to update the cache hits. Randomly increment the cacheHits counter. <markup lang=\"bash\" title=\"Build and run the application, then invoke the following endpoints:\" >curl http://localhost:8080/cards curl http://localhost:8080/cards curl http://localhost:8080/cards/birthday curl http://localhost:8080/cards/birthday curl http://localhost:8080/cards/birthday curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response from /metrics/application :\" >{ \"anyCard\": 2, \"birthdayCard\": 3, \"cacheHits\": 2, \"io.helidon.examples.quickstart.mp.totalCards.GreetingCards\": 5 } The cache was hit two times out of five queries. ",
            "title": "Field Level Metrics"
        },
        {
            "location": "mp/metrics/metrics",
            "text": " The metrics you have tested so far are updated in response to an application REST request, i.e GET /cards . These metrics can be declared in a request scoped class and Helidon will store the metric in the MetricRegistry , so the value persists across requests. When GET /metrics/application is invoked, Helidon will return the current value of the metric stored in the MetricRegistry . The Gauge metric is different from all the other metrics. The application must provide a getter to return the gauge value in an application scoped class. When GET /metrics/application is invoked, Helidon will call the Gauge getter, store that value in the MetricsRegistry , and return it as part of the metrics response payload. So, the Gauge metric value is updated real-time, in response to the get metrics request. The following example demonstrates how to use a Gauge to track application up-time. <markup lang=\"java\" title=\"Create a new GreetingCardsAppMetrics class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.time.Duration; import java.util.concurrent.atomic.AtomicLong; import jakarta.enterprise.context.ApplicationScoped; import jakarta.enterprise.context.Initialized; import jakarta.enterprise.event.Observes; import org.eclipse.microprofile.metrics.annotation.Gauge; @ApplicationScoped public class GreetingCardsAppMetrics { private AtomicLong startTime = new AtomicLong(0); public void onStartUp(@Observes @Initialized(ApplicationScoped.class) Object init) { startTime = new AtomicLong(System.currentTimeMillis()); } @Gauge(unit = \"TimeSeconds\") public long appUpTimeSeconds() { return Duration.ofMillis(System.currentTimeMillis() - startTime.get()).getSeconds(); } } This managed object must be application scoped to properly register and use the Gauge metric. Declare an AtomicLong field to hold the start time of the application. Initialize the application start time. Return the application appUpTimeSeconds metric, which will be included in the application metrics. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code to simplify the metrics output:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import jakarta.enterprise.context.RequestScoped; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.annotation.Counted; @Path(\"/cards\") @RequestScoped public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"cardCount\", absolute = true) public JsonObject anyCard() throws InterruptedException { return createResponse(\"Here are some random cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } } <markup lang=\"bash\" title=\"Build and run the application, then invoke the application metrics endpoint:\" >curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response from /metrics/application :\" >{ \"cardCount\": 0, \"io.helidon.examples.quickstart.mp.GreetingCardsAppMetrics.appUpTimeSeconds\": 6 } The application has been running for 6 seconds. ",
            "title": "Gauge Metric"
        },
        {
            "location": "mp/metrics/metrics",
            "text": " Adding Method-level Annotations The following example adds a new resource class, GreetingCards , to the Helidon MP QuickStart example. It shows how to use the @Counted annotation to track the number of times the /cards endpoint is called. <markup lang=\"java\" title=\"Create a new class GreetingCards with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import jakarta.enterprise.context.RequestScoped; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.annotation.Counted; @Path(\"/cards\") @RequestScoped public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"any-card\") public JsonObject anyCard() throws InterruptedException { return createResponse(\"Here are some random cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } } This class is annotated with Path which sets the path for this resource as /cards . The @RequestScoped annotation defines that this bean is request scoped. The request scope is active only for the duration of one web service invocation and it is destroyed at the end of that invocation. The annotation @Counted will register a Counter metric for this method, creating it if needed. The counter is incremented each time the anyCards method is called. The name attribute is optional. <markup lang=\"bash\" title=\"Build and run the application\" >mvn package java -jar target/helidon-quickstart-mp.jar <markup lang=\"base\" title=\"Access the application endpoints\" >curl http://localhost:8080/cards curl http://localhost:8080/cards curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response:\" >{ \"io.helidon.examples.quickstart.mp.GreetingCards.any-card\":2 } The any-card count is two, since you invoked the endpoint twice. Notice the counter name is fully qualified with the class and method names. You can remove the prefix by using the absolute=true field in the @Counted annotation. You must use absolute=false (the default) for class-level annotations. Additional Method-level Metrics The @ConcurrentGauge , @Timed`, @Metered , and @SimplyTimed annotations can also be used with a method. For the following example. you can just annotate the same method with @Metered and @Timed . These metrics collect significant information about the measured methods, but at a cost of some overhead and more complicated output. Use @SimplyTimed in cases where capturing the invocation count and the total elapsed time spent in a block of code is sufficient. Note that when using multiple annotations on a method, you must give the metrics different names as shown below (although they do not have to be absolute). <markup lang=\"java\" title=\"Update the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import jakarta.enterprise.context.RequestScoped; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.MetricUnits; import org.eclipse.microprofile.metrics.annotation.Counted; import org.eclipse.microprofile.metrics.annotation.Metered; import org.eclipse.microprofile.metrics.annotation.Timed; @Path(\"/cards\") @RequestScoped public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"cardCount\", absolute = true) @Metered(name = \"cardMeter\", absolute = true, unit = MetricUnits.MILLISECONDS) @Timed(name = \"cardTimer\", absolute = true, unit = MetricUnits.MILLISECONDS) public JsonObject anyCard() { return createResponse(\"Here are some random cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } } Specify a custom name for the Counter metric and set absolute=true to remove the path prefix from the name. Add the @Metered annotation to get a Meter metric. Add the @Timed annotation to get a Timer metric. <markup lang=\"bash\" title=\"Build and run the application\" >mvn package java -jar target/helidon-quickstart-mp.jar <markup lang=\"base\" title=\"Access the application endpoints\" >curl http://localhost:8080/cards curl http://localhost:8080/cards curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response:\" >{ \"cardCount\": 2, \"cardMeter\": { \"count\": 2, \"meanRate\": 0.15653506570241812, \"oneMinRate\": 0, \"fiveMinRate\": 0, \"fifteenMinRate\": 0 }, \"cardTimer\": { \"count\": 2, \"elapsedTime\": 2, \"meanRate\": 0.15651866263362785, \"oneMinRate\": 0, \"fiveMinRate\": 0, \"fifteenMinRate\": 0, \"min\": 0, \"max\": 2, \"mean\": 1.0506565, \"stddev\": 1.0405735, \"p50\": 2.09123, \"p75\": 2.09123, \"p95\": 2.09123, \"p98\": 2.09123, \"p99\": 2.09123, \"p999\": 2.09123 } } The Meter metric includes the count field (it is a superset of Counter ). The Timer metric includes the Meter fields (it is a superset of Meter ). Class-level Metrics You can collect metrics at the class-level to aggregate data from all methods in that class using the same metric. The following example introduces a metric to count all card queries. In the following example, the method-level metrics are not needed to aggregate the counts, but they are left in the example to demonstrate the combined output of all three metrics. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import jakarta.enterprise.context.RequestScoped; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.annotation.Counted; @Path(\"/cards\") @RequestScoped @Counted(name = \"totalCards\") public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) @Counted(absolute = true) public JsonObject anyCard() throws InterruptedException { return createResponse(\"Here are some random cards ...\"); } @Path(\"/birthday\") @GET @Produces(MediaType.APPLICATION_JSON) @Counted(absolute = true) public JsonObject birthdayCard() throws InterruptedException { return createResponse(\"Here are some birthday cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } } This class is annotated with @Counted , which aggregates count data from all the method that have a Count annotation. Use absolute=true to remove path prefix for method-level annotations. Add a method with a Counter metric to get birthday cards. <markup lang=\"bash\" title=\"Build and run the application\" >mvn package java -jar target/helidon-quickstart-mp.jar <markup lang=\"bash\" title=\"Access the application endpoints\" >curl http://localhost:8080/cards curl http://localhost:8080/cards/birthday curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response from /metrics/application :\" >{ \"anyCard\": 1, \"birthdayCard\": 1, \"io.helidon.examples.quickstart.mp.totalCards.GreetingCards\": 2 } The totalCards count is a total of all the method-level Counter metrics. Class level metric names are always fully qualified. Field Level Metrics Field level metrics can be injected into managed objects, but they need to be updated by the application code. This annotation can be used on fields of type Meter , Timer , Counter , and Histogram . The following example shows how to use a field-level Counter metric to track cache hits. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import java.util.Random; import jakarta.enterprise.context.RequestScoped; import jakarta.inject.Inject; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.Counter; import org.eclipse.microprofile.metrics.annotation.Counted; import org.eclipse.microprofile.metrics.annotation.Metric; @Path(\"/cards\") @RequestScoped @Counted(name = \"totalCards\") public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @Inject @Metric(name = \"cacheHits\", absolute = true) private Counter cacheHits; @GET @Produces(MediaType.APPLICATION_JSON) @Counted(absolute = true) public JsonObject anyCard() throws InterruptedException { updateStats(); return createResponse(\"Here are some random cards ...\"); } @Path(\"/birthday\") @GET @Produces(MediaType.APPLICATION_JSON) @Counted(absolute = true) public JsonObject birthdayCard() throws InterruptedException { updateStats(); return createResponse(\"Here are some birthday cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } private void updateStats() { if (new Random().nextInt(3) == 1) { cacheHits.inc(); } } } A Counter metric field, cacheHits , is automatically injected by Helidon. Call updateStats() to update the cache hits. Call updateStats() to update the cache hits. Randomly increment the cacheHits counter. <markup lang=\"bash\" title=\"Build and run the application, then invoke the following endpoints:\" >curl http://localhost:8080/cards curl http://localhost:8080/cards curl http://localhost:8080/cards/birthday curl http://localhost:8080/cards/birthday curl http://localhost:8080/cards/birthday curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response from /metrics/application :\" >{ \"anyCard\": 2, \"birthdayCard\": 3, \"cacheHits\": 2, \"io.helidon.examples.quickstart.mp.totalCards.GreetingCards\": 5 } The cache was hit two times out of five queries. Gauge Metric The metrics you have tested so far are updated in response to an application REST request, i.e GET /cards . These metrics can be declared in a request scoped class and Helidon will store the metric in the MetricRegistry , so the value persists across requests. When GET /metrics/application is invoked, Helidon will return the current value of the metric stored in the MetricRegistry . The Gauge metric is different from all the other metrics. The application must provide a getter to return the gauge value in an application scoped class. When GET /metrics/application is invoked, Helidon will call the Gauge getter, store that value in the MetricsRegistry , and return it as part of the metrics response payload. So, the Gauge metric value is updated real-time, in response to the get metrics request. The following example demonstrates how to use a Gauge to track application up-time. <markup lang=\"java\" title=\"Create a new GreetingCardsAppMetrics class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.time.Duration; import java.util.concurrent.atomic.AtomicLong; import jakarta.enterprise.context.ApplicationScoped; import jakarta.enterprise.context.Initialized; import jakarta.enterprise.event.Observes; import org.eclipse.microprofile.metrics.annotation.Gauge; @ApplicationScoped public class GreetingCardsAppMetrics { private AtomicLong startTime = new AtomicLong(0); public void onStartUp(@Observes @Initialized(ApplicationScoped.class) Object init) { startTime = new AtomicLong(System.currentTimeMillis()); } @Gauge(unit = \"TimeSeconds\") public long appUpTimeSeconds() { return Duration.ofMillis(System.currentTimeMillis() - startTime.get()).getSeconds(); } } This managed object must be application scoped to properly register and use the Gauge metric. Declare an AtomicLong field to hold the start time of the application. Initialize the application start time. Return the application appUpTimeSeconds metric, which will be included in the application metrics. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code to simplify the metrics output:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import jakarta.enterprise.context.RequestScoped; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.annotation.Counted; @Path(\"/cards\") @RequestScoped public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"cardCount\", absolute = true) public JsonObject anyCard() throws InterruptedException { return createResponse(\"Here are some random cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } } <markup lang=\"bash\" title=\"Build and run the application, then invoke the application metrics endpoint:\" >curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response from /metrics/application :\" >{ \"cardCount\": 0, \"io.helidon.examples.quickstart.mp.GreetingCardsAppMetrics.appUpTimeSeconds\": 6 } The application has been running for 6 seconds. ",
            "title": "Example Application Code"
        },
        {
            "location": "mp/metrics/metrics",
            "text": "<markup lang=\"properties\" title=\"Disabling metrics entirely\" >metrics.enabled=false Helidon does not update metrics, and the /metrics endpoints respond with 404 plus a message that the metrics subsystem is disabled. ",
            "title": "Disable Metrics Subsystem"
        },
        {
            "location": "mp/metrics/metrics",
            "text": " You can be even more selective. Within a registry type you can configure up to two regular expression patterns: one matching metric names to exclude , and one matching metric names to include . Helidon updates and reports a metric only if two conditions hold: the metric name does not match the exclude regex pattern (if you define one), and either there is no include regex pattern, or the metric name matches the include pattern. Note Make sure any include regex pattern you specify matches all the metric names you want to capture. Suppose your application creates and updates a group of metrics with names such as myapp.xxx.queries , myapp.xxx.creates , myapp.xxx.updates , and myapp.xxx.deletes where xxx can be either supplier or customer . The following example gathers all metrics except those from your application regarding suppliers although supplier updates are included : <markup lang=\"properties\" title=\"Disabling and enabling metrics by name\" >metrics.registries.0.type=application metrics.registries.0.application.filter.exclude=myapp\\.supplier\\..* metrics.registries.0.application.filter.include=myapp\\.supplier\\.updates This setting excludes metrics with names starting with myapp.supplier except for the metric myapp.supplier.updates . The exclude and include values are regular expressions. ",
            "title": "Disable Selected Metrics"
        },
        {
            "location": "mp/metrics/metrics",
            "text": " Any time you include the Helidon metrics module in your application, Helidon tracks two basic performance indicator metrics: a Counter of all requests received ( requests.count ), and a Meter of all requests received ( requests.meter ). Helidon MP also includes additional, extended KPI metrics which are disabled by default: current number of requests in-flight - a ConcurrentGauge ( requests.inFlight ) of requests currently being processed long-running requests - a Meter ( requests.longRunning ) measuring the rate at which Helidon processes requests which take at least a given amount of time to complete; configurable, defaults to 10000 milliseconds (10 seconds) load - a Meter ( requests.load ) measuring the rate at which requests are worked on (as opposed to received) deferred - a Meter ( requests.deferred ) measuring the rate at which a request&#8217;s processing is delayed after Helidon receives the request You can enable and control these metrics using configuration: <markup lang=\"properties\" title=\"Controlling extended KPI metrics\" >metrics.key-performance-indicators.extended = true metrics.key-performance-indicators.long-running.threshold-ms = 2000 ",
            "title": "Collecting Basic and Extended Key Performance Indicator (KPI) Metrics"
        },
        {
            "location": "mp/metrics/metrics",
            "text": "<markup lang=\"properties\" title=\"Controlling REST request metrics\" >metrics.rest-request-enabled=true Helidon automatically registers and updates SimpleTimer metrics for every REST endpoint in your service. ",
            "title": "Enable REST.request Metrics"
        },
        {
            "location": "mp/metrics/metrics",
            "text": " Metrics configuration is quite extensive and powerful and, therefore, a bit complicated. The rest of this section illustrates some of the most common scenarios: Disable metrics entirely. Selectively enable or disable metrics by metric registry type and, within type, by name. Choose whether to collect extended key performance indicator metrics. Control REST.request metrics collection. Disable Metrics Subsystem <markup lang=\"properties\" title=\"Disabling metrics entirely\" >metrics.enabled=false Helidon does not update metrics, and the /metrics endpoints respond with 404 plus a message that the metrics subsystem is disabled. Disable Selected Metrics You can be even more selective. Within a registry type you can configure up to two regular expression patterns: one matching metric names to exclude , and one matching metric names to include . Helidon updates and reports a metric only if two conditions hold: the metric name does not match the exclude regex pattern (if you define one), and either there is no include regex pattern, or the metric name matches the include pattern. Note Make sure any include regex pattern you specify matches all the metric names you want to capture. Suppose your application creates and updates a group of metrics with names such as myapp.xxx.queries , myapp.xxx.creates , myapp.xxx.updates , and myapp.xxx.deletes where xxx can be either supplier or customer . The following example gathers all metrics except those from your application regarding suppliers although supplier updates are included : <markup lang=\"properties\" title=\"Disabling and enabling metrics by name\" >metrics.registries.0.type=application metrics.registries.0.application.filter.exclude=myapp\\.supplier\\..* metrics.registries.0.application.filter.include=myapp\\.supplier\\.updates This setting excludes metrics with names starting with myapp.supplier except for the metric myapp.supplier.updates . The exclude and include values are regular expressions. Collecting Basic and Extended Key Performance Indicator (KPI) Metrics Any time you include the Helidon metrics module in your application, Helidon tracks two basic performance indicator metrics: a Counter of all requests received ( requests.count ), and a Meter of all requests received ( requests.meter ). Helidon MP also includes additional, extended KPI metrics which are disabled by default: current number of requests in-flight - a ConcurrentGauge ( requests.inFlight ) of requests currently being processed long-running requests - a Meter ( requests.longRunning ) measuring the rate at which Helidon processes requests which take at least a given amount of time to complete; configurable, defaults to 10000 milliseconds (10 seconds) load - a Meter ( requests.load ) measuring the rate at which requests are worked on (as opposed to received) deferred - a Meter ( requests.deferred ) measuring the rate at which a request&#8217;s processing is delayed after Helidon receives the request You can enable and control these metrics using configuration: <markup lang=\"properties\" title=\"Controlling extended KPI metrics\" >metrics.key-performance-indicators.extended = true metrics.key-performance-indicators.long-running.threshold-ms = 2000 Enable REST.request Metrics <markup lang=\"properties\" title=\"Controlling REST request metrics\" >metrics.rest-request-enabled=true Helidon automatically registers and updates SimpleTimer metrics for every REST endpoint in your service. ",
            "title": "Example Configuration"
        },
        {
            "location": "mp/metrics/metrics",
            "text": " Helidon MP includes a prewritten example application illustrating enabling/disabling metrics using configuration. The rest of this section contains other examples of working with metrics: Example Application Code Example Configuration Example Application Code Adding Method-level Annotations The following example adds a new resource class, GreetingCards , to the Helidon MP QuickStart example. It shows how to use the @Counted annotation to track the number of times the /cards endpoint is called. <markup lang=\"java\" title=\"Create a new class GreetingCards with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import jakarta.enterprise.context.RequestScoped; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.annotation.Counted; @Path(\"/cards\") @RequestScoped public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"any-card\") public JsonObject anyCard() throws InterruptedException { return createResponse(\"Here are some random cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } } This class is annotated with Path which sets the path for this resource as /cards . The @RequestScoped annotation defines that this bean is request scoped. The request scope is active only for the duration of one web service invocation and it is destroyed at the end of that invocation. The annotation @Counted will register a Counter metric for this method, creating it if needed. The counter is incremented each time the anyCards method is called. The name attribute is optional. <markup lang=\"bash\" title=\"Build and run the application\" >mvn package java -jar target/helidon-quickstart-mp.jar <markup lang=\"base\" title=\"Access the application endpoints\" >curl http://localhost:8080/cards curl http://localhost:8080/cards curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response:\" >{ \"io.helidon.examples.quickstart.mp.GreetingCards.any-card\":2 } The any-card count is two, since you invoked the endpoint twice. Notice the counter name is fully qualified with the class and method names. You can remove the prefix by using the absolute=true field in the @Counted annotation. You must use absolute=false (the default) for class-level annotations. Additional Method-level Metrics The @ConcurrentGauge , @Timed`, @Metered , and @SimplyTimed annotations can also be used with a method. For the following example. you can just annotate the same method with @Metered and @Timed . These metrics collect significant information about the measured methods, but at a cost of some overhead and more complicated output. Use @SimplyTimed in cases where capturing the invocation count and the total elapsed time spent in a block of code is sufficient. Note that when using multiple annotations on a method, you must give the metrics different names as shown below (although they do not have to be absolute). <markup lang=\"java\" title=\"Update the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import jakarta.enterprise.context.RequestScoped; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.MetricUnits; import org.eclipse.microprofile.metrics.annotation.Counted; import org.eclipse.microprofile.metrics.annotation.Metered; import org.eclipse.microprofile.metrics.annotation.Timed; @Path(\"/cards\") @RequestScoped public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"cardCount\", absolute = true) @Metered(name = \"cardMeter\", absolute = true, unit = MetricUnits.MILLISECONDS) @Timed(name = \"cardTimer\", absolute = true, unit = MetricUnits.MILLISECONDS) public JsonObject anyCard() { return createResponse(\"Here are some random cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } } Specify a custom name for the Counter metric and set absolute=true to remove the path prefix from the name. Add the @Metered annotation to get a Meter metric. Add the @Timed annotation to get a Timer metric. <markup lang=\"bash\" title=\"Build and run the application\" >mvn package java -jar target/helidon-quickstart-mp.jar <markup lang=\"base\" title=\"Access the application endpoints\" >curl http://localhost:8080/cards curl http://localhost:8080/cards curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response:\" >{ \"cardCount\": 2, \"cardMeter\": { \"count\": 2, \"meanRate\": 0.15653506570241812, \"oneMinRate\": 0, \"fiveMinRate\": 0, \"fifteenMinRate\": 0 }, \"cardTimer\": { \"count\": 2, \"elapsedTime\": 2, \"meanRate\": 0.15651866263362785, \"oneMinRate\": 0, \"fiveMinRate\": 0, \"fifteenMinRate\": 0, \"min\": 0, \"max\": 2, \"mean\": 1.0506565, \"stddev\": 1.0405735, \"p50\": 2.09123, \"p75\": 2.09123, \"p95\": 2.09123, \"p98\": 2.09123, \"p99\": 2.09123, \"p999\": 2.09123 } } The Meter metric includes the count field (it is a superset of Counter ). The Timer metric includes the Meter fields (it is a superset of Meter ). Class-level Metrics You can collect metrics at the class-level to aggregate data from all methods in that class using the same metric. The following example introduces a metric to count all card queries. In the following example, the method-level metrics are not needed to aggregate the counts, but they are left in the example to demonstrate the combined output of all three metrics. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import jakarta.enterprise.context.RequestScoped; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.annotation.Counted; @Path(\"/cards\") @RequestScoped @Counted(name = \"totalCards\") public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) @Counted(absolute = true) public JsonObject anyCard() throws InterruptedException { return createResponse(\"Here are some random cards ...\"); } @Path(\"/birthday\") @GET @Produces(MediaType.APPLICATION_JSON) @Counted(absolute = true) public JsonObject birthdayCard() throws InterruptedException { return createResponse(\"Here are some birthday cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } } This class is annotated with @Counted , which aggregates count data from all the method that have a Count annotation. Use absolute=true to remove path prefix for method-level annotations. Add a method with a Counter metric to get birthday cards. <markup lang=\"bash\" title=\"Build and run the application\" >mvn package java -jar target/helidon-quickstart-mp.jar <markup lang=\"bash\" title=\"Access the application endpoints\" >curl http://localhost:8080/cards curl http://localhost:8080/cards/birthday curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response from /metrics/application :\" >{ \"anyCard\": 1, \"birthdayCard\": 1, \"io.helidon.examples.quickstart.mp.totalCards.GreetingCards\": 2 } The totalCards count is a total of all the method-level Counter metrics. Class level metric names are always fully qualified. Field Level Metrics Field level metrics can be injected into managed objects, but they need to be updated by the application code. This annotation can be used on fields of type Meter , Timer , Counter , and Histogram . The following example shows how to use a field-level Counter metric to track cache hits. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import java.util.Random; import jakarta.enterprise.context.RequestScoped; import jakarta.inject.Inject; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.Counter; import org.eclipse.microprofile.metrics.annotation.Counted; import org.eclipse.microprofile.metrics.annotation.Metric; @Path(\"/cards\") @RequestScoped @Counted(name = \"totalCards\") public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @Inject @Metric(name = \"cacheHits\", absolute = true) private Counter cacheHits; @GET @Produces(MediaType.APPLICATION_JSON) @Counted(absolute = true) public JsonObject anyCard() throws InterruptedException { updateStats(); return createResponse(\"Here are some random cards ...\"); } @Path(\"/birthday\") @GET @Produces(MediaType.APPLICATION_JSON) @Counted(absolute = true) public JsonObject birthdayCard() throws InterruptedException { updateStats(); return createResponse(\"Here are some birthday cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } private void updateStats() { if (new Random().nextInt(3) == 1) { cacheHits.inc(); } } } A Counter metric field, cacheHits , is automatically injected by Helidon. Call updateStats() to update the cache hits. Call updateStats() to update the cache hits. Randomly increment the cacheHits counter. <markup lang=\"bash\" title=\"Build and run the application, then invoke the following endpoints:\" >curl http://localhost:8080/cards curl http://localhost:8080/cards curl http://localhost:8080/cards/birthday curl http://localhost:8080/cards/birthday curl http://localhost:8080/cards/birthday curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response from /metrics/application :\" >{ \"anyCard\": 2, \"birthdayCard\": 3, \"cacheHits\": 2, \"io.helidon.examples.quickstart.mp.totalCards.GreetingCards\": 5 } The cache was hit two times out of five queries. Gauge Metric The metrics you have tested so far are updated in response to an application REST request, i.e GET /cards . These metrics can be declared in a request scoped class and Helidon will store the metric in the MetricRegistry , so the value persists across requests. When GET /metrics/application is invoked, Helidon will return the current value of the metric stored in the MetricRegistry . The Gauge metric is different from all the other metrics. The application must provide a getter to return the gauge value in an application scoped class. When GET /metrics/application is invoked, Helidon will call the Gauge getter, store that value in the MetricsRegistry , and return it as part of the metrics response payload. So, the Gauge metric value is updated real-time, in response to the get metrics request. The following example demonstrates how to use a Gauge to track application up-time. <markup lang=\"java\" title=\"Create a new GreetingCardsAppMetrics class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.time.Duration; import java.util.concurrent.atomic.AtomicLong; import jakarta.enterprise.context.ApplicationScoped; import jakarta.enterprise.context.Initialized; import jakarta.enterprise.event.Observes; import org.eclipse.microprofile.metrics.annotation.Gauge; @ApplicationScoped public class GreetingCardsAppMetrics { private AtomicLong startTime = new AtomicLong(0); public void onStartUp(@Observes @Initialized(ApplicationScoped.class) Object init) { startTime = new AtomicLong(System.currentTimeMillis()); } @Gauge(unit = \"TimeSeconds\") public long appUpTimeSeconds() { return Duration.ofMillis(System.currentTimeMillis() - startTime.get()).getSeconds(); } } This managed object must be application scoped to properly register and use the Gauge metric. Declare an AtomicLong field to hold the start time of the application. Initialize the application start time. Return the application appUpTimeSeconds metric, which will be included in the application metrics. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code to simplify the metrics output:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import jakarta.enterprise.context.RequestScoped; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.core.MediaType; import org.eclipse.microprofile.metrics.annotation.Counted; @Path(\"/cards\") @RequestScoped public class GreetingCards { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); @GET @Produces(MediaType.APPLICATION_JSON) @Counted(name = \"cardCount\", absolute = true) public JsonObject anyCard() throws InterruptedException { return createResponse(\"Here are some random cards ...\"); } private JsonObject createResponse(String msg) { return JSON.createObjectBuilder().add(\"message\", msg).build(); } } <markup lang=\"bash\" title=\"Build and run the application, then invoke the application metrics endpoint:\" >curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response from /metrics/application :\" >{ \"cardCount\": 0, \"io.helidon.examples.quickstart.mp.GreetingCardsAppMetrics.appUpTimeSeconds\": 6 } The application has been running for 6 seconds. Example Configuration Metrics configuration is quite extensive and powerful and, therefore, a bit complicated. The rest of this section illustrates some of the most common scenarios: Disable metrics entirely. Selectively enable or disable metrics by metric registry type and, within type, by name. Choose whether to collect extended key performance indicator metrics. Control REST.request metrics collection. Disable Metrics Subsystem <markup lang=\"properties\" title=\"Disabling metrics entirely\" >metrics.enabled=false Helidon does not update metrics, and the /metrics endpoints respond with 404 plus a message that the metrics subsystem is disabled. Disable Selected Metrics You can be even more selective. Within a registry type you can configure up to two regular expression patterns: one matching metric names to exclude , and one matching metric names to include . Helidon updates and reports a metric only if two conditions hold: the metric name does not match the exclude regex pattern (if you define one), and either there is no include regex pattern, or the metric name matches the include pattern. Note Make sure any include regex pattern you specify matches all the metric names you want to capture. Suppose your application creates and updates a group of metrics with names such as myapp.xxx.queries , myapp.xxx.creates , myapp.xxx.updates , and myapp.xxx.deletes where xxx can be either supplier or customer . The following example gathers all metrics except those from your application regarding suppliers although supplier updates are included : <markup lang=\"properties\" title=\"Disabling and enabling metrics by name\" >metrics.registries.0.type=application metrics.registries.0.application.filter.exclude=myapp\\.supplier\\..* metrics.registries.0.application.filter.include=myapp\\.supplier\\.updates This setting excludes metrics with names starting with myapp.supplier except for the metric myapp.supplier.updates . The exclude and include values are regular expressions. Collecting Basic and Extended Key Performance Indicator (KPI) Metrics Any time you include the Helidon metrics module in your application, Helidon tracks two basic performance indicator metrics: a Counter of all requests received ( requests.count ), and a Meter of all requests received ( requests.meter ). Helidon MP also includes additional, extended KPI metrics which are disabled by default: current number of requests in-flight - a ConcurrentGauge ( requests.inFlight ) of requests currently being processed long-running requests - a Meter ( requests.longRunning ) measuring the rate at which Helidon processes requests which take at least a given amount of time to complete; configurable, defaults to 10000 milliseconds (10 seconds) load - a Meter ( requests.load ) measuring the rate at which requests are worked on (as opposed to received) deferred - a Meter ( requests.deferred ) measuring the rate at which a request&#8217;s processing is delayed after Helidon receives the request You can enable and control these metrics using configuration: <markup lang=\"properties\" title=\"Controlling extended KPI metrics\" >metrics.key-performance-indicators.extended = true metrics.key-performance-indicators.long-running.threshold-ms = 2000 Enable REST.request Metrics <markup lang=\"properties\" title=\"Controlling REST request metrics\" >metrics.rest-request-enabled=true Helidon automatically registers and updates SimpleTimer metrics for every REST endpoint in your service. ",
            "title": "Examples"
        },
        {
            "location": "mp/metrics/metrics",
            "text": " The following example shows how to integrate the Helidon MP application with Kubernetes. <markup lang=\"bash\" title=\"Stop the application and build the docker image:\" >docker build -t helidon-metrics-mp . <markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named metrics.yaml , with the following content:\" >kind: Service apiVersion: v1 metadata: name: helidon-metrics labels: app: helidon-metrics annotations: prometheus.io/scrape: true spec: type: NodePort selector: app: helidon-metrics ports: - port: 8080 targetPort: 8080 name: http --- kind: Deployment apiVersion: apps/v1 metadata: name: helidon-metrics spec: replicas: 1 selector: matchLabels: app: helidon-metrics template: metadata: labels: app: helidon-metrics version: v1 spec: containers: - name: helidon-metrics image: helidon-metrics-mp imagePullPolicy: IfNotPresent ports: - containerPort: 8080 A service of type NodePort that serves the default routes on port 8080 . An annotation that will allow Prometheus to discover and scrape the application pod. A deployment with one replica of a pod. <markup lang=\"bash\" title=\"Create and deploy the application into Kubernetes:\" >kubectl apply -f ./metrics.yaml <markup lang=\"bash\" title=\"Get the service information:\" >kubectl get service/helidon-metrics <markup lang=\"bash\" >NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE helidon-metrics NodePort 10.99.159.2 &lt;none&gt; 8080:31143/TCP 8s A service of type NodePort that serves the default routes on port 31143 . <markup lang=\"bash\" title=\"Verify the metrics endpoint using port 30116 , your port will likely be different:\" >curl http://localhost:31143/metrics Leave the application running in Kubernetes since it will be used for Prometheus integration. ",
            "title": "Kubernetes Integration"
        },
        {
            "location": "mp/metrics/metrics",
            "text": " The metrics service that you just deployed into Kubernetes is already annotated with prometheus.io/scrape: . This will allow Prometheus to discover the service and scrape the metrics. This example shows how to install Prometheus into Kubernetes, then verify that it discovered the Helidon metrics in your application. <markup lang=\"bash\" title=\"Install Prometheus and wait until the pod is ready:\" >helm install stable/prometheus --name metrics export POD_NAME=$(kubectl get pods --namespace default -l \"app=prometheus,component=server\" -o jsonpath=\"{.items[0].metadata.name}\") kubectl get pod $POD_NAME You will see output similar to the following. Repeat the kubectl get pod command until you see 2/2 and Running . This may take up to one minute. <markup lang=\"bash\" >metrics-prometheus-server-5fc5dc86cb-79lk4 2/2 Running 0 46s <markup lang=\"bash\" title=\"Create a port-forward so you can access the server URL:\" >kubectl --namespace default port-forward $POD_NAME 7090:9090 Now open your browser and navigate to http://localhost:7090/targets . Search for helidon on the page and you will see your Helidon application as one of the Prometheus targets. ",
            "title": "Prometheus Integration"
        },
        {
            "location": "mp/metrics/metrics",
            "text": " You can now delete the Kubernetes resources that were just created during this example. <markup lang=\"bash\" title=\"Delete the Prometheus Kubernetes resources:\" >helm delete --purge metrics <markup lang=\"bash\" title=\"Delete the application Kubernetes resources:\" >kubectl delete -f ./metrics.yaml ",
            "title": "Final Cleanup"
        },
        {
            "location": "mp/metrics/metrics",
            "text": " Kubernetes Integration The following example shows how to integrate the Helidon MP application with Kubernetes. <markup lang=\"bash\" title=\"Stop the application and build the docker image:\" >docker build -t helidon-metrics-mp . <markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named metrics.yaml , with the following content:\" >kind: Service apiVersion: v1 metadata: name: helidon-metrics labels: app: helidon-metrics annotations: prometheus.io/scrape: true spec: type: NodePort selector: app: helidon-metrics ports: - port: 8080 targetPort: 8080 name: http --- kind: Deployment apiVersion: apps/v1 metadata: name: helidon-metrics spec: replicas: 1 selector: matchLabels: app: helidon-metrics template: metadata: labels: app: helidon-metrics version: v1 spec: containers: - name: helidon-metrics image: helidon-metrics-mp imagePullPolicy: IfNotPresent ports: - containerPort: 8080 A service of type NodePort that serves the default routes on port 8080 . An annotation that will allow Prometheus to discover and scrape the application pod. A deployment with one replica of a pod. <markup lang=\"bash\" title=\"Create and deploy the application into Kubernetes:\" >kubectl apply -f ./metrics.yaml <markup lang=\"bash\" title=\"Get the service information:\" >kubectl get service/helidon-metrics <markup lang=\"bash\" >NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE helidon-metrics NodePort 10.99.159.2 &lt;none&gt; 8080:31143/TCP 8s A service of type NodePort that serves the default routes on port 31143 . <markup lang=\"bash\" title=\"Verify the metrics endpoint using port 30116 , your port will likely be different:\" >curl http://localhost:31143/metrics Leave the application running in Kubernetes since it will be used for Prometheus integration. Prometheus Integration The metrics service that you just deployed into Kubernetes is already annotated with prometheus.io/scrape: . This will allow Prometheus to discover the service and scrape the metrics. This example shows how to install Prometheus into Kubernetes, then verify that it discovered the Helidon metrics in your application. <markup lang=\"bash\" title=\"Install Prometheus and wait until the pod is ready:\" >helm install stable/prometheus --name metrics export POD_NAME=$(kubectl get pods --namespace default -l \"app=prometheus,component=server\" -o jsonpath=\"{.items[0].metadata.name}\") kubectl get pod $POD_NAME You will see output similar to the following. Repeat the kubectl get pod command until you see 2/2 and Running . This may take up to one minute. <markup lang=\"bash\" >metrics-prometheus-server-5fc5dc86cb-79lk4 2/2 Running 0 46s <markup lang=\"bash\" title=\"Create a port-forward so you can access the server URL:\" >kubectl --namespace default port-forward $POD_NAME 7090:9090 Now open your browser and navigate to http://localhost:7090/targets . Search for helidon on the page and you will see your Helidon application as one of the Prometheus targets. Final Cleanup You can now delete the Kubernetes resources that were just created during this example. <markup lang=\"bash\" title=\"Delete the Prometheus Kubernetes resources:\" >helm delete --purge metrics <markup lang=\"bash\" title=\"Delete the application Kubernetes resources:\" >kubectl delete -f ./metrics.yaml ",
            "title": "Integration with Kubernetes and Prometheus"
        },
        {
            "location": "mp/metrics/metrics",
            "text": " MicroProfile Metrics specification MicroProfile Metrics API ",
            "title": "References"
        },
        {
            "location": "mp/metrics/metrics",
            "text": " Integration with Kubernetes and Prometheus Kubernetes Integration The following example shows how to integrate the Helidon MP application with Kubernetes. <markup lang=\"bash\" title=\"Stop the application and build the docker image:\" >docker build -t helidon-metrics-mp . <markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named metrics.yaml , with the following content:\" >kind: Service apiVersion: v1 metadata: name: helidon-metrics labels: app: helidon-metrics annotations: prometheus.io/scrape: true spec: type: NodePort selector: app: helidon-metrics ports: - port: 8080 targetPort: 8080 name: http --- kind: Deployment apiVersion: apps/v1 metadata: name: helidon-metrics spec: replicas: 1 selector: matchLabels: app: helidon-metrics template: metadata: labels: app: helidon-metrics version: v1 spec: containers: - name: helidon-metrics image: helidon-metrics-mp imagePullPolicy: IfNotPresent ports: - containerPort: 8080 A service of type NodePort that serves the default routes on port 8080 . An annotation that will allow Prometheus to discover and scrape the application pod. A deployment with one replica of a pod. <markup lang=\"bash\" title=\"Create and deploy the application into Kubernetes:\" >kubectl apply -f ./metrics.yaml <markup lang=\"bash\" title=\"Get the service information:\" >kubectl get service/helidon-metrics <markup lang=\"bash\" >NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE helidon-metrics NodePort 10.99.159.2 &lt;none&gt; 8080:31143/TCP 8s A service of type NodePort that serves the default routes on port 31143 . <markup lang=\"bash\" title=\"Verify the metrics endpoint using port 30116 , your port will likely be different:\" >curl http://localhost:31143/metrics Leave the application running in Kubernetes since it will be used for Prometheus integration. Prometheus Integration The metrics service that you just deployed into Kubernetes is already annotated with prometheus.io/scrape: . This will allow Prometheus to discover the service and scrape the metrics. This example shows how to install Prometheus into Kubernetes, then verify that it discovered the Helidon metrics in your application. <markup lang=\"bash\" title=\"Install Prometheus and wait until the pod is ready:\" >helm install stable/prometheus --name metrics export POD_NAME=$(kubectl get pods --namespace default -l \"app=prometheus,component=server\" -o jsonpath=\"{.items[0].metadata.name}\") kubectl get pod $POD_NAME You will see output similar to the following. Repeat the kubectl get pod command until you see 2/2 and Running . This may take up to one minute. <markup lang=\"bash\" >metrics-prometheus-server-5fc5dc86cb-79lk4 2/2 Running 0 46s <markup lang=\"bash\" title=\"Create a port-forward so you can access the server URL:\" >kubectl --namespace default port-forward $POD_NAME 7090:9090 Now open your browser and navigate to http://localhost:7090/targets . Search for helidon on the page and you will see your Helidon application as one of the Prometheus targets. Final Cleanup You can now delete the Kubernetes resources that were just created during this example. <markup lang=\"bash\" title=\"Delete the Prometheus Kubernetes resources:\" >helm delete --purge metrics <markup lang=\"bash\" title=\"Delete the application Kubernetes resources:\" >kubectl delete -f ./metrics.yaml References MicroProfile Metrics specification MicroProfile Metrics API ",
            "title": "Additional Information"
        },
        {
            "location": "mp/metrics/micrometer",
            "text": " Overview Maven Coordinates Usage API Configuration Examples Additional Information ",
            "title": "Contents"
        },
        {
            "location": "mp/metrics/micrometer",
            "text": " Helidon MP simplifies how you can use Micrometer for application-specific metrics: The endpoint /micrometer : A configurable endpoint that exposes metrics according to which Micrometer meter registry responds to the HTTP request. The Micrometer annotations @Timed and @Counted . Configuration to tailor the Prometheus and other Micrometer meter registries. In Helidon 3.0.2, Micrometer support is separate from the Helidon MP metrics API and the built-in Helidon metrics. ",
            "title": "Overview"
        },
        {
            "location": "mp/metrics/micrometer",
            "text": " To enable Micrometer support add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.micrometer&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-micrometer-cdi&lt;/artifactId&gt; &lt;/dependency&gt; Micrometer supports different types of meter registries which have different output styles and formats. Helidon provides built-in support for the Prometheus meter registry. To use other meter registry types, you will need to add dependencies for them to your pom.xml and, optionally, add configuration to set them up as you wish. ",
            "title": "Maven Coordinates"
        },
        {
            "location": "mp/metrics/micrometer",
            "text": " To use Micrometer support, you can simply add the Micrometer @Timed and @Counted annotations to methods in your application. Helidon automatically registers those meters with the Micrometer composite MeterRegistry . In addition to annotating your methods, your code can create, look up, and update metrics programmatically using the Micrometer MeterRegistry API. The Micrometer concepts document provides a good starting point for learning how to use Micrometer&#8217;s interfaces and classes. ",
            "title": "Registering and Updating Meters"
        },
        {
            "location": "mp/metrics/micrometer",
            "text": " Helidon MP Micrometer integration automatically creates a REST endpoint which clients can access to retrieve Micrometer metrics, by default at the /micrometer endpoint. ",
            "title": "Accessing the Helidon Micrometer Endpoint"
        },
        {
            "location": "mp/metrics/micrometer",
            "text": " Your application registers and updates Micrometer meters using annotations or direct use of the Micrometer API. Your users retrieve Micrometer meters using an endpoint which Helidon creates automatically. Registering and Updating Meters To use Micrometer support, you can simply add the Micrometer @Timed and @Counted annotations to methods in your application. Helidon automatically registers those meters with the Micrometer composite MeterRegistry . In addition to annotating your methods, your code can create, look up, and update metrics programmatically using the Micrometer MeterRegistry API. The Micrometer concepts document provides a good starting point for learning how to use Micrometer&#8217;s interfaces and classes. Accessing the Helidon Micrometer Endpoint Helidon MP Micrometer integration automatically creates a REST endpoint which clients can access to retrieve Micrometer metrics, by default at the /micrometer endpoint. ",
            "title": "Usage"
        },
        {
            "location": "mp/metrics/micrometer",
            "text": " Helidon automatically registers and updates meters associated with methods in your service where you add the Micrometer annotations. If you want to use the Micrometer MeterRegistry directly from your own code, simply @Inject the MeterRegistry into one of your REST resource classes or any other bean which CDI recognizes. Helidon injects the same Micrometer MeterRegistry that it uses for handling Micrometer annotations you add to your code. ",
            "title": "The Helidon Micrometer API"
        },
        {
            "location": "mp/metrics/micrometer",
            "text": " Your code can create, look up, and update metrics programmatically using the Micrometer MeterRegistry API. The Micrometer concepts document provides a good starting point for learning how to use Micrometer&#8217;s interfaces and classes. ",
            "title": "The Micrometer API"
        },
        {
            "location": "mp/metrics/micrometer",
            "text": " To incorporate Micrometer metrics into your code, you will work with two APIs: a small one specific to Helidon, and the Micrometer API itself. The Helidon Micrometer API Helidon automatically registers and updates meters associated with methods in your service where you add the Micrometer annotations. If you want to use the Micrometer MeterRegistry directly from your own code, simply @Inject the MeterRegistry into one of your REST resource classes or any other bean which CDI recognizes. Helidon injects the same Micrometer MeterRegistry that it uses for handling Micrometer annotations you add to your code. The Micrometer API Your code can create, look up, and update metrics programmatically using the Micrometer MeterRegistry API. The Micrometer concepts document provides a good starting point for learning how to use Micrometer&#8217;s interfaces and classes. ",
            "title": "API"
        },
        {
            "location": "mp/metrics/micrometer",
            "text": " Optional configuration options key type default value description cors CrossOriginConfig &#160; Sets the cross-origin config builder for use in establishing CORS support for the service endpoints. routing string &#160; Sets the routing name to use for setting up the service&#8217;s endpoint. web-context string &#160; Sets the web context to use for the service&#8217;s endpoint. By default, Helidon Micrometer integration exposes the /micrometer endpoint. You can override the path using the micrometer.web-context configuration key. <markup lang=\"properties\" title=\"Overriding the default Micrometer path\" >micrometer.web-context=my-micrometer ",
            "title": "Configuration options"
        },
        {
            "location": "mp/metrics/micrometer",
            "text": " You can configure the Helidon Micrometer REST service as you can other built-in Helidon services by adding configuration settings under the micrometer top-level key. Type: io.helidon.integrations.micrometer.MicrometerSupport <markup lang=\"text\" title=\"Config key\" >micrometer Configuration options Optional configuration options key type default value description cors CrossOriginConfig &#160; Sets the cross-origin config builder for use in establishing CORS support for the service endpoints. routing string &#160; Sets the routing name to use for setting up the service&#8217;s endpoint. web-context string &#160; Sets the web context to use for the service&#8217;s endpoint. By default, Helidon Micrometer integration exposes the /micrometer endpoint. You can override the path using the micrometer.web-context configuration key. <markup lang=\"properties\" title=\"Overriding the default Micrometer path\" >micrometer.web-context=my-micrometer ",
            "title": "Configuration"
        },
        {
            "location": "mp/metrics/micrometer",
            "text": "<markup lang=\"java\" title=\"Adding Micrometer annotations to JAX-RS resource GET methods\" >import io.micrometer.core.annotation.Counted; import io.micrometer.core.annotation.Timed; private static final String PERSONALIZED_GETS_COUNTER_NAME = \"personalizedGets\"; private static final String PERSONALIZED_GETS_COUNTER_DESCRIPTION = \"Counts personalized GET operations\"; private static final String GETS_TIMER_NAME = \"allGets\"; private static final String GETS_TIMER_DESCRIPTION = \"Tracks all GET operations\"; @GET @Produces(MediaType.APPLICATION_JSON) @Timed(value = GETS_TIMER_NAME, description = GETS_TIMER_DESCRIPTION, histogram = true) public JsonObject getDefaultMessage() { return createResponse(\"World\"); } @Path(\"/{name}\") @GET @Produces(MediaType.APPLICATION_JSON) @Counted(value = PERSONALIZED_GETS_COUNTER_NAME, description = PERSONALIZED_GETS_COUNTER_DESCRIPTION) @Timed(value = GETS_TIMER_NAME, description = GETS_TIMER_DESCRIPTION, histogram = true) public JsonObject getMessage(@PathParam(\"name\") String name) { return createResponse(name); } Declare constants used in annotating multiple methods. Use @Timed to time and count both GET methods. Use @Counted to count the accesses to the GET method that returns a personalized greeting. ",
            "title": "Add Micrometer annotations"
        },
        {
            "location": "mp/metrics/micrometer",
            "text": " Unless you specify otherwise, Helidon uses defaults for any built-in Micrometer meter registry. For example, Helidon configures the built-in Prometheus registry using PrometheusConfig.DEFAULT . To use configuration to control the selection and behavior of Helidon&#8217;s built-in Micrometer meter registries, include in your configuration (such as application.yaml ) a micrometer.builtin-registries section. <markup lang=\"properties\" title=\"Enroll Prometheus built-in meter registry using default configuration\" >micrometer.builtin-registries.0.type=prometheus <markup lang=\"properties\" title=\"Enroll Prometheus built-in meter registry with non-default configuration\" >micrometer.builtin-registries.0.type=prometheus micrometer.builtin-registries.0.prefix=myPrefix Note that the first config example is equivalent to the default Helidon Micrometer behavior; Helidon by default supports the Prometheus meter registry. The configuration keys that are valid for the builtin-registries child entries depend on the type of Micrometer meter registry. For example, support in Helidon for the Prometheus meter registry respects the prefix configuration setting but other meter registries might not and might support other settings. Refer to the documentation for the meter registry you want to configure to find out what items apply to that registry type. Helidon does not validate the configuration keys you specify for meter registries. ",
            "title": "Overriding Defaults for Built-in Meter Registry Types"
        },
        {
            "location": "mp/metrics/micrometer",
            "text": " In addition to annotating your methods, you can create, look up, and update metrics explicitly in your code. Add the following injection to a bean: <markup lang=\"java\" title=\"Inject the MeterRegistry \" >@Inject private MeterRegistry registry; Helidon automatically injects a reference to the MeterRegistry it manages into your code. Your code can use the normal Micrometer API with this registry to create, find, update, and even delete meters. Overriding Defaults for Built-in Meter Registry Types Unless you specify otherwise, Helidon uses defaults for any built-in Micrometer meter registry. For example, Helidon configures the built-in Prometheus registry using PrometheusConfig.DEFAULT . To use configuration to control the selection and behavior of Helidon&#8217;s built-in Micrometer meter registries, include in your configuration (such as application.yaml ) a micrometer.builtin-registries section. <markup lang=\"properties\" title=\"Enroll Prometheus built-in meter registry using default configuration\" >micrometer.builtin-registries.0.type=prometheus <markup lang=\"properties\" title=\"Enroll Prometheus built-in meter registry with non-default configuration\" >micrometer.builtin-registries.0.type=prometheus micrometer.builtin-registries.0.prefix=myPrefix Note that the first config example is equivalent to the default Helidon Micrometer behavior; Helidon by default supports the Prometheus meter registry. The configuration keys that are valid for the builtin-registries child entries depend on the type of Micrometer meter registry. For example, support in Helidon for the Prometheus meter registry respects the prefix configuration setting but other meter registries might not and might support other settings. Refer to the documentation for the meter registry you want to configure to find out what items apply to that registry type. Helidon does not validate the configuration keys you specify for meter registries. ",
            "title": "Using the Helidon-provided Micrometer MeterRegistry from Code"
        },
        {
            "location": "mp/metrics/micrometer",
            "text": " Helidon MP includes an example application which uses Micrometer support. The examples below take you step-by-step through the process of enhancing the Helidon MP QuickStart application to track (by time and invocation count) all GET methods and to count all requests for a personalized greeting. Add Micrometer annotations <markup lang=\"java\" title=\"Adding Micrometer annotations to JAX-RS resource GET methods\" >import io.micrometer.core.annotation.Counted; import io.micrometer.core.annotation.Timed; private static final String PERSONALIZED_GETS_COUNTER_NAME = \"personalizedGets\"; private static final String PERSONALIZED_GETS_COUNTER_DESCRIPTION = \"Counts personalized GET operations\"; private static final String GETS_TIMER_NAME = \"allGets\"; private static final String GETS_TIMER_DESCRIPTION = \"Tracks all GET operations\"; @GET @Produces(MediaType.APPLICATION_JSON) @Timed(value = GETS_TIMER_NAME, description = GETS_TIMER_DESCRIPTION, histogram = true) public JsonObject getDefaultMessage() { return createResponse(\"World\"); } @Path(\"/{name}\") @GET @Produces(MediaType.APPLICATION_JSON) @Counted(value = PERSONALIZED_GETS_COUNTER_NAME, description = PERSONALIZED_GETS_COUNTER_DESCRIPTION) @Timed(value = GETS_TIMER_NAME, description = GETS_TIMER_DESCRIPTION, histogram = true) public JsonObject getMessage(@PathParam(\"name\") String name) { return createResponse(name); } Declare constants used in annotating multiple methods. Use @Timed to time and count both GET methods. Use @Counted to count the accesses to the GET method that returns a personalized greeting. Using the Helidon-provided Micrometer MeterRegistry from Code In addition to annotating your methods, you can create, look up, and update metrics explicitly in your code. Add the following injection to a bean: <markup lang=\"java\" title=\"Inject the MeterRegistry \" >@Inject private MeterRegistry registry; Helidon automatically injects a reference to the MeterRegistry it manages into your code. Your code can use the normal Micrometer API with this registry to create, find, update, and even delete meters. Overriding Defaults for Built-in Meter Registry Types Unless you specify otherwise, Helidon uses defaults for any built-in Micrometer meter registry. For example, Helidon configures the built-in Prometheus registry using PrometheusConfig.DEFAULT . To use configuration to control the selection and behavior of Helidon&#8217;s built-in Micrometer meter registries, include in your configuration (such as application.yaml ) a micrometer.builtin-registries section. <markup lang=\"properties\" title=\"Enroll Prometheus built-in meter registry using default configuration\" >micrometer.builtin-registries.0.type=prometheus <markup lang=\"properties\" title=\"Enroll Prometheus built-in meter registry with non-default configuration\" >micrometer.builtin-registries.0.type=prometheus micrometer.builtin-registries.0.prefix=myPrefix Note that the first config example is equivalent to the default Helidon Micrometer behavior; Helidon by default supports the Prometheus meter registry. The configuration keys that are valid for the builtin-registries child entries depend on the type of Micrometer meter registry. For example, support in Helidon for the Prometheus meter registry respects the prefix configuration setting but other meter registries might not and might support other settings. Refer to the documentation for the meter registry you want to configure to find out what items apply to that registry type. Helidon does not validate the configuration keys you specify for meter registries. ",
            "title": "Examples"
        },
        {
            "location": "mp/metrics/micrometer",
            "text": " The Micrometer website describes the project as a whole and has links to more information. ",
            "title": "Additional Information"
        },
        {
            "location": "mp/metrics/prometheus-exemplar-support",
            "text": " Overview Maven Coordinates Usage Examples Additional Information ",
            "title": "Contents"
        },
        {
            "location": "mp/metrics/prometheus-exemplar-support",
            "text": " A metric typically reflects the usage of a single point in your service processing multiple requests over time. A value such as the total time consumed by a given REST endpoint underscores the aggregate nature of metric values; Helidon accumulates the time from all requests in the total duration. Tracing, on the other hand, captures the usage of multiple parts of your code as your service responds to a single request. Metrics and tracing come together in Helidon&#8217;s support for examplars. Note exemplar - one that serves as a model or example &#8201;&#8212;&#8201;Merriam-Webster Dictionary In the context of metrics, an exemplar for a given metric is a specific sample which, in some sense, made a typical contribution to the metric&#8217;s value. For example, an exemplar for a SimpleTimer might be a sample in which the duration it contributed to the value of a SimpleTimer is near the mean of the durations over all samples. The metrics output identifies the exemplar sample using the trace ID of the trace which triggered that sample. ",
            "title": "Overview"
        },
        {
            "location": "mp/metrics/prometheus-exemplar-support",
            "text": " To enable OpenMetrics exemplar support add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics-trace-exemplar&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; Also, include the Helidon integration module for a tracing implementation (such as Helidon Zipkin ) <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-zipkin&lt;/artifactId&gt; &lt;/dependency&gt; Add the Helidon tracing component itself: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-tracing&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "mp/metrics/prometheus-exemplar-support",
            "text": " Helidon automatically records a sample (label, value, and timestamp) with each update to a histogram, simple timer, or counter. When a client accesses the /metrics endpoint, Helidon adds the label, value, and timestamp to the OpenMetrics response. Helidon adds an exemplar to the output for each statistical value&#8212;&#8203;such as minimum, maximum, mean, and quantiles&#8212;&#8203;for histograms, timers, simple times, and for counters. The exemplar information in the output describes a single, actual sample that is representative of the statistical value. Helidon chooses the representative examplar for each value using information that is already recorded for each type of metric: Selection of exemplars for types of metrics Metric Value Type Example Sample Selected as Exemplar corresponds directly to a specific sample minimum or maximum of a value any sample with that exact value collects samples into bins (quantiles) histogram (as with timers) any sample from the bin maintains running statistics counts, totals most recent sample computes its value from multiple samples mean sample for which its value is at least as close as other samples to the statistical calculation In cases with multiple representative samples (for example, two samples' values are equally close to the mean), Helidon chooses one of them arbitrarily. ",
            "title": "Interpreting Exemplars"
        },
        {
            "location": "mp/metrics/prometheus-exemplar-support",
            "text": " In the OpenMetrics output, an exemplar actually appears as a comment appended to the normal OpenMetrics output. <markup title=\"OpenMetrics format with exemplars\" > metric-identifier metric-value # exemplar-label sample-timestamp Even downstream consumers of OpenMetrics output that do not recognize the exemplar format should continue to work correctly (as long as they do recognize comments). But some consumers, such as trace collectors and their U/Is, understand the exemplar format, and they allow you to browse metrics and then navigate directly to the trace for the metric&#8217;s exemplar. ",
            "title": "Output Format"
        },
        {
            "location": "mp/metrics/prometheus-exemplar-support",
            "text": " Once you add the appropriate dependencies to your project, exemplar support runs automatically as part of Helidon metrics. You do not need to change your application or configuration. Interpreting Exemplars Helidon automatically records a sample (label, value, and timestamp) with each update to a histogram, simple timer, or counter. When a client accesses the /metrics endpoint, Helidon adds the label, value, and timestamp to the OpenMetrics response. Helidon adds an exemplar to the output for each statistical value&#8212;&#8203;such as minimum, maximum, mean, and quantiles&#8212;&#8203;for histograms, timers, simple times, and for counters. The exemplar information in the output describes a single, actual sample that is representative of the statistical value. Helidon chooses the representative examplar for each value using information that is already recorded for each type of metric: Selection of exemplars for types of metrics Metric Value Type Example Sample Selected as Exemplar corresponds directly to a specific sample minimum or maximum of a value any sample with that exact value collects samples into bins (quantiles) histogram (as with timers) any sample from the bin maintains running statistics counts, totals most recent sample computes its value from multiple samples mean sample for which its value is at least as close as other samples to the statistical calculation In cases with multiple representative samples (for example, two samples' values are equally close to the mean), Helidon chooses one of them arbitrarily. Output Format In the OpenMetrics output, an exemplar actually appears as a comment appended to the normal OpenMetrics output. <markup title=\"OpenMetrics format with exemplars\" > metric-identifier metric-value # exemplar-label sample-timestamp Even downstream consumers of OpenMetrics output that do not recognize the exemplar format should continue to work correctly (as long as they do recognize comments). But some consumers, such as trace collectors and their U/Is, understand the exemplar format, and they allow you to browse metrics and then navigate directly to the trace for the metric&#8217;s exemplar. ",
            "title": "Usage"
        },
        {
            "location": "mp/metrics/prometheus-exemplar-support",
            "text": " Once you enable exemplar support you can see the exemplars in the metrics output. # TYPE application_getTimer_mean_seconds gauge application_getTimer_mean_seconds 8.303030623354298E-4 # {trace_id=\"067632454fe4e8d1\"} 1.14701E-4 1617723032.570000 # TYPE application_getTimer_max_seconds gauge application_getTimer_max_seconds 0.003952636 # {trace_id=\"fce183094e471633\"} 0.003952636 1617723030.108000 # TYPE application_getTimer_min_seconds gauge application_getTimer_min_seconds 5.5254E-5 # {trace_id=\"0b1a4bf22b4e47fd\"} 5.5254E-5 1617723033.311000 The first exemplar is a sample with value at least as close to the mean for that timer as any other sample. This second exemplar is for an exact sample with value the same as the maximum value the timer has observed. # TYPE application_globalRequestTracker_total counter # HELP application_globalRequestTracker_total application_globalRequestTracker_total 4 # {trace_id=\"daf26fe35fee9917\"} 0.001183992 1617725180.234000 # TYPE application_globalRequestTracker_elapsedTime_seconds gauge application_globalRequestTracker_elapsedTime_seconds 0.030309068 # {trace_id=\"daf26fe35fee9917\"} 0.001183992 1617725180.234000 The exemplar for a SimpleTimer is the same for the total and the elapsedTime sub metrics: always the most recent sample which updated the SimpleTimer . ",
            "title": "Examples"
        },
        {
            "location": "mp/metrics/prometheus-exemplar-support",
            "text": " Brief discussion of exemplars in the OpenMetrics spec ",
            "title": "Additional Information"
        },
        {
            "location": "mp/openapi",
            "text": " Overview Maven Coordinates Usage Configuration Examples Additional Information Reference ",
            "title": "Contents"
        },
        {
            "location": "mp/openapi",
            "text": " The OpenAPI specification defines a standard way to express the interface exposed by a REST service. The MicroProfile OpenAPI spec explains how MicroProfile embraces OpenAPI, adding annotations, configuration, and a service provider interface (SPI). Helidon MP implements the MicroProfile OpenAPI specification. The OpenAPI support in Helidon MP performs two main tasks: Build an in-memory model of the REST API your service implements. Expose the model in text format (typically YAML) via the /openapi endpoint. To construct the model, Helidon gathers information about the service API from whichever of these sources are present in the application: a model reader The SPI defines an interface you can implement in your application for programmatically providing part or all of the model; a static OpenAPI document file packaged as part of your service; OpenAPI annotations; a filter class The SPI defines an interface you can implement in your application which can mask parts of the model. ",
            "title": "Overview"
        },
        {
            "location": "mp/openapi",
            "text": " To enable MicroProfile OpenAPI either add a dependency on the helidon-microprofile bundle or add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.eclipse.microprofile.openapi&lt;/groupId&gt; &lt;artifactId&gt;microprofile-openapi-api&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.openapi&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-openapi&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; Defines the MicroProfile OpenAPI annotations so you can use them in your code. Adds the Helidon MP OpenAPI runtime support. ",
            "title": "Maven Coordinates"
        },
        {
            "location": "mp/openapi",
            "text": " You can very simply add support for OpenAPI to your Helidon MP application. This document shows what changes you need to make to your application and how to access the OpenAPI document for your application at runtime. ",
            "title": "OpenAPI support in Helidon MP"
        },
        {
            "location": "mp/openapi",
            "text": " You can add MicroProfile OpenAPI annotations to the endpoints in your source code. These annotations allow the Helidon MP OpenAPI runtime to discover the endpoints and information about them via CDI at app start-up. Here is one of the endpoints, annotated for OpenAPI, from the example mentioned earlier: <markup lang=\"java\" >@GET @Operation(summary = \"Returns a generic greeting\", description = \"Greets the user generically\") @APIResponse(description = \"Simple JSON containing the greeting\", content = @Content(mediaType = \"application/json\", schema = @Schema(implementation = GreetingMessage.class))) @Produces(MediaType.APPLICATION_JSON) public JsonObject getDefaultMessage() {...} @Operation gives information about this endpoint. @APIResponse describes the HTTP response and declares its media type and contents. You can also define any request parameters the endpoint expects, although this endpoint uses none. This excerpt shows only a few annotations for illustration. The Helidon MP OpenAPI example illustrates more, and the MicroProfile OpenAPI spec describes them all. ",
            "title": "Annotate the endpoints in your app"
        },
        {
            "location": "mp/openapi",
            "text": " Add a static file at META-INF/openapi.yml , META-INF/openapi.yaml , or META-INF/openapi.json . Tools such as Swagger let you describe your app&#8217;s API and they then generate an OpenAPI document file which you can include in your application so OpenAPI can use it. ",
            "title": "Provide a static OpenAPI file"
        },
        {
            "location": "mp/openapi",
            "text": " Write a Java class that implements the OpenAPI org.eclipse.microprofile.openapi.OASModelReader interface. Your model reader code programmatically adds elements to the internal model that OpenAPI builds. ",
            "title": "Write and configure a model reader class"
        },
        {
            "location": "mp/openapi",
            "text": " Add a static file at META-INF/openapi.yml , META-INF/openapi.yaml , or META-INF/openapi.json . Tools such as Swagger let you describe your app&#8217;s API and they then generate an OpenAPI document file which you can include in your application so OpenAPI can use it. ",
            "title": "Provide a static OpenAPI file"
        },
        {
            "location": "mp/openapi",
            "text": " Write a Java class that implements the OpenAPI org.eclipse.microprofile.openapi.OASModelReader interface. Your model reader code programmatically adds elements to the internal model that OpenAPI builds. Change your application&#8217;s MP configuration to set mp.openapi.model.reader as the fully-qualified class name of your class. ",
            "title": "Write and configure a model reader class"
        },
        {
            "location": "mp/openapi",
            "text": " Write a Java class that implements the OpenAPI org.eclipse.microprofile.openapi.OASFilter interface. As OpenAPI composes its internal model, it invokes your filter with each model element before adding the element to the model. Your filter can accept the element as-is, modify it, or suppress it. Change your application&#8217;s configuration to set mp.openapi.filter as the full-qualified class name of your class. ",
            "title": "Write and configure a filter class"
        },
        {
            "location": "mp/openapi",
            "text": " Helidon MP OpenAPI combines information from all of the following sources as it builds its in-memory model of your application&#8217;s API. It constructs the OpenAPI document from this internal model. Your application can use one or more of these techniques. Annotate the endpoints in your app You can add MicroProfile OpenAPI annotations to the endpoints in your source code. These annotations allow the Helidon MP OpenAPI runtime to discover the endpoints and information about them via CDI at app start-up. Here is one of the endpoints, annotated for OpenAPI, from the example mentioned earlier: <markup lang=\"java\" >@GET @Operation(summary = \"Returns a generic greeting\", description = \"Greets the user generically\") @APIResponse(description = \"Simple JSON containing the greeting\", content = @Content(mediaType = \"application/json\", schema = @Schema(implementation = GreetingMessage.class))) @Produces(MediaType.APPLICATION_JSON) public JsonObject getDefaultMessage() {...} @Operation gives information about this endpoint. @APIResponse describes the HTTP response and declares its media type and contents. You can also define any request parameters the endpoint expects, although this endpoint uses none. This excerpt shows only a few annotations for illustration. The Helidon MP OpenAPI example illustrates more, and the MicroProfile OpenAPI spec describes them all. Provide a static OpenAPI file Add a static file at META-INF/openapi.yml , META-INF/openapi.yaml , or META-INF/openapi.json . Tools such as Swagger let you describe your app&#8217;s API and they then generate an OpenAPI document file which you can include in your application so OpenAPI can use it. Write and configure a model reader class Write a Java class that implements the OpenAPI org.eclipse.microprofile.openapi.OASModelReader interface. Your model reader code programmatically adds elements to the internal model that OpenAPI builds. Provide a static OpenAPI file Add a static file at META-INF/openapi.yml , META-INF/openapi.yaml , or META-INF/openapi.json . Tools such as Swagger let you describe your app&#8217;s API and they then generate an OpenAPI document file which you can include in your application so OpenAPI can use it. Write and configure a model reader class Write a Java class that implements the OpenAPI org.eclipse.microprofile.openapi.OASModelReader interface. Your model reader code programmatically adds elements to the internal model that OpenAPI builds. Change your application&#8217;s MP configuration to set mp.openapi.model.reader as the fully-qualified class name of your class. Write and configure a filter class Write a Java class that implements the OpenAPI org.eclipse.microprofile.openapi.OASFilter interface. As OpenAPI composes its internal model, it invokes your filter with each model element before adding the element to the model. Your filter can accept the element as-is, modify it, or suppress it. Change your application&#8217;s configuration to set mp.openapi.filter as the full-qualified class name of your class. ",
            "title": "Furnish OpenAPI information about your endpoints"
        },
        {
            "location": "mp/openapi",
            "text": " To use OpenAPI from your Helidon MP app, in addition to adding dependencies as described above: Furnish OpenAPI information about your application&#8217;s endpoints. Update your application&#8217;s configuration (optional). Furnish OpenAPI information about your endpoints Helidon MP OpenAPI combines information from all of the following sources as it builds its in-memory model of your application&#8217;s API. It constructs the OpenAPI document from this internal model. Your application can use one or more of these techniques. Annotate the endpoints in your app You can add MicroProfile OpenAPI annotations to the endpoints in your source code. These annotations allow the Helidon MP OpenAPI runtime to discover the endpoints and information about them via CDI at app start-up. Here is one of the endpoints, annotated for OpenAPI, from the example mentioned earlier: <markup lang=\"java\" >@GET @Operation(summary = \"Returns a generic greeting\", description = \"Greets the user generically\") @APIResponse(description = \"Simple JSON containing the greeting\", content = @Content(mediaType = \"application/json\", schema = @Schema(implementation = GreetingMessage.class))) @Produces(MediaType.APPLICATION_JSON) public JsonObject getDefaultMessage() {...} @Operation gives information about this endpoint. @APIResponse describes the HTTP response and declares its media type and contents. You can also define any request parameters the endpoint expects, although this endpoint uses none. This excerpt shows only a few annotations for illustration. The Helidon MP OpenAPI example illustrates more, and the MicroProfile OpenAPI spec describes them all. Provide a static OpenAPI file Add a static file at META-INF/openapi.yml , META-INF/openapi.yaml , or META-INF/openapi.json . Tools such as Swagger let you describe your app&#8217;s API and they then generate an OpenAPI document file which you can include in your application so OpenAPI can use it. Write and configure a model reader class Write a Java class that implements the OpenAPI org.eclipse.microprofile.openapi.OASModelReader interface. Your model reader code programmatically adds elements to the internal model that OpenAPI builds. Provide a static OpenAPI file Add a static file at META-INF/openapi.yml , META-INF/openapi.yaml , or META-INF/openapi.json . Tools such as Swagger let you describe your app&#8217;s API and they then generate an OpenAPI document file which you can include in your application so OpenAPI can use it. Write and configure a model reader class Write a Java class that implements the OpenAPI org.eclipse.microprofile.openapi.OASModelReader interface. Your model reader code programmatically adds elements to the internal model that OpenAPI builds. Change your application&#8217;s MP configuration to set mp.openapi.model.reader as the fully-qualified class name of your class. Write and configure a filter class Write a Java class that implements the OpenAPI org.eclipse.microprofile.openapi.OASFilter interface. As OpenAPI composes its internal model, it invokes your filter with each model element before adding the element to the model. Your filter can accept the element as-is, modify it, or suppress it. Change your application&#8217;s configuration to set mp.openapi.filter as the full-qualified class name of your class. ",
            "title": "Changing your application"
        },
        {
            "location": "mp/openapi",
            "text": " Beyond the two config properties that denote the model reader and filter, Helidon MP OpenAPI supports a number of other mandated settings. These are described in the configuration section of the MicroProfile OpenAPI spec. ",
            "title": "Update your application configuration"
        },
        {
            "location": "mp/openapi",
            "text": " Once you add the MP OpenAPI dependency to your project, your application will automatically respond to the built-in endpoint&#8201;&#8212;&#8201; /openapi &#8201;&#8212;&#8201;and it will return the OpenAPI document describing the endpoints in your application. By default, per the MicroProfile OpenAPI spec, the default format of the OpenAPI document is YAML. There is not yet an adopted IANA YAML media type, but a proposed one specifically for OpenAPI documents that has some support is application/vnd.oai.openapi . That is what Helidon returns, by default. In addition, a client can specify the HTTP header Accept as either application/vnd.oai.openapi+json or application/json to request JSON. Alternatively, the client can pass the query parameter format as either JSON or YAML to receive application/json or application/vnd.oai.openapi (YAML) output, respectively. ",
            "title": "Accessing the REST Endpoint"
        },
        {
            "location": "mp/openapi",
            "text": " OpenAPI support in Helidon MP You can very simply add support for OpenAPI to your Helidon MP application. This document shows what changes you need to make to your application and how to access the OpenAPI document for your application at runtime. Changing your application To use OpenAPI from your Helidon MP app, in addition to adding dependencies as described above: Furnish OpenAPI information about your application&#8217;s endpoints. Update your application&#8217;s configuration (optional). Furnish OpenAPI information about your endpoints Helidon MP OpenAPI combines information from all of the following sources as it builds its in-memory model of your application&#8217;s API. It constructs the OpenAPI document from this internal model. Your application can use one or more of these techniques. Annotate the endpoints in your app You can add MicroProfile OpenAPI annotations to the endpoints in your source code. These annotations allow the Helidon MP OpenAPI runtime to discover the endpoints and information about them via CDI at app start-up. Here is one of the endpoints, annotated for OpenAPI, from the example mentioned earlier: <markup lang=\"java\" >@GET @Operation(summary = \"Returns a generic greeting\", description = \"Greets the user generically\") @APIResponse(description = \"Simple JSON containing the greeting\", content = @Content(mediaType = \"application/json\", schema = @Schema(implementation = GreetingMessage.class))) @Produces(MediaType.APPLICATION_JSON) public JsonObject getDefaultMessage() {...} @Operation gives information about this endpoint. @APIResponse describes the HTTP response and declares its media type and contents. You can also define any request parameters the endpoint expects, although this endpoint uses none. This excerpt shows only a few annotations for illustration. The Helidon MP OpenAPI example illustrates more, and the MicroProfile OpenAPI spec describes them all. Provide a static OpenAPI file Add a static file at META-INF/openapi.yml , META-INF/openapi.yaml , or META-INF/openapi.json . Tools such as Swagger let you describe your app&#8217;s API and they then generate an OpenAPI document file which you can include in your application so OpenAPI can use it. Write and configure a model reader class Write a Java class that implements the OpenAPI org.eclipse.microprofile.openapi.OASModelReader interface. Your model reader code programmatically adds elements to the internal model that OpenAPI builds. Provide a static OpenAPI file Add a static file at META-INF/openapi.yml , META-INF/openapi.yaml , or META-INF/openapi.json . Tools such as Swagger let you describe your app&#8217;s API and they then generate an OpenAPI document file which you can include in your application so OpenAPI can use it. Write and configure a model reader class Write a Java class that implements the OpenAPI org.eclipse.microprofile.openapi.OASModelReader interface. Your model reader code programmatically adds elements to the internal model that OpenAPI builds. Change your application&#8217;s MP configuration to set mp.openapi.model.reader as the fully-qualified class name of your class. Write and configure a filter class Write a Java class that implements the OpenAPI org.eclipse.microprofile.openapi.OASFilter interface. As OpenAPI composes its internal model, it invokes your filter with each model element before adding the element to the model. Your filter can accept the element as-is, modify it, or suppress it. Change your application&#8217;s configuration to set mp.openapi.filter as the full-qualified class name of your class. Update your application configuration Beyond the two config properties that denote the model reader and filter, Helidon MP OpenAPI supports a number of other mandated settings. These are described in the configuration section of the MicroProfile OpenAPI spec. Accessing the REST Endpoint Once you add the MP OpenAPI dependency to your project, your application will automatically respond to the built-in endpoint&#8201;&#8212;&#8201; /openapi &#8201;&#8212;&#8201;and it will return the OpenAPI document describing the endpoints in your application. By default, per the MicroProfile OpenAPI spec, the default format of the OpenAPI document is YAML. There is not yet an adopted IANA YAML media type, but a proposed one specifically for OpenAPI documents that has some support is application/vnd.oai.openapi . That is what Helidon returns, by default. In addition, a client can specify the HTTP header Accept as either application/vnd.oai.openapi+json or application/json to request JSON. Alternatively, the client can pass the query parameter format as either JSON or YAML to receive application/json or application/vnd.oai.openapi (YAML) output, respectively. ",
            "title": "Usage"
        },
        {
            "location": "mp/openapi",
            "text": " The MicroProfile OpenAPI specification gives a listing and brief examples of the annotations you can add to your code to convey OpenAPI information. The MicroProfile OpenAPI JavaDocs give full details of the annotations and the other classes and interfaces you can use in your code. ",
            "title": "API"
        },
        {
            "location": "mp/openapi",
            "text": " Optional configuration options key type default value description application-path-disable boolean false Sets whether the app path search should be disabled. cors CrossOriginConfig &#160; Assigns the CORS settings for the OpenAPI endpoint. custom-schema-registry-class string &#160; Sets the custom schema registry class. filter string &#160; Sets the developer-provided OpenAPI filter class name. model.reader string &#160; Sets the developer-provided OpenAPI model reader class name. scan.classes string[&#93; &#160; Specify the list of classes to scan. scan.disable boolean false Disable annotation scanning. scan.exclude.classes string[&#93; &#160; Specify the list of classes to exclude from scans. scan.exclude.packages string[&#93; &#160; Specify the list of packages to exclude from scans. scan.packages string[&#93; &#160; Specify the list of packages to scan. schema.* string &#160; Sets the schema for the indicated fully-qualified class name (represented here by '*'); value is the schema in JSON format. Repeat for multiple classes. servers string[&#93; &#160; Sets servers. servers.operation.* string[&#93; &#160; Sets alternative servers to service the indicated operation (represented here by '*'). Repeat for multiple operations. servers.path.* string[&#93; &#160; Sets alternative servers to service all operations at the indicated path (represented here by '*'). Repeat for multiple paths. static-file string META-INF/openapi.* Sets the file system path of the static OpenAPI document file. Default types are json , yaml , and yml . web-context string /openapi Sets the web context path for the OpenAPI endpoint. ",
            "title": "Configuration options"
        },
        {
            "location": "mp/openapi",
            "text": " Helidon OpenAPI configuration supports the following settings: Type: io.helidon.microprofile.openapi.MPOpenAPISupport <markup lang=\"text\" title=\"Config key\" >mp.openapi Configuration options Optional configuration options key type default value description application-path-disable boolean false Sets whether the app path search should be disabled. cors CrossOriginConfig &#160; Assigns the CORS settings for the OpenAPI endpoint. custom-schema-registry-class string &#160; Sets the custom schema registry class. filter string &#160; Sets the developer-provided OpenAPI filter class name. model.reader string &#160; Sets the developer-provided OpenAPI model reader class name. scan.classes string[&#93; &#160; Specify the list of classes to scan. scan.disable boolean false Disable annotation scanning. scan.exclude.classes string[&#93; &#160; Specify the list of classes to exclude from scans. scan.exclude.packages string[&#93; &#160; Specify the list of packages to exclude from scans. scan.packages string[&#93; &#160; Specify the list of packages to scan. schema.* string &#160; Sets the schema for the indicated fully-qualified class name (represented here by '*'); value is the schema in JSON format. Repeat for multiple classes. servers string[&#93; &#160; Sets servers. servers.operation.* string[&#93; &#160; Sets alternative servers to service the indicated operation (represented here by '*'). Repeat for multiple operations. servers.path.* string[&#93; &#160; Sets alternative servers to service all operations at the indicated path (represented here by '*'). Repeat for multiple paths. static-file string META-INF/openapi.* Sets the file system path of the static OpenAPI document file. Default types are json , yaml , and yml . web-context string /openapi Sets the web context path for the OpenAPI endpoint. ",
            "title": "Configuration"
        },
        {
            "location": "mp/openapi",
            "text": " This example shows a simple greeting application, similar to the one from the Helidon MP QuickStart, enhanced with OpenAPI support. <markup lang=\"java\" >@Path(\"/greeting\") @PUT @Operation(summary = \"Set the greeting prefix\", description = \"Permits the client to set the prefix part of the greeting (\\\"Hello\\\")\") @RequestBody( name = \"greeting\", description = \"Conveys the new greeting prefix to use in building greetings\", content = @Content( mediaType = \"application/json\", schema = @Schema(implementation = GreetingMessage.class), examples = @ExampleObject( name = \"greeting\", summary = \"Example greeting message to update\", value = \"New greeting message\"))) @Consumes(MediaType.APPLICATION_JSON) @Produces(MediaType.APPLICATION_JSON) public Response updateGreeting(JsonObject jsonObject) { ... } With @Operation annotation we document the current method. With @RequestBody annotation we document the content produced. Internal annotations @Content , @Schema and @ExampleObjects are used to give more details about the returned data. If we want to hide a specific path an OASFilter is used. The OASFilter interface allows application developers to receive callbacks for various key OpenAPI elements. The interface has a default implementation for every method, which allows application developers to only override the methods they care about. To use it, simply create an implementation of this interface and register it using the mp.openapi.filter configuration key, where the value is the fully qualified name of the filter class. The following example filter prevents information about a given path from appearing in the OpenAPI document. <markup lang=\"java\" >import org.eclipse.microprofile.openapi.models.Operation; import org.eclipse.microprofile.openapi.models.PathItem; public class SimpleAPIFilter implements OASFilter { @Override public PathItem filterPathItem(PathItem pathItem) { for (Map.Entry&lt;PathItem.HttpMethod, Operation&gt; methodOp : pathItem.getOperations().entrySet()) { if (SimpleAPIModelReader.DOOMED_OPERATION_ID .equals(methodOp.getValue().getOperationId())) { return null; } } return OASFilter.super.filterPathItem(pathItem); } } You can implement a model reader to provide all or part of the in-memory OpenAPI model programmatically. Helidon OpenAPI merges the model from the model reader with models from the other sources (a static file and annotations). The example model reader below creates an OpenAPI object describing two paths. It turns out that the filter described earlier will suppress one of the paths, but the model reader does not know or care. <markup lang=\"java\" >import org.eclipse.microprofile.openapi.OASFactory; import org.eclipse.microprofile.openapi.OASModelReader; import org.eclipse.microprofile.openapi.models.OpenAPI; import org.eclipse.microprofile.openapi.models.PathItem; import org.eclipse.microprofile.openapi.models.Paths; /** * Defines two paths using the OpenAPI model reader mechanism, one that should * be suppressed by the filter class and one that should appear in the published * OpenAPI document. */ public class SimpleAPIModelReader implements OASModelReader { /** * Path for the example endpoint added by this model reader that should be visible. */ public static final String MODEL_READER_PATH = \"/test/newpath\"; /** * Path for an endpoint that the filter should hide. */ public static final String DOOMED_PATH = \"/test/doomed\"; /** * ID for an endpoint that the filter should hide. */ public static final String DOOMED_OPERATION_ID = \"doomedPath\"; /** * Summary text for the endpoint. */ public static final String SUMMARY = \"A sample test endpoint from ModelReader\"; @Override public OpenAPI buildModel() { /* * Add two path items, one of which we expect to be removed by * the filter and a very simple one that will appear in the * published OpenAPI document. */ PathItem newPathItem = OASFactory.createPathItem() .GET(OASFactory.createOperation() .operationId(\"newPath\") .summary(SUMMARY)); PathItem doomedPathItem = OASFactory.createPathItem() .GET(OASFactory.createOperation() .operationId(DOOMED_OPERATION_ID) .summary(\"This should become invisible\")); OpenAPI openAPI = OASFactory.createOpenAPI(); Paths paths = OASFactory.createPaths() .addPathItem(MODEL_READER_PATH, newPathItem) .addPathItem(DOOMED_PATH, doomedPathItem); openAPI.paths(paths); return openAPI; } } Having written the filter and model reader classes, identify them by adding configuration to META-INF/microprofile-config.properties as the following example shows. <markup lang=\"properties\" >mp.openapi.filter=io.helidon.microprofile.examples.openapi.basic.internal.SimpleAPIFilter mp.openapi.model.reader=io.helidon.microprofile.examples.openapi.basic.internal.SimpleAPIModelReader Now just build and run: <markup lang=\"bash\" >mvn package java -jar target/helidon-examples-microprofile-openapi-basic.jar Try the endpoints: <markup lang=\"bash\" >curl -X GET http://localhost:8080/greet {\"message\":\"Hello World!\"} curl -X GET http://localhost:8080/openapi [lengthy OpenAPI document] The output describes not only then endpoints from GreetResource but also one contributed by the SimpleAPIModelReader . Full example is available in our official repository ",
            "title": "Helidon MP Basic OpenAPI Example"
        },
        {
            "location": "mp/openapi",
            "text": " Helidon MP includes a complete OpenAPI example based on the MP quick-start sample app. The rest of this section shows, step-by-step, how one might change the original QuickStart service to adopt OpenAPI. Helidon MP Basic OpenAPI Example This example shows a simple greeting application, similar to the one from the Helidon MP QuickStart, enhanced with OpenAPI support. <markup lang=\"java\" >@Path(\"/greeting\") @PUT @Operation(summary = \"Set the greeting prefix\", description = \"Permits the client to set the prefix part of the greeting (\\\"Hello\\\")\") @RequestBody( name = \"greeting\", description = \"Conveys the new greeting prefix to use in building greetings\", content = @Content( mediaType = \"application/json\", schema = @Schema(implementation = GreetingMessage.class), examples = @ExampleObject( name = \"greeting\", summary = \"Example greeting message to update\", value = \"New greeting message\"))) @Consumes(MediaType.APPLICATION_JSON) @Produces(MediaType.APPLICATION_JSON) public Response updateGreeting(JsonObject jsonObject) { ... } With @Operation annotation we document the current method. With @RequestBody annotation we document the content produced. Internal annotations @Content , @Schema and @ExampleObjects are used to give more details about the returned data. If we want to hide a specific path an OASFilter is used. The OASFilter interface allows application developers to receive callbacks for various key OpenAPI elements. The interface has a default implementation for every method, which allows application developers to only override the methods they care about. To use it, simply create an implementation of this interface and register it using the mp.openapi.filter configuration key, where the value is the fully qualified name of the filter class. The following example filter prevents information about a given path from appearing in the OpenAPI document. <markup lang=\"java\" >import org.eclipse.microprofile.openapi.models.Operation; import org.eclipse.microprofile.openapi.models.PathItem; public class SimpleAPIFilter implements OASFilter { @Override public PathItem filterPathItem(PathItem pathItem) { for (Map.Entry&lt;PathItem.HttpMethod, Operation&gt; methodOp : pathItem.getOperations().entrySet()) { if (SimpleAPIModelReader.DOOMED_OPERATION_ID .equals(methodOp.getValue().getOperationId())) { return null; } } return OASFilter.super.filterPathItem(pathItem); } } You can implement a model reader to provide all or part of the in-memory OpenAPI model programmatically. Helidon OpenAPI merges the model from the model reader with models from the other sources (a static file and annotations). The example model reader below creates an OpenAPI object describing two paths. It turns out that the filter described earlier will suppress one of the paths, but the model reader does not know or care. <markup lang=\"java\" >import org.eclipse.microprofile.openapi.OASFactory; import org.eclipse.microprofile.openapi.OASModelReader; import org.eclipse.microprofile.openapi.models.OpenAPI; import org.eclipse.microprofile.openapi.models.PathItem; import org.eclipse.microprofile.openapi.models.Paths; /** * Defines two paths using the OpenAPI model reader mechanism, one that should * be suppressed by the filter class and one that should appear in the published * OpenAPI document. */ public class SimpleAPIModelReader implements OASModelReader { /** * Path for the example endpoint added by this model reader that should be visible. */ public static final String MODEL_READER_PATH = \"/test/newpath\"; /** * Path for an endpoint that the filter should hide. */ public static final String DOOMED_PATH = \"/test/doomed\"; /** * ID for an endpoint that the filter should hide. */ public static final String DOOMED_OPERATION_ID = \"doomedPath\"; /** * Summary text for the endpoint. */ public static final String SUMMARY = \"A sample test endpoint from ModelReader\"; @Override public OpenAPI buildModel() { /* * Add two path items, one of which we expect to be removed by * the filter and a very simple one that will appear in the * published OpenAPI document. */ PathItem newPathItem = OASFactory.createPathItem() .GET(OASFactory.createOperation() .operationId(\"newPath\") .summary(SUMMARY)); PathItem doomedPathItem = OASFactory.createPathItem() .GET(OASFactory.createOperation() .operationId(DOOMED_OPERATION_ID) .summary(\"This should become invisible\")); OpenAPI openAPI = OASFactory.createOpenAPI(); Paths paths = OASFactory.createPaths() .addPathItem(MODEL_READER_PATH, newPathItem) .addPathItem(DOOMED_PATH, doomedPathItem); openAPI.paths(paths); return openAPI; } } Having written the filter and model reader classes, identify them by adding configuration to META-INF/microprofile-config.properties as the following example shows. <markup lang=\"properties\" >mp.openapi.filter=io.helidon.microprofile.examples.openapi.basic.internal.SimpleAPIFilter mp.openapi.model.reader=io.helidon.microprofile.examples.openapi.basic.internal.SimpleAPIModelReader Now just build and run: <markup lang=\"bash\" >mvn package java -jar target/helidon-examples-microprofile-openapi-basic.jar Try the endpoints: <markup lang=\"bash\" >curl -X GET http://localhost:8080/greet {\"message\":\"Hello World!\"} curl -X GET http://localhost:8080/openapi [lengthy OpenAPI document] The output describes not only then endpoints from GreetResource but also one contributed by the SimpleAPIModelReader . Full example is available in our official repository ",
            "title": "Examples"
        },
        {
            "location": "mp/openapi",
            "text": " A Jandex index stores information about the classes and methods in your app and what annotations they have. It allows CDI to process annotations faster during your application&#8217;s start-up. Add the Jandex maven plug-in to the &lt;build&gt;&lt;plugins&gt; section of your pom.xml : <markup lang=\"xml\" >&lt;plugin&gt; &lt;groupId&gt;org.jboss.jandex&lt;/groupId&gt; &lt;artifactId&gt;jandex-maven-plugin&lt;/artifactId&gt; &lt;version&gt;{jandex-plugin-version}&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;make-index&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;jandex&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; When you build your app maven should include the index META-INF/jandex.idx in the JAR. Note If you do not modify your build to create the index then the Helidon MP OpenAPI runtime automatically creates one in memory during app start-up. This slows down your app start-up and, depending on how CDI is configured, might inadvertently miss information. We strongly recommend using the Jandex plug-in to build the index into your app. ",
            "title": "Building the Jandex index"
        },
        {
            "location": "mp/openapi",
            "text": " Building the Jandex index A Jandex index stores information about the classes and methods in your app and what annotations they have. It allows CDI to process annotations faster during your application&#8217;s start-up. Add the Jandex maven plug-in to the &lt;build&gt;&lt;plugins&gt; section of your pom.xml : <markup lang=\"xml\" >&lt;plugin&gt; &lt;groupId&gt;org.jboss.jandex&lt;/groupId&gt; &lt;artifactId&gt;jandex-maven-plugin&lt;/artifactId&gt; &lt;version&gt;{jandex-plugin-version}&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;make-index&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;jandex&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; When you build your app maven should include the index META-INF/jandex.idx in the JAR. Note If you do not modify your build to create the index then the Helidon MP OpenAPI runtime automatically creates one in memory during app start-up. This slows down your app start-up and, depending on how CDI is configured, might inadvertently miss information. We strongly recommend using the Jandex plug-in to build the index into your app. ",
            "title": "Additional Information"
        },
        {
            "location": "mp/openapi",
            "text": " MicroProfile OpenAPI GitHub Repository MicroProfile OpenAPI Specification ",
            "title": "Reference"
        },
        {
            "location": "mp/persistence",
            "text": " Overview Named Data Source Integration Project Setup Setting Up a Connection Pool Setting Up the HikariCP Connection Pool Maven Coordinates (HikariCP) Setting Up the Oracle Universal Connection Pool Maven Coordinates (Oracle Universal Connection Pool) Setting Up a Database Driver Setting Up H2 Maven Coordinates (H2) Setting Up Oracle JDBC Maven Coordinates (Oracle JDBC) Configuration Examples Usage Jakarta Transactions (JTA) Integration Maven Coordinates Configuration Usage Jakarta Persistence (JPA) Integration Project Setup Common Maven Coordinates Setting Up Static Metamodel Generation Maven Coordinates (Hibernate ORM) Setting Up Static Weaving (Hibernate ORM) Maven Coordinates (Eclipselink) Setting Up Static Weaving (Eclipselink) Configuration Usage Examples References ",
            "title": "Contents"
        },
        {
            "location": "mp/persistence",
            "text": " Helidon MP comes with deep integration for three specification-defined, broadly persistence-related technologies that can be used together or separately: Named data sources Jakarta Transactions (JTA) Jakarta Persistence (JPA) Each integration&#8217;s setup, configuration, and usage are described below. ",
            "title": "Overview"
        },
        {
            "location": "mp/persistence",
            "text": " Helidon MP&#8217;s named data source integration allows you to safely inject managed javax.sql.DataSource instances that are annotated with jakarta.inject.Named annotations into your Helidon MP application. java.sql.Connection objects acquired from these data sources will be pooled by your choice of one of two possible connection pool implementations. The connections managed by the connection pool will be supplied by your relational database vendor&#8217;s JDBC driver. How you set up Helidon MP&#8217;s named data source integration differs depending on which of these two connection pools, which JDBC driver, and which relational database product you use. Representative setups are described below. The list of such setups is not exhaustive. ",
            "title": "Overview"
        },
        {
            "location": "mp/persistence",
            "text": " Helidon MP&#8217;s named data source integration requires a connection pool implementation. Helidon MP comes with support for two connection pools: HikariCP Oracle Universal Connection Pool You can choose to use either, but not both. Details concerning each connection pool&#8217;s setup are described below. ",
            "title": "Overview"
        },
        {
            "location": "mp/persistence",
            "text": " To include the HikariCP connection pool in your Helidon MP application: Ensure your dependencies are managed Ensure the following &lt;dependency&gt; element is present as a child element of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.cdi&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-cdi-datasource-hikaricp&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; The scope is runtime , indicating that the HikariCP integration will be available on the runtime classpath. ",
            "title": "Maven Coordinates (HikariCP)"
        },
        {
            "location": "mp/persistence",
            "text": " Maven Coordinates (HikariCP) To include the HikariCP connection pool in your Helidon MP application: Ensure your dependencies are managed Ensure the following &lt;dependency&gt; element is present as a child element of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.cdi&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-cdi-datasource-hikaricp&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; The scope is runtime , indicating that the HikariCP integration will be available on the runtime classpath. ",
            "title": "Setting Up the HikariCP Connection Pool"
        },
        {
            "location": "mp/persistence",
            "text": " To include the Oracle Universal Connection Pool in your Helidon MP application: Ensure your dependencies are managed Ensure the following &lt;dependency&gt; element is present as a child element of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.cdi&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-cdi-datasource-ucp&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; The scope is runtime , indicating that the Oracle Universal Connection Pool integration will be available on the runtime classpath. ",
            "title": "Maven Coordinates (Oracle Universal Connection Pool)"
        },
        {
            "location": "mp/persistence",
            "text": " Maven Coordinates (Oracle Universal Connection Pool) To include the Oracle Universal Connection Pool in your Helidon MP application: Ensure your dependencies are managed Ensure the following &lt;dependency&gt; element is present as a child element of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.cdi&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-cdi-datasource-ucp&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; The scope is runtime , indicating that the Oracle Universal Connection Pool integration will be available on the runtime classpath. ",
            "title": "Setting up the Oracle Universal Connection Pool"
        },
        {
            "location": "mp/persistence",
            "text": " Overview Helidon MP&#8217;s named data source integration requires a connection pool implementation. Helidon MP comes with support for two connection pools: HikariCP Oracle Universal Connection Pool You can choose to use either, but not both. Details concerning each connection pool&#8217;s setup are described below. Setting Up the HikariCP Connection Pool Maven Coordinates (HikariCP) To include the HikariCP connection pool in your Helidon MP application: Ensure your dependencies are managed Ensure the following &lt;dependency&gt; element is present as a child element of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.cdi&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-cdi-datasource-hikaricp&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; The scope is runtime , indicating that the HikariCP integration will be available on the runtime classpath. Setting up the Oracle Universal Connection Pool Maven Coordinates (Oracle Universal Connection Pool) To include the Oracle Universal Connection Pool in your Helidon MP application: Ensure your dependencies are managed Ensure the following &lt;dependency&gt; element is present as a child element of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.cdi&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-cdi-datasource-ucp&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; The scope is runtime , indicating that the Oracle Universal Connection Pool integration will be available on the runtime classpath. ",
            "title": "Setting Up a Connection Pool"
        },
        {
            "location": "mp/persistence",
            "text": " Regardless of which connection pool you use, at the lowest level JDBC database driver classes are responsible for making any connections to a relational database. JDBC database driver classes are database-product-specific. Once you have decided upon a relational database product to use, and JDBC driver classes to use to connect to it, ensure your dependencies are managed , and then ensure that a runtime -scoped &lt;dependency&gt; element describing your JDBC driver classes is present as a child element of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element. See the JDBC 4.3 Specification for more information about JDBC. Representative setups are described below. The list of such setups is not exhaustive. ",
            "title": "Overview"
        },
        {
            "location": "mp/persistence",
            "text": " To include the H2 JDBC driver classes in your Helidon MP application so your application can connect to an H2 database (whether in-memory or persistent): Ensure your dependencies are managed Ensure the following &lt;dependency&gt; element is present as a child element of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;com.h2database&lt;/groupId&gt; &lt;artifactId&gt;h2&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; The scope is runtime , indicating that the H2 JDBC driver classes will be available on the runtime classpath. ",
            "title": "Maven Coordinates (H2)"
        },
        {
            "location": "mp/persistence",
            "text": " Maven Coordinates (H2) To include the H2 JDBC driver classes in your Helidon MP application so your application can connect to an H2 database (whether in-memory or persistent): Ensure your dependencies are managed Ensure the following &lt;dependency&gt; element is present as a child element of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;com.h2database&lt;/groupId&gt; &lt;artifactId&gt;h2&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; The scope is runtime , indicating that the H2 JDBC driver classes will be available on the runtime classpath. ",
            "title": "Setting Up H2"
        },
        {
            "location": "mp/persistence",
            "text": " To include the Oracle JDBC driver classes in your Helidon MP application so your application can connect to an Oracle database : Ensure your dependencies are managed Read and understand Developer&#8217;s Guide For Oracle JDBC 21c on Maven Central For a basic setup, ensure the following &lt;dependency&gt; element is present as a child element of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;com.oracle.database.jdbc&lt;/groupId&gt; &lt;artifactId&gt;ojdbc11&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; See [Developer&#8217;s Guide For Oracle JDBC 21c on Maven Central for more details. The ojdbc11 artifact implements relevant parts of the JDBC 4.3 specification , which forms part of Java 17, which is the Java version targeted by Helidon 3. The scope is runtime , indicating that the Oracle JDBC driver classes will be available on the runtime classpath. ",
            "title": "Maven Coordinates (Oracle JDBC)"
        },
        {
            "location": "mp/persistence",
            "text": " Maven Coordinates (Oracle JDBC) To include the Oracle JDBC driver classes in your Helidon MP application so your application can connect to an Oracle database : Ensure your dependencies are managed Read and understand Developer&#8217;s Guide For Oracle JDBC 21c on Maven Central For a basic setup, ensure the following &lt;dependency&gt; element is present as a child element of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;com.oracle.database.jdbc&lt;/groupId&gt; &lt;artifactId&gt;ojdbc11&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; See [Developer&#8217;s Guide For Oracle JDBC 21c on Maven Central for more details. The ojdbc11 artifact implements relevant parts of the JDBC 4.3 specification , which forms part of Java 17, which is the Java version targeted by Helidon 3. The scope is runtime , indicating that the Oracle JDBC driver classes will be available on the runtime classpath. ",
            "title": "Setting Up Oracle JDBC"
        },
        {
            "location": "mp/persistence",
            "text": " Overview Regardless of which connection pool you use, at the lowest level JDBC database driver classes are responsible for making any connections to a relational database. JDBC database driver classes are database-product-specific. Once you have decided upon a relational database product to use, and JDBC driver classes to use to connect to it, ensure your dependencies are managed , and then ensure that a runtime -scoped &lt;dependency&gt; element describing your JDBC driver classes is present as a child element of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element. See the JDBC 4.3 Specification for more information about JDBC. Representative setups are described below. The list of such setups is not exhaustive. Setting Up H2 Maven Coordinates (H2) To include the H2 JDBC driver classes in your Helidon MP application so your application can connect to an H2 database (whether in-memory or persistent): Ensure your dependencies are managed Ensure the following &lt;dependency&gt; element is present as a child element of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;com.h2database&lt;/groupId&gt; &lt;artifactId&gt;h2&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; The scope is runtime , indicating that the H2 JDBC driver classes will be available on the runtime classpath. Setting Up Oracle JDBC Maven Coordinates (Oracle JDBC) To include the Oracle JDBC driver classes in your Helidon MP application so your application can connect to an Oracle database : Ensure your dependencies are managed Read and understand Developer&#8217;s Guide For Oracle JDBC 21c on Maven Central For a basic setup, ensure the following &lt;dependency&gt; element is present as a child element of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;com.oracle.database.jdbc&lt;/groupId&gt; &lt;artifactId&gt;ojdbc11&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; See [Developer&#8217;s Guide For Oracle JDBC 21c on Maven Central for more details. The ojdbc11 artifact implements relevant parts of the JDBC 4.3 specification , which forms part of Java 17, which is the Java version targeted by Helidon 3. The scope is runtime , indicating that the Oracle JDBC driver classes will be available on the runtime classpath. ",
            "title": "Setting Up a Database Driver"
        },
        {
            "location": "mp/persistence",
            "text": " Setting Up a Connection Pool Overview Helidon MP&#8217;s named data source integration requires a connection pool implementation. Helidon MP comes with support for two connection pools: HikariCP Oracle Universal Connection Pool You can choose to use either, but not both. Details concerning each connection pool&#8217;s setup are described below. Setting Up the HikariCP Connection Pool Maven Coordinates (HikariCP) To include the HikariCP connection pool in your Helidon MP application: Ensure your dependencies are managed Ensure the following &lt;dependency&gt; element is present as a child element of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.cdi&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-cdi-datasource-hikaricp&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; The scope is runtime , indicating that the HikariCP integration will be available on the runtime classpath. Setting up the Oracle Universal Connection Pool Maven Coordinates (Oracle Universal Connection Pool) To include the Oracle Universal Connection Pool in your Helidon MP application: Ensure your dependencies are managed Ensure the following &lt;dependency&gt; element is present as a child element of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.cdi&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-cdi-datasource-ucp&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; The scope is runtime , indicating that the Oracle Universal Connection Pool integration will be available on the runtime classpath. Setting Up a Database Driver Overview Regardless of which connection pool you use, at the lowest level JDBC database driver classes are responsible for making any connections to a relational database. JDBC database driver classes are database-product-specific. Once you have decided upon a relational database product to use, and JDBC driver classes to use to connect to it, ensure your dependencies are managed , and then ensure that a runtime -scoped &lt;dependency&gt; element describing your JDBC driver classes is present as a child element of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element. See the JDBC 4.3 Specification for more information about JDBC. Representative setups are described below. The list of such setups is not exhaustive. Setting Up H2 Maven Coordinates (H2) To include the H2 JDBC driver classes in your Helidon MP application so your application can connect to an H2 database (whether in-memory or persistent): Ensure your dependencies are managed Ensure the following &lt;dependency&gt; element is present as a child element of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;com.h2database&lt;/groupId&gt; &lt;artifactId&gt;h2&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; The scope is runtime , indicating that the H2 JDBC driver classes will be available on the runtime classpath. Setting Up Oracle JDBC Maven Coordinates (Oracle JDBC) To include the Oracle JDBC driver classes in your Helidon MP application so your application can connect to an Oracle database : Ensure your dependencies are managed Read and understand Developer&#8217;s Guide For Oracle JDBC 21c on Maven Central For a basic setup, ensure the following &lt;dependency&gt; element is present as a child element of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;com.oracle.database.jdbc&lt;/groupId&gt; &lt;artifactId&gt;ojdbc11&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; See [Developer&#8217;s Guide For Oracle JDBC 21c on Maven Central for more details. The ojdbc11 artifact implements relevant parts of the JDBC 4.3 specification , which forms part of Java 17, which is the Java version targeted by Helidon 3. The scope is runtime , indicating that the Oracle JDBC driver classes will be available on the runtime classpath. ",
            "title": "Project Setup"
        },
        {
            "location": "mp/persistence",
            "text": " Each connection pool supported by Helidon&#8217;s named data source integration support is, itself, a DataSource that wraps a vendor-supplied DataSource present in the JDBC driver classes you added to your project. You must configure both the pool and the vendor-supplied DataSource . To configure Helidon MP&#8217;s named data source integration: Decide where each property of the configuration will reside, as permitted by Helidon MP&#8217;s MicroProfile Config implementation Create configuration suitable for the combination of your selected connection pool and your selected vendor-supplied DataSource implementation in those locations Helidon MP&#8217;s named data source integration relies on Helidon MP&#8217;s usage of MicroProfile Config , so you have many choices for each configuration property when deciding on your configuration&#8217;s location in (1) above. The configuration property values themselves are necessarily specific to the connection pool you selected, and to the vendor-supplied DataSource responsible for actually connecting to your relational database. In general, at a minimum, in your configuration you typically supply: Information so the connection pool knows which vendor-supplied DataSource implementation to manage A JDBC URL specific to the vendor-supplied DataSource describing where the database is located, so the managed vendor-supplied DataSource knows how to connect to it Information required for the vendor-supplied DataSource to authenticate to the database and otherwise tailor itself to it Some examples for representative configurations follow. The list of such configurations is not exhaustive. ",
            "title": "Overview"
        },
        {
            "location": "mp/persistence",
            "text": " All MicroProfile Config-compatible property names for Helidon MP&#8217;s named data source integration follow a common pattern: objecttype . datasourcename . propertyname The name of a given configuration property always begins with the objecttype portion: a fully-qualified Java class name of the object being configured. Configuration for Helidon MP&#8217;s named data source integration concerns the behavior of javax.sql.DataSource objects, so Helidon MP&#8217;s named data source integration configuration property names begin with javax.sql.DataSource . A period ( . ) separates the objecttype portion from the rest of the property name. The datasourcename portion, the name of the data source being configured, comes next. It cannot contain a period ( . ). A period ( . ) separates the datasourcename portion from the rest of the property name. The propertyname portion, identifying the connection-pool- or vendor-supplied- DataSource -specific configuration property name, comes last. It may contain periods ( . ). As an example, configuration to set an imaginary foo.bar property on the test data source&#8217;s associated connection pool or vendor-specific DataSource to baz looks like this in Java .properties format: <markup lang=\"properties\" >javax.sql.DataSource.test.foo.bar=baz The objecttype portion of the configuration property name is javax.sql.DataSource . The datasourcename portion of the configuration property name is test . The propertyname portion of the configuration property name is foo.bar . ",
            "title": "Configuration Prefixes"
        },
        {
            "location": "mp/persistence",
            "text": " Here is an example of some named data source configuration as might be found in a src/main/resources/META-INF/microprofile-config.properties configuration source: <markup lang=\"properties\" >javax.sql.DataSource.yourDataSourceName.somePropertyOfYourConnectionPoolAndDataSource = itsValue javax.sql.DataSource.yourDataSourceName.someOtherPropertyOfYourConnectionPoolAndDataSource = anotherValue ",
            "title": "Example: META-INF/microprofile-config.properties Classpath Resource"
        },
        {
            "location": "mp/persistence",
            "text": " Here is an example of some named data source configuration using system properties on the command line instead: <markup lang=\"bash\" >java \\ -Djavax.sql.DataSource.yourDataSourceName.somePropertyOfYourConnectionPoolAndDataSource=itsValue \\ -Djavax.sql.DataSource.yourDataSourceName.someOtherPropertyOfYourConnectionPoolAndDataSource=anotherValue \\ # ... ",
            "title": "Example: System Properties Set on the Command Line"
        },
        {
            "location": "mp/persistence",
            "text": " Here is an example of some named data source configuration using environment variables as typed directly into a command line shell, relying on MicroProfile Config&#8217;s mapping rules , since many shells will not understand environment variable names with periods (.) in them: <markup lang=\"bash\" >JAVAX_SQL_DATASOURCE_YOURDATASOURCENAME_SOMEPROPERTYOFYOURCONNECTIONPOOLANDDATASOURCE=itsValue \\ JAVAX_SQL_DATASOURCE_YOURDATASOURCENAME_SOMEOTHERPROPERTYOFYOURCONNECTIONPOOLANDDATASOURCE=anotherValue \\ java # ... ",
            "title": "Example: Environment Variables Set on the Command Line"
        },
        {
            "location": "mp/persistence",
            "text": " Here is an example of some named data source configuration using environment variables as supplied via the env shell command , thus removing the need for MicroProfile Config&#8217;s mapping rules : <markup lang=\"bash\" >env 'javax.sql.DataSource.yourDataSourceName.somePropertyOfYourConnectionPoolAndDataSource=itsValue' \\ 'javax.sql.DataSource.yourDataSourceName.someOtherPropertyOfYourConnectionPoolAndDataSource=anotherValue' \\ java # ... ",
            "title": "Example: Environment Variables Set By the env Command"
        },
        {
            "location": "mp/persistence",
            "text": " Here is an example of some named data source configuration as might be found in a src/main/resources/application.yaml classpath resource: <markup lang=\"yaml\" >javax: sql: DataSource: yourDataSourceName: somePropertyOfYourConnectionPoolAndDataSource: itsValue someOtherPropertyOfYourConnectionPoolAndDataSource: anotherValue ",
            "title": "Example: application.yaml Classpath Resource"
        },
        {
            "location": "mp/persistence",
            "text": " This example presumes you have: set up the Oracle Universal Connection Pool set up Oracle JDBC This example, in Java properties file format, configures an Oracle Universal Connection Pool-managed data source named main to connect to an Oracle Database on localhost port 1521 , using the oracle.jdbc.poolOracleDataSource vendor-supplied DataSource , with a service name of XE , a user of scott , and a password of tiger : <markup lang=\"properties\" >javax.sql.DataSource.main.connectionFactoryClassName = oracle.jdbc.pool.OracleDataSource javax.sql.DataSource.main.url = jdbc:oracle:thin://@localhost:1521/XE javax.sql.DataSource.main.user = scott javax.sql.DataSource.main.password = tiger Why connectionFactoryClassName ? See PoolDataSourceImpl#setConnectionFactoryClassName(String) . See Thin-style Service Name Syntax . In general, the properties that can be set on the Oracle Universal Connection Pool can be inferred from the \"setter\" methods found in the javadoc for the PoolDataSourceImpl class . In general, the properties that can be set on the oracle.jdbc.pool.OracleDataSource DataSource implementation can be inferred from the \"setter\" methods found in its javadoc . Unlike HikariCP , the Oracle Universal Connection Pool does not distinguish cleanly between configuration properties that affect its behavior and those that affect the behavior of the vendor-supplied DataSource implementation whose connections it pools. For example, in the example above it is not possible to tell that connectionFactoryClassName is a property of the Oracle Universal Connection Pool , and user is a property of the oracle.jdbc.pool.OracleDataSource DataSource implementation . In some cases, the Oracle Universal Connection Pool will set the given property on both the connection pool itself and on the vendor-supplied DataSource it manages . ",
            "title": "Example: Configuring the Oracle Universal Connection Pool and Oracle JDBC"
        },
        {
            "location": "mp/persistence",
            "text": " This example presumes you have: set up the HikariCP connection pool set up H2 This example, in Java properties file format, configures a HikariCP-managed data source named test to connect to an in-memory H2 database named unit-testing with a user of sa and an empty password: <markup lang=\"properties\" >javax.sql.DataSource.test.dataSourceClassName = org.h2.jdbcx.JdbcDataSource javax.sql.DataSource.test.dataSource.url = jdbc:h2:mem:unit-testing;DB_CLOSE_DELAY=-1 javax.sql.DataSource.test.dataSource.user = sa javax.sql.DataSource.test.dataSource.password = Why dataSourceClassName ? See HikariCP&#8217;s configuration documentation for information about how HikariCP separates configuration of the connection pool itself from configuration of the vendor-supplied DataSource . Why dataSource. ? See PropertyElf.java , lines 47–49 . See the H2 database&#8217;s documentation about its URL format . HikariCP&#8217;s configuration properties are described on its Github repository . Properties that should be forwarded on to the vendor-supplied DataSource are prefixed with dataSource. as seen in the example above. In general, the properties that can be set on the org.h2.jdbcx.JdbcDataSource vendor-supplied DataSource can be inferred from the \"setter\" methods found in its javadoc . ",
            "title": "Example: Configuring the HikariCP Connection Pool and H2"
        },
        {
            "location": "mp/persistence",
            "text": " Here are some examples illustrating general named data source configuration patterns in various common MicroProfile Config-compatible locations . Example: META-INF/microprofile-config.properties Classpath Resource Here is an example of some named data source configuration as might be found in a src/main/resources/META-INF/microprofile-config.properties configuration source: <markup lang=\"properties\" >javax.sql.DataSource.yourDataSourceName.somePropertyOfYourConnectionPoolAndDataSource = itsValue javax.sql.DataSource.yourDataSourceName.someOtherPropertyOfYourConnectionPoolAndDataSource = anotherValue Example: System Properties Set on the Command Line Here is an example of some named data source configuration using system properties on the command line instead: <markup lang=\"bash\" >java \\ -Djavax.sql.DataSource.yourDataSourceName.somePropertyOfYourConnectionPoolAndDataSource=itsValue \\ -Djavax.sql.DataSource.yourDataSourceName.someOtherPropertyOfYourConnectionPoolAndDataSource=anotherValue \\ # ... Example: Environment Variables Set on the Command Line Here is an example of some named data source configuration using environment variables as typed directly into a command line shell, relying on MicroProfile Config&#8217;s mapping rules , since many shells will not understand environment variable names with periods (.) in them: <markup lang=\"bash\" >JAVAX_SQL_DATASOURCE_YOURDATASOURCENAME_SOMEPROPERTYOFYOURCONNECTIONPOOLANDDATASOURCE=itsValue \\ JAVAX_SQL_DATASOURCE_YOURDATASOURCENAME_SOMEOTHERPROPERTYOFYOURCONNECTIONPOOLANDDATASOURCE=anotherValue \\ java # ... Example: Environment Variables Set By the env Command Here is an example of some named data source configuration using environment variables as supplied via the env shell command , thus removing the need for MicroProfile Config&#8217;s mapping rules : <markup lang=\"bash\" >env 'javax.sql.DataSource.yourDataSourceName.somePropertyOfYourConnectionPoolAndDataSource=itsValue' \\ 'javax.sql.DataSource.yourDataSourceName.someOtherPropertyOfYourConnectionPoolAndDataSource=anotherValue' \\ java # ... Example: application.yaml Classpath Resource Here is an example of some named data source configuration as might be found in a src/main/resources/application.yaml classpath resource: <markup lang=\"yaml\" >javax: sql: DataSource: yourDataSourceName: somePropertyOfYourConnectionPoolAndDataSource: itsValue someOtherPropertyOfYourConnectionPoolAndDataSource: anotherValue Example: Configuring the Oracle Universal Connection Pool and Oracle JDBC This example presumes you have: set up the Oracle Universal Connection Pool set up Oracle JDBC This example, in Java properties file format, configures an Oracle Universal Connection Pool-managed data source named main to connect to an Oracle Database on localhost port 1521 , using the oracle.jdbc.poolOracleDataSource vendor-supplied DataSource , with a service name of XE , a user of scott , and a password of tiger : <markup lang=\"properties\" >javax.sql.DataSource.main.connectionFactoryClassName = oracle.jdbc.pool.OracleDataSource javax.sql.DataSource.main.url = jdbc:oracle:thin://@localhost:1521/XE javax.sql.DataSource.main.user = scott javax.sql.DataSource.main.password = tiger Why connectionFactoryClassName ? See PoolDataSourceImpl#setConnectionFactoryClassName(String) . See Thin-style Service Name Syntax . In general, the properties that can be set on the Oracle Universal Connection Pool can be inferred from the \"setter\" methods found in the javadoc for the PoolDataSourceImpl class . In general, the properties that can be set on the oracle.jdbc.pool.OracleDataSource DataSource implementation can be inferred from the \"setter\" methods found in its javadoc . Unlike HikariCP , the Oracle Universal Connection Pool does not distinguish cleanly between configuration properties that affect its behavior and those that affect the behavior of the vendor-supplied DataSource implementation whose connections it pools. For example, in the example above it is not possible to tell that connectionFactoryClassName is a property of the Oracle Universal Connection Pool , and user is a property of the oracle.jdbc.pool.OracleDataSource DataSource implementation . In some cases, the Oracle Universal Connection Pool will set the given property on both the connection pool itself and on the vendor-supplied DataSource it manages . Example: Configuring the HikariCP Connection Pool and H2 This example presumes you have: set up the HikariCP connection pool set up H2 This example, in Java properties file format, configures a HikariCP-managed data source named test to connect to an in-memory H2 database named unit-testing with a user of sa and an empty password: <markup lang=\"properties\" >javax.sql.DataSource.test.dataSourceClassName = org.h2.jdbcx.JdbcDataSource javax.sql.DataSource.test.dataSource.url = jdbc:h2:mem:unit-testing;DB_CLOSE_DELAY=-1 javax.sql.DataSource.test.dataSource.user = sa javax.sql.DataSource.test.dataSource.password = Why dataSourceClassName ? See HikariCP&#8217;s configuration documentation for information about how HikariCP separates configuration of the connection pool itself from configuration of the vendor-supplied DataSource . Why dataSource. ? See PropertyElf.java , lines 47–49 . See the H2 database&#8217;s documentation about its URL format . HikariCP&#8217;s configuration properties are described on its Github repository . Properties that should be forwarded on to the vendor-supplied DataSource are prefixed with dataSource. as seen in the example above. In general, the properties that can be set on the org.h2.jdbcx.JdbcDataSource vendor-supplied DataSource can be inferred from the \"setter\" methods found in its javadoc . ",
            "title": "Examples"
        },
        {
            "location": "mp/persistence",
            "text": " You use Helidon MP&#8217;s named data source integration in the same way, regardless of your choices of vendor-supplied DataSource and connection pool. To use Helidon MP&#8217;s named data source integration in your application, once it has been set up and configured , create an ordinary DataSource -typed injection point in a Java class representing a CDI bean somewhere in your application, annotated with the name of the data source you wish to use. Here is how to define such a field-backed injection point: <markup lang=\"java\" >import javax.sql.DataSource; import jakarta.inject.Inject; import jakarta.inject.Named; // ... @Inject @Named(\"test\") private DataSource ds; @Inject marks the field as an injection point. Its behavior is defined by the Jakarta Dependency Injection specification . @Named(\"test\") says to use the data source named test (as declared by the datasourcename portion of a named data source configuration property). The field injection point has a type of javax.sql.DataSource , and the field itselfmay be named anything you like. Here is how to define such a constructor parameter injection point: <markup lang=\"java\" >import javax.sql.DataSource; import jakarta.inject.Inject; import jakarta.inject.Named; // ... private final DataSource ds; @Inject public SomeObject(@Named(\"test\") DataSource ds) { this.ds = ds; } This is the field whose value will be set in the constructor. @Inject marks the constructor as one containing parameter injection points. Its behavior is defined by the Jakarta Dependency Injection specification . @Named(\"test\") says to use the data source named test (as declared by the datasourcename portion of a named data source configuration property). The parameter injection point has a type of javax.sql.DataSource , and the parameter itself may be named anything you like. The injected argument will never be null . ",
            "title": "Usage"
        },
        {
            "location": "mp/persistence",
            "text": " Overview Each connection pool supported by Helidon&#8217;s named data source integration support is, itself, a DataSource that wraps a vendor-supplied DataSource present in the JDBC driver classes you added to your project. You must configure both the pool and the vendor-supplied DataSource . To configure Helidon MP&#8217;s named data source integration: Decide where each property of the configuration will reside, as permitted by Helidon MP&#8217;s MicroProfile Config implementation Create configuration suitable for the combination of your selected connection pool and your selected vendor-supplied DataSource implementation in those locations Helidon MP&#8217;s named data source integration relies on Helidon MP&#8217;s usage of MicroProfile Config , so you have many choices for each configuration property when deciding on your configuration&#8217;s location in (1) above. The configuration property values themselves are necessarily specific to the connection pool you selected, and to the vendor-supplied DataSource responsible for actually connecting to your relational database. In general, at a minimum, in your configuration you typically supply: Information so the connection pool knows which vendor-supplied DataSource implementation to manage A JDBC URL specific to the vendor-supplied DataSource describing where the database is located, so the managed vendor-supplied DataSource knows how to connect to it Information required for the vendor-supplied DataSource to authenticate to the database and otherwise tailor itself to it Some examples for representative configurations follow. The list of such configurations is not exhaustive. Configuration Prefixes All MicroProfile Config-compatible property names for Helidon MP&#8217;s named data source integration follow a common pattern: objecttype . datasourcename . propertyname The name of a given configuration property always begins with the objecttype portion: a fully-qualified Java class name of the object being configured. Configuration for Helidon MP&#8217;s named data source integration concerns the behavior of javax.sql.DataSource objects, so Helidon MP&#8217;s named data source integration configuration property names begin with javax.sql.DataSource . A period ( . ) separates the objecttype portion from the rest of the property name. The datasourcename portion, the name of the data source being configured, comes next. It cannot contain a period ( . ). A period ( . ) separates the datasourcename portion from the rest of the property name. The propertyname portion, identifying the connection-pool- or vendor-supplied- DataSource -specific configuration property name, comes last. It may contain periods ( . ). As an example, configuration to set an imaginary foo.bar property on the test data source&#8217;s associated connection pool or vendor-specific DataSource to baz looks like this in Java .properties format: <markup lang=\"properties\" >javax.sql.DataSource.test.foo.bar=baz The objecttype portion of the configuration property name is javax.sql.DataSource . The datasourcename portion of the configuration property name is test . The propertyname portion of the configuration property name is foo.bar . Examples Here are some examples illustrating general named data source configuration patterns in various common MicroProfile Config-compatible locations . Example: META-INF/microprofile-config.properties Classpath Resource Here is an example of some named data source configuration as might be found in a src/main/resources/META-INF/microprofile-config.properties configuration source: <markup lang=\"properties\" >javax.sql.DataSource.yourDataSourceName.somePropertyOfYourConnectionPoolAndDataSource = itsValue javax.sql.DataSource.yourDataSourceName.someOtherPropertyOfYourConnectionPoolAndDataSource = anotherValue Example: System Properties Set on the Command Line Here is an example of some named data source configuration using system properties on the command line instead: <markup lang=\"bash\" >java \\ -Djavax.sql.DataSource.yourDataSourceName.somePropertyOfYourConnectionPoolAndDataSource=itsValue \\ -Djavax.sql.DataSource.yourDataSourceName.someOtherPropertyOfYourConnectionPoolAndDataSource=anotherValue \\ # ... Example: Environment Variables Set on the Command Line Here is an example of some named data source configuration using environment variables as typed directly into a command line shell, relying on MicroProfile Config&#8217;s mapping rules , since many shells will not understand environment variable names with periods (.) in them: <markup lang=\"bash\" >JAVAX_SQL_DATASOURCE_YOURDATASOURCENAME_SOMEPROPERTYOFYOURCONNECTIONPOOLANDDATASOURCE=itsValue \\ JAVAX_SQL_DATASOURCE_YOURDATASOURCENAME_SOMEOTHERPROPERTYOFYOURCONNECTIONPOOLANDDATASOURCE=anotherValue \\ java # ... Example: Environment Variables Set By the env Command Here is an example of some named data source configuration using environment variables as supplied via the env shell command , thus removing the need for MicroProfile Config&#8217;s mapping rules : <markup lang=\"bash\" >env 'javax.sql.DataSource.yourDataSourceName.somePropertyOfYourConnectionPoolAndDataSource=itsValue' \\ 'javax.sql.DataSource.yourDataSourceName.someOtherPropertyOfYourConnectionPoolAndDataSource=anotherValue' \\ java # ... Example: application.yaml Classpath Resource Here is an example of some named data source configuration as might be found in a src/main/resources/application.yaml classpath resource: <markup lang=\"yaml\" >javax: sql: DataSource: yourDataSourceName: somePropertyOfYourConnectionPoolAndDataSource: itsValue someOtherPropertyOfYourConnectionPoolAndDataSource: anotherValue Example: Configuring the Oracle Universal Connection Pool and Oracle JDBC This example presumes you have: set up the Oracle Universal Connection Pool set up Oracle JDBC This example, in Java properties file format, configures an Oracle Universal Connection Pool-managed data source named main to connect to an Oracle Database on localhost port 1521 , using the oracle.jdbc.poolOracleDataSource vendor-supplied DataSource , with a service name of XE , a user of scott , and a password of tiger : <markup lang=\"properties\" >javax.sql.DataSource.main.connectionFactoryClassName = oracle.jdbc.pool.OracleDataSource javax.sql.DataSource.main.url = jdbc:oracle:thin://@localhost:1521/XE javax.sql.DataSource.main.user = scott javax.sql.DataSource.main.password = tiger Why connectionFactoryClassName ? See PoolDataSourceImpl#setConnectionFactoryClassName(String) . See Thin-style Service Name Syntax . In general, the properties that can be set on the Oracle Universal Connection Pool can be inferred from the \"setter\" methods found in the javadoc for the PoolDataSourceImpl class . In general, the properties that can be set on the oracle.jdbc.pool.OracleDataSource DataSource implementation can be inferred from the \"setter\" methods found in its javadoc . Unlike HikariCP , the Oracle Universal Connection Pool does not distinguish cleanly between configuration properties that affect its behavior and those that affect the behavior of the vendor-supplied DataSource implementation whose connections it pools. For example, in the example above it is not possible to tell that connectionFactoryClassName is a property of the Oracle Universal Connection Pool , and user is a property of the oracle.jdbc.pool.OracleDataSource DataSource implementation . In some cases, the Oracle Universal Connection Pool will set the given property on both the connection pool itself and on the vendor-supplied DataSource it manages . Example: Configuring the HikariCP Connection Pool and H2 This example presumes you have: set up the HikariCP connection pool set up H2 This example, in Java properties file format, configures a HikariCP-managed data source named test to connect to an in-memory H2 database named unit-testing with a user of sa and an empty password: <markup lang=\"properties\" >javax.sql.DataSource.test.dataSourceClassName = org.h2.jdbcx.JdbcDataSource javax.sql.DataSource.test.dataSource.url = jdbc:h2:mem:unit-testing;DB_CLOSE_DELAY=-1 javax.sql.DataSource.test.dataSource.user = sa javax.sql.DataSource.test.dataSource.password = Why dataSourceClassName ? See HikariCP&#8217;s configuration documentation for information about how HikariCP separates configuration of the connection pool itself from configuration of the vendor-supplied DataSource . Why dataSource. ? See PropertyElf.java , lines 47–49 . See the H2 database&#8217;s documentation about its URL format . HikariCP&#8217;s configuration properties are described on its Github repository . Properties that should be forwarded on to the vendor-supplied DataSource are prefixed with dataSource. as seen in the example above. In general, the properties that can be set on the org.h2.jdbcx.JdbcDataSource vendor-supplied DataSource can be inferred from the \"setter\" methods found in its javadoc . Usage You use Helidon MP&#8217;s named data source integration in the same way, regardless of your choices of vendor-supplied DataSource and connection pool. To use Helidon MP&#8217;s named data source integration in your application, once it has been set up and configured , create an ordinary DataSource -typed injection point in a Java class representing a CDI bean somewhere in your application, annotated with the name of the data source you wish to use. Here is how to define such a field-backed injection point: <markup lang=\"java\" >import javax.sql.DataSource; import jakarta.inject.Inject; import jakarta.inject.Named; // ... @Inject @Named(\"test\") private DataSource ds; @Inject marks the field as an injection point. Its behavior is defined by the Jakarta Dependency Injection specification . @Named(\"test\") says to use the data source named test (as declared by the datasourcename portion of a named data source configuration property). The field injection point has a type of javax.sql.DataSource , and the field itselfmay be named anything you like. Here is how to define such a constructor parameter injection point: <markup lang=\"java\" >import javax.sql.DataSource; import jakarta.inject.Inject; import jakarta.inject.Named; // ... private final DataSource ds; @Inject public SomeObject(@Named(\"test\") DataSource ds) { this.ds = ds; } This is the field whose value will be set in the constructor. @Inject marks the constructor as one containing parameter injection points. Its behavior is defined by the Jakarta Dependency Injection specification . @Named(\"test\") says to use the data source named test (as declared by the datasourcename portion of a named data source configuration property). The parameter injection point has a type of javax.sql.DataSource , and the parameter itself may be named anything you like. The injected argument will never be null . ",
            "title": "Configuration"
        },
        {
            "location": "mp/persistence",
            "text": " Overview Helidon MP&#8217;s named data source integration allows you to safely inject managed javax.sql.DataSource instances that are annotated with jakarta.inject.Named annotations into your Helidon MP application. java.sql.Connection objects acquired from these data sources will be pooled by your choice of one of two possible connection pool implementations. The connections managed by the connection pool will be supplied by your relational database vendor&#8217;s JDBC driver. How you set up Helidon MP&#8217;s named data source integration differs depending on which of these two connection pools, which JDBC driver, and which relational database product you use. Representative setups are described below. The list of such setups is not exhaustive. Project Setup Setting Up a Connection Pool Overview Helidon MP&#8217;s named data source integration requires a connection pool implementation. Helidon MP comes with support for two connection pools: HikariCP Oracle Universal Connection Pool You can choose to use either, but not both. Details concerning each connection pool&#8217;s setup are described below. Setting Up the HikariCP Connection Pool Maven Coordinates (HikariCP) To include the HikariCP connection pool in your Helidon MP application: Ensure your dependencies are managed Ensure the following &lt;dependency&gt; element is present as a child element of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.cdi&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-cdi-datasource-hikaricp&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; The scope is runtime , indicating that the HikariCP integration will be available on the runtime classpath. Setting up the Oracle Universal Connection Pool Maven Coordinates (Oracle Universal Connection Pool) To include the Oracle Universal Connection Pool in your Helidon MP application: Ensure your dependencies are managed Ensure the following &lt;dependency&gt; element is present as a child element of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.cdi&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-cdi-datasource-ucp&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; The scope is runtime , indicating that the Oracle Universal Connection Pool integration will be available on the runtime classpath. Setting Up a Database Driver Overview Regardless of which connection pool you use, at the lowest level JDBC database driver classes are responsible for making any connections to a relational database. JDBC database driver classes are database-product-specific. Once you have decided upon a relational database product to use, and JDBC driver classes to use to connect to it, ensure your dependencies are managed , and then ensure that a runtime -scoped &lt;dependency&gt; element describing your JDBC driver classes is present as a child element of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element. See the JDBC 4.3 Specification for more information about JDBC. Representative setups are described below. The list of such setups is not exhaustive. Setting Up H2 Maven Coordinates (H2) To include the H2 JDBC driver classes in your Helidon MP application so your application can connect to an H2 database (whether in-memory or persistent): Ensure your dependencies are managed Ensure the following &lt;dependency&gt; element is present as a child element of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;com.h2database&lt;/groupId&gt; &lt;artifactId&gt;h2&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; The scope is runtime , indicating that the H2 JDBC driver classes will be available on the runtime classpath. Setting Up Oracle JDBC Maven Coordinates (Oracle JDBC) To include the Oracle JDBC driver classes in your Helidon MP application so your application can connect to an Oracle database : Ensure your dependencies are managed Read and understand Developer&#8217;s Guide For Oracle JDBC 21c on Maven Central For a basic setup, ensure the following &lt;dependency&gt; element is present as a child element of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;com.oracle.database.jdbc&lt;/groupId&gt; &lt;artifactId&gt;ojdbc11&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; See [Developer&#8217;s Guide For Oracle JDBC 21c on Maven Central for more details. The ojdbc11 artifact implements relevant parts of the JDBC 4.3 specification , which forms part of Java 17, which is the Java version targeted by Helidon 3. The scope is runtime , indicating that the Oracle JDBC driver classes will be available on the runtime classpath. Configuration Overview Each connection pool supported by Helidon&#8217;s named data source integration support is, itself, a DataSource that wraps a vendor-supplied DataSource present in the JDBC driver classes you added to your project. You must configure both the pool and the vendor-supplied DataSource . To configure Helidon MP&#8217;s named data source integration: Decide where each property of the configuration will reside, as permitted by Helidon MP&#8217;s MicroProfile Config implementation Create configuration suitable for the combination of your selected connection pool and your selected vendor-supplied DataSource implementation in those locations Helidon MP&#8217;s named data source integration relies on Helidon MP&#8217;s usage of MicroProfile Config , so you have many choices for each configuration property when deciding on your configuration&#8217;s location in (1) above. The configuration property values themselves are necessarily specific to the connection pool you selected, and to the vendor-supplied DataSource responsible for actually connecting to your relational database. In general, at a minimum, in your configuration you typically supply: Information so the connection pool knows which vendor-supplied DataSource implementation to manage A JDBC URL specific to the vendor-supplied DataSource describing where the database is located, so the managed vendor-supplied DataSource knows how to connect to it Information required for the vendor-supplied DataSource to authenticate to the database and otherwise tailor itself to it Some examples for representative configurations follow. The list of such configurations is not exhaustive. Configuration Prefixes All MicroProfile Config-compatible property names for Helidon MP&#8217;s named data source integration follow a common pattern: objecttype . datasourcename . propertyname The name of a given configuration property always begins with the objecttype portion: a fully-qualified Java class name of the object being configured. Configuration for Helidon MP&#8217;s named data source integration concerns the behavior of javax.sql.DataSource objects, so Helidon MP&#8217;s named data source integration configuration property names begin with javax.sql.DataSource . A period ( . ) separates the objecttype portion from the rest of the property name. The datasourcename portion, the name of the data source being configured, comes next. It cannot contain a period ( . ). A period ( . ) separates the datasourcename portion from the rest of the property name. The propertyname portion, identifying the connection-pool- or vendor-supplied- DataSource -specific configuration property name, comes last. It may contain periods ( . ). As an example, configuration to set an imaginary foo.bar property on the test data source&#8217;s associated connection pool or vendor-specific DataSource to baz looks like this in Java .properties format: <markup lang=\"properties\" >javax.sql.DataSource.test.foo.bar=baz The objecttype portion of the configuration property name is javax.sql.DataSource . The datasourcename portion of the configuration property name is test . The propertyname portion of the configuration property name is foo.bar . Examples Here are some examples illustrating general named data source configuration patterns in various common MicroProfile Config-compatible locations . Example: META-INF/microprofile-config.properties Classpath Resource Here is an example of some named data source configuration as might be found in a src/main/resources/META-INF/microprofile-config.properties configuration source: <markup lang=\"properties\" >javax.sql.DataSource.yourDataSourceName.somePropertyOfYourConnectionPoolAndDataSource = itsValue javax.sql.DataSource.yourDataSourceName.someOtherPropertyOfYourConnectionPoolAndDataSource = anotherValue Example: System Properties Set on the Command Line Here is an example of some named data source configuration using system properties on the command line instead: <markup lang=\"bash\" >java \\ -Djavax.sql.DataSource.yourDataSourceName.somePropertyOfYourConnectionPoolAndDataSource=itsValue \\ -Djavax.sql.DataSource.yourDataSourceName.someOtherPropertyOfYourConnectionPoolAndDataSource=anotherValue \\ # ... Example: Environment Variables Set on the Command Line Here is an example of some named data source configuration using environment variables as typed directly into a command line shell, relying on MicroProfile Config&#8217;s mapping rules , since many shells will not understand environment variable names with periods (.) in them: <markup lang=\"bash\" >JAVAX_SQL_DATASOURCE_YOURDATASOURCENAME_SOMEPROPERTYOFYOURCONNECTIONPOOLANDDATASOURCE=itsValue \\ JAVAX_SQL_DATASOURCE_YOURDATASOURCENAME_SOMEOTHERPROPERTYOFYOURCONNECTIONPOOLANDDATASOURCE=anotherValue \\ java # ... Example: Environment Variables Set By the env Command Here is an example of some named data source configuration using environment variables as supplied via the env shell command , thus removing the need for MicroProfile Config&#8217;s mapping rules : <markup lang=\"bash\" >env 'javax.sql.DataSource.yourDataSourceName.somePropertyOfYourConnectionPoolAndDataSource=itsValue' \\ 'javax.sql.DataSource.yourDataSourceName.someOtherPropertyOfYourConnectionPoolAndDataSource=anotherValue' \\ java # ... Example: application.yaml Classpath Resource Here is an example of some named data source configuration as might be found in a src/main/resources/application.yaml classpath resource: <markup lang=\"yaml\" >javax: sql: DataSource: yourDataSourceName: somePropertyOfYourConnectionPoolAndDataSource: itsValue someOtherPropertyOfYourConnectionPoolAndDataSource: anotherValue Example: Configuring the Oracle Universal Connection Pool and Oracle JDBC This example presumes you have: set up the Oracle Universal Connection Pool set up Oracle JDBC This example, in Java properties file format, configures an Oracle Universal Connection Pool-managed data source named main to connect to an Oracle Database on localhost port 1521 , using the oracle.jdbc.poolOracleDataSource vendor-supplied DataSource , with a service name of XE , a user of scott , and a password of tiger : <markup lang=\"properties\" >javax.sql.DataSource.main.connectionFactoryClassName = oracle.jdbc.pool.OracleDataSource javax.sql.DataSource.main.url = jdbc:oracle:thin://@localhost:1521/XE javax.sql.DataSource.main.user = scott javax.sql.DataSource.main.password = tiger Why connectionFactoryClassName ? See PoolDataSourceImpl#setConnectionFactoryClassName(String) . See Thin-style Service Name Syntax . In general, the properties that can be set on the Oracle Universal Connection Pool can be inferred from the \"setter\" methods found in the javadoc for the PoolDataSourceImpl class . In general, the properties that can be set on the oracle.jdbc.pool.OracleDataSource DataSource implementation can be inferred from the \"setter\" methods found in its javadoc . Unlike HikariCP , the Oracle Universal Connection Pool does not distinguish cleanly between configuration properties that affect its behavior and those that affect the behavior of the vendor-supplied DataSource implementation whose connections it pools. For example, in the example above it is not possible to tell that connectionFactoryClassName is a property of the Oracle Universal Connection Pool , and user is a property of the oracle.jdbc.pool.OracleDataSource DataSource implementation . In some cases, the Oracle Universal Connection Pool will set the given property on both the connection pool itself and on the vendor-supplied DataSource it manages . Example: Configuring the HikariCP Connection Pool and H2 This example presumes you have: set up the HikariCP connection pool set up H2 This example, in Java properties file format, configures a HikariCP-managed data source named test to connect to an in-memory H2 database named unit-testing with a user of sa and an empty password: <markup lang=\"properties\" >javax.sql.DataSource.test.dataSourceClassName = org.h2.jdbcx.JdbcDataSource javax.sql.DataSource.test.dataSource.url = jdbc:h2:mem:unit-testing;DB_CLOSE_DELAY=-1 javax.sql.DataSource.test.dataSource.user = sa javax.sql.DataSource.test.dataSource.password = Why dataSourceClassName ? See HikariCP&#8217;s configuration documentation for information about how HikariCP separates configuration of the connection pool itself from configuration of the vendor-supplied DataSource . Why dataSource. ? See PropertyElf.java , lines 47–49 . See the H2 database&#8217;s documentation about its URL format . HikariCP&#8217;s configuration properties are described on its Github repository . Properties that should be forwarded on to the vendor-supplied DataSource are prefixed with dataSource. as seen in the example above. In general, the properties that can be set on the org.h2.jdbcx.JdbcDataSource vendor-supplied DataSource can be inferred from the \"setter\" methods found in its javadoc . Usage You use Helidon MP&#8217;s named data source integration in the same way, regardless of your choices of vendor-supplied DataSource and connection pool. To use Helidon MP&#8217;s named data source integration in your application, once it has been set up and configured , create an ordinary DataSource -typed injection point in a Java class representing a CDI bean somewhere in your application, annotated with the name of the data source you wish to use. Here is how to define such a field-backed injection point: <markup lang=\"java\" >import javax.sql.DataSource; import jakarta.inject.Inject; import jakarta.inject.Named; // ... @Inject @Named(\"test\") private DataSource ds; @Inject marks the field as an injection point. Its behavior is defined by the Jakarta Dependency Injection specification . @Named(\"test\") says to use the data source named test (as declared by the datasourcename portion of a named data source configuration property). The field injection point has a type of javax.sql.DataSource , and the field itselfmay be named anything you like. Here is how to define such a constructor parameter injection point: <markup lang=\"java\" >import javax.sql.DataSource; import jakarta.inject.Inject; import jakarta.inject.Named; // ... private final DataSource ds; @Inject public SomeObject(@Named(\"test\") DataSource ds) { this.ds = ds; } This is the field whose value will be set in the constructor. @Inject marks the constructor as one containing parameter injection points. Its behavior is defined by the Jakarta Dependency Injection specification . @Named(\"test\") says to use the data source named test (as declared by the datasourcename portion of a named data source configuration property). The parameter injection point has a type of javax.sql.DataSource , and the parameter itself may be named anything you like. The injected argument will never be null . ",
            "title": "Named Data Source Integration"
        },
        {
            "location": "mp/persistence",
            "text": " Helidon MP&#8217;s Jakarta Transactions integration integrates the Naryana transaction engine , an implementation of the Jakarta Transactions Specification , into Helidon MP. It lets you use @jakarta.transaction.Transactional to declare JTA transactions in your Java code. ",
            "title": "Overview"
        },
        {
            "location": "mp/persistence",
            "text": " To include Helidon&#8217;s JTA integration in your application: Ensure your dependencies are managed Ensure the following &lt;dependency&gt; elements are present as child elements of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;jakarta.transaction&lt;/groupId&gt; &lt;artifactId&gt;jakarta.transaction-api&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.cdi&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-cdi-jta-weld&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; The scope is provided , which ensures that the JTA classes required for compilation are available at compile time. The implementation of these API classes (provided by Narayana ) will be available at runtime. ",
            "title": "Maven Coordinates (JTA)"
        },
        {
            "location": "mp/persistence",
            "text": " Helidon MP&#8217;s Jakarta Transactions integration does not require configuration, but configuration is possible. Because configuration is of the underlying Narayana transaction engine , any restrictions are those of the engine, not of Helidon itself. Narayana, unlike Helidon MP, does not use MicroProfile Config, so its configuration options are less flexible. Some common examples of Narayana configuration follow. ",
            "title": "Overview"
        },
        {
            "location": "mp/persistence",
            "text": " Narayana features an object store directory which it uses to store information about transaction outcomes. To set its location, you may set the ObjectStoreEnvironmentBean.objectStoreDir system property to the full path of a writeable directory: <markup lang=\"bash\" >java -DObjectStoreEnvironmentBean.objectStoreDir=/var/tmp # ... See Specifying the object store location for more information. ",
            "title": "Configuring the Object Store Directory"
        },
        {
            "location": "mp/persistence",
            "text": " To configure Narayana&#8217;s default transaction manager timeout , set the com.arjuna.ats.arjuna.coordinator.defaultTimeout system property to an integral value in seconds: <markup lang=\"bash\" >java -Dcom.arjuna.ats.arjuna.coordinator.defaultTimeout=60 # ... For more on configuring Narayana, see Setting Properties in the Naryana documentation. ",
            "title": "Configuring the Default Transaction Manager Timeout"
        },
        {
            "location": "mp/persistence",
            "text": " Overview Helidon MP&#8217;s Jakarta Transactions integration does not require configuration, but configuration is possible. Because configuration is of the underlying Narayana transaction engine , any restrictions are those of the engine, not of Helidon itself. Narayana, unlike Helidon MP, does not use MicroProfile Config, so its configuration options are less flexible. Some common examples of Narayana configuration follow. Configuring the Object Store Directory Narayana features an object store directory which it uses to store information about transaction outcomes. To set its location, you may set the ObjectStoreEnvironmentBean.objectStoreDir system property to the full path of a writeable directory: <markup lang=\"bash\" >java -DObjectStoreEnvironmentBean.objectStoreDir=/var/tmp # ... See Specifying the object store location for more information. Configuring the Default Transaction Manager Timeout To configure Narayana&#8217;s default transaction manager timeout , set the com.arjuna.ats.arjuna.coordinator.defaultTimeout system property to an integral value in seconds: <markup lang=\"bash\" >java -Dcom.arjuna.ats.arjuna.coordinator.defaultTimeout=60 # ... For more on configuring Narayana, see Setting Properties in the Naryana documentation. ",
            "title": "Configuration"
        },
        {
            "location": "mp/persistence",
            "text": " To use Helidon MP&#8217;s Jakarta Transactions integration, annotate a method with the jakarta.transaction.Transactional annotation: <markup lang=\"java\" >import jakarta.transaction.Transactional; // ... @Transactional public String getGreeting(Integer id) { // Use a JTA-aware facility to do something transactional here. } The @Transactional annotation indicates that this method should be invoked in the scope of a JTA transaction. The object on which the method is invoked must be one that Helidon MP&#8217;s CDI container has created , i.e. it must be managed. ( CDI beans are managed , as are Jakarta RESTful Web Services resource classes .) For @Transactional to have any effect, whatever is used inside the method must be JTA-aware (such as a Jakarta Persistence object like a managed EntityManager ). ",
            "title": "Usage"
        },
        {
            "location": "mp/persistence",
            "text": " Overview Helidon MP&#8217;s Jakarta Transactions integration integrates the Naryana transaction engine , an implementation of the Jakarta Transactions Specification , into Helidon MP. It lets you use @jakarta.transaction.Transactional to declare JTA transactions in your Java code. Maven Coordinates (JTA) To include Helidon&#8217;s JTA integration in your application: Ensure your dependencies are managed Ensure the following &lt;dependency&gt; elements are present as child elements of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;jakarta.transaction&lt;/groupId&gt; &lt;artifactId&gt;jakarta.transaction-api&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.cdi&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-cdi-jta-weld&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; The scope is provided , which ensures that the JTA classes required for compilation are available at compile time. The implementation of these API classes (provided by Narayana ) will be available at runtime. Configuration Overview Helidon MP&#8217;s Jakarta Transactions integration does not require configuration, but configuration is possible. Because configuration is of the underlying Narayana transaction engine , any restrictions are those of the engine, not of Helidon itself. Narayana, unlike Helidon MP, does not use MicroProfile Config, so its configuration options are less flexible. Some common examples of Narayana configuration follow. Configuring the Object Store Directory Narayana features an object store directory which it uses to store information about transaction outcomes. To set its location, you may set the ObjectStoreEnvironmentBean.objectStoreDir system property to the full path of a writeable directory: <markup lang=\"bash\" >java -DObjectStoreEnvironmentBean.objectStoreDir=/var/tmp # ... See Specifying the object store location for more information. Configuring the Default Transaction Manager Timeout To configure Narayana&#8217;s default transaction manager timeout , set the com.arjuna.ats.arjuna.coordinator.defaultTimeout system property to an integral value in seconds: <markup lang=\"bash\" >java -Dcom.arjuna.ats.arjuna.coordinator.defaultTimeout=60 # ... For more on configuring Narayana, see Setting Properties in the Naryana documentation. Usage To use Helidon MP&#8217;s Jakarta Transactions integration, annotate a method with the jakarta.transaction.Transactional annotation: <markup lang=\"java\" >import jakarta.transaction.Transactional; // ... @Transactional public String getGreeting(Integer id) { // Use a JTA-aware facility to do something transactional here. } The @Transactional annotation indicates that this method should be invoked in the scope of a JTA transaction. The object on which the method is invoked must be one that Helidon MP&#8217;s CDI container has created , i.e. it must be managed. ( CDI beans are managed , as are Jakarta RESTful Web Services resource classes .) For @Transactional to have any effect, whatever is used inside the method must be JTA-aware (such as a Jakarta Persistence object like a managed EntityManager ). ",
            "title": "Jakarta Transactions (JTA) Integration"
        },
        {
            "location": "mp/persistence",
            "text": " Helidon MP&#8217;s Jakarta Persistence integration allows you to interact with Jakarta Persistence (JPA) objects as if your code were running in an application server, handling automatic creation and management of objects such as EntityManager and EntityManagerFactory instances. More pragmatically, it allows you to inject managed EntityManager instances using the @PersistenceContext annotation. Jakarta Persistence is a Jakarta EE specification that describes, among other things, how its implementations: Map Java objects to relational database tables Manage such persistent Java objects Interact with Jakarta Transactions Interact with named data sources Jakarta Persistence may be used in an entirely application-managed manner, which requires no integration at all. This application-managed mode places the burden of error handling, thread safety, transaction management, and other concerns on the user. This documentation does not cover application-managed mode JPA. Jakarta Persistence may also (preferably) be used in a fully container-managed manner, which requires that a container, like Helidon MP, handle error management, thread safety and transaction management on behalf of the user. This documentation covers this container-managed mode of JPA exclusively. Helidon MP&#8217;s Jakarta Persistence integration comes with support for two JPA implementations, known as JPA providers : Hibernate ORM Eclipselink In any given project, you use one or the other, but not both. How you set up Helidon MP&#8217;s Jakarta Persistence integration differs depending on which of these JPA providers you choose to use. Jakarta Persistence requires Jakarta Transactions and makes use of named data sources , so as you set up your project you will need to understand: Helidon MP&#8217;s named data source integration Helidon MP&#8217;s Jakarta Transactions integration ",
            "title": "Overview"
        },
        {
            "location": "mp/persistence",
            "text": " While the Jakarta Persistence specification standardizes many aspects around programming and usage, it deliberately leaves many required setup and configuration aspects up to the JPA provider. You will need to set up your project differently depending on which JPA provider you choose. To set up Helidon MP&#8217;s Jakarta Persistence integration in your application to work with your chosen JPA provider, you must: Set up and configure named data sources as appropriate Set up and configure Helidon MP&#8217;s Jakarta Transactions support Include the proper Jakarta Persistence-related dependencies Set up your project to generate and compile the static metamodel Set up your project for static weaving Details and examples for each supported JPA provider are below. ",
            "title": "Overview"
        },
        {
            "location": "mp/persistence",
            "text": " To include the Jakarta Persistence APIs that you will need and to include the core of Helidon&#8217;s Jakarta Persistence integration: Ensure your dependencies are managed Ensure you have set up and configured named data sources as appropriate Ensure you have set up and configured Helidon MP&#8217;s Jakarta Transactions support Ensure the following &lt;dependency&gt; elements are present as child elements of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;jakarta.persistence&lt;/groupId&gt; &lt;artifactId&gt;jakarta.persistence-api&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.cdi&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-cdi-jpa&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; The scope is provided , which ensures that the JPA classes required for compilation are available at compile time. The scope is runtime , which ensures that Helidon&#8217;s core, provider-independent Jakarta Persistence integration is available at runtime. These &lt;dependency&gt; elements do not set up a JPA provider. See details below for the JPA provider you have chosen to use. ",
            "title": "Maven Coordinates (Common)"
        },
        {
            "location": "mp/persistence",
            "text": " To generate and compile the Jakarta Persistence static metamodel for your application, regardless of whether you are using Hibernate ORM or Eclipselink, make sure the &lt;plugin&gt; element in the following code snippet is present as a child element of the &lt;pluginManagement&gt;&lt;plugins&gt; element sequence as shown below: <markup lang=\"xml\" >&lt;pluginManagement&gt; &lt;plugins&gt; &lt;!-- ... --&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;default-compile&lt;/id&gt; &lt;configuration&gt; &lt;annotationProcessorPaths&gt; &lt;annotationProcessorPath&gt; &lt;groupId&gt;org.hibernate.orm&lt;/groupId&gt; &lt;artifactId&gt;hibernate-jpamodelgen&lt;/artifactId&gt; &lt;version&gt;6.1.1.Final&lt;/version&gt; &lt;/annotationProcessorPath&gt; &lt;/annotationProcessorPaths&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;!-- ... --&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; This adds the hibernate-jpamodelgen jar, which contains a Java annotation processor that generates the static metamodel source code , to the Java compiler&#8217;s annotation processor path so that it is active at compile time. Always check Maven Central for up to date versions and make sure the version used is that of Hibernate ORM itself. For more on the Hibernate ORM hibernate-jpamodelgen annotation processor, see Hibernate Metamodel Generator in Hibernate ORM&#8217;s documentation. Many parts of Hibernate ORM&#8217;s documentation of this feature are outdated. ",
            "title": "Setting Up Static Metamodel Generation"
        },
        {
            "location": "mp/persistence",
            "text": " To include Helidon&#8217;s Jakarta Persistence-related integration for Hibernate ORM: Ensure your dependencies are managed Ensure the basics of your JPA project are set up properly Ensure the following &lt;dependency&gt; elements are present as child elements of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.cdi&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-cdi-eclipselink&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; The scope is runtime , which ensures that Helidon MP&#8217;s Hibernate ORM integration is available at runtime. ",
            "title": "Maven Coordinates (Hibernate ORM)"
        },
        {
            "location": "mp/persistence",
            "text": " Hibernate ORM can alter your classes' bytecode at build time to keep track of changes made to objects participating in Jakarta Persistence workflows. To set up this required static weaving for Hibernate ORM, ensure that the following &lt;plugin&gt; element is present as a child element of your project&#8217;s pom.xml file&#8217;s &lt;plugins&gt; element: <markup lang=\"xml\" >&lt;plugin&gt; &lt;groupId&gt;org.hibernate.orm.tooling&lt;/groupId&gt; &lt;artifactId&gt;hibernate-enhance-maven-plugin&lt;/artifactId&gt; &lt;!-- Ideally, your plugin versions are managed via a &lt;pluginManagement&gt; element, which is why the &lt;version&gt; element is commented out below. If, nevertheless, you opt for the explicit version, check https://search.maven.org/artifact/org.hibernate.orm/hibernate-enhance-maven-plugin for up-to-date versions, and make sure the version is the same as that of Hibernate ORM itself. --&gt; &lt;!-- &lt;version&gt;6.1.1.Final&lt;/version&gt; --&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;Statically enhance JPA entities for Hibernate&lt;/id&gt; &lt;phase&gt;compile&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;enhance&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;failOnError&gt;true&lt;/failOnError&gt; &lt;enableDirtyTracking&gt;true&lt;/enableDirtyTracking&gt; &lt;enableLazyInitialization&gt;true&lt;/enableLazyInitialization&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; You must also add a file named src/main/resources/META-INF/hibernate.properties with the following line as its sole contents: <markup lang=\"properties\" title=\" src/main/resources/META-INF/hibernate.properties \" >hibernate.bytecode.provider=none The value of none instructs Hibernate ORM to not attempt to perform weaving at runtime . For more on the hibernate-enhance-maven-plugin in particular, see its documentation . For more on Hibernate ORM&#8217;s bytecode enhancement (weaving) in general, see Bytecode Enhancement in Hibernate ORM&#8217;s documentation. For more on bytecode enhancement properties, see Bytecode Enhancement Properties in Hibernate ORM&#8217;s documentation. ",
            "title": "Setting Up Static Weaving (Hibernate ORM)"
        },
        {
            "location": "mp/persistence",
            "text": " To include Helidon&#8217;s Jakarta Persistence-related integration for Eclipselink: Ensure your dependencies are managed Ensure the basics of your JPA project are set up properly Ensure the following &lt;dependency&gt; elements are present as child elements of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.cdi&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-cdi-eclipselink&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; The scope is runtime , which ensures that Helidon MP&#8217;s Eclipselink integration is available at runtime. ",
            "title": "Maven Coordinates (Eclipselink)"
        },
        {
            "location": "mp/persistence",
            "text": " Eclipselink can alter your classes' bytecode at build time to keep track of changes made to objects participating in Jakarta Persistence workflows. To set up this required static weaving for Eclipselink, ensure that the following &lt;plugin&gt; element is present as a child element of your project&#8217;s pom.xml file&#8217;s &lt;plugins&gt; element: <markup lang=\"xml\" >&lt;plugin&gt; &lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt; &lt;artifactId&gt;exec-maven-plugin&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;weave&lt;/id&gt; &lt;phase&gt;process-classes&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;java&lt;/goal&gt; &lt;/goals&gt; &lt;configuration combine.self=\"override\"&gt; &lt;classpathScope&gt;compile&lt;/classpathScope&gt; &lt;mainClass&gt;org.eclipse.persistence.tools.weaving.jpa.StaticWeave&lt;/mainClass&gt; &lt;arguments&gt; &lt;argument&gt;-loglevel&lt;/argument&gt; &lt;argument&gt;INFO&lt;/argument&gt; &lt;argument&gt;-persistenceinfo&lt;/argument&gt; &lt;argument&gt;${project.build.outputDirectory}&lt;/argument&gt; &lt;argument&gt;${project.build.outputDirectory}&lt;/argument&gt; &lt;argument&gt;${project.build.outputDirectory}&lt;/argument&gt; &lt;/arguments&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; Always check Maven Central for up-to-date versions. For more on the Eclipselink static weaving command-line utility, see Static Weaving in the Eclipselink documentation. ",
            "title": "Setting Up Static Weaving (Eclipselink)"
        },
        {
            "location": "mp/persistence",
            "text": " Overview While the Jakarta Persistence specification standardizes many aspects around programming and usage, it deliberately leaves many required setup and configuration aspects up to the JPA provider. You will need to set up your project differently depending on which JPA provider you choose. To set up Helidon MP&#8217;s Jakarta Persistence integration in your application to work with your chosen JPA provider, you must: Set up and configure named data sources as appropriate Set up and configure Helidon MP&#8217;s Jakarta Transactions support Include the proper Jakarta Persistence-related dependencies Set up your project to generate and compile the static metamodel Set up your project for static weaving Details and examples for each supported JPA provider are below. Maven Coordinates (Common) To include the Jakarta Persistence APIs that you will need and to include the core of Helidon&#8217;s Jakarta Persistence integration: Ensure your dependencies are managed Ensure you have set up and configured named data sources as appropriate Ensure you have set up and configured Helidon MP&#8217;s Jakarta Transactions support Ensure the following &lt;dependency&gt; elements are present as child elements of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;jakarta.persistence&lt;/groupId&gt; &lt;artifactId&gt;jakarta.persistence-api&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.cdi&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-cdi-jpa&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; The scope is provided , which ensures that the JPA classes required for compilation are available at compile time. The scope is runtime , which ensures that Helidon&#8217;s core, provider-independent Jakarta Persistence integration is available at runtime. These &lt;dependency&gt; elements do not set up a JPA provider. See details below for the JPA provider you have chosen to use. Setting Up Static Metamodel Generation To generate and compile the Jakarta Persistence static metamodel for your application, regardless of whether you are using Hibernate ORM or Eclipselink, make sure the &lt;plugin&gt; element in the following code snippet is present as a child element of the &lt;pluginManagement&gt;&lt;plugins&gt; element sequence as shown below: <markup lang=\"xml\" >&lt;pluginManagement&gt; &lt;plugins&gt; &lt;!-- ... --&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;default-compile&lt;/id&gt; &lt;configuration&gt; &lt;annotationProcessorPaths&gt; &lt;annotationProcessorPath&gt; &lt;groupId&gt;org.hibernate.orm&lt;/groupId&gt; &lt;artifactId&gt;hibernate-jpamodelgen&lt;/artifactId&gt; &lt;version&gt;6.1.1.Final&lt;/version&gt; &lt;/annotationProcessorPath&gt; &lt;/annotationProcessorPaths&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;!-- ... --&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; This adds the hibernate-jpamodelgen jar, which contains a Java annotation processor that generates the static metamodel source code , to the Java compiler&#8217;s annotation processor path so that it is active at compile time. Always check Maven Central for up to date versions and make sure the version used is that of Hibernate ORM itself. For more on the Hibernate ORM hibernate-jpamodelgen annotation processor, see Hibernate Metamodel Generator in Hibernate ORM&#8217;s documentation. Many parts of Hibernate ORM&#8217;s documentation of this feature are outdated. Maven Coordinates (Hibernate ORM) To include Helidon&#8217;s Jakarta Persistence-related integration for Hibernate ORM: Ensure your dependencies are managed Ensure the basics of your JPA project are set up properly Ensure the following &lt;dependency&gt; elements are present as child elements of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.cdi&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-cdi-eclipselink&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; The scope is runtime , which ensures that Helidon MP&#8217;s Hibernate ORM integration is available at runtime. Setting Up Static Weaving (Hibernate ORM) Hibernate ORM can alter your classes' bytecode at build time to keep track of changes made to objects participating in Jakarta Persistence workflows. To set up this required static weaving for Hibernate ORM, ensure that the following &lt;plugin&gt; element is present as a child element of your project&#8217;s pom.xml file&#8217;s &lt;plugins&gt; element: <markup lang=\"xml\" >&lt;plugin&gt; &lt;groupId&gt;org.hibernate.orm.tooling&lt;/groupId&gt; &lt;artifactId&gt;hibernate-enhance-maven-plugin&lt;/artifactId&gt; &lt;!-- Ideally, your plugin versions are managed via a &lt;pluginManagement&gt; element, which is why the &lt;version&gt; element is commented out below. If, nevertheless, you opt for the explicit version, check https://search.maven.org/artifact/org.hibernate.orm/hibernate-enhance-maven-plugin for up-to-date versions, and make sure the version is the same as that of Hibernate ORM itself. --&gt; &lt;!-- &lt;version&gt;6.1.1.Final&lt;/version&gt; --&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;Statically enhance JPA entities for Hibernate&lt;/id&gt; &lt;phase&gt;compile&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;enhance&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;failOnError&gt;true&lt;/failOnError&gt; &lt;enableDirtyTracking&gt;true&lt;/enableDirtyTracking&gt; &lt;enableLazyInitialization&gt;true&lt;/enableLazyInitialization&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; You must also add a file named src/main/resources/META-INF/hibernate.properties with the following line as its sole contents: <markup lang=\"properties\" title=\" src/main/resources/META-INF/hibernate.properties \" >hibernate.bytecode.provider=none The value of none instructs Hibernate ORM to not attempt to perform weaving at runtime . For more on the hibernate-enhance-maven-plugin in particular, see its documentation . For more on Hibernate ORM&#8217;s bytecode enhancement (weaving) in general, see Bytecode Enhancement in Hibernate ORM&#8217;s documentation. For more on bytecode enhancement properties, see Bytecode Enhancement Properties in Hibernate ORM&#8217;s documentation. Maven Coordinates (Eclipselink) To include Helidon&#8217;s Jakarta Persistence-related integration for Eclipselink: Ensure your dependencies are managed Ensure the basics of your JPA project are set up properly Ensure the following &lt;dependency&gt; elements are present as child elements of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.cdi&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-cdi-eclipselink&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; The scope is runtime , which ensures that Helidon MP&#8217;s Eclipselink integration is available at runtime. Setting Up Static Weaving (Eclipselink) Eclipselink can alter your classes' bytecode at build time to keep track of changes made to objects participating in Jakarta Persistence workflows. To set up this required static weaving for Eclipselink, ensure that the following &lt;plugin&gt; element is present as a child element of your project&#8217;s pom.xml file&#8217;s &lt;plugins&gt; element: <markup lang=\"xml\" >&lt;plugin&gt; &lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt; &lt;artifactId&gt;exec-maven-plugin&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;weave&lt;/id&gt; &lt;phase&gt;process-classes&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;java&lt;/goal&gt; &lt;/goals&gt; &lt;configuration combine.self=\"override\"&gt; &lt;classpathScope&gt;compile&lt;/classpathScope&gt; &lt;mainClass&gt;org.eclipse.persistence.tools.weaving.jpa.StaticWeave&lt;/mainClass&gt; &lt;arguments&gt; &lt;argument&gt;-loglevel&lt;/argument&gt; &lt;argument&gt;INFO&lt;/argument&gt; &lt;argument&gt;-persistenceinfo&lt;/argument&gt; &lt;argument&gt;${project.build.outputDirectory}&lt;/argument&gt; &lt;argument&gt;${project.build.outputDirectory}&lt;/argument&gt; &lt;argument&gt;${project.build.outputDirectory}&lt;/argument&gt; &lt;/arguments&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; Always check Maven Central for up-to-date versions. For more on the Eclipselink static weaving command-line utility, see Static Weaving in the Eclipselink documentation. ",
            "title": "Setting Up a JPA Provider"
        },
        {
            "location": "mp/persistence",
            "text": " Setting Up a JPA Provider Overview While the Jakarta Persistence specification standardizes many aspects around programming and usage, it deliberately leaves many required setup and configuration aspects up to the JPA provider. You will need to set up your project differently depending on which JPA provider you choose. To set up Helidon MP&#8217;s Jakarta Persistence integration in your application to work with your chosen JPA provider, you must: Set up and configure named data sources as appropriate Set up and configure Helidon MP&#8217;s Jakarta Transactions support Include the proper Jakarta Persistence-related dependencies Set up your project to generate and compile the static metamodel Set up your project for static weaving Details and examples for each supported JPA provider are below. Maven Coordinates (Common) To include the Jakarta Persistence APIs that you will need and to include the core of Helidon&#8217;s Jakarta Persistence integration: Ensure your dependencies are managed Ensure you have set up and configured named data sources as appropriate Ensure you have set up and configured Helidon MP&#8217;s Jakarta Transactions support Ensure the following &lt;dependency&gt; elements are present as child elements of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;jakarta.persistence&lt;/groupId&gt; &lt;artifactId&gt;jakarta.persistence-api&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.cdi&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-cdi-jpa&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; The scope is provided , which ensures that the JPA classes required for compilation are available at compile time. The scope is runtime , which ensures that Helidon&#8217;s core, provider-independent Jakarta Persistence integration is available at runtime. These &lt;dependency&gt; elements do not set up a JPA provider. See details below for the JPA provider you have chosen to use. Setting Up Static Metamodel Generation To generate and compile the Jakarta Persistence static metamodel for your application, regardless of whether you are using Hibernate ORM or Eclipselink, make sure the &lt;plugin&gt; element in the following code snippet is present as a child element of the &lt;pluginManagement&gt;&lt;plugins&gt; element sequence as shown below: <markup lang=\"xml\" >&lt;pluginManagement&gt; &lt;plugins&gt; &lt;!-- ... --&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;default-compile&lt;/id&gt; &lt;configuration&gt; &lt;annotationProcessorPaths&gt; &lt;annotationProcessorPath&gt; &lt;groupId&gt;org.hibernate.orm&lt;/groupId&gt; &lt;artifactId&gt;hibernate-jpamodelgen&lt;/artifactId&gt; &lt;version&gt;6.1.1.Final&lt;/version&gt; &lt;/annotationProcessorPath&gt; &lt;/annotationProcessorPaths&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;!-- ... --&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; This adds the hibernate-jpamodelgen jar, which contains a Java annotation processor that generates the static metamodel source code , to the Java compiler&#8217;s annotation processor path so that it is active at compile time. Always check Maven Central for up to date versions and make sure the version used is that of Hibernate ORM itself. For more on the Hibernate ORM hibernate-jpamodelgen annotation processor, see Hibernate Metamodel Generator in Hibernate ORM&#8217;s documentation. Many parts of Hibernate ORM&#8217;s documentation of this feature are outdated. Maven Coordinates (Hibernate ORM) To include Helidon&#8217;s Jakarta Persistence-related integration for Hibernate ORM: Ensure your dependencies are managed Ensure the basics of your JPA project are set up properly Ensure the following &lt;dependency&gt; elements are present as child elements of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.cdi&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-cdi-eclipselink&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; The scope is runtime , which ensures that Helidon MP&#8217;s Hibernate ORM integration is available at runtime. Setting Up Static Weaving (Hibernate ORM) Hibernate ORM can alter your classes' bytecode at build time to keep track of changes made to objects participating in Jakarta Persistence workflows. To set up this required static weaving for Hibernate ORM, ensure that the following &lt;plugin&gt; element is present as a child element of your project&#8217;s pom.xml file&#8217;s &lt;plugins&gt; element: <markup lang=\"xml\" >&lt;plugin&gt; &lt;groupId&gt;org.hibernate.orm.tooling&lt;/groupId&gt; &lt;artifactId&gt;hibernate-enhance-maven-plugin&lt;/artifactId&gt; &lt;!-- Ideally, your plugin versions are managed via a &lt;pluginManagement&gt; element, which is why the &lt;version&gt; element is commented out below. If, nevertheless, you opt for the explicit version, check https://search.maven.org/artifact/org.hibernate.orm/hibernate-enhance-maven-plugin for up-to-date versions, and make sure the version is the same as that of Hibernate ORM itself. --&gt; &lt;!-- &lt;version&gt;6.1.1.Final&lt;/version&gt; --&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;Statically enhance JPA entities for Hibernate&lt;/id&gt; &lt;phase&gt;compile&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;enhance&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;failOnError&gt;true&lt;/failOnError&gt; &lt;enableDirtyTracking&gt;true&lt;/enableDirtyTracking&gt; &lt;enableLazyInitialization&gt;true&lt;/enableLazyInitialization&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; You must also add a file named src/main/resources/META-INF/hibernate.properties with the following line as its sole contents: <markup lang=\"properties\" title=\" src/main/resources/META-INF/hibernate.properties \" >hibernate.bytecode.provider=none The value of none instructs Hibernate ORM to not attempt to perform weaving at runtime . For more on the hibernate-enhance-maven-plugin in particular, see its documentation . For more on Hibernate ORM&#8217;s bytecode enhancement (weaving) in general, see Bytecode Enhancement in Hibernate ORM&#8217;s documentation. For more on bytecode enhancement properties, see Bytecode Enhancement Properties in Hibernate ORM&#8217;s documentation. Maven Coordinates (Eclipselink) To include Helidon&#8217;s Jakarta Persistence-related integration for Eclipselink: Ensure your dependencies are managed Ensure the basics of your JPA project are set up properly Ensure the following &lt;dependency&gt; elements are present as child elements of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.cdi&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-cdi-eclipselink&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; The scope is runtime , which ensures that Helidon MP&#8217;s Eclipselink integration is available at runtime. Setting Up Static Weaving (Eclipselink) Eclipselink can alter your classes' bytecode at build time to keep track of changes made to objects participating in Jakarta Persistence workflows. To set up this required static weaving for Eclipselink, ensure that the following &lt;plugin&gt; element is present as a child element of your project&#8217;s pom.xml file&#8217;s &lt;plugins&gt; element: <markup lang=\"xml\" >&lt;plugin&gt; &lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt; &lt;artifactId&gt;exec-maven-plugin&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;weave&lt;/id&gt; &lt;phase&gt;process-classes&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;java&lt;/goal&gt; &lt;/goals&gt; &lt;configuration combine.self=\"override\"&gt; &lt;classpathScope&gt;compile&lt;/classpathScope&gt; &lt;mainClass&gt;org.eclipse.persistence.tools.weaving.jpa.StaticWeave&lt;/mainClass&gt; &lt;arguments&gt; &lt;argument&gt;-loglevel&lt;/argument&gt; &lt;argument&gt;INFO&lt;/argument&gt; &lt;argument&gt;-persistenceinfo&lt;/argument&gt; &lt;argument&gt;${project.build.outputDirectory}&lt;/argument&gt; &lt;argument&gt;${project.build.outputDirectory}&lt;/argument&gt; &lt;argument&gt;${project.build.outputDirectory}&lt;/argument&gt; &lt;/arguments&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; Always check Maven Central for up-to-date versions. For more on the Eclipselink static weaving command-line utility, see Static Weaving in the Eclipselink documentation. ",
            "title": "Project Setup"
        },
        {
            "location": "mp/persistence",
            "text": " Here is a partial example of a persistence unit named prod with a helpful description: <markup lang=\"xml\" title=\" src/main/resources/META-INF/persistence.xml \" >&lt;!-- ... --&gt; &lt;persistence-unit name=\"prod\" transaction-type=\"JTA\"&gt; &lt;description&gt;The production database&lt;/description&gt; &lt;/persistence-unit&gt; &lt;!-- ... --&gt; Because Helidon MP&#8217;s JPA integration is for container-managed JPA, the transaction-type attribute must in practice always be set to JTA . The order of subsequent child elements is significant and governed by the XML schema . In most microservices, there will be only one persistence unit. A &lt;persistence-unit&gt; is represented in Jakarta Persistence as an instance of the PersistenceUnitInfo class. ",
            "title": "Example: Persistence Unit Skeleton"
        },
        {
            "location": "mp/persistence",
            "text": " Here is a partial example of a persistence unit named prod , with a helpful description, linked with a JTA data source named main : <markup lang=\"xml\" title=\" src/main/resources/META-INF/persistence.xml \" >&lt;!-- ... ---&gt; &lt;persistence-unit name=\"prod\" transaction-type=\"JTA\"&gt; &lt;description&gt;The production database&lt;/description&gt; &lt;jta-data-source&gt;main&lt;/jta-data-source&gt; &lt;/persistence-unit&gt; &lt;!-- ... --&gt; This links this persistence unit to a data source named main , whose connectivity information can be found in a MicroProfile-Config-compatible location, as detailed in the data source configuration section above. Other persistence unit characteristics go here. ",
            "title": "Example: Persistence Unit with JTA Data Source"
        },
        {
            "location": "mp/persistence",
            "text": " A persistence unit is always associated with exactly one named data source . Because Helidon MP&#8217;s Jakarta Persistence integration provides support for container-managed JPA, and because container-managed JPA requires Jakarta Transactions (JTA), the kind of named data source a persistence unit is associated with is always a JTA data source. The &lt;jta-data-source&gt; element, a child of the &lt;persistence-unit&gt; element, is how you link a persistence unit to a named data source you previously configured . Example: Persistence Unit with JTA Data Source Here is a partial example of a persistence unit named prod , with a helpful description, linked with a JTA data source named main : <markup lang=\"xml\" title=\" src/main/resources/META-INF/persistence.xml \" >&lt;!-- ... ---&gt; &lt;persistence-unit name=\"prod\" transaction-type=\"JTA\"&gt; &lt;description&gt;The production database&lt;/description&gt; &lt;jta-data-source&gt;main&lt;/jta-data-source&gt; &lt;/persistence-unit&gt; &lt;!-- ... --&gt; This links this persistence unit to a data source named main , whose connectivity information can be found in a MicroProfile-Config-compatible location, as detailed in the data source configuration section above. Other persistence unit characteristics go here. ",
            "title": "JTA Data Source"
        },
        {
            "location": "mp/persistence",
            "text": " Here is a partial example of a persistence unit named prod , with a helpful description, linked with a JTA data source named main , containing two entity classes: <markup lang=\"xml\" title=\" src/main/resources/META-INF/persistence.xml \" >&lt;!-- ... ---&gt; &lt;persistence-unit name=\"prod\" transaction-type=\"JTA\"&gt; &lt;description&gt;The production database&lt;/description&gt; &lt;jta-data-source&gt;main&lt;/jta-data-source&gt; &lt;class&gt;com.example.ExampleEntity0&lt;/class&gt; &lt;class&gt;com.example.ExampleEntity1&lt;/class&gt; &lt;/persistence-unit&gt; &lt;!-- ... --&gt; Each entity class is listed with a separate &lt;class&gt; element, and there is no containing &lt;classes&gt; element or similar. Other persistence unit characteristics go here. ",
            "title": "Example: Persistence Unit with Class Elements"
        },
        {
            "location": "mp/persistence",
            "text": " A persistence unit lists the classes that should be managed and that will take part in Jakarta Persistence workflows. You must list: Entity classes Embeddable classes Mapped superclasses Converter classes You use a sequence of &lt;class&gt; elements to do this. Each &lt;class&gt; element contains the fully-qualified class name of one of the types of managed classes listed above. There are other mechanisms that can be used in a META-INF/persistence.xml file to describe managed classes , but they may or may not be honored by a given JPA provider. Example: Persistence Unit with Class Elements Here is a partial example of a persistence unit named prod , with a helpful description, linked with a JTA data source named main , containing two entity classes: <markup lang=\"xml\" title=\" src/main/resources/META-INF/persistence.xml \" >&lt;!-- ... ---&gt; &lt;persistence-unit name=\"prod\" transaction-type=\"JTA\"&gt; &lt;description&gt;The production database&lt;/description&gt; &lt;jta-data-source&gt;main&lt;/jta-data-source&gt; &lt;class&gt;com.example.ExampleEntity0&lt;/class&gt; &lt;class&gt;com.example.ExampleEntity1&lt;/class&gt; &lt;/persistence-unit&gt; &lt;!-- ... --&gt; Each entity class is listed with a separate &lt;class&gt; element, and there is no containing &lt;classes&gt; element or similar. Other persistence unit characteristics go here. ",
            "title": "Classes"
        },
        {
            "location": "mp/persistence",
            "text": " Here is a partial exmaple of a persistence unit named prod , with a helpful description, linked with a JTA data source named main , containing two entity classes, configuring a Hibernate ORM-specific property: <markup lang=\"xml\" title=\" src/main/resources/META-INF/persistence.xml \" >&lt;!-- ... ---&gt; &lt;persistence-unit name=\"prod\" transaction-type=\"JTA\"&gt; &lt;description&gt;The production database&lt;/description&gt; &lt;jta-data-source&gt;main&lt;/jta-data-source&gt; &lt;class&gt;com.example.ExampleEntity0&lt;/class&gt; &lt;class&gt;com.example.ExampleEntity1&lt;/class&gt; &lt;properties&gt; &lt;property name=\"hibernate.show_sql\" value=\"true\"/&gt; &lt;property name=\"eclipselink.weaving\" value=\"false\"/&gt; &lt;/properties&gt; &lt;/persistence-unit&gt; &lt;!-- ... --&gt; The name identifies a name present in the datasourcename portion of a named datasource configuration . There is no need for any kind of reserved prefix (like java:comp/env ). This is a Hibernate ORM-specific property and will be properly ignored if the JPA provider you have set up is Eclipselink. See Statement logging and statistics in the Hibernate ORM documentation for more details about the hibernate.show_sql property. This is an Eclipselink-specific property (and (a) is required and (b) must be set to false if you are using Eclipselink), and will be properly ignored if the JPA provider you have set up is Hibernate ORM. See weaving in the Eclipselink documentation for more details about the eclipselink.weaving property. For an exhaustive list of Hibernate ORM-specific properties, see Configurations in the Hibernate ORM documentation. For an exhaustive list of Eclipselink-specific properties, see Persistence Property Extensions Reference in the Eclipselink documentation. ",
            "title": "Example: Persistence Unit with Properties"
        },
        {
            "location": "mp/persistence",
            "text": " Persistence units can have simple properties attached to them to further configure the backing JPA provider. You use the &lt;properties&gt; element to specify them. Helidon MP&#8217;s Jakarta Persistence integration is for container-managed JPA, so the vendor-independent properties described in the specification directly concerned with database connectivity information, such as jakarta.persistence.jdbc.url , do not apply and will be ignored if present. See the JTA Data Source section above for how a persistence unit is linked to a named data source . Example: Persistence Unit with Properties Here is a partial exmaple of a persistence unit named prod , with a helpful description, linked with a JTA data source named main , containing two entity classes, configuring a Hibernate ORM-specific property: <markup lang=\"xml\" title=\" src/main/resources/META-INF/persistence.xml \" >&lt;!-- ... ---&gt; &lt;persistence-unit name=\"prod\" transaction-type=\"JTA\"&gt; &lt;description&gt;The production database&lt;/description&gt; &lt;jta-data-source&gt;main&lt;/jta-data-source&gt; &lt;class&gt;com.example.ExampleEntity0&lt;/class&gt; &lt;class&gt;com.example.ExampleEntity1&lt;/class&gt; &lt;properties&gt; &lt;property name=\"hibernate.show_sql\" value=\"true\"/&gt; &lt;property name=\"eclipselink.weaving\" value=\"false\"/&gt; &lt;/properties&gt; &lt;/persistence-unit&gt; &lt;!-- ... --&gt; The name identifies a name present in the datasourcename portion of a named datasource configuration . There is no need for any kind of reserved prefix (like java:comp/env ). This is a Hibernate ORM-specific property and will be properly ignored if the JPA provider you have set up is Eclipselink. See Statement logging and statistics in the Hibernate ORM documentation for more details about the hibernate.show_sql property. This is an Eclipselink-specific property (and (a) is required and (b) must be set to false if you are using Eclipselink), and will be properly ignored if the JPA provider you have set up is Hibernate ORM. See weaving in the Eclipselink documentation for more details about the eclipselink.weaving property. For an exhaustive list of Hibernate ORM-specific properties, see Configurations in the Hibernate ORM documentation. For an exhaustive list of Eclipselink-specific properties, see Persistence Property Extensions Reference in the Eclipselink documentation. ",
            "title": "Properties"
        },
        {
            "location": "mp/persistence",
            "text": " You list your application&#8217;s persistence units as &lt;persistence-unit&gt; child elements of the enclosing &lt;persistence&gt; element. Each &lt;persistence-unit&gt; element identifies a named persistence unit that will correspond to an EntityManager in your code, and represents a collection of entities in a relational database. Example: Persistence Unit Skeleton Here is a partial example of a persistence unit named prod with a helpful description: <markup lang=\"xml\" title=\" src/main/resources/META-INF/persistence.xml \" >&lt;!-- ... --&gt; &lt;persistence-unit name=\"prod\" transaction-type=\"JTA\"&gt; &lt;description&gt;The production database&lt;/description&gt; &lt;/persistence-unit&gt; &lt;!-- ... --&gt; Because Helidon MP&#8217;s JPA integration is for container-managed JPA, the transaction-type attribute must in practice always be set to JTA . The order of subsequent child elements is significant and governed by the XML schema . In most microservices, there will be only one persistence unit. A &lt;persistence-unit&gt; is represented in Jakarta Persistence as an instance of the PersistenceUnitInfo class. JTA Data Source A persistence unit is always associated with exactly one named data source . Because Helidon MP&#8217;s Jakarta Persistence integration provides support for container-managed JPA, and because container-managed JPA requires Jakarta Transactions (JTA), the kind of named data source a persistence unit is associated with is always a JTA data source. The &lt;jta-data-source&gt; element, a child of the &lt;persistence-unit&gt; element, is how you link a persistence unit to a named data source you previously configured . Example: Persistence Unit with JTA Data Source Here is a partial example of a persistence unit named prod , with a helpful description, linked with a JTA data source named main : <markup lang=\"xml\" title=\" src/main/resources/META-INF/persistence.xml \" >&lt;!-- ... ---&gt; &lt;persistence-unit name=\"prod\" transaction-type=\"JTA\"&gt; &lt;description&gt;The production database&lt;/description&gt; &lt;jta-data-source&gt;main&lt;/jta-data-source&gt; &lt;/persistence-unit&gt; &lt;!-- ... --&gt; This links this persistence unit to a data source named main , whose connectivity information can be found in a MicroProfile-Config-compatible location, as detailed in the data source configuration section above. Other persistence unit characteristics go here. Classes A persistence unit lists the classes that should be managed and that will take part in Jakarta Persistence workflows. You must list: Entity classes Embeddable classes Mapped superclasses Converter classes You use a sequence of &lt;class&gt; elements to do this. Each &lt;class&gt; element contains the fully-qualified class name of one of the types of managed classes listed above. There are other mechanisms that can be used in a META-INF/persistence.xml file to describe managed classes , but they may or may not be honored by a given JPA provider. Example: Persistence Unit with Class Elements Here is a partial example of a persistence unit named prod , with a helpful description, linked with a JTA data source named main , containing two entity classes: <markup lang=\"xml\" title=\" src/main/resources/META-INF/persistence.xml \" >&lt;!-- ... ---&gt; &lt;persistence-unit name=\"prod\" transaction-type=\"JTA\"&gt; &lt;description&gt;The production database&lt;/description&gt; &lt;jta-data-source&gt;main&lt;/jta-data-source&gt; &lt;class&gt;com.example.ExampleEntity0&lt;/class&gt; &lt;class&gt;com.example.ExampleEntity1&lt;/class&gt; &lt;/persistence-unit&gt; &lt;!-- ... --&gt; Each entity class is listed with a separate &lt;class&gt; element, and there is no containing &lt;classes&gt; element or similar. Other persistence unit characteristics go here. Properties Persistence units can have simple properties attached to them to further configure the backing JPA provider. You use the &lt;properties&gt; element to specify them. Helidon MP&#8217;s Jakarta Persistence integration is for container-managed JPA, so the vendor-independent properties described in the specification directly concerned with database connectivity information, such as jakarta.persistence.jdbc.url , do not apply and will be ignored if present. See the JTA Data Source section above for how a persistence unit is linked to a named data source . Example: Persistence Unit with Properties Here is a partial exmaple of a persistence unit named prod , with a helpful description, linked with a JTA data source named main , containing two entity classes, configuring a Hibernate ORM-specific property: <markup lang=\"xml\" title=\" src/main/resources/META-INF/persistence.xml \" >&lt;!-- ... ---&gt; &lt;persistence-unit name=\"prod\" transaction-type=\"JTA\"&gt; &lt;description&gt;The production database&lt;/description&gt; &lt;jta-data-source&gt;main&lt;/jta-data-source&gt; &lt;class&gt;com.example.ExampleEntity0&lt;/class&gt; &lt;class&gt;com.example.ExampleEntity1&lt;/class&gt; &lt;properties&gt; &lt;property name=\"hibernate.show_sql\" value=\"true\"/&gt; &lt;property name=\"eclipselink.weaving\" value=\"false\"/&gt; &lt;/properties&gt; &lt;/persistence-unit&gt; &lt;!-- ... --&gt; The name identifies a name present in the datasourcename portion of a named datasource configuration . There is no need for any kind of reserved prefix (like java:comp/env ). This is a Hibernate ORM-specific property and will be properly ignored if the JPA provider you have set up is Eclipselink. See Statement logging and statistics in the Hibernate ORM documentation for more details about the hibernate.show_sql property. This is an Eclipselink-specific property (and (a) is required and (b) must be set to false if you are using Eclipselink), and will be properly ignored if the JPA provider you have set up is Hibernate ORM. See weaving in the Eclipselink documentation for more details about the eclipselink.weaving property. For an exhaustive list of Hibernate ORM-specific properties, see Configurations in the Hibernate ORM documentation. For an exhaustive list of Eclipselink-specific properties, see Persistence Property Extensions Reference in the Eclipselink documentation. ",
            "title": "Persistence Unit"
        },
        {
            "location": "mp/persistence",
            "text": " To configure Helidon MP&#8217;s Jakarta Persistence integration, you author a src/main/resources/META-INF/persistence.xml file . It contains a mix of standardized elements and JPA provider-specific properties. For details about the structure and syntax of the META-INF/persistence.xml file, see persistence.xml file in the Jakarta Persistence specification. Fundamentally, a META-INF/persistence.xml file contains a collection of persistence units . A persistence unit represents a collection of entities in a relational database loosely coupled to a named data source that knows how to connect to it. Your src/main/resources/META-INF/persistence.xml file must begin (and end) with the following XML: <markup lang=\"xml\" title=\" src/main/resources/META-INF/persistence.xml \" >&lt;persistence xmlns=\"https://jakarta.ee/xml/ns/persistence\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"https://jakarta.ee/xml/ns/persistence https://jakarta.ee/xml/ns/persistence/persistence_3_0.xsd\" version=\"3.0\"&gt; &lt;/persistence&gt; Helidon MP&#8217;s Jakarta Persistence integration supports Jakarta Persistence version 3.0 . `&lt;persistence-unit&gt; elements are listed here. Persistence Unit You list your application&#8217;s persistence units as &lt;persistence-unit&gt; child elements of the enclosing &lt;persistence&gt; element. Each &lt;persistence-unit&gt; element identifies a named persistence unit that will correspond to an EntityManager in your code, and represents a collection of entities in a relational database. Example: Persistence Unit Skeleton Here is a partial example of a persistence unit named prod with a helpful description: <markup lang=\"xml\" title=\" src/main/resources/META-INF/persistence.xml \" >&lt;!-- ... --&gt; &lt;persistence-unit name=\"prod\" transaction-type=\"JTA\"&gt; &lt;description&gt;The production database&lt;/description&gt; &lt;/persistence-unit&gt; &lt;!-- ... --&gt; Because Helidon MP&#8217;s JPA integration is for container-managed JPA, the transaction-type attribute must in practice always be set to JTA . The order of subsequent child elements is significant and governed by the XML schema . In most microservices, there will be only one persistence unit. A &lt;persistence-unit&gt; is represented in Jakarta Persistence as an instance of the PersistenceUnitInfo class. JTA Data Source A persistence unit is always associated with exactly one named data source . Because Helidon MP&#8217;s Jakarta Persistence integration provides support for container-managed JPA, and because container-managed JPA requires Jakarta Transactions (JTA), the kind of named data source a persistence unit is associated with is always a JTA data source. The &lt;jta-data-source&gt; element, a child of the &lt;persistence-unit&gt; element, is how you link a persistence unit to a named data source you previously configured . Example: Persistence Unit with JTA Data Source Here is a partial example of a persistence unit named prod , with a helpful description, linked with a JTA data source named main : <markup lang=\"xml\" title=\" src/main/resources/META-INF/persistence.xml \" >&lt;!-- ... ---&gt; &lt;persistence-unit name=\"prod\" transaction-type=\"JTA\"&gt; &lt;description&gt;The production database&lt;/description&gt; &lt;jta-data-source&gt;main&lt;/jta-data-source&gt; &lt;/persistence-unit&gt; &lt;!-- ... --&gt; This links this persistence unit to a data source named main , whose connectivity information can be found in a MicroProfile-Config-compatible location, as detailed in the data source configuration section above. Other persistence unit characteristics go here. Classes A persistence unit lists the classes that should be managed and that will take part in Jakarta Persistence workflows. You must list: Entity classes Embeddable classes Mapped superclasses Converter classes You use a sequence of &lt;class&gt; elements to do this. Each &lt;class&gt; element contains the fully-qualified class name of one of the types of managed classes listed above. There are other mechanisms that can be used in a META-INF/persistence.xml file to describe managed classes , but they may or may not be honored by a given JPA provider. Example: Persistence Unit with Class Elements Here is a partial example of a persistence unit named prod , with a helpful description, linked with a JTA data source named main , containing two entity classes: <markup lang=\"xml\" title=\" src/main/resources/META-INF/persistence.xml \" >&lt;!-- ... ---&gt; &lt;persistence-unit name=\"prod\" transaction-type=\"JTA\"&gt; &lt;description&gt;The production database&lt;/description&gt; &lt;jta-data-source&gt;main&lt;/jta-data-source&gt; &lt;class&gt;com.example.ExampleEntity0&lt;/class&gt; &lt;class&gt;com.example.ExampleEntity1&lt;/class&gt; &lt;/persistence-unit&gt; &lt;!-- ... --&gt; Each entity class is listed with a separate &lt;class&gt; element, and there is no containing &lt;classes&gt; element or similar. Other persistence unit characteristics go here. Properties Persistence units can have simple properties attached to them to further configure the backing JPA provider. You use the &lt;properties&gt; element to specify them. Helidon MP&#8217;s Jakarta Persistence integration is for container-managed JPA, so the vendor-independent properties described in the specification directly concerned with database connectivity information, such as jakarta.persistence.jdbc.url , do not apply and will be ignored if present. See the JTA Data Source section above for how a persistence unit is linked to a named data source . Example: Persistence Unit with Properties Here is a partial exmaple of a persistence unit named prod , with a helpful description, linked with a JTA data source named main , containing two entity classes, configuring a Hibernate ORM-specific property: <markup lang=\"xml\" title=\" src/main/resources/META-INF/persistence.xml \" >&lt;!-- ... ---&gt; &lt;persistence-unit name=\"prod\" transaction-type=\"JTA\"&gt; &lt;description&gt;The production database&lt;/description&gt; &lt;jta-data-source&gt;main&lt;/jta-data-source&gt; &lt;class&gt;com.example.ExampleEntity0&lt;/class&gt; &lt;class&gt;com.example.ExampleEntity1&lt;/class&gt; &lt;properties&gt; &lt;property name=\"hibernate.show_sql\" value=\"true\"/&gt; &lt;property name=\"eclipselink.weaving\" value=\"false\"/&gt; &lt;/properties&gt; &lt;/persistence-unit&gt; &lt;!-- ... --&gt; The name identifies a name present in the datasourcename portion of a named datasource configuration . There is no need for any kind of reserved prefix (like java:comp/env ). This is a Hibernate ORM-specific property and will be properly ignored if the JPA provider you have set up is Eclipselink. See Statement logging and statistics in the Hibernate ORM documentation for more details about the hibernate.show_sql property. This is an Eclipselink-specific property (and (a) is required and (b) must be set to false if you are using Eclipselink), and will be properly ignored if the JPA provider you have set up is Hibernate ORM. See weaving in the Eclipselink documentation for more details about the eclipselink.weaving property. For an exhaustive list of Hibernate ORM-specific properties, see Configurations in the Hibernate ORM documentation. For an exhaustive list of Eclipselink-specific properties, see Persistence Property Extensions Reference in the Eclipselink documentation. ",
            "title": "Configuration"
        },
        {
            "location": "mp/persistence",
            "text": " To use Helidon MP&#8217;s Jakarta Persistence integration, once you have set up and configured your project, you use the Jakarta Persistence APIs in almost the same manner as if your project were deployed to a Jakarta EE server. Specifically, you: Annotate your managed classes (entities, mapped superclasses, etc.) appropriately (using @Entity and similar annotations) Inject EntityManager instances appropriately with the @PersistenceContext annotation Use an injected EntityManager to work with your managed objects In addition, you use Helidon MP&#8217;s JTA integration to declare transactional boundaries where appropriate. A full tutorial of Jakarta Persistence is well beyond the scope of this documentation. Consult the specification for details on how to map your entity classes to relational database tables, and how to perform other related tasks. ",
            "title": "Usage"
        },
        {
            "location": "mp/persistence",
            "text": " JPA Pokemons Example ",
            "title": "Examples"
        },
        {
            "location": "mp/persistence",
            "text": " Overview Helidon MP&#8217;s Jakarta Persistence integration allows you to interact with Jakarta Persistence (JPA) objects as if your code were running in an application server, handling automatic creation and management of objects such as EntityManager and EntityManagerFactory instances. More pragmatically, it allows you to inject managed EntityManager instances using the @PersistenceContext annotation. Jakarta Persistence is a Jakarta EE specification that describes, among other things, how its implementations: Map Java objects to relational database tables Manage such persistent Java objects Interact with Jakarta Transactions Interact with named data sources Jakarta Persistence may be used in an entirely application-managed manner, which requires no integration at all. This application-managed mode places the burden of error handling, thread safety, transaction management, and other concerns on the user. This documentation does not cover application-managed mode JPA. Jakarta Persistence may also (preferably) be used in a fully container-managed manner, which requires that a container, like Helidon MP, handle error management, thread safety and transaction management on behalf of the user. This documentation covers this container-managed mode of JPA exclusively. Helidon MP&#8217;s Jakarta Persistence integration comes with support for two JPA implementations, known as JPA providers : Hibernate ORM Eclipselink In any given project, you use one or the other, but not both. How you set up Helidon MP&#8217;s Jakarta Persistence integration differs depending on which of these JPA providers you choose to use. Jakarta Persistence requires Jakarta Transactions and makes use of named data sources , so as you set up your project you will need to understand: Helidon MP&#8217;s named data source integration Helidon MP&#8217;s Jakarta Transactions integration Project Setup Setting Up a JPA Provider Overview While the Jakarta Persistence specification standardizes many aspects around programming and usage, it deliberately leaves many required setup and configuration aspects up to the JPA provider. You will need to set up your project differently depending on which JPA provider you choose. To set up Helidon MP&#8217;s Jakarta Persistence integration in your application to work with your chosen JPA provider, you must: Set up and configure named data sources as appropriate Set up and configure Helidon MP&#8217;s Jakarta Transactions support Include the proper Jakarta Persistence-related dependencies Set up your project to generate and compile the static metamodel Set up your project for static weaving Details and examples for each supported JPA provider are below. Maven Coordinates (Common) To include the Jakarta Persistence APIs that you will need and to include the core of Helidon&#8217;s Jakarta Persistence integration: Ensure your dependencies are managed Ensure you have set up and configured named data sources as appropriate Ensure you have set up and configured Helidon MP&#8217;s Jakarta Transactions support Ensure the following &lt;dependency&gt; elements are present as child elements of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;jakarta.persistence&lt;/groupId&gt; &lt;artifactId&gt;jakarta.persistence-api&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.cdi&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-cdi-jpa&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; The scope is provided , which ensures that the JPA classes required for compilation are available at compile time. The scope is runtime , which ensures that Helidon&#8217;s core, provider-independent Jakarta Persistence integration is available at runtime. These &lt;dependency&gt; elements do not set up a JPA provider. See details below for the JPA provider you have chosen to use. Setting Up Static Metamodel Generation To generate and compile the Jakarta Persistence static metamodel for your application, regardless of whether you are using Hibernate ORM or Eclipselink, make sure the &lt;plugin&gt; element in the following code snippet is present as a child element of the &lt;pluginManagement&gt;&lt;plugins&gt; element sequence as shown below: <markup lang=\"xml\" >&lt;pluginManagement&gt; &lt;plugins&gt; &lt;!-- ... --&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;default-compile&lt;/id&gt; &lt;configuration&gt; &lt;annotationProcessorPaths&gt; &lt;annotationProcessorPath&gt; &lt;groupId&gt;org.hibernate.orm&lt;/groupId&gt; &lt;artifactId&gt;hibernate-jpamodelgen&lt;/artifactId&gt; &lt;version&gt;6.1.1.Final&lt;/version&gt; &lt;/annotationProcessorPath&gt; &lt;/annotationProcessorPaths&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;!-- ... --&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; This adds the hibernate-jpamodelgen jar, which contains a Java annotation processor that generates the static metamodel source code , to the Java compiler&#8217;s annotation processor path so that it is active at compile time. Always check Maven Central for up to date versions and make sure the version used is that of Hibernate ORM itself. For more on the Hibernate ORM hibernate-jpamodelgen annotation processor, see Hibernate Metamodel Generator in Hibernate ORM&#8217;s documentation. Many parts of Hibernate ORM&#8217;s documentation of this feature are outdated. Maven Coordinates (Hibernate ORM) To include Helidon&#8217;s Jakarta Persistence-related integration for Hibernate ORM: Ensure your dependencies are managed Ensure the basics of your JPA project are set up properly Ensure the following &lt;dependency&gt; elements are present as child elements of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.cdi&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-cdi-eclipselink&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; The scope is runtime , which ensures that Helidon MP&#8217;s Hibernate ORM integration is available at runtime. Setting Up Static Weaving (Hibernate ORM) Hibernate ORM can alter your classes' bytecode at build time to keep track of changes made to objects participating in Jakarta Persistence workflows. To set up this required static weaving for Hibernate ORM, ensure that the following &lt;plugin&gt; element is present as a child element of your project&#8217;s pom.xml file&#8217;s &lt;plugins&gt; element: <markup lang=\"xml\" >&lt;plugin&gt; &lt;groupId&gt;org.hibernate.orm.tooling&lt;/groupId&gt; &lt;artifactId&gt;hibernate-enhance-maven-plugin&lt;/artifactId&gt; &lt;!-- Ideally, your plugin versions are managed via a &lt;pluginManagement&gt; element, which is why the &lt;version&gt; element is commented out below. If, nevertheless, you opt for the explicit version, check https://search.maven.org/artifact/org.hibernate.orm/hibernate-enhance-maven-plugin for up-to-date versions, and make sure the version is the same as that of Hibernate ORM itself. --&gt; &lt;!-- &lt;version&gt;6.1.1.Final&lt;/version&gt; --&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;Statically enhance JPA entities for Hibernate&lt;/id&gt; &lt;phase&gt;compile&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;enhance&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;failOnError&gt;true&lt;/failOnError&gt; &lt;enableDirtyTracking&gt;true&lt;/enableDirtyTracking&gt; &lt;enableLazyInitialization&gt;true&lt;/enableLazyInitialization&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; You must also add a file named src/main/resources/META-INF/hibernate.properties with the following line as its sole contents: <markup lang=\"properties\" title=\" src/main/resources/META-INF/hibernate.properties \" >hibernate.bytecode.provider=none The value of none instructs Hibernate ORM to not attempt to perform weaving at runtime . For more on the hibernate-enhance-maven-plugin in particular, see its documentation . For more on Hibernate ORM&#8217;s bytecode enhancement (weaving) in general, see Bytecode Enhancement in Hibernate ORM&#8217;s documentation. For more on bytecode enhancement properties, see Bytecode Enhancement Properties in Hibernate ORM&#8217;s documentation. Maven Coordinates (Eclipselink) To include Helidon&#8217;s Jakarta Persistence-related integration for Eclipselink: Ensure your dependencies are managed Ensure the basics of your JPA project are set up properly Ensure the following &lt;dependency&gt; elements are present as child elements of your project&#8217;s pom.xml file&#8217;s &lt;dependencies&gt; element: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.cdi&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-cdi-eclipselink&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; The scope is runtime , which ensures that Helidon MP&#8217;s Eclipselink integration is available at runtime. Setting Up Static Weaving (Eclipselink) Eclipselink can alter your classes' bytecode at build time to keep track of changes made to objects participating in Jakarta Persistence workflows. To set up this required static weaving for Eclipselink, ensure that the following &lt;plugin&gt; element is present as a child element of your project&#8217;s pom.xml file&#8217;s &lt;plugins&gt; element: <markup lang=\"xml\" >&lt;plugin&gt; &lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt; &lt;artifactId&gt;exec-maven-plugin&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;weave&lt;/id&gt; &lt;phase&gt;process-classes&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;java&lt;/goal&gt; &lt;/goals&gt; &lt;configuration combine.self=\"override\"&gt; &lt;classpathScope&gt;compile&lt;/classpathScope&gt; &lt;mainClass&gt;org.eclipse.persistence.tools.weaving.jpa.StaticWeave&lt;/mainClass&gt; &lt;arguments&gt; &lt;argument&gt;-loglevel&lt;/argument&gt; &lt;argument&gt;INFO&lt;/argument&gt; &lt;argument&gt;-persistenceinfo&lt;/argument&gt; &lt;argument&gt;${project.build.outputDirectory}&lt;/argument&gt; &lt;argument&gt;${project.build.outputDirectory}&lt;/argument&gt; &lt;argument&gt;${project.build.outputDirectory}&lt;/argument&gt; &lt;/arguments&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; Always check Maven Central for up-to-date versions. For more on the Eclipselink static weaving command-line utility, see Static Weaving in the Eclipselink documentation. Configuration To configure Helidon MP&#8217;s Jakarta Persistence integration, you author a src/main/resources/META-INF/persistence.xml file . It contains a mix of standardized elements and JPA provider-specific properties. For details about the structure and syntax of the META-INF/persistence.xml file, see persistence.xml file in the Jakarta Persistence specification. Fundamentally, a META-INF/persistence.xml file contains a collection of persistence units . A persistence unit represents a collection of entities in a relational database loosely coupled to a named data source that knows how to connect to it. Your src/main/resources/META-INF/persistence.xml file must begin (and end) with the following XML: <markup lang=\"xml\" title=\" src/main/resources/META-INF/persistence.xml \" >&lt;persistence xmlns=\"https://jakarta.ee/xml/ns/persistence\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"https://jakarta.ee/xml/ns/persistence https://jakarta.ee/xml/ns/persistence/persistence_3_0.xsd\" version=\"3.0\"&gt; &lt;/persistence&gt; Helidon MP&#8217;s Jakarta Persistence integration supports Jakarta Persistence version 3.0 . `&lt;persistence-unit&gt; elements are listed here. Persistence Unit You list your application&#8217;s persistence units as &lt;persistence-unit&gt; child elements of the enclosing &lt;persistence&gt; element. Each &lt;persistence-unit&gt; element identifies a named persistence unit that will correspond to an EntityManager in your code, and represents a collection of entities in a relational database. Example: Persistence Unit Skeleton Here is a partial example of a persistence unit named prod with a helpful description: <markup lang=\"xml\" title=\" src/main/resources/META-INF/persistence.xml \" >&lt;!-- ... --&gt; &lt;persistence-unit name=\"prod\" transaction-type=\"JTA\"&gt; &lt;description&gt;The production database&lt;/description&gt; &lt;/persistence-unit&gt; &lt;!-- ... --&gt; Because Helidon MP&#8217;s JPA integration is for container-managed JPA, the transaction-type attribute must in practice always be set to JTA . The order of subsequent child elements is significant and governed by the XML schema . In most microservices, there will be only one persistence unit. A &lt;persistence-unit&gt; is represented in Jakarta Persistence as an instance of the PersistenceUnitInfo class. JTA Data Source A persistence unit is always associated with exactly one named data source . Because Helidon MP&#8217;s Jakarta Persistence integration provides support for container-managed JPA, and because container-managed JPA requires Jakarta Transactions (JTA), the kind of named data source a persistence unit is associated with is always a JTA data source. The &lt;jta-data-source&gt; element, a child of the &lt;persistence-unit&gt; element, is how you link a persistence unit to a named data source you previously configured . Example: Persistence Unit with JTA Data Source Here is a partial example of a persistence unit named prod , with a helpful description, linked with a JTA data source named main : <markup lang=\"xml\" title=\" src/main/resources/META-INF/persistence.xml \" >&lt;!-- ... ---&gt; &lt;persistence-unit name=\"prod\" transaction-type=\"JTA\"&gt; &lt;description&gt;The production database&lt;/description&gt; &lt;jta-data-source&gt;main&lt;/jta-data-source&gt; &lt;/persistence-unit&gt; &lt;!-- ... --&gt; This links this persistence unit to a data source named main , whose connectivity information can be found in a MicroProfile-Config-compatible location, as detailed in the data source configuration section above. Other persistence unit characteristics go here. Classes A persistence unit lists the classes that should be managed and that will take part in Jakarta Persistence workflows. You must list: Entity classes Embeddable classes Mapped superclasses Converter classes You use a sequence of &lt;class&gt; elements to do this. Each &lt;class&gt; element contains the fully-qualified class name of one of the types of managed classes listed above. There are other mechanisms that can be used in a META-INF/persistence.xml file to describe managed classes , but they may or may not be honored by a given JPA provider. Example: Persistence Unit with Class Elements Here is a partial example of a persistence unit named prod , with a helpful description, linked with a JTA data source named main , containing two entity classes: <markup lang=\"xml\" title=\" src/main/resources/META-INF/persistence.xml \" >&lt;!-- ... ---&gt; &lt;persistence-unit name=\"prod\" transaction-type=\"JTA\"&gt; &lt;description&gt;The production database&lt;/description&gt; &lt;jta-data-source&gt;main&lt;/jta-data-source&gt; &lt;class&gt;com.example.ExampleEntity0&lt;/class&gt; &lt;class&gt;com.example.ExampleEntity1&lt;/class&gt; &lt;/persistence-unit&gt; &lt;!-- ... --&gt; Each entity class is listed with a separate &lt;class&gt; element, and there is no containing &lt;classes&gt; element or similar. Other persistence unit characteristics go here. Properties Persistence units can have simple properties attached to them to further configure the backing JPA provider. You use the &lt;properties&gt; element to specify them. Helidon MP&#8217;s Jakarta Persistence integration is for container-managed JPA, so the vendor-independent properties described in the specification directly concerned with database connectivity information, such as jakarta.persistence.jdbc.url , do not apply and will be ignored if present. See the JTA Data Source section above for how a persistence unit is linked to a named data source . Example: Persistence Unit with Properties Here is a partial exmaple of a persistence unit named prod , with a helpful description, linked with a JTA data source named main , containing two entity classes, configuring a Hibernate ORM-specific property: <markup lang=\"xml\" title=\" src/main/resources/META-INF/persistence.xml \" >&lt;!-- ... ---&gt; &lt;persistence-unit name=\"prod\" transaction-type=\"JTA\"&gt; &lt;description&gt;The production database&lt;/description&gt; &lt;jta-data-source&gt;main&lt;/jta-data-source&gt; &lt;class&gt;com.example.ExampleEntity0&lt;/class&gt; &lt;class&gt;com.example.ExampleEntity1&lt;/class&gt; &lt;properties&gt; &lt;property name=\"hibernate.show_sql\" value=\"true\"/&gt; &lt;property name=\"eclipselink.weaving\" value=\"false\"/&gt; &lt;/properties&gt; &lt;/persistence-unit&gt; &lt;!-- ... --&gt; The name identifies a name present in the datasourcename portion of a named datasource configuration . There is no need for any kind of reserved prefix (like java:comp/env ). This is a Hibernate ORM-specific property and will be properly ignored if the JPA provider you have set up is Eclipselink. See Statement logging and statistics in the Hibernate ORM documentation for more details about the hibernate.show_sql property. This is an Eclipselink-specific property (and (a) is required and (b) must be set to false if you are using Eclipselink), and will be properly ignored if the JPA provider you have set up is Hibernate ORM. See weaving in the Eclipselink documentation for more details about the eclipselink.weaving property. For an exhaustive list of Hibernate ORM-specific properties, see Configurations in the Hibernate ORM documentation. For an exhaustive list of Eclipselink-specific properties, see Persistence Property Extensions Reference in the Eclipselink documentation. Usage To use Helidon MP&#8217;s Jakarta Persistence integration, once you have set up and configured your project, you use the Jakarta Persistence APIs in almost the same manner as if your project were deployed to a Jakarta EE server. Specifically, you: Annotate your managed classes (entities, mapped superclasses, etc.) appropriately (using @Entity and similar annotations) Inject EntityManager instances appropriately with the @PersistenceContext annotation Use an injected EntityManager to work with your managed objects In addition, you use Helidon MP&#8217;s JTA integration to declare transactional boundaries where appropriate. A full tutorial of Jakarta Persistence is well beyond the scope of this documentation. Consult the specification for details on how to map your entity classes to relational database tables, and how to perform other related tasks. Examples JPA Pokemons Example ",
            "title": "Jakarta Persistence (JPA)"
        },
        {
            "location": "mp/persistence",
            "text": " Managing Dependencies in Helidon MP MicroProfile Config in Helidon MP JDBC 4.3 Specification HikariCP 5.0.1 documentation Developers Guide For Oracle JDBC 21c on Maven Central Oracle® Universal Connection Pool Developer&#8217;s Guide, Release 21c Oracle® Universal Connection Pool Java API Reference, Release 21c Oracle® Database JDBC Developer&#8217;s Guide and Reference, Release 21c Oracle® Database JDBC Java API Reference, Release 21c H2 Database Engine documentation Jakarta Transactions 2.0 Specification Jakarta Transactions 2.0 API Reference Narayana Project Documentation Narayana API Reference Jakarta Persistence {persistence-lib-jakarta-persistence-api} Specification Jakarta Persistence {persistence-lib-jakarta-persistence-api} API Reference Hibernate ORM User Guide Eclipselink documentation ",
            "title": "References"
        },
        {
            "location": "mp/reactivemessaging/aq",
            "text": " To enable AQ Connector add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.messaging.aq&lt;/groupId&gt; &lt;artifactId&gt;helidon-messaging-aq&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "mp/reactivemessaging/aq",
            "text": " Connector name: helidon-aq Attributes datasource name of the datasource bean used to connect Oracle DB with AQ url jdbc connection string used to connect Oracle DB with AQ (forbidden when datasource is specified) username User name used to connect Oracle DB with AQ (forbidden when datasource is specified) password Password to connect Oracle DB with AQ (forbidden when datasource is specified) type Possible values are: queue , topic destination Queue or topic name acknowledge-mode Possible values are: AUTO_ACKNOWLEDGE - session automatically acknowledges a client’s receipt of a message, CLIENT_ACKNOWLEDGE - receipt of a message is acknowledged only when Message.ack() is called manually, DUPS_OK_ACKNOWLEDGE - session lazily acknowledges the delivery of messages. Default value: AUTO_ACKNOWLEDGE transacted Indicates whether the session will use a local transaction. Default value: false message-selector JMS API message selector expression based on a subset of the SQL92. Expression can only access headers and properties, not the payload. client-id Client identifier for JMS connection. durable True for creating durable consumer (only for topic). Default value: false subscriber-name Subscriber name for durable consumer used to identify subscription. non-local If true then any messages published to the topic using this session&#8217;s connection, or any other connection with the same client identifier, will not be added to the durable subscription. Default value: false named-factory Select in case factory is injected as a named bean or configured with name. poll-timeout Timeout for polling for next message in every poll cycle in millis. Default value: 50 period-executions Period for executing poll cycles in millis. Default value: 100 session-group-id When multiple channels share same session-group-id , they share same JMS session and same JDBC connection as well. ",
            "title": "Configuration"
        },
        {
            "location": "mp/reactivemessaging/aq",
            "text": " The simplest possible usage is leaving construction of AQjmsConnectionFactory to the connector. <markup lang=\"yaml\" title=\"Example of connector config:\" >mp: messaging: connector: helidon-aq: transacted: false acknowledge-mode: CLIENT_ACKNOWLEDGE url: jdbc:oracle:thin:@(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(Host=192.168.0.123)(Port=1521))(CONNECT_DATA=(SID=TESTSID))) user: gandalf password: mellon outgoing.to-aq: connector: helidon-aq destination: TESTQUEUE type: queue incoming.from-aq: connector: helidon-aq destination: TESTQUEUE type: queue Its also possible and preferable to refer to configured datasource , in our example Oracle UCP datasource : <markup lang=\"yaml\" title=\"Example of connector config with Oracle UCP datasource:\" >javax: sql: DataSource: aq-test-ds: connectionFactoryClassName: oracle.jdbc.pool.OracleDataSource URL: jdbc:oracle:thin:@exampledb_high?TNS_ADMIN=/home/gandalf/wallets/Wallet_EXAMPLEDB user: gandalf password: SuperSecretPassword1234 mp: messaging: connector: helidon-aq: transacted: false acknowledge-mode: CLIENT_ACKNOWLEDGE data-source: aq-test-ds outgoing.toJms: connector: helidon-aq destination: TESTQUEUE type: queue incoming.fromJms: connector: helidon-aq destination: TESTQUEUE type: queue ",
            "title": "Configured JMS Factory"
        },
        {
            "location": "mp/reactivemessaging/aq",
            "text": " If you need more advanced configurations, connector can work with injected AQjmsConnectionFactory : <markup lang=\"java\" title=\"Inject:\" > @Produces @ApplicationScoped @Named(\"aq-orderdb-factory\") public AQjmsConnectionFactory connectionFactory() throws JMSException { AQjmsQueueConnectionFactory fact = new AQjmsQueueConnectionFactory(); fact.setJdbcURL(config.get(\"jdbc.url\").asString().get()); fact.setUsername(config.get(\"jdbc.user\").asString().get()); fact.setPassword(config.get(\"jdbc.pass\").asString().get()); return fact; } <markup lang=\"yaml\" title=\"Config:\" >jdbc: url: jdbc:oracle:thin:@(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(Host=192.168.0.123)(Port=1521))(CONNECT_DATA=(SID=TESTSID))) user: gandalf pass: mellon mp: messaging: connector: helidon-aq: named-factory: aq-orderdb-factory outgoing.to-aq: connector: helidon-aq session-group-id: order-connection-1 destination: TESTQUEUE type: queue incoming.from-aq: connector: helidon-aq session-group-id: order-connection-1 destination: TESTQUEUE type: queue ",
            "title": "Injected JMS factory"
        },
        {
            "location": "mp/reactivemessaging/aq",
            "text": "<markup lang=\"java\" title=\"Consuming one by one unwrapped value:\" >@Incoming(\"from-aq\") public void consumeAq(String msg) { System.out.println(\"Oracle AQ says: \" + msg); } <markup lang=\"java\" title=\"Consuming one by one, manual ack:\" >@Incoming(\"from-aq\") @Acknowledgment(Acknowledgment.Strategy.MANUAL) public CompletionStage&lt;?&gt; consumeAq(AqMessage&lt;String&gt; msg) { // direct commit //msg.getDbConnection().commit(); System.out.println(\"Oracle AQ says: \" + msg.getPayload()); // ack commits only in non-transacted mode return msg.ack(); } ",
            "title": "Consuming"
        },
        {
            "location": "mp/reactivemessaging/aq",
            "text": "<markup lang=\"java\" title=\"Producing to AQ:\" >@Outgoing(\"to-aq\") public PublisherBuilder&lt;String&gt; produceToAq() { return ReactiveStreams.of(\"test1\", \"test2\"); } ",
            "title": "Producing"
        },
        {
            "location": "mp/reactivemessaging/aq",
            "text": " Connecting streams to Oracle AQ with Reactive Messaging couldn&#8217;t be easier. This connector extends Helidon&#8217;s JMS connector with Oracle&#8217;s AQ-specific API. Configuration Connector name: helidon-aq Attributes datasource name of the datasource bean used to connect Oracle DB with AQ url jdbc connection string used to connect Oracle DB with AQ (forbidden when datasource is specified) username User name used to connect Oracle DB with AQ (forbidden when datasource is specified) password Password to connect Oracle DB with AQ (forbidden when datasource is specified) type Possible values are: queue , topic destination Queue or topic name acknowledge-mode Possible values are: AUTO_ACKNOWLEDGE - session automatically acknowledges a client’s receipt of a message, CLIENT_ACKNOWLEDGE - receipt of a message is acknowledged only when Message.ack() is called manually, DUPS_OK_ACKNOWLEDGE - session lazily acknowledges the delivery of messages. Default value: AUTO_ACKNOWLEDGE transacted Indicates whether the session will use a local transaction. Default value: false message-selector JMS API message selector expression based on a subset of the SQL92. Expression can only access headers and properties, not the payload. client-id Client identifier for JMS connection. durable True for creating durable consumer (only for topic). Default value: false subscriber-name Subscriber name for durable consumer used to identify subscription. non-local If true then any messages published to the topic using this session&#8217;s connection, or any other connection with the same client identifier, will not be added to the durable subscription. Default value: false named-factory Select in case factory is injected as a named bean or configured with name. poll-timeout Timeout for polling for next message in every poll cycle in millis. Default value: 50 period-executions Period for executing poll cycles in millis. Default value: 100 session-group-id When multiple channels share same session-group-id , they share same JMS session and same JDBC connection as well. Configured JMS Factory The simplest possible usage is leaving construction of AQjmsConnectionFactory to the connector. <markup lang=\"yaml\" title=\"Example of connector config:\" >mp: messaging: connector: helidon-aq: transacted: false acknowledge-mode: CLIENT_ACKNOWLEDGE url: jdbc:oracle:thin:@(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(Host=192.168.0.123)(Port=1521))(CONNECT_DATA=(SID=TESTSID))) user: gandalf password: mellon outgoing.to-aq: connector: helidon-aq destination: TESTQUEUE type: queue incoming.from-aq: connector: helidon-aq destination: TESTQUEUE type: queue Its also possible and preferable to refer to configured datasource , in our example Oracle UCP datasource : <markup lang=\"yaml\" title=\"Example of connector config with Oracle UCP datasource:\" >javax: sql: DataSource: aq-test-ds: connectionFactoryClassName: oracle.jdbc.pool.OracleDataSource URL: jdbc:oracle:thin:@exampledb_high?TNS_ADMIN=/home/gandalf/wallets/Wallet_EXAMPLEDB user: gandalf password: SuperSecretPassword1234 mp: messaging: connector: helidon-aq: transacted: false acknowledge-mode: CLIENT_ACKNOWLEDGE data-source: aq-test-ds outgoing.toJms: connector: helidon-aq destination: TESTQUEUE type: queue incoming.fromJms: connector: helidon-aq destination: TESTQUEUE type: queue Injected JMS factory If you need more advanced configurations, connector can work with injected AQjmsConnectionFactory : <markup lang=\"java\" title=\"Inject:\" > @Produces @ApplicationScoped @Named(\"aq-orderdb-factory\") public AQjmsConnectionFactory connectionFactory() throws JMSException { AQjmsQueueConnectionFactory fact = new AQjmsQueueConnectionFactory(); fact.setJdbcURL(config.get(\"jdbc.url\").asString().get()); fact.setUsername(config.get(\"jdbc.user\").asString().get()); fact.setPassword(config.get(\"jdbc.pass\").asString().get()); return fact; } <markup lang=\"yaml\" title=\"Config:\" >jdbc: url: jdbc:oracle:thin:@(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(Host=192.168.0.123)(Port=1521))(CONNECT_DATA=(SID=TESTSID))) user: gandalf pass: mellon mp: messaging: connector: helidon-aq: named-factory: aq-orderdb-factory outgoing.to-aq: connector: helidon-aq session-group-id: order-connection-1 destination: TESTQUEUE type: queue incoming.from-aq: connector: helidon-aq session-group-id: order-connection-1 destination: TESTQUEUE type: queue Consuming <markup lang=\"java\" title=\"Consuming one by one unwrapped value:\" >@Incoming(\"from-aq\") public void consumeAq(String msg) { System.out.println(\"Oracle AQ says: \" + msg); } <markup lang=\"java\" title=\"Consuming one by one, manual ack:\" >@Incoming(\"from-aq\") @Acknowledgment(Acknowledgment.Strategy.MANUAL) public CompletionStage&lt;?&gt; consumeAq(AqMessage&lt;String&gt; msg) { // direct commit //msg.getDbConnection().commit(); System.out.println(\"Oracle AQ says: \" + msg.getPayload()); // ack commits only in non-transacted mode return msg.ack(); } Producing <markup lang=\"java\" title=\"Producing to AQ:\" >@Outgoing(\"to-aq\") public PublisherBuilder&lt;String&gt; produceToAq() { return ReactiveStreams.of(\"test1\", \"test2\"); } ",
            "title": "Reactive Oracle Advanced Queueing Connector"
        },
        {
            "location": "mp/reactivemessaging/introduction",
            "text": " Overview Maven Coordinates Usage Configuration Reference Additional Information ",
            "title": "Contents"
        },
        {
            "location": "mp/reactivemessaging/introduction",
            "text": " Reactive messaging offers a new way of processing messages that is different from the older method of using message-driven beans. One significant difference is that blocking is no longer the only way to apply backpressure to the message source. Reactive messaging uses reactive streams as message channels so you can construct very effective pipelines for working with the messages or, if you prefer, you can continue to use older messaging methods. Like the message-driven beans, MicroProfile Reactive Messaging uses CDI beans to produce, consume or process messages over Reactive Streams. These essaging beans are expected to be either ApplicationScoped or Dependent scoped. Messages are managed by methods annotated by @Incoming and @Outgoing and the invocation is always driven by message core - either at assembly time, or for every message coming from the stream. ",
            "title": "Overview"
        },
        {
            "location": "mp/reactivemessaging/introduction",
            "text": " To enable MicroProfile Reactive Messaging add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.messaging&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-messaging&lt;/artifactId&gt; &lt;/dependency&gt; To include health checks for Messaging add the following dependency: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.messaging&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-messaging-health&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "mp/reactivemessaging/introduction",
            "text": " Consuming methods can be connected to the channel&#8217;s downstream to consume the message coming through the channel. The incoming annotation has one required attribute value that defines the channel name. Consuming method can function in two ways: consume every message coming from the stream connected to the channels - invoked per each message prepare reactive stream&#8217;s subscriber and connect it to the channel - invoked only once during the channel construction <markup lang=\"java\" title=\"Example consuming every message from channel example-channel-2 :\" >@Incoming(\"example-channel-2\") public void printMessage(String msg) { System.out.println(\"Just received message: \" + msg); } <markup lang=\"java\" title=\"Example preparing reactive stream subscriber for channel example-channel-1 :\" >@Incoming(\"example-channel-2\") public Subscriber&lt;String&gt; printMessage() { return ReactiveStreams.&lt;String&gt;builder() .forEach(msg -&gt; System.out.println(\"Just received message: \" + msg)) .build(); } ",
            "title": "Consuming Method"
        },
        {
            "location": "mp/reactivemessaging/introduction",
            "text": " Directly injected publisher can be connected as a channel downstream, you can consume the data from the channel by subscribing to it. Helidon can inject following types of publishers: Publisher&lt;PAYLOAD&gt; - Reactive streams publisher with unwrapped payload Publisher&lt;Message&lt;PAYLOAD&gt;&gt; - Reactive streams publisher with whole message PublisherBuilder&lt;PAYLOAD&gt; - MP Reactive streams operators publisher builder with unwrapped payload PublisherBuilder&lt;Message&lt;PAYLOAD&gt;&gt; - MP Reactive streams operators publisher builder with whole message Flow.Publisher&lt;PAYLOAD&gt; - JDK&#8217;s flow publisher with unwrapped payload Flow.Publisher&lt;Message&lt;PAYLOAD&gt;&gt; - JDK&#8217;s flow publisher with whole message Multi&lt;PAYLOAD&gt; - Helidon flow reactive operators with unwrapped payload Multi&lt;Message&lt;PAYLOAD&gt;&gt; - Helidon flow reactive operators with whole message <markup lang=\"java\" title=\"Example of consuming payloads from channel example-channel-1 with injected publisher:\" >@Inject public MyBean(@Channel(\"example-channel-1\") Multi&lt;String&gt; multiChannel) { multiChannel .map(String::toUpperCase) .forEach(s -&gt; System.out.println(\"Received \" + s)); } ",
            "title": "Injected Publisher"
        },
        {
            "location": "mp/reactivemessaging/introduction",
            "text": " The annotation has one required attribute value that defines the channel name. The annotated messaging method can function in two ways: produce exactly one message to the stream connected to the channel prepare reactive stream&#8217;s publisher and connect it to the channel <markup lang=\"java\" title=\"Example producing exactly one message to channel example-channel-1 :\" >@Outgoing(\"example-channel-1\") public String produceMessage() { return \"foo\"; } <markup lang=\"java\" title=\"Example preparing reactive stream publisher publishing three messages to the channel example-channel-1 :\" >@Outgoing(\"example-channel-1\") public Publisher&lt;String&gt; printMessage() { return ReactiveStreams.of(\"foo\", \"bar\", \"baz\").buildRs(); } Messaging methods are not meant to be invoked directly! ",
            "title": "Producing Method"
        },
        {
            "location": "mp/reactivemessaging/introduction",
            "text": " Reactive messaging uses named channels to connect one source (upstream) with one consumer (downstream). Each channel needs to have both ends connected otherwise the container cannot successfully start. Channels can be connected either to emitter (1), producing method (2) or connector (3) on the upstream side. And injected publisher (4), consuming method (5) or connector (6) on the downstream. Consuming Method Consuming methods can be connected to the channel&#8217;s downstream to consume the message coming through the channel. The incoming annotation has one required attribute value that defines the channel name. Consuming method can function in two ways: consume every message coming from the stream connected to the channels - invoked per each message prepare reactive stream&#8217;s subscriber and connect it to the channel - invoked only once during the channel construction <markup lang=\"java\" title=\"Example consuming every message from channel example-channel-2 :\" >@Incoming(\"example-channel-2\") public void printMessage(String msg) { System.out.println(\"Just received message: \" + msg); } <markup lang=\"java\" title=\"Example preparing reactive stream subscriber for channel example-channel-1 :\" >@Incoming(\"example-channel-2\") public Subscriber&lt;String&gt; printMessage() { return ReactiveStreams.&lt;String&gt;builder() .forEach(msg -&gt; System.out.println(\"Just received message: \" + msg)) .build(); } Injected Publisher Directly injected publisher can be connected as a channel downstream, you can consume the data from the channel by subscribing to it. Helidon can inject following types of publishers: Publisher&lt;PAYLOAD&gt; - Reactive streams publisher with unwrapped payload Publisher&lt;Message&lt;PAYLOAD&gt;&gt; - Reactive streams publisher with whole message PublisherBuilder&lt;PAYLOAD&gt; - MP Reactive streams operators publisher builder with unwrapped payload PublisherBuilder&lt;Message&lt;PAYLOAD&gt;&gt; - MP Reactive streams operators publisher builder with whole message Flow.Publisher&lt;PAYLOAD&gt; - JDK&#8217;s flow publisher with unwrapped payload Flow.Publisher&lt;Message&lt;PAYLOAD&gt;&gt; - JDK&#8217;s flow publisher with whole message Multi&lt;PAYLOAD&gt; - Helidon flow reactive operators with unwrapped payload Multi&lt;Message&lt;PAYLOAD&gt;&gt; - Helidon flow reactive operators with whole message <markup lang=\"java\" title=\"Example of consuming payloads from channel example-channel-1 with injected publisher:\" >@Inject public MyBean(@Channel(\"example-channel-1\") Multi&lt;String&gt; multiChannel) { multiChannel .map(String::toUpperCase) .forEach(s -&gt; System.out.println(\"Received \" + s)); } Producing Method The annotation has one required attribute value that defines the channel name. The annotated messaging method can function in two ways: produce exactly one message to the stream connected to the channel prepare reactive stream&#8217;s publisher and connect it to the channel <markup lang=\"java\" title=\"Example producing exactly one message to channel example-channel-1 :\" >@Outgoing(\"example-channel-1\") public String produceMessage() { return \"foo\"; } <markup lang=\"java\" title=\"Example preparing reactive stream publisher publishing three messages to the channel example-channel-1 :\" >@Outgoing(\"example-channel-1\") public Publisher&lt;String&gt; printMessage() { return ReactiveStreams.of(\"foo\", \"bar\", \"baz\").buildRs(); } Messaging methods are not meant to be invoked directly! ",
            "title": "Channels"
        },
        {
            "location": "mp/reactivemessaging/introduction",
            "text": " Such methods acts as processors, consuming messages from one channel and producing to another. Diagram shows how processing method (2) serves as a downstream to the my-channel (1) and an upstream to the other-channel (3), connecting them together. Processing method can function in multiple ways: process every message prepare reactive stream&#8217;s processor and connect it between the channels on every message prepare new publisher(equivalent to flatMap operator) <markup lang=\"java\" title=\"Example processing every message from channel example-channel-1 to channel example-channel-2 :\" >@Incoming(\"example-channel-1\") @Outgoing(\"example-channel-2\") public String processMessage(String msg) { return msg.toUpperCase(); } <markup lang=\"java\" title=\"Example preparing processor stream to be connected between channels example-channel-1 and example-channel-2 :\" >@Incoming(\"example-channel-1\") @Outgoing(\"example-channel-2\") public Processor&lt;String, String&gt; processMessage() { return ReactiveStreams.&lt;String&gt;builder() .map(String::toUpperCase) .buildRs(); } <markup lang=\"java\" title=\"Example processing every message from channel example-channel-1`as stream to be flattened to channel `example-channel-2 :\" >@Incoming(\"example-channel-1\") @Outgoing(\"example-channel-2\") public String processMessage(String msg) { return ReactiveStreams.of(msg.toUpperCase(), msg.toLowerCase()).buildRs(); } ",
            "title": "Processing Method"
        },
        {
            "location": "mp/reactivemessaging/introduction",
            "text": " To send messages from imperative code, you can inject a special channel source called an emitter. Emitter can serve only as an upstream, source of the messages, for messaging channel. <markup lang=\"java\" title=\"Example of sending message from JAX-RS method to channel example-channel-1 \" >@Inject @Channel(\"example-channel-1\") private Emitter&lt;String&gt; emitter; @PUT @Path(\"/sendMessage\") @Consumes(MediaType.TEXT_PLAIN) public Response sendMessage(final String payload) { emitter.send(payload); } Emitters, as a source of messages for reactive channels, need to address possible backpressure from the downstream side of the channel. In case there is not enough demand from the downstream, you can configure a buffer size strategy using the @OnOverflow annotation. Additional overflow strategies are described below. Overflow strategies Strategy Description BUFFER Buffer unconsumed values until configured bufferSize is reached, when reached calling Emitter.emit throws IllegalStateException . Buffer size can be configured with @OnOverflow or with config key mp.messaging.emitter.default-buffer-size . Default value is 128 . UNBOUNDED_BUFFER Buffer unconsumed values until application runs out of memory. THROW_EXCEPTION Calling Emitter.emit throws IllegalStateException if there is not enough items requested by downstream. DROP If there is not enough items requested by downstream, emitted message is silently dropped. FAIL If there is not enough items requested by downstream, emitting message causes error signal being send to downstream. Whole channel is terminated. No other messages can be sent. LATEST Keeps only the latest item. Any previous unconsumed message is silently dropped. NONE Messages are sent to downstream even if there is no demand. Backpressure is effectively ignored. Processing Method Such methods acts as processors, consuming messages from one channel and producing to another. Diagram shows how processing method (2) serves as a downstream to the my-channel (1) and an upstream to the other-channel (3), connecting them together. Processing method can function in multiple ways: process every message prepare reactive stream&#8217;s processor and connect it between the channels on every message prepare new publisher(equivalent to flatMap operator) <markup lang=\"java\" title=\"Example processing every message from channel example-channel-1 to channel example-channel-2 :\" >@Incoming(\"example-channel-1\") @Outgoing(\"example-channel-2\") public String processMessage(String msg) { return msg.toUpperCase(); } <markup lang=\"java\" title=\"Example preparing processor stream to be connected between channels example-channel-1 and example-channel-2 :\" >@Incoming(\"example-channel-1\") @Outgoing(\"example-channel-2\") public Processor&lt;String, String&gt; processMessage() { return ReactiveStreams.&lt;String&gt;builder() .map(String::toUpperCase) .buildRs(); } <markup lang=\"java\" title=\"Example processing every message from channel example-channel-1`as stream to be flattened to channel `example-channel-2 :\" >@Incoming(\"example-channel-1\") @Outgoing(\"example-channel-2\") public String processMessage(String msg) { return ReactiveStreams.of(msg.toUpperCase(), msg.toLowerCase()).buildRs(); } ",
            "title": "Emitter"
        },
        {
            "location": "mp/reactivemessaging/introduction",
            "text": " Messaging connector is an application-scoped bean that implements one or both of following interfaces: IncomingConnectorFactory - connector can create an upstream publisher to produce messages to a channel OutgoingConnectorFactory - connector can create a downstream subscriber to consume messages from a channel <markup lang=\"java\" title=\"Example connector example-connector :\" >@ApplicationScoped @Connector(\"example-connector\") public class ExampleConnector implements IncomingConnectorFactory, OutgoingConnectorFactory { @Override public PublisherBuilder&lt;? extends Message&lt;?&gt;&gt; getPublisherBuilder(Config config) { return ReactiveStreams.of(\"foo\", \"bar\") .map(Message::of); } @Override public SubscriberBuilder&lt;? extends Message&lt;?&gt;, Void&gt; getSubscriberBuilder(Config config) { return ReactiveStreams.&lt;Message&lt;?&gt;&gt;builder() .map(Message::getPayload) .forEach(o -&gt; System.out.println(\"Connector says: \" + o)); } } ",
            "title": "Connector"
        },
        {
            "location": "mp/reactivemessaging/introduction",
            "text": " Channels Emitter Connector Channels Reactive messaging uses named channels to connect one source (upstream) with one consumer (downstream). Each channel needs to have both ends connected otherwise the container cannot successfully start. Channels can be connected either to emitter (1), producing method (2) or connector (3) on the upstream side. And injected publisher (4), consuming method (5) or connector (6) on the downstream. Consuming Method Consuming methods can be connected to the channel&#8217;s downstream to consume the message coming through the channel. The incoming annotation has one required attribute value that defines the channel name. Consuming method can function in two ways: consume every message coming from the stream connected to the channels - invoked per each message prepare reactive stream&#8217;s subscriber and connect it to the channel - invoked only once during the channel construction <markup lang=\"java\" title=\"Example consuming every message from channel example-channel-2 :\" >@Incoming(\"example-channel-2\") public void printMessage(String msg) { System.out.println(\"Just received message: \" + msg); } <markup lang=\"java\" title=\"Example preparing reactive stream subscriber for channel example-channel-1 :\" >@Incoming(\"example-channel-2\") public Subscriber&lt;String&gt; printMessage() { return ReactiveStreams.&lt;String&gt;builder() .forEach(msg -&gt; System.out.println(\"Just received message: \" + msg)) .build(); } Injected Publisher Directly injected publisher can be connected as a channel downstream, you can consume the data from the channel by subscribing to it. Helidon can inject following types of publishers: Publisher&lt;PAYLOAD&gt; - Reactive streams publisher with unwrapped payload Publisher&lt;Message&lt;PAYLOAD&gt;&gt; - Reactive streams publisher with whole message PublisherBuilder&lt;PAYLOAD&gt; - MP Reactive streams operators publisher builder with unwrapped payload PublisherBuilder&lt;Message&lt;PAYLOAD&gt;&gt; - MP Reactive streams operators publisher builder with whole message Flow.Publisher&lt;PAYLOAD&gt; - JDK&#8217;s flow publisher with unwrapped payload Flow.Publisher&lt;Message&lt;PAYLOAD&gt;&gt; - JDK&#8217;s flow publisher with whole message Multi&lt;PAYLOAD&gt; - Helidon flow reactive operators with unwrapped payload Multi&lt;Message&lt;PAYLOAD&gt;&gt; - Helidon flow reactive operators with whole message <markup lang=\"java\" title=\"Example of consuming payloads from channel example-channel-1 with injected publisher:\" >@Inject public MyBean(@Channel(\"example-channel-1\") Multi&lt;String&gt; multiChannel) { multiChannel .map(String::toUpperCase) .forEach(s -&gt; System.out.println(\"Received \" + s)); } Producing Method The annotation has one required attribute value that defines the channel name. The annotated messaging method can function in two ways: produce exactly one message to the stream connected to the channel prepare reactive stream&#8217;s publisher and connect it to the channel <markup lang=\"java\" title=\"Example producing exactly one message to channel example-channel-1 :\" >@Outgoing(\"example-channel-1\") public String produceMessage() { return \"foo\"; } <markup lang=\"java\" title=\"Example preparing reactive stream publisher publishing three messages to the channel example-channel-1 :\" >@Outgoing(\"example-channel-1\") public Publisher&lt;String&gt; printMessage() { return ReactiveStreams.of(\"foo\", \"bar\", \"baz\").buildRs(); } Messaging methods are not meant to be invoked directly! Emitter To send messages from imperative code, you can inject a special channel source called an emitter. Emitter can serve only as an upstream, source of the messages, for messaging channel. <markup lang=\"java\" title=\"Example of sending message from JAX-RS method to channel example-channel-1 \" >@Inject @Channel(\"example-channel-1\") private Emitter&lt;String&gt; emitter; @PUT @Path(\"/sendMessage\") @Consumes(MediaType.TEXT_PLAIN) public Response sendMessage(final String payload) { emitter.send(payload); } Emitters, as a source of messages for reactive channels, need to address possible backpressure from the downstream side of the channel. In case there is not enough demand from the downstream, you can configure a buffer size strategy using the @OnOverflow annotation. Additional overflow strategies are described below. Overflow strategies Strategy Description BUFFER Buffer unconsumed values until configured bufferSize is reached, when reached calling Emitter.emit throws IllegalStateException . Buffer size can be configured with @OnOverflow or with config key mp.messaging.emitter.default-buffer-size . Default value is 128 . UNBOUNDED_BUFFER Buffer unconsumed values until application runs out of memory. THROW_EXCEPTION Calling Emitter.emit throws IllegalStateException if there is not enough items requested by downstream. DROP If there is not enough items requested by downstream, emitted message is silently dropped. FAIL If there is not enough items requested by downstream, emitting message causes error signal being send to downstream. Whole channel is terminated. No other messages can be sent. LATEST Keeps only the latest item. Any previous unconsumed message is silently dropped. NONE Messages are sent to downstream even if there is no demand. Backpressure is effectively ignored. Processing Method Such methods acts as processors, consuming messages from one channel and producing to another. Diagram shows how processing method (2) serves as a downstream to the my-channel (1) and an upstream to the other-channel (3), connecting them together. Processing method can function in multiple ways: process every message prepare reactive stream&#8217;s processor and connect it between the channels on every message prepare new publisher(equivalent to flatMap operator) <markup lang=\"java\" title=\"Example processing every message from channel example-channel-1 to channel example-channel-2 :\" >@Incoming(\"example-channel-1\") @Outgoing(\"example-channel-2\") public String processMessage(String msg) { return msg.toUpperCase(); } <markup lang=\"java\" title=\"Example preparing processor stream to be connected between channels example-channel-1 and example-channel-2 :\" >@Incoming(\"example-channel-1\") @Outgoing(\"example-channel-2\") public Processor&lt;String, String&gt; processMessage() { return ReactiveStreams.&lt;String&gt;builder() .map(String::toUpperCase) .buildRs(); } <markup lang=\"java\" title=\"Example processing every message from channel example-channel-1`as stream to be flattened to channel `example-channel-2 :\" >@Incoming(\"example-channel-1\") @Outgoing(\"example-channel-2\") public String processMessage(String msg) { return ReactiveStreams.of(msg.toUpperCase(), msg.toLowerCase()).buildRs(); } Connector Messaging connector is an application-scoped bean that implements one or both of following interfaces: IncomingConnectorFactory - connector can create an upstream publisher to produce messages to a channel OutgoingConnectorFactory - connector can create a downstream subscriber to consume messages from a channel <markup lang=\"java\" title=\"Example connector example-connector :\" >@ApplicationScoped @Connector(\"example-connector\") public class ExampleConnector implements IncomingConnectorFactory, OutgoingConnectorFactory { @Override public PublisherBuilder&lt;? extends Message&lt;?&gt;&gt; getPublisherBuilder(Config config) { return ReactiveStreams.of(\"foo\", \"bar\") .map(Message::of); } @Override public SubscriberBuilder&lt;? extends Message&lt;?&gt;, Void&gt; getSubscriberBuilder(Config config) { return ReactiveStreams.&lt;Message&lt;?&gt;&gt;builder() .map(Message::getPayload) .forEach(o -&gt; System.out.println(\"Connector says: \" + o)); } } ",
            "title": "Usage"
        },
        {
            "location": "mp/reactivemessaging/introduction",
            "text": " The Reactive Messaging Message class can be used to wrap or unwrap data items between methods and connectors. The message wrapping and unwrapping can be performed explicitly by using org.eclipse.microprofile.reactive.messaging.Message#of(T) or implicitly through the messaging core. <markup lang=\"java\" title=\"Example of explicit and implicit wrapping and unwrapping\" >@Outgoing(\"publisher-payload\") public PublisherBuilder&lt;Integer&gt; streamOfMessages() { return ReactiveStreams.of(0, 1, 2, 3, 4, 5, 6, 7, 8, 9); } @Incoming(\"publisher-payload\") @Outgoing(\"wrapped-message\") public Message&lt;String&gt; rewrapMessageManually(Message&lt;Integer&gt; message) { return Message.of(Integer.toString(message.getPayload())); } @Incoming(\"wrapped-message\") public void consumeImplicitlyUnwrappedMessage(String value) { System.out.println(\"Consuming message: \" + value); } ",
            "title": "Message"
        },
        {
            "location": "mp/reactivemessaging/introduction",
            "text": " Messages carry a callback for reception acknowledgement (ack) and negative acknowledgement (nack). An acknowledgement in messaging methods is possible manually by org.eclipse.microprofile.reactive.messaging.Message#ack or automatically according explicit or implicit acknowledgement strategy by the messaging core. Explicit strategy configuration is possible with @Acknowledgment annotation which has one required attribute value that expects the strategy type from enum org.eclipse.microprofile.reactive.messaging.Acknowledgment.Strategy . More information about supported signatures and implicit automatic acknowledgement can be found in specification Message acknowledgement . Acknowledgement strategies @Acknowledgment(Acknowledgment.Strategy.NONE) No acknowledgment @Acknowledgment(Acknowledgment.Strategy.MANUAL) No automatic acknowledgment @Acknowledgment(Acknowledgment.Strategy.PRE_PROCESSING) Ack automatically before method invocation or processing @Acknowledgment(Acknowledgment.Strategy.POST_PROCESSING) Ack automatically after method invocation or processing <markup lang=\"java\" title=\"Example of manual acknowledgment\" >@Outgoing(\"consume-and-ack\") public PublisherBuilder&lt;Integer&gt; streamOfMessages() { return ReactiveStreams.of(Message.of(\"This is Payload\", () -&gt; { System.out.println(\"This particular message was acked!\"); return CompletableFuture.completedFuture(null); })).buildRs(); } @Incoming(\"consume-and-ack\") @Acknowledgment(Acknowledgment.Strategy.MANUAL) public CompletionStage&lt;Void&gt; receiveAndAckMessage(Message&lt;String&gt; msg) { return msg.ack(); } Calling ack() will print \"This particular message was acked!\" to System.out <markup lang=\"java\" title=\"Example of manual acknowledgment\" >@Outgoing(\"consume-and-ack\") public PublisherBuilder&lt;Integer&gt; streamOfMessages() { return ReactiveStreams.of(Message.of(\"This is Payload\", () -&gt; { System.out.println(\"This particular message was acked!\"); return CompletableFuture.completedFuture(null); })).buildRs(); } @Incoming(\"consume-and-ack\") @Acknowledgment(Acknowledgment.Strategy.MANUAL) public CompletionStage&lt;Void&gt; receiveAndAckMessage(Message&lt;String&gt; msg) { return msg.ack(); } Calling ack() will print \"This particular message was acked!\" to System.out <markup lang=\"java\" title=\"Example of explicit pre-process acknowledgment\" >@Outgoing(\"consume-and-ack\") public PublisherBuilder&lt;Integer&gt; streamOfMessages() { return ReactiveStreams.of(Message.of(\"This is Payload\", () -&gt; { System.out.println(\"This particular message was acked!\"); return CompletableFuture.completedFuture(null); })).buildRs(); } /** * Prints to the console: * &gt; This particular message was acked! * &gt; Method invocation! */ @Incoming(\"consume-and-ack\") @Acknowledgment(Acknowledgment.Strategy.PRE_PROCESSING) public CompletionStage&lt;Void&gt; receiveAndAckMessage(Message&lt;String&gt; msg) { System.out.println(\"Method invocation!\"); return CompletableFuture.completedFuture(null); } <markup lang=\"java\" title=\"Example of explicit post-process acknowledgment\" >@Outgoing(\"consume-and-ack\") public PublisherBuilder&lt;Integer&gt; streamOfMessages() { return ReactiveStreams.of(Message.of(\"This is Payload\", () -&gt; { System.out.println(\"This particular message was acked!\"); return CompletableFuture.completedFuture(null); })).buildRs(); } /** * Prints to the console: * &gt; Method invocation! * &gt; This particular message was acked! */ @Incoming(\"consume-and-ack\") @Acknowledgment(Acknowledgment.Strategy.POST_PROCESSING) public CompletionStage&lt;Void&gt; receiveAndAckMessage(Message&lt;String&gt; msg) { System.out.println(\"Method invocation!\"); return CompletableFuture.completedFuture(null); } ",
            "title": "Acknowledgement"
        },
        {
            "location": "mp/reactivemessaging/introduction",
            "text": " Messaging in Helidon has built in health probes for liveness and readiness. To activate it add the health check dependency . Liveness - channel is considered UP until cancel or onError signal is intercepted on it. Readiness - channel is considered DOWN until onSubscribe signal is intercepted on it. If you check your health endpoints /health/live and /health/ready you will discover every messaging channel to have its own probe. <markup lang=\"json\" >{ \"name\": \"messaging\", \"state\": \"UP\", \"status\": \"UP\", \"data\": { \"my-channel-1\": \"UP\", \"my-channel-2\": \"UP\" } } Caution: Due to the nack support are exceptions thrown in messaging methods NOT translated to error and cancel signals implicitly anymore ",
            "title": "Health check"
        },
        {
            "location": "mp/reactivemessaging/introduction",
            "text": " The channel must be configured to use connector as its upstream or downstream. <markup lang=\"yaml\" title=\"Example of channel to connector mapping config:\" >mp.messaging.outgoing.to-connector-channel.connector: example-connector mp.messaging.incoming.from-connector-channel.connector: example-connector Use connector example-connector as a downstream for channel to-connector-channel to consume the messages from the channel Use connector example-connector as an upstream for channel to-connector-channel to produce messages to the channel <markup lang=\"java\" title=\"Example producing to connector:\" >@Outgoing(\"to-connector-channel\") public Publisher&lt;String&gt; produce() { return Flowable.just(\"fee\", \"fie\"); } &gt; Connector says: fee &gt; Connector says: fie <markup lang=\"java\" title=\"Example consuming from connector:\" >@Incoming(\"from-connector-channel\") public void consume(String value) { System.out.println(\"Consuming: \" + value); } &gt; Consuming: foo &gt; Consuming: bar When the connector constructs a publisher or subscriber for a given channel, it can access general connector configuration and channel-specific properties merged together with special synthetic property channel-name . Connector specific config (1) merged together with global connector config (2). <markup lang=\"java\" title=\"Example connector accessing configuration:\" >@ApplicationScoped @Connector(\"example-connector\") public class ExampleConnector implements IncomingConnectorFactory { @Override public PublisherBuilder&lt;? extends Message&lt;?&gt;&gt; getPublisherBuilder(final Config config) { String firstPropValue = config.getValue(\"channel-specific-prop\", String.class); String secondPropValue = config.getValue(\"connector-specific-prop\", String.class); String secondPropValue = config.getValue(\"channel-name\", String.class); return ReactiveStreams.of(firstPropValue, secondPropValue) .map(Message::of); } } Config context is merged from channel and connector contexts Name of the channel requesting publisher as it&#8217;s upstream from this connector <markup lang=\"yaml\" title=\"Example of channel to connector mapping config with custom properties:\" >mp.messaging.incoming.from-connector-channel.connector: example-connector mp.messaging.incoming.from-connector-channel.channel-specific-prop: foo mp.messaging.connector.example-connector.connector-specific-prop: bar Channel &#8594; Connector mapping Channel configuration properties Connector configuration properties <markup lang=\"java\" title=\"Example consuming from connector:\" >@Incoming(\"from-connector-channel\") public void consume(String value) { System.out.println(\"Consuming: \" + value); } &gt; Consuming: foo &gt; Consuming: bar Message The Reactive Messaging Message class can be used to wrap or unwrap data items between methods and connectors. The message wrapping and unwrapping can be performed explicitly by using org.eclipse.microprofile.reactive.messaging.Message#of(T) or implicitly through the messaging core. <markup lang=\"java\" title=\"Example of explicit and implicit wrapping and unwrapping\" >@Outgoing(\"publisher-payload\") public PublisherBuilder&lt;Integer&gt; streamOfMessages() { return ReactiveStreams.of(0, 1, 2, 3, 4, 5, 6, 7, 8, 9); } @Incoming(\"publisher-payload\") @Outgoing(\"wrapped-message\") public Message&lt;String&gt; rewrapMessageManually(Message&lt;Integer&gt; message) { return Message.of(Integer.toString(message.getPayload())); } @Incoming(\"wrapped-message\") public void consumeImplicitlyUnwrappedMessage(String value) { System.out.println(\"Consuming message: \" + value); } Acknowledgement Messages carry a callback for reception acknowledgement (ack) and negative acknowledgement (nack). An acknowledgement in messaging methods is possible manually by org.eclipse.microprofile.reactive.messaging.Message#ack or automatically according explicit or implicit acknowledgement strategy by the messaging core. Explicit strategy configuration is possible with @Acknowledgment annotation which has one required attribute value that expects the strategy type from enum org.eclipse.microprofile.reactive.messaging.Acknowledgment.Strategy . More information about supported signatures and implicit automatic acknowledgement can be found in specification Message acknowledgement . Acknowledgement strategies @Acknowledgment(Acknowledgment.Strategy.NONE) No acknowledgment @Acknowledgment(Acknowledgment.Strategy.MANUAL) No automatic acknowledgment @Acknowledgment(Acknowledgment.Strategy.PRE_PROCESSING) Ack automatically before method invocation or processing @Acknowledgment(Acknowledgment.Strategy.POST_PROCESSING) Ack automatically after method invocation or processing <markup lang=\"java\" title=\"Example of manual acknowledgment\" >@Outgoing(\"consume-and-ack\") public PublisherBuilder&lt;Integer&gt; streamOfMessages() { return ReactiveStreams.of(Message.of(\"This is Payload\", () -&gt; { System.out.println(\"This particular message was acked!\"); return CompletableFuture.completedFuture(null); })).buildRs(); } @Incoming(\"consume-and-ack\") @Acknowledgment(Acknowledgment.Strategy.MANUAL) public CompletionStage&lt;Void&gt; receiveAndAckMessage(Message&lt;String&gt; msg) { return msg.ack(); } Calling ack() will print \"This particular message was acked!\" to System.out <markup lang=\"java\" title=\"Example of manual acknowledgment\" >@Outgoing(\"consume-and-ack\") public PublisherBuilder&lt;Integer&gt; streamOfMessages() { return ReactiveStreams.of(Message.of(\"This is Payload\", () -&gt; { System.out.println(\"This particular message was acked!\"); return CompletableFuture.completedFuture(null); })).buildRs(); } @Incoming(\"consume-and-ack\") @Acknowledgment(Acknowledgment.Strategy.MANUAL) public CompletionStage&lt;Void&gt; receiveAndAckMessage(Message&lt;String&gt; msg) { return msg.ack(); } Calling ack() will print \"This particular message was acked!\" to System.out <markup lang=\"java\" title=\"Example of explicit pre-process acknowledgment\" >@Outgoing(\"consume-and-ack\") public PublisherBuilder&lt;Integer&gt; streamOfMessages() { return ReactiveStreams.of(Message.of(\"This is Payload\", () -&gt; { System.out.println(\"This particular message was acked!\"); return CompletableFuture.completedFuture(null); })).buildRs(); } /** * Prints to the console: * &gt; This particular message was acked! * &gt; Method invocation! */ @Incoming(\"consume-and-ack\") @Acknowledgment(Acknowledgment.Strategy.PRE_PROCESSING) public CompletionStage&lt;Void&gt; receiveAndAckMessage(Message&lt;String&gt; msg) { System.out.println(\"Method invocation!\"); return CompletableFuture.completedFuture(null); } <markup lang=\"java\" title=\"Example of explicit post-process acknowledgment\" >@Outgoing(\"consume-and-ack\") public PublisherBuilder&lt;Integer&gt; streamOfMessages() { return ReactiveStreams.of(Message.of(\"This is Payload\", () -&gt; { System.out.println(\"This particular message was acked!\"); return CompletableFuture.completedFuture(null); })).buildRs(); } /** * Prints to the console: * &gt; Method invocation! * &gt; This particular message was acked! */ @Incoming(\"consume-and-ack\") @Acknowledgment(Acknowledgment.Strategy.POST_PROCESSING) public CompletionStage&lt;Void&gt; receiveAndAckMessage(Message&lt;String&gt; msg) { System.out.println(\"Method invocation!\"); return CompletableFuture.completedFuture(null); } Health check Messaging in Helidon has built in health probes for liveness and readiness. To activate it add the health check dependency . Liveness - channel is considered UP until cancel or onError signal is intercepted on it. Readiness - channel is considered DOWN until onSubscribe signal is intercepted on it. If you check your health endpoints /health/live and /health/ready you will discover every messaging channel to have its own probe. <markup lang=\"json\" >{ \"name\": \"messaging\", \"state\": \"UP\", \"status\": \"UP\", \"data\": { \"my-channel-1\": \"UP\", \"my-channel-2\": \"UP\" } } Caution: Due to the nack support are exceptions thrown in messaging methods NOT translated to error and cancel signals implicitly anymore ",
            "title": "Configuration"
        },
        {
            "location": "mp/reactivemessaging/introduction",
            "text": " Helidon MicroProfile Reactive Messaging MicroProfile Reactive Messaging Specification MicroProfile Reactive Messaging on GitHub ",
            "title": "Reference"
        },
        {
            "location": "mp/reactivemessaging/introduction",
            "text": " Exceptions thrown in messaging methods are not propagated as error or cancel signals to the stream(use mp.messaging.helidon.propagate-errors=true for backward compatible mode) - errors are propagated only to the upstream by nack functionality. Default acknowledgement strategies changed for selected signatures(all with Message as a parameter or return type) - See the specification issue #97 ",
            "title": "Upgrading to Messaging 3.0"
        },
        {
            "location": "mp/reactivemessaging/introduction",
            "text": " Upgrading to Messaging 3.0 Exceptions thrown in messaging methods are not propagated as error or cancel signals to the stream(use mp.messaging.helidon.propagate-errors=true for backward compatible mode) - errors are propagated only to the upstream by nack functionality. Default acknowledgement strategies changed for selected signatures(all with Message as a parameter or return type) - See the specification issue #97 ",
            "title": "Additional Information"
        },
        {
            "location": "mp/reactivemessaging/jms",
            "text": " To enable JMS Connector add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.messaging.jms&lt;/groupId&gt; &lt;artifactId&gt;helidon-messaging-jms&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "mp/reactivemessaging/jms",
            "text": " Connector name: helidon-jms Attributes username User name used to connect JMS session password Password to connect JMS session type Possible values are: queue , topic destination Queue or topic name acknowledge-mode Possible values are: AUTO_ACKNOWLEDGE - session automatically acknowledges a client&#8217;s receipt of a message, CLIENT_ACKNOWLEDGE - receipt of a message is acknowledged only when Message.ack() is called manually, DUPS_OK_ACKNOWLEDGE - session lazily acknowledges the delivery of messages. Default value: AUTO_ACKNOWLEDGE transacted Indicates whether the session will use a local transaction. Default value: false message-selector JMS API message selector expression based on a subset of the SQL92. Expression can only access headers and properties, not the payload. client-id Client identifier for JMS connection. durable True for creating durable consumer (only for topic). Default value: false subscriber-name Subscriber name for durable consumer used to identify subscription. non-local If true then any messages published to the topic using this session&#8217;s connection, or any other connection with the same client identifier, will not be added to the durable subscription. Default value: false named-factory Select in case factory is injected as a named bean or configured with name. poll-timeout Timeout for polling for next message in every poll cycle in millis. Default value: 50 period-executions Period for executing poll cycles in millis. Default value: 100 session-group-id When multiple channels share same session-group-id , they share same JMS session and same JDBC connection as well. jndi.jms-factory JNDI name of JMS factory. jndi.env-properties Environment properties used for creating initial context java.naming.factory.initial , java.naming.provider.url &#8230;&#8203; producer.someproperty property with producer prefix is set to producer instance (for example WLS Unit-of-Order WLMessageProducer.setUnitOfOrder(\"unit-1\") can be configured as producer.unit-of-order=unit-1 ) ",
            "title": "Config"
        },
        {
            "location": "mp/reactivemessaging/jms",
            "text": " The simplest possible usage is looking up JMS ConnectionFactory in the naming context. <markup lang=\"yaml\" title=\"Example of connector config:\" >mp.messaging: incoming.from-jms: connector: helidon-jms destination: messaging-test-queue-1 type: queue outgoing.to-jms: connector: helidon-jms destination: messaging-test-queue-1 type: queue connector: helidon-jms: user: Gandalf password: mellon jndi: jms-factory: ConnectionFactory env-properties: java.naming: factory.initial: org.apache.activemq.jndi.ActiveMQInitialContextFactory provider.url: tcp://localhost:61616 ",
            "title": "Configured JMS factory"
        },
        {
            "location": "mp/reactivemessaging/jms",
            "text": " In case you need more advanced setup, connector can work with injected factory instance. <markup lang=\"java\" title=\"Inject:\" > @Produces @ApplicationScoped @Named(\"active-mq-factory\") public ConnectionFactory connectionFactory() { return new ActiveMQConnectionFactory(config.get(\"jms.url\").asString().get()); } <markup lang=\"yaml\" title=\"Config:\" >jms: url: tcp://127.0.0.1:61616 mp: messaging: connector: helidon-jms: named-factory: active-mq-factory outgoing.to-jms: connector: helidon-jms session-group-id: order-connection-1 destination: TESTQUEUE type: queue incoming.from-jms: connector: helidon-jms session-group-id: order-connection-1 destination: TESTQUEUE type: queue ",
            "title": "Injected JMS factory"
        },
        {
            "location": "mp/reactivemessaging/jms",
            "text": "<markup lang=\"java\" title=\"Consuming one by one unwrapped value:\" >@Incoming(\"from-jms\") public void consumeJms(String msg) { System.out.println(\"JMS says: \" + msg); } <markup lang=\"java\" title=\"Consuming one by one, manual ack:\" >@Incoming(\"from-jms\") @Acknowledgment(Acknowledgment.Strategy.MANUAL) public CompletionStage&lt;?&gt; consumeJms(JmsMessage&lt;String&gt; msg) { System.out.println(\"JMS says: \" + msg.getPayload()); return msg.ack(); } ",
            "title": "Consuming"
        },
        {
            "location": "mp/reactivemessaging/jms",
            "text": "<markup lang=\"java\" title=\"Example of producing to JMS:\" >@Outgoing(\"to-jms\") public PublisherBuilder&lt;String&gt; produceToJms() { return ReactiveStreams.of(\"test1\", \"test2\"); } <markup lang=\"java\" title=\"Example of more advanced producing to JMS:\" >@Outgoing(\"to-jms\") public PublisherBuilder&lt;String&gt; produceToJms() { return ReactiveStreams.of(\"test1\", \"test2\") .map(s -&gt; JmsMessage.builder(s) .correlationId(UUID.randomUUID().toString()) .property(\"stringProp\", \"cool property\") .property(\"byteProp\", 4) .property(\"intProp\", 5) .onAck(() -&gt; System.out.println(\"Acked!\")) .build()); } <markup lang=\"java\" title=\"Example of even more advanced producing to JMS with custom mapper:\" >@Outgoing(\"to-jms\") public PublisherBuilder&lt;String&gt; produceToJms() { return ReactiveStreams.of(\"test1\", \"test2\") .map(s -&gt; JmsMessage.builder(s) .customMapper((p, session) -&gt; { TextMessage textMessage = session.createTextMessage(p); textMessage.setStringProperty(\"custom-mapped-property\", \"XXX\" + p); return textMessage; }) .build() ); } ",
            "title": "Producing"
        },
        {
            "location": "mp/reactivemessaging/jms",
            "text": " Connecting streams to JMS with Reactive Messaging couldn&#8217;t be easier. Config Connector name: helidon-jms Attributes username User name used to connect JMS session password Password to connect JMS session type Possible values are: queue , topic destination Queue or topic name acknowledge-mode Possible values are: AUTO_ACKNOWLEDGE - session automatically acknowledges a client&#8217;s receipt of a message, CLIENT_ACKNOWLEDGE - receipt of a message is acknowledged only when Message.ack() is called manually, DUPS_OK_ACKNOWLEDGE - session lazily acknowledges the delivery of messages. Default value: AUTO_ACKNOWLEDGE transacted Indicates whether the session will use a local transaction. Default value: false message-selector JMS API message selector expression based on a subset of the SQL92. Expression can only access headers and properties, not the payload. client-id Client identifier for JMS connection. durable True for creating durable consumer (only for topic). Default value: false subscriber-name Subscriber name for durable consumer used to identify subscription. non-local If true then any messages published to the topic using this session&#8217;s connection, or any other connection with the same client identifier, will not be added to the durable subscription. Default value: false named-factory Select in case factory is injected as a named bean or configured with name. poll-timeout Timeout for polling for next message in every poll cycle in millis. Default value: 50 period-executions Period for executing poll cycles in millis. Default value: 100 session-group-id When multiple channels share same session-group-id , they share same JMS session and same JDBC connection as well. jndi.jms-factory JNDI name of JMS factory. jndi.env-properties Environment properties used for creating initial context java.naming.factory.initial , java.naming.provider.url &#8230;&#8203; producer.someproperty property with producer prefix is set to producer instance (for example WLS Unit-of-Order WLMessageProducer.setUnitOfOrder(\"unit-1\") can be configured as producer.unit-of-order=unit-1 ) Configured JMS factory The simplest possible usage is looking up JMS ConnectionFactory in the naming context. <markup lang=\"yaml\" title=\"Example of connector config:\" >mp.messaging: incoming.from-jms: connector: helidon-jms destination: messaging-test-queue-1 type: queue outgoing.to-jms: connector: helidon-jms destination: messaging-test-queue-1 type: queue connector: helidon-jms: user: Gandalf password: mellon jndi: jms-factory: ConnectionFactory env-properties: java.naming: factory.initial: org.apache.activemq.jndi.ActiveMQInitialContextFactory provider.url: tcp://localhost:61616 Injected JMS factory In case you need more advanced setup, connector can work with injected factory instance. <markup lang=\"java\" title=\"Inject:\" > @Produces @ApplicationScoped @Named(\"active-mq-factory\") public ConnectionFactory connectionFactory() { return new ActiveMQConnectionFactory(config.get(\"jms.url\").asString().get()); } <markup lang=\"yaml\" title=\"Config:\" >jms: url: tcp://127.0.0.1:61616 mp: messaging: connector: helidon-jms: named-factory: active-mq-factory outgoing.to-jms: connector: helidon-jms session-group-id: order-connection-1 destination: TESTQUEUE type: queue incoming.from-jms: connector: helidon-jms session-group-id: order-connection-1 destination: TESTQUEUE type: queue Consuming <markup lang=\"java\" title=\"Consuming one by one unwrapped value:\" >@Incoming(\"from-jms\") public void consumeJms(String msg) { System.out.println(\"JMS says: \" + msg); } <markup lang=\"java\" title=\"Consuming one by one, manual ack:\" >@Incoming(\"from-jms\") @Acknowledgment(Acknowledgment.Strategy.MANUAL) public CompletionStage&lt;?&gt; consumeJms(JmsMessage&lt;String&gt; msg) { System.out.println(\"JMS says: \" + msg.getPayload()); return msg.ack(); } Producing <markup lang=\"java\" title=\"Example of producing to JMS:\" >@Outgoing(\"to-jms\") public PublisherBuilder&lt;String&gt; produceToJms() { return ReactiveStreams.of(\"test1\", \"test2\"); } <markup lang=\"java\" title=\"Example of more advanced producing to JMS:\" >@Outgoing(\"to-jms\") public PublisherBuilder&lt;String&gt; produceToJms() { return ReactiveStreams.of(\"test1\", \"test2\") .map(s -&gt; JmsMessage.builder(s) .correlationId(UUID.randomUUID().toString()) .property(\"stringProp\", \"cool property\") .property(\"byteProp\", 4) .property(\"intProp\", 5) .onAck(() -&gt; System.out.println(\"Acked!\")) .build()); } <markup lang=\"java\" title=\"Example of even more advanced producing to JMS with custom mapper:\" >@Outgoing(\"to-jms\") public PublisherBuilder&lt;String&gt; produceToJms() { return ReactiveStreams.of(\"test1\", \"test2\") .map(s -&gt; JmsMessage.builder(s) .customMapper((p, session) -&gt; { TextMessage textMessage = session.createTextMessage(p); textMessage.setStringProperty(\"custom-mapped-property\", \"XXX\" + p); return textMessage; }) .build() ); } ",
            "title": "Reactive JMS Connector"
        },
        {
            "location": "mp/reactivemessaging/kafka",
            "text": " Overview Maven Coordinates NACK Strategy Examples ",
            "title": "Contents"
        },
        {
            "location": "mp/reactivemessaging/kafka",
            "text": " To enable Reactive Kafka Connector add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.messaging.kafka&lt;/groupId&gt; &lt;artifactId&gt;helidon-messaging-kafka&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "mp/reactivemessaging/kafka",
            "text": " Connecting streams to Kafka with Reactive Messaging is easy to do. There is a standard Kafka client behind the scenes, all the producer and consumer configs can be propagated through messaging config. <markup lang=\"yaml\" title=\"Example of connector config:\" >mp.messaging: incoming.from-kafka: connector: helidon-kafka topic: messaging-test-topic-1 auto.offset.reset: latest enable.auto.commit: true group.id: example-group-id outgoing.to-kafka: connector: helidon-kafka topic: messaging-test-topic-1 connector: helidon-kafka: bootstrap.servers: localhost:9092 key.serializer: org.apache.kafka.common.serialization.StringSerializer value.serializer: org.apache.kafka.common.serialization.StringSerializer key.deserializer: org.apache.kafka.common.serialization.StringDeserializer value.deserializer: org.apache.kafka.common.serialization.StringDeserializer Kafka client consumer&#8217;s property auto.offset.reset configuration for from-kafka channel only Kafka client&#8217;s property bootstrap.servers configuration for all channels using the connector <markup lang=\"java\" title=\"Example of consuming from Kafka:\" >@Incoming(\"from-kafka\") public void consumeKafka(String msg) { System.out.println(\"Kafka says: \" + msg); } <markup lang=\"java\" title=\"Example of producing to Kafka:\" >@Outgoing(\"to-kafka\") public PublisherBuilder&lt;String&gt; produceToKafka() { return ReactiveStreams.of(\"test1\", \"test2\"); } ",
            "title": "Overview"
        },
        {
            "location": "mp/reactivemessaging/kafka",
            "text": " Default NACK strategy for Kafka connector. When ",
            "title": "Kill channel"
        },
        {
            "location": "mp/reactivemessaging/kafka",
            "text": " Sends nacked messages to error topic, DLQ is well known pattern for dealing with unprocessed messages. Helidon can derive connection settings for DLQ topic automatically if the error topic is present on the same Kafka cluster. Serializers are derived from deserializers used for consumption org.apache.kafka.common.serialization.StringDeserializer &gt; org.apache.kafka.common.serialization.StringSerializer . Note that the name of the error topic is needed only in this case. <markup lang=\"yaml\" title=\"Example of derived DLQ config:\" >mp.messaging: incoming: my-channel: nack-dlq: dql_topic_name If a custom connection is needed, then use the 'nack-dlq' key for all of the producer configuration. <markup lang=\"yaml\" title=\"Example of custom DLQ config:\" >mp.messaging: incoming: my-channel: nack-dlq: topic: dql_topic_name bootstrap.servers: localhost:9092 key.serializer: org.apache.kafka.common.serialization.StringSerializer value.serializer: org.apache.kafka.common.serialization.StringSerializer ",
            "title": "Dead Letter Queue"
        },
        {
            "location": "mp/reactivemessaging/kafka",
            "text": " Only logs nacked messages and throws them away, offset is committed and channel continues normally consuming subsequent messages. <markup lang=\"yaml\" title=\"Example of log only enabled nack strategy\" >mp.messaging: incoming: my-channel: nack-log-only: true ",
            "title": "Log only"
        },
        {
            "location": "mp/reactivemessaging/kafka",
            "text": " Strategy Description Kill channel Nacked message sends error signal and causes channel failure so Messaging Health check can report it as DOWN DLQ Nacked messages are sent to specified dead-letter-queue Log only Nacked message is logged and channel continues normally Kill channel Default NACK strategy for Kafka connector. When Dead Letter Queue Sends nacked messages to error topic, DLQ is well known pattern for dealing with unprocessed messages. Helidon can derive connection settings for DLQ topic automatically if the error topic is present on the same Kafka cluster. Serializers are derived from deserializers used for consumption org.apache.kafka.common.serialization.StringDeserializer &gt; org.apache.kafka.common.serialization.StringSerializer . Note that the name of the error topic is needed only in this case. <markup lang=\"yaml\" title=\"Example of derived DLQ config:\" >mp.messaging: incoming: my-channel: nack-dlq: dql_topic_name If a custom connection is needed, then use the 'nack-dlq' key for all of the producer configuration. <markup lang=\"yaml\" title=\"Example of custom DLQ config:\" >mp.messaging: incoming: my-channel: nack-dlq: topic: dql_topic_name bootstrap.servers: localhost:9092 key.serializer: org.apache.kafka.common.serialization.StringSerializer value.serializer: org.apache.kafka.common.serialization.StringSerializer Log only Only logs nacked messages and throws them away, offset is committed and channel continues normally consuming subsequent messages. <markup lang=\"yaml\" title=\"Example of log only enabled nack strategy\" >mp.messaging: incoming: my-channel: nack-log-only: true ",
            "title": "NACK Strategy"
        },
        {
            "location": "mp/reactivemessaging/kafka",
            "text": " Don&#8217;t forget to check out the examples with pre-configured Kafka docker image, for easy testing: https://github.com/oracle/helidon/tree/master/examples/messaging ",
            "title": "Examples"
        },
        {
            "location": "mp/reactivemessaging/mock",
            "text": " Overview Usage Configuration Helidon Test ",
            "title": "Contents"
        },
        {
            "location": "mp/reactivemessaging/mock",
            "text": " Mock connector is a simple application scoped bean that can be used for emitting to a channel or asserting received data in a test environment. All data received are kept in memory only. ",
            "title": "Overview"
        },
        {
            "location": "mp/reactivemessaging/mock",
            "text": " To enable Mock Connector add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.messaging.mock&lt;/groupId&gt; &lt;artifactId&gt;helidon-messaging-mock&lt;/artifactId&gt; &lt;/dependency&gt; Mock connector should be used in the test environment only! For injecting Mock Connector use @TestConnector qualifier: <markup lang=\"java\" >@Inject @TestConnector MockConnector mockConnector; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "mp/reactivemessaging/mock",
            "text": "<markup lang=\"java\" title=\"Emitting String values a , b , c \" >mockConnector .incoming(\"my-incoming-channel\", String.class) .emit(\"a\", \"b\", \"c\"); Get incoming channel of given name and payload type ",
            "title": "Emitting Data"
        },
        {
            "location": "mp/reactivemessaging/mock",
            "text": "<markup lang=\"java\" title=\"Awaiting and asserting payloads with custom mapper\" >mockConnector .outgoing(\"my-outgoing-channel\", String.class) .awaitData(TIMEOUT, Message::getPayload, \"a\", \"b\", \"c\"); Get outgoing channel of given name and payload type Request number of expected items and block the thread until items arrive then assert the payloads ",
            "title": "Asserting Data"
        },
        {
            "location": "mp/reactivemessaging/mock",
            "text": " Key Default value Description mock-data Initial data emitted to the channel immediately after subscription mock-data-type java.lang.String Type of the emitted initial data to be emitted ",
            "title": "Configuration"
        },
        {
            "location": "mp/reactivemessaging/mock",
            "text": " Emitting Data Asserting Data Emitting Data <markup lang=\"java\" title=\"Emitting String values a , b , c \" >mockConnector .incoming(\"my-incoming-channel\", String.class) .emit(\"a\", \"b\", \"c\"); Get incoming channel of given name and payload type Asserting Data <markup lang=\"java\" title=\"Awaiting and asserting payloads with custom mapper\" >mockConnector .outgoing(\"my-outgoing-channel\", String.class) .awaitData(TIMEOUT, Message::getPayload, \"a\", \"b\", \"c\"); Get outgoing channel of given name and payload type Request number of expected items and block the thread until items arrive then assert the payloads Configuration Key Default value Description mock-data Initial data emitted to the channel immediately after subscription mock-data-type java.lang.String Type of the emitted initial data to be emitted ",
            "title": "Usage"
        },
        {
            "location": "mp/reactivemessaging/mock",
            "text": " Mock connector works great with built-in Helidon test support for JUnit 5 or TestNG . As Helidon test support makes a bean out of your test, you can inject MockConnector directly into it. <markup lang=\"java\" >@HelidonTest @DisableDiscovery @AddBean(MockConnector.class) @AddExtension(MessagingCdiExtension.class) @AddConfig(key = \"mp.messaging.incoming.test-channel-in.connector\", value = MockConnector.CONNECTOR_NAME) @AddConfig(key = \"mp.messaging.incoming.test-channel-in.mock-data-type\", value = \"java.lang.Integer\") @AddConfig(key = \"mp.messaging.incoming.test-channel-in.mock-data\", value = \"6,7,8\") @AddConfig(key = \"mp.messaging.outgoing.test-channel-out.connector\", value = MockConnector.CONNECTOR_NAME) public class MessagingTest { private static final Duration TIMEOUT = Duration.ofSeconds(15); @Inject @TestConnector private MockConnector mockConnector; @Incoming(\"test-channel-in\") @Outgoing(\"test-channel-out\") int multiply(int payload) { return payload * 10; } @Test void testMultiplyChannel() { mockConnector.outgoing(\"test-channel-out\", Integer.TYPE) .awaitPayloads(TIMEOUT, 60, 70, 80); } } If you want to add all the beans manually Manually add MockConnector bean, so it is accessible by messaging for constructing the channels Messaging support in Helidon MP is provided by this CDI extension Instruct messaging to use mock-connector as an upstream for channel test-channel-in Generate mock data of java.lang.Integer , String is default Generate mock data Instruct messaging to use mock-connector as a downstream for channel test-channel-out Inject mock connector so we can access publishers and subscribers registered within the mock connector Messaging processing method connecting together channels test-channel-in and test-channel-out Actual JUnit 5 test method which is going to block the thread until 3 items are intercepted on test-channel-out channel&#8217;s downstream and assert those with expected values. ",
            "title": "Helidon Test with Mock Connector"
        },
        {
            "location": "mp/reactivestreams/engine",
            "text": " Overview Maven Coordinates Usage ",
            "title": "Contents"
        },
        {
            "location": "mp/reactivestreams/engine",
            "text": " Helidon has its own set of reactive operators that have no dependencies outside of the Helidon ecosystem. These operators can be used with java.util.concurrent.Flow based reactive streams. ",
            "title": "Overview"
        },
        {
            "location": "mp/reactivestreams/engine",
            "text": " To enable Reactive Engine add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.common&lt;/groupId&gt; &lt;artifactId&gt;helidon-common-reactive&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "mp/reactivestreams/engine",
            "text": " In the situations when part of the operator chain needs to be prepared in advance, compose and to operators are at hand. <markup lang=\"java\" title=\"Combining operator chains:\" >// Assembly of stream, nothing is streamed yet Multi&lt;String&gt; publisherStage = Multi.just(\"foo\", \"bar\") .map(String::trim); Function&lt;Multi&lt;T&gt;, Multi&lt;T&gt;&gt; processorStage = upstream -&gt; upstream.map(String::toUpperCase); // Execution of pre-prepared stream publisherStage .compose(processorStage) .map(s -&gt; \"Item received: \" + s) .forEach(System.out::println); &gt; Item received: FOO &gt; Item received: BAR ",
            "title": "Operator Chains Composition"
        },
        {
            "location": "mp/reactivestreams/engine",
            "text": " The stream processing operator chain can be easily constructed by io.helidon.common.reactive.Multi , or io.helidon.common.reactive.Single for streams with single value. <markup lang=\"java\" title=\"Example of Multi usage:\" >AtomicInteger sum = new AtomicInteger(); Multi.just(\"1\", \"2\", \"3\", \"4\", \"5\") .limit(3) .map(Integer::parseInt) .forEach(sum::addAndGet); System.out.println(\"Sum: \" + sum.get()); &gt; Sum: 6 <markup lang=\"java\" title=\"Example of Single usage:\" >Single.just(\"1\") .map(Integer::parseInt) .map(i -&gt; i + 5) .toStage() .whenComplete((i, t) -&gt; System.out.println(\"Result: \" + i)); &gt; Result: 6 Operators defer Call the given supplier function for each individual downstream Subscriber to return a Flow.Publisher to subscribe to. map Map this Multi instance to a new Multi of another type using the given Mapper . defaultIfEmpty Signals the default item if the upstream is empty. switchIfEmpty Switch to the other publisher if the upstream is empty. peek Invoke provided consumer for every item in stream. distinct Filter out all duplicates. filter Filter stream items with provided predicate. takeWhile Take the longest prefix of elements from this stream that satisfy the given predicate. As long as predicate returns true, items from upstream are sent to downstream, when predicate returns false stream is completed. dropWhile Drop the longest prefix of elements from this stream that satisfy the given predicate. As long as predicate returns true, items from upstream are NOT sent to downstream but being dropped, predicate is never called again after it returns false for the first time. limit Limit stream to allow only specified number of items to pass. skip Skip first n items, all the others are emitted. flatMap Transform each upstream item with the supplied function into a Flow.Publisher , subscribe to them and then flatten their items into a single sequence of items emitted to the downstream. flatMap Transform each upstream item with the supplied function and flatten the resulting Flow.Publisher to downstream while limiting the maximum number of concurrent inner `Flow.Publisher`s and their in-flight item count, optionally aggregating and delaying all errors until all sources terminate. flatMapCompletionStage Transform each upstream item with the supplied function and flatten the resulting CompletionStage results to downstream. flatMapIterable Transform each upstream item with the supplied function and flatten the resulting Iterable to the downstream. flatMapOptional Transform each upstream item with the supplied function and flatten the resulting Optional to the downstream as item if present. observeOn Re-emit the upstream&#8217;s signals to the downstream on the given executor&#8217;s thread using a default buffer size of 32 and errors skipping ahead of items. observeOn Re-emit the upstream&#8217;s signals to the downstream on the given executor&#8217;s thread. forEach Terminal stage, invokes provided consumer for every item in the stream. collectList Collect the items of this Multi instance into a Single of List . collect Collect the items of this Multi instance into a Single . collect Collect the items of this Multi into a collection provided via a Supplier and mutated by a BiConsumer callback. collectStream Collects up upstream items with the help of the callbacks of a java.util.stream.Collector . reduce Combine subsequent items via a callback function and emit the final value result as a Single. reduce Combine every upstream item with an accumulator value to produce a new accumulator value and emit the final accumulator value as a Single. first Get the first item of this Multi instance as a Single . from Wrap a CompletionStage into a Multi and signal its outcome non-blockingly. from Wrap a CompletionStage into a Multi and signal its outcome non-blockingly. from Create a Multi instance wrapped around the given publisher. from Create a Multi instance that publishes the given iterable. from Create a Multi instance that publishes the given Stream . just Create a Multi instance that publishes the given items to a single subscriber. just Create a Multi instance that publishes the given items to a single subscriber. singleton Create a Multi that emits a pre-existing item and then completes. error Create a Multi instance that reports the given exception to its subscriber(s). The exception is reported by invoking Subscriber#onError(java.lang.Throwable) when Publisher#subscribe(Subscriber) is called. empty Get a Multi instance that completes immediately. never Get a Multi instance that never completes. concat Concat streams to one. onTerminate Executes given java.lang.Runnable when any of signals onComplete, onCancel or onError is received. ifEmpty Executes given java.lang.Runnable when stream is finished without value(empty stream). onComplete Executes given java.lang.Runnable when onComplete signal is received. onError Executes the given java.util.function.Consumer when an onError signal is received. onCancel Executes given java.lang.Runnable when a cancel signal is received. takeUntil Relay upstream items until the other source signals an item or completes. range Emits a range of ever increasing integers. rangeLong Emits a range of ever increasing longs. timer Signal 0L and complete the sequence after the given time elapsed. interval Signal 0L, 1L and so on periodically to the downstream. interval Signal 0L after an initial delay, then 1L, 2L and so on periodically to the downstream. timeout Signals a TimeoutException if the upstream doesn&#8217;t signal the next item, error or completion within the specified time. timeout Switches to a fallback source if the upstream doesn&#8217;t signal the next item, error or completion within the specified time. onErrorResume java.util.function.Function providing one item to be submitted as onNext in case of onError signal is received. onErrorResumeWith Resume stream from supplied publisher if onError signal is intercepted. retry Retry a failing upstream at most the given number of times before giving up. retry Retry a failing upstream if the predicate returns true. retryWhen Retry a failing upstream when the given function returns a publisher that signals an item. Operator Chains Composition In the situations when part of the operator chain needs to be prepared in advance, compose and to operators are at hand. <markup lang=\"java\" title=\"Combining operator chains:\" >// Assembly of stream, nothing is streamed yet Multi&lt;String&gt; publisherStage = Multi.just(\"foo\", \"bar\") .map(String::trim); Function&lt;Multi&lt;T&gt;, Multi&lt;T&gt;&gt; processorStage = upstream -&gt; upstream.map(String::toUpperCase); // Execution of pre-prepared stream publisherStage .compose(processorStage) .map(s -&gt; \"Item received: \" + s) .forEach(System.out::println); &gt; Item received: FOO &gt; Item received: BAR ",
            "title": "Usage"
        },
        {
            "location": "mp/reactivestreams/rsoperators",
            "text": " Overview Maven Coordinates Usage Reference ",
            "title": "Contents"
        },
        {
            "location": "mp/reactivestreams/rsoperators",
            "text": " Helidon implements MicroProfile Reactive Streams Operators specification which defines reactive operators and provides a standartized tool for manipulation with Reactive Streams . You can use the Helidon supported reactive operators and tooling when you want to maintain source-level portability between different implementations of the MicroProfile specifications. ",
            "title": "Overview"
        },
        {
            "location": "mp/reactivestreams/rsoperators",
            "text": " To enable Reactive Streams either add a dependency on the helidon-microprofile bundle or add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.reactive-streams&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-reactive-streams&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "mp/reactivestreams/rsoperators",
            "text": " Graphs are pre-prepared stream builders with stages , which can be combined together to close graph with methods via and to . <markup lang=\"java\" title=\"Combining the graphs and running the stream:\" >// Assembly of stream, nothing is streamed yet PublisherBuilder&lt;String&gt; publisherStage = ReactiveStreams.of(\"foo\", \"bar\") .map(String::trim); ProcessorBuilder&lt;String, String&gt; processorStage = ReactiveStreams.&lt;String&gt;builder() .map(String::toUpperCase); SubscriberBuilder&lt;String, Void&gt; subscriberStage = ReactiveStreams.&lt;String&gt;builder() .map(s -&gt; \"Item received: \" + s) .forEach(System.out::println); // Execution of pre-prepared stream publisherStage .via(processorStage) .to(subscriberStage).run(); &gt; Item received: FOO &gt; Item received: BAR ",
            "title": "Graphs"
        },
        {
            "location": "mp/reactivestreams/rsoperators",
            "text": " The MicroProfile Reactive Streams Operators specification provides a set of operators within stages, as well as the builders used to prepare graphs of stages from which streams can be built. <markup lang=\"java\" title=\"Example of simple closed graph usage:\" >AtomicInteger sum = new AtomicInteger(); ReactiveStreams.of(\"1\", \"2\", \"3\", \"4\", \"5\") .limit(3) .map(Integer::parseInt) .forEach(sum::addAndGet) .run() .whenComplete((r, t) -&gt; System.out.println(\"Sum: \" + sum.get())); &gt; Sum: 6 Operators(Stages) fromIterable Create new PublisherBuilder from supplied Iterable of Create new PublisherBuilder emitting supplied elements ofNullable Empty stream if supplied item is null iterate Create infinite stream with every next item created by supplied operator from previous item generate Create infinite stream with every item created by invocation of supplier empty Create new PublisherBuilder emitting as a first thing complete signal failed Create new PublisherBuilder emitting as a first thing error signal concat Concat two streams coupled Two parallel streams sharing cancel, onError and onComplete signals limit Limit the size of the stream, when limit is reached completes peek Invoke consumer for every item passing this operator filter Drop item when expression result to false map Transform items flatMap Flatten supplied stream to current stream flatMapIterable Flatten supplied iterable to current stream flatMapCompletionStage Map elements to completion stage and wait for each to be completed, keeps the order flatMapRSPublisher Map elements to Publishers and flatten this sub streams to original stream takeWhile Let items pass until expression is true, first time its false completes dropWhile Drop items until expression is true, first time its false let everything pass skip Drop first n items distinct Let pass only distinct items via Connect supplied processor to current stream return supplied processor onError Invoke supplied consumer when onError signal received onErrorResume Emit one last supplied item when onError signal received onErrorResumeWith When onError signal received continue emitting from supplied publisher builder onErrorResumeWithRsPublisher When onError signal received continue emitting from supplied publisher onComplete Invoke supplied runnable when onComplete signal received onTerminate Invoke supplied runnable when onComplete or onError signal received ifEmpty Executes given java.lang.Runnable when stream is finished without value(empty stream). to Connect this stream to supplied subscriber toList Collect all intercepted items to List collect Collect all intercepted items with provided collector forEach Invoke supplied Consumer for each intercepted item ignore Ignore all onNext signals, wait for onComplete reduce Reduction with provided expression cancel Cancel stream immediately findFirst Return first intercepted element Graphs Graphs are pre-prepared stream builders with stages , which can be combined together to close graph with methods via and to . <markup lang=\"java\" title=\"Combining the graphs and running the stream:\" >// Assembly of stream, nothing is streamed yet PublisherBuilder&lt;String&gt; publisherStage = ReactiveStreams.of(\"foo\", \"bar\") .map(String::trim); ProcessorBuilder&lt;String, String&gt; processorStage = ReactiveStreams.&lt;String&gt;builder() .map(String::toUpperCase); SubscriberBuilder&lt;String, Void&gt; subscriberStage = ReactiveStreams.&lt;String&gt;builder() .map(s -&gt; \"Item received: \" + s) .forEach(System.out::println); // Execution of pre-prepared stream publisherStage .via(processorStage) .to(subscriberStage).run(); &gt; Item received: FOO &gt; Item received: BAR ",
            "title": "Usage"
        },
        {
            "location": "mp/reactivestreams/rsoperators",
            "text": " MicroProfile Reactive Streams Operators Specification MicroProfile Reactive Streams Operators JavaDoc MicroProfile Reactive Streams Operators on GitHub ",
            "title": "Reference"
        },
        {
            "location": "mp/restclient",
            "text": " Overview Maven Coordinates API Configuration Examples Reference ",
            "title": "Contents"
        },
        {
            "location": "mp/restclient",
            "text": " MicroProfile Rest Client adds the capability to invoke remote services by defining a Java interface with Jakarta REST (JAX-RS) annotations that resembles a server-side resource class. Helidon will automatically create a proxy class for the interface and map local proxy calls to remote REST calls. For more information, see Rest Client For MicroProfile Specification . ",
            "title": "Overview"
        },
        {
            "location": "mp/restclient",
            "text": " To enable MicroProfile Rest Client either add a dependency on the helidon-microprofile bundle or add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.rest-client&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-rest-client&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "mp/restclient",
            "text": " MicroProfile Rest Client can be created using a builder obtained from RestClientBuilder.newBuilder() . The builder provides methods to specify the client interface to be proxied as well as to configure additional details such as server URI, SSL context, connection timeouts, etc. Any method call on the resulting proxy object will be automatically translated into a remote call to the service using the provided configuration. <markup lang=\"java\" title=\"Example\" >SomeResource greetResource = RestClientBuilder.newBuilder() .baseUri(URI.create(\"http://localhost:8080/greet\")) .build(GreetRestClient.class); greetResource.getDefaultMessage(); The RestClientBuilder interface extends the Configurable interface from Jakarta REST (JAX-RS), enabling direct registration of providers such as filters, param converters, exception mappers, etc. <markup lang=\"java\" title=\"Example\" >SomeResource greetResource = RestClientBuilder.newBuilder() .baseUri(URI.create(\"http://localhost:8080\")) .register(GreetClientRequestFilter.class) .register(GreetClientExceptionMapper.class) .build(GreetRestClient.class); greetResource.getDefaultMessage(); ",
            "title": "Creating a New Client Using a Builder"
        },
        {
            "location": "mp/restclient",
            "text": " A client interface can be annotated with @RegisterRestClient to automatically register it with CDI. This annotation has a property called baseUri that can be used to define the base endpoint to be used by the client to access the service. <markup lang=\"java\" title=\"Example\" >@Path(\"/greet\") @RegisterRestClient(baseUri=\"http://localhost:8080\") public interface GreetRestClient { // ... } Any Jakarta REST (JAX-RS) providers for a client can be registered using the (repeatable) @RegisterProvider annotation on the interface as shown below. <markup lang=\"java\" title=\"Example\" >@Path(\"/greet\") @RegisterRestClient(baseUri=\"http://localhost:8080\") @RegisterProvider(GreetClientRequestFilter.class) @RegisterProvider(GreetClientExceptionMapper.class) public interface GreetRestClient { // ... } Once a client interface is annotated, it can be injected into any CDI bean. All properties in annotation RegisterRestClient can be overridden via configuration as described in Configuration options <markup lang=\"java\" title=\"Example\" >public class MyBean { @Inject @RestClient GreetRestClient client; void myMethod() { client.getMessage(\"Helidon\"); } } ",
            "title": "Creating a New Client Using CDI"
        },
        {
            "location": "mp/restclient",
            "text": " Class Description org.eclipse.microprofile.rest.client.RestClientBuilder Base builder instance. Contains configuration options and a build method that creates the actual client instance. Annotation Description @RegisterRestClient A marker annotation to register a client at runtime. This marker must be applied to any CDI managed clients. @RestClient RestClient qualifier which should be used on an CDI injection points. Creating a New Client Using a Builder MicroProfile Rest Client can be created using a builder obtained from RestClientBuilder.newBuilder() . The builder provides methods to specify the client interface to be proxied as well as to configure additional details such as server URI, SSL context, connection timeouts, etc. Any method call on the resulting proxy object will be automatically translated into a remote call to the service using the provided configuration. <markup lang=\"java\" title=\"Example\" >SomeResource greetResource = RestClientBuilder.newBuilder() .baseUri(URI.create(\"http://localhost:8080/greet\")) .build(GreetRestClient.class); greetResource.getDefaultMessage(); The RestClientBuilder interface extends the Configurable interface from Jakarta REST (JAX-RS), enabling direct registration of providers such as filters, param converters, exception mappers, etc. <markup lang=\"java\" title=\"Example\" >SomeResource greetResource = RestClientBuilder.newBuilder() .baseUri(URI.create(\"http://localhost:8080\")) .register(GreetClientRequestFilter.class) .register(GreetClientExceptionMapper.class) .build(GreetRestClient.class); greetResource.getDefaultMessage(); Creating a New Client Using CDI A client interface can be annotated with @RegisterRestClient to automatically register it with CDI. This annotation has a property called baseUri that can be used to define the base endpoint to be used by the client to access the service. <markup lang=\"java\" title=\"Example\" >@Path(\"/greet\") @RegisterRestClient(baseUri=\"http://localhost:8080\") public interface GreetRestClient { // ... } Any Jakarta REST (JAX-RS) providers for a client can be registered using the (repeatable) @RegisterProvider annotation on the interface as shown below. <markup lang=\"java\" title=\"Example\" >@Path(\"/greet\") @RegisterRestClient(baseUri=\"http://localhost:8080\") @RegisterProvider(GreetClientRequestFilter.class) @RegisterProvider(GreetClientExceptionMapper.class) public interface GreetRestClient { // ... } Once a client interface is annotated, it can be injected into any CDI bean. All properties in annotation RegisterRestClient can be overridden via configuration as described in Configuration options <markup lang=\"java\" title=\"Example\" >public class MyBean { @Inject @RestClient GreetRestClient client; void myMethod() { client.getMessage(\"Helidon\"); } } ",
            "title": "API"
        },
        {
            "location": "mp/restclient",
            "text": " Required configuration options: key type default value description $restClient/mp-rest/url string &#160; Sets the base URL to use for this service. This option or /mp-rest/uri need to be set if the value is not present in RegisterRestClient#baseUri . $restClient/mp-rest/uri string &#160; Sets the base URI to use for this service. This option or /mp-rest/url need to be set if the value is not present in RegisterRestClient#baseUri . Optional configuration options: key type default value description $restClient/mp-rest/scope string jakarta.enterprise.context.Dependent The fully qualified classname to a CDI scope to use for injection. $restClient/mp-rest/connectTimeout long &#160; Sets timeout in milliseconds to wait to connect to the remote endpoint. $restClient/mp-rest/readTimeout long &#160; Sets timeout in milliseconds to wait for a response from the remote endpoint. $restClient/mp-rest/followRedirects boolean false Sets value used to determine whether the client should follow HTTP redirect responses. $restClient/mp-rest/proxyAddress string &#160; Sets a string value in the form of &lt;proxyHost&gt;:&lt;proxyPort&gt; that specifies the HTTP proxy server hostname (or IP address) and port for requests of this client to use. $restClient/mp-rest/queryParamStyle string (MULTI_PAIRS, COMMA_SEPARATED, ARRAY_PAIRS) MULTI_PAIRS Sets enumerated type string value that specifies the format in which multiple values for the same query parameter is used. $restClient/mp-rest/trustStore string &#160; Sets the trust store location. Can point to either a classpath resource (e.g. classpath:/client-truststore.jks) or a file (e.g. file:/home/user/client-truststore.jks). $restClient/mp-rest/trustStorePassword string &#160; Sets the password for the trust store. $restClient/mp-rest/trustStoreType string JKS Sets the type of the trust store. $restClient/mp-rest/keyStore string &#160; Sets the key store location. Can point to either a classpath resource (e.g. classpath:/client-keystore.jks) or a file (e.g. file:/home/user/client-keystore.jks). $restClient/mp-rest/keyStorePassword string &#160; Sets the password for the keystore. $restClient/mp-rest/keyStoreType string JKS Sets the type of the keystore. $restClient/mp-rest/hostnameVerifier string &#160; Sets the hostname verifier class. This class must have a public no-argument constructor. Configuration options affecting CDI and programmatically created clients: key type default value description $restClient/mp-rest/providers string &#160; A comma separated list of fully-qualified provider classnames to include in the client. $restClient/mp-rest/providers/&lt;fully-qualified-provider-classname&gt;/priority string &#160; Sets the priority of the provider for this interface. org.eclipse.microprofile.rest.client.propagateHeaders string &#160; To specify which headers to propagate from the inbound JAX-RS request to the outbound MP Rest Client request. Should not be prefixed with the rest client class or alias. microprofile.rest.client.disable.default.mapper boolean false Whether to disable default exception mapper. Should not be prefixed with the rest client class or alias. ",
            "title": "Configuration options"
        },
        {
            "location": "mp/restclient",
            "text": " Configuration is only available for CDI managed client instances, it is not supported for client created programmatically using RestClientBuilder . Most of the configuration properties mentioned below have to be prepended with the fully qualified classname of the client interface to be configured. It is possible to avoid fully qualified classname by using @RegisterRestClient(configKey=\"clientAlias\") , the prefix $restClient is used below to indicate an alias or a class name. Configuration options Required configuration options: key type default value description $restClient/mp-rest/url string &#160; Sets the base URL to use for this service. This option or /mp-rest/uri need to be set if the value is not present in RegisterRestClient#baseUri . $restClient/mp-rest/uri string &#160; Sets the base URI to use for this service. This option or /mp-rest/url need to be set if the value is not present in RegisterRestClient#baseUri . Optional configuration options: key type default value description $restClient/mp-rest/scope string jakarta.enterprise.context.Dependent The fully qualified classname to a CDI scope to use for injection. $restClient/mp-rest/connectTimeout long &#160; Sets timeout in milliseconds to wait to connect to the remote endpoint. $restClient/mp-rest/readTimeout long &#160; Sets timeout in milliseconds to wait for a response from the remote endpoint. $restClient/mp-rest/followRedirects boolean false Sets value used to determine whether the client should follow HTTP redirect responses. $restClient/mp-rest/proxyAddress string &#160; Sets a string value in the form of &lt;proxyHost&gt;:&lt;proxyPort&gt; that specifies the HTTP proxy server hostname (or IP address) and port for requests of this client to use. $restClient/mp-rest/queryParamStyle string (MULTI_PAIRS, COMMA_SEPARATED, ARRAY_PAIRS) MULTI_PAIRS Sets enumerated type string value that specifies the format in which multiple values for the same query parameter is used. $restClient/mp-rest/trustStore string &#160; Sets the trust store location. Can point to either a classpath resource (e.g. classpath:/client-truststore.jks) or a file (e.g. file:/home/user/client-truststore.jks). $restClient/mp-rest/trustStorePassword string &#160; Sets the password for the trust store. $restClient/mp-rest/trustStoreType string JKS Sets the type of the trust store. $restClient/mp-rest/keyStore string &#160; Sets the key store location. Can point to either a classpath resource (e.g. classpath:/client-keystore.jks) or a file (e.g. file:/home/user/client-keystore.jks). $restClient/mp-rest/keyStorePassword string &#160; Sets the password for the keystore. $restClient/mp-rest/keyStoreType string JKS Sets the type of the keystore. $restClient/mp-rest/hostnameVerifier string &#160; Sets the hostname verifier class. This class must have a public no-argument constructor. Configuration options affecting CDI and programmatically created clients: key type default value description $restClient/mp-rest/providers string &#160; A comma separated list of fully-qualified provider classnames to include in the client. $restClient/mp-rest/providers/&lt;fully-qualified-provider-classname&gt;/priority string &#160; Sets the priority of the provider for this interface. org.eclipse.microprofile.rest.client.propagateHeaders string &#160; To specify which headers to propagate from the inbound JAX-RS request to the outbound MP Rest Client request. Should not be prefixed with the rest client class or alias. microprofile.rest.client.disable.default.mapper boolean false Whether to disable default exception mapper. Should not be prefixed with the rest client class or alias. ",
            "title": "Configuration"
        },
        {
            "location": "mp/restclient",
            "text": " To be able to run and test this example, use the Helidon MP examples/quickstarts . Add a dependency on the Helidon Rest Client implementation and create the following client interface: <markup lang=\"java\" title=\"client interface\" >@Path(\"/greet\") interface GreetRestClient { @GET JsonObject getDefaultMessage(); @Path(\"/{name}\") @GET JsonObject getMessage(@PathParam(\"name\") String name); } Then create a runnable method as described in Creating new client , but with baseUri http://localhost:8080/greet and the above interface. By calling GreetRestClient.getDefaultMessage() you reach the endpoint of Helidon quickstart. ",
            "title": "Examples"
        },
        {
            "location": "mp/restclient",
            "text": " Helidon MicroProfile RestClient JavaDoc MicroProfile RestClient Specification MicroProfile RestClient on GitHub ",
            "title": "Reference"
        },
        {
            "location": "mp/scheduling",
            "text": " Overview Maven Coordinates Usage Configuration Examples Reference ",
            "title": "Contents"
        },
        {
            "location": "mp/scheduling",
            "text": " Scheduling is an essential feature for the Enterprise. Helidon has its own implementation of Scheduling functionality based on Cron-utils . ",
            "title": "Overview"
        },
        {
            "location": "mp/scheduling",
            "text": " To enable Scheduling add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.scheduling&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-scheduling&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "mp/scheduling",
            "text": " For simple fixed rate invocation interval is @FixedRate the easiest way for scheduling task invocation. <markup lang=\"java\" >@FixedRate(initialDelay = 5, value = 10, timeUnit = TimeUnit.MINUTES) All values defined with the annotation can be overridden from the config. <markup lang=\"yaml\" title=\"Overriding annotated values from config\" >fully.qualified.ClassName.methodName: schedule: initial-delay: 5 delay: 15 time-unit: HOURS Metadata like human-readable interval description or configured values are available through FixedRateInvocation injected as method parameter. <markup lang=\"java\" >@FixedRate(initialDelay = 5, value = 10, timeUnit = TimeUnit.MINUTES) ",
            "title": "Fixed rate"
        },
        {
            "location": "mp/scheduling",
            "text": " For more complicated interval definition, cron expression can be leveraged with @Schedule annotation. <markup lang=\"java\" >@Scheduled(\"0 15 8 ? * *\", concurrentExecution = false) public void methodName() { ... } ",
            "title": "Cron expression"
        },
        {
            "location": "mp/scheduling",
            "text": "<markup title=\"Cron expression format\" >&lt;seconds&gt; &lt;minutes&gt; &lt;hours&gt; &lt;day-of-month&gt; &lt;month&gt; &lt;day-of-week&gt; &lt;year&gt; Cron expression fields Order Name Supported values Supported field format Optional 1 seconds 0-59 CONST, LIST, RANGE, WILDCARD, INCREMENT false 2 minutes 0-59 CONST, LIST, RANGE, WILDCARD, INCREMENT false 3 hours 0-23 CONST, LIST, RANGE, WILDCARD, INCREMENT false 4 day-of-month 1-31 CONST, LIST, RANGE, WILDCARD, INCREMENT, ANY, LAST, WEEKDAY false 5 month 1-12 or JAN-DEC CONST, LIST, RANGE, WILDCARD, INCREMENT false 6 day-of-week 1-7 or SUN-SAT CONST, LIST, RANGE, WILDCARD, INCREMENT, ANY, NTH, LAST false 7 year 1970-2099 CONST, LIST, RANGE, WILDCARD, INCREMENT true Field formats Name Regex format Example Description CONST \\d+ 12 exact value LIST \\d+,\\d+(,\\d+)* 1,2,3,4 list of constants RANGE \\d+-\\d+ 15-30 range of values from-to WILDCARD \\* * all values withing the field INCREMENT \\d+\\/\\d+ 0/5 inital number / increments, 2/5 means 2,7,9,11,16,&#8230;&#8203; ANY \\? ? any day(apply only to day-of-week and day-of-month) NTH \\# 1#3 nth day of the month, 2#3 means third monday of the month LAST \\d*L(+\\d+|\\-\\d+)? 3L-3 last day of the month in day-of-month or last nth day in the day-of-week WEEKDAY \\# 1#3 nearest weekday of the nth day of month, 1W is the first monday of the week Examples Cron expression Description * * * * * ? Every second 0/2 * * * * ? * Every 2 seconds 0 45 9 ? * * Every day at 9:45 0 15 8 ? * MON-FRI Every workday at 8:15 Metadata like human-readable interval description or configured values are available through CronInvocation injected as method parameter. <markup lang=\"java\" >@Scheduled(\"0 15 8 ? * *\") public void methodName(CronInvocation inv) { ... } ",
            "title": "Cron expression"
        },
        {
            "location": "mp/scheduling",
            "text": " For scheduling tasks in Helidon you can choose from @Scheduled or @FixedRate annotations by required complexity of invocation interval. All you need is define method with one of the annotations in application scoped bean. Fixed rate For simple fixed rate invocation interval is @FixedRate the easiest way for scheduling task invocation. <markup lang=\"java\" >@FixedRate(initialDelay = 5, value = 10, timeUnit = TimeUnit.MINUTES) All values defined with the annotation can be overridden from the config. <markup lang=\"yaml\" title=\"Overriding annotated values from config\" >fully.qualified.ClassName.methodName: schedule: initial-delay: 5 delay: 15 time-unit: HOURS Metadata like human-readable interval description or configured values are available through FixedRateInvocation injected as method parameter. <markup lang=\"java\" >@FixedRate(initialDelay = 5, value = 10, timeUnit = TimeUnit.MINUTES) Cron expression For more complicated interval definition, cron expression can be leveraged with @Schedule annotation. <markup lang=\"java\" >@Scheduled(\"0 15 8 ? * *\", concurrentExecution = false) public void methodName() { ... } Cron expression <markup title=\"Cron expression format\" >&lt;seconds&gt; &lt;minutes&gt; &lt;hours&gt; &lt;day-of-month&gt; &lt;month&gt; &lt;day-of-week&gt; &lt;year&gt; Cron expression fields Order Name Supported values Supported field format Optional 1 seconds 0-59 CONST, LIST, RANGE, WILDCARD, INCREMENT false 2 minutes 0-59 CONST, LIST, RANGE, WILDCARD, INCREMENT false 3 hours 0-23 CONST, LIST, RANGE, WILDCARD, INCREMENT false 4 day-of-month 1-31 CONST, LIST, RANGE, WILDCARD, INCREMENT, ANY, LAST, WEEKDAY false 5 month 1-12 or JAN-DEC CONST, LIST, RANGE, WILDCARD, INCREMENT false 6 day-of-week 1-7 or SUN-SAT CONST, LIST, RANGE, WILDCARD, INCREMENT, ANY, NTH, LAST false 7 year 1970-2099 CONST, LIST, RANGE, WILDCARD, INCREMENT true Field formats Name Regex format Example Description CONST \\d+ 12 exact value LIST \\d+,\\d+(,\\d+)* 1,2,3,4 list of constants RANGE \\d+-\\d+ 15-30 range of values from-to WILDCARD \\* * all values withing the field INCREMENT \\d+\\/\\d+ 0/5 inital number / increments, 2/5 means 2,7,9,11,16,&#8230;&#8203; ANY \\? ? any day(apply only to day-of-week and day-of-month) NTH \\# 1#3 nth day of the month, 2#3 means third monday of the month LAST \\d*L(+\\d+|\\-\\d+)? 3L-3 last day of the month in day-of-month or last nth day in the day-of-week WEEKDAY \\# 1#3 nearest weekday of the nth day of month, 1W is the first monday of the week Examples Cron expression Description * * * * * ? Every second 0/2 * * * * ? * Every 2 seconds 0 45 9 ? * * Every day at 9:45 0 15 8 ? * MON-FRI Every workday at 8:15 Metadata like human-readable interval description or configured values are available through CronInvocation injected as method parameter. <markup lang=\"java\" >@Scheduled(\"0 15 8 ? * *\") public void methodName(CronInvocation inv) { ... } ",
            "title": "Usage"
        },
        {
            "location": "mp/scheduling",
            "text": " Scheduled annotation properties can be overridden using application.yaml properties <markup lang=\"yaml\" title=\"Overriding annotated values from config\" >fully.qualified.ClassName.methodName: schedule: cron: \"* * * * * ?\" concurrent: false Configuration properties Property Description cron String containing cron setup concurrent Boolean, equivalent concurrentExecution property of @Scheduled . Default true . ",
            "title": "Configuration"
        },
        {
            "location": "mp/scheduling",
            "text": "<markup lang=\"java\" title=\"Example of scheduling with fixed rate\" >@FixedRate(initialDelay = 5, value = 10, timeUnit = TimeUnit.MINUTES) public void methodName() { System.out.println(\"Every 10 minutes, first invocation 5 minutes after start\"); } ",
            "title": "Fixed rate"
        },
        {
            "location": "mp/scheduling",
            "text": "<markup lang=\"java\" title=\"Example with invocation metadata\" >@FixedRate(initialDelay = 5, value = 10, timeUnit = TimeUnit.MINUTES) public void methodName(FixedRateInvocation inv) { System.out.println(\"Method invoked \" + inv.description()); } ",
            "title": "FixedRate Metadata Injection"
        },
        {
            "location": "mp/scheduling",
            "text": "<markup lang=\"java\" title=\"Example of scheduling with cron expression\" >@Scheduled(\"0 15 8 ? * *\", concurrentExecution = false) public void methodName() { System.out.println(\"Executer every day at 8:15\"); } ",
            "title": "Cron expression"
        },
        {
            "location": "mp/scheduling",
            "text": "<markup lang=\"java\" title=\"Example with invocation metadata\" >@Scheduled(\"0 15 8 ? * *\") public void methodName(CronInvocation inv) { System.out.println(\"Method invoked \" + inv.description()); } ",
            "title": "Scheduled Metadata Injection."
        },
        {
            "location": "mp/scheduling",
            "text": " Fixed rate <markup lang=\"java\" title=\"Example of scheduling with fixed rate\" >@FixedRate(initialDelay = 5, value = 10, timeUnit = TimeUnit.MINUTES) public void methodName() { System.out.println(\"Every 10 minutes, first invocation 5 minutes after start\"); } FixedRate Metadata Injection <markup lang=\"java\" title=\"Example with invocation metadata\" >@FixedRate(initialDelay = 5, value = 10, timeUnit = TimeUnit.MINUTES) public void methodName(FixedRateInvocation inv) { System.out.println(\"Method invoked \" + inv.description()); } Cron expression <markup lang=\"java\" title=\"Example of scheduling with cron expression\" >@Scheduled(\"0 15 8 ? * *\", concurrentExecution = false) public void methodName() { System.out.println(\"Executer every day at 8:15\"); } Scheduled Metadata Injection. <markup lang=\"java\" title=\"Example with invocation metadata\" >@Scheduled(\"0 15 8 ? * *\") public void methodName(CronInvocation inv) { System.out.println(\"Method invoked \" + inv.description()); } ",
            "title": "Examples"
        },
        {
            "location": "mp/scheduling",
            "text": " Cron-utils GitHub page Helidon Scheduling JavaDoc ",
            "title": "Reference"
        },
        {
            "location": "mp/security/configuration-secrets",
            "text": " When security requires a configuration with repeating complex elements, use Helidon Config. This example configures a basic authentication provider and protects static content on the web server. It also includes annotations in Jersey. ",
            "title": "preambule"
        },
        {
            "location": "mp/security/configuration-secrets",
            "text": " The config encryption filter has an option that defines whether encryption is required or not. If it&#8217;s set to true, which is the default, then: Configuration values with ${CLEAR=&#8230;&#8203;} template will cause an exception when requested. The filter fails during bootstrap if security.config.aes.insecure-passphrase is configured. ",
            "title": "Requiring encryption"
        },
        {
            "location": "mp/security/configuration-secrets",
            "text": " The config encryption filter provides a Main class io.helidon.config.encryption.Main that can be used to encrypt values. <markup lang=\"bash\" title=\"Encrypt secret secretToEncrypt using shared secret masterPassword \" >java -jar &lt;path-to-app-libs-dir&gt;/helidon-config-encryption-{helidon-version}.jar aes masterPassword secretToEncrypt The tool returns the string to be entered into configuration as the value of a property. ",
            "title": "Encrypting values (AES)"
        },
        {
            "location": "mp/security/configuration-secrets",
            "text": " You can provide a shared secret in a couple of ways: in configuration - for testing/demo purposes only - key is security.config.aes.insecure-passphrase as an environment variable - SECURE_CONFIG_AES_MASTER_PWD ",
            "title": "Shared Secret (AES)"
        },
        {
            "location": "mp/security/configuration-secrets",
            "text": " Symmetric encryption is based on a shared secret that is known by the person encrypting the value and is also provided to the application. Encrypting values (AES) The config encryption filter provides a Main class io.helidon.config.encryption.Main that can be used to encrypt values. <markup lang=\"bash\" title=\"Encrypt secret secretToEncrypt using shared secret masterPassword \" >java -jar &lt;path-to-app-libs-dir&gt;/helidon-config-encryption-{helidon-version}.jar aes masterPassword secretToEncrypt The tool returns the string to be entered into configuration as the value of a property. Shared Secret (AES) You can provide a shared secret in a couple of ways: in configuration - for testing/demo purposes only - key is security.config.aes.insecure-passphrase as an environment variable - SECURE_CONFIG_AES_MASTER_PWD ",
            "title": "Using symmetric encryption (AES)"
        },
        {
            "location": "mp/security/configuration-secrets",
            "text": " The config encryption filter provides a Main class io.helidon.config.encryption.Main that can be used to encrypt values. <markup lang=\"bash\" title=\"Encrypt secret secretToEncrypt using public certificate in a keystore\" >java -jar &lt;path-to-app-libs-dir&gt;/helidon-config-encryption-{helidon-version}.jar rsa /path/to/keystore.p12 keystorePassword publicCertAlias secretToEncrypt The tool returns the string to be entered into configuration as the value of a property. ",
            "title": "Encrypting values (RSA)"
        },
        {
            "location": "mp/security/configuration-secrets",
            "text": " You can configure the properties of a private key in a keystore. These keys are prefixed with security.config.rsa.keystore RSA Configuration Options: Keystore What Configuration Key Environment Variable Description Keystore path resource.path SECURE_CONFIG_RSA_PRIVATE_KEY Keystore is located in file system Keystore resource.resource-path N/A Keystore is located on classpath Private key alias key.alias SECURE_CONFIG_PRIVATE_KEY_ALIAS Alias of the private key (such as \"1\", which is usually the default) Keystore passphrase passphrase SECURE_CONFIG_PRIVATE_KEYSTORE_PASSPHRASE Password for the keystore (and private key). RSA Configuration Options: PEM (PKCS#8) private key What Configuration Key Environment Variable Description Path pem.key.resource.path SECURE_CONFIG_RSA_PEM_KEY Key is located on file system Resource path pem.key.resource.resource-path N/A Key is located on classpath Passphrase pem.key.passphrase SECURE_CONFIG_PRIVATE_KEY_PASSPHRASE Password protecting the private key <markup lang=\"yaml\" title=\"Example yaml configuration\" >security.config: # Set to true for production - if set to true, clear text passwords will cause failure require-encryption: false # The \"master\" password for AES decryption. For production, set this via system property or environment variable. aes.insecure-passphrase: \"myMasterPasswordForEncryption\" # See documentation of pki-util rsa: keystore: # load from classpath resource.resource-path: \".ssh/keystore.p12\" # If keystore is used, alias to use from the keystore (in this example, it is \"1\") key.alias: \"1\" # Password of keystore passphrase: \"helidon\" ",
            "title": "Configure config encryption filter (RSA)"
        },
        {
            "location": "mp/security/configuration-secrets",
            "text": " This approach is based on a pair of keys: a public key which is known to anybody, and a private key which is known to a limited set of parties (usually a single person or process). For asymmetric encryption, the following is true: a value encrypted by a public key can only be decrypted by the private key When using the config encryption filter, you should encrypt the configuration values using the public key, and give the application process access to the private key to decrypt the values. Encrypting values (RSA) The config encryption filter provides a Main class io.helidon.config.encryption.Main that can be used to encrypt values. <markup lang=\"bash\" title=\"Encrypt secret secretToEncrypt using public certificate in a keystore\" >java -jar &lt;path-to-app-libs-dir&gt;/helidon-config-encryption-{helidon-version}.jar rsa /path/to/keystore.p12 keystorePassword publicCertAlias secretToEncrypt The tool returns the string to be entered into configuration as the value of a property. Configure config encryption filter (RSA) You can configure the properties of a private key in a keystore. These keys are prefixed with security.config.rsa.keystore RSA Configuration Options: Keystore What Configuration Key Environment Variable Description Keystore path resource.path SECURE_CONFIG_RSA_PRIVATE_KEY Keystore is located in file system Keystore resource.resource-path N/A Keystore is located on classpath Private key alias key.alias SECURE_CONFIG_PRIVATE_KEY_ALIAS Alias of the private key (such as \"1\", which is usually the default) Keystore passphrase passphrase SECURE_CONFIG_PRIVATE_KEYSTORE_PASSPHRASE Password for the keystore (and private key). RSA Configuration Options: PEM (PKCS#8) private key What Configuration Key Environment Variable Description Path pem.key.resource.path SECURE_CONFIG_RSA_PEM_KEY Key is located on file system Resource path pem.key.resource.resource-path N/A Key is located on classpath Passphrase pem.key.passphrase SECURE_CONFIG_PRIVATE_KEY_PASSPHRASE Password protecting the private key <markup lang=\"yaml\" title=\"Example yaml configuration\" >security.config: # Set to true for production - if set to true, clear text passwords will cause failure require-encryption: false # The \"master\" password for AES decryption. For production, set this via system property or environment variable. aes.insecure-passphrase: \"myMasterPasswordForEncryption\" # See documentation of pki-util rsa: keystore: # load from classpath resource.resource-path: \".ssh/keystore.p12\" # If keystore is used, alias to use from the keystore (in this example, it is \"1\") key.alias: \"1\" # Password of keystore passphrase: \"helidon\" ",
            "title": "Using asymmetric encryption (RSA)"
        },
        {
            "location": "mp/security/configuration-secrets",
            "text": " In Helidon MP, the config encryption filter is enabled by default . However, if you don&#8217;t configure it, the filter only supports a template for aliasing that checks that no clear text passwords are present (template ${CLEAR=&#8230;&#8203;}. In Helidon SE, you may add support for this filter with dependency (loaded through a java service mechanism): <markup lang=\"xml\" title=\"Maven Dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.config&lt;/groupId&gt; &lt;artifactId&gt;helidon-config-encryption&lt;/artifactId&gt; &lt;/dependency&gt; Put encrypted values into your configuration file so that it can be stored in a public repository with no danger of exposing the secret values. Be sure to use a strong and secret password. The supported templates are: Templates Template Description Example ${CLEAR=&#8230;&#8203;} Secret in clear text (for testing) - requiresEncryption must be disabled ${CLEAR=knownSecret} ${RSA-P=&#8230;&#8203;} Public/private key encryption, base64 value ${RSA-P=aGr3sFCMQznixrgbIk9qNfoLnO1cdi3H86qweCNjxFvH4dYg5IQM1EuoyTjJaXcSCG5MBskpeA3bjnWYrzeAFFlZHuYSPsb+wJVzGLrfUColTn+BPJjpJ3rmEd3AVkJl1ASfBBMh3q3deC+rvUdhfoTGBO8sC0teUATklCQSxfHOnIxswxqrplnoGXToGiTIfehiN2IZNulRKeoDQ0AeoKREmq5au4L8OOmS+D9BqnlKMc0F1tULZ7+h3Cxla4lXC5WRPoPfHBU4vzRZOGzeDvLkRgrD60caw/wKn5M0Wy1A1cKR8E46ceBXCjJ2eWIcLyhZSAZWDe3ceNrawHZtCg==} ${GCM=&#8230;&#8203;} Shared secret ecryption, base64 value ${GCM=D/UgMzsNb265HU1NDvdzm7tACHdsW6u1PjYEcRkV/OLiWcI+ET6Q4MKCz0zHyEh9} Requiring encryption The config encryption filter has an option that defines whether encryption is required or not. If it&#8217;s set to true, which is the default, then: Configuration values with ${CLEAR=&#8230;&#8203;} template will cause an exception when requested. The filter fails during bootstrap if security.config.aes.insecure-passphrase is configured. Using symmetric encryption (AES) Symmetric encryption is based on a shared secret that is known by the person encrypting the value and is also provided to the application. Encrypting values (AES) The config encryption filter provides a Main class io.helidon.config.encryption.Main that can be used to encrypt values. <markup lang=\"bash\" title=\"Encrypt secret secretToEncrypt using shared secret masterPassword \" >java -jar &lt;path-to-app-libs-dir&gt;/helidon-config-encryption-{helidon-version}.jar aes masterPassword secretToEncrypt The tool returns the string to be entered into configuration as the value of a property. Shared Secret (AES) You can provide a shared secret in a couple of ways: in configuration - for testing/demo purposes only - key is security.config.aes.insecure-passphrase as an environment variable - SECURE_CONFIG_AES_MASTER_PWD Using asymmetric encryption (RSA) This approach is based on a pair of keys: a public key which is known to anybody, and a private key which is known to a limited set of parties (usually a single person or process). For asymmetric encryption, the following is true: a value encrypted by a public key can only be decrypted by the private key When using the config encryption filter, you should encrypt the configuration values using the public key, and give the application process access to the private key to decrypt the values. Encrypting values (RSA) The config encryption filter provides a Main class io.helidon.config.encryption.Main that can be used to encrypt values. <markup lang=\"bash\" title=\"Encrypt secret secretToEncrypt using public certificate in a keystore\" >java -jar &lt;path-to-app-libs-dir&gt;/helidon-config-encryption-{helidon-version}.jar rsa /path/to/keystore.p12 keystorePassword publicCertAlias secretToEncrypt The tool returns the string to be entered into configuration as the value of a property. Configure config encryption filter (RSA) You can configure the properties of a private key in a keystore. These keys are prefixed with security.config.rsa.keystore RSA Configuration Options: Keystore What Configuration Key Environment Variable Description Keystore path resource.path SECURE_CONFIG_RSA_PRIVATE_KEY Keystore is located in file system Keystore resource.resource-path N/A Keystore is located on classpath Private key alias key.alias SECURE_CONFIG_PRIVATE_KEY_ALIAS Alias of the private key (such as \"1\", which is usually the default) Keystore passphrase passphrase SECURE_CONFIG_PRIVATE_KEYSTORE_PASSPHRASE Password for the keystore (and private key). RSA Configuration Options: PEM (PKCS#8) private key What Configuration Key Environment Variable Description Path pem.key.resource.path SECURE_CONFIG_RSA_PEM_KEY Key is located on file system Resource path pem.key.resource.resource-path N/A Key is located on classpath Passphrase pem.key.passphrase SECURE_CONFIG_PRIVATE_KEY_PASSPHRASE Password protecting the private key <markup lang=\"yaml\" title=\"Example yaml configuration\" >security.config: # Set to true for production - if set to true, clear text passwords will cause failure require-encryption: false # The \"master\" password for AES decryption. For production, set this via system property or environment variable. aes.insecure-passphrase: \"myMasterPasswordForEncryption\" # See documentation of pki-util rsa: keystore: # load from classpath resource.resource-path: \".ssh/keystore.p12\" # If keystore is used, alias to use from the keystore (in this example, it is \"1\") key.alias: \"1\" # Password of keystore passphrase: \"helidon\" ",
            "title": "Protecting Configuration Secrets"
        },
        {
            "location": "mp/security/jep-290",
            "text": " Overview Deserialization Setup System Property Configuration Programmatic Configuration ",
            "title": "Contents"
        },
        {
            "location": "mp/security/jep-290",
            "text": " JEP-290 brought support for deserialization filters to Java programming language. Such filtering allows us to control which classes may be deserialized using Java serialization. ",
            "title": "Overview"
        },
        {
            "location": "mp/security/jep-290",
            "text": " Helidon default settings forbids any deserialization except for patterns defined in a pattern property of any META-INF/helidon/serial-config.properties on classpath. The patterns are semicolon delimited strings, such as io.myapp.&#42;&#42;;java.util.HashMap (any subpackage of io.myapp and class java.util.HashMap ). Helidon will always add a deny-all filter pattern to the end of the pattern string (to make sure we exclude any unspecified class - we only operate on whitelists) These defaults can be modified either through system properties, or programmatically. ",
            "title": "Deserialization Setup"
        },
        {
            "location": "mp/security/jep-290",
            "text": " The following system properties can be used to control deserialization in Helidon: System properties property default value description helidon.serialFilter.pattern !&#42; Filter pattern to use, deny all is always added helidon.serialFilter.ignoreFiles false Whether to ignore files META-INF/helidon/serial-config.properties in libraries on the classpath helidon.serialFilter.failure.action FAIL Action to do when the configuration of global filter exists and is not consistent with our security expectations (e.g. contains a pattern to include all). Options: FAIL - throw an exception to terminate startup WARN - log a warning IGNORE - ignore this and silently continue helidon.serialFilter.missing.action CONFIGURE Action to do when there is no global configuration. Options: CONFIGURE - configure Helidon defaults FAIL - throw an exception to terminate startup WARN - log a warning IGNORE - ignore this and silently continue helidon.serialFilter.trace NONE Tracing configuration for deserialization. Controls what information (if any) will be logged to a logger io.helidon.common.SerializationConfig.TracingObjectInputFilter in INFO log level. Options: NONE - do not trace BASIC - trace only classes, and only once per class FULL - trace all deserialization filter requests ",
            "title": "System Property Configuration"
        },
        {
            "location": "mp/security/jep-290",
            "text": " Custom SerializationConfig may be registered, but it must be done before Helidon server is started. <markup lang=\"java\" title=\"Configure custom Helidon serialization config\" >SerializationConfig.builder() .traceSerialization(SerializationConfig.TraceOption.BASIC) .filterPattern(MyType.class.getName()) .ignoreFiles(true) .onWrongConfig(SerializationConfig.Action.IGNORE) .build() .configure(); Trace first instance of each class that is deserialized Configure a single class filter pattern (only allows deserialization of class MyType Ignore files defined in META-INF/helidon/serial-config.properties In case there is an existing global serialization configuration on JDK, ignore it and continue (global filter cannot be reconfigured) Configure this serialization config as the default for this JVM ",
            "title": "Programmatic Configuration"
        },
        {
            "location": "mp/security/providers",
            "text": "<markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-oidc&lt;/artifactId&gt; &lt;/dependency&gt; Open ID Connect security provider Type: io.helidon.security.providers.oidc.OidcProvider <markup lang=\"text\" title=\"Config key\" >oidc This type provides the following service implementations: io.helidon.security.spi.AuthenticationProvider io.helidon.security.spi.SecurityProvider ",
            "title": "Setup"
        },
        {
            "location": "mp/security/providers",
            "text": " Optional configuration options key type default value description audience string &#160; Audience of issued tokens. authorization-endpoint-uri URI &#160; URI of an authorization endpoint used to redirect users to for logging-in. If not defined, it is obtained from #oidcMetadata(Resource), if that is not defined an attempt is made to use #identityUri(URI)/oauth2/v1/authorize. base-scopes string openid Configure base scopes. By default this is DEFAULT_BASE_SCOPES . If scope has a qualifier, it must be used here. client-id string &#160; Client ID as generated by OIDC server. client-secret string &#160; Client secret as generated by OIDC server. Used to authenticate this application with the server when requesting JWT based on a code. client-timeout-millis Duration 30000 Timeout of calls using web client. cookie-domain string &#160; Domain the cookie is valid for. Not used by default. cookie-http-only boolean true When using cookie, if set to true, the HttpOnly attribute will be configured. Defaults to OidcCookieHandler.Builder#DEFAULT_HTTP_ONLY . cookie-max-age-seconds long &#160; When using cookie, used to set MaxAge attribute of the cookie, defining how long the cookie is valid. Not used by default. cookie-name string JSESSIONID Name of the cookie to use. Defaults to DEFAULT_COOKIE_NAME . cookie-path string / Path the cookie is valid for. Defaults to \"/\". cookie-same-site SameSite (LAX, STRICT, NONE) LAX When using cookie, used to set the SameSite cookie value. Can be \"Strict\" or \"Lax\". cookie-secure boolean false When using cookie, if set to true, the Secure attribute will be configured. Defaults to false. cookie-use boolean true Whether to use cookie to store JWT between requests. Defaults to DEFAULT_COOKIE_USE . cors CrossOriginConfig &#160; Assign cross-origin resource sharing settings. force-https-redirects boolean false Force HTTPS for redirects to identity provider. Defaults to false . frontend-uri string &#160; Full URI of this application that is visible from user browser. Used to redirect request back from identity server after successful login. header-token TokenHandler &#160; A TokenHandler to process header containing a JWT. Default is \"Authorization\" header with a prefix \"bearer \". header-use boolean true Whether to expect JWT in a header field. identity-uri URI &#160; URI of the identity server, base used to retrieve OIDC metadata. introspect-endpoint-uri URI &#160; Endpoint to use to validate JWT. Either use this or set #signJwk(JwkKeys) or #signJwk(Resource). issuer string &#160; Issuer of issued tokens. max-redirects int 5 Configure maximal number of redirects when redirecting to an OIDC provider within a single authentication attempt. Defaults to `DEFAULT_MAX_REDIRECTS` oidc-metadata-well-known boolean true If set to true, metadata will be loaded from default (well known) location, unless it is explicitly defined using oidc-metadata-resource. If set to false, it would not be loaded even if oidc-metadata-resource is not defined. In such a case all URIs must be explicitly defined (e.g. token-endpoint-uri). oidc-metadata.resource Resource &#160; Resource configuration for OIDC Metadata containing endpoints to various identity services, as well as information about the identity server. optional boolean false Whether authentication is required. By default, request will fail if the authentication cannot be verified. If set to true, request will process and this provider will abstain. outbound OutboundTarget[&#93; &#160; Add a new target configuration. propagate boolean false Whether to propagate identity. proxy-host string &#160; Proxy host to use. When defined, triggers usage of proxy for HTTP requests. Setting to empty String has the same meaning as setting to null - disables proxy. proxy-port int 80 Proxy port. Defaults to DEFAULT_PROXY_PORT proxy-protocol string http Proxy protocol to use when proxy is used. Defaults to DEFAULT_PROXY_PROTOCOL . query-param-name string accessToken Name of a query parameter that contains the JWT token when parameter is used. query-param-use boolean false Whether to use a query parameter to send JWT token from application to this server. redirect boolean false By default the client should redirect to the identity server for the user to log in. This behavior can be overridden by setting redirect to false. When token is not present in the request, the client will not redirect and just return appropriate error response code. redirect-attempt-param string h_ra Configure the parameter used to store the number of attempts in redirect. Defaults to `DEFAULT_ATTEMPT_PARAM` redirect-uri string /oidc/redirect URI to register web server component on, used by the OIDC server to redirect authorization requests to after a user logs in or approves scopes. Note that usually the redirect URI configured here must be the same one as configured on OIDC server. Defaults to `DEFAULT_REDIRECT_URI` scope-audience string &#160; Audience of the scope required by this application. This is prefixed to the scope name when requesting scopes from the identity server. Defaults to empty string. server-type string @default Configure one of the supported types of identity servers. If the type does not have an explicit mapping, a warning is logged and the default implementation is used. sign-jwk.resource Resource &#160; A resource pointing to JWK with public keys of signing certificates used to validate JWT. token-endpoint-auth ClientAuthentication (CLIENT_SECRET_BASIC, CLIENT_SECRET_POST, CLIENT_SECRET_JWT, PRIVATE_KEY_JWT, NONE) CLIENT_SECRET_BASIC Type of authentication to use when invoking the token endpoint. Current supported options: io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#CLIENT_SECRET_BASIC io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#CLIENT_SECRET_POST io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#NONE token-endpoint-uri URI &#160; URI of a token endpoint used to obtain a JWT based on the authentication code. If not defined, it is obtained from #oidcMetadata(Resource), if that is not defined an attempt is made to use #identityUri(URI)/oauth2/v1/token. use-jwt-groups boolean true Claim groups from JWT will be used to automatically add groups to current subject (may be used with jakarta.annotation.security.RolesAllowed annotation). validate-jwt-with-jwk boolean true Use JWK (a set of keys to validate signatures of JWT) to validate tokens. Use this method when you want to use default values for JWK or introspection endpoint URI. ",
            "title": "Configuration options"
        },
        {
            "location": "mp/security/providers",
            "text": " Open ID Connect security provider. Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-oidc&lt;/artifactId&gt; &lt;/dependency&gt; Open ID Connect security provider Type: io.helidon.security.providers.oidc.OidcProvider <markup lang=\"text\" title=\"Config key\" >oidc This type provides the following service implementations: io.helidon.security.spi.AuthenticationProvider io.helidon.security.spi.SecurityProvider Configuration options Optional configuration options key type default value description audience string &#160; Audience of issued tokens. authorization-endpoint-uri URI &#160; URI of an authorization endpoint used to redirect users to for logging-in. If not defined, it is obtained from #oidcMetadata(Resource), if that is not defined an attempt is made to use #identityUri(URI)/oauth2/v1/authorize. base-scopes string openid Configure base scopes. By default this is DEFAULT_BASE_SCOPES . If scope has a qualifier, it must be used here. client-id string &#160; Client ID as generated by OIDC server. client-secret string &#160; Client secret as generated by OIDC server. Used to authenticate this application with the server when requesting JWT based on a code. client-timeout-millis Duration 30000 Timeout of calls using web client. cookie-domain string &#160; Domain the cookie is valid for. Not used by default. cookie-http-only boolean true When using cookie, if set to true, the HttpOnly attribute will be configured. Defaults to OidcCookieHandler.Builder#DEFAULT_HTTP_ONLY . cookie-max-age-seconds long &#160; When using cookie, used to set MaxAge attribute of the cookie, defining how long the cookie is valid. Not used by default. cookie-name string JSESSIONID Name of the cookie to use. Defaults to DEFAULT_COOKIE_NAME . cookie-path string / Path the cookie is valid for. Defaults to \"/\". cookie-same-site SameSite (LAX, STRICT, NONE) LAX When using cookie, used to set the SameSite cookie value. Can be \"Strict\" or \"Lax\". cookie-secure boolean false When using cookie, if set to true, the Secure attribute will be configured. Defaults to false. cookie-use boolean true Whether to use cookie to store JWT between requests. Defaults to DEFAULT_COOKIE_USE . cors CrossOriginConfig &#160; Assign cross-origin resource sharing settings. force-https-redirects boolean false Force HTTPS for redirects to identity provider. Defaults to false . frontend-uri string &#160; Full URI of this application that is visible from user browser. Used to redirect request back from identity server after successful login. header-token TokenHandler &#160; A TokenHandler to process header containing a JWT. Default is \"Authorization\" header with a prefix \"bearer \". header-use boolean true Whether to expect JWT in a header field. identity-uri URI &#160; URI of the identity server, base used to retrieve OIDC metadata. introspect-endpoint-uri URI &#160; Endpoint to use to validate JWT. Either use this or set #signJwk(JwkKeys) or #signJwk(Resource). issuer string &#160; Issuer of issued tokens. max-redirects int 5 Configure maximal number of redirects when redirecting to an OIDC provider within a single authentication attempt. Defaults to `DEFAULT_MAX_REDIRECTS` oidc-metadata-well-known boolean true If set to true, metadata will be loaded from default (well known) location, unless it is explicitly defined using oidc-metadata-resource. If set to false, it would not be loaded even if oidc-metadata-resource is not defined. In such a case all URIs must be explicitly defined (e.g. token-endpoint-uri). oidc-metadata.resource Resource &#160; Resource configuration for OIDC Metadata containing endpoints to various identity services, as well as information about the identity server. optional boolean false Whether authentication is required. By default, request will fail if the authentication cannot be verified. If set to true, request will process and this provider will abstain. outbound OutboundTarget[&#93; &#160; Add a new target configuration. propagate boolean false Whether to propagate identity. proxy-host string &#160; Proxy host to use. When defined, triggers usage of proxy for HTTP requests. Setting to empty String has the same meaning as setting to null - disables proxy. proxy-port int 80 Proxy port. Defaults to DEFAULT_PROXY_PORT proxy-protocol string http Proxy protocol to use when proxy is used. Defaults to DEFAULT_PROXY_PROTOCOL . query-param-name string accessToken Name of a query parameter that contains the JWT token when parameter is used. query-param-use boolean false Whether to use a query parameter to send JWT token from application to this server. redirect boolean false By default the client should redirect to the identity server for the user to log in. This behavior can be overridden by setting redirect to false. When token is not present in the request, the client will not redirect and just return appropriate error response code. redirect-attempt-param string h_ra Configure the parameter used to store the number of attempts in redirect. Defaults to `DEFAULT_ATTEMPT_PARAM` redirect-uri string /oidc/redirect URI to register web server component on, used by the OIDC server to redirect authorization requests to after a user logs in or approves scopes. Note that usually the redirect URI configured here must be the same one as configured on OIDC server. Defaults to `DEFAULT_REDIRECT_URI` scope-audience string &#160; Audience of the scope required by this application. This is prefixed to the scope name when requesting scopes from the identity server. Defaults to empty string. server-type string @default Configure one of the supported types of identity servers. If the type does not have an explicit mapping, a warning is logged and the default implementation is used. sign-jwk.resource Resource &#160; A resource pointing to JWK with public keys of signing certificates used to validate JWT. token-endpoint-auth ClientAuthentication (CLIENT_SECRET_BASIC, CLIENT_SECRET_POST, CLIENT_SECRET_JWT, PRIVATE_KEY_JWT, NONE) CLIENT_SECRET_BASIC Type of authentication to use when invoking the token endpoint. Current supported options: io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#CLIENT_SECRET_BASIC io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#CLIENT_SECRET_POST io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#NONE token-endpoint-uri URI &#160; URI of a token endpoint used to obtain a JWT based on the authentication code. If not defined, it is obtained from #oidcMetadata(Resource), if that is not defined an attempt is made to use #identityUri(URI)/oauth2/v1/token. use-jwt-groups boolean true Claim groups from JWT will be used to automatically add groups to current subject (may be used with jakarta.annotation.security.RolesAllowed annotation). validate-jwt-with-jwk boolean true Use JWK (a set of keys to validate signatures of JWT) to validate tokens. Use this method when you want to use default values for JWK or introspection endpoint URI. ",
            "title": "OIDC Provider"
        },
        {
            "location": "mp/security/providers",
            "text": " See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - oidc: client-id: \"client-id-of-this-service\" client-secret: \"${CLEAR=client-secret-of-this-service}\" identity-uri: \"http://your-tenant.identity-server.com\" frontend-uri: \"http://my-service:8080\" audience: \"http://my-service\" cors: allow-origins: [\"http://foo.com\", \"http://there.com\"] allow-methods: [\"PUT\", \"DELETE\"] outbound: - name: \"internal-services\" hosts: [\"*.example.org\"] outbound-token: header: \"X-Internal-Auth\" ",
            "title": "Example code"
        },
        {
            "location": "mp/security/providers",
            "text": " At Helidon startup, if OIDC provider is configured, the following will happen: client-id , client-secret , and identityUri are validated - these must provide values Unless all resources are configured as local resources, the provider attempts to contact the oidc-metadata.resource endpoint to retrieve all endpoints At runtime, depending on configuration&#8230;&#8203; If a request comes without a token or with insufficient scopes: If redirect is set to true (default), request is redirected to the authorization endpoint of the identity server. If set to false, 401 is returned User authenticates against the identity server The identity server redirects back to Helidon service with a code Helidon service contacts the identity server&#8217;s token endpoint, to exchange the code for a JWT The JWT is stored in a cookie (if cookie support is enabled, which it is by default) Helidon service redirects to original endpoint (on itself) Helidon obtains a token from request (from cookie, header, or query parameter): Token is parsed as a singed JWT We validate the JWT signature either against local JWK or against the identity server&#8217;s introspection endpoint depending on configuration We validate the issuer and audience of the token if it matches the configured values A subject is created from the JWT, including scopes from the token We validate that we have sufficient scopes to proceed, and return 403 if not Handling is returned to security to process other security providers ",
            "title": "How does it work?"
        },
        {
            "location": "mp/security/providers",
            "text": " Helidon provides the following security providers for endpoint protection: Provider Type Outbound supported Description OIDC Provider Authentication ✅ Open ID Connect supporting JWT, Scopes, Groups and OIDC code flow HTTP Basic Authentication Authentication ✅ HTTP Basic Authentication support HTTP Digest Authentication Authentication 🚫 HTTP Digest Authentication support Header Assertion Authentication ✅ Asserting a user based on a header value HTTP Signatures Authentication ✅ Protecting service to service communication through signatures IDCS Roles Role Mapping 🚫 Retrieves roles from IDCS provider for authenticated user ABAC Authorization Authorization 🚫 Attribute based access control authorization policies The following providers are no longer evolved: Provider Type Outbound supported Description Google Login Authentication ✅ Authenticates a token from request against Google servers JWT Provider Authentication ✅ JWT tokens passed from frontend OIDC Provider Open ID Connect security provider. Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-oidc&lt;/artifactId&gt; &lt;/dependency&gt; Open ID Connect security provider Type: io.helidon.security.providers.oidc.OidcProvider <markup lang=\"text\" title=\"Config key\" >oidc This type provides the following service implementations: io.helidon.security.spi.AuthenticationProvider io.helidon.security.spi.SecurityProvider Configuration options Optional configuration options key type default value description audience string &#160; Audience of issued tokens. authorization-endpoint-uri URI &#160; URI of an authorization endpoint used to redirect users to for logging-in. If not defined, it is obtained from #oidcMetadata(Resource), if that is not defined an attempt is made to use #identityUri(URI)/oauth2/v1/authorize. base-scopes string openid Configure base scopes. By default this is DEFAULT_BASE_SCOPES . If scope has a qualifier, it must be used here. client-id string &#160; Client ID as generated by OIDC server. client-secret string &#160; Client secret as generated by OIDC server. Used to authenticate this application with the server when requesting JWT based on a code. client-timeout-millis Duration 30000 Timeout of calls using web client. cookie-domain string &#160; Domain the cookie is valid for. Not used by default. cookie-http-only boolean true When using cookie, if set to true, the HttpOnly attribute will be configured. Defaults to OidcCookieHandler.Builder#DEFAULT_HTTP_ONLY . cookie-max-age-seconds long &#160; When using cookie, used to set MaxAge attribute of the cookie, defining how long the cookie is valid. Not used by default. cookie-name string JSESSIONID Name of the cookie to use. Defaults to DEFAULT_COOKIE_NAME . cookie-path string / Path the cookie is valid for. Defaults to \"/\". cookie-same-site SameSite (LAX, STRICT, NONE) LAX When using cookie, used to set the SameSite cookie value. Can be \"Strict\" or \"Lax\". cookie-secure boolean false When using cookie, if set to true, the Secure attribute will be configured. Defaults to false. cookie-use boolean true Whether to use cookie to store JWT between requests. Defaults to DEFAULT_COOKIE_USE . cors CrossOriginConfig &#160; Assign cross-origin resource sharing settings. force-https-redirects boolean false Force HTTPS for redirects to identity provider. Defaults to false . frontend-uri string &#160; Full URI of this application that is visible from user browser. Used to redirect request back from identity server after successful login. header-token TokenHandler &#160; A TokenHandler to process header containing a JWT. Default is \"Authorization\" header with a prefix \"bearer \". header-use boolean true Whether to expect JWT in a header field. identity-uri URI &#160; URI of the identity server, base used to retrieve OIDC metadata. introspect-endpoint-uri URI &#160; Endpoint to use to validate JWT. Either use this or set #signJwk(JwkKeys) or #signJwk(Resource). issuer string &#160; Issuer of issued tokens. max-redirects int 5 Configure maximal number of redirects when redirecting to an OIDC provider within a single authentication attempt. Defaults to `DEFAULT_MAX_REDIRECTS` oidc-metadata-well-known boolean true If set to true, metadata will be loaded from default (well known) location, unless it is explicitly defined using oidc-metadata-resource. If set to false, it would not be loaded even if oidc-metadata-resource is not defined. In such a case all URIs must be explicitly defined (e.g. token-endpoint-uri). oidc-metadata.resource Resource &#160; Resource configuration for OIDC Metadata containing endpoints to various identity services, as well as information about the identity server. optional boolean false Whether authentication is required. By default, request will fail if the authentication cannot be verified. If set to true, request will process and this provider will abstain. outbound OutboundTarget[&#93; &#160; Add a new target configuration. propagate boolean false Whether to propagate identity. proxy-host string &#160; Proxy host to use. When defined, triggers usage of proxy for HTTP requests. Setting to empty String has the same meaning as setting to null - disables proxy. proxy-port int 80 Proxy port. Defaults to DEFAULT_PROXY_PORT proxy-protocol string http Proxy protocol to use when proxy is used. Defaults to DEFAULT_PROXY_PROTOCOL . query-param-name string accessToken Name of a query parameter that contains the JWT token when parameter is used. query-param-use boolean false Whether to use a query parameter to send JWT token from application to this server. redirect boolean false By default the client should redirect to the identity server for the user to log in. This behavior can be overridden by setting redirect to false. When token is not present in the request, the client will not redirect and just return appropriate error response code. redirect-attempt-param string h_ra Configure the parameter used to store the number of attempts in redirect. Defaults to `DEFAULT_ATTEMPT_PARAM` redirect-uri string /oidc/redirect URI to register web server component on, used by the OIDC server to redirect authorization requests to after a user logs in or approves scopes. Note that usually the redirect URI configured here must be the same one as configured on OIDC server. Defaults to `DEFAULT_REDIRECT_URI` scope-audience string &#160; Audience of the scope required by this application. This is prefixed to the scope name when requesting scopes from the identity server. Defaults to empty string. server-type string @default Configure one of the supported types of identity servers. If the type does not have an explicit mapping, a warning is logged and the default implementation is used. sign-jwk.resource Resource &#160; A resource pointing to JWK with public keys of signing certificates used to validate JWT. token-endpoint-auth ClientAuthentication (CLIENT_SECRET_BASIC, CLIENT_SECRET_POST, CLIENT_SECRET_JWT, PRIVATE_KEY_JWT, NONE) CLIENT_SECRET_BASIC Type of authentication to use when invoking the token endpoint. Current supported options: io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#CLIENT_SECRET_BASIC io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#CLIENT_SECRET_POST io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#NONE token-endpoint-uri URI &#160; URI of a token endpoint used to obtain a JWT based on the authentication code. If not defined, it is obtained from #oidcMetadata(Resource), if that is not defined an attempt is made to use #identityUri(URI)/oauth2/v1/token. use-jwt-groups boolean true Claim groups from JWT will be used to automatically add groups to current subject (may be used with jakarta.annotation.security.RolesAllowed annotation). validate-jwt-with-jwk boolean true Use JWK (a set of keys to validate signatures of JWT) to validate tokens. Use this method when you want to use default values for JWK or introspection endpoint URI. Example code See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - oidc: client-id: \"client-id-of-this-service\" client-secret: \"${CLEAR=client-secret-of-this-service}\" identity-uri: \"http://your-tenant.identity-server.com\" frontend-uri: \"http://my-service:8080\" audience: \"http://my-service\" cors: allow-origins: [\"http://foo.com\", \"http://there.com\"] allow-methods: [\"PUT\", \"DELETE\"] outbound: - name: \"internal-services\" hosts: [\"*.example.org\"] outbound-token: header: \"X-Internal-Auth\" How does it work? At Helidon startup, if OIDC provider is configured, the following will happen: client-id , client-secret , and identityUri are validated - these must provide values Unless all resources are configured as local resources, the provider attempts to contact the oidc-metadata.resource endpoint to retrieve all endpoints At runtime, depending on configuration&#8230;&#8203; If a request comes without a token or with insufficient scopes: If redirect is set to true (default), request is redirected to the authorization endpoint of the identity server. If set to false, 401 is returned User authenticates against the identity server The identity server redirects back to Helidon service with a code Helidon service contacts the identity server&#8217;s token endpoint, to exchange the code for a JWT The JWT is stored in a cookie (if cookie support is enabled, which it is by default) Helidon service redirects to original endpoint (on itself) Helidon obtains a token from request (from cookie, header, or query parameter): Token is parsed as a singed JWT We validate the JWT signature either against local JWK or against the identity server&#8217;s introspection endpoint depending on configuration We validate the issuer and audience of the token if it matches the configured values A subject is created from the JWT, including scopes from the token We validate that we have sufficient scopes to proceed, and return 403 if not Handling is returned to security to process other security providers ",
            "title": "Implemented Security Providers"
        },
        {
            "location": "mp/security/providers",
            "text": "<markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-http-auth&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Setup"
        },
        {
            "location": "mp/security/providers",
            "text": " HTTP Basic Authentication provider Type: io.helidon.security.providers.httpauth.HttpBasicAuthProvider <markup lang=\"text\" title=\"Config key\" >http-basic-auth This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthenticationProvider ",
            "title": "Overview"
        },
        {
            "location": "mp/security/providers",
            "text": " Optional configuration options key type default value description optional boolean false Whether authentication is required. By default, request will fail if the authentication cannot be verified. If set to false, request will process and this provider will abstain. outbound OutboundTarget[&#93; &#160; Add a new outbound target to configure identity propagation or explicit username/password. principal-type SubjectType (USER, SERVICE) USER Principal type this provider extracts (and also propagates). realm string helidon Set the realm to use when challenging users. users ConfigUser[&#93; &#160; Set user store to validate users. Removes any other stores added through #addUserStore(SecureUserStore). ",
            "title": "Configuration options"
        },
        {
            "location": "mp/security/providers",
            "text": " See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - http-basic-auth: realm: \"helidon\" users: - login: \"john\" password: \"${CLEAR=password}\" roles: [\"admin\"] - login: \"jack\" password: \"password\" roles: [\"user\", \"admin\"] outbound: - name: \"internal-services\" hosts: [\"*.example.org\"] # Propagates current user's identity or identity from request property outbound-token: header: \"X-Internal-Auth\" - name: \"partner-service\" hosts: [\"*.partner.org\"] # Uses this username and password username: \"partner-user-1\" password: \"${CLEAR=password}\" ",
            "title": "Example code"
        },
        {
            "location": "mp/security/providers",
            "text": " See https://tools.ietf.org/html/rfc7617 . Authentication of request When a request is received without the Authorization: basic &#8230;&#8203;. header, a challenge is returned to provide such authentication. When a request is received with the Authorization: basic &#8230;&#8203;. header, the username and password is validated against configured users (and users obtained from custom service if any provided). Subject is created based on the username and roles provided by the user store. Identity propagation When identity propagation is configured, there are several options for identifying username and password to propagate: We propagate the current username and password (inbound request must be authenticated using basic authentication). We use username and password from an explicitly configured property (See HttpBasicAuthProvider.EP_PROPERTY_OUTBOUND_USER and HttpBasicAuthProvider.EP_PROPERTY_OUTBOUND_PASSWORD ) We use username and password associated with an outbound target (see example configuration above) Identity is propagated only if: There is an outbound target configured for the endpoint Or there is an explicitly configured username/password for the current request (through request property) Custom user store Java service loader service io.helidon.security.providers.httpauth.spi.UserStoreService can be implemented to provide users to the provider, such as when validated against an internal database or LDAP server. The user store is defined so you never need the clear text password of the user. Warning on security of HTTP Basic Authenticaton (or lack thereof) Basic authentication uses base64 encoded username and password and passes it over the network. Base64 is only encoding, not encryption - so anybody that gets hold of the header value can learn the actual username and password of the user. This is a security risk and an attack vector that everybody should be aware of before using HTTP Basic Authentication. We recommend using this approach only for testing and demo purposes. ",
            "title": "How does it work?"
        },
        {
            "location": "mp/security/providers",
            "text": " HTTP Basic authentication support Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-http-auth&lt;/artifactId&gt; &lt;/dependency&gt; Overview HTTP Basic Authentication provider Type: io.helidon.security.providers.httpauth.HttpBasicAuthProvider <markup lang=\"text\" title=\"Config key\" >http-basic-auth This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthenticationProvider Configuration options Optional configuration options key type default value description optional boolean false Whether authentication is required. By default, request will fail if the authentication cannot be verified. If set to false, request will process and this provider will abstain. outbound OutboundTarget[&#93; &#160; Add a new outbound target to configure identity propagation or explicit username/password. principal-type SubjectType (USER, SERVICE) USER Principal type this provider extracts (and also propagates). realm string helidon Set the realm to use when challenging users. users ConfigUser[&#93; &#160; Set user store to validate users. Removes any other stores added through #addUserStore(SecureUserStore). Example code See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - http-basic-auth: realm: \"helidon\" users: - login: \"john\" password: \"${CLEAR=password}\" roles: [\"admin\"] - login: \"jack\" password: \"password\" roles: [\"user\", \"admin\"] outbound: - name: \"internal-services\" hosts: [\"*.example.org\"] # Propagates current user's identity or identity from request property outbound-token: header: \"X-Internal-Auth\" - name: \"partner-service\" hosts: [\"*.partner.org\"] # Uses this username and password username: \"partner-user-1\" password: \"${CLEAR=password}\" How does it work? See https://tools.ietf.org/html/rfc7617 . Authentication of request When a request is received without the Authorization: basic &#8230;&#8203;. header, a challenge is returned to provide such authentication. When a request is received with the Authorization: basic &#8230;&#8203;. header, the username and password is validated against configured users (and users obtained from custom service if any provided). Subject is created based on the username and roles provided by the user store. Identity propagation When identity propagation is configured, there are several options for identifying username and password to propagate: We propagate the current username and password (inbound request must be authenticated using basic authentication). We use username and password from an explicitly configured property (See HttpBasicAuthProvider.EP_PROPERTY_OUTBOUND_USER and HttpBasicAuthProvider.EP_PROPERTY_OUTBOUND_PASSWORD ) We use username and password associated with an outbound target (see example configuration above) Identity is propagated only if: There is an outbound target configured for the endpoint Or there is an explicitly configured username/password for the current request (through request property) Custom user store Java service loader service io.helidon.security.providers.httpauth.spi.UserStoreService can be implemented to provide users to the provider, such as when validated against an internal database or LDAP server. The user store is defined so you never need the clear text password of the user. Warning on security of HTTP Basic Authenticaton (or lack thereof) Basic authentication uses base64 encoded username and password and passes it over the network. Base64 is only encoding, not encryption - so anybody that gets hold of the header value can learn the actual username and password of the user. This is a security risk and an attack vector that everybody should be aware of before using HTTP Basic Authentication. We recommend using this approach only for testing and demo purposes. ",
            "title": "HTTP Basic Authentication Provider"
        },
        {
            "location": "mp/security/providers",
            "text": "<markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-http-auth&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Setup"
        },
        {
            "location": "mp/security/providers",
            "text": " Http digest authentication security provider Type: io.helidon.security.providers.httpauth.HttpDigestAuthProvider <markup lang=\"text\" title=\"Config key\" >http-digest-auth This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthenticationProvider ",
            "title": "Overview"
        },
        {
            "location": "mp/security/providers",
            "text": " Optional configuration options key type default value description algorithm Algorithm (MD5) MD5 Digest algorithm to use. nonce-timeout-millis long 86400000 How long will the nonce value be valid. When timed-out, browser will re-request username/password. optional boolean false Whether authentication is required. By default, request will fail if the authentication cannot be verified. If set to false, request will process and this provider will abstain. principal-type SubjectType (USER, SERVICE) USER Principal type this provider extracts (and also propagates). qop Qop (NONE, AUTH) NONE Only AUTH supported. If left empty, uses the legacy approach (older RFC version). AUTH-INT is not supported. realm string Helidon Set the realm to use when challenging users. server-secret string &#160; The nonce is encrypted using this secret - to make sure the nonce we get back was generated by us and to make sure we can safely time-out nonce values. This secret must be the same for all service instances (or all services that want to share the same authentication). Defaults to a random password - e.g. if deployed to multiple servers, the authentication WILL NOT WORK. You MUST provide your own password to work in a distributed environment with non-sticky load balancing. users ConfigUser[&#93; &#160; Set user store to obtain passwords and roles based on logins. ",
            "title": "Configuration options"
        },
        {
            "location": "mp/security/providers",
            "text": "<markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - http-digest-auth: realm: \"helidon\" server-secret: \"${CLEAR=service-wide-secret-not-known-outside}\" users: - login: \"john\" password: \"${CLEAR=password}\" roles: [\"admin\"] - login: \"jack\" password: \"password\" roles: [\"user\", \"admin\"] ",
            "title": "Example code"
        },
        {
            "location": "mp/security/providers",
            "text": " See https://tools.ietf.org/html/rfc7616 . Authentication of request When a request is received without the Authorization: digest &#8230;&#8203;. header, a challenge is returned to provide such authentication using WWW-Authenticate header. When a request is received with the Authorization: digest &#8230;&#8203;. header, the request is validated against configured users (and users obtained from custom service if any provided). Subject is created based on the username and roles provided by the user store. Custom user store Java service loader service io.helidon.security.providers.httpauth.spi.UserStoreService can be implemented to provide users to the provider, such as when validated against an internal database or LDAP server. The user store is defined so you never need the clear text password of the user. Note on security of HTTP Digest Authenticaton These authentication schemes should be obsolete , though they provide a very easy way to test a protected resource. ",
            "title": "How does it work?"
        },
        {
            "location": "mp/security/providers",
            "text": " HTTP Digest authentication support Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-http-auth&lt;/artifactId&gt; &lt;/dependency&gt; Overview Http digest authentication security provider Type: io.helidon.security.providers.httpauth.HttpDigestAuthProvider <markup lang=\"text\" title=\"Config key\" >http-digest-auth This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthenticationProvider Configuration options Optional configuration options key type default value description algorithm Algorithm (MD5) MD5 Digest algorithm to use. nonce-timeout-millis long 86400000 How long will the nonce value be valid. When timed-out, browser will re-request username/password. optional boolean false Whether authentication is required. By default, request will fail if the authentication cannot be verified. If set to false, request will process and this provider will abstain. principal-type SubjectType (USER, SERVICE) USER Principal type this provider extracts (and also propagates). qop Qop (NONE, AUTH) NONE Only AUTH supported. If left empty, uses the legacy approach (older RFC version). AUTH-INT is not supported. realm string Helidon Set the realm to use when challenging users. server-secret string &#160; The nonce is encrypted using this secret - to make sure the nonce we get back was generated by us and to make sure we can safely time-out nonce values. This secret must be the same for all service instances (or all services that want to share the same authentication). Defaults to a random password - e.g. if deployed to multiple servers, the authentication WILL NOT WORK. You MUST provide your own password to work in a distributed environment with non-sticky load balancing. users ConfigUser[&#93; &#160; Set user store to obtain passwords and roles based on logins. Example code <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - http-digest-auth: realm: \"helidon\" server-secret: \"${CLEAR=service-wide-secret-not-known-outside}\" users: - login: \"john\" password: \"${CLEAR=password}\" roles: [\"admin\"] - login: \"jack\" password: \"password\" roles: [\"user\", \"admin\"] How does it work? See https://tools.ietf.org/html/rfc7616 . Authentication of request When a request is received without the Authorization: digest &#8230;&#8203;. header, a challenge is returned to provide such authentication using WWW-Authenticate header. When a request is received with the Authorization: digest &#8230;&#8203;. header, the request is validated against configured users (and users obtained from custom service if any provided). Subject is created based on the username and roles provided by the user store. Custom user store Java service loader service io.helidon.security.providers.httpauth.spi.UserStoreService can be implemented to provide users to the provider, such as when validated against an internal database or LDAP server. The user store is defined so you never need the clear text password of the user. Note on security of HTTP Digest Authenticaton These authentication schemes should be obsolete , though they provide a very easy way to test a protected resource. ",
            "title": "HTTP Digest Authentication Provider"
        },
        {
            "location": "mp/security/providers",
            "text": "<markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-header&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Setup"
        },
        {
            "location": "mp/security/providers",
            "text": " Security provider that extracts a username (or service name) from a header. Type: io.helidon.security.providers.header.HeaderAtnProvider <markup lang=\"text\" title=\"Config key\" >header-atn This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthenticationProvider ",
            "title": "Overview"
        },
        {
            "location": "mp/security/providers",
            "text": " Optional configuration options key type default value description atn-token TokenHandler &#160; Token handler to extract username from request. authenticate boolean true Whether to authenticate requests. optional boolean false Whether authentication is required. By default, request will fail if the username cannot be extracted. If set to false, request will process and this provider will abstain. outbound OutboundTarget[&#93; &#160; Configure outbound target for identity propagation. outbound-token TokenHandler &#160; Token handler to create outbound headers to propagate identity. If not defined, #atnTokenHandler will be used. principal-type SubjectType (USER, SERVICE) USER Principal type this provider extracts (and also propagates). propagate boolean false Whether to propagate identity. ",
            "title": "Configuration options"
        },
        {
            "location": "mp/security/providers",
            "text": "<markup lang=\"yaml\" title=\"Configuration example\" >security: providers: header-atn: atn-token: header: \"X-AUTH-USER\" outbound: - name: \"internal-services\" hosts: [\"*.example.org\"] # propagates the current user or service id using the same header as authentication - name: \"partner-service\" hosts: [\"*.partner.org\"] # propagates an explicit username in a custom header username: \"service-27\" outbound-token: header: \"X-Service-Auth\" ",
            "title": "Example code"
        },
        {
            "location": "mp/security/providers",
            "text": " This provider inspects a specified request header and extracts the username/service name from it and asserts it as current subject&#8217;s principal. This can be used when we use perimeter authentication (e.g. there is a gateway that takes care of authentication and propagates the user in a header). Identity propagation Identity is propagated only if an outbound target matches the target service. The following options exist when propagating identity: 1. We propagate the current username using the configured header 2. We use username associated with an outbound target (see example configuration above) Caution When using this provider, you must be sure the header cannot be explicitly configured by a user or another service. All requests should go through a gateway that removes this header from inbound traffic, and only configures it for authenticated users/services. Another option is to use this with fully trusted parties (such as services within a single company, on a single protected network not accessible to any users), and of course for testing and demo purposes. ",
            "title": "How does it work?"
        },
        {
            "location": "mp/security/providers",
            "text": " Asserts user or service identity based on a value of a header. Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-header&lt;/artifactId&gt; &lt;/dependency&gt; Overview Security provider that extracts a username (or service name) from a header. Type: io.helidon.security.providers.header.HeaderAtnProvider <markup lang=\"text\" title=\"Config key\" >header-atn This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthenticationProvider Configuration options Optional configuration options key type default value description atn-token TokenHandler &#160; Token handler to extract username from request. authenticate boolean true Whether to authenticate requests. optional boolean false Whether authentication is required. By default, request will fail if the username cannot be extracted. If set to false, request will process and this provider will abstain. outbound OutboundTarget[&#93; &#160; Configure outbound target for identity propagation. outbound-token TokenHandler &#160; Token handler to create outbound headers to propagate identity. If not defined, #atnTokenHandler will be used. principal-type SubjectType (USER, SERVICE) USER Principal type this provider extracts (and also propagates). propagate boolean false Whether to propagate identity. Example code <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: header-atn: atn-token: header: \"X-AUTH-USER\" outbound: - name: \"internal-services\" hosts: [\"*.example.org\"] # propagates the current user or service id using the same header as authentication - name: \"partner-service\" hosts: [\"*.partner.org\"] # propagates an explicit username in a custom header username: \"service-27\" outbound-token: header: \"X-Service-Auth\" How does it work? This provider inspects a specified request header and extracts the username/service name from it and asserts it as current subject&#8217;s principal. This can be used when we use perimeter authentication (e.g. there is a gateway that takes care of authentication and propagates the user in a header). Identity propagation Identity is propagated only if an outbound target matches the target service. The following options exist when propagating identity: 1. We propagate the current username using the configured header 2. We use username associated with an outbound target (see example configuration above) Caution When using this provider, you must be sure the header cannot be explicitly configured by a user or another service. All requests should go through a gateway that removes this header from inbound traffic, and only configures it for authenticated users/services. Another option is to use this with fully trusted parties (such as services within a single company, on a single protected network not accessible to any users), and of course for testing and demo purposes. ",
            "title": "Header Authentication Provider"
        },
        {
            "location": "mp/security/providers",
            "text": "<markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-http-sign&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Setup"
        },
        {
            "location": "mp/security/providers",
            "text": " HTTP header signature provider. Type: io.helidon.security.providers.httpsign.HttpSignProvider <markup lang=\"text\" title=\"Config key\" >http-signatures This type provides the following service implementations: io.helidon.security.spi.AuthenticationProvider ",
            "title": "Overview"
        },
        {
            "location": "mp/security/providers",
            "text": " Optional configuration options key type default value description backward-compatible-eol boolean false Enable support for Helidon versions before 3.0.0 (exclusive). Until version 3.0.0 (exclusive) there was a trailing end of line added to the signed data. To be able to communicate cross versions, we must configure this when talking to older versions of Helidon. Default value is `false`. In Helidon 2.x, this switch exists as well and the default is `true`, to allow communication between versions as needed. headers HttpSignHeader[&#93; (SIGNATURE, AUTHORIZATION, CUSTOM) &#160; Add a header that is validated on inbound requests. Provider may support more than one header to validate. inbound.keys InboundClientDefinition[&#93; &#160; Add inbound configuration. This is used to validate signature and authenticate the party. The same can be done through configuration: &lt;pre&gt; { name = \"http-signatures\" class = \"HttpSignProvider\" http-signatures { inbound { # This configures the InboundClientDefinition keys: [ { key-id = \"service1\" hmac.secret = \"${CLEAR=password}\" }] } } } &lt;/pre&gt; optional boolean true Set whether the signature is optional. If set to true (default), this provider will SecurityResponse.SecurityStatus#ABSTAIN from this request if signature is not present. If set to false, this provider will SecurityResponse.SecurityStatus#FAILURE fail if signature is not present. outbound OutboundConfig &#160; Add outbound targets to this builder. The targets are used to chose what to do for outbound communication. The targets should have OutboundTargetDefinition attached through OutboundTarget.Builder#customObject(Class, Object) to tell us how to sign the request. The same can be done through configuration: &lt;pre&gt; { name = \"http-signatures\" class = \"HttpSignProvider\" http-signatures { targets: [ { name = \"service2\" hosts = [\"localhost\"] paths = [\"/service2/.*\"] # This configures the OutboundTargetDefinition signature { key-id = \"service1\" hmac.secret = \"${CLEAR=password}\" } }] } } &lt;/pre&gt; realm string helidon Realm to use for challenging inbound requests that do not have \"Authorization\" header in case header is HttpSignHeader#AUTHORIZATION and singatures are not optional. sign-headers HeadersConfig[&#93; &#160; Override the default inbound required headers (e.g. headers that MUST be signed and headers that MUST be signed IF present). Defaults: get, head, delete methods: date, (request-target), host are mandatory; authorization if present (unless we are creating/validating the HttpSignHeader#AUTHORIZATION ourselves put, post: same as above, with addition of: content-length, content-type and digest if present for other methods: date, (request-target) Note that this provider DOES NOT validate the \"Digest\" HTTP header, only the signature. ",
            "title": "Configuration options"
        },
        {
            "location": "mp/security/providers",
            "text": " See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - http-signatures: inbound: keys: - key-id: \"service1-hmac\" principal-name: \"Service1 - HMAC signature\" hmac.secret: \"${CLEAR=somePasswordForHmacShouldBeEncrypted}\" - key-id: \"service1-rsa\" principal-name: \"Service1 - RSA signature\" public-key: keystore: resource.path: \"src/main/resources/keystore.p12\" passphrase: \"password\" cert.alias: \"service_cert\" outbound: - name: \"service2-hmac\" hosts: [\"localhost\"] paths: [\"/service2\"] signature: key-id: \"service1-hmac\" hmac.secret: \"${CLEAR=somePasswordForHmacShouldBeEncrypted}\" - name: \"service2-rsa\" hosts: [\"localhost\"] paths: [\"/service2-rsa.*\"] signature: key-id: \"service1-rsa\" private-key: keystore: resource.path: \"src/main/resources/keystore.p12\" passphrase: \"password\" key.alias: \"myPrivateKey\" ",
            "title": "Example code"
        },
        {
            "location": "mp/security/providers",
            "text": " standard: based on https://tools.ietf.org/html/draft-cavage-http-signatures-03 key-id: an arbitrary string used to locate signature configuration - when a request is received the provider locates validation configuration based on this id (e.g. HMAC shared secret or RSA public key). Commonly used meanings are: key fingerprint (RSA); API Key ",
            "title": "Signature basics"
        },
        {
            "location": "mp/security/providers",
            "text": " Inbound Signatures We act as a server and another party is calling us with a signed HTTP request. We validate the signature and assume identity of the caller. Outbound Signatures We act as a client and we sign our outgoing requests. If there is a matching outbound target specified in configuration, its configuration will be applied for signing the outgoing request, otherwise there is no signature added ",
            "title": "How does it work?"
        },
        {
            "location": "mp/security/providers",
            "text": " Support for HTTP Signatures. Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-http-sign&lt;/artifactId&gt; &lt;/dependency&gt; Overview HTTP header signature provider. Type: io.helidon.security.providers.httpsign.HttpSignProvider <markup lang=\"text\" title=\"Config key\" >http-signatures This type provides the following service implementations: io.helidon.security.spi.AuthenticationProvider Configuration options Optional configuration options key type default value description backward-compatible-eol boolean false Enable support for Helidon versions before 3.0.0 (exclusive). Until version 3.0.0 (exclusive) there was a trailing end of line added to the signed data. To be able to communicate cross versions, we must configure this when talking to older versions of Helidon. Default value is `false`. In Helidon 2.x, this switch exists as well and the default is `true`, to allow communication between versions as needed. headers HttpSignHeader[&#93; (SIGNATURE, AUTHORIZATION, CUSTOM) &#160; Add a header that is validated on inbound requests. Provider may support more than one header to validate. inbound.keys InboundClientDefinition[&#93; &#160; Add inbound configuration. This is used to validate signature and authenticate the party. The same can be done through configuration: &lt;pre&gt; { name = \"http-signatures\" class = \"HttpSignProvider\" http-signatures { inbound { # This configures the InboundClientDefinition keys: [ { key-id = \"service1\" hmac.secret = \"${CLEAR=password}\" }] } } } &lt;/pre&gt; optional boolean true Set whether the signature is optional. If set to true (default), this provider will SecurityResponse.SecurityStatus#ABSTAIN from this request if signature is not present. If set to false, this provider will SecurityResponse.SecurityStatus#FAILURE fail if signature is not present. outbound OutboundConfig &#160; Add outbound targets to this builder. The targets are used to chose what to do for outbound communication. The targets should have OutboundTargetDefinition attached through OutboundTarget.Builder#customObject(Class, Object) to tell us how to sign the request. The same can be done through configuration: &lt;pre&gt; { name = \"http-signatures\" class = \"HttpSignProvider\" http-signatures { targets: [ { name = \"service2\" hosts = [\"localhost\"] paths = [\"/service2/.*\"] # This configures the OutboundTargetDefinition signature { key-id = \"service1\" hmac.secret = \"${CLEAR=password}\" } }] } } &lt;/pre&gt; realm string helidon Realm to use for challenging inbound requests that do not have \"Authorization\" header in case header is HttpSignHeader#AUTHORIZATION and singatures are not optional. sign-headers HeadersConfig[&#93; &#160; Override the default inbound required headers (e.g. headers that MUST be signed and headers that MUST be signed IF present). Defaults: get, head, delete methods: date, (request-target), host are mandatory; authorization if present (unless we are creating/validating the HttpSignHeader#AUTHORIZATION ourselves put, post: same as above, with addition of: content-length, content-type and digest if present for other methods: date, (request-target) Note that this provider DOES NOT validate the \"Digest\" HTTP header, only the signature. Example code See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - http-signatures: inbound: keys: - key-id: \"service1-hmac\" principal-name: \"Service1 - HMAC signature\" hmac.secret: \"${CLEAR=somePasswordForHmacShouldBeEncrypted}\" - key-id: \"service1-rsa\" principal-name: \"Service1 - RSA signature\" public-key: keystore: resource.path: \"src/main/resources/keystore.p12\" passphrase: \"password\" cert.alias: \"service_cert\" outbound: - name: \"service2-hmac\" hosts: [\"localhost\"] paths: [\"/service2\"] signature: key-id: \"service1-hmac\" hmac.secret: \"${CLEAR=somePasswordForHmacShouldBeEncrypted}\" - name: \"service2-rsa\" hosts: [\"localhost\"] paths: [\"/service2-rsa.*\"] signature: key-id: \"service1-rsa\" private-key: keystore: resource.path: \"src/main/resources/keystore.p12\" passphrase: \"password\" key.alias: \"myPrivateKey\" Signature basics standard: based on https://tools.ietf.org/html/draft-cavage-http-signatures-03 key-id: an arbitrary string used to locate signature configuration - when a request is received the provider locates validation configuration based on this id (e.g. HMAC shared secret or RSA public key). Commonly used meanings are: key fingerprint (RSA); API Key How does it work? Inbound Signatures We act as a server and another party is calling us with a signed HTTP request. We validate the signature and assume identity of the caller. Outbound Signatures We act as a client and we sign our outgoing requests. If there is a matching outbound target specified in configuration, its configuration will be applied for signing the outgoing request, otherwise there is no signature added ",
            "title": "HTTP Signatures Provider"
        },
        {
            "location": "mp/security/providers",
            "text": "<markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-idcs-mapper&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Setup"
        },
        {
            "location": "mp/security/providers",
            "text": " IDCS role mapping provider Type: io.helidon.security.providers.idcs.mapper.IdcsRoleMapperRxProvider <markup lang=\"text\" title=\"Config key\" >idcs-role-mapper This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.SubjectMappingProvider ",
            "title": "Single-tenant IDCS Role Mapper"
        },
        {
            "location": "mp/security/providers",
            "text": " Optional configuration options key type default value description cache-config EvictableCache &#160; Use explicit io.helidon.security.providers.common.EvictableCache for role caching. default-idcs-subject-type string user Configure subject type to use when requesting roles from IDCS. Can be either #IDCS_SUBJECT_TYPE_USER or #IDCS_SUBJECT_TYPE_CLIENT. Defaults to #IDCS_SUBJECT_TYPE_USER. oidc-config OidcConfig &#160; Use explicit io.helidon.security.providers.oidc.common.OidcConfig instance, e.g. when using it also for OIDC provider. subject-types SubjectType[&#93; (USER, SERVICE) USER Add a supported subject type. If none added, io.helidon.security.SubjectType#USER is used. If any added, only the ones added will be used (e.g. if you want to use both io.helidon.security.SubjectType#USER and io.helidon.security.SubjectType#SERVICE, both need to be added. ",
            "title": "Configuration options"
        },
        {
            "location": "mp/security/providers",
            "text": " Multitenant IDCS role mapping provider Type: io.helidon.security.providers.idcs.mapper.IdcsMtRoleMapperRxProvider <markup lang=\"text\" title=\"Config key\" >idcs-role-mapper This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.SubjectMappingProvider ",
            "title": "Multi-tenant IDCS Role Mapper"
        },
        {
            "location": "mp/security/providers",
            "text": " Optional configuration options key type default value description cache-config EvictableCache &#160; Use explicit io.helidon.security.providers.common.EvictableCache for role caching. default-idcs-subject-type string user Configure subject type to use when requesting roles from IDCS. Can be either #IDCS_SUBJECT_TYPE_USER or #IDCS_SUBJECT_TYPE_CLIENT. Defaults to #IDCS_SUBJECT_TYPE_USER. idcs-app-name-handler TokenHandler &#160; Configure token handler for IDCS Application name. By default the header IdcsMtRoleMapperRxProvider#IDCS_APP_HEADER is used. idcs-tenant-handler TokenHandler &#160; Configure token handler for IDCS Tenant ID. By default the header IdcsMtRoleMapperRxProvider#IDCS_TENANT_HEADER is used. oidc-config OidcConfig &#160; Use explicit io.helidon.security.providers.oidc.common.OidcConfig instance, e.g. when using it also for OIDC provider. subject-types SubjectType[&#93; (USER, SERVICE) USER Add a supported subject type. If none added, io.helidon.security.SubjectType#USER is used. If any added, only the ones added will be used (e.g. if you want to use both io.helidon.security.SubjectType#USER and io.helidon.security.SubjectType#SERVICE, both need to be added. ",
            "title": "Configuration options"
        },
        {
            "location": "mp/security/providers",
            "text": " See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - idcs-role-mapper: multitenant: false oidc-config: client-id: \"client-id\" client-secret: \"client-secret\" identity-uri: \"IDCS identity server address\" ",
            "title": "Example code"
        },
        {
            "location": "mp/security/providers",
            "text": " The provider asks the IDCS server to provide list of roles for the currently authenticated user. The result is cached for a certain period of time (see cache-config above). ",
            "title": "How does it work?"
        },
        {
            "location": "mp/security/providers",
            "text": " A role mapper to retrieve roles from Oracle IDCS. Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-idcs-mapper&lt;/artifactId&gt; &lt;/dependency&gt; Single-tenant IDCS Role Mapper IDCS role mapping provider Type: io.helidon.security.providers.idcs.mapper.IdcsRoleMapperRxProvider <markup lang=\"text\" title=\"Config key\" >idcs-role-mapper This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.SubjectMappingProvider Configuration options Optional configuration options key type default value description cache-config EvictableCache &#160; Use explicit io.helidon.security.providers.common.EvictableCache for role caching. default-idcs-subject-type string user Configure subject type to use when requesting roles from IDCS. Can be either #IDCS_SUBJECT_TYPE_USER or #IDCS_SUBJECT_TYPE_CLIENT. Defaults to #IDCS_SUBJECT_TYPE_USER. oidc-config OidcConfig &#160; Use explicit io.helidon.security.providers.oidc.common.OidcConfig instance, e.g. when using it also for OIDC provider. subject-types SubjectType[&#93; (USER, SERVICE) USER Add a supported subject type. If none added, io.helidon.security.SubjectType#USER is used. If any added, only the ones added will be used (e.g. if you want to use both io.helidon.security.SubjectType#USER and io.helidon.security.SubjectType#SERVICE, both need to be added. Multi-tenant IDCS Role Mapper Multitenant IDCS role mapping provider Type: io.helidon.security.providers.idcs.mapper.IdcsMtRoleMapperRxProvider <markup lang=\"text\" title=\"Config key\" >idcs-role-mapper This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.SubjectMappingProvider Configuration options Optional configuration options key type default value description cache-config EvictableCache &#160; Use explicit io.helidon.security.providers.common.EvictableCache for role caching. default-idcs-subject-type string user Configure subject type to use when requesting roles from IDCS. Can be either #IDCS_SUBJECT_TYPE_USER or #IDCS_SUBJECT_TYPE_CLIENT. Defaults to #IDCS_SUBJECT_TYPE_USER. idcs-app-name-handler TokenHandler &#160; Configure token handler for IDCS Application name. By default the header IdcsMtRoleMapperRxProvider#IDCS_APP_HEADER is used. idcs-tenant-handler TokenHandler &#160; Configure token handler for IDCS Tenant ID. By default the header IdcsMtRoleMapperRxProvider#IDCS_TENANT_HEADER is used. oidc-config OidcConfig &#160; Use explicit io.helidon.security.providers.oidc.common.OidcConfig instance, e.g. when using it also for OIDC provider. subject-types SubjectType[&#93; (USER, SERVICE) USER Add a supported subject type. If none added, io.helidon.security.SubjectType#USER is used. If any added, only the ones added will be used (e.g. if you want to use both io.helidon.security.SubjectType#USER and io.helidon.security.SubjectType#SERVICE, both need to be added. Example code See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - idcs-role-mapper: multitenant: false oidc-config: client-id: \"client-id\" client-secret: \"client-secret\" identity-uri: \"IDCS identity server address\" How does it work? The provider asks the IDCS server to provide list of roles for the currently authenticated user. The result is cached for a certain period of time (see cache-config above). ",
            "title": "IDCS Role Mapper"
        },
        {
            "location": "mp/security/providers",
            "text": " Attribute Based Access Control provider Type: io.helidon.security.providers.abac.AbacProvider <markup lang=\"text\" title=\"Config key\" >abac This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthorizationProvider ",
            "title": "Overview"
        },
        {
            "location": "mp/security/providers",
            "text": " Optional configuration options key type default value description fail-if-none-validated boolean true Whether to fail if NONE of the attributes is validated. fail-on-unvalidated boolean true Whether to fail if any attribute is left unvalidated. ",
            "title": "Configuration options"
        },
        {
            "location": "mp/security/providers",
            "text": "<markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-abac&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Dependency"
        },
        {
            "location": "mp/security/providers",
            "text": " See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - abac: ",
            "title": "Examples"
        },
        {
            "location": "mp/security/providers",
            "text": " The following table shows all configuration options of the provider and their default values key default value description fail-on-unvalidated true \"Unvalidated\" means: an attribute is defined, but there is no validator available for it fail-if-none-validated true \"None validated\" means: there was not a single attribute that was validated ",
            "title": "Configuration Options"
        },
        {
            "location": "mp/security/providers",
            "text": " ABAC uses available validators and validates them against attributes of the authenticated user. Combinations of fail-on-unvalidated and fail-if-none-validated : true &amp; true : Will fail if any attribute is not validated and if any has failed validation false &amp; true : Will fail if there is one or more attributes present and NONE of them is validated or if any has failed validation, Will NOT fail if there is at least one validated attribute and any number of not validated attributes (and NONE failed) false &amp; false : Will fail if there is any attribute that failed validation, Will NOT fail if there are no failed validation or if there are NONE validated Any attribute of the following objects can be used: environment (such as time of request) - e.g. env.time.year subject (user) - e.g. subject.principal.id subject (service) - e.g. service.principal.id object (must be explicitly invoked by developer in code, as object cannot be automatically added to security context) - e.g. object.owner This provider checks that all defined ABAC validators are validated. If there is a definition for a validator that is not checked, the request is denied (depending on configuration as mentioned above). ABAC provider also allows an object to be used in authorization process, such as when evaluating if an object&#8217;s owner is the current user. The following example uses the Expression language validator to demonstrate the point in a JAX-RS resource: <markup lang=\"java\" title=\"Example of using an object\" >@Authenticated @Path(\"/abac\") public class AbacResource { @GET @Authorized(explicit = true) @PolicyStatement(\"${env.time.year &gt;= 2017 &amp;&amp; object.owner == subject.principal.id}\") public Response process(@Context SecurityContext context) { // probably looked up from a database SomeResource res = new SomeResource(\"user\"); AuthorizationResponse atzResponse = context.authorize(res); if (atzResponse.isPermitted()) { //do the update return Response.ok().entity(\"fine, sir\").build(); } else { return Response.status(Response.Status.FORBIDDEN) .entity(atzResponse.getDescription().orElse(\"Access not granted\")) .build(); } } } The following validators are implemented: Roles Scopes EL Policy ",
            "title": "Usage"
        },
        {
            "location": "mp/security/providers",
            "text": " When using sub-resource locators in JAX-RS, the roles allowed are collected from each \"level\" of execution: - Application class annotations - Resource class annotations + resource method annotations - Sub-resource class annotations + sub-resource method annotations - Sub-resource class annotations + sub-resource method annotations (for every sub-resource on the path) The RolesAllowed or Roles annotation to be used is the last one in the path as defined above. Example 1: There is a RolesAllowed(\"admin\") defined on a sub-resource locator resource class. In this case the required role is admin . Example 2: There is a RolesAllowed(\"admin\") defined on a sub-resource locator resource class and a RolesAllowed(\"user\") defined on the method of the sub-resource that provides the response. In this case the required role is user . ",
            "title": "Interaction with JAX-RS Sub-Resource Locators"
        },
        {
            "location": "mp/security/providers",
            "text": " Checks whether user/service is in either of the required role(s). Configuration Key: role-validator Annotations: @RolesAllowed , @RoleValidator.Roles <markup lang=\"yaml\" title=\"Configuration example for WebServer \" >security: web-server.paths: - path: \"/user[/{*}]\" roles-allowed: [\"user\"] <markup lang=\"java\" title=\"JAX-RS example\" >@RolesAllowed(\"user\") @RoleValidator.Roles(value = \"service_role\", subjectType = SubjectType.SERVICE) @Authenticated @Path(\"/abac\") public class AbacResource { } Interaction with JAX-RS Sub-Resource Locators When using sub-resource locators in JAX-RS, the roles allowed are collected from each \"level\" of execution: - Application class annotations - Resource class annotations + resource method annotations - Sub-resource class annotations + sub-resource method annotations - Sub-resource class annotations + sub-resource method annotations (for every sub-resource on the path) The RolesAllowed or Roles annotation to be used is the last one in the path as defined above. Example 1: There is a RolesAllowed(\"admin\") defined on a sub-resource locator resource class. In this case the required role is admin . Example 2: There is a RolesAllowed(\"admin\") defined on a sub-resource locator resource class and a RolesAllowed(\"user\") defined on the method of the sub-resource that provides the response. In this case the required role is user . ",
            "title": "Role Validator"
        },
        {
            "location": "mp/security/providers",
            "text": " Checks whether user has all the required scopes. Configuration Key: scope-validator Annotations: @Scope <markup lang=\"yaml\" title=\"Configuration example for WebServer \" >security: web-server.paths: - path: \"/user[/{*}]\" abac.scopes: [\"calendar_read\", \"calendar_edit\"] <markup lang=\"java\" title=\"JAX-RS example\" >@Scope(\"calendar_read\") @Scope(\"calendar_edit\") @Authenticated @Path(\"/abac\") public class AbacResource { } ",
            "title": "Scope Validator"
        },
        {
            "location": "mp/security/providers",
            "text": " Policy executor using Java EE policy expression language (EL) Configuration Key: policy-javax-el Annotations: @PolicyStatement Example of a policy statement: ${env.time.year &gt;= 2017} <markup lang=\"yaml\" title=\"Configuration example for WebServer \" >security: web-server.paths: - path: \"/user[/{*}]\" policy: statement: \"hasScopes('calendar_read','calendar_edit') AND timeOfDayBetween('8:15', '17:30')\" <markup lang=\"java\" title=\"JAX-RS example\" >@PolicyStatement(\"${env.time.year &gt;= 2017}\") @Authenticated @Path(\"/abac\") public class AbacResource { } ",
            "title": "Expression Language Policy Validator"
        },
        {
            "location": "mp/security/providers",
            "text": " Attribute-based Access Control (ABAC) authorization provider provides security and authorization service implementations. Overview Attribute Based Access Control provider Type: io.helidon.security.providers.abac.AbacProvider <markup lang=\"text\" title=\"Config key\" >abac This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthorizationProvider Configuration options Optional configuration options key type default value description fail-if-none-validated boolean true Whether to fail if NONE of the attributes is validated. fail-on-unvalidated boolean true Whether to fail if any attribute is left unvalidated. Maven Dependency <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-abac&lt;/artifactId&gt; &lt;/dependency&gt; Examples See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - abac: Configuration Options The following table shows all configuration options of the provider and their default values key default value description fail-on-unvalidated true \"Unvalidated\" means: an attribute is defined, but there is no validator available for it fail-if-none-validated true \"None validated\" means: there was not a single attribute that was validated Usage ABAC uses available validators and validates them against attributes of the authenticated user. Combinations of fail-on-unvalidated and fail-if-none-validated : true &amp; true : Will fail if any attribute is not validated and if any has failed validation false &amp; true : Will fail if there is one or more attributes present and NONE of them is validated or if any has failed validation, Will NOT fail if there is at least one validated attribute and any number of not validated attributes (and NONE failed) false &amp; false : Will fail if there is any attribute that failed validation, Will NOT fail if there are no failed validation or if there are NONE validated Any attribute of the following objects can be used: environment (such as time of request) - e.g. env.time.year subject (user) - e.g. subject.principal.id subject (service) - e.g. service.principal.id object (must be explicitly invoked by developer in code, as object cannot be automatically added to security context) - e.g. object.owner This provider checks that all defined ABAC validators are validated. If there is a definition for a validator that is not checked, the request is denied (depending on configuration as mentioned above). ABAC provider also allows an object to be used in authorization process, such as when evaluating if an object&#8217;s owner is the current user. The following example uses the Expression language validator to demonstrate the point in a JAX-RS resource: <markup lang=\"java\" title=\"Example of using an object\" >@Authenticated @Path(\"/abac\") public class AbacResource { @GET @Authorized(explicit = true) @PolicyStatement(\"${env.time.year &gt;= 2017 &amp;&amp; object.owner == subject.principal.id}\") public Response process(@Context SecurityContext context) { // probably looked up from a database SomeResource res = new SomeResource(\"user\"); AuthorizationResponse atzResponse = context.authorize(res); if (atzResponse.isPermitted()) { //do the update return Response.ok().entity(\"fine, sir\").build(); } else { return Response.status(Response.Status.FORBIDDEN) .entity(atzResponse.getDescription().orElse(\"Access not granted\")) .build(); } } } The following validators are implemented: Roles Scopes EL Policy Role Validator Checks whether user/service is in either of the required role(s). Configuration Key: role-validator Annotations: @RolesAllowed , @RoleValidator.Roles <markup lang=\"yaml\" title=\"Configuration example for WebServer \" >security: web-server.paths: - path: \"/user[/{*}]\" roles-allowed: [\"user\"] <markup lang=\"java\" title=\"JAX-RS example\" >@RolesAllowed(\"user\") @RoleValidator.Roles(value = \"service_role\", subjectType = SubjectType.SERVICE) @Authenticated @Path(\"/abac\") public class AbacResource { } Interaction with JAX-RS Sub-Resource Locators When using sub-resource locators in JAX-RS, the roles allowed are collected from each \"level\" of execution: - Application class annotations - Resource class annotations + resource method annotations - Sub-resource class annotations + sub-resource method annotations - Sub-resource class annotations + sub-resource method annotations (for every sub-resource on the path) The RolesAllowed or Roles annotation to be used is the last one in the path as defined above. Example 1: There is a RolesAllowed(\"admin\") defined on a sub-resource locator resource class. In this case the required role is admin . Example 2: There is a RolesAllowed(\"admin\") defined on a sub-resource locator resource class and a RolesAllowed(\"user\") defined on the method of the sub-resource that provides the response. In this case the required role is user . Scope Validator Checks whether user has all the required scopes. Configuration Key: scope-validator Annotations: @Scope <markup lang=\"yaml\" title=\"Configuration example for WebServer \" >security: web-server.paths: - path: \"/user[/{*}]\" abac.scopes: [\"calendar_read\", \"calendar_edit\"] <markup lang=\"java\" title=\"JAX-RS example\" >@Scope(\"calendar_read\") @Scope(\"calendar_edit\") @Authenticated @Path(\"/abac\") public class AbacResource { } Expression Language Policy Validator Policy executor using Java EE policy expression language (EL) Configuration Key: policy-javax-el Annotations: @PolicyStatement Example of a policy statement: ${env.time.year &gt;= 2017} <markup lang=\"yaml\" title=\"Configuration example for WebServer \" >security: web-server.paths: - path: \"/user[/{*}]\" policy: statement: \"hasScopes('calendar_read','calendar_edit') AND timeOfDayBetween('8:15', '17:30')\" <markup lang=\"java\" title=\"JAX-RS example\" >@PolicyStatement(\"${env.time.year &gt;= 2017}\") @Authenticated @Path(\"/abac\") public class AbacResource { } ",
            "title": "ABAC Provider"
        },
        {
            "location": "mp/security/providers",
            "text": "<markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-google-login&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Setup"
        },
        {
            "location": "mp/security/providers",
            "text": " Google Authentication provider Type: io.helidon.security.providers.google.login.GoogleTokenProvider <markup lang=\"text\" title=\"Config key\" >google-login This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthenticationProvider ",
            "title": "Overview"
        },
        {
            "location": "mp/security/providers",
            "text": " Optional configuration options key type default value description client-id string &#160; Google application client id, to validate that the token was generated by Google for us. optional boolean false If set to true, this provider will return io.helidon.security.SecurityResponse.SecurityStatus#ABSTAIN instead of failing in case of invalid request. outbound OutboundConfig &#160; Outbound configuration - a set of outbound targets that will have the token propagated. proxy-host string &#160; Set proxy host when talking to Google. proxy-port int 80 Set proxy port when talking to Google. realm string helidon Set the authentication realm to build challenge, defaults to \"helidon\". token TokenHandler &#x60;Authorization&#x60; header with &#x60;bearer&#x60; prefix Token provider to extract Google access token from request, defaults to \"Authorization\" header with a \"bearer \" prefix. ",
            "title": "Configuration options"
        },
        {
            "location": "mp/security/providers",
            "text": " See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - provider: client-id: \"Google client id\" ",
            "title": "Example code"
        },
        {
            "location": "mp/security/providers",
            "text": " We expect to receive a token (with sufficient scopes) from the inbound request, such as when using the Google login button on a page. The page has access to the token in javascript and can send it to backend with every request in a header field ( Authorization with `bearer ` prefix is assumed by default). Once we receive the token in Helidon, we parse it and: Validate if it timed out locally Return a cached response (see EvictableCache with default values) Otherwise verify using Google API - GoogleIdTokenVerifier We build a subject from the Google token with the following attributes filled (if in token): userId email name emailVerified locale family_name given_name picture (URL) Outbound security The token will be propagated to outbound calls if an outbound target exists that matches the invoked endpoint (see outbound configuration above). ",
            "title": "How does it work?"
        },
        {
            "location": "mp/security/providers",
            "text": " Authenticates a token from request against Google identity provider Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-google-login&lt;/artifactId&gt; &lt;/dependency&gt; Overview Google Authentication provider Type: io.helidon.security.providers.google.login.GoogleTokenProvider <markup lang=\"text\" title=\"Config key\" >google-login This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthenticationProvider Configuration options Optional configuration options key type default value description client-id string &#160; Google application client id, to validate that the token was generated by Google for us. optional boolean false If set to true, this provider will return io.helidon.security.SecurityResponse.SecurityStatus#ABSTAIN instead of failing in case of invalid request. outbound OutboundConfig &#160; Outbound configuration - a set of outbound targets that will have the token propagated. proxy-host string &#160; Set proxy host when talking to Google. proxy-port int 80 Set proxy port when talking to Google. realm string helidon Set the authentication realm to build challenge, defaults to \"helidon\". token TokenHandler &#x60;Authorization&#x60; header with &#x60;bearer&#x60; prefix Token provider to extract Google access token from request, defaults to \"Authorization\" header with a \"bearer \" prefix. Example code See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - provider: client-id: \"Google client id\" How does it work? We expect to receive a token (with sufficient scopes) from the inbound request, such as when using the Google login button on a page. The page has access to the token in javascript and can send it to backend with every request in a header field ( Authorization with `bearer ` prefix is assumed by default). Once we receive the token in Helidon, we parse it and: Validate if it timed out locally Return a cached response (see EvictableCache with default values) Otherwise verify using Google API - GoogleIdTokenVerifier We build a subject from the Google token with the following attributes filled (if in token): userId email name emailVerified locale family_name given_name picture (URL) Outbound security The token will be propagated to outbound calls if an outbound target exists that matches the invoked endpoint (see outbound configuration above). ",
            "title": "Google Login Provider"
        },
        {
            "location": "mp/security/providers",
            "text": "<markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-jwt&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Setup"
        },
        {
            "location": "mp/security/providers",
            "text": " JWT authentication provider Type: io.helidon.security.providers.jwt.JwtProvider <markup lang=\"text\" title=\"Config key\" >jwt This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthenticationProvider ",
            "title": "Overview"
        },
        {
            "location": "mp/security/providers",
            "text": " Optional configuration options key type default value description allow-impersonation boolean false Whether to allow impersonation by explicitly overriding username from outbound requests using #EP_PROPERTY_OUTBOUND_USER property. By default this is not allowed and identity can only be propagated. allow-unsigned boolean false Configure support for unsigned JWT. If this is set to true any JWT that has algorithm set to none and no kid defined will be accepted. Note that this has serious security impact - if JWT can be sent from a third party, this allows the third party to send ANY JWT and it would be accpted as valid. atn-token.handler TokenHandler &#160; Token handler to extract username from request. atn-token.jwk.resource Resource &#160; JWK resource used to verify JWTs created by other parties. atn-token.jwt-audience string &#160; Audience expected in inbound JWTs. atn-token.verify-signature boolean true Configure whether to verify signatures. Signatures verification is enabled by default. You can configure the provider not to verify signatures. &lt;b&gt;Make sure your service is properly secured on network level and only accessible from a secure endpoint that provides the JWTs when signature verification is disabled. If signature verification is disabled, this service will accept &lt;i&gt;ANY&lt;/i&gt; JWT&lt;/b&gt; authenticate boolean true Whether to authenticate requests. optional boolean false Whether authentication is required. By default, request will fail if the username cannot be extracted. If set to false, request will process and this provider will abstain. principal-type SubjectType (USER, SERVICE) USER Principal type this provider extracts (and also propagates). propagate boolean true Whether to propagate identity. sign-token OutboundConfig &#160; Configuration of outbound rules. sign-token.jwk.resource Resource &#160; JWK resource used to sign JWTs created by us. sign-token.jwt-issuer string &#160; Issuer used to create new JWTs. use-jwt-groups boolean true Claim groups from JWT will be used to automatically add groups to current subject (may be used with jakarta.annotation.security.RolesAllowed annotation). ",
            "title": "Configuration options"
        },
        {
            "location": "mp/security/providers",
            "text": " See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - provider: atn-token: jwk.resource.resource-path: \"verifying-jwk.json\" jwt-audience: \"http://my.service\" sign-token: jwk.resource.resource-path: \"signing-jwk.json\" jwt-issuer: \"http://my.server/identity\" outbound: - name: \"propagate-token\" hosts: [\"*.internal.org\"] - name: \"generate-token\" hosts: [\"1.partner-service\"] jwk-kid: \"partner-1\" jwt-kid: \"helidon\" jwt-audience: \"http://1.partner-service\" ",
            "title": "Example code"
        },
        {
            "location": "mp/security/providers",
            "text": " JSON Web Token (JWT) provider has support for authentication and outbound security. Authentication is based on validating the token (signature, valid before etc.) and on asserting the subject of the JWT subject claim. For outbound, we support either token propagation (e.g. the token from request is propagated further) or support for generating a brand new token based on configuration of this provider. ",
            "title": "How does it work?"
        },
        {
            "location": "mp/security/providers",
            "text": " JWT token authentication and outbound security provider. Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-jwt&lt;/artifactId&gt; &lt;/dependency&gt; Overview JWT authentication provider Type: io.helidon.security.providers.jwt.JwtProvider <markup lang=\"text\" title=\"Config key\" >jwt This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthenticationProvider Configuration options Optional configuration options key type default value description allow-impersonation boolean false Whether to allow impersonation by explicitly overriding username from outbound requests using #EP_PROPERTY_OUTBOUND_USER property. By default this is not allowed and identity can only be propagated. allow-unsigned boolean false Configure support for unsigned JWT. If this is set to true any JWT that has algorithm set to none and no kid defined will be accepted. Note that this has serious security impact - if JWT can be sent from a third party, this allows the third party to send ANY JWT and it would be accpted as valid. atn-token.handler TokenHandler &#160; Token handler to extract username from request. atn-token.jwk.resource Resource &#160; JWK resource used to verify JWTs created by other parties. atn-token.jwt-audience string &#160; Audience expected in inbound JWTs. atn-token.verify-signature boolean true Configure whether to verify signatures. Signatures verification is enabled by default. You can configure the provider not to verify signatures. &lt;b&gt;Make sure your service is properly secured on network level and only accessible from a secure endpoint that provides the JWTs when signature verification is disabled. If signature verification is disabled, this service will accept &lt;i&gt;ANY&lt;/i&gt; JWT&lt;/b&gt; authenticate boolean true Whether to authenticate requests. optional boolean false Whether authentication is required. By default, request will fail if the username cannot be extracted. If set to false, request will process and this provider will abstain. principal-type SubjectType (USER, SERVICE) USER Principal type this provider extracts (and also propagates). propagate boolean true Whether to propagate identity. sign-token OutboundConfig &#160; Configuration of outbound rules. sign-token.jwk.resource Resource &#160; JWK resource used to sign JWTs created by us. sign-token.jwt-issuer string &#160; Issuer used to create new JWTs. use-jwt-groups boolean true Claim groups from JWT will be used to automatically add groups to current subject (may be used with jakarta.annotation.security.RolesAllowed annotation). Example code See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - provider: atn-token: jwk.resource.resource-path: \"verifying-jwk.json\" jwt-audience: \"http://my.service\" sign-token: jwk.resource.resource-path: \"signing-jwk.json\" jwt-issuer: \"http://my.server/identity\" outbound: - name: \"propagate-token\" hosts: [\"*.internal.org\"] - name: \"generate-token\" hosts: [\"1.partner-service\"] jwk-kid: \"partner-1\" jwt-kid: \"helidon\" jwt-audience: \"http://1.partner-service\" How does it work? JSON Web Token (JWT) provider has support for authentication and outbound security. Authentication is based on validating the token (signature, valid before etc.) and on asserting the subject of the JWT subject claim. For outbound, we support either token propagation (e.g. the token from request is propagated further) or support for generating a brand new token based on configuration of this provider. ",
            "title": "JWT Provider"
        },
        {
            "location": "mp/security/providers",
            "text": " As an experimental feature, you can set up cross-origin handling for the redirect and logout endpoints in an optional cors block inside the oidc configuration. The table below lists the configuration keys that identify the CORS characteristics. include::[tag=cors-config-table] The following example of basic cross-origin configuration limits cross-origin resource sharing for PUT and DELETE operations to only foo.com and there.com : <markup lang=\"yaml\" >allow-origins: [\"http://foo.com\", \"http://there.com\"] allow-methods: [\"PUT\", \"DELETE\"] HTTP Basic Authentication Provider HTTP Basic authentication support Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-http-auth&lt;/artifactId&gt; &lt;/dependency&gt; Overview HTTP Basic Authentication provider Type: io.helidon.security.providers.httpauth.HttpBasicAuthProvider <markup lang=\"text\" title=\"Config key\" >http-basic-auth This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthenticationProvider Configuration options Optional configuration options key type default value description optional boolean false Whether authentication is required. By default, request will fail if the authentication cannot be verified. If set to false, request will process and this provider will abstain. outbound OutboundTarget[&#93; &#160; Add a new outbound target to configure identity propagation or explicit username/password. principal-type SubjectType (USER, SERVICE) USER Principal type this provider extracts (and also propagates). realm string helidon Set the realm to use when challenging users. users ConfigUser[&#93; &#160; Set user store to validate users. Removes any other stores added through #addUserStore(SecureUserStore). Example code See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - http-basic-auth: realm: \"helidon\" users: - login: \"john\" password: \"${CLEAR=password}\" roles: [\"admin\"] - login: \"jack\" password: \"password\" roles: [\"user\", \"admin\"] outbound: - name: \"internal-services\" hosts: [\"*.example.org\"] # Propagates current user's identity or identity from request property outbound-token: header: \"X-Internal-Auth\" - name: \"partner-service\" hosts: [\"*.partner.org\"] # Uses this username and password username: \"partner-user-1\" password: \"${CLEAR=password}\" How does it work? See https://tools.ietf.org/html/rfc7617 . Authentication of request When a request is received without the Authorization: basic &#8230;&#8203;. header, a challenge is returned to provide such authentication. When a request is received with the Authorization: basic &#8230;&#8203;. header, the username and password is validated against configured users (and users obtained from custom service if any provided). Subject is created based on the username and roles provided by the user store. Identity propagation When identity propagation is configured, there are several options for identifying username and password to propagate: We propagate the current username and password (inbound request must be authenticated using basic authentication). We use username and password from an explicitly configured property (See HttpBasicAuthProvider.EP_PROPERTY_OUTBOUND_USER and HttpBasicAuthProvider.EP_PROPERTY_OUTBOUND_PASSWORD ) We use username and password associated with an outbound target (see example configuration above) Identity is propagated only if: There is an outbound target configured for the endpoint Or there is an explicitly configured username/password for the current request (through request property) Custom user store Java service loader service io.helidon.security.providers.httpauth.spi.UserStoreService can be implemented to provide users to the provider, such as when validated against an internal database or LDAP server. The user store is defined so you never need the clear text password of the user. Warning on security of HTTP Basic Authenticaton (or lack thereof) Basic authentication uses base64 encoded username and password and passes it over the network. Base64 is only encoding, not encryption - so anybody that gets hold of the header value can learn the actual username and password of the user. This is a security risk and an attack vector that everybody should be aware of before using HTTP Basic Authentication. We recommend using this approach only for testing and demo purposes. HTTP Digest Authentication Provider HTTP Digest authentication support Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-http-auth&lt;/artifactId&gt; &lt;/dependency&gt; Overview Http digest authentication security provider Type: io.helidon.security.providers.httpauth.HttpDigestAuthProvider <markup lang=\"text\" title=\"Config key\" >http-digest-auth This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthenticationProvider Configuration options Optional configuration options key type default value description algorithm Algorithm (MD5) MD5 Digest algorithm to use. nonce-timeout-millis long 86400000 How long will the nonce value be valid. When timed-out, browser will re-request username/password. optional boolean false Whether authentication is required. By default, request will fail if the authentication cannot be verified. If set to false, request will process and this provider will abstain. principal-type SubjectType (USER, SERVICE) USER Principal type this provider extracts (and also propagates). qop Qop (NONE, AUTH) NONE Only AUTH supported. If left empty, uses the legacy approach (older RFC version). AUTH-INT is not supported. realm string Helidon Set the realm to use when challenging users. server-secret string &#160; The nonce is encrypted using this secret - to make sure the nonce we get back was generated by us and to make sure we can safely time-out nonce values. This secret must be the same for all service instances (or all services that want to share the same authentication). Defaults to a random password - e.g. if deployed to multiple servers, the authentication WILL NOT WORK. You MUST provide your own password to work in a distributed environment with non-sticky load balancing. users ConfigUser[&#93; &#160; Set user store to obtain passwords and roles based on logins. Example code <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - http-digest-auth: realm: \"helidon\" server-secret: \"${CLEAR=service-wide-secret-not-known-outside}\" users: - login: \"john\" password: \"${CLEAR=password}\" roles: [\"admin\"] - login: \"jack\" password: \"password\" roles: [\"user\", \"admin\"] How does it work? See https://tools.ietf.org/html/rfc7616 . Authentication of request When a request is received without the Authorization: digest &#8230;&#8203;. header, a challenge is returned to provide such authentication using WWW-Authenticate header. When a request is received with the Authorization: digest &#8230;&#8203;. header, the request is validated against configured users (and users obtained from custom service if any provided). Subject is created based on the username and roles provided by the user store. Custom user store Java service loader service io.helidon.security.providers.httpauth.spi.UserStoreService can be implemented to provide users to the provider, such as when validated against an internal database or LDAP server. The user store is defined so you never need the clear text password of the user. Note on security of HTTP Digest Authenticaton These authentication schemes should be obsolete , though they provide a very easy way to test a protected resource. Header Authentication Provider Asserts user or service identity based on a value of a header. Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-header&lt;/artifactId&gt; &lt;/dependency&gt; Overview Security provider that extracts a username (or service name) from a header. Type: io.helidon.security.providers.header.HeaderAtnProvider <markup lang=\"text\" title=\"Config key\" >header-atn This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthenticationProvider Configuration options Optional configuration options key type default value description atn-token TokenHandler &#160; Token handler to extract username from request. authenticate boolean true Whether to authenticate requests. optional boolean false Whether authentication is required. By default, request will fail if the username cannot be extracted. If set to false, request will process and this provider will abstain. outbound OutboundTarget[&#93; &#160; Configure outbound target for identity propagation. outbound-token TokenHandler &#160; Token handler to create outbound headers to propagate identity. If not defined, #atnTokenHandler will be used. principal-type SubjectType (USER, SERVICE) USER Principal type this provider extracts (and also propagates). propagate boolean false Whether to propagate identity. Example code <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: header-atn: atn-token: header: \"X-AUTH-USER\" outbound: - name: \"internal-services\" hosts: [\"*.example.org\"] # propagates the current user or service id using the same header as authentication - name: \"partner-service\" hosts: [\"*.partner.org\"] # propagates an explicit username in a custom header username: \"service-27\" outbound-token: header: \"X-Service-Auth\" How does it work? This provider inspects a specified request header and extracts the username/service name from it and asserts it as current subject&#8217;s principal. This can be used when we use perimeter authentication (e.g. there is a gateway that takes care of authentication and propagates the user in a header). Identity propagation Identity is propagated only if an outbound target matches the target service. The following options exist when propagating identity: 1. We propagate the current username using the configured header 2. We use username associated with an outbound target (see example configuration above) Caution When using this provider, you must be sure the header cannot be explicitly configured by a user or another service. All requests should go through a gateway that removes this header from inbound traffic, and only configures it for authenticated users/services. Another option is to use this with fully trusted parties (such as services within a single company, on a single protected network not accessible to any users), and of course for testing and demo purposes. HTTP Signatures Provider Support for HTTP Signatures. Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-http-sign&lt;/artifactId&gt; &lt;/dependency&gt; Overview HTTP header signature provider. Type: io.helidon.security.providers.httpsign.HttpSignProvider <markup lang=\"text\" title=\"Config key\" >http-signatures This type provides the following service implementations: io.helidon.security.spi.AuthenticationProvider Configuration options Optional configuration options key type default value description backward-compatible-eol boolean false Enable support for Helidon versions before 3.0.0 (exclusive). Until version 3.0.0 (exclusive) there was a trailing end of line added to the signed data. To be able to communicate cross versions, we must configure this when talking to older versions of Helidon. Default value is `false`. In Helidon 2.x, this switch exists as well and the default is `true`, to allow communication between versions as needed. headers HttpSignHeader[&#93; (SIGNATURE, AUTHORIZATION, CUSTOM) &#160; Add a header that is validated on inbound requests. Provider may support more than one header to validate. inbound.keys InboundClientDefinition[&#93; &#160; Add inbound configuration. This is used to validate signature and authenticate the party. The same can be done through configuration: &lt;pre&gt; { name = \"http-signatures\" class = \"HttpSignProvider\" http-signatures { inbound { # This configures the InboundClientDefinition keys: [ { key-id = \"service1\" hmac.secret = \"${CLEAR=password}\" }] } } } &lt;/pre&gt; optional boolean true Set whether the signature is optional. If set to true (default), this provider will SecurityResponse.SecurityStatus#ABSTAIN from this request if signature is not present. If set to false, this provider will SecurityResponse.SecurityStatus#FAILURE fail if signature is not present. outbound OutboundConfig &#160; Add outbound targets to this builder. The targets are used to chose what to do for outbound communication. The targets should have OutboundTargetDefinition attached through OutboundTarget.Builder#customObject(Class, Object) to tell us how to sign the request. The same can be done through configuration: &lt;pre&gt; { name = \"http-signatures\" class = \"HttpSignProvider\" http-signatures { targets: [ { name = \"service2\" hosts = [\"localhost\"] paths = [\"/service2/.*\"] # This configures the OutboundTargetDefinition signature { key-id = \"service1\" hmac.secret = \"${CLEAR=password}\" } }] } } &lt;/pre&gt; realm string helidon Realm to use for challenging inbound requests that do not have \"Authorization\" header in case header is HttpSignHeader#AUTHORIZATION and singatures are not optional. sign-headers HeadersConfig[&#93; &#160; Override the default inbound required headers (e.g. headers that MUST be signed and headers that MUST be signed IF present). Defaults: get, head, delete methods: date, (request-target), host are mandatory; authorization if present (unless we are creating/validating the HttpSignHeader#AUTHORIZATION ourselves put, post: same as above, with addition of: content-length, content-type and digest if present for other methods: date, (request-target) Note that this provider DOES NOT validate the \"Digest\" HTTP header, only the signature. Example code See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - http-signatures: inbound: keys: - key-id: \"service1-hmac\" principal-name: \"Service1 - HMAC signature\" hmac.secret: \"${CLEAR=somePasswordForHmacShouldBeEncrypted}\" - key-id: \"service1-rsa\" principal-name: \"Service1 - RSA signature\" public-key: keystore: resource.path: \"src/main/resources/keystore.p12\" passphrase: \"password\" cert.alias: \"service_cert\" outbound: - name: \"service2-hmac\" hosts: [\"localhost\"] paths: [\"/service2\"] signature: key-id: \"service1-hmac\" hmac.secret: \"${CLEAR=somePasswordForHmacShouldBeEncrypted}\" - name: \"service2-rsa\" hosts: [\"localhost\"] paths: [\"/service2-rsa.*\"] signature: key-id: \"service1-rsa\" private-key: keystore: resource.path: \"src/main/resources/keystore.p12\" passphrase: \"password\" key.alias: \"myPrivateKey\" Signature basics standard: based on https://tools.ietf.org/html/draft-cavage-http-signatures-03 key-id: an arbitrary string used to locate signature configuration - when a request is received the provider locates validation configuration based on this id (e.g. HMAC shared secret or RSA public key). Commonly used meanings are: key fingerprint (RSA); API Key How does it work? Inbound Signatures We act as a server and another party is calling us with a signed HTTP request. We validate the signature and assume identity of the caller. Outbound Signatures We act as a client and we sign our outgoing requests. If there is a matching outbound target specified in configuration, its configuration will be applied for signing the outgoing request, otherwise there is no signature added IDCS Role Mapper A role mapper to retrieve roles from Oracle IDCS. Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-idcs-mapper&lt;/artifactId&gt; &lt;/dependency&gt; Single-tenant IDCS Role Mapper IDCS role mapping provider Type: io.helidon.security.providers.idcs.mapper.IdcsRoleMapperRxProvider <markup lang=\"text\" title=\"Config key\" >idcs-role-mapper This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.SubjectMappingProvider Configuration options Optional configuration options key type default value description cache-config EvictableCache &#160; Use explicit io.helidon.security.providers.common.EvictableCache for role caching. default-idcs-subject-type string user Configure subject type to use when requesting roles from IDCS. Can be either #IDCS_SUBJECT_TYPE_USER or #IDCS_SUBJECT_TYPE_CLIENT. Defaults to #IDCS_SUBJECT_TYPE_USER. oidc-config OidcConfig &#160; Use explicit io.helidon.security.providers.oidc.common.OidcConfig instance, e.g. when using it also for OIDC provider. subject-types SubjectType[&#93; (USER, SERVICE) USER Add a supported subject type. If none added, io.helidon.security.SubjectType#USER is used. If any added, only the ones added will be used (e.g. if you want to use both io.helidon.security.SubjectType#USER and io.helidon.security.SubjectType#SERVICE, both need to be added. Multi-tenant IDCS Role Mapper Multitenant IDCS role mapping provider Type: io.helidon.security.providers.idcs.mapper.IdcsMtRoleMapperRxProvider <markup lang=\"text\" title=\"Config key\" >idcs-role-mapper This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.SubjectMappingProvider Configuration options Optional configuration options key type default value description cache-config EvictableCache &#160; Use explicit io.helidon.security.providers.common.EvictableCache for role caching. default-idcs-subject-type string user Configure subject type to use when requesting roles from IDCS. Can be either #IDCS_SUBJECT_TYPE_USER or #IDCS_SUBJECT_TYPE_CLIENT. Defaults to #IDCS_SUBJECT_TYPE_USER. idcs-app-name-handler TokenHandler &#160; Configure token handler for IDCS Application name. By default the header IdcsMtRoleMapperRxProvider#IDCS_APP_HEADER is used. idcs-tenant-handler TokenHandler &#160; Configure token handler for IDCS Tenant ID. By default the header IdcsMtRoleMapperRxProvider#IDCS_TENANT_HEADER is used. oidc-config OidcConfig &#160; Use explicit io.helidon.security.providers.oidc.common.OidcConfig instance, e.g. when using it also for OIDC provider. subject-types SubjectType[&#93; (USER, SERVICE) USER Add a supported subject type. If none added, io.helidon.security.SubjectType#USER is used. If any added, only the ones added will be used (e.g. if you want to use both io.helidon.security.SubjectType#USER and io.helidon.security.SubjectType#SERVICE, both need to be added. Example code See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - idcs-role-mapper: multitenant: false oidc-config: client-id: \"client-id\" client-secret: \"client-secret\" identity-uri: \"IDCS identity server address\" How does it work? The provider asks the IDCS server to provide list of roles for the currently authenticated user. The result is cached for a certain period of time (see cache-config above). ABAC Provider Attribute-based Access Control (ABAC) authorization provider provides security and authorization service implementations. Overview Attribute Based Access Control provider Type: io.helidon.security.providers.abac.AbacProvider <markup lang=\"text\" title=\"Config key\" >abac This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthorizationProvider Configuration options Optional configuration options key type default value description fail-if-none-validated boolean true Whether to fail if NONE of the attributes is validated. fail-on-unvalidated boolean true Whether to fail if any attribute is left unvalidated. Maven Dependency <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-abac&lt;/artifactId&gt; &lt;/dependency&gt; Examples See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - abac: Configuration Options The following table shows all configuration options of the provider and their default values key default value description fail-on-unvalidated true \"Unvalidated\" means: an attribute is defined, but there is no validator available for it fail-if-none-validated true \"None validated\" means: there was not a single attribute that was validated Usage ABAC uses available validators and validates them against attributes of the authenticated user. Combinations of fail-on-unvalidated and fail-if-none-validated : true &amp; true : Will fail if any attribute is not validated and if any has failed validation false &amp; true : Will fail if there is one or more attributes present and NONE of them is validated or if any has failed validation, Will NOT fail if there is at least one validated attribute and any number of not validated attributes (and NONE failed) false &amp; false : Will fail if there is any attribute that failed validation, Will NOT fail if there are no failed validation or if there are NONE validated Any attribute of the following objects can be used: environment (such as time of request) - e.g. env.time.year subject (user) - e.g. subject.principal.id subject (service) - e.g. service.principal.id object (must be explicitly invoked by developer in code, as object cannot be automatically added to security context) - e.g. object.owner This provider checks that all defined ABAC validators are validated. If there is a definition for a validator that is not checked, the request is denied (depending on configuration as mentioned above). ABAC provider also allows an object to be used in authorization process, such as when evaluating if an object&#8217;s owner is the current user. The following example uses the Expression language validator to demonstrate the point in a JAX-RS resource: <markup lang=\"java\" title=\"Example of using an object\" >@Authenticated @Path(\"/abac\") public class AbacResource { @GET @Authorized(explicit = true) @PolicyStatement(\"${env.time.year &gt;= 2017 &amp;&amp; object.owner == subject.principal.id}\") public Response process(@Context SecurityContext context) { // probably looked up from a database SomeResource res = new SomeResource(\"user\"); AuthorizationResponse atzResponse = context.authorize(res); if (atzResponse.isPermitted()) { //do the update return Response.ok().entity(\"fine, sir\").build(); } else { return Response.status(Response.Status.FORBIDDEN) .entity(atzResponse.getDescription().orElse(\"Access not granted\")) .build(); } } } The following validators are implemented: Roles Scopes EL Policy Role Validator Checks whether user/service is in either of the required role(s). Configuration Key: role-validator Annotations: @RolesAllowed , @RoleValidator.Roles <markup lang=\"yaml\" title=\"Configuration example for WebServer \" >security: web-server.paths: - path: \"/user[/{*}]\" roles-allowed: [\"user\"] <markup lang=\"java\" title=\"JAX-RS example\" >@RolesAllowed(\"user\") @RoleValidator.Roles(value = \"service_role\", subjectType = SubjectType.SERVICE) @Authenticated @Path(\"/abac\") public class AbacResource { } Interaction with JAX-RS Sub-Resource Locators When using sub-resource locators in JAX-RS, the roles allowed are collected from each \"level\" of execution: - Application class annotations - Resource class annotations + resource method annotations - Sub-resource class annotations + sub-resource method annotations - Sub-resource class annotations + sub-resource method annotations (for every sub-resource on the path) The RolesAllowed or Roles annotation to be used is the last one in the path as defined above. Example 1: There is a RolesAllowed(\"admin\") defined on a sub-resource locator resource class. In this case the required role is admin . Example 2: There is a RolesAllowed(\"admin\") defined on a sub-resource locator resource class and a RolesAllowed(\"user\") defined on the method of the sub-resource that provides the response. In this case the required role is user . Scope Validator Checks whether user has all the required scopes. Configuration Key: scope-validator Annotations: @Scope <markup lang=\"yaml\" title=\"Configuration example for WebServer \" >security: web-server.paths: - path: \"/user[/{*}]\" abac.scopes: [\"calendar_read\", \"calendar_edit\"] <markup lang=\"java\" title=\"JAX-RS example\" >@Scope(\"calendar_read\") @Scope(\"calendar_edit\") @Authenticated @Path(\"/abac\") public class AbacResource { } Expression Language Policy Validator Policy executor using Java EE policy expression language (EL) Configuration Key: policy-javax-el Annotations: @PolicyStatement Example of a policy statement: ${env.time.year &gt;= 2017} <markup lang=\"yaml\" title=\"Configuration example for WebServer \" >security: web-server.paths: - path: \"/user[/{*}]\" policy: statement: \"hasScopes('calendar_read','calendar_edit') AND timeOfDayBetween('8:15', '17:30')\" <markup lang=\"java\" title=\"JAX-RS example\" >@PolicyStatement(\"${env.time.year &gt;= 2017}\") @Authenticated @Path(\"/abac\") public class AbacResource { } Google Login Provider Authenticates a token from request against Google identity provider Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-google-login&lt;/artifactId&gt; &lt;/dependency&gt; Overview Google Authentication provider Type: io.helidon.security.providers.google.login.GoogleTokenProvider <markup lang=\"text\" title=\"Config key\" >google-login This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthenticationProvider Configuration options Optional configuration options key type default value description client-id string &#160; Google application client id, to validate that the token was generated by Google for us. optional boolean false If set to true, this provider will return io.helidon.security.SecurityResponse.SecurityStatus#ABSTAIN instead of failing in case of invalid request. outbound OutboundConfig &#160; Outbound configuration - a set of outbound targets that will have the token propagated. proxy-host string &#160; Set proxy host when talking to Google. proxy-port int 80 Set proxy port when talking to Google. realm string helidon Set the authentication realm to build challenge, defaults to \"helidon\". token TokenHandler &#x60;Authorization&#x60; header with &#x60;bearer&#x60; prefix Token provider to extract Google access token from request, defaults to \"Authorization\" header with a \"bearer \" prefix. Example code See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - provider: client-id: \"Google client id\" How does it work? We expect to receive a token (with sufficient scopes) from the inbound request, such as when using the Google login button on a page. The page has access to the token in javascript and can send it to backend with every request in a header field ( Authorization with `bearer ` prefix is assumed by default). Once we receive the token in Helidon, we parse it and: Validate if it timed out locally Return a cached response (see EvictableCache with default values) Otherwise verify using Google API - GoogleIdTokenVerifier We build a subject from the Google token with the following attributes filled (if in token): userId email name emailVerified locale family_name given_name picture (URL) Outbound security The token will be propagated to outbound calls if an outbound target exists that matches the invoked endpoint (see outbound configuration above). JWT Provider JWT token authentication and outbound security provider. Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-jwt&lt;/artifactId&gt; &lt;/dependency&gt; Overview JWT authentication provider Type: io.helidon.security.providers.jwt.JwtProvider <markup lang=\"text\" title=\"Config key\" >jwt This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthenticationProvider Configuration options Optional configuration options key type default value description allow-impersonation boolean false Whether to allow impersonation by explicitly overriding username from outbound requests using #EP_PROPERTY_OUTBOUND_USER property. By default this is not allowed and identity can only be propagated. allow-unsigned boolean false Configure support for unsigned JWT. If this is set to true any JWT that has algorithm set to none and no kid defined will be accepted. Note that this has serious security impact - if JWT can be sent from a third party, this allows the third party to send ANY JWT and it would be accpted as valid. atn-token.handler TokenHandler &#160; Token handler to extract username from request. atn-token.jwk.resource Resource &#160; JWK resource used to verify JWTs created by other parties. atn-token.jwt-audience string &#160; Audience expected in inbound JWTs. atn-token.verify-signature boolean true Configure whether to verify signatures. Signatures verification is enabled by default. You can configure the provider not to verify signatures. &lt;b&gt;Make sure your service is properly secured on network level and only accessible from a secure endpoint that provides the JWTs when signature verification is disabled. If signature verification is disabled, this service will accept &lt;i&gt;ANY&lt;/i&gt; JWT&lt;/b&gt; authenticate boolean true Whether to authenticate requests. optional boolean false Whether authentication is required. By default, request will fail if the username cannot be extracted. If set to false, request will process and this provider will abstain. principal-type SubjectType (USER, SERVICE) USER Principal type this provider extracts (and also propagates). propagate boolean true Whether to propagate identity. sign-token OutboundConfig &#160; Configuration of outbound rules. sign-token.jwk.resource Resource &#160; JWK resource used to sign JWTs created by us. sign-token.jwt-issuer string &#160; Issuer used to create new JWTs. use-jwt-groups boolean true Claim groups from JWT will be used to automatically add groups to current subject (may be used with jakarta.annotation.security.RolesAllowed annotation). Example code See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - provider: atn-token: jwk.resource.resource-path: \"verifying-jwk.json\" jwt-audience: \"http://my.service\" sign-token: jwk.resource.resource-path: \"signing-jwk.json\" jwt-issuer: \"http://my.server/identity\" outbound: - name: \"propagate-token\" hosts: [\"*.internal.org\"] - name: \"generate-token\" hosts: [\"1.partner-service\"] jwk-kid: \"partner-1\" jwt-kid: \"helidon\" jwt-audience: \"http://1.partner-service\" How does it work? JSON Web Token (JWT) provider has support for authentication and outbound security. Authentication is based on validating the token (signature, valid before etc.) and on asserting the subject of the JWT subject claim. For outbound, we support either token propagation (e.g. the token from request is propagated further) or support for generating a brand new token based on configuration of this provider. ",
            "title": "CORS Settings"
        },
        {
            "location": "mp/security/security",
            "text": " To add security, such as protecting resource methods with authentication, to a MicroProfile application, add the Helidon security integration dependency to your project. ",
            "title": "preambule"
        },
        {
            "location": "mp/security/security",
            "text": " For JAX-RS resources, declare security by adding annotations to a resource class or method. <markup lang=\"java\" title=\"Protected resource method\" >@GET @io.helidon.security.annotations.Authenticated @io.helidon.security.annotations.Authorized // you can also use io.helidon.security.abac.role.RoleValidator.Roles @RolesAllowed(\"admin\") public String adminResource(@Context io.helidon.security.SecurityContext securityContext) { return \"you are \" + securityContext.userName(); } Security in Helidon MicroProfile is built on top of Jersey&#8217;s and can be enabled/disabled using the property security.jersey.enabled=[true|false] . ",
            "title": "Securing a JAX-RS Resource"
        },
        {
            "location": "mp/security/security",
            "text": " The configuration is usually placed under security.web-server (this can be customized in Helidon SE). The following example shows how to configure the application.yaml using customized setting: <markup lang=\"yaml\" title=\"application.yaml\" >security: providers: - abac: - provider-key: web-server: defaults: authenticate: true paths: - path: \"/metrics[/{*}]\" roles-allowed: \"admin\" - path: \"/health[/{*}]\" roles-allowed: \"monitor\" - path: \"/openapi[/{*}]\" abac: scopes: [\"openapi\"] - path: \"/static[/{*}]\" roles-allowed: [\"user\", \"monitor\"] Attribute based access control provider that checks roles and scopes The provider(s) used in your application, such as oidc Default configuration for all configured paths Protection of /metrics and all nested paths with admin role required Protection of /health and all nested paths with monitor role required Protection of /openapi and all nested paths with openapi scope required Protection of static content configured on /static path with either user or monitor role required If you need to use a properties file, such as microprofile-config.properties , you can convert the file by using index based numbers for arrays, such as: <markup lang=\"properties\" title=\"microprofile-config.properties\" >security.providers.0.abac= security.providers.1.provider-key.optional=false security.web-server.defaults.authenticate=true security.web-server.paths.0.path=/metrics[/{*}] security.web-server.paths.0.roles-allowed=admin security.web-server.paths.3.path=/static[/{*}] security.web-server.paths.3.roles-allowed=user,monitor ",
            "title": "Configuring Endpoint Protection"
        },
        {
            "location": "mp/security/security",
            "text": " There are several endpoints provided by Helidon services, such as: Health endpoint ( /health ) Metrics endpoint ( /metrics ) OpenAPI endpoint ( /openapi ) Configured static content (can use any path configured) These endpoints are all implemented using Helidon reactive WebServer and as such can be protected only through Security integration with WebServer. The following section describes configuration of such protection using configuration files, in this case using a yaml file, as it provides a tree structure. Configuring Endpoint Protection The configuration is usually placed under security.web-server (this can be customized in Helidon SE). The following example shows how to configure the application.yaml using customized setting: <markup lang=\"yaml\" title=\"application.yaml\" >security: providers: - abac: - provider-key: web-server: defaults: authenticate: true paths: - path: \"/metrics[/{*}]\" roles-allowed: \"admin\" - path: \"/health[/{*}]\" roles-allowed: \"monitor\" - path: \"/openapi[/{*}]\" abac: scopes: [\"openapi\"] - path: \"/static[/{*}]\" roles-allowed: [\"user\", \"monitor\"] Attribute based access control provider that checks roles and scopes The provider(s) used in your application, such as oidc Default configuration for all configured paths Protection of /metrics and all nested paths with admin role required Protection of /health and all nested paths with monitor role required Protection of /openapi and all nested paths with openapi scope required Protection of static content configured on /static path with either user or monitor role required If you need to use a properties file, such as microprofile-config.properties , you can convert the file by using index based numbers for arrays, such as: <markup lang=\"properties\" title=\"microprofile-config.properties\" >security.providers.0.abac= security.providers.1.provider-key.optional=false security.web-server.defaults.authenticate=true security.web-server.paths.0.path=/metrics[/{*}] security.web-server.paths.0.roles-allowed=admin security.web-server.paths.3.path=/static[/{*}] security.web-server.paths.3.roles-allowed=user,monitor ",
            "title": "Protecting Helidon Endpoints"
        },
        {
            "location": "mp/security/security",
            "text": " To enable Security add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-security&lt;/artifactId&gt; &lt;/dependency&gt; Securing a JAX-RS Resource For JAX-RS resources, declare security by adding annotations to a resource class or method. <markup lang=\"java\" title=\"Protected resource method\" >@GET @io.helidon.security.annotations.Authenticated @io.helidon.security.annotations.Authorized // you can also use io.helidon.security.abac.role.RoleValidator.Roles @RolesAllowed(\"admin\") public String adminResource(@Context io.helidon.security.SecurityContext securityContext) { return \"you are \" + securityContext.userName(); } Security in Helidon MicroProfile is built on top of Jersey&#8217;s and can be enabled/disabled using the property security.jersey.enabled=[true|false] . Protecting Helidon Endpoints There are several endpoints provided by Helidon services, such as: Health endpoint ( /health ) Metrics endpoint ( /metrics ) OpenAPI endpoint ( /openapi ) Configured static content (can use any path configured) These endpoints are all implemented using Helidon reactive WebServer and as such can be protected only through Security integration with WebServer. The following section describes configuration of such protection using configuration files, in this case using a yaml file, as it provides a tree structure. Configuring Endpoint Protection The configuration is usually placed under security.web-server (this can be customized in Helidon SE). The following example shows how to configure the application.yaml using customized setting: <markup lang=\"yaml\" title=\"application.yaml\" >security: providers: - abac: - provider-key: web-server: defaults: authenticate: true paths: - path: \"/metrics[/{*}]\" roles-allowed: \"admin\" - path: \"/health[/{*}]\" roles-allowed: \"monitor\" - path: \"/openapi[/{*}]\" abac: scopes: [\"openapi\"] - path: \"/static[/{*}]\" roles-allowed: [\"user\", \"monitor\"] Attribute based access control provider that checks roles and scopes The provider(s) used in your application, such as oidc Default configuration for all configured paths Protection of /metrics and all nested paths with admin role required Protection of /health and all nested paths with monitor role required Protection of /openapi and all nested paths with openapi scope required Protection of static content configured on /static path with either user or monitor role required If you need to use a properties file, such as microprofile-config.properties , you can convert the file by using index based numbers for arrays, such as: <markup lang=\"properties\" title=\"microprofile-config.properties\" >security.providers.0.abac= security.providers.1.provider-key.optional=false security.web-server.defaults.authenticate=true security.web-server.paths.0.path=/metrics[/{*}] security.web-server.paths.0.roles-allowed=admin security.web-server.paths.3.path=/static[/{*}] security.web-server.paths.3.roles-allowed=user,monitor ",
            "title": "Maven Coordinates"
        },
        {
            "location": "mp/server",
            "text": " Overview Maven Coordinates Usage API Configuration Examples Reference ",
            "title": "Content"
        },
        {
            "location": "mp/server",
            "text": " Helidon provides a MicroProfile server implementation ( io.helidon.microprofile.server ) that encapsulates the Helidon WebServer. ",
            "title": "Overview"
        },
        {
            "location": "mp/server",
            "text": " To enable MicroProfile Server add the helidon-microprofile-core bundle dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.bundles&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-core&lt;/artifactId&gt; &lt;/dependency&gt; MicroProfile Server is already included in the bundle. If full control over the dependencies is required, and you want to minimize the quantity of the dependencies - Helidon MicroProfile Server should be used. In this case the following dependencies should be included in your project&#8217;s pom.xml : <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.server&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-server&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven-Coordinates"
        },
        {
            "location": "mp/server",
            "text": " Helidon Microprofile Server is used to collect and deploy JAX-RS application. It is recommended to instantiate the server directly as is done in the Helidon MP Quickstart example . Note that the server lifecycle is bound to CDI. ",
            "title": "Usage"
        },
        {
            "location": "mp/server",
            "text": " Optional configuration options key type default value description executor-service ExecutorService&gt; &#160; Set a supplier of an executor service to use for tasks connected with application processing (JAX-RS). host string &#160; Configure listen host. port int &#160; Configure listen port. The following table provides a brief description of routing annotations, including its parameters. More information in Configuring a reactive route section. <div class=\"table__overflow elevation-1 flex sm10 \"> Annotation Description @RoutingName( value = \"\" required = false ) Binds a JAX-RS Application or Helidon Service to a specific (named) routing on WebServer .The routing should have a corresponding named socket configured on the WebServer to run the routing on. @RoutingPath(\"/path\") Path of a Helidon Service to register with routing. ",
            "title": "Configuration Options"
        },
        {
            "location": "mp/server",
            "text": " Configuration of Helidon Microprofile Server Type: io.helidon.microprofile.server.Server This is a standalone configuration type, prefix from configuration root: server Configuration Options Optional configuration options key type default value description executor-service ExecutorService&gt; &#160; Set a supplier of an executor service to use for tasks connected with application processing (JAX-RS). host string &#160; Configure listen host. port int &#160; Configure listen port. The following table provides a brief description of routing annotations, including its parameters. More information in Configuring a reactive route section. <div class=\"table__overflow elevation-1 flex sm10 \"> Annotation Description @RoutingName( value = \"\" required = false ) Binds a JAX-RS Application or Helidon Service to a specific (named) routing on WebServer .The routing should have a corresponding named socket configured on the WebServer to run the routing on. @RoutingPath(\"/path\") Path of a Helidon Service to register with routing. ",
            "title": "API"
        },
        {
            "location": "mp/server",
            "text": " Optional configuration options key type default value description backlog int 1024 Configures a maximum length of the queue of incoming connections on the server socket. Default value is #DEFAULT_BACKLOG_SIZE. bind-address string &#160; Deprecated Configures local address where the server listens on with the server socket. If not configured, then listens an all local addresses. enable-compression boolean false Enable negotiation for gzip/deflate content encodings. Clients can request compression using the \"Accept-Encoding\" header. Default is `false` features.print-details boolean false Set to true to print detailed feature information on startup. host string &#160; A helper method that just calls #bindAddress(String). max-header-size int 16384 Maximal number of bytes of all header values combined. When a bigger value is received, a io.helidon.common.http.Http.Status#BAD_REQUEST_400 is returned. Default is `8192` max-initial-line-length int 4096 Maximal number of characters in the initial HTTP line. Default is `4096` max-payload-size long &#160; Set a maximum payload size for a client request. Can prevent DoS attacks. max-upgrade-content-length int 65536 Set a maximum length of the content of an upgrade request. Default is `64*1024` backpressure-buffer-size long 5242880 Set a maximum length of the unflushed response data sending buffer can keep without applying backpressure. Depends on backpressure-policy what happens if max buffer size is reached. Default is `5*1024*1024` - 5Mb backpressure-policy String LINEAR Sets the strategy for applying backpressure to the reactive stream of response data. LINEAR - Data chunks are requested one-by-one after previous data chunk has been written to Netty&#8217;s buffer, when backpressure-buffer-size watermark is reached, new chunks are not requested until buffer size decrease under the watermark value. PREFETCH - After first data chunk arrives, expected number of chunks needed to fill the buffer up to watermark is calculated and requested. AUTO_FLUSH - Data are requested one-by-one, in case buffer reaches watermark, no other data is requested and extra flush is initiated. UNBOUNDED - No backpressure is applied, Long.MAX_VALUE(unbounded) is requested from upstream. Default is `LINEAR` port int 0 Configures a server port to listen on with the server socket. If port is 0 then any available ephemeral port will be used. receive-buffer-size int &#160; Configures proposed value of the TCP receive window that is advertised to the remote peer on the server socket. If `0` then use implementation default. sockets SocketConfiguration[&#93; &#160; Adds an additional named server socket configuration. As a result, the server will listen on multiple ports. An additional named server socket may have a dedicated Routing configured through io.helidon.webserver.WebServer.Builder#addNamedRouting(String, Routing). timeout-millis long 0 Socket timeout in milliseconds tls WebServerTls &#160; Configures SSL for this socket. When configured, the server enforces SSL configuration. If this method is called, any other method except for #tls(java.util.function.Supplier)¨ and repeated invocation of this method would be ignored. If this method is called again, the previous configuration would be ignored. worker-count int &#160; Sets a count of threads in pool used to process HTTP requests. Default value is CPU_COUNT * 2 . Configuration key: `workers` ",
            "title": "Configuration options"
        },
        {
            "location": "mp/server",
            "text": " By default, the server uses the MicroProfile Config, but you may also want to use Helidon configuration . In this example, the configuration is in a file, and it includes Helidon configuration options. Configuration of the HTTP server. Type: io.helidon.webserver.WebServer This is a standalone configuration type, prefix from configuration root: server Configuration options Optional configuration options key type default value description backlog int 1024 Configures a maximum length of the queue of incoming connections on the server socket. Default value is #DEFAULT_BACKLOG_SIZE. bind-address string &#160; Deprecated Configures local address where the server listens on with the server socket. If not configured, then listens an all local addresses. enable-compression boolean false Enable negotiation for gzip/deflate content encodings. Clients can request compression using the \"Accept-Encoding\" header. Default is `false` features.print-details boolean false Set to true to print detailed feature information on startup. host string &#160; A helper method that just calls #bindAddress(String). max-header-size int 16384 Maximal number of bytes of all header values combined. When a bigger value is received, a io.helidon.common.http.Http.Status#BAD_REQUEST_400 is returned. Default is `8192` max-initial-line-length int 4096 Maximal number of characters in the initial HTTP line. Default is `4096` max-payload-size long &#160; Set a maximum payload size for a client request. Can prevent DoS attacks. max-upgrade-content-length int 65536 Set a maximum length of the content of an upgrade request. Default is `64*1024` backpressure-buffer-size long 5242880 Set a maximum length of the unflushed response data sending buffer can keep without applying backpressure. Depends on backpressure-policy what happens if max buffer size is reached. Default is `5*1024*1024` - 5Mb backpressure-policy String LINEAR Sets the strategy for applying backpressure to the reactive stream of response data. LINEAR - Data chunks are requested one-by-one after previous data chunk has been written to Netty&#8217;s buffer, when backpressure-buffer-size watermark is reached, new chunks are not requested until buffer size decrease under the watermark value. PREFETCH - After first data chunk arrives, expected number of chunks needed to fill the buffer up to watermark is calculated and requested. AUTO_FLUSH - Data are requested one-by-one, in case buffer reaches watermark, no other data is requested and extra flush is initiated. UNBOUNDED - No backpressure is applied, Long.MAX_VALUE(unbounded) is requested from upstream. Default is `LINEAR` port int 0 Configures a server port to listen on with the server socket. If port is 0 then any available ephemeral port will be used. receive-buffer-size int &#160; Configures proposed value of the TCP receive window that is advertised to the remote peer on the server socket. If `0` then use implementation default. sockets SocketConfiguration[&#93; &#160; Adds an additional named server socket configuration. As a result, the server will listen on multiple ports. An additional named server socket may have a dedicated Routing configured through io.helidon.webserver.WebServer.Builder#addNamedRouting(String, Routing). timeout-millis long 0 Socket timeout in milliseconds tls WebServerTls &#160; Configures SSL for this socket. When configured, the server enforces SSL configuration. If this method is called, any other method except for #tls(java.util.function.Supplier)¨ and repeated invocation of this method would be ignored. If this method is called again, the previous configuration would be ignored. worker-count int &#160; Sets a count of threads in pool used to process HTTP requests. Default value is CPU_COUNT * 2 . Configuration key: `workers` ",
            "title": "Configuration"
        },
        {
            "location": "mp/server",
            "text": " Access logging in Helidon is done by a dedicated module that can be added to Maven and configured. To enable Access logging add the following dependency to project&#8217;s pom.xml : <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-access-log&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Access Log"
        },
        {
            "location": "mp/server",
            "text": " Access log can be configured as follows: <markup lang=\"properties\" title=\"Access Log configuration file\" >server.port=8080 server.host=0.0.0.0 server.access-log.format=helidon All options shown above are also available programmatically when using builder. ",
            "title": "Configuring Access Log in a configuration file"
        },
        {
            "location": "mp/server",
            "text": " The following configuration options can be defined: <div class=\"table__overflow elevation-1 flex sm10 \"> Config key Default value Builder method Description enabled true enabled(boolean) When this option is set to false , access logging will be disabled logger-name io.helidon.webserver.AccessLog loggerName(String) Name of the logger to use when writing log entries format helidon helidonLogFormat() , commonLogFormat() , add(AccessLogEntry entry) Configuration of access log output, when helidon is defined, the Helidon log format (see below) is used. Can be configured to explicitly define log entries (see below as well) exclude-paths N/A excludePaths(List&lt;String&gt;) List of path patterns to exclude from access log. Path pattern syntax is as defined in io.helidon.webserver.PathMatcher . Can be used to exclude paths such as /health or /metrics to avoid cluttering log. ",
            "title": "Configuration Options"
        },
        {
            "location": "mp/server",
            "text": " The following log entries are supported in Helidon: <div class=\"table__overflow elevation-1 flex sm7 \"> Config format Class (to use with builder) Description %h HostLogEntry IP address of the remote host %l UserIdLogEntry Client identity, always undefined in Helidon %u UserLogEntry The username of logged-in user (when Security is used) %t TimestampLogEntry The current timestamp %r RequestLineLogEntry The request line (method, path and HTTP version) %s StatusLogEntry The HTTP status returned to the client %b SizeLogEntry The response entity size (if available) %D TimeTakenLogEntry The time taken in microseconds %T TimeTakenLogEntry The time taken in seconds %{ header-name }i HeaderLogEntry Value of a header (can have multiple such specification to write multiple headers) Currently we only support the entries defined above, with NO support for free text. ",
            "title": "Supported Log Entries"
        },
        {
            "location": "mp/server",
            "text": " When format is set to helidon , the format used is: \"%h %u %t %r %s %b %D\" The entries logged: IP Address Username of a logged-in user Timestamp Request Line HTTP Status code Entity size Time taken (microseconds) Access log example: <markup lang=\"listing\" >192.168.0.104 - [18/Jun/2019:22:28:55 +0200] \"GET /greet/test HTTP/1.1\" 200 53 0:0:0:0:0:0:0:1 - [18/Jun/2019:22:29:00 +0200] \"GET /metrics/vendor HTTP/1.1\" 200 1658 0:0:0:0:0:0:0:1 jack [18/Jun/2019:22:29:07 +0200] \"PUT /greet/greeting HTTP/1.1\" 200 21 0:0:0:0:0:0:0:1 jill [18/Jun/2019:22:29:12 +0200] \"PUT /greet/greeting HTTP/1.1\" 403 0 0:0:0:0:0:0:0:1 - [18/Jun/2019:22:29:17 +0200] \"PUT /greet/greeting HTTP/1.1\" 401 0 ",
            "title": "Helidon Log Format"
        },
        {
            "location": "mp/server",
            "text": " Supported Log Entries The following log entries are supported in Helidon: <div class=\"table__overflow elevation-1 flex sm7 \"> Config format Class (to use with builder) Description %h HostLogEntry IP address of the remote host %l UserIdLogEntry Client identity, always undefined in Helidon %u UserLogEntry The username of logged-in user (when Security is used) %t TimestampLogEntry The current timestamp %r RequestLineLogEntry The request line (method, path and HTTP version) %s StatusLogEntry The HTTP status returned to the client %b SizeLogEntry The response entity size (if available) %D TimeTakenLogEntry The time taken in microseconds %T TimeTakenLogEntry The time taken in seconds %{ header-name }i HeaderLogEntry Value of a header (can have multiple such specification to write multiple headers) Currently we only support the entries defined above, with NO support for free text. Helidon Log Format When format is set to helidon , the format used is: \"%h %u %t %r %s %b %D\" The entries logged: IP Address Username of a logged-in user Timestamp Request Line HTTP Status code Entity size Time taken (microseconds) Access log example: <markup lang=\"listing\" >192.168.0.104 - [18/Jun/2019:22:28:55 +0200] \"GET /greet/test HTTP/1.1\" 200 53 0:0:0:0:0:0:0:1 - [18/Jun/2019:22:29:00 +0200] \"GET /metrics/vendor HTTP/1.1\" 200 1658 0:0:0:0:0:0:0:1 jack [18/Jun/2019:22:29:07 +0200] \"PUT /greet/greeting HTTP/1.1\" 200 21 0:0:0:0:0:0:0:1 jill [18/Jun/2019:22:29:12 +0200] \"PUT /greet/greeting HTTP/1.1\" 403 0 0:0:0:0:0:0:0:1 - [18/Jun/2019:22:29:17 +0200] \"PUT /greet/greeting HTTP/1.1\" 401 0 ",
            "title": "Supported Log Formats"
        },
        {
            "location": "mp/server",
            "text": " Helidon MP also supports custom TLS configuration. You can set the following properties: Server truststore Keystore with trusted certificates Private key and certificate Server certificate which will be used in TLS handshake <markup lang=\"properties\" title=\"META-INF/microprofile-config.properties - Server configuration\" >#Truststore setup server.tls.trust.keystore.resource.resource-path=server.p12 server.tls.trust.keystore.passphrase=password server.tls.trust.keystore.trust-store=true #Keystore with private key and server certificate server.tls.private-key.keystore.resource.resource-path=server.p12 server.tls.private-key.keystore.passphrase=password Or the same configuration done in application.yaml file. <markup lang=\"yaml\" title=\"application.yaml - Server configuration\" >server: tls: #Truststore setup trust: keystore: passphrase: \"password\" trust-store: true resource: resource-path: \"keystore.p12\" #Keystore with private key and server certificate private-key: keystore: passphrase: \"password\" resource: resource-path: \"keystore.p12\" ",
            "title": "Configuring TLS"
        },
        {
            "location": "mp/server",
            "text": " Helidon MP can expose multiple ports, with the following limitations: The default port is the port that serves your application (JAX-RS applications and resources) Other ports (in this example we configure one \"admin\" port) can be assigned endpoints that are exposed by Helidon components, currently supported by MP Health and MP Metrics For this example, we will use a YAML file: The port 7011 is the default port and will serve your application The port 8011 is named \"admin\" (this is an arbitrary name) MP Metrics are configured to use the \"admin\" port through the routing configuration (reference is by name) MP Health is configured the same way to reference the \"admin\" port <markup lang=\"yaml\" title=\"application.yaml - Server configuration\" >server: port: 7011 host: \"some.host\" sockets: admin: port: 8011 bind-address: \"some.host\" metrics: routing: \"admin\" health: routing: \"admin\" ",
            "title": "Configuring additional ports"
        },
        {
            "location": "mp/server",
            "text": " The service can be customized using annotations and/or configuration to be registered on a specific path registered with a named routing ",
            "title": "Customizing the reactive service"
        },
        {
            "location": "mp/server",
            "text": " You can annotate a service bean with this annotation to assign it to a specific named routing, that is (most likely) going to be bound to a specific port. The annotation has two attributes: - value that defines the routing name - required to mark that the routing name MUST be configured in Helidon server <markup lang=\"java\" title=\" @RoutingName example\" >@ApplicationScoped @RoutingName(value=\"admin\", required=\"true\") @RoutingPath(\"/admin\") public class AdminService implements Service { } The example above will be bound to admin routing (and port) and will fail if such a port is not configured. ",
            "title": "Annotation @RoutingName "
        },
        {
            "location": "mp/server",
            "text": " For each service bean you can define the routing name and its required flag by specifying a configuration option bean-class-name.routing-name.name and bean-class-name.routing-name.required . For service beans produced with producer method replace bean-class-name with class-name.producer-method-name . Example (YAML) configuration for a service bean io.helidon.examples.AdminService that changes the routing name to management and its required flag to false : <markup lang=\"yaml\" >io.helidon.examples.AdminService: routing-name: name: \"management\" required: false ",
            "title": "Configuration override of routing name"
        },
        {
            "location": "mp/server",
            "text": " Helidon has the concept of named routing. These correspond to the named ports configured with WebServer. You can assign a reactive service to a named routing (and as a result to a named port) using either an annotation or configuration (or both to override the value from annotation). Annotation @RoutingName You can annotate a service bean with this annotation to assign it to a specific named routing, that is (most likely) going to be bound to a specific port. The annotation has two attributes: - value that defines the routing name - required to mark that the routing name MUST be configured in Helidon server <markup lang=\"java\" title=\" @RoutingName example\" >@ApplicationScoped @RoutingName(value=\"admin\", required=\"true\") @RoutingPath(\"/admin\") public class AdminService implements Service { } The example above will be bound to admin routing (and port) and will fail if such a port is not configured. Configuration override of routing name For each service bean you can define the routing name and its required flag by specifying a configuration option bean-class-name.routing-name.name and bean-class-name.routing-name.required . For service beans produced with producer method replace bean-class-name with class-name.producer-method-name . Example (YAML) configuration for a service bean io.helidon.examples.AdminService that changes the routing name to management and its required flag to false : <markup lang=\"yaml\" >io.helidon.examples.AdminService: routing-name: name: \"management\" required: false ",
            "title": "Assigning a reactive service to named ports"
        },
        {
            "location": "mp/server",
            "text": " You can configure @RoutingPath to define the path a service is registered on. ",
            "title": "Annotation @RoutingPath "
        },
        {
            "location": "mp/server",
            "text": " For each reactive service class you can define the routing path by specifying a configuration option class-name.routing-path.path . Example (YAML) configuration for a class io.helidon.example.AdminService that changes the routing path to /management : <markup lang=\"yaml\" >io.helidon.examples.AdminService: routing-path: path: \"/management\" ",
            "title": "Configuration override of routing path"
        },
        {
            "location": "mp/server",
            "text": " Each service is registered on a path. If none is configured, then the service would be configured on the root path. You can configure service path using an annotation or configuration (or both to override value from annotation) Annotation @RoutingPath You can configure @RoutingPath to define the path a service is registered on. Configuration override of routing path For each reactive service class you can define the routing path by specifying a configuration option class-name.routing-path.path . Example (YAML) configuration for a class io.helidon.example.AdminService that changes the routing path to /management : <markup lang=\"yaml\" >io.helidon.examples.AdminService: routing-path: path: \"/management\" ",
            "title": "Configuring a reactive service path"
        },
        {
            "location": "mp/server",
            "text": " Helidon MP Server will pick up CDI beans that implement the io.helidon.webserver.Service interface and configure them with the underlying WebServer. This allows configuration of reactive routes to run alongside a JAX-RS application. The bean is expected to be either ApplicationScoped or Dependent and will be requested only once during the boot of the Server . The bean will support injection of ApplicationScoped and Dependent scoped beans. You cannot inject RequestScoped beans. Please use WebServer features to handle request related objects. Customizing the reactive service The service can be customized using annotations and/or configuration to be registered on a specific path registered with a named routing Assigning a reactive service to named ports Helidon has the concept of named routing. These correspond to the named ports configured with WebServer. You can assign a reactive service to a named routing (and as a result to a named port) using either an annotation or configuration (or both to override the value from annotation). Annotation @RoutingName You can annotate a service bean with this annotation to assign it to a specific named routing, that is (most likely) going to be bound to a specific port. The annotation has two attributes: - value that defines the routing name - required to mark that the routing name MUST be configured in Helidon server <markup lang=\"java\" title=\" @RoutingName example\" >@ApplicationScoped @RoutingName(value=\"admin\", required=\"true\") @RoutingPath(\"/admin\") public class AdminService implements Service { } The example above will be bound to admin routing (and port) and will fail if such a port is not configured. Configuration override of routing name For each service bean you can define the routing name and its required flag by specifying a configuration option bean-class-name.routing-name.name and bean-class-name.routing-name.required . For service beans produced with producer method replace bean-class-name with class-name.producer-method-name . Example (YAML) configuration for a service bean io.helidon.examples.AdminService that changes the routing name to management and its required flag to false : <markup lang=\"yaml\" >io.helidon.examples.AdminService: routing-name: name: \"management\" required: false Configuring a reactive service path Each service is registered on a path. If none is configured, then the service would be configured on the root path. You can configure service path using an annotation or configuration (or both to override value from annotation) Annotation @RoutingPath You can configure @RoutingPath to define the path a service is registered on. Configuration override of routing path For each reactive service class you can define the routing path by specifying a configuration option class-name.routing-path.path . Example (YAML) configuration for a class io.helidon.example.AdminService that changes the routing path to /management : <markup lang=\"yaml\" >io.helidon.examples.AdminService: routing-path: path: \"/management\" ",
            "title": "Configuring A Reactive Route"
        },
        {
            "location": "mp/server",
            "text": "<markup lang=\"properties\" title=\"META-INF/microprofile-config.properties - File system static content\" ># Location of content on file system server.static.path.location=/var/www/html # default is index.html server.static.path.welcome=resource.html # static content path - default is \"/\" # server.static.path.context=/static-file <markup lang=\"properties\" title=\"META-INF/microprofile-config.properties - Classpath static content\" ># src/main/resources/WEB in your source tree server.static.classpath.location=/WEB # default is index.html server.static.classpath.welcome=resource.html # static content path - default is \"/\" # server.static.classpath.context=/static-cp ",
            "title": "Serving Static Content"
        },
        {
            "location": "mp/server",
            "text": " A full configuration example (YAML): <markup lang=\"yaml\" >server: port: 8080 sockets: management: port: 8090 io.helidon.examples.AdminApplication: routing-name: name: \"management\" required: true routing-path: path: \"/management\" ",
            "title": "Example configuration of routing"
        },
        {
            "location": "mp/server",
            "text": " Access Log Access logging in Helidon is done by a dedicated module that can be added to Maven and configured. To enable Access logging add the following dependency to project&#8217;s pom.xml : <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-access-log&lt;/artifactId&gt; &lt;/dependency&gt; Configuring Access Log in a configuration file Access log can be configured as follows: <markup lang=\"properties\" title=\"Access Log configuration file\" >server.port=8080 server.host=0.0.0.0 server.access-log.format=helidon All options shown above are also available programmatically when using builder. Configuration Options The following configuration options can be defined: <div class=\"table__overflow elevation-1 flex sm10 \"> Config key Default value Builder method Description enabled true enabled(boolean) When this option is set to false , access logging will be disabled logger-name io.helidon.webserver.AccessLog loggerName(String) Name of the logger to use when writing log entries format helidon helidonLogFormat() , commonLogFormat() , add(AccessLogEntry entry) Configuration of access log output, when helidon is defined, the Helidon log format (see below) is used. Can be configured to explicitly define log entries (see below as well) exclude-paths N/A excludePaths(List&lt;String&gt;) List of path patterns to exclude from access log. Path pattern syntax is as defined in io.helidon.webserver.PathMatcher . Can be used to exclude paths such as /health or /metrics to avoid cluttering log. Supported Log Formats Supported Log Entries The following log entries are supported in Helidon: <div class=\"table__overflow elevation-1 flex sm7 \"> Config format Class (to use with builder) Description %h HostLogEntry IP address of the remote host %l UserIdLogEntry Client identity, always undefined in Helidon %u UserLogEntry The username of logged-in user (when Security is used) %t TimestampLogEntry The current timestamp %r RequestLineLogEntry The request line (method, path and HTTP version) %s StatusLogEntry The HTTP status returned to the client %b SizeLogEntry The response entity size (if available) %D TimeTakenLogEntry The time taken in microseconds %T TimeTakenLogEntry The time taken in seconds %{ header-name }i HeaderLogEntry Value of a header (can have multiple such specification to write multiple headers) Currently we only support the entries defined above, with NO support for free text. Helidon Log Format When format is set to helidon , the format used is: \"%h %u %t %r %s %b %D\" The entries logged: IP Address Username of a logged-in user Timestamp Request Line HTTP Status code Entity size Time taken (microseconds) Access log example: <markup lang=\"listing\" >192.168.0.104 - [18/Jun/2019:22:28:55 +0200] \"GET /greet/test HTTP/1.1\" 200 53 0:0:0:0:0:0:0:1 - [18/Jun/2019:22:29:00 +0200] \"GET /metrics/vendor HTTP/1.1\" 200 1658 0:0:0:0:0:0:0:1 jack [18/Jun/2019:22:29:07 +0200] \"PUT /greet/greeting HTTP/1.1\" 200 21 0:0:0:0:0:0:0:1 jill [18/Jun/2019:22:29:12 +0200] \"PUT /greet/greeting HTTP/1.1\" 403 0 0:0:0:0:0:0:0:1 - [18/Jun/2019:22:29:17 +0200] \"PUT /greet/greeting HTTP/1.1\" 401 0 Configuring TLS Helidon MP also supports custom TLS configuration. You can set the following properties: Server truststore Keystore with trusted certificates Private key and certificate Server certificate which will be used in TLS handshake <markup lang=\"properties\" title=\"META-INF/microprofile-config.properties - Server configuration\" >#Truststore setup server.tls.trust.keystore.resource.resource-path=server.p12 server.tls.trust.keystore.passphrase=password server.tls.trust.keystore.trust-store=true #Keystore with private key and server certificate server.tls.private-key.keystore.resource.resource-path=server.p12 server.tls.private-key.keystore.passphrase=password Or the same configuration done in application.yaml file. <markup lang=\"yaml\" title=\"application.yaml - Server configuration\" >server: tls: #Truststore setup trust: keystore: passphrase: \"password\" trust-store: true resource: resource-path: \"keystore.p12\" #Keystore with private key and server certificate private-key: keystore: passphrase: \"password\" resource: resource-path: \"keystore.p12\" Configuring additional ports Helidon MP can expose multiple ports, with the following limitations: The default port is the port that serves your application (JAX-RS applications and resources) Other ports (in this example we configure one \"admin\" port) can be assigned endpoints that are exposed by Helidon components, currently supported by MP Health and MP Metrics For this example, we will use a YAML file: The port 7011 is the default port and will serve your application The port 8011 is named \"admin\" (this is an arbitrary name) MP Metrics are configured to use the \"admin\" port through the routing configuration (reference is by name) MP Health is configured the same way to reference the \"admin\" port <markup lang=\"yaml\" title=\"application.yaml - Server configuration\" >server: port: 7011 host: \"some.host\" sockets: admin: port: 8011 bind-address: \"some.host\" metrics: routing: \"admin\" health: routing: \"admin\" Configuring A Reactive Route Helidon MP Server will pick up CDI beans that implement the io.helidon.webserver.Service interface and configure them with the underlying WebServer. This allows configuration of reactive routes to run alongside a JAX-RS application. The bean is expected to be either ApplicationScoped or Dependent and will be requested only once during the boot of the Server . The bean will support injection of ApplicationScoped and Dependent scoped beans. You cannot inject RequestScoped beans. Please use WebServer features to handle request related objects. Customizing the reactive service The service can be customized using annotations and/or configuration to be registered on a specific path registered with a named routing Assigning a reactive service to named ports Helidon has the concept of named routing. These correspond to the named ports configured with WebServer. You can assign a reactive service to a named routing (and as a result to a named port) using either an annotation or configuration (or both to override the value from annotation). Annotation @RoutingName You can annotate a service bean with this annotation to assign it to a specific named routing, that is (most likely) going to be bound to a specific port. The annotation has two attributes: - value that defines the routing name - required to mark that the routing name MUST be configured in Helidon server <markup lang=\"java\" title=\" @RoutingName example\" >@ApplicationScoped @RoutingName(value=\"admin\", required=\"true\") @RoutingPath(\"/admin\") public class AdminService implements Service { } The example above will be bound to admin routing (and port) and will fail if such a port is not configured. Configuration override of routing name For each service bean you can define the routing name and its required flag by specifying a configuration option bean-class-name.routing-name.name and bean-class-name.routing-name.required . For service beans produced with producer method replace bean-class-name with class-name.producer-method-name . Example (YAML) configuration for a service bean io.helidon.examples.AdminService that changes the routing name to management and its required flag to false : <markup lang=\"yaml\" >io.helidon.examples.AdminService: routing-name: name: \"management\" required: false Configuring a reactive service path Each service is registered on a path. If none is configured, then the service would be configured on the root path. You can configure service path using an annotation or configuration (or both to override value from annotation) Annotation @RoutingPath You can configure @RoutingPath to define the path a service is registered on. Configuration override of routing path For each reactive service class you can define the routing path by specifying a configuration option class-name.routing-path.path . Example (YAML) configuration for a class io.helidon.example.AdminService that changes the routing path to /management : <markup lang=\"yaml\" >io.helidon.examples.AdminService: routing-path: path: \"/management\" Serving Static Content <markup lang=\"properties\" title=\"META-INF/microprofile-config.properties - File system static content\" ># Location of content on file system server.static.path.location=/var/www/html # default is index.html server.static.path.welcome=resource.html # static content path - default is \"/\" # server.static.path.context=/static-file <markup lang=\"properties\" title=\"META-INF/microprofile-config.properties - Classpath static content\" ># src/main/resources/WEB in your source tree server.static.classpath.location=/WEB # default is index.html server.static.classpath.welcome=resource.html # static content path - default is \"/\" # server.static.classpath.context=/static-cp Example configuration of routing A full configuration example (YAML): <markup lang=\"yaml\" >server: port: 8080 sockets: management: port: 8090 io.helidon.examples.AdminApplication: routing-name: name: \"management\" required: true routing-path: path: \"/management\" ",
            "title": "Examples"
        },
        {
            "location": "mp/server",
            "text": " Helidon MicroProfile Server Javadoc Helidon MicroProfile Server on GitHub ",
            "title": "Reference"
        },
        {
            "location": "mp/testing-ng",
            "text": " Overview Maven Coordinates Usage API Examples Reference ",
            "title": "Contents"
        },
        {
            "location": "mp/testing-ng",
            "text": " Helidon provides built-in test support for CDI testing in TestNG. ",
            "title": "Overview"
        },
        {
            "location": "mp/testing-ng",
            "text": " To enable Testing with TestNG add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.tests&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-tests-testng&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "mp/testing-ng",
            "text": " A test can be annotated as follows: @HelidonTest(resetPerTest = true) This will change the behavior as follows: A new CDI container is created for each test method invocation annotations to add config, beans and extension can be added for each method in addition to the class you cannot inject fields or constructor parameters of the test class itself (as a single instance is shared by more containers) ",
            "title": "Usage - per method CDI container"
        },
        {
            "location": "mp/testing-ng",
            "text": " In addition to the @AddConfig annotation, you can also use @Configuration to configure additional classpath properties config sources using configSources , and to mark that a custom configuration is desired. If @Configuration(useExisting=true) , the existing (or default) MicroProfile configuration would be used. In this case it is important to set property mp.initializer.allow=true in order CDI container to start, when used with @HelidonTest . You can set up config in @BeforeAll method and register it with ConfigProviderResolver using MP Config APIs, and declare @Configuration(useExisting=true) . Note that this is not compatible with repeatable tests that use method sources that access CDI, as we must delay the CDI startup to the test class instantiation (which is too late, as the method sources are already invoked by this time). If you want to use method sources that use CDI with repeatable tests, please do not use @Configuration(useExisting=true) Test method parameters are currently not supported. ",
            "title": "Usage - configuration"
        },
        {
            "location": "mp/testing-ng",
            "text": " By default, a test can be annotated with io.helidon.microprofile.tests.testng.HelidonTest annotation to mark it as a CDI test. This annotation will start the CDI container before any test method is invoked, and stop it after the last method is invoked. This annotation also enables injection into the test class itself. A test can also be annotated with io.helidon.microprofile.tests.testng.HelidonTest annotation to mark it as a CDI test. This annotation will start the CDI container before any test method is invoked, and stop it after the last method is invoked. This annotation also enables injection into the test class itself. Usage - per method CDI container A test can be annotated as follows: @HelidonTest(resetPerTest = true) This will change the behavior as follows: A new CDI container is created for each test method invocation annotations to add config, beans and extension can be added for each method in addition to the class you cannot inject fields or constructor parameters of the test class itself (as a single instance is shared by more containers) Usage - configuration In addition to the @AddConfig annotation, you can also use @Configuration to configure additional classpath properties config sources using configSources , and to mark that a custom configuration is desired. If @Configuration(useExisting=true) , the existing (or default) MicroProfile configuration would be used. In this case it is important to set property mp.initializer.allow=true in order CDI container to start, when used with @HelidonTest . You can set up config in @BeforeAll method and register it with ConfigProviderResolver using MP Config APIs, and declare @Configuration(useExisting=true) . Note that this is not compatible with repeatable tests that use method sources that access CDI, as we must delay the CDI startup to the test class instantiation (which is too late, as the method sources are already invoked by this time). If you want to use method sources that use CDI with repeatable tests, please do not use @Configuration(useExisting=true) Test method parameters are currently not supported. ",
            "title": "Usage"
        },
        {
            "location": "mp/testing-ng",
            "text": " The annotations described in this section are inherited (for the non-repeatable ones), and additive (for repeatable). So if you declare @DisableDiscovery on abstract class, all implementations will have discovery disabled, unless you annotate the implementation class with @DisableDiscovery(false) . If you declare @AddBean on both abstract class and implementation class, both beans will be added. In addition to this simplification, the following annotations are supported: Annotation Usage @io.helidon.microprofile.tests.testng.AddBean Used to add one or more beans to the container (if not part of a bean archive, or when discovery is disabled) @io.helidon.microprofile.tests.testng.AddExtension Used to add one or more CDI extensions to the container (if not added through service loader, or when discovery is disabled) @io.helidon.microprofile.tests.testng.AddConfig Used to add one or more configuration properties to MicroProfile config without the need of creating a microprofile-config.properties file @io.helidon.microprofile.tests.testng.DisableDiscovery Used to disable automated discovery of beans and extensions ",
            "title": "API"
        },
        {
            "location": "mp/testing-ng",
            "text": " In current example Helidon container will be launched prior test. The Bean Discovery will be disabled. MyBean will be added to the test, so that it can be injected. ConfigCdiExtension will be enabled for this test. And finally, a configuration property will be added using @AddConfig annotation. <markup lang=\"java\" title=\"Code sample\" >@HelidonTest @DisableDiscovery @AddBean(MyBean.class) @AddExtension(ConfigCdiExtension.class) @AddConfig(key = \"app.greeting\", value = \"TestHello\") class TestExample { @Inject private MyBean myBean; @Test void testGreeting() { assertThat(myBean, notNullValue()); assertThat(myBean.greeting(), is(\"TestHello\")); } } ",
            "title": "Examples"
        },
        {
            "location": "mp/testing-ng",
            "text": " TestNG User Guide ",
            "title": "Reference"
        },
        {
            "location": "mp/testing",
            "text": " Overview Maven Coordinates Usage Examples Additional Information Reference ",
            "title": "Contents"
        },
        {
            "location": "mp/testing",
            "text": " Helidon provides built-in test support for CDI testing in JUnit5. ",
            "title": "Overview"
        },
        {
            "location": "mp/testing",
            "text": " To enable Testing with JUnit add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.tests&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-tests-junit5&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "mp/testing",
            "text": " When a test is annotated with @HelidonTest(resetPerTest = true) , the behavior will change as follows: A new CDI container is created for each test method invocation annotations to add config, beans and extension can be added for each method in addition to the class you cannot inject fields or constructor parameters of the test class itself (as a single instance is shared by more containers) you can add SeContainer as a method parameter of any test method and you will get the current container ",
            "title": "Usage - per method CDI container"
        },
        {
            "location": "mp/testing",
            "text": " In addition to the @AddConfig annotation, you can also use @Configuration to configure additional classpath properties and configSources to mark that a custom configuration is desired. If @Configuration(useExisting=true) , the existing (or default) MicroProfile configuration would be used. it is important to set property mp.initializer.allow=true in order for the CDI container to start, when used with @HelidonTest . You can set up config in @BeforeAll method and register it with ConfigProviderResolver using MP Config APIs, and declare @Configuration(useExisting=true) . Note that this is not compatible with repeatable tests that use method sources that access CDI, as we must delay the CDI startup to the test class instantiation (which is too late, as the method sources are already invoked by this time). If you want to use method sources that use CDI with repeatable tests, please do not use @Configuration(useExisting=true) ",
            "title": "Usage - configuration"
        },
        {
            "location": "mp/testing",
            "text": " The following types are available for injection (when a single CDI container is used per test class): WebTarget - a JAX-RS client&#8217;s target configured for the current hostname and port when helidon-micorprofile-server is on the classpath The following types are available as method parameters (in any type of Helidon tests): WebTarget - a JAX-RS client&#8217;s target configured for the current hostname and port when helidon-micorprofile-server is on the classpath SeContainer - the current container instance ",
            "title": "Usage - added parameters and injection types"
        },
        {
            "location": "mp/testing",
            "text": " A test can be annotated with io.helidon.microprofile.tests.junit5.HelidonTest to mark it as a CDI test. This annotation will start the CDI container before any test method is invoked, and stop it after the last method is invoked. This annotation also enables injection into the test class itself. Usage - per method CDI container When a test is annotated with @HelidonTest(resetPerTest = true) , the behavior will change as follows: A new CDI container is created for each test method invocation annotations to add config, beans and extension can be added for each method in addition to the class you cannot inject fields or constructor parameters of the test class itself (as a single instance is shared by more containers) you can add SeContainer as a method parameter of any test method and you will get the current container Usage - configuration In addition to the @AddConfig annotation, you can also use @Configuration to configure additional classpath properties and configSources to mark that a custom configuration is desired. If @Configuration(useExisting=true) , the existing (or default) MicroProfile configuration would be used. it is important to set property mp.initializer.allow=true in order for the CDI container to start, when used with @HelidonTest . You can set up config in @BeforeAll method and register it with ConfigProviderResolver using MP Config APIs, and declare @Configuration(useExisting=true) . Note that this is not compatible with repeatable tests that use method sources that access CDI, as we must delay the CDI startup to the test class instantiation (which is too late, as the method sources are already invoked by this time). If you want to use method sources that use CDI with repeatable tests, please do not use @Configuration(useExisting=true) Usage - added parameters and injection types The following types are available for injection (when a single CDI container is used per test class): WebTarget - a JAX-RS client&#8217;s target configured for the current hostname and port when helidon-micorprofile-server is on the classpath The following types are available as method parameters (in any type of Helidon tests): WebTarget - a JAX-RS client&#8217;s target configured for the current hostname and port when helidon-micorprofile-server is on the classpath SeContainer - the current container instance ",
            "title": "Usage"
        },
        {
            "location": "mp/testing",
            "text": " The annotations described in this section are inherited (for the non-repeatable ones), and additive (for repeatable). So if you declare @DisableDiscovery on abstract class, all implementations will have discovery disabled, unless you annotate the implementation class with @DisableDiscovery(false) . If you declare @AddBean on both abstract class and implementation class, both beans will be added. In addition to this simplification, the following annotations are supported: Annotation Usage @io.helidon.microprofile.tests.junit5.AddBean Used to add one or more beans to the container (if not part of a bean archive, or when discovery is disabled) @io.helidon.microprofile.tests.junit5.AddExtension Used to add one or more CDI extensions to the container (if not added through service loader, or when discovery is disabled) @io.helidon.microprofile.tests.junit5.AddConfig Used to add one or more configuration properties to MicroProfile config without the need of creating a microprofile-config.properties file Used @io.helidon.microprofile.tests.junit5.DisableDiscovery to disable automated discovery of beans and extensions ",
            "title": "API"
        },
        {
            "location": "mp/testing",
            "text": " In this example, the Helidon container will be launched before the test. The Bean Discovery will be disabled. MyBean will be added to the test, so that it can be injected. ConfigCdiExtension will be enabled for this test. And finally, a configuration property will be added using @AddConfig annotation. <markup lang=\"java\" title=\"Code sample\" >@HelidonTest @DisableDiscovery @AddBean(MyBean.class) @AddExtension(ConfigCdiExtension.class) @AddConfig(key = \"app.greeting\", value = \"TestHello\") class TestExample { @Inject private MyBean myBean; @Test void testGreeting() { assertThat(myBean, notNullValue()); assertThat(myBean.greeting(), is(\"TestHello\")); } } ",
            "title": "Examples"
        },
        {
            "location": "mp/testing",
            "text": " Official blog article about Helidon and JUnit usage ",
            "title": "Additional Information"
        },
        {
            "location": "mp/testing",
            "text": " JUnit 5 User Guide ",
            "title": "Reference"
        },
        {
            "location": "mp/tracing",
            "text": " Overview Maven Coordinates Usage Configuration Examples Additional Information Zipkin Tracing Jaeger Tracing Reference ",
            "title": "Contents"
        },
        {
            "location": "mp/tracing",
            "text": " Distributed tracing is a critical feature of micro-service based applications, since it traces workflow both within a service and across multiple services. This provides insight to sequence and timing data for specific blocks of work, which helps you identify performance and operational issues. Helidon MP includes support for distributed tracing through the OpenTracing API . Tracing is integrated with WebServer, gRPC Server, and Security. ",
            "title": "Overview"
        },
        {
            "location": "mp/tracing",
            "text": " To enable MicroProfile Tracing either add a dependency on the helidon-microprofile bundle or add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-tracing&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "mp/tracing",
            "text": " This section explains a few concepts that you need to understand before you get started with tracing. In the context of this document, a service is synonymous with an application. A span is the basic unit of work done within a single service, on a single host. Every span has a name, starting timestamp, and duration. For example, the work done by a REST endpoint is a span. A span is associated to a single service, but its descendants can belong to different services and hosts. A trace contains a collection of spans from one or more services, running on one or more hosts. For example, if you trace a service endpoint that calls another service, then the trace would contain spans from both services. Within a trace, spans are organized as a directed acyclic graph (DAG) and can belong to multiple services, running on multiple hosts. The OpenTracing Data Model describes the details at The OpenTracing Semantic Specification . Spans are automatically created by Helidon as needed during execution of the REST request. Additional spans can be added through MP annotation @Traced or through OpenTracing APIs. ",
            "title": "Usage"
        },
        {
            "location": "mp/tracing",
            "text": " The following table lists all spans traced by Helidon components: <div class=\"table__overflow elevation-1 flex sm10 \"> component span name description web-server HTTP Request The overall span of the Web Server from request initiation until response Note that in Zipkin the name is replaced with jax-rs span name if jax-rs tracing is used. web-server content-read Span for reading the request entity web-server content-write Span for writing the response entity security security Processing of request security security security:atn Span for request authentication security security:atz Span for request authorization security security:response Processing of response security security security:outbound Processing of outbound security jax-rs A generated name Span for the resource method invocation, name is generated from class and method name jax-rs jersey-client-call Span for outbound client call Some of these spans log to the span. These log events can be (in most cases) configured: <div class=\"table__overflow elevation-1 flex sm10 \"> span name log name configurable enabled by default description HTTP Request handler.class YES YES Each handler has its class and event logged security status YES YES Logs either \"status: PROCEED\" or \"status: DENY\" security:atn security.user YES NO The username of the user if logged in security:atn security.service YES NO The name of the service if logged in security:atn status YES YES Logs the status of security response (such as SUCCESS ) security:atz status YES YES Logs the status of security response (such as SUCCESS ) security:outbound status YES YES Logs the status of security response (such as SUCCESS ) There are also tags that are set by Helidon components. These are not configurable. <div class=\"table__overflow elevation-1 flex sm10 \"> span name tag name description HTTP Request component name of the component - helidon-webserver , or jaxrs when using MP HTTP Request http.method HTTP method of the request, such as GET , POST HTTP Request http.status_code HTTP status code of the response HTTP Request http.url The path of the request (for SE without protocol, host and port) HTTP Request error If the request ends in error, this tag is set to true , usually accompanied by logs with details content-read requested.type Type (class) of the requested entity (if entity is read) content-write response.type Type (class) of the entity being sent (if entity is sent) security security.id ID of the security context created for this request (if security is used) jersey-client-call http.method HTTP method of the client request jersey-client-call http.status_code HTTP status code of client response jersey-client-call http.url Full URL of the request (such as http://localhost:8080/greet ) ",
            "title": "Traced spans"
        },
        {
            "location": "mp/tracing",
            "text": " You can configure a custom service name using the tracing.service configuration property. If this property is undefined, name is created from JAX-RS Application name, or Helidon MP is used if no application is defined. Jaeger tracer configuration. Type: io.helidon.tracing.Tracer This is a standalone configuration type, prefix from configuration root: tracing ",
            "title": "Enabling and Disabling Tracing"
        },
        {
            "location": "mp/tracing",
            "text": " Enabling and Disabling Tracing You can configure a custom service name using the tracing.service configuration property. If this property is undefined, name is created from JAX-RS Application name, or Helidon MP is used if no application is defined. Jaeger tracer configuration. Type: io.helidon.tracing.Tracer This is a standalone configuration type, prefix from configuration root: tracing ",
            "title": "Configuration"
        },
        {
            "location": "mp/tracing",
            "text": " To have a better overview in the search pane of a tracer, you can customize the top-level span name using configuration. Example: <markup lang=\"properties\" title=\"Configuration properties\" >tracing.components.web-server.spans.0.name=\"HTTP Request\" tracing.components.web-server.spans.0.new-name: \"HTTP %1$s %2$s\" This is supported ONLY for the span named \"HTTP Request\" on component \"web-server\". Parameters provided: Method - HTTP method Path - path of the request (such as '/greet') Query - query of the request (may be null) ",
            "title": "Renaming top level span using request properties"
        },
        {
            "location": "mp/tracing",
            "text": " For WebServer we have path-based support for configuring tracing, in addition to the configuration described above. Path configuration can use any path string supported by the WebServer. The configuration itself has the same possibilities as traced configuration described above. The path specific configuration will be merged with global configuration (path is the \"newer\" configuration, global is the \"older\") Renaming top level span using request properties To have a better overview in the search pane of a tracer, you can customize the top-level span name using configuration. Example: <markup lang=\"properties\" title=\"Configuration properties\" >tracing.components.web-server.spans.0.name=\"HTTP Request\" tracing.components.web-server.spans.0.new-name: \"HTTP %1$s %2$s\" This is supported ONLY for the span named \"HTTP Request\" on component \"web-server\". Parameters provided: Method - HTTP method Path - path of the request (such as '/greet') Query - query of the request (may be null) ",
            "title": "Controlling Tracing Output"
        },
        {
            "location": "mp/tracing",
            "text": " Optional configuration options key type default value description boolean-tags Map&lt;string, boolean&gt; &#160; Tracer level tags that get added to all reported spans. client-cert-pem Resource &#160; Certificate of client in PEM format. enabled boolean true When enabled, tracing will be sent. If enabled is false, tracing should use a no-op tracer. exporter-timeout-millis Duration 10000 Timeout of exporter requests. global boolean true When enabled, the created instance is also registered as a global tracer. host string &#160; Host to use to connect to tracing collector. Default is defined by each tracing integration. int-tags Map&lt;string, int&gt; &#160; Tracer level tags that get added to all reported spans. path string &#160; Path on the collector host to use when sending data to tracing collector. Default is defined by each tracing integration. port int &#160; Port to use to connect to tracing collector. Default is defined by each tracing integration. private-key-pem Resource &#160; Private key in PEM format. protocol string &#160; Protocol to use (such as http or https ) to connect to tracing collector. Default is defined by each tracing integration. sampler-param Number 1 The sampler parameter (number). sampler-type SamplerType (CONSTANT, RATIO) CONSTANT Sampler type. See &lt;a href=\"https://www.jaegertracing.io/docs/latest/sampling/#client-sampling-configuration\"&gt;Sampler types&lt;/a&gt;. service string &#160; Service name of the traced service. tags Map&lt;string, string&gt; &#160; Tracer level tags that get added to all reported spans. trusted-cert-pem Resource &#160; Trusted certificates in PEM format. To disable Helidon tracing for WebServer and security: <markup lang=\"properties\" >tracing.components.web-server.enabled=false tracing.components.security.enabled=false To disable MP Tracing per specification: <markup lang=\"properties\" >mp.opentracing.server.skip-pattern=.* Tracing configuration can be defined in application.yaml file. <markup lang=\"yaml\" title=\"Tracing configuration example\" >tracing: paths: - path: \"/favicon.ico\" enabled: false - path: \"/metrics\" enabled: false - path: \"/health\" enabled: false components: web-server: spans: - name: \"HTTP Request\" logs: - name: \"content-write\" enabled: false Controlling Tracing Output For WebServer we have path-based support for configuring tracing, in addition to the configuration described above. Path configuration can use any path string supported by the WebServer. The configuration itself has the same possibilities as traced configuration described above. The path specific configuration will be merged with global configuration (path is the \"newer\" configuration, global is the \"older\") Renaming top level span using request properties To have a better overview in the search pane of a tracer, you can customize the top-level span name using configuration. Example: <markup lang=\"properties\" title=\"Configuration properties\" >tracing.components.web-server.spans.0.name=\"HTTP Request\" tracing.components.web-server.spans.0.new-name: \"HTTP %1$s %2$s\" This is supported ONLY for the span named \"HTTP Request\" on component \"web-server\". Parameters provided: Method - HTTP method Path - path of the request (such as '/greet') Query - query of the request (may be null) ",
            "title": "Configuration options"
        },
        {
            "location": "mp/tracing",
            "text": " Update the pom.xml file and add the following Zipkin dependency to the &lt;dependencies&gt; section ( not &lt;dependencyManagement&gt; ). This will enable Helidon to use Zipkin at the default host and port, localhost:9411 . <markup lang=\"xml\" title=\"Add the following dependency to pom.xml :\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-zipkin&lt;/artifactId&gt; &lt;/dependency&gt; All spans sent by Helidon to Zipkin need to be associated with a service. Specify the service name below. <markup lang=\"bash\" title=\"Add the following line to META-INF/microprofile-config.properties :\" >tracing.service=helidon-mp-1 <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-mp.jar <markup lang=\"bash\" title=\"Run the curl command in a new terminal window and check the response:\" >curl http://localhost:8080/greet <markup lang=\"json\" title=\"Response body\" >{ \"message\": \"Hello World!\" } ",
            "title": "Enable Tracing in the Helidon Application"
        },
        {
            "location": "mp/tracing",
            "text": " Because tracing is now enabled, the previous /greet endpoint invocation resulted in a new trace being created. Let&#8217;s get the trace data that was generated using the Zipkin API. First, get the service information. Helidon automatically enables tracing for JAX-RS resources methods so you don&#8217;t need to use annotations with JAX-RS. See MicroProfile OpenTracing for more details. <markup lang=\"bash\" title=\"Run the curl command and check the response:\" >curl http://localhost:9411/api/v2/services <markup lang=\"json\" title=\"Response body\" >[\"helidon-mp-1\"] This is the tracing service name specified in META-INF/microprofile-config.properties . Each span used by a service has a name, which is unique within a trace. If you invoke the /greet endpoint multiple times, you will still get the same set of names. <markup lang=\"bash\" title=\"Invoke the endpoint below and check the response:\" >curl -X GET \"http://localhost:9411/api/v2/spans?serviceName=helidon-mp-1\" -H \"accept: application/json\" Get the span names for the helidon-mp-1 service. <markup lang=\"json\" title=\"Response body\" >[ \"content-read\", \"content-write\", \"get:io.helidon.examples.quickstart.mp.greetresource.getdefaultmessage\", \"security\", \"security:atn\", \"security:atz\", \"security:response\" ] These are the span names. If you invoke the /greet endpoint again, then invoke the /spans endpoint, you will get the same response. Next, get the contents of the trace as shown below. Notice that each span has a parentId field, except the get:io.helidon.examples.quickstart.mp.greetresource.getdefaultmessage span, which is the root. <markup lang=\"bash\" title=\"Invoke the endpoint below and check the response:\" >curl -X GET \"http://localhost:9411/api/v2/traces?serviceName=helidon-mp-1&amp;limit=1\" -H \"accept: application/json\" Get the newest trace only, using the limit=1 query param. There are other query params that let you restrict results to a specific time window. <markup lang=\"json\" title=\"Response body\" >[ [ { \"traceId\": \"2e0af8866efdef35\", \"parentId\": \"2e0af8866efdef35\", \"id\": \"b5d61690f230fde4\", \"kind\": \"SERVER\", \"name\": \"content-read\", \"timestamp\": 1568077339998659, \"duration\": 41, \"localEndpoint\": { \"serviceName\": \"helidon-mp-1\", \"ipv4\": \"192.168.1.115\" }, \"tags\": { \"requested.type\": \"java.io.InputStream\" } } ] ] The request will return seven spans, one for each name, along with an unnamed JSON node, which has the status. ",
            "title": "View Tracing Using Zipkin REST API"
        },
        {
            "location": "mp/tracing",
            "text": " The tracing output data is verbose and can be difficult to interpret using the REST API, especially since it represents a structure of spans. Zipkin provides a web-based UI at http://localhost:9411/zipkin , where you can see a visual representation of the same data and the relationship between spans within a trace. If you see a Lens UI button at the top center then click on it and it will take you to the specific UI used by this guide. Click on the UI refresh button (the search icon) as shown in the image below. Notice that you can change the look-back time to restrict the trace list. Trace refresh The image below shows the trace summary, including start time and duration of each trace. There are two traces, each one generated in response to a curl http://localhost:8080/greet invocation. The oldest trace will have a much longer duration since there is one-time initialization that occurs. Tracing list view Click on a trace and you will see the trace detail page where the spans are listed. You can clearly see the root span and the relationship among all the spans in the trace, along with timing information. Trace detail page A parent span might not depend on the result of the child. This is called a FollowsFrom reference, see Open Tracing Semantic Spec . Note that the last span that writes the response after the root span ends falls into this category. You can examine span details by clicking on the span row. Refer to the image below, which shows the security span details, including timing information. You can see times for each space relative to the root span. These rows are annotated with Server Start and Server Finish , as shown in the third column. Span detail page ",
            "title": "View Tracing Using Zipkin UI"
        },
        {
            "location": "mp/tracing",
            "text": " So far in this tutorial you have used tracing with JAX-RS without needing to annotate. You can enable tracing on other CDI beans, either at the class level or at the method level, as shown by the following examples. ",
            "title": "Enable Tracing on CDI Beans"
        },
        {
            "location": "mp/tracing",
            "text": " To trace at the method level, you just annotate a method with @Traced. <markup lang=\"java\" title=\"Update the GreetingProvider class; 1) Add a new import and 2) Add the @Traced annotation to the getMessage method:\" >import org.eclipse.microprofile.opentracing.Traced; @Traced String getMessage() { return message.get(); } Import the Traced annotation. Enable tracing for getMessage. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints and check the response:\" >curl http://localhost:8080/greet curl -X GET \"http://localhost:9411/api/v2/spans?serviceName=helidon-mp-1\" -H \"accept: application/json\" <markup lang=\"json\" title=\"Response body\" >[ \"content-read\", \"content-write\", \"dosomework\", \"get:io.helidon.examples.quickstart.mp.greetresource.getdefaultmessage\", \"io.helidon.examples.quickstart.mp.greetingprovider.getmessage\", \"security\", \"security:atn\", \"security:atz\", \"security:response\" ] There is a new span name for the getmessage method, since your code called that method during the invocation of /greet . Click the back button on your browser, then click on the UI refresh button to see the new trace. Select the newest trace in the list to see the trace detail page like the one below. Notice the new span named io.helidon.examples.quickstart.mp.greetingprovider.getmessage . Trace detail page with new span getmessage ",
            "title": "Tracing at the Method Level"
        },
        {
            "location": "mp/tracing",
            "text": " To trace at the class level, annotate the class with @Traced. This will enable tracing for all class methods, except for the constructor and private methods. Update the GreetingProvider class Add @Traced to the GreetingProvider class Remove @Traced from the getMessage method <markup lang=\"java\" >@Traced @ApplicationScoped public class GreetingProvider { String getMessage() { return message.get(); } } This will enable tracing for all class methods, except for the constructor and methods that are private. Remove @Traced for the getMessage method. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints and check the response:\" >curl http://localhost:8080/greet curl -X GET \"http://localhost:9411/api/v2/spans?serviceName=helidon-mp-1\" -H \"accept: application/json\" <markup lang=\"json\" title=\"Response body\" >[ \"io.helidon.examples.quickstart.mp.greetingprovider.getmessage\" ] The service has the same set of span names as above, since getmessage was the only method called in this bean. Next, invoke HTTP PUT to change the greeting, which will cause setMessage to be called. <markup lang=\"bash\" title=\"Invoke the endpoints and check the response:\" >curl -i -X PUT -H \"Content-Type: application/json\" -d '{\"greeting\": \"Hi\"}' http://localhost:8080/greet/greeting curl -X GET \"http://localhost:9411/api/v2/spans?serviceName=helidon-mp-1\" -H \"accept: application/json\" Invoke the endpoint to change the greeting. <markup lang=\"json\" title=\"Response body\" >[ \"content-read\", \"content-write\", \"get:io.helidon.examples.quickstart.mp.greetresource.getdefaultmessage\", \"io.helidon.examples.quickstart.mp.greetingprovider.getmessage\", \"io.helidon.examples.quickstart.mp.greetingprovider.setmessage\", \"put:io.helidon.examples.quickstart.mp.greetresource.updategreeting\", \"security\", \"security:atn\", \"security:atz\", \"security:response\" ] The GreetingProvider.setmessage method was traced since you enabled class level tracing. The JAX-RS method GreetResource.updategreeting was traced automatically by Helidon. You can refresh the UI view and drill down the trace to see the new spans. Methods invoked directly by your code are not enabled for tracing, even if you explicitly annotate them with @Traced. Tracing only works for methods invoked on CDI beans. See the example below. <markup lang=\"java\" title=\"Update the GreetingProvider class with the following code:\" >@ApplicationScoped public class GreetingProvider { private final AtomicReference&lt;String&gt; message = new AtomicReference&lt;&gt;(); @Inject public GreetingProvider(@ConfigProperty(name = \"app.greeting\") String message) { this.message.set(message); } @Traced String getMessage() { return getMessage2(); } @Traced String getMessage2() { return message.get(); } void setMessage(String message) { this.message.set(message); } } The getMessage method will be traced since it is externally invoked by GreetResource . The getMessage2 method will not be traced, even with the @Traced annotation, since it is called internally by getMessage . <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints and check the response:\" >curl http://localhost:8080/greet curl -X GET \"http://localhost:9411/api/v2/spans?serviceName=helidon-mp-1\" -H \"accept: application/json\" <markup lang=\"json\" title=\"Response body\" >[ \"io.helidon.examples.quickstart.mp.greetingprovider.getmessage\" ] The getMessage method is traced, but getMessage2 is not. ",
            "title": "Tracing at the Class Level"
        },
        {
            "location": "mp/tracing",
            "text": " First, you need to run the Zipkin tracer. Helidon will communicate with this tracer at runtime. <markup lang=\"bash\" title=\"Run Zipkin within a docker container, then check the Zipkin server health:\" >docker run -d --name zipkin -p 9411:9411 openzipkin/zipkin Run the Zipkin docker image named openzipkin/zipkin . <markup lang=\"bash\" title=\"Check the Zipkin server health:\" >curl http://localhost:9411/health Invoke the Zipkin REST API to check the Zipkin server health. <markup lang=\"json\" title=\"Response body\" >{ \"status\": \"UP\", \"zipkin\": { \"status\": \"UP\", \"details\": { \"InMemoryStorage{}\": { \"status\": \"UP\" } } } } All status fields should be UP . Enable Tracing in the Helidon Application Update the pom.xml file and add the following Zipkin dependency to the &lt;dependencies&gt; section ( not &lt;dependencyManagement&gt; ). This will enable Helidon to use Zipkin at the default host and port, localhost:9411 . <markup lang=\"xml\" title=\"Add the following dependency to pom.xml :\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-zipkin&lt;/artifactId&gt; &lt;/dependency&gt; All spans sent by Helidon to Zipkin need to be associated with a service. Specify the service name below. <markup lang=\"bash\" title=\"Add the following line to META-INF/microprofile-config.properties :\" >tracing.service=helidon-mp-1 <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-mp.jar <markup lang=\"bash\" title=\"Run the curl command in a new terminal window and check the response:\" >curl http://localhost:8080/greet <markup lang=\"json\" title=\"Response body\" >{ \"message\": \"Hello World!\" } View Tracing Using Zipkin REST API Because tracing is now enabled, the previous /greet endpoint invocation resulted in a new trace being created. Let&#8217;s get the trace data that was generated using the Zipkin API. First, get the service information. Helidon automatically enables tracing for JAX-RS resources methods so you don&#8217;t need to use annotations with JAX-RS. See MicroProfile OpenTracing for more details. <markup lang=\"bash\" title=\"Run the curl command and check the response:\" >curl http://localhost:9411/api/v2/services <markup lang=\"json\" title=\"Response body\" >[\"helidon-mp-1\"] This is the tracing service name specified in META-INF/microprofile-config.properties . Each span used by a service has a name, which is unique within a trace. If you invoke the /greet endpoint multiple times, you will still get the same set of names. <markup lang=\"bash\" title=\"Invoke the endpoint below and check the response:\" >curl -X GET \"http://localhost:9411/api/v2/spans?serviceName=helidon-mp-1\" -H \"accept: application/json\" Get the span names for the helidon-mp-1 service. <markup lang=\"json\" title=\"Response body\" >[ \"content-read\", \"content-write\", \"get:io.helidon.examples.quickstart.mp.greetresource.getdefaultmessage\", \"security\", \"security:atn\", \"security:atz\", \"security:response\" ] These are the span names. If you invoke the /greet endpoint again, then invoke the /spans endpoint, you will get the same response. Next, get the contents of the trace as shown below. Notice that each span has a parentId field, except the get:io.helidon.examples.quickstart.mp.greetresource.getdefaultmessage span, which is the root. <markup lang=\"bash\" title=\"Invoke the endpoint below and check the response:\" >curl -X GET \"http://localhost:9411/api/v2/traces?serviceName=helidon-mp-1&amp;limit=1\" -H \"accept: application/json\" Get the newest trace only, using the limit=1 query param. There are other query params that let you restrict results to a specific time window. <markup lang=\"json\" title=\"Response body\" >[ [ { \"traceId\": \"2e0af8866efdef35\", \"parentId\": \"2e0af8866efdef35\", \"id\": \"b5d61690f230fde4\", \"kind\": \"SERVER\", \"name\": \"content-read\", \"timestamp\": 1568077339998659, \"duration\": 41, \"localEndpoint\": { \"serviceName\": \"helidon-mp-1\", \"ipv4\": \"192.168.1.115\" }, \"tags\": { \"requested.type\": \"java.io.InputStream\" } } ] ] The request will return seven spans, one for each name, along with an unnamed JSON node, which has the status. View Tracing Using Zipkin UI The tracing output data is verbose and can be difficult to interpret using the REST API, especially since it represents a structure of spans. Zipkin provides a web-based UI at http://localhost:9411/zipkin , where you can see a visual representation of the same data and the relationship between spans within a trace. If you see a Lens UI button at the top center then click on it and it will take you to the specific UI used by this guide. Click on the UI refresh button (the search icon) as shown in the image below. Notice that you can change the look-back time to restrict the trace list. Trace refresh The image below shows the trace summary, including start time and duration of each trace. There are two traces, each one generated in response to a curl http://localhost:8080/greet invocation. The oldest trace will have a much longer duration since there is one-time initialization that occurs. Tracing list view Click on a trace and you will see the trace detail page where the spans are listed. You can clearly see the root span and the relationship among all the spans in the trace, along with timing information. Trace detail page A parent span might not depend on the result of the child. This is called a FollowsFrom reference, see Open Tracing Semantic Spec . Note that the last span that writes the response after the root span ends falls into this category. You can examine span details by clicking on the span row. Refer to the image below, which shows the security span details, including timing information. You can see times for each space relative to the root span. These rows are annotated with Server Start and Server Finish , as shown in the third column. Span detail page Enable Tracing on CDI Beans So far in this tutorial you have used tracing with JAX-RS without needing to annotate. You can enable tracing on other CDI beans, either at the class level or at the method level, as shown by the following examples. Tracing at the Method Level To trace at the method level, you just annotate a method with @Traced. <markup lang=\"java\" title=\"Update the GreetingProvider class; 1) Add a new import and 2) Add the @Traced annotation to the getMessage method:\" >import org.eclipse.microprofile.opentracing.Traced; @Traced String getMessage() { return message.get(); } Import the Traced annotation. Enable tracing for getMessage. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints and check the response:\" >curl http://localhost:8080/greet curl -X GET \"http://localhost:9411/api/v2/spans?serviceName=helidon-mp-1\" -H \"accept: application/json\" <markup lang=\"json\" title=\"Response body\" >[ \"content-read\", \"content-write\", \"dosomework\", \"get:io.helidon.examples.quickstart.mp.greetresource.getdefaultmessage\", \"io.helidon.examples.quickstart.mp.greetingprovider.getmessage\", \"security\", \"security:atn\", \"security:atz\", \"security:response\" ] There is a new span name for the getmessage method, since your code called that method during the invocation of /greet . Click the back button on your browser, then click on the UI refresh button to see the new trace. Select the newest trace in the list to see the trace detail page like the one below. Notice the new span named io.helidon.examples.quickstart.mp.greetingprovider.getmessage . Trace detail page with new span getmessage Tracing at the Class Level To trace at the class level, annotate the class with @Traced. This will enable tracing for all class methods, except for the constructor and private methods. Update the GreetingProvider class Add @Traced to the GreetingProvider class Remove @Traced from the getMessage method <markup lang=\"java\" >@Traced @ApplicationScoped public class GreetingProvider { String getMessage() { return message.get(); } } This will enable tracing for all class methods, except for the constructor and methods that are private. Remove @Traced for the getMessage method. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints and check the response:\" >curl http://localhost:8080/greet curl -X GET \"http://localhost:9411/api/v2/spans?serviceName=helidon-mp-1\" -H \"accept: application/json\" <markup lang=\"json\" title=\"Response body\" >[ \"io.helidon.examples.quickstart.mp.greetingprovider.getmessage\" ] The service has the same set of span names as above, since getmessage was the only method called in this bean. Next, invoke HTTP PUT to change the greeting, which will cause setMessage to be called. <markup lang=\"bash\" title=\"Invoke the endpoints and check the response:\" >curl -i -X PUT -H \"Content-Type: application/json\" -d '{\"greeting\": \"Hi\"}' http://localhost:8080/greet/greeting curl -X GET \"http://localhost:9411/api/v2/spans?serviceName=helidon-mp-1\" -H \"accept: application/json\" Invoke the endpoint to change the greeting. <markup lang=\"json\" title=\"Response body\" >[ \"content-read\", \"content-write\", \"get:io.helidon.examples.quickstart.mp.greetresource.getdefaultmessage\", \"io.helidon.examples.quickstart.mp.greetingprovider.getmessage\", \"io.helidon.examples.quickstart.mp.greetingprovider.setmessage\", \"put:io.helidon.examples.quickstart.mp.greetresource.updategreeting\", \"security\", \"security:atn\", \"security:atz\", \"security:response\" ] The GreetingProvider.setmessage method was traced since you enabled class level tracing. The JAX-RS method GreetResource.updategreeting was traced automatically by Helidon. You can refresh the UI view and drill down the trace to see the new spans. Methods invoked directly by your code are not enabled for tracing, even if you explicitly annotate them with @Traced. Tracing only works for methods invoked on CDI beans. See the example below. <markup lang=\"java\" title=\"Update the GreetingProvider class with the following code:\" >@ApplicationScoped public class GreetingProvider { private final AtomicReference&lt;String&gt; message = new AtomicReference&lt;&gt;(); @Inject public GreetingProvider(@ConfigProperty(name = \"app.greeting\") String message) { this.message.set(message); } @Traced String getMessage() { return getMessage2(); } @Traced String getMessage2() { return message.get(); } void setMessage(String message) { this.message.set(message); } } The getMessage method will be traced since it is externally invoked by GreetResource . The getMessage2 method will not be traced, even with the @Traced annotation, since it is called internally by getMessage . <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints and check the response:\" >curl http://localhost:8080/greet curl -X GET \"http://localhost:9411/api/v2/spans?serviceName=helidon-mp-1\" -H \"accept: application/json\" <markup lang=\"json\" title=\"Response body\" >[ \"io.helidon.examples.quickstart.mp.greetingprovider.getmessage\" ] The getMessage method is traced, but getMessage2 is not. ",
            "title": "Set up Zipkin"
        },
        {
            "location": "mp/tracing",
            "text": "<markup lang=\"bash\" title=\"Run the Maven archetype:\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-mp \\ -DarchetypeVersion=3.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-mp-2 \\ -Dpackage=io.helidon.examples.quickstart.mp <markup lang=\"bash\" title=\"The project will be built and run from the helidon-quickstart-mp directory:\" >cd helidon-quickstart-mp-2 <markup lang=\"xml\" title=\"Add the following dependency to pom.xml :\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-zipkin&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"bash\" title=\"Replace META-INF/microprofile-config.properties with the following:\" >app.greeting=Hello From MP-2 tracing.service=helidon-mp-2 # Microprofile server properties server.port=8081 <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-mp-2.jar <markup lang=\"bash\" title=\"Run the curl command in a new terminal window and check the response ( notice the port is 8081 ) :\" >curl http://localhost:8081/greet <markup lang=\"json\" title=\"Response body\" >{ \"message\": \"Hello From MP-2 World!\" } ",
            "title": "Create a second service"
        },
        {
            "location": "mp/tracing",
            "text": " Once you have validated that the second service is running correctly, you need to modify the original application to call it. <markup lang=\"java\" title=\"Replace the GreetResource class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import jakarta.enterprise.context.RequestScoped; import jakarta.inject.Inject; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.client.WebTarget; import jakarta.ws.rs.core.MediaType; import org.glassfish.jersey.server.Uri; @Path(\"/greet\") @RequestScoped public class GreetResource { @Uri(\"http://localhost:8081/greet\") private WebTarget target; private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); private final GreetingProvider greetingProvider; @Inject public GreetResource(GreetingProvider greetingConfig) { this.greetingProvider = greetingConfig; } @GET @Produces(MediaType.APPLICATION_JSON) public JsonObject getDefaultMessage() { return createResponse(\"World\"); } @GET @Path(\"/outbound\") public JsonObject outbound() { return target.request().accept(MediaType.APPLICATION_JSON_TYPE).get(JsonObject.class); } private JsonObject createResponse(String who) { String msg = String.format(\"%s %s!\", greetingProvider.getMessage(), who); return JSON.createObjectBuilder().add(\"message\", msg).build(); } } This is the WebTarget needed to send a request to the second service at port 8081 . This is the new endpoint that will call the second service. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl -i http://localhost:8080/greet/outbound The request went to the service on 8080 , which then invoked the service at 8081 to get the greeting. <markup lang=\"json\" title=\"Response body\" >{ \"message\": \"Hello From MP-2 World!\" } Notice the greeting came from the second service. Refresh the Zipkin UI trace listing page and notice that there is a trace across two services. Tracing multiple service list view Click on the trace with two services to see the detail view. Tracing across multiple services detail view In the image above, you can see that the trace includes spans from two services. You will notice there is a gap before the sixth span, which is a get operation. This is a one-time client initialization delay. Run the /outbound curl command again and look at the new trace to see that the delay no longer exists. You can now stop your second service, it is no longer used in this guide. ",
            "title": "Modify the first service"
        },
        {
            "location": "mp/tracing",
            "text": " Helidon automatically traces across services as long as the services use the same tracer, for example, the same instance of Zipkin. This means a single trace can include spans from multiple services and hosts. OpenTracing uses a SpanContext to propagate tracing information across process boundaries. When you make client API calls, Helidon will internally call OpenTracing APIs to propagate the SpanContext . There is nothing you need to do in your application to make this work. To demonstrate distributed tracing, you will need to create a second project, where the server listens on port 8081. Create a new root directory to hold this new project, then do the following steps, similar to what you did at the start of this guide: Create a second service <markup lang=\"bash\" title=\"Run the Maven archetype:\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-mp \\ -DarchetypeVersion=3.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-mp-2 \\ -Dpackage=io.helidon.examples.quickstart.mp <markup lang=\"bash\" title=\"The project will be built and run from the helidon-quickstart-mp directory:\" >cd helidon-quickstart-mp-2 <markup lang=\"xml\" title=\"Add the following dependency to pom.xml :\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-zipkin&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"bash\" title=\"Replace META-INF/microprofile-config.properties with the following:\" >app.greeting=Hello From MP-2 tracing.service=helidon-mp-2 # Microprofile server properties server.port=8081 <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-mp-2.jar <markup lang=\"bash\" title=\"Run the curl command in a new terminal window and check the response ( notice the port is 8081 ) :\" >curl http://localhost:8081/greet <markup lang=\"json\" title=\"Response body\" >{ \"message\": \"Hello From MP-2 World!\" } Modify the first service Once you have validated that the second service is running correctly, you need to modify the original application to call it. <markup lang=\"java\" title=\"Replace the GreetResource class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import jakarta.enterprise.context.RequestScoped; import jakarta.inject.Inject; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.client.WebTarget; import jakarta.ws.rs.core.MediaType; import org.glassfish.jersey.server.Uri; @Path(\"/greet\") @RequestScoped public class GreetResource { @Uri(\"http://localhost:8081/greet\") private WebTarget target; private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); private final GreetingProvider greetingProvider; @Inject public GreetResource(GreetingProvider greetingConfig) { this.greetingProvider = greetingConfig; } @GET @Produces(MediaType.APPLICATION_JSON) public JsonObject getDefaultMessage() { return createResponse(\"World\"); } @GET @Path(\"/outbound\") public JsonObject outbound() { return target.request().accept(MediaType.APPLICATION_JSON_TYPE).get(JsonObject.class); } private JsonObject createResponse(String who) { String msg = String.format(\"%s %s!\", greetingProvider.getMessage(), who); return JSON.createObjectBuilder().add(\"message\", msg).build(); } } This is the WebTarget needed to send a request to the second service at port 8081 . This is the new endpoint that will call the second service. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl -i http://localhost:8080/greet/outbound The request went to the service on 8080 , which then invoked the service at 8081 to get the greeting. <markup lang=\"json\" title=\"Response body\" >{ \"message\": \"Hello From MP-2 World!\" } Notice the greeting came from the second service. Refresh the Zipkin UI trace listing page and notice that there is a trace across two services. Tracing multiple service list view Click on the trace with two services to see the detail view. Tracing across multiple services detail view In the image above, you can see that the trace includes spans from two services. You will notice there is a gap before the sixth span, which is a get operation. This is a one-time client initialization delay. Run the /outbound curl command again and look at the new trace to see that the delay no longer exists. You can now stop your second service, it is no longer used in this guide. ",
            "title": "Trace Across Services"
        },
        {
            "location": "mp/tracing",
            "text": " The examples in this guide demonstrate how to integrate tracing with Helidon, how to view traces, how to trace across multiple services, and how to integrate tracing with Kubernetes. All examples use Zipkin and traces will be viewed using both the Zipkin API and UI. Set up Zipkin First, you need to run the Zipkin tracer. Helidon will communicate with this tracer at runtime. <markup lang=\"bash\" title=\"Run Zipkin within a docker container, then check the Zipkin server health:\" >docker run -d --name zipkin -p 9411:9411 openzipkin/zipkin Run the Zipkin docker image named openzipkin/zipkin . <markup lang=\"bash\" title=\"Check the Zipkin server health:\" >curl http://localhost:9411/health Invoke the Zipkin REST API to check the Zipkin server health. <markup lang=\"json\" title=\"Response body\" >{ \"status\": \"UP\", \"zipkin\": { \"status\": \"UP\", \"details\": { \"InMemoryStorage{}\": { \"status\": \"UP\" } } } } All status fields should be UP . Enable Tracing in the Helidon Application Update the pom.xml file and add the following Zipkin dependency to the &lt;dependencies&gt; section ( not &lt;dependencyManagement&gt; ). This will enable Helidon to use Zipkin at the default host and port, localhost:9411 . <markup lang=\"xml\" title=\"Add the following dependency to pom.xml :\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-zipkin&lt;/artifactId&gt; &lt;/dependency&gt; All spans sent by Helidon to Zipkin need to be associated with a service. Specify the service name below. <markup lang=\"bash\" title=\"Add the following line to META-INF/microprofile-config.properties :\" >tracing.service=helidon-mp-1 <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-mp.jar <markup lang=\"bash\" title=\"Run the curl command in a new terminal window and check the response:\" >curl http://localhost:8080/greet <markup lang=\"json\" title=\"Response body\" >{ \"message\": \"Hello World!\" } View Tracing Using Zipkin REST API Because tracing is now enabled, the previous /greet endpoint invocation resulted in a new trace being created. Let&#8217;s get the trace data that was generated using the Zipkin API. First, get the service information. Helidon automatically enables tracing for JAX-RS resources methods so you don&#8217;t need to use annotations with JAX-RS. See MicroProfile OpenTracing for more details. <markup lang=\"bash\" title=\"Run the curl command and check the response:\" >curl http://localhost:9411/api/v2/services <markup lang=\"json\" title=\"Response body\" >[\"helidon-mp-1\"] This is the tracing service name specified in META-INF/microprofile-config.properties . Each span used by a service has a name, which is unique within a trace. If you invoke the /greet endpoint multiple times, you will still get the same set of names. <markup lang=\"bash\" title=\"Invoke the endpoint below and check the response:\" >curl -X GET \"http://localhost:9411/api/v2/spans?serviceName=helidon-mp-1\" -H \"accept: application/json\" Get the span names for the helidon-mp-1 service. <markup lang=\"json\" title=\"Response body\" >[ \"content-read\", \"content-write\", \"get:io.helidon.examples.quickstart.mp.greetresource.getdefaultmessage\", \"security\", \"security:atn\", \"security:atz\", \"security:response\" ] These are the span names. If you invoke the /greet endpoint again, then invoke the /spans endpoint, you will get the same response. Next, get the contents of the trace as shown below. Notice that each span has a parentId field, except the get:io.helidon.examples.quickstart.mp.greetresource.getdefaultmessage span, which is the root. <markup lang=\"bash\" title=\"Invoke the endpoint below and check the response:\" >curl -X GET \"http://localhost:9411/api/v2/traces?serviceName=helidon-mp-1&amp;limit=1\" -H \"accept: application/json\" Get the newest trace only, using the limit=1 query param. There are other query params that let you restrict results to a specific time window. <markup lang=\"json\" title=\"Response body\" >[ [ { \"traceId\": \"2e0af8866efdef35\", \"parentId\": \"2e0af8866efdef35\", \"id\": \"b5d61690f230fde4\", \"kind\": \"SERVER\", \"name\": \"content-read\", \"timestamp\": 1568077339998659, \"duration\": 41, \"localEndpoint\": { \"serviceName\": \"helidon-mp-1\", \"ipv4\": \"192.168.1.115\" }, \"tags\": { \"requested.type\": \"java.io.InputStream\" } } ] ] The request will return seven spans, one for each name, along with an unnamed JSON node, which has the status. View Tracing Using Zipkin UI The tracing output data is verbose and can be difficult to interpret using the REST API, especially since it represents a structure of spans. Zipkin provides a web-based UI at http://localhost:9411/zipkin , where you can see a visual representation of the same data and the relationship between spans within a trace. If you see a Lens UI button at the top center then click on it and it will take you to the specific UI used by this guide. Click on the UI refresh button (the search icon) as shown in the image below. Notice that you can change the look-back time to restrict the trace list. Trace refresh The image below shows the trace summary, including start time and duration of each trace. There are two traces, each one generated in response to a curl http://localhost:8080/greet invocation. The oldest trace will have a much longer duration since there is one-time initialization that occurs. Tracing list view Click on a trace and you will see the trace detail page where the spans are listed. You can clearly see the root span and the relationship among all the spans in the trace, along with timing information. Trace detail page A parent span might not depend on the result of the child. This is called a FollowsFrom reference, see Open Tracing Semantic Spec . Note that the last span that writes the response after the root span ends falls into this category. You can examine span details by clicking on the span row. Refer to the image below, which shows the security span details, including timing information. You can see times for each space relative to the root span. These rows are annotated with Server Start and Server Finish , as shown in the third column. Span detail page Enable Tracing on CDI Beans So far in this tutorial you have used tracing with JAX-RS without needing to annotate. You can enable tracing on other CDI beans, either at the class level or at the method level, as shown by the following examples. Tracing at the Method Level To trace at the method level, you just annotate a method with @Traced. <markup lang=\"java\" title=\"Update the GreetingProvider class; 1) Add a new import and 2) Add the @Traced annotation to the getMessage method:\" >import org.eclipse.microprofile.opentracing.Traced; @Traced String getMessage() { return message.get(); } Import the Traced annotation. Enable tracing for getMessage. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints and check the response:\" >curl http://localhost:8080/greet curl -X GET \"http://localhost:9411/api/v2/spans?serviceName=helidon-mp-1\" -H \"accept: application/json\" <markup lang=\"json\" title=\"Response body\" >[ \"content-read\", \"content-write\", \"dosomework\", \"get:io.helidon.examples.quickstart.mp.greetresource.getdefaultmessage\", \"io.helidon.examples.quickstart.mp.greetingprovider.getmessage\", \"security\", \"security:atn\", \"security:atz\", \"security:response\" ] There is a new span name for the getmessage method, since your code called that method during the invocation of /greet . Click the back button on your browser, then click on the UI refresh button to see the new trace. Select the newest trace in the list to see the trace detail page like the one below. Notice the new span named io.helidon.examples.quickstart.mp.greetingprovider.getmessage . Trace detail page with new span getmessage Tracing at the Class Level To trace at the class level, annotate the class with @Traced. This will enable tracing for all class methods, except for the constructor and private methods. Update the GreetingProvider class Add @Traced to the GreetingProvider class Remove @Traced from the getMessage method <markup lang=\"java\" >@Traced @ApplicationScoped public class GreetingProvider { String getMessage() { return message.get(); } } This will enable tracing for all class methods, except for the constructor and methods that are private. Remove @Traced for the getMessage method. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints and check the response:\" >curl http://localhost:8080/greet curl -X GET \"http://localhost:9411/api/v2/spans?serviceName=helidon-mp-1\" -H \"accept: application/json\" <markup lang=\"json\" title=\"Response body\" >[ \"io.helidon.examples.quickstart.mp.greetingprovider.getmessage\" ] The service has the same set of span names as above, since getmessage was the only method called in this bean. Next, invoke HTTP PUT to change the greeting, which will cause setMessage to be called. <markup lang=\"bash\" title=\"Invoke the endpoints and check the response:\" >curl -i -X PUT -H \"Content-Type: application/json\" -d '{\"greeting\": \"Hi\"}' http://localhost:8080/greet/greeting curl -X GET \"http://localhost:9411/api/v2/spans?serviceName=helidon-mp-1\" -H \"accept: application/json\" Invoke the endpoint to change the greeting. <markup lang=\"json\" title=\"Response body\" >[ \"content-read\", \"content-write\", \"get:io.helidon.examples.quickstart.mp.greetresource.getdefaultmessage\", \"io.helidon.examples.quickstart.mp.greetingprovider.getmessage\", \"io.helidon.examples.quickstart.mp.greetingprovider.setmessage\", \"put:io.helidon.examples.quickstart.mp.greetresource.updategreeting\", \"security\", \"security:atn\", \"security:atz\", \"security:response\" ] The GreetingProvider.setmessage method was traced since you enabled class level tracing. The JAX-RS method GreetResource.updategreeting was traced automatically by Helidon. You can refresh the UI view and drill down the trace to see the new spans. Methods invoked directly by your code are not enabled for tracing, even if you explicitly annotate them with @Traced. Tracing only works for methods invoked on CDI beans. See the example below. <markup lang=\"java\" title=\"Update the GreetingProvider class with the following code:\" >@ApplicationScoped public class GreetingProvider { private final AtomicReference&lt;String&gt; message = new AtomicReference&lt;&gt;(); @Inject public GreetingProvider(@ConfigProperty(name = \"app.greeting\") String message) { this.message.set(message); } @Traced String getMessage() { return getMessage2(); } @Traced String getMessage2() { return message.get(); } void setMessage(String message) { this.message.set(message); } } The getMessage method will be traced since it is externally invoked by GreetResource . The getMessage2 method will not be traced, even with the @Traced annotation, since it is called internally by getMessage . <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints and check the response:\" >curl http://localhost:8080/greet curl -X GET \"http://localhost:9411/api/v2/spans?serviceName=helidon-mp-1\" -H \"accept: application/json\" <markup lang=\"json\" title=\"Response body\" >[ \"io.helidon.examples.quickstart.mp.greetingprovider.getmessage\" ] The getMessage method is traced, but getMessage2 is not. Trace Across Services Helidon automatically traces across services as long as the services use the same tracer, for example, the same instance of Zipkin. This means a single trace can include spans from multiple services and hosts. OpenTracing uses a SpanContext to propagate tracing information across process boundaries. When you make client API calls, Helidon will internally call OpenTracing APIs to propagate the SpanContext . There is nothing you need to do in your application to make this work. To demonstrate distributed tracing, you will need to create a second project, where the server listens on port 8081. Create a new root directory to hold this new project, then do the following steps, similar to what you did at the start of this guide: Create a second service <markup lang=\"bash\" title=\"Run the Maven archetype:\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-mp \\ -DarchetypeVersion=3.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-mp-2 \\ -Dpackage=io.helidon.examples.quickstart.mp <markup lang=\"bash\" title=\"The project will be built and run from the helidon-quickstart-mp directory:\" >cd helidon-quickstart-mp-2 <markup lang=\"xml\" title=\"Add the following dependency to pom.xml :\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-zipkin&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"bash\" title=\"Replace META-INF/microprofile-config.properties with the following:\" >app.greeting=Hello From MP-2 tracing.service=helidon-mp-2 # Microprofile server properties server.port=8081 <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-mp-2.jar <markup lang=\"bash\" title=\"Run the curl command in a new terminal window and check the response ( notice the port is 8081 ) :\" >curl http://localhost:8081/greet <markup lang=\"json\" title=\"Response body\" >{ \"message\": \"Hello From MP-2 World!\" } Modify the first service Once you have validated that the second service is running correctly, you need to modify the original application to call it. <markup lang=\"java\" title=\"Replace the GreetResource class with the following code:\" >package io.helidon.examples.quickstart.mp; import java.util.Collections; import jakarta.enterprise.context.RequestScoped; import jakarta.inject.Inject; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.GET; import jakarta.ws.rs.Path; import jakarta.ws.rs.Produces; import jakarta.ws.rs.client.WebTarget; import jakarta.ws.rs.core.MediaType; import org.glassfish.jersey.server.Uri; @Path(\"/greet\") @RequestScoped public class GreetResource { @Uri(\"http://localhost:8081/greet\") private WebTarget target; private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); private final GreetingProvider greetingProvider; @Inject public GreetResource(GreetingProvider greetingConfig) { this.greetingProvider = greetingConfig; } @GET @Produces(MediaType.APPLICATION_JSON) public JsonObject getDefaultMessage() { return createResponse(\"World\"); } @GET @Path(\"/outbound\") public JsonObject outbound() { return target.request().accept(MediaType.APPLICATION_JSON_TYPE).get(JsonObject.class); } private JsonObject createResponse(String who) { String msg = String.format(\"%s %s!\", greetingProvider.getMessage(), who); return JSON.createObjectBuilder().add(\"message\", msg).build(); } } This is the WebTarget needed to send a request to the second service at port 8081 . This is the new endpoint that will call the second service. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl -i http://localhost:8080/greet/outbound The request went to the service on 8080 , which then invoked the service at 8081 to get the greeting. <markup lang=\"json\" title=\"Response body\" >{ \"message\": \"Hello From MP-2 World!\" } Notice the greeting came from the second service. Refresh the Zipkin UI trace listing page and notice that there is a trace across two services. Tracing multiple service list view Click on the trace with two services to see the detail view. Tracing across multiple services detail view In the image above, you can see that the trace includes spans from two services. You will notice there is a gap before the sixth span, which is a get operation. This is a one-time client initialization delay. Run the /outbound curl command again and look at the new trace to see that the delay no longer exists. You can now stop your second service, it is no longer used in this guide. ",
            "title": "Examples"
        },
        {
            "location": "mp/tracing",
            "text": "<markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named zipkin.yaml , with the following contents:\" >apiVersion: v1 kind: Service metadata: name: zipkin spec: ports: - port: 9411 protocol: TCP selector: app: zipkin --- kind: Pod apiVersion: v1 metadata: name: zipkin labels: app: zipkin spec: containers: - name: zipkin image: openzipkin/zipkin imagePullPolicy: IfNotPresent ports: - containerPort: 9411 <markup lang=\"bash\" title=\"Create the Zipkin pod and ClusterIP service:\" >kubectl apply -f ./zipkin.yaml <markup lang=\"bash\" title=\"Create a Zipkin external server and expose it on port 9142:\" >kubectl expose pod zipkin --name=zipkin-external --port=9412 --target-port=9411 --type=LoadBalancer Create a service so that you can access the Zipkin UI. Navigate to http://localhost:9412/zipkin to validate that you can access Zipkin running in Kubernetes. It may take a few seconds before it is ready. ",
            "title": "Deploy Zipkin into Kubernetes"
        },
        {
            "location": "mp/tracing",
            "text": "<markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named tracing.yaml , with the following contents:\" >kind: Service apiVersion: v1 metadata: name: helidon-tracing labels: app: helidon-tracing spec: type: NodePort selector: app: helidon-tracing ports: - port: 8080 targetPort: 8080 name: http --- kind: Deployment apiVersion: apps/v1 metadata: name: helidon-tracing spec: replicas: 1 selector: matchLabels: app: helidon-tracing template: metadata: labels: app: helidon-tracing version: v1 spec: containers: - name: helidon-tracing image: helidon-tracing-mp imagePullPolicy: IfNotPresent ports: - containerPort: 8080 A service of type NodePort that serves the default routes on port 8080 . A deployment with one replica of a pod. <markup lang=\"bash\" title=\"Create and deploy the application into Kubernetes:\" >kubectl apply -f ./tracing.yaml ",
            "title": "Deploy Your Helidon Application into Kubernetes"
        },
        {
            "location": "mp/tracing",
            "text": "<markup lang=\"bash\" title=\"Get the application service information:\" >kubectl get service/helidon-tracing <markup lang=\"listing\" >NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE helidon-tracing NodePort 10.99.159.2 &lt;none&gt; 8080:31143/TCP 8s A service of type NodePort that serves the default routes on port 31143 . <markup lang=\"bash\" title=\"Verify the tracing endpoint using port 31143 , your port will likely be different:\" >curl http://localhost:31143/greet <markup lang=\"json\" title=\"Response body\" >{ \"message\": \"Hello World!\" } Access the Zipkin UI at http://localhost:9412/zipkin and click on the refresh icon to see the trace that was just created. ",
            "title": "Access Your Application and the Zipkin Trace"
        },
        {
            "location": "mp/tracing",
            "text": " You can now delete the Kubernetes resources that were just created during this example. <markup lang=\"bash\" title=\"Delete the Kubernetes resources:\" >kubectl delete -f ./zipkin.yaml kubectl delete -f ./tracing.yaml kubectl delete service zipkin-external docker rm -f zipkin ",
            "title": "Cleanup"
        },
        {
            "location": "mp/tracing",
            "text": " The following example demonstrate how to use Zipkin from a Helidon application running in Kubernetes. <markup lang=\"bash\" title=\"Update application.yaml :\" >tracing: host: \"zipkin\" <markup lang=\"bash\" title=\"Stop the application and build the docker image for your application:\" >docker build -t helidon-tracing-mp . Deploy Zipkin into Kubernetes <markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named zipkin.yaml , with the following contents:\" >apiVersion: v1 kind: Service metadata: name: zipkin spec: ports: - port: 9411 protocol: TCP selector: app: zipkin --- kind: Pod apiVersion: v1 metadata: name: zipkin labels: app: zipkin spec: containers: - name: zipkin image: openzipkin/zipkin imagePullPolicy: IfNotPresent ports: - containerPort: 9411 <markup lang=\"bash\" title=\"Create the Zipkin pod and ClusterIP service:\" >kubectl apply -f ./zipkin.yaml <markup lang=\"bash\" title=\"Create a Zipkin external server and expose it on port 9142:\" >kubectl expose pod zipkin --name=zipkin-external --port=9412 --target-port=9411 --type=LoadBalancer Create a service so that you can access the Zipkin UI. Navigate to http://localhost:9412/zipkin to validate that you can access Zipkin running in Kubernetes. It may take a few seconds before it is ready. Deploy Your Helidon Application into Kubernetes <markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named tracing.yaml , with the following contents:\" >kind: Service apiVersion: v1 metadata: name: helidon-tracing labels: app: helidon-tracing spec: type: NodePort selector: app: helidon-tracing ports: - port: 8080 targetPort: 8080 name: http --- kind: Deployment apiVersion: apps/v1 metadata: name: helidon-tracing spec: replicas: 1 selector: matchLabels: app: helidon-tracing template: metadata: labels: app: helidon-tracing version: v1 spec: containers: - name: helidon-tracing image: helidon-tracing-mp imagePullPolicy: IfNotPresent ports: - containerPort: 8080 A service of type NodePort that serves the default routes on port 8080 . A deployment with one replica of a pod. <markup lang=\"bash\" title=\"Create and deploy the application into Kubernetes:\" >kubectl apply -f ./tracing.yaml Access Your Application and the Zipkin Trace <markup lang=\"bash\" title=\"Get the application service information:\" >kubectl get service/helidon-tracing <markup lang=\"listing\" >NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE helidon-tracing NodePort 10.99.159.2 &lt;none&gt; 8080:31143/TCP 8s A service of type NodePort that serves the default routes on port 31143 . <markup lang=\"bash\" title=\"Verify the tracing endpoint using port 31143 , your port will likely be different:\" >curl http://localhost:31143/greet <markup lang=\"json\" title=\"Response body\" >{ \"message\": \"Hello World!\" } Access the Zipkin UI at http://localhost:9412/zipkin and click on the refresh icon to see the trace that was just created. Cleanup You can now delete the Kubernetes resources that were just created during this example. <markup lang=\"bash\" title=\"Delete the Kubernetes resources:\" >kubectl delete -f ./zipkin.yaml kubectl delete -f ./tracing.yaml kubectl delete service zipkin-external docker rm -f zipkin ",
            "title": "Integration with Kubernetes"
        },
        {
            "location": "mp/tracing",
            "text": " Helidon MP fully supports MicroProfile OpenTracing. You can add custom spans using @Traced annotation on methods of CDI beans. Note for invoking methods on same class: If you invoke a method on the same class, @Traced annotation would be ignored, as it is not invoked through a CDI proxy and as such cannot be intercepted. To make sure @Traced is honored, use it on JAX-RS resource methods and on CDI bean methods used from other beans. ",
            "title": "Creating custom spans"
        },
        {
            "location": "mp/tracing",
            "text": " There is an option to provide SpanContext programmatically (such as when writing a command line application that starts the span manually). You can either configure the span context as the active span, or explicitly define it as client property. <markup lang=\"java\" title=\"Tracing propagation with Jersey client\" >import static io.helidon.tracing.jersey.client.ClientTracingFilter.CURRENT_SPAN_CONTEXT_PROPERTY_NAME; import static io.helidon.tracing.jersey.client.ClientTracingFilter.TRACER_PROPERTY_NAME; Response response = client.target(serviceEndpoint) .request() // tracer should be provided unless available as GlobalTracer .property(TRACER_PROPERTY_NAME, tracer) .property(CURRENT_SPAN_CONTEXT_PROPERTY_NAME, spanContext) .get(); ",
            "title": "Manual handling of traces in Jersey Client"
        },
        {
            "location": "mp/tracing",
            "text": " Automated trace propagation is supported currently only with Jersey client. Tracing propagation works automatically as long as you run within the scope of Helidon MP and use Helidon components to invoke external services. Manual handling of traces in Jersey Client There is an option to provide SpanContext programmatically (such as when writing a command line application that starts the span manually). You can either configure the span context as the active span, or explicitly define it as client property. <markup lang=\"java\" title=\"Tracing propagation with Jersey client\" >import static io.helidon.tracing.jersey.client.ClientTracingFilter.CURRENT_SPAN_CONTEXT_PROPERTY_NAME; import static io.helidon.tracing.jersey.client.ClientTracingFilter.TRACER_PROPERTY_NAME; Response response = client.target(serviceEndpoint) .request() // tracer should be provided unless available as GlobalTracer .property(TRACER_PROPERTY_NAME, tracer) .property(CURRENT_SPAN_CONTEXT_PROPERTY_NAME, spanContext) .get(); ",
            "title": "Trace propagation across services"
        },
        {
            "location": "mp/tracing",
            "text": "<markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-zipkin&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Zipkin Tracing"
        },
        {
            "location": "mp/tracing",
            "text": " Zipkin Tracing <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-zipkin&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Additional Information"
        },
        {
            "location": "mp/tracing",
            "text": " Zipkin tracer configuration Type: io.opentracing.Tracer This is a standalone configuration type, prefix from configuration root: tracing ",
            "title": "Configuring Zipkin"
        },
        {
            "location": "mp/tracing",
            "text": "<markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-jaeger&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Jaeger Tracing"
        },
        {
            "location": "mp/tracing",
            "text": " Optional configuration options key type default value description api-version Version (V1, V2) V2 Version of Zipkin API to use. Defaults to Version#V2. boolean-tags Map&lt;string, boolean&gt; &#160; Tracer level tags that get added to all reported spans. enabled boolean true When enabled, tracing will be sent. If enabled is false, tracing should use a no-op tracer. global boolean true When enabled, the created instance is also registered as a global tracer. host string &#160; Host to use to connect to tracing collector. Default is defined by each tracing integration. int-tags Map&lt;string, int&gt; &#160; Tracer level tags that get added to all reported spans. path string &#160; Path on the collector host to use when sending data to tracing collector. Default is defined by each tracing integration. port int &#160; Port to use to connect to tracing collector. Default is defined by each tracing integration. protocol string &#160; Protocol to use (such as http or https ) to connect to tracing collector. Default is defined by each tracing integration. service string &#160; Service name of the traced service. tags Map&lt;string, string&gt; &#160; Tracer level tags that get added to all reported spans. The following is an example of a Zipkin configuration, specified in the YAML format. <markup lang=\"yaml\" >tracing: zipkin: service: \"helidon-service\" protocol: \"https\" host: \"zipkin\" port: 9987 api-version: 1 # this is the default path for API version 2 path: \"/api/v2/spans\" tags: tag1: \"tag1-value\" tag2: \"tag2-value\" boolean-tags: tag3: true tag4: false int-tags: tag5: 145 tag6: 741 Example of Zipkin trace: Jaeger Tracing <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-jaeger&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Configuration options"
        },
        {
            "location": "mp/tracing",
            "text": " Jaeger tracer configuration. Type: io.helidon.tracing.Tracer This is a standalone configuration type, prefix from configuration root: tracing ",
            "title": "Configuring Jaeger"
        },
        {
            "location": "mp/tracing",
            "text": " As the Jaeger Tracing section describes, you can use Jaeger tracing in your Helidon application. ",
            "title": "Jaeger Tracing Metrics"
        },
        {
            "location": "mp/tracing",
            "text": " Optional configuration options key type default value description boolean-tags Map&lt;string, boolean&gt; &#160; Tracer level tags that get added to all reported spans. client-cert-pem Resource &#160; Certificate of client in PEM format. enabled boolean true When enabled, tracing will be sent. If enabled is false, tracing should use a no-op tracer. exporter-timeout-millis Duration 10000 Timeout of exporter requests. global boolean true When enabled, the created instance is also registered as a global tracer. host string &#160; Host to use to connect to tracing collector. Default is defined by each tracing integration. int-tags Map&lt;string, int&gt; &#160; Tracer level tags that get added to all reported spans. path string &#160; Path on the collector host to use when sending data to tracing collector. Default is defined by each tracing integration. port int &#160; Port to use to connect to tracing collector. Default is defined by each tracing integration. private-key-pem Resource &#160; Private key in PEM format. protocol string &#160; Protocol to use (such as http or https ) to connect to tracing collector. Default is defined by each tracing integration. sampler-param Number 1 The sampler parameter (number). sampler-type SamplerType (CONSTANT, RATIO) CONSTANT Sampler type. See &lt;a href=\"https://www.jaegertracing.io/docs/latest/sampling/#client-sampling-configuration\"&gt;Sampler types&lt;/a&gt;. service string &#160; Service name of the traced service. tags Map&lt;string, string&gt; &#160; Tracer level tags that get added to all reported spans. trusted-cert-pem Resource &#160; Trusted certificates in PEM format. The following is an example of a Jaeger configuration, specified in the YAML format. <markup lang=\"yaml\" >tracing: service: \"helidon-full-http\" protocol: \"https\" host: \"jaeger\" port: 14240 Jaeger Tracing Metrics As the Jaeger Tracing section describes, you can use Jaeger tracing in your Helidon application. ",
            "title": "Configuration options"
        },
        {
            "location": "mp/tracing",
            "text": " MicroProfile Opentracing Specification Opentracing Project ",
            "title": "Reference"
        },
        {
            "location": "mp/websocket",
            "text": " Overview Maven Coordinates Usage API Examples Reference ",
            "title": "Contents"
        },
        {
            "location": "mp/websocket",
            "text": " Helidon integrates with Tyrus to provide support for the Jakarta WebSocket API . ",
            "title": "Overview"
        },
        {
            "location": "mp/websocket",
            "text": " To enable Jakarta Websocket add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.websocket&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-websocket&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "mp/websocket",
            "text": " The WebSocket API enables Java applications to participate in WebSocket interactions as both servers and clients. The server API supports two flavors: annotated and programmatic endpoints. Annotated endpoints, as suggested by their name, use Java annotations to provide the necessary meta-data to define WebSocket handlers; programmatic endpoints implement API interfaces and are annotation free. Annotated endpoints tend to be more flexible since they allow different method signatures depending on the application needs, whereas programmatic endpoints must implement an interface and are, therefore, bounded to its definition. Helidon MP support is centered around annotations and bean discovery using CDI. Developers can choose between annotated and programmatic endpoints or use any combination of them. Using annotated endpoints is recommended in MP as they usually result in more succinct and easier-to-read code. ",
            "title": "Usage"
        },
        {
            "location": "mp/websocket",
            "text": " <div class=\"table__overflow elevation-1 flex sm10 \"> Annotation Description @ServerEndpoint This class level annotation declares that the class it decorates is a web socket endpoint that will be deployed and made available in the URI-space of a web socket server. The annotation allows the developer to define the URL (or URI template) which this endpoint will be published, and other important properties of the endpoint to the websocket runtime, such as the encoders it uses to send messages. @ClientEndpoint The ClientEndpoint annotation, a class level annotation, is used to denote that a POJO is a web socket client and can be deployed as such. Similar to @ServerEndpoint , POJOs that are annotated with this annotation can have methods that, using the web socket method level annotations, are web socket lifecycle methods. @OnOpen This method level annotation can be used to decorate a Java method that will be called when a new web socket session is open. @OnMessage This method level annotation can be used to make a Java method receive incoming web socket messages. Each websocket endpoint may only have one message handling method for each of the native websocket message formats: text, binary and pong. @OnError This method level annotation can be used to decorate a Java method that will be called in order to handle errors. @OnClose This method level annotation can be used to decorate a Java method that will be called when a web socket session is closing. ",
            "title": "API"
        },
        {
            "location": "mp/websocket",
            "text": " This section describes the implementation of a simple application that uses a REST resource to push messages into a shared queue and a WebSocket endpoint to download messages from the queue, one at a time, over a connection. The example will show how REST and WebSocket connections can be seamlessly combined into a Helidon application. The Helidon MP application shown here takes full advantage of CDI and class scanning and does not require any additional code given that the necessary information is available from the code annotations. The REST endpoint is implemented as a JAX-RS resource, and the shared queue (in application scope) is directly injected: <markup lang=\"java\" >@Path(\"rest\") public class MessageQueueResource { @Inject private MessageQueue messageQueue; @POST @Consumes(\"text/plain\") public void push(String s) { messageQueue.push(s); } } Here we opt for the use of an annotated WebSocket endpoint decorated by @ServerEndpoint that provides all the meta-data necessary for Helidon to create the endpoint. <markup lang=\"java\" >@ServerEndpoint( value = \"/websocket\", encoders = { UppercaseEncoder.class }) public class MessageBoardEndpoint { @Inject private MessageQueue messageQueue; @OnMessage public void onMessage(Session session, String message) { if (message.equals(\"SEND\")) { while (!messageQueue.isEmpty()) { session.getBasicRemote().sendObject(messageQueue.pop()); } } } } Since MessageBoardEndpoint is just a POJO, it uses additional annotations for event handlers such as @OnMessage . One advantage of this approach, much like in the JAX-RS API, is that method signatures are not fixed. In the snipped above, the parameters (which could be specified in any order!) include the WebSocket session and the message received that triggered the call. So what else is needed to run this Helidon MP app? Nothing else other than the supporting classes MessageQueue and UppercaseEncoder . Helidon MP declares both @Path and @ServerEndpoint as bean defining annotation, so all that is needed is for CDI discovery to be enabled --typically in your beans.xml file. By default, both JAX-RS resources and WebSocket endpoints will be available under the root path \"/\" . This default value can be overridden by providing subclasses/implementations for jakarta.ws.rs.Application and jakarta.websocket.server.ServerApplicationConfig , respectively. JAX-RS uses @ApplicationPath on application subclasses to provide this root path, but since there is no equivalent in the WebSocket API, Helidon MP uses its own annotation @RoutingPath on jakarta.websocket.server.ServerApplicationConfig implementations. For instance, if in our example we include the following class: <markup lang=\"java\" >@ApplicationScoped @RoutingPath(\"/web\") public class MessageBoardApplication implements ServerApplicationConfig { @Override public Set&lt;ServerEndpointConfig&gt; getEndpointConfigs( Set&lt;Class&lt;? extends Endpoint&gt;&gt; endpoints) { assert endpoints.isEmpty(); return Collections.emptySet(); // No programmatic endpoints } @Override public Set&lt;Class&lt;?&gt;&gt; getAnnotatedEndpointClasses(Set&lt;Class&lt;?&gt;&gt; endpoints) { return endpoints; // Returned scanned endpoints } } the root path for WebSocket endpoints will be \"/web\" instead of the default \"/\" . Note that @RoutingPath is not a bean defining annotation, thus the need to use @ApplicationScoped --which, as before, requires CDI bean discovery mode to be annotated . In addition to @RoutingPath , these classes can be annotated with @RoutingName to associate an endpoint with a Helidon named socket. Please refer to the Javadoc of that annotation for additional information. All endpoint methods in Helidon MP are executed in a separate thread pool, independently of Netty. Therefore, there is no need to create additional threads for blocking or long-running operations as these will not affect Netty&#8217;s ability to process networking data. For more information see the example . ",
            "title": "Examples"
        },
        {
            "location": "mp/websocket",
            "text": " Eclipse Tyrus WebSocket RFC 6455 Helidon MicroProfile Tyrus Javadoc ",
            "title": "Reference"
        },
        {
            "location": "se/aot",
            "text": " Helidon applications can be compiled into a native executable using GraalVM native image. When using applications created using the CLI, or when you configure Helidon application pom as a parent of your module, you can use the following steps to build a native image from your application: Create an environment variable GRAALVM_HOME pointing to your installation of GraalVM with native-image installed Run Maven command mvn clean package -Pnative-image Execute the native executable created in target directory of your project ",
            "title": "preambule"
        },
        {
            "location": "se/aot",
            "text": " Some Helidon components are not (yet) supported in native image, some have restrictions. The following table lists all Helidon features and their support for native image. Helidon SE features in AOT Feature Component AOT note ✅ Config Config &#160; ✅ &#160; Encryption &#160; ✅ &#160; HOCON &#160; ✅ &#160; Object Mapping &#160; ✅ &#160; YAML &#160; ❓ &#160; etcd Not yet tested. ✅ &#160; git &#160; ✅ Db Client Db Client &#160; ✅ &#160; Health Check &#160; 🔶 &#160; JDBC Tested with Helidon modules for Oracle and H2 driver (see examples) ✅ &#160; Metrics &#160; ✅ &#160; Tracing &#160; ✅ &#160; mongo &#160; ✅ Health Health &#160; ✅ &#160; Built-ins &#160; ✅ Messaging Messaging &#160; ✅ Metrics Metrics &#160; ✅ OpenAPI OpenAPI &#160; ✅ Security Security &#160; ✅ &#160; Integration: Jersey &#160; ✅ &#160; Integration: WebServer &#160; ✅ &#160; Integration: gRPC &#160; ✅ &#160; OIDC &#160; ✅ &#160; Provider: ABAC &#160; ✅ &#160; Provider/ABAC/Policy: EL Requires reflection configuration for used classes. ✅ &#160; Provider/ABAC: Role &#160; ✅ &#160; Provider/ABAC: Scope &#160; ✅ &#160; Provider/ABAC: Time &#160; ❓ &#160; Provider: Google Login Not yet tested. ✅ &#160; Provider: Header &#160; ✅ &#160; Provider: HTTP Basic &#160; ✅ &#160; Provider: HTTP Digest &#160; ✅ &#160; Provider: HTTP Signatures &#160; ❓ &#160; Provider: IDCS Role Mapper Not yet tested. ✅ &#160; Provider: JWT &#160; ✅ Tracing Tracing &#160; ✅ &#160; Integration: Jersey Server &#160; ✅ &#160; Integration: Jersey Client &#160; ✅ &#160; Jaeger &#160; ✅ &#160; Zipkin &#160; ✅ WebClient WebClient &#160; ✅ &#160; Web Client &#160; ✅ &#160; Jackson &#160; ✅ &#160; JSON-B &#160; ✅ &#160; JSON-P &#160; ✅ &#160; Metrics &#160; ✅ &#160; Multi-part &#160; ✅ &#160; Security &#160; ✅ &#160; Tracing &#160; ✅ WebServer WebServer &#160; ✅ &#160; Access Log &#160; ✅ &#160; CORS &#160; ✅ &#160; Jackson &#160; ✅ &#160; Jersey &#160; ✅ &#160; JSON-B &#160; ✅ &#160; JSON-P &#160; ✅ &#160; Multi-part &#160; ❓ &#160; Prometheus Not yet tested. ✅ &#160; Websocket Server only. ✅ gRPC Server gRPC Server Since GraalVM 21.0.0 ✅ &#160; Metrics &#160; ✅ gRPC Client gRPC Client Since GraalVM 21.0.0 ✅ &#160; Metrics &#160; ✅ Scheduling Scheduling &#160; ✅ OCI OCI Integration Modules with group id io.helidon.integrations.oci ✅ Vault Hashicorp Vault Integration &#160; ",
            "title": "AOT supported modules"
        },
        {
            "location": "se/config/advanced-configuration",
            "text": " Overview Advanced Config Sources Advanced Config Parsers Config Keys with . in name Filters, Overrides and Token Substitution Executors for Asynchronous Config Activity ",
            "title": "Contents"
        },
        {
            "location": "se/config/advanced-configuration",
            "text": " This section discusses several advanced topics related to Helidon configuration. ",
            "title": "Overview"
        },
        {
            "location": "se/config/advanced-configuration",
            "text": " The config system supports using environment variables as a config source, and is enabled by default. Since environment variable names are normally restricted to alphanumeric characters and underscore, this config source adds aliases that enable setting or overriding config entries with dotted and/or hyphenated keys. The mapping makes it possible to set or override a config entry with a key of \"foo.bar\" using an environment variable named \"FOO_BAR\" and \"foo.bar-baz\" using \"FOO_BAR_dash_BAZ\" . One use case for this mapping is config overrides in containers, where passing environment variables directly or via Kubernetes Secrets/ConfigMaps is common. Scripts that solve the mapping problem by explicitly converting variables to system properties can also be simplified. Aliases are produced for any environment variable name that matches all of the following: does not begin or end with a '_' character does not contain \"__\" contains one or more '_' characters For each such name, two aliases are added with the names mapped as follows: Replace any \"_dash_\" or \"_DASH_\" substrings with \"-\" , e.g. \"APP_PAGE_dash_SIZE\" becomes \"APP_PAGE-SIZE\" . Replace '_' with '.' and add as an alias, e.g. \"APP_GREETING\" is added as \"APP.GREETING\" and \"APP_PAGE-SIZE\" is added as \"APP.PAGE-SIZE\" . This mapping is added primarily to support mixed case config keys such as \"app.someCamelCaseKey\" . Convert the result of step 2 to lowercase and add as an alias, e.g. \"APP.GREETING\" is added as \"app.greeting\" and \"APP.PAGE-SIZE\" is added as \"app.page-size\" . ",
            "title": "Environment Variables Config Source"
        },
        {
            "location": "se/config/advanced-configuration",
            "text": " The config system supports using a file system directory as a config source. Each non-directory file in the directory becomes a config entry: the file name is the key and the contents of that file are used as the corresponding config String value. The following example shows, for example, one way to load Kubernetes secrets mounted on the pod&#8217;s filesystem. If the directory conf/secrets contains these two files <markup title=\"File secrets/username \" >jose <markup title=\"File secrets/password \" >^ery$ecretP&amp;ssword your application can load this as configuration as follows: <markup lang=\"java\" title=\"Using directory config source\" >Config secrets = Config.builder( ConfigSources.directory(\"conf/secrets\")) .disableEnvironmentVariablesSource() .disableSystemPropertiesSource() .build(); assert secrets.get(\"username\") .asString() .get() .equals(\"jose\"); assert secrets.get(\"password\") .asString() .get() .equals(\"^ery$ecretP&amp;ssword\"); Loads all files from the conf/secrets directory. No need to use environment variables or system properties as sources in building the Config . The loaded config maps the key username to the value jose &#8230;&#8203; &#8230;&#8203;and the key password to ^ery$ecretP&amp;ssword . Remember that your application can process the contents of a given file as configuration. See the config sources section and the ConfigSources.file JavaDoc. ",
            "title": "Directory Config Source"
        },
        {
            "location": "se/config/advanced-configuration",
            "text": "<markup lang=\"java\" >Config anotherConfig = Config.create(classpath(\"application.conf\")); Config config = Config.create( ConfigSources.create(anotherConfig.get(\"data\"))); ",
            "title": "Subtree of Another Config "
        },
        {
            "location": "se/config/advanced-configuration",
            "text": "<markup lang=\"java\" >Config config = Config.create( ConfigSources.create(System.getProperties()).build()); ",
            "title": " Properties Object"
        },
        {
            "location": "se/config/advanced-configuration",
            "text": "<markup lang=\"java\" >Config config = Config.create( ConfigSources.create(\"app.greeting = Hi\", \"text/x-java-properties\")); ",
            "title": " String of a Given Media Type"
        },
        {
            "location": "se/config/advanced-configuration",
            "text": "<markup lang=\"java\" >Config config = Config.crate( ConfigSources.create(Map.of(\"app.page-size\", \"20\")) .lax() .build()); ",
            "title": " Map "
        },
        {
            "location": "se/config/advanced-configuration",
            "text": "<markup lang=\"java\" >Config config = Config.create( ConfigSources.create(ObjectNode.builder() .addList(\"app.basic-range\", ListNode.builder() .addValue(\"-20\") .addValue(\"20\") .build()) .build())); ConfigSources.create variants for Properties or Map arguments return a ConfigSources.MapBuilder instance. A similar create variant accepts a Readable instead of a String . MapBuilder by default throws an exception if a key appears more than once in the map. The lax() method relaxes this; the config system logs a warning instead. ",
            "title": " ad hoc Config Nodes"
        },
        {
            "location": "se/config/advanced-configuration",
            "text": " The config system provides several ways to create a Config tree from data already in memory. See the ConfigSources javadoc for further details. The numerous variants of the from method construct ConfigSource or Builder&lt;ConfigSource&gt; instances. Subtree of Another Config <markup lang=\"java\" >Config anotherConfig = Config.create(classpath(\"application.conf\")); Config config = Config.create( ConfigSources.create(anotherConfig.get(\"data\"))); Properties Object <markup lang=\"java\" >Config config = Config.create( ConfigSources.create(System.getProperties()).build()); String of a Given Media Type <markup lang=\"java\" >Config config = Config.create( ConfigSources.create(\"app.greeting = Hi\", \"text/x-java-properties\")); Map <markup lang=\"java\" >Config config = Config.crate( ConfigSources.create(Map.of(\"app.page-size\", \"20\")) .lax() .build()); ad hoc Config Nodes <markup lang=\"java\" >Config config = Config.create( ConfigSources.create(ObjectNode.builder() .addList(\"app.basic-range\", ListNode.builder() .addValue(\"-20\") .addValue(\"20\") .build()) .build())); ConfigSources.create variants for Properties or Map arguments return a ConfigSources.MapBuilder instance. A similar create variant accepts a Readable instead of a String . MapBuilder by default throws an exception if a key appears more than once in the map. The lax() method relaxes this; the config system logs a warning instead. ",
            "title": "In-memory Config Sources"
        },
        {
            "location": "se/config/advanced-configuration",
            "text": " Sometimes you might want to create a single config tree from multiple sources but in a way that keeps the config from different sources in different subtrees. The config system lets you assign a prefix to all keys from a given source using the ConfigSources.prefixed method. The following example shows two YAML files as config sources and the code to load each with a different prefix into a single Config tree: <markup lang=\"hocon\" title=\"File app.conf \" >greeting = \"Hello\" page-size = 20 basic-range = [ -20, 20 ] <markup lang=\"hocon\" title=\"File data.conf \" >providers: [ { name = \"Provider1\" class = \"this.is.my.Provider1\" }, { name = \"Provider2\" class = \"this.is.my.Provider2\" } ] <markup lang=\"java\" title=\"Using prefixed config source\" >Config config = Config.create( ConfigSources.prefixed(\"app\", classpath(\"app.conf\")), ConfigSources.prefixed(\"data\", classpath(\"data.conf\"))); assert config.get(\"app.greeting\") .asString() .get() .equals(\"Hello\"); assert config.get(\"data.providers.0.name\") .asString() .get() .equals(\"Provider1\"); Specifies the prefix app for the associated source. Supplier&lt;ConfigSource&gt; for the file app.conf loaded from the current classpath . Specifies the prefix data for the associated source. Supplier&lt;ConfigSource&gt; for the file app.conf loaded from the current classpath . Key app.greeting combines the app prefix and the original key greeting from the app.conf source. Key data.providers.0.name combines the data prefix and the original key providers.0.name property from data.conf source. This technique can be useful, for example, if multiple sources contain keys that might overlap; assigning different prefixes to the keys from different sources gives your application a way to access all config elements distinctly even if their keys would otherwise conflict. ",
            "title": "Prefixed Config Sources"
        },
        {
            "location": "se/config/advanced-configuration",
            "text": " The ConfigSources.create(Supplier&lt;ConfigSource&gt;&#8230;&#8203;) and ConfigSources.create(List&lt;Supplier&lt;ConfigSource&gt;&#8230;&#8203;) methods return a CompositeBuilder . By default, earlier sources in the list have higher priority than later ones, meaning that if the same key appears in two or more sources the source earlier in the list prevails. Each CompositeConfigSource 's merging strategy actually controls this behavior. The config system provides the FallbackMergingStrategy which implements the default, \"first wins\" algorithm. You can write your own implementation of ConfigSources.MergingStrategy and use it instead to provide a different algorithm. <markup lang=\"java\" title=\"Composite config source example\" >Config config = Config.create( ConfigSources.create(file(\"conf/dev.properties\").optional(), file(\"conf/config.properties\").optional()) .add(classpath(\"application.properties\")) .mergingStrategy(ConfigSources.MergingStrategy.fallback())); Creates a new Config instance from a single composite config source. Method ConfigSources.create(sources&#8230;&#8203;) returns CompositeBuilder instance initialized with two sources (from dev.properties and config.properties files). Adds third config source ( application.properties on classpath) to the same CompositeBuilder . Specifies the merging strategy. This example uses the default fallback merging strategy. ",
            "title": "Merging Strategies"
        },
        {
            "location": "se/config/advanced-configuration",
            "text": " Prefixed Config Sources Sometimes you might want to create a single config tree from multiple sources but in a way that keeps the config from different sources in different subtrees. The config system lets you assign a prefix to all keys from a given source using the ConfigSources.prefixed method. The following example shows two YAML files as config sources and the code to load each with a different prefix into a single Config tree: <markup lang=\"hocon\" title=\"File app.conf \" >greeting = \"Hello\" page-size = 20 basic-range = [ -20, 20 ] <markup lang=\"hocon\" title=\"File data.conf \" >providers: [ { name = \"Provider1\" class = \"this.is.my.Provider1\" }, { name = \"Provider2\" class = \"this.is.my.Provider2\" } ] <markup lang=\"java\" title=\"Using prefixed config source\" >Config config = Config.create( ConfigSources.prefixed(\"app\", classpath(\"app.conf\")), ConfigSources.prefixed(\"data\", classpath(\"data.conf\"))); assert config.get(\"app.greeting\") .asString() .get() .equals(\"Hello\"); assert config.get(\"data.providers.0.name\") .asString() .get() .equals(\"Provider1\"); Specifies the prefix app for the associated source. Supplier&lt;ConfigSource&gt; for the file app.conf loaded from the current classpath . Specifies the prefix data for the associated source. Supplier&lt;ConfigSource&gt; for the file app.conf loaded from the current classpath . Key app.greeting combines the app prefix and the original key greeting from the app.conf source. Key data.providers.0.name combines the data prefix and the original key providers.0.name property from data.conf source. This technique can be useful, for example, if multiple sources contain keys that might overlap; assigning different prefixes to the keys from different sources gives your application a way to access all config elements distinctly even if their keys would otherwise conflict. Merging Strategies The ConfigSources.create(Supplier&lt;ConfigSource&gt;&#8230;&#8203;) and ConfigSources.create(List&lt;Supplier&lt;ConfigSource&gt;&#8230;&#8203;) methods return a CompositeBuilder . By default, earlier sources in the list have higher priority than later ones, meaning that if the same key appears in two or more sources the source earlier in the list prevails. Each CompositeConfigSource 's merging strategy actually controls this behavior. The config system provides the FallbackMergingStrategy which implements the default, \"first wins\" algorithm. You can write your own implementation of ConfigSources.MergingStrategy and use it instead to provide a different algorithm. <markup lang=\"java\" title=\"Composite config source example\" >Config config = Config.create( ConfigSources.create(file(\"conf/dev.properties\").optional(), file(\"conf/config.properties\").optional()) .add(classpath(\"application.properties\")) .mergingStrategy(ConfigSources.MergingStrategy.fallback())); Creates a new Config instance from a single composite config source. Method ConfigSources.create(sources&#8230;&#8203;) returns CompositeBuilder instance initialized with two sources (from dev.properties and config.properties files). Adds third config source ( application.properties on classpath) to the same CompositeBuilder . Specifies the merging strategy. This example uses the default fallback merging strategy. ",
            "title": "Handling Key Collisions"
        },
        {
            "location": "se/config/advanced-configuration",
            "text": " Although the examples above use a single source, you can build a single Config from multiple sources. Handling Key Collisions Prefixed Config Sources Sometimes you might want to create a single config tree from multiple sources but in a way that keeps the config from different sources in different subtrees. The config system lets you assign a prefix to all keys from a given source using the ConfigSources.prefixed method. The following example shows two YAML files as config sources and the code to load each with a different prefix into a single Config tree: <markup lang=\"hocon\" title=\"File app.conf \" >greeting = \"Hello\" page-size = 20 basic-range = [ -20, 20 ] <markup lang=\"hocon\" title=\"File data.conf \" >providers: [ { name = \"Provider1\" class = \"this.is.my.Provider1\" }, { name = \"Provider2\" class = \"this.is.my.Provider2\" } ] <markup lang=\"java\" title=\"Using prefixed config source\" >Config config = Config.create( ConfigSources.prefixed(\"app\", classpath(\"app.conf\")), ConfigSources.prefixed(\"data\", classpath(\"data.conf\"))); assert config.get(\"app.greeting\") .asString() .get() .equals(\"Hello\"); assert config.get(\"data.providers.0.name\") .asString() .get() .equals(\"Provider1\"); Specifies the prefix app for the associated source. Supplier&lt;ConfigSource&gt; for the file app.conf loaded from the current classpath . Specifies the prefix data for the associated source. Supplier&lt;ConfigSource&gt; for the file app.conf loaded from the current classpath . Key app.greeting combines the app prefix and the original key greeting from the app.conf source. Key data.providers.0.name combines the data prefix and the original key providers.0.name property from data.conf source. This technique can be useful, for example, if multiple sources contain keys that might overlap; assigning different prefixes to the keys from different sources gives your application a way to access all config elements distinctly even if their keys would otherwise conflict. Merging Strategies The ConfigSources.create(Supplier&lt;ConfigSource&gt;&#8230;&#8203;) and ConfigSources.create(List&lt;Supplier&lt;ConfigSource&gt;&#8230;&#8203;) methods return a CompositeBuilder . By default, earlier sources in the list have higher priority than later ones, meaning that if the same key appears in two or more sources the source earlier in the list prevails. Each CompositeConfigSource 's merging strategy actually controls this behavior. The config system provides the FallbackMergingStrategy which implements the default, \"first wins\" algorithm. You can write your own implementation of ConfigSources.MergingStrategy and use it instead to provide a different algorithm. <markup lang=\"java\" title=\"Composite config source example\" >Config config = Config.create( ConfigSources.create(file(\"conf/dev.properties\").optional(), file(\"conf/config.properties\").optional()) .add(classpath(\"application.properties\")) .mergingStrategy(ConfigSources.MergingStrategy.fallback())); Creates a new Config instance from a single composite config source. Method ConfigSources.create(sources&#8230;&#8203;) returns CompositeBuilder instance initialized with two sources (from dev.properties and config.properties files). Adds third config source ( application.properties on classpath) to the same CompositeBuilder . Specifies the merging strategy. This example uses the default fallback merging strategy. ",
            "title": "Multi-Source Config s and Composite Config Sources"
        },
        {
            "location": "se/config/advanced-configuration",
            "text": " Environment Variables Config Source The config system supports using environment variables as a config source, and is enabled by default. Since environment variable names are normally restricted to alphanumeric characters and underscore, this config source adds aliases that enable setting or overriding config entries with dotted and/or hyphenated keys. The mapping makes it possible to set or override a config entry with a key of \"foo.bar\" using an environment variable named \"FOO_BAR\" and \"foo.bar-baz\" using \"FOO_BAR_dash_BAZ\" . One use case for this mapping is config overrides in containers, where passing environment variables directly or via Kubernetes Secrets/ConfigMaps is common. Scripts that solve the mapping problem by explicitly converting variables to system properties can also be simplified. Aliases are produced for any environment variable name that matches all of the following: does not begin or end with a '_' character does not contain \"__\" contains one or more '_' characters For each such name, two aliases are added with the names mapped as follows: Replace any \"_dash_\" or \"_DASH_\" substrings with \"-\" , e.g. \"APP_PAGE_dash_SIZE\" becomes \"APP_PAGE-SIZE\" . Replace '_' with '.' and add as an alias, e.g. \"APP_GREETING\" is added as \"APP.GREETING\" and \"APP_PAGE-SIZE\" is added as \"APP.PAGE-SIZE\" . This mapping is added primarily to support mixed case config keys such as \"app.someCamelCaseKey\" . Convert the result of step 2 to lowercase and add as an alias, e.g. \"APP.GREETING\" is added as \"app.greeting\" and \"APP.PAGE-SIZE\" is added as \"app.page-size\" . Directory Config Source The config system supports using a file system directory as a config source. Each non-directory file in the directory becomes a config entry: the file name is the key and the contents of that file are used as the corresponding config String value. The following example shows, for example, one way to load Kubernetes secrets mounted on the pod&#8217;s filesystem. If the directory conf/secrets contains these two files <markup title=\"File secrets/username \" >jose <markup title=\"File secrets/password \" >^ery$ecretP&amp;ssword your application can load this as configuration as follows: <markup lang=\"java\" title=\"Using directory config source\" >Config secrets = Config.builder( ConfigSources.directory(\"conf/secrets\")) .disableEnvironmentVariablesSource() .disableSystemPropertiesSource() .build(); assert secrets.get(\"username\") .asString() .get() .equals(\"jose\"); assert secrets.get(\"password\") .asString() .get() .equals(\"^ery$ecretP&amp;ssword\"); Loads all files from the conf/secrets directory. No need to use environment variables or system properties as sources in building the Config . The loaded config maps the key username to the value jose &#8230;&#8203; &#8230;&#8203;and the key password to ^ery$ecretP&amp;ssword . Remember that your application can process the contents of a given file as configuration. See the config sources section and the ConfigSources.file JavaDoc. In-memory Config Sources The config system provides several ways to create a Config tree from data already in memory. See the ConfigSources javadoc for further details. The numerous variants of the from method construct ConfigSource or Builder&lt;ConfigSource&gt; instances. Subtree of Another Config <markup lang=\"java\" >Config anotherConfig = Config.create(classpath(\"application.conf\")); Config config = Config.create( ConfigSources.create(anotherConfig.get(\"data\"))); Properties Object <markup lang=\"java\" >Config config = Config.create( ConfigSources.create(System.getProperties()).build()); String of a Given Media Type <markup lang=\"java\" >Config config = Config.create( ConfigSources.create(\"app.greeting = Hi\", \"text/x-java-properties\")); Map <markup lang=\"java\" >Config config = Config.crate( ConfigSources.create(Map.of(\"app.page-size\", \"20\")) .lax() .build()); ad hoc Config Nodes <markup lang=\"java\" >Config config = Config.create( ConfigSources.create(ObjectNode.builder() .addList(\"app.basic-range\", ListNode.builder() .addValue(\"-20\") .addValue(\"20\") .build()) .build())); ConfigSources.create variants for Properties or Map arguments return a ConfigSources.MapBuilder instance. A similar create variant accepts a Readable instead of a String . MapBuilder by default throws an exception if a key appears more than once in the map. The lax() method relaxes this; the config system logs a warning instead. Multi-Source Config s and Composite Config Sources Although the examples above use a single source, you can build a single Config from multiple sources. Handling Key Collisions Prefixed Config Sources Sometimes you might want to create a single config tree from multiple sources but in a way that keeps the config from different sources in different subtrees. The config system lets you assign a prefix to all keys from a given source using the ConfigSources.prefixed method. The following example shows two YAML files as config sources and the code to load each with a different prefix into a single Config tree: <markup lang=\"hocon\" title=\"File app.conf \" >greeting = \"Hello\" page-size = 20 basic-range = [ -20, 20 ] <markup lang=\"hocon\" title=\"File data.conf \" >providers: [ { name = \"Provider1\" class = \"this.is.my.Provider1\" }, { name = \"Provider2\" class = \"this.is.my.Provider2\" } ] <markup lang=\"java\" title=\"Using prefixed config source\" >Config config = Config.create( ConfigSources.prefixed(\"app\", classpath(\"app.conf\")), ConfigSources.prefixed(\"data\", classpath(\"data.conf\"))); assert config.get(\"app.greeting\") .asString() .get() .equals(\"Hello\"); assert config.get(\"data.providers.0.name\") .asString() .get() .equals(\"Provider1\"); Specifies the prefix app for the associated source. Supplier&lt;ConfigSource&gt; for the file app.conf loaded from the current classpath . Specifies the prefix data for the associated source. Supplier&lt;ConfigSource&gt; for the file app.conf loaded from the current classpath . Key app.greeting combines the app prefix and the original key greeting from the app.conf source. Key data.providers.0.name combines the data prefix and the original key providers.0.name property from data.conf source. This technique can be useful, for example, if multiple sources contain keys that might overlap; assigning different prefixes to the keys from different sources gives your application a way to access all config elements distinctly even if their keys would otherwise conflict. Merging Strategies The ConfigSources.create(Supplier&lt;ConfigSource&gt;&#8230;&#8203;) and ConfigSources.create(List&lt;Supplier&lt;ConfigSource&gt;&#8230;&#8203;) methods return a CompositeBuilder . By default, earlier sources in the list have higher priority than later ones, meaning that if the same key appears in two or more sources the source earlier in the list prevails. Each CompositeConfigSource 's merging strategy actually controls this behavior. The config system provides the FallbackMergingStrategy which implements the default, \"first wins\" algorithm. You can write your own implementation of ConfigSources.MergingStrategy and use it instead to provide a different algorithm. <markup lang=\"java\" title=\"Composite config source example\" >Config config = Config.create( ConfigSources.create(file(\"conf/dev.properties\").optional(), file(\"conf/config.properties\").optional()) .add(classpath(\"application.properties\")) .mergingStrategy(ConfigSources.MergingStrategy.fallback())); Creates a new Config instance from a single composite config source. Method ConfigSources.create(sources&#8230;&#8203;) returns CompositeBuilder instance initialized with two sources (from dev.properties and config.properties files). Adds third config source ( application.properties on classpath) to the same CompositeBuilder . Specifies the merging strategy. This example uses the default fallback merging strategy. ",
            "title": "Advanced Config Sources"
        },
        {
            "location": "se/config/advanced-configuration",
            "text": " Most applications let the config system try to infer the media type of the config source. By default, config source implementations use the io.helidon.common.media.type.MediaTypes API to infer the source media type from the source, typically (but not always) based on the file type portion of the file path. Helidon media type module has a predefined set of mappings as configured in common/media-type/src/main/resources/io/helidon/common/media/type/default-media-types.properties , including the Config supported formats: .properties , .yaml , .json and .conf . To handle other formats you can implement and register your own io.helidon.common.media.type.spi.MediaTypeDetector Java Service implementations. (Typically, you would also write and register a config parser to translate that format; see Locating a Parser below.) ",
            "title": "By Inference"
        },
        {
            "location": "se/config/advanced-configuration",
            "text": " Your application can specify what media type to use in interpreting a config source. Use this if your application knows the media type but the system might not be able to infer it correctly, either because no type detector would recognize it or because there might be more than one inferred media type. <markup lang=\"java\" title=\"Specify mediaType for config source\" >Config config = Config.create(classpath(\"props\") .mediaType(\"text/x-java-properties\")); The config system cannot infer the media type because there is no file type in the path props . The developer knows the file is in Java Properties format so specifies the media type explicitly. Note that a file type detector could be written to also inspect the contents of the file to infer the media type. The detectors provided by Helidon only inspect the suffix in the name of the file. ",
            "title": "By Application Directive"
        },
        {
            "location": "se/config/advanced-configuration",
            "text": " By Inference Most applications let the config system try to infer the media type of the config source. By default, config source implementations use the io.helidon.common.media.type.MediaTypes API to infer the source media type from the source, typically (but not always) based on the file type portion of the file path. Helidon media type module has a predefined set of mappings as configured in common/media-type/src/main/resources/io/helidon/common/media/type/default-media-types.properties , including the Config supported formats: .properties , .yaml , .json and .conf . To handle other formats you can implement and register your own io.helidon.common.media.type.spi.MediaTypeDetector Java Service implementations. (Typically, you would also write and register a config parser to translate that format; see Locating a Parser below.) By Application Directive Your application can specify what media type to use in interpreting a config source. Use this if your application knows the media type but the system might not be able to infer it correctly, either because no type detector would recognize it or because there might be more than one inferred media type. <markup lang=\"java\" title=\"Specify mediaType for config source\" >Config config = Config.create(classpath(\"props\") .mediaType(\"text/x-java-properties\")); The config system cannot infer the media type because there is no file type in the path props . The developer knows the file is in Java Properties format so specifies the media type explicitly. Note that a file type detector could be written to also inspect the contents of the file to infer the media type. The detectors provided by Helidon only inspect the suffix in the name of the file. ",
            "title": "Identifying the Media Type"
        },
        {
            "location": "se/config/advanced-configuration",
            "text": " Each config parser reports which media types it handles. Once the config system has determined a source&#8217;s media type, it searches the config parsers associated with the config builder for one that recognizes that media type. It then uses that parser to translate the config in the source into the in-memory config tree. The application can add one or more parsers to a Config.Builder using the addParser method. This makes the parser available for use by the config sources associated with that builder, but does not directly tie a given parser to a given source. The builder uses media-type matching to select one of the parsers registered with the builder for each source. If the config system cannot locate a parser that matches the media type of a source, it throws a ConfigException when trying to prepare the configuration. ",
            "title": "By Inference from media-type "
        },
        {
            "location": "se/config/advanced-configuration",
            "text": " Your application can specify which parser to use for a config source. The AbstractParsableConfigSource.Builder class exposes the parser method, which accepts the ConfigParser to be used for that source. Several methods on ConfigSources such as classpath , directory , and file return this builder class. Generally try to rely on media-type matching rather than specifying a given parser for a given source in the application. This keeps your application more flexible, both by insulating it from implementation classes and by letting it easily take advantage of improvements in or alternatives to the parsers available for a given media type. <markup lang=\"java\" title=\"Specify parser for config source\" >Config config = Config.create(classpath(\"props\") .parser(ConfigParsers.properties())); The config system cannot infer the media type because there is no file type in the path props . The developer knows the file is in Java Properties format so specifies the properties parser explicitly. ",
            "title": "By Application Directive"
        },
        {
            "location": "se/config/advanced-configuration",
            "text": " By Inference from media-type Each config parser reports which media types it handles. Once the config system has determined a source&#8217;s media type, it searches the config parsers associated with the config builder for one that recognizes that media type. It then uses that parser to translate the config in the source into the in-memory config tree. The application can add one or more parsers to a Config.Builder using the addParser method. This makes the parser available for use by the config sources associated with that builder, but does not directly tie a given parser to a given source. The builder uses media-type matching to select one of the parsers registered with the builder for each source. If the config system cannot locate a parser that matches the media type of a source, it throws a ConfigException when trying to prepare the configuration. By Application Directive Your application can specify which parser to use for a config source. The AbstractParsableConfigSource.Builder class exposes the parser method, which accepts the ConfigParser to be used for that source. Several methods on ConfigSources such as classpath , directory , and file return this builder class. Generally try to rely on media-type matching rather than specifying a given parser for a given source in the application. This keeps your application more flexible, both by insulating it from implementation classes and by letting it easily take advantage of improvements in or alternatives to the parsers available for a given media type. <markup lang=\"java\" title=\"Specify parser for config source\" >Config config = Config.create(classpath(\"props\") .parser(ConfigParsers.properties())); The config system cannot infer the media type because there is no file type in the path props . The developer knows the file is in Java Properties format so specifies the properties parser explicitly. ",
            "title": "Locating a Parser"
        },
        {
            "location": "se/config/advanced-configuration",
            "text": " Although most applications are explicit about the config sources they use in building a Config , the config system often has to figure out what parser to use. It does so by: determining, the best that it can, the media type of the source, and locating a parser that can translate that media type. Identifying the Media Type By Inference Most applications let the config system try to infer the media type of the config source. By default, config source implementations use the io.helidon.common.media.type.MediaTypes API to infer the source media type from the source, typically (but not always) based on the file type portion of the file path. Helidon media type module has a predefined set of mappings as configured in common/media-type/src/main/resources/io/helidon/common/media/type/default-media-types.properties , including the Config supported formats: .properties , .yaml , .json and .conf . To handle other formats you can implement and register your own io.helidon.common.media.type.spi.MediaTypeDetector Java Service implementations. (Typically, you would also write and register a config parser to translate that format; see Locating a Parser below.) By Application Directive Your application can specify what media type to use in interpreting a config source. Use this if your application knows the media type but the system might not be able to infer it correctly, either because no type detector would recognize it or because there might be more than one inferred media type. <markup lang=\"java\" title=\"Specify mediaType for config source\" >Config config = Config.create(classpath(\"props\") .mediaType(\"text/x-java-properties\")); The config system cannot infer the media type because there is no file type in the path props . The developer knows the file is in Java Properties format so specifies the media type explicitly. Note that a file type detector could be written to also inspect the contents of the file to infer the media type. The detectors provided by Helidon only inspect the suffix in the name of the file. Locating a Parser By Inference from media-type Each config parser reports which media types it handles. Once the config system has determined a source&#8217;s media type, it searches the config parsers associated with the config builder for one that recognizes that media type. It then uses that parser to translate the config in the source into the in-memory config tree. The application can add one or more parsers to a Config.Builder using the addParser method. This makes the parser available for use by the config sources associated with that builder, but does not directly tie a given parser to a given source. The builder uses media-type matching to select one of the parsers registered with the builder for each source. If the config system cannot locate a parser that matches the media type of a source, it throws a ConfigException when trying to prepare the configuration. By Application Directive Your application can specify which parser to use for a config source. The AbstractParsableConfigSource.Builder class exposes the parser method, which accepts the ConfigParser to be used for that source. Several methods on ConfigSources such as classpath , directory , and file return this builder class. Generally try to rely on media-type matching rather than specifying a given parser for a given source in the application. This keeps your application more flexible, both by insulating it from implementation classes and by letting it easily take advantage of improvements in or alternatives to the parsers available for a given media type. <markup lang=\"java\" title=\"Specify parser for config source\" >Config config = Config.create(classpath(\"props\") .parser(ConfigParsers.properties())); The config system cannot infer the media type because there is no file type in the path props . The developer knows the file is in Java Properties format so specifies the properties parser explicitly. ",
            "title": "How Config Chooses Parsers"
        },
        {
            "location": "se/config/advanced-configuration",
            "text": "<markup lang=\"java\" title=\"Specify JSON as media type for node\" >Config config = Config.create( classpath(\"application.yaml\") .mediaTypeMapping( key -&gt; \"app\".equals(key.toString()) ? \"application/json\" : null)); assert config.get(\"secrets.username\").asString() .get().equals(\"jose\"); assert config.get(\"secrets.password\").asString() .get().equals(\"^ery$ecretP&amp;ssword\"); assert config.get(\"app\").type() == Type.OBJECT; assert config.get(\"app.greeting\") .asString().get().equals(\"Hello\"); assert config.get(\"app.page-size\") .asInt().get() == 20; assert config.get(\"app.basic-range.0\") .asInt().get() == -20; assert config.get(\"app.basic-range.1\") .asInt().get() == 20; The source builder&#8217;s mediaTypeMapping method accepts a function which returns the appropriate media types (if any) for config keys. The function says to treat the app property value as a JSON document and leave other nodes unchanged. Other properties are loaded as expected. Property app is now a structured object node. Because the function passed to mediaTypeMapping identifies the app node as a JSON document, the config system selects the config parser that is registered with the builder which also handles the JSON media type. Also, note that the config system replaces the original String value node with an object node resulting from parsing that String value as JSON. ",
            "title": "Specify Key-to-media-type Mapping"
        },
        {
            "location": "se/config/advanced-configuration",
            "text": " Alternatively, your application could map config keys to the specific parsers you want to use for parsing those keys' values. <markup lang=\"java\" title=\"Specify JSON formatted property' parser instance\" >Config config = Config.create( ConfigSources.classpath(\"application.yaml\") .parserMapping( key -&gt; \"app\".equals(key.toString()) ? HoconConfigParserBuilder.buildDefault() : null)); Uses the parserMapping method to map keys to parser instances. Tells the config system to use the HOCON parser for translating the String value of the app key. (HOCON is a superset of JSON.) As before, the config system replaces the value node in the containing config tree with the config tree resulting from the additional parse. ",
            "title": "Specify Key-to-parser Mapping"
        },
        {
            "location": "se/config/advanced-configuration",
            "text": " A config value node might contain an entire config document in String form, but in a format different from the containing document. Your application can tell the config system to parse such a node as config in a different format and replace the String value node in the original tree with the config tree that results from parsing that String . In this example, a YAML document contains a JSON document as a leaf. <markup lang=\"yaml\" title=\"YAML file with included JSON formatted property\" >secrets: username: \"jose\" password: \"^ery$ecretP&amp;ssword\" app: &gt; { \"greeting\": \"Hello\", \"page-size\": 20, \"basic-range\": [ -20, 20 ] } The property app is itself formatted as a JSON document. Specify Key-to-media-type Mapping <markup lang=\"java\" title=\"Specify JSON as media type for node\" >Config config = Config.create( classpath(\"application.yaml\") .mediaTypeMapping( key -&gt; \"app\".equals(key.toString()) ? \"application/json\" : null)); assert config.get(\"secrets.username\").asString() .get().equals(\"jose\"); assert config.get(\"secrets.password\").asString() .get().equals(\"^ery$ecretP&amp;ssword\"); assert config.get(\"app\").type() == Type.OBJECT; assert config.get(\"app.greeting\") .asString().get().equals(\"Hello\"); assert config.get(\"app.page-size\") .asInt().get() == 20; assert config.get(\"app.basic-range.0\") .asInt().get() == -20; assert config.get(\"app.basic-range.1\") .asInt().get() == 20; The source builder&#8217;s mediaTypeMapping method accepts a function which returns the appropriate media types (if any) for config keys. The function says to treat the app property value as a JSON document and leave other nodes unchanged. Other properties are loaded as expected. Property app is now a structured object node. Because the function passed to mediaTypeMapping identifies the app node as a JSON document, the config system selects the config parser that is registered with the builder which also handles the JSON media type. Also, note that the config system replaces the original String value node with an object node resulting from parsing that String value as JSON. Specify Key-to-parser Mapping Alternatively, your application could map config keys to the specific parsers you want to use for parsing those keys' values. <markup lang=\"java\" title=\"Specify JSON formatted property' parser instance\" >Config config = Config.create( ConfigSources.classpath(\"application.yaml\") .parserMapping( key -&gt; \"app\".equals(key.toString()) ? HoconConfigParserBuilder.buildDefault() : null)); Uses the parserMapping method to map keys to parser instances. Tells the config system to use the HOCON parser for translating the String value of the app key. (HOCON is a superset of JSON.) As before, the config system replaces the value node in the containing config tree with the config tree resulting from the additional parse. ",
            "title": "Parsing a Config Value as Config"
        },
        {
            "location": "se/config/advanced-configuration",
            "text": " Config sources and parsers work together to read and translate configuration data from some external form into the corresponding in-memory config tree. How Config Chooses Parsers Although most applications are explicit about the config sources they use in building a Config , the config system often has to figure out what parser to use. It does so by: determining, the best that it can, the media type of the source, and locating a parser that can translate that media type. Identifying the Media Type By Inference Most applications let the config system try to infer the media type of the config source. By default, config source implementations use the io.helidon.common.media.type.MediaTypes API to infer the source media type from the source, typically (but not always) based on the file type portion of the file path. Helidon media type module has a predefined set of mappings as configured in common/media-type/src/main/resources/io/helidon/common/media/type/default-media-types.properties , including the Config supported formats: .properties , .yaml , .json and .conf . To handle other formats you can implement and register your own io.helidon.common.media.type.spi.MediaTypeDetector Java Service implementations. (Typically, you would also write and register a config parser to translate that format; see Locating a Parser below.) By Application Directive Your application can specify what media type to use in interpreting a config source. Use this if your application knows the media type but the system might not be able to infer it correctly, either because no type detector would recognize it or because there might be more than one inferred media type. <markup lang=\"java\" title=\"Specify mediaType for config source\" >Config config = Config.create(classpath(\"props\") .mediaType(\"text/x-java-properties\")); The config system cannot infer the media type because there is no file type in the path props . The developer knows the file is in Java Properties format so specifies the media type explicitly. Note that a file type detector could be written to also inspect the contents of the file to infer the media type. The detectors provided by Helidon only inspect the suffix in the name of the file. Locating a Parser By Inference from media-type Each config parser reports which media types it handles. Once the config system has determined a source&#8217;s media type, it searches the config parsers associated with the config builder for one that recognizes that media type. It then uses that parser to translate the config in the source into the in-memory config tree. The application can add one or more parsers to a Config.Builder using the addParser method. This makes the parser available for use by the config sources associated with that builder, but does not directly tie a given parser to a given source. The builder uses media-type matching to select one of the parsers registered with the builder for each source. If the config system cannot locate a parser that matches the media type of a source, it throws a ConfigException when trying to prepare the configuration. By Application Directive Your application can specify which parser to use for a config source. The AbstractParsableConfigSource.Builder class exposes the parser method, which accepts the ConfigParser to be used for that source. Several methods on ConfigSources such as classpath , directory , and file return this builder class. Generally try to rely on media-type matching rather than specifying a given parser for a given source in the application. This keeps your application more flexible, both by insulating it from implementation classes and by letting it easily take advantage of improvements in or alternatives to the parsers available for a given media type. <markup lang=\"java\" title=\"Specify parser for config source\" >Config config = Config.create(classpath(\"props\") .parser(ConfigParsers.properties())); The config system cannot infer the media type because there is no file type in the path props . The developer knows the file is in Java Properties format so specifies the properties parser explicitly. Parsing a Config Value as Config A config value node might contain an entire config document in String form, but in a format different from the containing document. Your application can tell the config system to parse such a node as config in a different format and replace the String value node in the original tree with the config tree that results from parsing that String . In this example, a YAML document contains a JSON document as a leaf. <markup lang=\"yaml\" title=\"YAML file with included JSON formatted property\" >secrets: username: \"jose\" password: \"^ery$ecretP&amp;ssword\" app: &gt; { \"greeting\": \"Hello\", \"page-size\": 20, \"basic-range\": [ -20, 20 ] } The property app is itself formatted as a JSON document. Specify Key-to-media-type Mapping <markup lang=\"java\" title=\"Specify JSON as media type for node\" >Config config = Config.create( classpath(\"application.yaml\") .mediaTypeMapping( key -&gt; \"app\".equals(key.toString()) ? \"application/json\" : null)); assert config.get(\"secrets.username\").asString() .get().equals(\"jose\"); assert config.get(\"secrets.password\").asString() .get().equals(\"^ery$ecretP&amp;ssword\"); assert config.get(\"app\").type() == Type.OBJECT; assert config.get(\"app.greeting\") .asString().get().equals(\"Hello\"); assert config.get(\"app.page-size\") .asInt().get() == 20; assert config.get(\"app.basic-range.0\") .asInt().get() == -20; assert config.get(\"app.basic-range.1\") .asInt().get() == 20; The source builder&#8217;s mediaTypeMapping method accepts a function which returns the appropriate media types (if any) for config keys. The function says to treat the app property value as a JSON document and leave other nodes unchanged. Other properties are loaded as expected. Property app is now a structured object node. Because the function passed to mediaTypeMapping identifies the app node as a JSON document, the config system selects the config parser that is registered with the builder which also handles the JSON media type. Also, note that the config system replaces the original String value node with an object node resulting from parsing that String value as JSON. Specify Key-to-parser Mapping Alternatively, your application could map config keys to the specific parsers you want to use for parsing those keys' values. <markup lang=\"java\" title=\"Specify JSON formatted property' parser instance\" >Config config = Config.create( ConfigSources.classpath(\"application.yaml\") .parserMapping( key -&gt; \"app\".equals(key.toString()) ? HoconConfigParserBuilder.buildDefault() : null)); Uses the parserMapping method to map keys to parser instances. Tells the config system to use the HOCON parser for translating the String value of the app key. (HOCON is a superset of JSON.) As before, the config system replaces the value node in the containing config tree with the config tree resulting from the additional parse. ",
            "title": "Advanced Config Parsers"
        },
        {
            "location": "se/config/advanced-configuration",
            "text": " As described in the hierarchical features section each config node (except the root) has a non-null key. Important To emphasize, the dot character (&#8220;.&#8221;) has special meaning as a name separator in keys. To include a dot as a character in a key escape it as &#8220;~1&#8221;. For example, the following configuration file contains two object nodes with names oracle and oracle.com . <markup lang=\"json\" title=\"Example application.json with dot character in key\" >{ \"oracle\" : { \"com\" : true, \"cz\" : false }, \"oracle.com\" : { \"secured\" : true } } <markup lang=\"java\" title=\"Working with configuration with dot character in node name\" >Config config = Config.create(classpath(\"application.json\")); // node `oracle` assert config.get(\"oracle.com\").asBoolean().get() == true; assert config.get(\"oracle\").get(\"com\").asBoolean().get() == true; assert config.get(\"oracle.com\").type() == Type.VALUE; assert config.get(\"oracle.com\").name().equals(\"com\"); // node `oracle.com` assert config.get(\"oracle~1com.secured\").asBoolean().get() == true; assert config.get(Key.escapeName(\"oracle.com\")) .get(\"secured\").asBoolean().get() == true; assert config.get(Key.escapeName(\"oracle.com\")).type() == Type.OBJECT; assert config.get(Key.escapeName(\"oracle.com\")).name().equals(\"oracle.com\"); Work with the first oracle object as usual. As always you can use the fully-qualified key oracle.com or chain get(key) calls to access the com property value. Config node \"oracle\" / \"com\" is a leaf node (has type VALUE )&#8230;&#8203; &#8230;&#8203; and has the name com (the last token in its key). The second object has name oracle.com . The code must escape the dot in the node&#8217;s name using oracle~1com . Or, use the utility method Config.Key.escapeName(name) to escape dots or tildes that might be in the node&#8217;s name, in this example in oracle.com . The config node \"oracle.com\" has type OBJECT &#8230;&#8203; &#8230;&#8203;and name \"oracle.com\" . ",
            "title": "Config Keys with . in name"
        },
        {
            "location": "se/config/advanced-configuration",
            "text": " Each filter accepts a key and the value as defined in the source, and returns the value to be used. The filter can leave the value unchanged or alter it, as it sees fit. The built-in value-resolving filter enables the token substitution described below. See the ConfigFilter JavaDoc for more information. ",
            "title": "Filters"
        },
        {
            "location": "se/config/advanced-configuration",
            "text": " The overrides feature allows you to create an external document containing key/value pairs which replace the value otherwise returned for the name, and then add that document as an override source to a config builder. There are some key differences between overrides and filters. Because overrides are loaded from sources those sources can change while your application runs and so the overrides they that prescribe can change. The override document can use wildcards in key expressions. Overrides can affect only keys that already exist in the original source; filters can supply values even if the key is absent from the config source. Each override entry consists of a Java properties-format definition. The key is an expression (which can use wildcards) to match config keys read from the current config sources, and the override value is the new value for any key matching the key expression from that entry. Order is important. The config system tests every key expression/value pair one by one in the order they appear in the overrides sources. Once the config system finds an override entry in which the key expression matches the configuration key, the system returns that entry&#8217;s value for the key being processed. See the OverrideSource JavaDoc for more detail. ",
            "title": "Overrides"
        },
        {
            "location": "se/config/advanced-configuration",
            "text": " A token reference is a key token starting with $ , optionally enclosed between { and } , i.e. $ref , ${ref} . Even a key composed of more than one token can be referenced in another key, i.e. ${env.ref} . As an example use case, you can use token references to declare the default values (see resolving-tokens.yaml below), while the references may be resolved in another config source, which identifies a current environment (see env.yaml examples below). You can then use the same overrides for different environments, say test and prod . The configuration in each environment is then overridden with a different values using wildcards (see overrides.properties below). <markup lang=\"java\" title=\"Initialize Config with Override Definition from overrides.properties file\" >Config config = Config.builder() .overrides(OverrideSources.file(\"conf/overrides.properties\")) .sources(file(\"conf/env.yaml\"), classpath(\"resolving-tokens.yaml\")) .build(); Loads overrides from the specified file. A deployment-specific environment configuration file. A default configuration containing token references that are resolved using the environment-specific override. ",
            "title": "Tokens"
        },
        {
            "location": "se/config/advanced-configuration",
            "text": " When your application retrieves a config value, the config system can transform it before returning the value, according to filters , overrides , and tokens . The config system provides some built-in instances of these you can use, and you can add your own as described in the sections which describe filters and overrides . Your application can add filters and overrides explicitly to a config builder and the config system by default uses the Java service loader mechanism to locate all available filters and overrides and add them automatically to all config builders (unless your code disables that behavior for a given builder). Filters Each filter accepts a key and the value as defined in the source, and returns the value to be used. The filter can leave the value unchanged or alter it, as it sees fit. The built-in value-resolving filter enables the token substitution described below. See the ConfigFilter JavaDoc for more information. Overrides The overrides feature allows you to create an external document containing key/value pairs which replace the value otherwise returned for the name, and then add that document as an override source to a config builder. There are some key differences between overrides and filters. Because overrides are loaded from sources those sources can change while your application runs and so the overrides they that prescribe can change. The override document can use wildcards in key expressions. Overrides can affect only keys that already exist in the original source; filters can supply values even if the key is absent from the config source. Each override entry consists of a Java properties-format definition. The key is an expression (which can use wildcards) to match config keys read from the current config sources, and the override value is the new value for any key matching the key expression from that entry. Order is important. The config system tests every key expression/value pair one by one in the order they appear in the overrides sources. Once the config system finds an override entry in which the key expression matches the configuration key, the system returns that entry&#8217;s value for the key being processed. See the OverrideSource JavaDoc for more detail. Tokens A token reference is a key token starting with $ , optionally enclosed between { and } , i.e. $ref , ${ref} . Even a key composed of more than one token can be referenced in another key, i.e. ${env.ref} . As an example use case, you can use token references to declare the default values (see resolving-tokens.yaml below), while the references may be resolved in another config source, which identifies a current environment (see env.yaml examples below). You can then use the same overrides for different environments, say test and prod . The configuration in each environment is then overridden with a different values using wildcards (see overrides.properties below). <markup lang=\"java\" title=\"Initialize Config with Override Definition from overrides.properties file\" >Config config = Config.builder() .overrides(OverrideSources.file(\"conf/overrides.properties\")) .sources(file(\"conf/env.yaml\"), classpath(\"resolving-tokens.yaml\")) .build(); Loads overrides from the specified file. A deployment-specific environment configuration file. A default configuration containing token references that are resolved using the environment-specific override. ",
            "title": "Filters, Overrides, and Token Substitution"
        },
        {
            "location": "se/config/advanced-configuration",
            "text": " The two methods PollingStrategies.regular(Duration) and PollingStrategies.watch(Path) return builders for their respective strategies. Both builders expose the executor method which your application can invoke, passing a java.util.concurrent.ScheduledExecutorService instance it requires for the polling work. By default, each polling strategy instance uses a separate thread pool executor. The following example shares the same executor for two different polling strategy instances. <markup lang=\"java\" title=\"Customize polling strategy executors\" >ScheduledExecutorService executor = Executors.newScheduledThreadPool(2); Config config = Config.create( ConfigSources.file(\"conf/dev.properties\") .pollingStrategy( PollingStrategies.regular(Duration.ofSeconds(2)) .executor(executor)), ConfigSources.create(\"conf/config.properties\") .pollingStrategy( path -&gt; PollingStrategies.watch(path) .executor(executor))); Prepares a thread pool executor with core pool size set 2 to be shared by all polling strategies. Selects the built-in periodic polling strategy. Tells the config system to use the specific executor to poll the dev.properties config source. Uses the Java filesystem WatchService to monitor the specified path. Tells the config system to use the same executor to monitor the path. ",
            "title": "Executors for Polling Strategy"
        },
        {
            "location": "se/config/advanced-configuration",
            "text": " Recall that when a polling strategy detects a change in a source, it informs interested parties of the changes. By default, each Config.Builder arranges for the resulting Config tree to use a shared executor that reuses available threads from a pool, creating new threads as needed. The same executor is used for actually reloading the source. Your application can invoke the polling strategy builder&#8217;s changesExecutor method to tell the builder to use a different Executor . (As an aside, your application can also control the size of the buffer used for holding source change events by invoking the builder&#8217;s changesMaxBuffer method. The default is 256.) <markup lang=\"java\" title=\"Customize config and override sources' executors\" >Executor executor = Executors.newCachedThreadPool(); Config config = Config.builder() .overrides( OverrideSources.file(\"conf/overrides.properties\") .pollingStrategy(PollingStrategies::watch) .changesExecutor(executor) .changesMaxBuffer(4)) .sources( ConfigSources.file(\"conf/env.yaml\") .pollingStrategy(PollingStrategies::watch) .changesExecutor(executor) .changesMaxBuffer(4)) .build(); Prepares a thread pool executor to be shared by selected sources. Tells the builder that the resulting overrides source should use the specified Executor for notifying interested parties of changes and for reloading the override source. Specifies an event buffer size of 4. Uses the same Executor and event buffer size for the config source as for the override source above. ",
            "title": "Publishers for Source Change Events"
        },
        {
            "location": "se/config/advanced-configuration",
            "text": " When your application supplies multiple sources to a config builder, as with Config.create(Supplier&lt;ConfigSource&gt;&#8230;&#8203;) and Config.create(List&lt;Supplier&lt;ConfigSource&gt;&gt;) , the config system automatically uses a composite config source which aggregates the separate sources but also listens for changes to any of the individual sources, so it can delegate the change notification. For this change detection and notification the config system, by default, uses an executor with a dedicated thread pool that is shared across all Config instances. Your application can invoke the builder&#8217;s changesExecutor method to use a different ScheduledExecutorService instance. The builder returned by the from methods mentioned above is a CompositeBuilder which extends Config.Builder . Because a composite source might yield more numerous change events&#8201;&#8212;&#8201;because of the multiple underlying sources&#8201;&#8212;&#8201;your application can specify debounce timeout for the composite source by invoking the CompositeBuilder.changesDebounce(Duration) method. The composite source aggregates multiple change events within this debounce timeout period into a single event and broadcasts that one instead. Next, it reloads the sources at that time, not necessarily in response to every single change in any source. The default is 100 milliseconds. <markup lang=\"java\" title=\"Customize composite source executors\" >ScheduledExecutorService executor = Executors.newScheduledThreadPool(1); Config config = Config.create( ConfigSources.create(file(\"conf/dev.properties\") .pollingStrategy(PollingStrategies::watch), file(\"conf/config.properties\") .pollingStrategy(PollingStrategies::watch)) .changesExecutor(executor) .changesMaxBuffer(4) .changesDebounce(Duration.ofSeconds(1))); Prepares a thread pool executor. ConfigSources.create(Supplier&lt;ConfigSource&gt;&#8230;&#8203;) creates and returns a CompositeBuilder based on the two sources. Specifies a particular executor for monitoring and change event notification. Sets the subscriber&#8217;s buffer size to 4 events. The composite source discards any events not consumed by a subscriber if it needs to create room for more recent events. Change events will not fire more frequently than once per a second. ",
            "title": "Composite Config Source Executor"
        },
        {
            "location": "se/config/advanced-configuration",
            "text": " A loaded config tree subscribes to change events publishes by its source(s). By default, each Config uses an executor which manages a dedicated thread pool reusing previously-created threads when they are available and creating new threads as needed. All Config instances share the dedicated thread pool. Your application can specify a non-default Executor for a tree to use for accepting and propagating those events by invoking the changesExecutor method on the Config.Builder . Each source subscriber has a dedicated buffer for holding changes events. This defaults to 256, but you can tailor this value as needed. <markup lang=\"java\" title=\"Customize config executor\" >Executor executor = Executors.newCachedThreadPool(); Config config = Config.create( file(\"conf/config.properties\") .pollingStrategy(PollingStrategies::watch)) .changesExecutor(executor) .changesMaxBuffer(16) .build(); Prepares a specific thread pool executor. Specifies the executor the Config tree will use to listen for and propagate change events. Sets the event subscriber buffer to 16 events. ",
            "title": "Config Custom Executor"
        },
        {
            "location": "se/config/advanced-configuration",
            "text": " You can control which executor a retry policy should use for its work. The RetryPolicies.repeat(int retries) method returns a RetryPolicies.Builder . Your application can invoke the retry policy builder&#8217;s executor method to specify which ScheduledExecutorService instance it should use to schedule and execute delayed retries. By default, the config system uses a separate thread pool executor for each retry policy instance. <markup lang=\"java\" title=\"Customize retry policy executors\" >ScheduledExecutorService executor = Executors.newScheduledThreadPool(2, myThreadFactory); Config config = Config.create( ConfigSources.file(\"conf/dev.properties\") .optional() .retryPolicy(RetryPolicies.repeat(2) .executor(executor))); Prepares a thread pool executor with core pool size set to 2 and a custom java.util.concurrent.ThreadFactory . When the source is flagged as optional() , the loading attempt will be repeated as the retry policy defines, but an overall failure will not lead to failing the initial load or preventing the source from being polled if so configured. Uses the built-in repeating implementation of RetryPolicy that can be used with any config source, but typically for ones that might suffer brief, intermittent outages. Specifies the executor to use for loading and retries. ",
            "title": "Retry Policy Custom Executor"
        },
        {
            "location": "se/config/advanced-configuration",
            "text": " Various parts of the config system work asynchronously: polling strategies to detect changes to config sources, publishers to notify your application when such changes occur, Config instances which subscribe to and respond to change notifications for their underlying sources, and retry policies (which might wait between retries). Each of these uses an executor to perform its work. The config system provides default executors, but your application can specify different ones if necessary. Executors for Polling Strategy The two methods PollingStrategies.regular(Duration) and PollingStrategies.watch(Path) return builders for their respective strategies. Both builders expose the executor method which your application can invoke, passing a java.util.concurrent.ScheduledExecutorService instance it requires for the polling work. By default, each polling strategy instance uses a separate thread pool executor. The following example shares the same executor for two different polling strategy instances. <markup lang=\"java\" title=\"Customize polling strategy executors\" >ScheduledExecutorService executor = Executors.newScheduledThreadPool(2); Config config = Config.create( ConfigSources.file(\"conf/dev.properties\") .pollingStrategy( PollingStrategies.regular(Duration.ofSeconds(2)) .executor(executor)), ConfigSources.create(\"conf/config.properties\") .pollingStrategy( path -&gt; PollingStrategies.watch(path) .executor(executor))); Prepares a thread pool executor with core pool size set 2 to be shared by all polling strategies. Selects the built-in periodic polling strategy. Tells the config system to use the specific executor to poll the dev.properties config source. Uses the Java filesystem WatchService to monitor the specified path. Tells the config system to use the same executor to monitor the path. Publishers for Source Change Events Recall that when a polling strategy detects a change in a source, it informs interested parties of the changes. By default, each Config.Builder arranges for the resulting Config tree to use a shared executor that reuses available threads from a pool, creating new threads as needed. The same executor is used for actually reloading the source. Your application can invoke the polling strategy builder&#8217;s changesExecutor method to tell the builder to use a different Executor . (As an aside, your application can also control the size of the buffer used for holding source change events by invoking the builder&#8217;s changesMaxBuffer method. The default is 256.) <markup lang=\"java\" title=\"Customize config and override sources' executors\" >Executor executor = Executors.newCachedThreadPool(); Config config = Config.builder() .overrides( OverrideSources.file(\"conf/overrides.properties\") .pollingStrategy(PollingStrategies::watch) .changesExecutor(executor) .changesMaxBuffer(4)) .sources( ConfigSources.file(\"conf/env.yaml\") .pollingStrategy(PollingStrategies::watch) .changesExecutor(executor) .changesMaxBuffer(4)) .build(); Prepares a thread pool executor to be shared by selected sources. Tells the builder that the resulting overrides source should use the specified Executor for notifying interested parties of changes and for reloading the override source. Specifies an event buffer size of 4. Uses the same Executor and event buffer size for the config source as for the override source above. Composite Config Source Executor When your application supplies multiple sources to a config builder, as with Config.create(Supplier&lt;ConfigSource&gt;&#8230;&#8203;) and Config.create(List&lt;Supplier&lt;ConfigSource&gt;&gt;) , the config system automatically uses a composite config source which aggregates the separate sources but also listens for changes to any of the individual sources, so it can delegate the change notification. For this change detection and notification the config system, by default, uses an executor with a dedicated thread pool that is shared across all Config instances. Your application can invoke the builder&#8217;s changesExecutor method to use a different ScheduledExecutorService instance. The builder returned by the from methods mentioned above is a CompositeBuilder which extends Config.Builder . Because a composite source might yield more numerous change events&#8201;&#8212;&#8201;because of the multiple underlying sources&#8201;&#8212;&#8201;your application can specify debounce timeout for the composite source by invoking the CompositeBuilder.changesDebounce(Duration) method. The composite source aggregates multiple change events within this debounce timeout period into a single event and broadcasts that one instead. Next, it reloads the sources at that time, not necessarily in response to every single change in any source. The default is 100 milliseconds. <markup lang=\"java\" title=\"Customize composite source executors\" >ScheduledExecutorService executor = Executors.newScheduledThreadPool(1); Config config = Config.create( ConfigSources.create(file(\"conf/dev.properties\") .pollingStrategy(PollingStrategies::watch), file(\"conf/config.properties\") .pollingStrategy(PollingStrategies::watch)) .changesExecutor(executor) .changesMaxBuffer(4) .changesDebounce(Duration.ofSeconds(1))); Prepares a thread pool executor. ConfigSources.create(Supplier&lt;ConfigSource&gt;&#8230;&#8203;) creates and returns a CompositeBuilder based on the two sources. Specifies a particular executor for monitoring and change event notification. Sets the subscriber&#8217;s buffer size to 4 events. The composite source discards any events not consumed by a subscriber if it needs to create room for more recent events. Change events will not fire more frequently than once per a second. Config Custom Executor A loaded config tree subscribes to change events publishes by its source(s). By default, each Config uses an executor which manages a dedicated thread pool reusing previously-created threads when they are available and creating new threads as needed. All Config instances share the dedicated thread pool. Your application can specify a non-default Executor for a tree to use for accepting and propagating those events by invoking the changesExecutor method on the Config.Builder . Each source subscriber has a dedicated buffer for holding changes events. This defaults to 256, but you can tailor this value as needed. <markup lang=\"java\" title=\"Customize config executor\" >Executor executor = Executors.newCachedThreadPool(); Config config = Config.create( file(\"conf/config.properties\") .pollingStrategy(PollingStrategies::watch)) .changesExecutor(executor) .changesMaxBuffer(16) .build(); Prepares a specific thread pool executor. Specifies the executor the Config tree will use to listen for and propagate change events. Sets the event subscriber buffer to 16 events. Retry Policy Custom Executor You can control which executor a retry policy should use for its work. The RetryPolicies.repeat(int retries) method returns a RetryPolicies.Builder . Your application can invoke the retry policy builder&#8217;s executor method to specify which ScheduledExecutorService instance it should use to schedule and execute delayed retries. By default, the config system uses a separate thread pool executor for each retry policy instance. <markup lang=\"java\" title=\"Customize retry policy executors\" >ScheduledExecutorService executor = Executors.newScheduledThreadPool(2, myThreadFactory); Config config = Config.create( ConfigSources.file(\"conf/dev.properties\") .optional() .retryPolicy(RetryPolicies.repeat(2) .executor(executor))); Prepares a thread pool executor with core pool size set to 2 and a custom java.util.concurrent.ThreadFactory . When the source is flagged as optional() , the loading attempt will be repeated as the retry policy defines, but an overall failure will not lead to failing the initial load or preventing the source from being polled if so configured. Uses the built-in repeating implementation of RetryPolicy that can be used with any config source, but typically for ones that might suffer brief, intermittent outages. Specifies the executor to use for loading and retries. ",
            "title": "Executors for Asynchronous Config Activity"
        },
        {
            "location": "se/config/config-profiles",
            "text": " Overview Profile Options Profile Config Source Profile Files ",
            "title": "Contents"
        },
        {
            "location": "se/config/config-profiles",
            "text": " Configuration profiles provide a capability to prepare structure of configuration for each environment in advance, and then simply switch between these structures using a system property or an environment variable. ",
            "title": "Overview"
        },
        {
            "location": "se/config/config-profiles",
            "text": " To choose a configuration profile to use at runtime, you can use: A system property config.profile An environment variable HELIDON_CONFIG_PROFILE There are two ways to define a profile configuration: Use a config source with a profile specific name Use a profile file defining all configuration sources Configuration profiles can only be used when config is created using the Config.create() method without parameters. If you explicitly configure sources, profiles are ignored. ",
            "title": "Profile Options"
        },
        {
            "location": "se/config/config-profiles",
            "text": " If a profile is specified, config will load the profile-specific default configuration source before the \"main\" source. Let&#8217;s consider the selected profile is dev , and we have yaml configuration support on classpath; config will look for the following sources (in this order): application-dev.yaml on file system application-dev.properties on file system application-dev.yaml on classpath application-dev.properties on classpath application.yaml on file system application.properties on file system application.yaml on classpath application.properties on classpath ",
            "title": "Profile Config Sources"
        },
        {
            "location": "se/config/config-profiles",
            "text": " The config system supports these built-in types: Built-in Types Type Use Related ConfigSources Method Required Properties system-properties System properties are a config source ConfigSources.systemProperties() n/a environment-variables Environment variables are a config source ConfigSources.environmentVariables() n/a classpath Specified resource is used as a config source ConfigSources.classpath(String) resource - path to the resource to load file Specified file is used as a config source ConfigSources.file(Path) path - path to the file to load directory Each file in directory used as config entry, with key = file name and value = file contents ConfigSources.directory(String) path - path to the directory to use url Specified URL is read as a config source ConfigSources.url(URL) url - URL from which to load the config inlined The whole configuration tree under properties is added as a configuration source (excluding the properties node) n/a n/a prefixed Associated config source is loaded with the specified prefix ConfigSources.prefixed(String,Supplier) key - key of config element in associated source to load type - associated config source specification properties - as needed to further qualify the associated config source Except for the system-properties and environment-variables types, the profile properties section for a source can also specify any optional settings for the corresponding config source type. The JavaDoc for the related config source type builders lists the supported properties for each type. (For example, FileConfigSource.FileBuilder .) Here is an example profile in YAML format. Note how the properties sections are at the same level as the type or class within a sources array entry. <markup lang=\"yaml\" title=\"Profile config-profile.yaml illustrating all built-in sources available on the classpath\" >caching.enabled: false sources: - type: \"system-properties\" - type: \"environment-variables\" - type: \"directory\" properties: path: \"conf/secrets\" media-type-mapping: yaml: \"application/x-yaml\" password: \"application/base64\" polling-strategy: type: \"regular\" properties: interval: \"PT15S\" - type: \"url\" properties: url: \"http://config-service/my-config\" media-type: \"application/hocon\" optional: true retry-policy: type: \"repeat\" properties: retries: 3 - type: \"file\" properties: optional: true path: \"conf/env.yaml\" change-watcher: type: \"file\" properties: delay-millis: 5000 - type: \"prefixed\" properties: key: \"app\" type: \"classpath\" properties: resource: \"app.conf\" - type: \"classpath\" properties: resource: \"application.conf\" Note that the example shows how your profile can configure optional features such as polling strategies and retry policies for config sources. ",
            "title": "Built-in Types"
        },
        {
            "location": "se/config/config-profiles",
            "text": " Profiles can be used to set up custom config sources as well as the built-in ones described above. Implement the ConfigSourceProvider <markup lang=\"java\" >public class MyConfigSourceProvider implements ConfigSourceProvider { private static final String TYPE = \"my-type\"; @Override public boolean supports(String type) { return TYPE.equals(type); } @Override public ConfigSource create(String type, Config metaConfig) { // as we only support one in this implementation, we can just return it return MyConfigSource.create(metaConfig); } @Override public Set&lt;String&gt; supported() { return Collections.singleton(TYPE); } } Register it as a java service loader service <markup title=\"File META-INF/services/io.helidon.config.spi.ConfigSourceProvider \" >io.helidon.examples.MyConfigSourceProvider And in module-info.java if using JPMS: <markup lang=\"java\" title=\"File module-info.java \" >provides io.helidon.config.spi.ConfigSourceProvider with io.helidon.examples.MyConfigSourceProvider Now you can use the following profile: <markup lang=\"yaml\" >sources: - type: \"system-properties\" - type: \"environment-variables\" - type: \"my-type\" properties: my-property: \"some-value\" Note that it is the io.helidon.config.AbstractConfigSource class that provides support for polling strategies, change watchers, and retry policies. If you create custom config sources that should also offer this support be sure they extend AbstractConfigSource and implement appropriate SPI interfaces (such as io.helidon.config.spi.WatchableSource ) to support such features. ",
            "title": "Support for Custom Sources"
        },
        {
            "location": "se/config/config-profiles",
            "text": " Your config profile can include the set-up for polling strategies, change watchers, and retry policies if the config source supports them. Declare them in a way similar to how you declare the config sources themselves: by type and with accompanying properties . Config Profile Support for Built-in Polling Strategies Strategy Type Usage Properties regular Periodic polling - See PollingStrategies.regular method interval ( Duration ) - indicating how often to poll; e.g., PT15S represents 15 seconds Config Profile Support for Built-in Change Watchers Type Usage Properties file Filesystem monitoring - See PollingStrategies.watch method initial-delay-millis - delay between the start of the watcher and first check for changes Config Profile Support for Built-in Retry Policies Policy Type Usage Properties repeat Regularly-scheduled - see RetryPolicies.repeat . retries ( int ) - number of retries to perform Optional: delay ( Duration ) - initial delay between retries delay-factor ( double ) - delay is repeatedly multiplied by this each retry to compute the delay for each successive retry call-timeout ( Duration ) - timeout for a single invocation to load the source overall-timeout ( Duration ) - total timeout for all retry calls and delays To specify a custom polling strategy or custom retry policy, implement the interface ( io.helidon.config.spi.PollingStrategy , io.helidon.config.spi.ChangeWatcher , or io.helidon.config.spi.RetryPolicy ), and then implement the provider interface ( io.helidon.config.spi.PollingStrategyProvider , io.helidon.config.spi.ChangeWatcherProvider , or io.helidon.config.spi.RetryPolicyProvider ) to enable your custom implementations for profiles. You can then use any custom properties - these are provided as a Config instance to the create method of the Provider implementation. See RetryPolicy , ChangeWatcher , and PollingStrategy JavaDoc sections. ",
            "title": "Support for Custom Polling Strategies, Change Watchers, and Retry Policies"
        },
        {
            "location": "se/config/config-profiles",
            "text": " Configuration profile provides similar options to the configuration builder. The profile file must contain at least the list of sources from which configuration can be loaded. The root sources property contains an array (ordered) of objects defining each config source to be used. Each element of the array must contain at least the type property, determining the config source type (such as system-properties , file ). It may also contain a properties property with additional configuration of the config source. An example development profile using \"inlined\" configuration: <markup lang=\"yaml\" title=\"Config profile config-profile-dev.yaml \" >sources: - type: \"inlined\" properties: app.greeting: \"Hello World\" An example of a profile using environment variables, system properties, classpath, and file configuration: <markup lang=\"yaml\" title=\"Config profile config-profile-prod.yaml \" >sources: - type: \"environment-variables\" - type: \"system-properties\" - type: \"file\" properties: path: \"config/config-prod.yaml\" - type: \"classpath\" properties: resource: \"application.yaml\" Built-in Types The config system supports these built-in types: Built-in Types Type Use Related ConfigSources Method Required Properties system-properties System properties are a config source ConfigSources.systemProperties() n/a environment-variables Environment variables are a config source ConfigSources.environmentVariables() n/a classpath Specified resource is used as a config source ConfigSources.classpath(String) resource - path to the resource to load file Specified file is used as a config source ConfigSources.file(Path) path - path to the file to load directory Each file in directory used as config entry, with key = file name and value = file contents ConfigSources.directory(String) path - path to the directory to use url Specified URL is read as a config source ConfigSources.url(URL) url - URL from which to load the config inlined The whole configuration tree under properties is added as a configuration source (excluding the properties node) n/a n/a prefixed Associated config source is loaded with the specified prefix ConfigSources.prefixed(String,Supplier) key - key of config element in associated source to load type - associated config source specification properties - as needed to further qualify the associated config source Except for the system-properties and environment-variables types, the profile properties section for a source can also specify any optional settings for the corresponding config source type. The JavaDoc for the related config source type builders lists the supported properties for each type. (For example, FileConfigSource.FileBuilder .) Here is an example profile in YAML format. Note how the properties sections are at the same level as the type or class within a sources array entry. <markup lang=\"yaml\" title=\"Profile config-profile.yaml illustrating all built-in sources available on the classpath\" >caching.enabled: false sources: - type: \"system-properties\" - type: \"environment-variables\" - type: \"directory\" properties: path: \"conf/secrets\" media-type-mapping: yaml: \"application/x-yaml\" password: \"application/base64\" polling-strategy: type: \"regular\" properties: interval: \"PT15S\" - type: \"url\" properties: url: \"http://config-service/my-config\" media-type: \"application/hocon\" optional: true retry-policy: type: \"repeat\" properties: retries: 3 - type: \"file\" properties: optional: true path: \"conf/env.yaml\" change-watcher: type: \"file\" properties: delay-millis: 5000 - type: \"prefixed\" properties: key: \"app\" type: \"classpath\" properties: resource: \"app.conf\" - type: \"classpath\" properties: resource: \"application.conf\" Note that the example shows how your profile can configure optional features such as polling strategies and retry policies for config sources. Support for Custom Sources Profiles can be used to set up custom config sources as well as the built-in ones described above. Implement the ConfigSourceProvider <markup lang=\"java\" >public class MyConfigSourceProvider implements ConfigSourceProvider { private static final String TYPE = \"my-type\"; @Override public boolean supports(String type) { return TYPE.equals(type); } @Override public ConfigSource create(String type, Config metaConfig) { // as we only support one in this implementation, we can just return it return MyConfigSource.create(metaConfig); } @Override public Set&lt;String&gt; supported() { return Collections.singleton(TYPE); } } Register it as a java service loader service <markup title=\"File META-INF/services/io.helidon.config.spi.ConfigSourceProvider \" >io.helidon.examples.MyConfigSourceProvider And in module-info.java if using JPMS: <markup lang=\"java\" title=\"File module-info.java \" >provides io.helidon.config.spi.ConfigSourceProvider with io.helidon.examples.MyConfigSourceProvider Now you can use the following profile: <markup lang=\"yaml\" >sources: - type: \"system-properties\" - type: \"environment-variables\" - type: \"my-type\" properties: my-property: \"some-value\" Note that it is the io.helidon.config.AbstractConfigSource class that provides support for polling strategies, change watchers, and retry policies. If you create custom config sources that should also offer this support be sure they extend AbstractConfigSource and implement appropriate SPI interfaces (such as io.helidon.config.spi.WatchableSource ) to support such features. Support for Custom Polling Strategies, Change Watchers, and Retry Policies Your config profile can include the set-up for polling strategies, change watchers, and retry policies if the config source supports them. Declare them in a way similar to how you declare the config sources themselves: by type and with accompanying properties . Config Profile Support for Built-in Polling Strategies Strategy Type Usage Properties regular Periodic polling - See PollingStrategies.regular method interval ( Duration ) - indicating how often to poll; e.g., PT15S represents 15 seconds Config Profile Support for Built-in Change Watchers Type Usage Properties file Filesystem monitoring - See PollingStrategies.watch method initial-delay-millis - delay between the start of the watcher and first check for changes Config Profile Support for Built-in Retry Policies Policy Type Usage Properties repeat Regularly-scheduled - see RetryPolicies.repeat . retries ( int ) - number of retries to perform Optional: delay ( Duration ) - initial delay between retries delay-factor ( double ) - delay is repeatedly multiplied by this each retry to compute the delay for each successive retry call-timeout ( Duration ) - timeout for a single invocation to load the source overall-timeout ( Duration ) - total timeout for all retry calls and delays To specify a custom polling strategy or custom retry policy, implement the interface ( io.helidon.config.spi.PollingStrategy , io.helidon.config.spi.ChangeWatcher , or io.helidon.config.spi.RetryPolicy ), and then implement the provider interface ( io.helidon.config.spi.PollingStrategyProvider , io.helidon.config.spi.ChangeWatcherProvider , or io.helidon.config.spi.RetryPolicyProvider ) to enable your custom implementations for profiles. You can then use any custom properties - these are provided as a Config instance to the create method of the Provider implementation. See RetryPolicy , ChangeWatcher , and PollingStrategy JavaDoc sections. ",
            "title": "Profile File Format"
        },
        {
            "location": "se/config/config-profiles",
            "text": " If a profile is specified, config will look for a profile-specific \"meta configuration\". Let&#8217;s consider the selected profile is dev , and we have yaml configuration support on classpath; config will look for the following profiles (in this order): config-profile-dev.yaml on file system config-profile-dev.properties on file system config-profile-dev.yaml on classpath config-profile-dev.properties on classpath If any of these files is discovered, it would be used to set up the configuration. In case none is found, the config falls back to profile specific config sources . The structure of the file is described below in profile file format . In case you need to customize the location of the profile file, you can use the system property io.helidon.config.meta-config . For example if it is configured to config/profile.yaml , config looks for file config/profile-dev.yaml when dev profile is configured. Profile File Format Configuration profile provides similar options to the configuration builder. The profile file must contain at least the list of sources from which configuration can be loaded. The root sources property contains an array (ordered) of objects defining each config source to be used. Each element of the array must contain at least the type property, determining the config source type (such as system-properties , file ). It may also contain a properties property with additional configuration of the config source. An example development profile using \"inlined\" configuration: <markup lang=\"yaml\" title=\"Config profile config-profile-dev.yaml \" >sources: - type: \"inlined\" properties: app.greeting: \"Hello World\" An example of a profile using environment variables, system properties, classpath, and file configuration: <markup lang=\"yaml\" title=\"Config profile config-profile-prod.yaml \" >sources: - type: \"environment-variables\" - type: \"system-properties\" - type: \"file\" properties: path: \"config/config-prod.yaml\" - type: \"classpath\" properties: resource: \"application.yaml\" Built-in Types The config system supports these built-in types: Built-in Types Type Use Related ConfigSources Method Required Properties system-properties System properties are a config source ConfigSources.systemProperties() n/a environment-variables Environment variables are a config source ConfigSources.environmentVariables() n/a classpath Specified resource is used as a config source ConfigSources.classpath(String) resource - path to the resource to load file Specified file is used as a config source ConfigSources.file(Path) path - path to the file to load directory Each file in directory used as config entry, with key = file name and value = file contents ConfigSources.directory(String) path - path to the directory to use url Specified URL is read as a config source ConfigSources.url(URL) url - URL from which to load the config inlined The whole configuration tree under properties is added as a configuration source (excluding the properties node) n/a n/a prefixed Associated config source is loaded with the specified prefix ConfigSources.prefixed(String,Supplier) key - key of config element in associated source to load type - associated config source specification properties - as needed to further qualify the associated config source Except for the system-properties and environment-variables types, the profile properties section for a source can also specify any optional settings for the corresponding config source type. The JavaDoc for the related config source type builders lists the supported properties for each type. (For example, FileConfigSource.FileBuilder .) Here is an example profile in YAML format. Note how the properties sections are at the same level as the type or class within a sources array entry. <markup lang=\"yaml\" title=\"Profile config-profile.yaml illustrating all built-in sources available on the classpath\" >caching.enabled: false sources: - type: \"system-properties\" - type: \"environment-variables\" - type: \"directory\" properties: path: \"conf/secrets\" media-type-mapping: yaml: \"application/x-yaml\" password: \"application/base64\" polling-strategy: type: \"regular\" properties: interval: \"PT15S\" - type: \"url\" properties: url: \"http://config-service/my-config\" media-type: \"application/hocon\" optional: true retry-policy: type: \"repeat\" properties: retries: 3 - type: \"file\" properties: optional: true path: \"conf/env.yaml\" change-watcher: type: \"file\" properties: delay-millis: 5000 - type: \"prefixed\" properties: key: \"app\" type: \"classpath\" properties: resource: \"app.conf\" - type: \"classpath\" properties: resource: \"application.conf\" Note that the example shows how your profile can configure optional features such as polling strategies and retry policies for config sources. Support for Custom Sources Profiles can be used to set up custom config sources as well as the built-in ones described above. Implement the ConfigSourceProvider <markup lang=\"java\" >public class MyConfigSourceProvider implements ConfigSourceProvider { private static final String TYPE = \"my-type\"; @Override public boolean supports(String type) { return TYPE.equals(type); } @Override public ConfigSource create(String type, Config metaConfig) { // as we only support one in this implementation, we can just return it return MyConfigSource.create(metaConfig); } @Override public Set&lt;String&gt; supported() { return Collections.singleton(TYPE); } } Register it as a java service loader service <markup title=\"File META-INF/services/io.helidon.config.spi.ConfigSourceProvider \" >io.helidon.examples.MyConfigSourceProvider And in module-info.java if using JPMS: <markup lang=\"java\" title=\"File module-info.java \" >provides io.helidon.config.spi.ConfigSourceProvider with io.helidon.examples.MyConfigSourceProvider Now you can use the following profile: <markup lang=\"yaml\" >sources: - type: \"system-properties\" - type: \"environment-variables\" - type: \"my-type\" properties: my-property: \"some-value\" Note that it is the io.helidon.config.AbstractConfigSource class that provides support for polling strategies, change watchers, and retry policies. If you create custom config sources that should also offer this support be sure they extend AbstractConfigSource and implement appropriate SPI interfaces (such as io.helidon.config.spi.WatchableSource ) to support such features. Support for Custom Polling Strategies, Change Watchers, and Retry Policies Your config profile can include the set-up for polling strategies, change watchers, and retry policies if the config source supports them. Declare them in a way similar to how you declare the config sources themselves: by type and with accompanying properties . Config Profile Support for Built-in Polling Strategies Strategy Type Usage Properties regular Periodic polling - See PollingStrategies.regular method interval ( Duration ) - indicating how often to poll; e.g., PT15S represents 15 seconds Config Profile Support for Built-in Change Watchers Type Usage Properties file Filesystem monitoring - See PollingStrategies.watch method initial-delay-millis - delay between the start of the watcher and first check for changes Config Profile Support for Built-in Retry Policies Policy Type Usage Properties repeat Regularly-scheduled - see RetryPolicies.repeat . retries ( int ) - number of retries to perform Optional: delay ( Duration ) - initial delay between retries delay-factor ( double ) - delay is repeatedly multiplied by this each retry to compute the delay for each successive retry call-timeout ( Duration ) - timeout for a single invocation to load the source overall-timeout ( Duration ) - total timeout for all retry calls and delays To specify a custom polling strategy or custom retry policy, implement the interface ( io.helidon.config.spi.PollingStrategy , io.helidon.config.spi.ChangeWatcher , or io.helidon.config.spi.RetryPolicy ), and then implement the provider interface ( io.helidon.config.spi.PollingStrategyProvider , io.helidon.config.spi.ChangeWatcherProvider , or io.helidon.config.spi.RetryPolicyProvider ) to enable your custom implementations for profiles. You can then use any custom properties - these are provided as a Config instance to the create method of the Provider implementation. See RetryPolicy , ChangeWatcher , and PollingStrategy JavaDoc sections. ",
            "title": "Profile Files"
        },
        {
            "location": "se/config/extensions",
            "text": " Overview Configuring an Extension Config-SPI-ConfigSource Config-SPI-ConfigParser Config-SPI-OverrideSource Config-SPI-ConfigFilter Config-SPI-ConfigMapperProvider Change Support SPI Config-SPI-RetryPolicy ",
            "title": "Contents"
        },
        {
            "location": "se/config/extensions",
            "text": " Developer-provided extensions influence how the config system behaves. The getting_started'}\">config system introduction explains the design of the config system and how its parts work together to read and parse config data, convert it to Java types, fine-tune the look-up of config data, and reload and reprocess data when it changes. _Config extensions provided by the application modify and expand the way the config system performs these steps. Each config extension implements one of the interfaces defined in the Configuration SPI: ConfigSource - Loads raw configuration data from a given type of source and delegates to a ConfigParser , producing the in-memory data structure which represents the loaded and parsed configuration. ConfigParser - Translates configuration content in a given format into the corresponding internal config data structures. OverrideSource - Provides key/value pairs which override config values loaded from any ConfigSource , given the key and ignoring the original value. ConfigFilter - Transforms config String values returned from any value-type Config node, given the key and the original value. ConfigMapperProvider - Provides one or more ConfigMapper s each of which converts a Config object tree to a Java type specific to the application. PollingStrategy - Implements a custom technique to trigger polling of underlying sources for changes ChangeWatcher - Implements a custom technique to watch underlying sources for changes and notifying the config system of such a change The extension mechanism of Config can also use Java ServiceLoader . For this purpose, you implement providers that serve as factories for your implementation of an extension. This is to support config profiles even for custom extensions. Service providers: ConfigMapperProvider - support for config mappers, automatically discovered by the config system ConfigFilter - support for config filters, automatically discovered by the config system ConfigParser - support for config parsers, automatically discovered by the config system ConfigSourceProvider - support for named config sources, configurable through profiles ChangeWatcherProvider - support for named change watchers, configurable through profiles OverrideSourceProvider - support for named override sources, configurable through profiles PollingStrategyProvider - support for named polling strategies, configurable through profiles RetryPolicyProvider - support for retry policies, configurable through profiles The config system itself implements several of these SPIs, as noted in the sections below. ",
            "title": "Overview"
        },
        {
            "location": "se/config/extensions",
            "text": " The following example shows configuration of all possible extensions with Config (all custom extension have a name prefix My ): <markup lang=\"java\" >Config config = Config.builder() .addSource(FileConfigSource.builder() .changeWatcher(MyChangeWatcher.create()) .pollingStrategy(MyPollingStrategy.create()) .parser(MyConfigParser.create()) .retryPolicy(MyRetryPolicy.create())) .addSource(MySource.create()) .addFilter(MyFilter.create()) .overrides(MyOverrides.create()) .build() ",
            "title": "Manual Configuration with Builder"
        },
        {
            "location": "se/config/extensions",
            "text": " The following extensions are loaded using a service loader for any configuration instance, and do not require an explicit setup: ConfigParser - each config parser on the classpath that implements ConfigParserProvider as a Java service loader service ConfigFilter - each filter on the classpath that implements ConfigFilter as a Java service loader service Other extensions are only used from Java service loader when you use config profiles. Mapping is done through the type configured in config profile, and the type defined by the extension provider interface. For example for config sources, the interface defines the following methods (only subset shown): <markup lang=\"java\" >boolean supports(String type); ConfigSource create(String type, Config metaConfig); Considering the following meta configuration (or config profile): <markup lang=\"yaml\" >sources: - type: \"my-type\" properties: my-config: \"configuration\" The config system would iterate through all ConfigSourceProvider implementations found through Java ServiceLoader based on their priority. First provider that returns true when supports(\"my-type\") is called would be used, and an instance of a ConfigSource created using create(\"my-type\", config) , where config is located on the node of properties from config profile. ",
            "title": "Automatic Configuration Using a Service Loader"
        },
        {
            "location": "se/config/extensions",
            "text": " The config system invokes extensions of a given type in priority order. Developers can express the relative importance of an extension by annotating the service implementation class with @jakarta.annotation.Priority . The default value is 100. A lower priority value represents greater importance. ",
            "title": "About Priority"
        },
        {
            "location": "se/config/extensions",
            "text": " You can configure a custom extension in two ways: Manual configuration with builder Automatic configuration using a Java service loader Manual Configuration with Builder The following example shows configuration of all possible extensions with Config (all custom extension have a name prefix My ): <markup lang=\"java\" >Config config = Config.builder() .addSource(FileConfigSource.builder() .changeWatcher(MyChangeWatcher.create()) .pollingStrategy(MyPollingStrategy.create()) .parser(MyConfigParser.create()) .retryPolicy(MyRetryPolicy.create())) .addSource(MySource.create()) .addFilter(MyFilter.create()) .overrides(MyOverrides.create()) .build() Automatic Configuration Using a Service Loader The following extensions are loaded using a service loader for any configuration instance, and do not require an explicit setup: ConfigParser - each config parser on the classpath that implements ConfigParserProvider as a Java service loader service ConfigFilter - each filter on the classpath that implements ConfigFilter as a Java service loader service Other extensions are only used from Java service loader when you use config profiles. Mapping is done through the type configured in config profile, and the type defined by the extension provider interface. For example for config sources, the interface defines the following methods (only subset shown): <markup lang=\"java\" >boolean supports(String type); ConfigSource create(String type, Config metaConfig); Considering the following meta configuration (or config profile): <markup lang=\"yaml\" >sources: - type: \"my-type\" properties: my-config: \"configuration\" The config system would iterate through all ConfigSourceProvider implementations found through Java ServiceLoader based on their priority. First provider that returns true when supports(\"my-type\") is called would be used, and an instance of a ConfigSource created using create(\"my-type\", config) , where config is located on the node of properties from config profile. About Priority The config system invokes extensions of a given type in priority order. Developers can express the relative importance of an extension by annotating the service implementation class with @jakarta.annotation.Priority . The default value is 100. A lower priority value represents greater importance. ",
            "title": "Configuring an Extension"
        },
        {
            "location": "se/config/extensions",
            "text": " The config system includes built-in support for several types of sources (for example, Java String , Readable , Properties , and Map objects - see ConfigSources ). Implement a ConfigSource to load raw configuration data from a type of source that the config system does not already support. ConfigSource SPI For config sources that work directly with config nodes, the following API is available. These interfaces have an implementation provided by Helidon. The interfaces ConfigNode , ObjectNode , ValueNode and ListNode represent the in-memory data structure for loaded and parsed configuration data. ConfigNode SPI For config sources that work return data ( NodeConfigSource and ParsableConfigSource ) a Content must be returned that describes the loaded data. The following diagram depicts the Content API. Content SPI Some methods provided are not always mandatory, yet they are part of the APIs to simplify the overall class structure: ConfigContent.stamp() - this method is used by PollingStrategy to determine if content has been changed. This can be always empty for sources, that do not implement PollableSource ConfigParser.Content.charset() - this can return any Charset for media types that are binary ConfigParser.Content.mediaType() - this can be used to override media type (that would otherwise be \"guessed\" from the underlying source) ParsableSource.parser() - this can be used to override parser (that would otherwise be based on mediaType ) ParsableSource.mediaType() - return the configured or \"guessed\" media type of this source, see io.helidon.common.media.type.MediaTypes , if not returned, media type must be present on Content , or provided through media type mapping ",
            "title": "ConfigSource SPI"
        },
        {
            "location": "se/config/extensions",
            "text": " The parsing step converts config data in some format into the corresponding in-memory representation of config ObjectNode s. The config system can already parse several data formats (for example Java Properties , YAML, and HOCON). Implement the ConfigParser SPI to allow the config system to handle additional formats. ConfigParser SPI The ConfigParser.Content interface defines operations on the content that is to be parsed by a ConfigParser implementation: mediaType() - Reports the media type of the content (if it is to override media type defined on the config source) data() - Provides the InputStream with config source data charset() - Defines the charset to use to parse the stream in case this is a text based media type, ignored by parsers of binary content The application can register parsers for a builder by invoking Config.Builder#addParser(ConfigParser) . The config system also uses the Java service loader mechanism to load automatically, for all builders, any parsers listed in the META-INF/services/io.helidon.config.spi.ConfigParser resource on the runtime classpath. Prevent autoloading of parsers for a given builder by invoking Config.Builder#disableParserServices() . ConfigParser accepts @Priority . See About Priority . <markup lang=\"listing\" title=\"Example custom parser implementation listed in META-INF/services/io.helidon.config.spi.ConfigParser \" >my.module.MyConfigParser <markup lang=\"java\" title=\"Example custom parser definition in module-info.java \" >module my.module { requires transitive io.helidon.config; provides io.helidon.config.spi.ConfigParser with myModule.MyConfigParser; } ",
            "title": "ConfigParser SPI"
        },
        {
            "location": "se/config/extensions",
            "text": " When the application retrieves a configuration value the config system first uses the relevant config sources and filters. It then applies any overrides the application has provided. Each override has: a Predicate&lt;Config.Key&gt; (a boolean-valued function that operates on the config key), and a replacement, overriding , String value the config system should use if the predicate evaluates to true. To furnish overrides to the config system, implement the OverrideSource SPI one or more times and pass instances of those implementations to the config builder&#8217;s overrides method. The config system will apply the overrides returned from each OverrideSource to each config key requested from a Config that is based on that Config.Builder . To support custom override sources in config profiles, also implement the OverrideSourceProvider service loader SPI OverrideSource SPI Note that override sources can also implement PollableSource , and WatchableSource to add change support. ",
            "title": "OverrideSource SPI"
        },
        {
            "location": "se/config/extensions",
            "text": " The ConfigFilter JavaDoc describes multiple methods for adding filters to a Config.Builder . Some accept a ConfigFilter directly and some accept a provider function which, when passed a Config instance, returns a ConfigFilter . Neither a ConfigFilter nor a provider function which furnishes one should access the Config instance passed to the provider function. Instead, implement the ConfigFilter.init(Config) method on the filter. The config system invokes the filters' init methods according to the filters' @Priority order. Recall that whenever any code invokes Config.get , the Config instance invokes the apply method of all registered filters. By the time the application retrieves config this way the config system will have run the init method on all the filters. But note that when a filter&#8217;s init method invokes Config.get , the init methods of lower-priority filters will not yet have run. ConfigFilter SPI ",
            "title": "Initializing Filters"
        },
        {
            "location": "se/config/extensions",
            "text": " Before returning a String from Config.value() the config system applies any filters set up on the Config.Builder used to create the config tree that contains the config node of interest. The application provides filters as implementations of the ConfigFilter interface. Each filter is a function which accepts a Config.Key and an input String value and returns a String value the config system should use for that key going forward. The filter can return the original value or return some other value. The application registers filters and filter providers by passing ConfigFilter implementations to one of the config builder addFilter methods . The config system also uses the Java service loader mechanism to load additional filters automatically, for all builders, using the service interface described in the following table. Prevent a given builder from using the autoloaded filters by invoking the disableFilterServices method. Config SPI Interfaces for Filtering Interface Method Usage ConfigFilter Accepts @Priority . See About Priority . String apply(Config.Key key, String stringValue); Accepts a key and the corresponding String value and returns the String which the config system should use for that key. Initializing Filters The ConfigFilter JavaDoc describes multiple methods for adding filters to a Config.Builder . Some accept a ConfigFilter directly and some accept a provider function which, when passed a Config instance, returns a ConfigFilter . Neither a ConfigFilter nor a provider function which furnishes one should access the Config instance passed to the provider function. Instead, implement the ConfigFilter.init(Config) method on the filter. The config system invokes the filters' init methods according to the filters' @Priority order. Recall that whenever any code invokes Config.get , the Config instance invokes the apply method of all registered filters. By the time the application retrieves config this way the config system will have run the init method on all the filters. But note that when a filter&#8217;s init method invokes Config.get , the init methods of lower-priority filters will not yet have run. ConfigFilter SPI ",
            "title": "ConfigFilter SPI"
        },
        {
            "location": "se/config/extensions",
            "text": " The config system provides built-in mappings from String values to various Java types. (See ConfigMappers .) To handle mappings to other types the application can register custom mappers with the config system by implementing the ConfigMapperProvider SPI. Such providers return a map, with entries in which: the key is the Java type (a Class object) the mapper produces, and the value is a ConfigMapper that converts the config in-memory data structure into the type in the key. The provider may also implement other methods for finer tuned conversion mechanisms: genericTypeMappers() returns a map with entries for specific GenericType conversions, for example when the provider supports only mapping for GenericType&lt;Map&lt;String, Integer&gt;&gt; mapper(Class) returns a conversion function (optional) that converts a config node to the typed instance (if supported by this provider) mapper(GenericType) returns a conversion function (optional) that coverts a config node to the GenericType (if supported by this provider) - for example in case this provider supports any Map&lt;String, ?&gt; type, such as Map&lt;String, Integer&gt; and Map&lt;String, Double&gt; The config conversion system works as follows: For Config.as(Class) : Check whether a conversion function exists for the class requested (from method mappers() ). Check whether a conversion function is provided by any ConfigMapperProvider with method mapper(Class) . Check whether a conversion function exists for a generic type for the class requested (from method genericTypeMappers ). Check whether a conversion function is provided by any ConfigMapperProvider with method mapper(GenericType) for a generic type for the class requested. For Config.as(GenericType) - the first two steps are skipped. The config system also uses the Java ServiceLoader mechanism to load automatically, for all builders, any mappers returned by the providers listed in the META-INF/services/io.helidon.config.spi.ConfigMapperProvider resource on the runtime classpath. The application can prevent autoloading of mappers for a given builder by invoking Config.Builder#disableMapperServices() . Note that the built-in mappers described in ConfigMappers still operate. Mapper providers accept @Priority . See About Priority . ConfigMapperProvider SPI A mapper provider can specify a @jakarta.annotation.Priority . If no priority is explicitly assigned, the value of 100 is assumed. <markup lang=\"java\" title=\"Reference custom mapper provider implementation in META-INF/services/io.helidon.config.spi.ConfigMapperProvider \" >my.module.MyConfigMapperProvider <markup lang=\"java\" title=\"Reference custom mapper provider implementation in module-info.java \" >module my.module { requires transitive io.helidon.config; provides io.helidon.config.spi.ConfigMapperProvider with my.module.MyConfigMapperProvider; } ",
            "title": "ConfigMapperProvider SPI"
        },
        {
            "location": "se/config/extensions",
            "text": " An implementation of PollingStrategy gets an instance to poll, and triggers its poll method. The result of poll method may be used to update the polling strategy schedule. The approach of checking for changes is part of the config system, and the PollingStrategy does not need to be concerned with it. This is based on the source stamp as defined in ConfigContent and used in PollableSource.isModified(Object) methods. If a more sophisticated solution is needed, you may need to implement a ChangeWatcher instead. The config system offers polling strategy for periodic time-based checks. Often an application can create a config source simply by using one of the methods on ConfigSources (for example, ConfigSources#file(path) to get a builder and then invoke pollingStrategy passing a polling strategy. But the application can implement its own PollingStrategy and set it on the config source builder instead. PollingStrategy SPI To support polling strategies that can be configured in config profile, also implement the PollingStrategyProvider Java service loader SPI. ",
            "title": "PollingStrategy SPI"
        },
        {
            "location": "se/config/extensions",
            "text": " An implementation of ChangeWatcher gets the underlying source information and a change listener. The \"watcher\" then watches for changes of the source and notifies the listener when a change occurs. This is designed to support sources that can react on changes (such as file system). When a polling mechanism is needed, please check PollingStrategy above. The config system offers a change watcher for any Path based config source (such as FileConfigSource ) and for the etcd config source. To use a change watcher, simply create a config source using its builder and register the change watcher on the builder (the config source must support appropriate type of change watchers). ChangeWatcher SPI To support change watchers that can be configured in config profile, also implement the ChangeWatcherProvider Java service loader SPI. ",
            "title": "ChangeWatcher SPI"
        },
        {
            "location": "se/config/extensions",
            "text": " Once it loads a Config tree from ConfigSource , the config system does not itself change the in-memory Config tree. Even so, the underlying data available via the tree&#8217;s ConfigSource s can change. Implementations of PollingStrategy may trigger regular check whether a source has new data. Implementation of ChangeWatcher may watch the underlying source for changes and trigger an update. PollingStrategy SPI An implementation of PollingStrategy gets an instance to poll, and triggers its poll method. The result of poll method may be used to update the polling strategy schedule. The approach of checking for changes is part of the config system, and the PollingStrategy does not need to be concerned with it. This is based on the source stamp as defined in ConfigContent and used in PollableSource.isModified(Object) methods. If a more sophisticated solution is needed, you may need to implement a ChangeWatcher instead. The config system offers polling strategy for periodic time-based checks. Often an application can create a config source simply by using one of the methods on ConfigSources (for example, ConfigSources#file(path) to get a builder and then invoke pollingStrategy passing a polling strategy. But the application can implement its own PollingStrategy and set it on the config source builder instead. PollingStrategy SPI To support polling strategies that can be configured in config profile, also implement the PollingStrategyProvider Java service loader SPI. ChangeWatcher SPI An implementation of ChangeWatcher gets the underlying source information and a change listener. The \"watcher\" then watches for changes of the source and notifies the listener when a change occurs. This is designed to support sources that can react on changes (such as file system). When a polling mechanism is needed, please check PollingStrategy above. The config system offers a change watcher for any Path based config source (such as FileConfigSource ) and for the etcd config source. To use a change watcher, simply create a config source using its builder and register the change watcher on the builder (the config source must support appropriate type of change watchers). ChangeWatcher SPI To support change watchers that can be configured in config profile, also implement the ChangeWatcherProvider Java service loader SPI. ",
            "title": "Change Support SPI"
        },
        {
            "location": "se/config/extensions",
            "text": " The builder for each ConfigSource and OverrideSource accepts a RetryPolicy governing if and how the source should deal with failures loading the underlying data. A retry policy accepts a function, the invocation of which the policy will govern according to its own implementation. Applications can use the predefined policies in RetryPolicies , such as RetryPolicies.justCall which simply invokes the function without any retry. That class also exposes a builder for constructing a time-based retry policy, with several parameters: Parameters Controlling Built-in RetryPolicy Parameter Usage Default delay Initial delay between calls to the function 200 ms delayFactor Multiplier applied to delay on each successive call 2 callTimeout Time limit for each individual call of the function 500 ms overallTimeout Limit for the total elapsed time attempting to call the function successfully, including delays between calls 2 s The actual delay between function call starts as delay and changes by the factor delayFactor on each successive attempt. Note that the job of each retry policy is to call the provided function successfully. As such, the policy must perform the first attempt as well as any retries. RetryPolicy SPI The application can try to cancel the overall execution of a RetryPolicy by invoking the RetryPolicy#cancel(boolean mayInterruptIfRunning) method. Ideally the retry policy implementation should be able to abort the execution of the retry policy, even while a function call is in progress, but the policy must respond to cancel between function calls. In either case cancel returns true if the retry was aborted without a successful call to the function, and false otherwise, including if the function call had already completed successfully or had previously been successfully canceled. To support retry policies in config profiles, also implement the Java service loader SPI RetryPolicyProvider . ",
            "title": "RetryPolicy SPI"
        },
        {
            "location": "se/config/hierarchical-features",
            "text": " Overview Configuration Node Types Configuration Key In-memory Representation of Configuration Access by Key Access by General Navigation Detaching a Config Subtree ",
            "title": "Contents"
        },
        {
            "location": "se/config/hierarchical-features",
            "text": " The config system represents configuration as a tree in memory. Many developers will choose to work directly with config values&#8201;&#8212;&#8201;values from the leaves in the tree&#8201;&#8212;&#8201;accessing them by their keys. You can also navigate explicitly among the nodes of the tree without using keys. This section describes what the tree looks like and how you can traverse it. ",
            "title": "Overview"
        },
        {
            "location": "se/config/hierarchical-features",
            "text": " The config system represents configuration in memory using three types of nodes, each a different interface defined within the ConfigNode interface. ConfigNode Types Type Java Interface Usage object ConfigNode.ObjectNode Represents complex structure (a subtree). Its child nodes can be of any type. list ConfigNode.ListNode Represents a list of nodes. Its components can be of any type. value ConfigNode.ValueNode Represents a leaf node. A node of any type can have a String value. Each config tree in memory will have an object node as its root with child nodes as dictated by the source config data from which the config system built the tree. Missing Config Nodes If your application attempts to access a non-existent node, for example using <markup lang=\"java\" >config.get(\"key.does.not.exist\") the config system returns a Config node object with type MISSING . The in-memory config tree contains nodes only of types OBJECT , LIST , and VALUE . ",
            "title": "Configuration Node Types"
        },
        {
            "location": "se/config/hierarchical-features",
            "text": " Each config node (except the root) has a non-null key. Here is the formal definition of what keys can be: <markup lang=\"abnf\" title=\"The ABNF syntax of config key\" >config-key = *1( key-token *( \".\" key-token ) ) key-token = *( unescaped / escaped ) unescaped = %x00-2D / %x2F-7D / %x7F-10FFFF ; %x2E ('.') and %x7E ('~') are excluded from 'unescaped' escaped = \"~\" ( \"0\" / \"1\" ) ; representing '~' and '.', respectively Important To emphasize, the dot character (&#8220;.&#8221;) has special meaning as a name separator in keys. To include a dot as a character in a key escape it as &#8220;~1&#8221;. To include a tilda escape it as &#8220;~0&#8221;. ",
            "title": "Configuration Key"
        },
        {
            "location": "se/config/hierarchical-features",
            "text": " The following example is in HOCON (human-optimized config object notation) format. The config system supports HOCON as an extension module . <markup lang=\"hocon\" title=\"HOCON application.conf file\" >app { greeting = \"Hello\" page-size = 20 basic-range = [ -20, 20 ] } data { providers: [ { name = \"Provider1\" class = \"this.is.my.Provider1\" }, { name = \"Provider2\" class = \"this.is.my.Provider2\" } ] } The diagram below illustrates the in-memory tree for that configuration. Config Nodes structure of application.conf file Notes Each non-root node has a name which distinguishes it from other nodes with the same parent. The interpretation of the name depends on the node type. Node Type Name object value member name of the node within its parent list element index of the node within the containing list Each node&#8217;s key is the fully-qualified path using dotted names from the root to that node. The root has an empty key, empty name, and no value. The Config object exposes methods to return the name , key , and type of the node. ",
            "title": "In-memory Representation of Configuration"
        },
        {
            "location": "se/config/hierarchical-features",
            "text": " For many applications, accessing configuration values by key will be the simplest approach. If you write the code with a specific configuration structure in mind, your code can retrieve the value from a specific configuration node very easily. Your application can specify the entire navigation path as the key to a single get invocation, using dotted notation to separate the names of the nodes along the path. The code can navigate one level at a time using chained get invocations, each specifying one level of the path to the expected node. Or, you can mix the two styles. All the following lines retrieve the same Config node. <markup lang=\"java\" title=\"Equivalent Config Retrievals\" >assert config.get(\"\") == config; Config provName1 = config.get(\"data.providers.0.name\"); Config provName2 = config.get(\"data.providers.0\").get(\"name\"); Config provName3 = config.get(\"data.providers\").get(\"0.name\"); Config provName4 = config.get(\"data\").get(\"providers.0\").get(\"name\"); Config provName5 = config.get(\"data\").get(\"providers\").get(\"0\").get(\"name\"); using a single key mixed style (composite key and single key) navigating one level with each get invocation The Config.get(key) method always returns a Config object without throwing an exception. If the specified key does not exist the method returns a Config node of type MISSING . There are several ways your application can tell whether a given config value exists. Method Usage exists Returns true or false ifExists Execute functional operations for present nodes type Returns enum value for the Config.Type ; Config.Type.MISSING if the node represents a config value that does not exist as Returns the ConfigValue with the correct type that has all methods of Optional and a few additional ones - see ConfigValue interface. The config system throws a MissingValueException if the application tries to access the value of a missing node by invoking the ConfigValue.get() method. ",
            "title": "Access by Key"
        },
        {
            "location": "se/config/hierarchical-features",
            "text": " Some applications might need to work with configuration without knowing its structure or key names ahead of time, and such applications can use various methods on the Config class to do this. General Config Node Methods Method Usage asNodeList() Returns a ConfigValue&lt;List&lt;Config&gt;&gt;. For nodes of type OBJECT contains child nodes as a List . hasValue() For any node reports if the node has a value. This can be true for any node type except MISSING . isLeaf() Reports whether the node has no child nodes. Leaf nodes have no children and has a single value. key() Returns the fully-qualified path of the node using dotted notation. name() Returns the name of the node (the last part of the key). asNode() Returns a ConfigValue&lt;Config&gt; wrapped around the node traverse() traverse(Predicate&lt;Config&gt;) Returns a Stream&lt;Config&gt; as an iterative deepening depth-first traversal of the subtree type() Returns the Type enum value for the node: OBJECT , LIST , VALUE , or MISSING <markup lang=\"java\" title=\"List names of child nodes of an object node\" >List&lt;String&gt; appNodeNames = config.get(\"app\") .asNodeList() .map(nodes -&gt; { return nodes .stream() .map(Config::name) .sorted() .collect(Collectors.toList()); }) .orElse(Collections.emptyList()); assert appNodeNames.get(0).equals(\"basic-range\"); assert appNodeNames.get(1).equals(\"greeting\"); assert appNodeNames.get(2).equals(\"page-size\"); Get the ConfigValue with child Config instances. Map the node list to names using the Java Stream API (if present) Use an empty list if the \"app\" node does not exist Check that the list contains the expected child names: basic-range , greeting and page-size . <markup lang=\"java\" title=\"List child nodes of a list node\" >List&lt;Config&gt; providers = config.get(\"data.providers\") .asNodeList().orElse(Collections.emptyList()); assert providers.get(0).key().toString().equals(\"data.providers.0\"); assert providers.get(1).key().toString().equals(\"data.providers.1\"); Get child nodes of the data.providers list node as a List of Config instances. Check that the list contains the expected child nodes with keys data.providers.0 and data.providers.1 . The traverse() method returns a stream of the nodes in the subtree that is rooted at the current configuration node. Depending on the structure of the loaded configuration the stream contains a mix of object, list or leaf value nodes. <markup lang=\"java\" title=\"Traverse subtree below a list node\" >config.get(\"data.providers\") .traverse() .forEach(node -&gt; System.out.println(node.type() + \" \\t\" + node.key())); Visit the subtree rooted at the data.providers list node. Prints out following list of nodes (type and key): OBJECT data.providers.0 VALUE data.providers.0.name VALUE data.providers.0.class OBJECT data.providers.1 VALUE data.providers.1.name VALUE data.providers.1.class The optional Predicate&lt;Config&gt; argument to the traverse methods allows the application to prune the traversal of a subtree at any point. <markup lang=\"java\" title=\"Traverse root ( object ) node, skipping the entire data subtree\" >config.traverse(node -&gt; !node.name().equals(\"data\")) .forEach(node -&gt; System.out.println(node.type() + \" \\t\" + node.key())); Visit all root sub-nodes, excluding whole data tree structure but including others. Prints out following list of nodes (type and key): OBJECT app VALUE app.page-size VALUE app.greeting LIST app.basic-range VALUE app.basic-range.0 VALUE app.basic-range.1 ",
            "title": "Access by General Navigation"
        },
        {
            "location": "se/config/hierarchical-features",
            "text": " Sometimes it can be convenient to write part of your application to deal with configuration without it knowing if or where the relevant configuration is plugged into a larger config tree. For example, the application.properties from the introduction section contains several settings prefixed with web such as web.page-size . Perhaps in another config source the same information might be stored as server.web.page-size : <markup lang=\"java\" title=\"Alternate Structure for Web Config\" >server.web.page-size: 40 server.web.debug = true server.web.ratio = 1.4 You might want to write the web portion of your app to work with a config subtree with keys that are independent of the subtree&#8217;s position in a larger tree. This would allow you to reuse the web portion of your application without change, regardless of which structure a config source used. One easy way to do this is to detach a subtree from a larger config tree. When your application invokes the Config.detach method it gets back a copy of the config node but with no parent. The copy and the original node both point to the same objects for their child nodes (if any). The original node is unchanged. <markup lang=\"java\" title=\"Detaching a Subtree\" >Config originalRoot = // from the original example `.conf` file Config alternateRoot = // from the alternate structure above Config detachedFromOriginal = originalRoot.get(\"web\").detach(); Config detachedFromAlternate = alternateRoot.get(\"server.web\").detach(); assert originalRoot.get(\"web.debug\").equals(\"true\"); assert alternateRoot.get(\"server.web.debug\").equals(\"true\"); assert detachedFromOriginal.get(\"debug\").equals(\"true\"); assert detachedFromAlternate.get(\"debug\").equals(\"true\"); Navigation depends on knowing the full structure of the config and so is different for the two cases. Detaching so the web node is the root can use the same key regardless of where the config subtree came from. ",
            "title": "Detaching a Config Subtree"
        },
        {
            "location": "se/config/introduction",
            "text": " Overview Maven Coordinates Usage Configuration Reference Additional Information ",
            "title": "Contents"
        },
        {
            "location": "se/config/introduction",
            "text": " Helidon provides a very flexible and comprehensive configuration system, offering you many application configuration choices. The Config component provides a Java API to load and process configuration data from various sources into a Config object which the application can then use. ",
            "title": "Overview"
        },
        {
            "location": "se/config/introduction",
            "text": " To enable Config add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.config&lt;/groupId&gt; &lt;artifactId&gt;helidon-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "se/config/introduction",
            "text": " Configuration can be loaded from different types of locations and expressed in different formats. The config system includes support for several types of config sources, for example: Environment variables - the property is a name/value pair. Java system properties - the property is a name/value pair. Resources in the classpath - the contents of the resource is parsed according to its inferred format. File - the contents of the file is parsed according to its inferred format. Directory - each non-directory file in the directory becomes a config entry: the file name is the key. and the contents of that file are used as the corresponding config String value. A URL resource - contents is parsed according to its inferred format. A variety of in-memory data structures ( String , Map , Properties ) See the JavaDoc for the ConfigSources class for a complete list of the built-in config source types and how to use them. See the advanced topics' page for further information on some more involved aspects of config sources. ",
            "title": "Config Sources"
        },
        {
            "location": "se/config/introduction",
            "text": " When it reads configuration text from sources, the config system uses config parsers to translate that text into the in-memory data structures representing that configuration. The config system includes several built-in parsers, such as for the Java properties, YAML, JSON, and HOCON formats. See this section for how to change your pom.xml to make parsers for those formats available to your application. Then your application can invoke the config builder&#8217;s addParser method so that builder will use the parsers you choose. You can extend the system with custom parsers of your own. Implement the ConfigParser interface, then construct a Config.Builder using the addParser method, passing an instance of your customer parser. Invoke one of the sources methods to include a source that uses the custom format and then build the Config object. See the advanced topics' page for further information on some more involved aspects of config parsers. ",
            "title": "Config Parsers"
        },
        {
            "location": "se/config/introduction",
            "text": " A brief overview of the config system helps clarify its different parts and how they work together. Most applications will typically deal with more than one of these parts. These are the main parts of the configuration system: Config system - allows you to read configuration data in an application A config source - a location containing configuration data (File, Map, Properties etc.) A config parser - a component capable of transforming bytes into configuration data (such as JSON content, YAML etc.) Config Sources Configuration can be loaded from different types of locations and expressed in different formats. The config system includes support for several types of config sources, for example: Environment variables - the property is a name/value pair. Java system properties - the property is a name/value pair. Resources in the classpath - the contents of the resource is parsed according to its inferred format. File - the contents of the file is parsed according to its inferred format. Directory - each non-directory file in the directory becomes a config entry: the file name is the key. and the contents of that file are used as the corresponding config String value. A URL resource - contents is parsed according to its inferred format. A variety of in-memory data structures ( String , Map , Properties ) See the JavaDoc for the ConfigSources class for a complete list of the built-in config source types and how to use them. See the advanced topics' page for further information on some more involved aspects of config sources. Config Parsers When it reads configuration text from sources, the config system uses config parsers to translate that text into the in-memory data structures representing that configuration. The config system includes several built-in parsers, such as for the Java properties, YAML, JSON, and HOCON formats. See this section for how to change your pom.xml to make parsers for those formats available to your application. Then your application can invoke the config builder&#8217;s addParser method so that builder will use the parsers you choose. You can extend the system with custom parsers of your own. Implement the ConfigParser interface, then construct a Config.Builder using the addParser method, passing an instance of your customer parser. Invoke one of the sources methods to include a source that uses the custom format and then build the Config object. See the advanced topics' page for further information on some more involved aspects of config parsers. ",
            "title": "Usage"
        },
        {
            "location": "se/config/introduction",
            "text": " Although the default configuration is very simple to use, your application can take full control of all configuration sources and precedence. You can do so by creating and invoking methods on a Config.Builder object to construct a Config instance. When your application prepares a Config.Builder it sets what ConfigSource s and ConfigParser s the builder should use in constructing the resulting Config object. The JavaDoc explains how to use the Config.Builder . See the Custom Configuration Sources and advanced config sources sections for detailed examples and further information. ",
            "title": "Custom Config Sources"
        },
        {
            "location": "se/config/introduction",
            "text": " You have used Helidon to customize configuration behavior from your code using the Config and Config.Builder classes. As discussed previously, Config system reads configuration from a config source, which uses a config parser to translate the source into an in-memory tree which represents the configuration’s structure and values. This approach allows us to take any source data, be it a flat properties file or an object structure such as JSON, and transform it into a single tree that allows for overriding of values using heterogeneous config sources. We are using the . as a separator of tree structure. Example of two config sources that can be used by Config with the same data tree in different formats: A Properties source: <markup lang=\"properties\" >web.page-size=25 A YAML source: <markup lang=\"yaml\" >web: page-size: 25 The configuration has the same internal representation in Config . Once created, the Config object provides many methods the application can use to retrieve config data as various Java types. See the Config JavaDoc for complete details. <markup lang=\"java\" >int pageSize = config.get(\"web.page-size\") .asInt() .orElse(20); Or using the tree node approach: <markup lang=\"java\" >int pageSize = config .get(\"web\") .get(\"page-size\") .asInt() .orElse(20); For this first example we can see the basic features of Config : Configuration is a tree of Config nodes You can use . as a tree separator when requesting node values Each config value can be retrieved as a typed object, with shortcut methods for the most commonly used types, such as int , String , long and other You can immediately provide a default value for the cases the configuration option is not defined in any source ",
            "title": "Accessing Config Values"
        },
        {
            "location": "se/config/introduction",
            "text": " The Config system treats config sources as a hierarchy, where the first source that has a specific configuration key \"wins\" and its value is used, other sources are not even queried for it. In order to properly configure your application using configuration sources, you need to understand the precedence rules that Helidon uses to merge your configuration data. If any of the Helidon required properties are not specified in one of these source, then Helidon will use a default value. For example the default configuration when you use Config.create() uses the following config sources in precedence order: System properties config source Environment variables config source A classpath config source called application.? where the ? depends on supported media types currently on the classpath.By default, it is properties , but if you have YAML support on classpath, it would be application.yaml (a ConfigParser may add additional supported suffixes for default file) Let&#8217;s consider the following keys: System property answer=42 Environment variable ANSWER=38 A key in a configuration file answer=36 When you request config.get(`answer ).asInt().orElse(25) , you would get `42 This allows you to configure environment specific configuration values through system properties, environment variables, or through files available on each environment (be it a physical machine, a Kubernetes pod, or a docker image) without changing your source code. ",
            "title": "Overriding Values"
        },
        {
            "location": "se/config/introduction",
            "text": " Config system applies configured config filters on each value when it is requested for the first time. There is a built-in filter called ValueResolvingFilter (enabled by default, can be disabled through API) that resolves references to other keys in values in configuration. Example: Let&#8217;s consider the following example properties file <markup lang=\"properties\" >host=localhost first-service.host=${host}/firstservice second-service.host=${host}/secondservice The filter resolves the ${host} reference to the localhost value. This makes it easier to override values in testing and production, as you can just override the host key and leave the URIs same. See Filter, Overrides, and Token Substitution section for further information on some more involved aspects. ",
            "title": "Config Filters"
        },
        {
            "location": "se/config/introduction",
            "text": " The Config object lets your application retrieve config data as a typed ConfigValue. You can retrieve a ConfigValue&lt;T&gt; using the following as methods in Config : * asString() - to get a string config value * asBoolean() and other accessors for primitive types * as(Class) - to get a value for a type that has a mapper configured * as(Generic) - to get a value for a type supporting generics (such as Set&lt;String&gt; ) * asMap() - to get a map of key to value pairs * asList(Class) - to get a list of typed values * as(Function&lt;Config,T&gt;) - to get a typed value providing a mapper function ConfigValue&lt;T&gt; can be used to obtain: * an Optional&lt;T&gt; value from a single node , * the T value from a single node interpreted as a basic Java type (primitive or simple object) already known to the config system (such as a boolean or a Double ), or * a complex Java type from a subtree of the config tree. + The config system automatically knows how to return List and Map complex types, and you can provide config mappers to convert a config subtree to whatever Java types your application needs. See Property Mapping page for details on how to use the built-in mappings and your own custom ones to convert to simple and complex types. ",
            "title": "Typed config values"
        },
        {
            "location": "se/config/introduction",
            "text": " Config sources, especially those that depend on fallible mechanisms such as the network or a shared file system, might fail to load during momentary outages. The config system allows you to build resiliency into your application&#8217;s use of configuration that relies on such technologies. When your application builds a ConfigSource it can specify a retry policy . When the config system needs to load data from that source it delegates the load operation to that retry policy. That policy is responsible not only for loading the data but also for detecting errors during loading and implementing the algorithm for deciding when and how many times to retry a failed load before reporting a failure back to your application. The config system includes two predefined retry policies: Predefined Retry Policies Policy Summary \"just call\" (default) asks the config source to load the data with no retry \"repeat\" performs a settable number of time-based retries, reporting failure only after all available retries have failed See the RetryPolicies JavaDoc for complete details on these built-in retry policies. You can devise your own policy. Implement the RetryPolicy interface. Then pass an instance of your policy implementation to the config source builder&#8217;s retryPolicy method. ",
            "title": "Dealing with Loading Errors: Retry Policies"
        },
        {
            "location": "se/config/introduction",
            "text": " Each Config object which the config system returns to your application is immutable; even if the information in one of the underlying config sources changes, an in-memory data structure built from the earlier content remains unchanged. Nevertheless, we know that configuration sometimes changes, and we may want to react to such changes. So the config system allows your application to learn when such underlying changes in the data occur and respond accordingly. In Config system, you can do this through change support provided by these components: Config.onChange() API - you can use to add your listener, to be notified of configuration changes PollingStrategy - a component providing regular events to check if a source has changed. This requires support in config sources themselves (see PollableSource ) ChangeWatcher - a component watching the underlying source for changes. This requires support in config sources themselves (see WatchableSource ) EventConfigSource - an event source that is capable of notifying about changes itself If you want to receive onChange events, you must configure your Config with at least one source that is capable of providing changes (having a PollingStrategy or ChangeWatcher configured, or implementing EventConfigSource ) The mutability documentation explains this in detail, and the PollingStrategies JavaDoc describes the built-in implementations. You can, of course, write your own by implementing the PollingStrategy interface. On a config source builder invoke pollingStrategy with an instance of your custom strategy and then invoke build to create the ConfigSource . ",
            "title": "Change Support"
        },
        {
            "location": "se/config/introduction",
            "text": " If you add additional Helidon config maven artifacts to your dependencies, then the config system can read formats other than Java properties format and the default configuration will search for other application file types in the following order. Note that the default configuration stops once it finds one of the files below; it does not merge all such files it can find. Default Config Files (most to the least important) Source Helidon maven artifact ID (group ID: io.helidon.config ) Notes application.yaml helidon-config-yaml YAML format http://yaml.org application.conf helidon-config-hocon HOCON format https://github.com/lightbend/config#using-hocon-the-json-superset application.json helidon-config-hocon JSON format https://json.org/ application.properties helidon-config Java properties format You can also extend the config system to handle other types of sources by implementing the ConfigSource interface. See the extensions' documentation for complete information. ",
            "title": "Built-in Support for Config Formats"
        },
        {
            "location": "se/config/introduction",
            "text": " Helidon has an internal configuration, so you are not required to provide any configuration data for your application, though in practice you most likely would. In your application code, when you create a default Config object, Helidon uses the default configuration . <markup lang=\"Java\" >Config config = Config.create(); The Config object is created with default settings. Custom Config Sources Although the default configuration is very simple to use, your application can take full control of all configuration sources and precedence. You can do so by creating and invoking methods on a Config.Builder object to construct a Config instance. When your application prepares a Config.Builder it sets what ConfigSource s and ConfigParser s the builder should use in constructing the resulting Config object. The JavaDoc explains how to use the Config.Builder . See the Custom Configuration Sources and advanced config sources sections for detailed examples and further information. Accessing Config Values You have used Helidon to customize configuration behavior from your code using the Config and Config.Builder classes. As discussed previously, Config system reads configuration from a config source, which uses a config parser to translate the source into an in-memory tree which represents the configuration’s structure and values. This approach allows us to take any source data, be it a flat properties file or an object structure such as JSON, and transform it into a single tree that allows for overriding of values using heterogeneous config sources. We are using the . as a separator of tree structure. Example of two config sources that can be used by Config with the same data tree in different formats: A Properties source: <markup lang=\"properties\" >web.page-size=25 A YAML source: <markup lang=\"yaml\" >web: page-size: 25 The configuration has the same internal representation in Config . Once created, the Config object provides many methods the application can use to retrieve config data as various Java types. See the Config JavaDoc for complete details. <markup lang=\"java\" >int pageSize = config.get(\"web.page-size\") .asInt() .orElse(20); Or using the tree node approach: <markup lang=\"java\" >int pageSize = config .get(\"web\") .get(\"page-size\") .asInt() .orElse(20); For this first example we can see the basic features of Config : Configuration is a tree of Config nodes You can use . as a tree separator when requesting node values Each config value can be retrieved as a typed object, with shortcut methods for the most commonly used types, such as int , String , long and other You can immediately provide a default value for the cases the configuration option is not defined in any source Overriding Values The Config system treats config sources as a hierarchy, where the first source that has a specific configuration key \"wins\" and its value is used, other sources are not even queried for it. In order to properly configure your application using configuration sources, you need to understand the precedence rules that Helidon uses to merge your configuration data. If any of the Helidon required properties are not specified in one of these source, then Helidon will use a default value. For example the default configuration when you use Config.create() uses the following config sources in precedence order: System properties config source Environment variables config source A classpath config source called application.? where the ? depends on supported media types currently on the classpath.By default, it is properties , but if you have YAML support on classpath, it would be application.yaml (a ConfigParser may add additional supported suffixes for default file) Let&#8217;s consider the following keys: System property answer=42 Environment variable ANSWER=38 A key in a configuration file answer=36 When you request config.get(`answer ).asInt().orElse(25) , you would get `42 This allows you to configure environment specific configuration values through system properties, environment variables, or through files available on each environment (be it a physical machine, a Kubernetes pod, or a docker image) without changing your source code. Config Filters Config system applies configured config filters on each value when it is requested for the first time. There is a built-in filter called ValueResolvingFilter (enabled by default, can be disabled through API) that resolves references to other keys in values in configuration. Example: Let&#8217;s consider the following example properties file <markup lang=\"properties\" >host=localhost first-service.host=${host}/firstservice second-service.host=${host}/secondservice The filter resolves the ${host} reference to the localhost value. This makes it easier to override values in testing and production, as you can just override the host key and leave the URIs same. See Filter, Overrides, and Token Substitution section for further information on some more involved aspects. Typed config values The Config object lets your application retrieve config data as a typed ConfigValue. You can retrieve a ConfigValue&lt;T&gt; using the following as methods in Config : * asString() - to get a string config value * asBoolean() and other accessors for primitive types * as(Class) - to get a value for a type that has a mapper configured * as(Generic) - to get a value for a type supporting generics (such as Set&lt;String&gt; ) * asMap() - to get a map of key to value pairs * asList(Class) - to get a list of typed values * as(Function&lt;Config,T&gt;) - to get a typed value providing a mapper function ConfigValue&lt;T&gt; can be used to obtain: * an Optional&lt;T&gt; value from a single node , * the T value from a single node interpreted as a basic Java type (primitive or simple object) already known to the config system (such as a boolean or a Double ), or * a complex Java type from a subtree of the config tree. + The config system automatically knows how to return List and Map complex types, and you can provide config mappers to convert a config subtree to whatever Java types your application needs. See Property Mapping page for details on how to use the built-in mappings and your own custom ones to convert to simple and complex types. Dealing with Loading Errors: Retry Policies Config sources, especially those that depend on fallible mechanisms such as the network or a shared file system, might fail to load during momentary outages. The config system allows you to build resiliency into your application&#8217;s use of configuration that relies on such technologies. When your application builds a ConfigSource it can specify a retry policy . When the config system needs to load data from that source it delegates the load operation to that retry policy. That policy is responsible not only for loading the data but also for detecting errors during loading and implementing the algorithm for deciding when and how many times to retry a failed load before reporting a failure back to your application. The config system includes two predefined retry policies: Predefined Retry Policies Policy Summary \"just call\" (default) asks the config source to load the data with no retry \"repeat\" performs a settable number of time-based retries, reporting failure only after all available retries have failed See the RetryPolicies JavaDoc for complete details on these built-in retry policies. You can devise your own policy. Implement the RetryPolicy interface. Then pass an instance of your policy implementation to the config source builder&#8217;s retryPolicy method. Change Support Each Config object which the config system returns to your application is immutable; even if the information in one of the underlying config sources changes, an in-memory data structure built from the earlier content remains unchanged. Nevertheless, we know that configuration sometimes changes, and we may want to react to such changes. So the config system allows your application to learn when such underlying changes in the data occur and respond accordingly. In Config system, you can do this through change support provided by these components: Config.onChange() API - you can use to add your listener, to be notified of configuration changes PollingStrategy - a component providing regular events to check if a source has changed. This requires support in config sources themselves (see PollableSource ) ChangeWatcher - a component watching the underlying source for changes. This requires support in config sources themselves (see WatchableSource ) EventConfigSource - an event source that is capable of notifying about changes itself If you want to receive onChange events, you must configure your Config with at least one source that is capable of providing changes (having a PollingStrategy or ChangeWatcher configured, or implementing EventConfigSource ) The mutability documentation explains this in detail, and the PollingStrategies JavaDoc describes the built-in implementations. You can, of course, write your own by implementing the PollingStrategy interface. On a config source builder invoke pollingStrategy with an instance of your custom strategy and then invoke build to create the ConfigSource . Built-in Support for Config Formats If you add additional Helidon config maven artifacts to your dependencies, then the config system can read formats other than Java properties format and the default configuration will search for other application file types in the following order. Note that the default configuration stops once it finds one of the files below; it does not merge all such files it can find. Default Config Files (most to the least important) Source Helidon maven artifact ID (group ID: io.helidon.config ) Notes application.yaml helidon-config-yaml YAML format http://yaml.org application.conf helidon-config-hocon HOCON format https://github.com/lightbend/config#using-hocon-the-json-superset application.json helidon-config-hocon JSON format https://json.org/ application.properties helidon-config Java properties format You can also extend the config system to handle other types of sources by implementing the ConfigSource interface. See the extensions' documentation for complete information. ",
            "title": "Configuration"
        },
        {
            "location": "se/config/introduction",
            "text": " SE Config Guide Step-by-step guide about using Config in your Helidon SE application. ",
            "title": "Reference"
        },
        {
            "location": "se/config/introduction",
            "text": " The links in the following tables lead you to more information about various other config topics. Controlling How Config is Loaded Topic Documentation Where config comes from Config sources , Config Profiles What format config data is expressed in Config parsers , supported formats How to filter, override, and dereference values Filters and overrides What happens when config data changes Mutability Support How to deal with loading errors Config retry policies Accessing Configuration Data Topic Documentation How config data is translated into Java types Config mappers How to navigate config trees Navigation Extending and Fine-tuning the Config System Topic Documentation Writing extensions Extensions ",
            "title": "Additional Information"
        },
        {
            "location": "se/config/mutability-support",
            "text": " Overview Using Config Metadata Responding to Changes in Config Sources Accessing Always-current Values ",
            "title": "Contents"
        },
        {
            "location": "se/config/mutability-support",
            "text": " An in-memory config tree, once loaded, is immutable, even though the data in the underlying config sources can change over time. The config system internally records which config sources it used to load each config tree and some metadata about the configuration. Your application can be aware of updates to the underlying config sources by: using the metadata the config system maintains, responding to change when the config sources are updated, or using Supplier s of particular config values to obtain the always-current value for a key. ",
            "title": "Overview"
        },
        {
            "location": "se/config/mutability-support",
            "text": " The config system records when it loads each configuration into memory. Your application can retrieve it by invoking the timestamp method : <markup lang=\"java\" >java.time.Instance loadTime = myConfig.timestamp(); on any config node. ",
            "title": "Loading Time"
        },
        {
            "location": "se/config/mutability-support",
            "text": " The config system maintains a Config.Context for each Config node. Your application can retrieve the context by invoking the Config.context() method and then use it for these operations: Uses of Config.Context Method Usage Instant timestamp() Returns the load time of the last loaded configuration that used the context. Config last() Returns the most recently loaded configuration that used the context. Config reload() Reloads the entire config tree from the current contents of the same config sources used to load the tree in which the current node resides. Note that the config context describes or replaces a currently-loaded config tree. It by itself does not help your application decide when reloading the config might be useful. ",
            "title": "Config Context"
        },
        {
            "location": "se/config/mutability-support",
            "text": " Loading Time The config system records when it loads each configuration into memory. Your application can retrieve it by invoking the timestamp method : <markup lang=\"java\" >java.time.Instance loadTime = myConfig.timestamp(); on any config node. Config Context The config system maintains a Config.Context for each Config node. Your application can retrieve the context by invoking the Config.context() method and then use it for these operations: Uses of Config.Context Method Usage Instant timestamp() Returns the load time of the last loaded configuration that used the context. Config last() Returns the most recently loaded configuration that used the context. Config reload() Reloads the entire config tree from the current contents of the same config sources used to load the tree in which the current node resides. Note that the config context describes or replaces a currently-loaded config tree. It by itself does not help your application decide when reloading the config might be useful. ",
            "title": "Using Config Metadata"
        },
        {
            "location": "se/config/mutability-support",
            "text": " When the application creates a config source, it can set up change detection for that source. This is called polling in the Helidon API but specific change detection algorithms might not use actual polling. You choose a specific PollingStrategy for each config source you want to monitor. See the section on polling strategies in the config extensions doc page for more information. The config system provides some built-in polling strategies, exposed as these methods on the PollingStrategies class: regular(Duration interval) - a general-purpose scheduled polling strategy with a specified, constant polling interval. watch(Path watchedPath) - a filesystem-specific strategy to watch specified path. You can use this strategy with the file and classpath built-in config sources. nop() - a no-op strategy This example builds a Config object from three sources, each set up with a different polling strategy: <markup lang=\"java\" title=\"Build a Config with a different PollingStrategy for each config source\" >Config config = Config.create( ConfigSources.file(\"conf/dev.properties\") .pollingStrategy(PollingStrategies.regular(Duration.ofSeconds(2))) .optional(), ConfigSources.file(\"conf/config.properties\") .changeWatcher(FileSystemWatcher.create()) .optional(), ConfigSources.classpath(\"application.properties\") .pollingStrategy(PollingStrategies::nop)); Optional file source conf/dev.properties will be checked for changes every 2 seconds. Optional file source conf/config.properties will be watched by the Java WatchService for changes on filesystem. The classpath resource application.properties will not be checked for changes. PollingStrategies.nop() polling strategy is default. The polling strategies internally inform the config system when they detect changes in the monitored config sources (except that the nop strategy does nothing). ",
            "title": "Setting up Config Source Change Detection"
        },
        {
            "location": "se/config/mutability-support",
            "text": " A simple approach is for your application to register a function that should run when any change occurs. <markup lang=\"java\" title=\"Subscribe on greeting property changes via onChange method\" >config.get(\"greeting\") .onChange((changedNode) -&gt; { System.out.println(\"Node \" + changedNode.key() + \" has changed!\"); return true; }); Navigate to the Config node on which you want to register. Invoke the onChange method, passing a function ( Function&lt;Config, Boolean&gt; ). The config system invokes that function each time the subtree rooted at the greeting node changes. The changedNode is a new instance of Config representing the updated subtree rooted at greeting . The function should return true to continue being run on subsequent changes, false to stop. ",
            "title": "Registering Actions"
        },
        {
            "location": "se/config/mutability-support",
            "text": " The config system also supports the flow publisher/subscriber model for applications that need more control over the pace at which the config system delivers config change events. Each Config instance exposes the Config.changes() method which returns a Flow.Publisher&lt;Config&gt; . Your application can invoke this method, then invoke subscribe on the returned Flow.Publisher , passing your own Flow.Subscriber implementation. The config system will invoke your subscriber&#8217;s methods as appropriate, most notably calling onNext whenever it detects a change in one of the underlying config sources for the config node of interest. Mote that your subscriber will be notified when a change occurs anywhere in the subtree represented by the Config node. <markup lang=\"java\" title=\"Subscribe on greeting property changes\" >config.get(\"greeting\") .changes() .subscribe(new Flow.Subscriber&lt;&gt;() { Flow.Subscription subscription; @Override public void onSubscribe(Flow.Subscription subscription) { this.subscription = subscription; subscription.request(1); } @Override public void onNext(Config changedNode) { System.out.println(\"Node \" + changedNode.key() + \" has changed!\"); subscription.request(1); } @Override public void onError(Throwable throwable) { } @Override public void onComplete() { } }); Navigate to the Config node on which you want to register. Invoke changes to get the Flow.Publisher of changes to the subtree rooted at the Config node. Subscribe to the publisher passing a custom Flow.Subscriber&lt;Config&gt; implementation. Request the first event delivery in onSubscribe method. The config system invokes onNext each time the subtree rooted at the greeting node changes. The changedNode is a new instance of Config representing the updated subtree rooted at greeting , regardless of where in the subtree the change actually occurred. Remember to request the next event delivery in onNext . The config system does not currently invoke onError . The config system invokes onComplete if all config sources indicate there will be no other change event . Note Your application does not need to subscribe to the new Config instance passed to your onNext method. The original subscription remains in force for changes to the \"new\" instance. ",
            "title": "Subscribing to Events"
        },
        {
            "location": "se/config/mutability-support",
            "text": " To know when config sources have changed, your application must register its interest on the Config node of interest. The config system will then notify your application of any change within the subtree rooted at that node. In particular, if you register on the root node, then the config system notifies your code of changes anywhere in the config tree. You can register in either of two ways: register an action to be run upon each change, or subscribe to a Flow.Publisher that notifies of changes. Registering Actions A simple approach is for your application to register a function that should run when any change occurs. <markup lang=\"java\" title=\"Subscribe on greeting property changes via onChange method\" >config.get(\"greeting\") .onChange((changedNode) -&gt; { System.out.println(\"Node \" + changedNode.key() + \" has changed!\"); return true; }); Navigate to the Config node on which you want to register. Invoke the onChange method, passing a function ( Function&lt;Config, Boolean&gt; ). The config system invokes that function each time the subtree rooted at the greeting node changes. The changedNode is a new instance of Config representing the updated subtree rooted at greeting . The function should return true to continue being run on subsequent changes, false to stop. Subscribing to Events The config system also supports the flow publisher/subscriber model for applications that need more control over the pace at which the config system delivers config change events. Each Config instance exposes the Config.changes() method which returns a Flow.Publisher&lt;Config&gt; . Your application can invoke this method, then invoke subscribe on the returned Flow.Publisher , passing your own Flow.Subscriber implementation. The config system will invoke your subscriber&#8217;s methods as appropriate, most notably calling onNext whenever it detects a change in one of the underlying config sources for the config node of interest. Mote that your subscriber will be notified when a change occurs anywhere in the subtree represented by the Config node. <markup lang=\"java\" title=\"Subscribe on greeting property changes\" >config.get(\"greeting\") .changes() .subscribe(new Flow.Subscriber&lt;&gt;() { Flow.Subscription subscription; @Override public void onSubscribe(Flow.Subscription subscription) { this.subscription = subscription; subscription.request(1); } @Override public void onNext(Config changedNode) { System.out.println(\"Node \" + changedNode.key() + \" has changed!\"); subscription.request(1); } @Override public void onError(Throwable throwable) { } @Override public void onComplete() { } }); Navigate to the Config node on which you want to register. Invoke changes to get the Flow.Publisher of changes to the subtree rooted at the Config node. Subscribe to the publisher passing a custom Flow.Subscriber&lt;Config&gt; implementation. Request the first event delivery in onSubscribe method. The config system invokes onNext each time the subtree rooted at the greeting node changes. The changedNode is a new instance of Config representing the updated subtree rooted at greeting , regardless of where in the subtree the change actually occurred. Remember to request the next event delivery in onNext . The config system does not currently invoke onError . The config system invokes onComplete if all config sources indicate there will be no other change event . Note Your application does not need to subscribe to the new Config instance passed to your onNext method. The original subscription remains in force for changes to the \"new\" instance. ",
            "title": "Registering a Config Change Response"
        },
        {
            "location": "se/config/mutability-support",
            "text": " Evolving API This section describes the Config.changes() method. It is marked as deprecated because it returns an io.helidon.reactive.Flow.Publisher object. In a future Helidon release that requires Java 11 or later this method will be un-deprecated and changed&#8201;&#8212;&#8201;or a similar method will be added&#8201;&#8212;&#8201;so that the return type is java.util.concurrent.Flow.Publisher instead. Any code you write using the existing Config.changes() method might need to change at that time. Although in-memory config trees do not change once loaded, applications can respond to change in the underlying config sources by: setting up change detection for the config sources used to build a configuration, and registering a response to be run when a source changes. Your code&#8217;s response can react to the changes in whatever way makes sense for your application. The following sections describe these steps in detail. Setting up Config Source Change Detection When the application creates a config source, it can set up change detection for that source. This is called polling in the Helidon API but specific change detection algorithms might not use actual polling. You choose a specific PollingStrategy for each config source you want to monitor. See the section on polling strategies in the config extensions doc page for more information. The config system provides some built-in polling strategies, exposed as these methods on the PollingStrategies class: regular(Duration interval) - a general-purpose scheduled polling strategy with a specified, constant polling interval. watch(Path watchedPath) - a filesystem-specific strategy to watch specified path. You can use this strategy with the file and classpath built-in config sources. nop() - a no-op strategy This example builds a Config object from three sources, each set up with a different polling strategy: <markup lang=\"java\" title=\"Build a Config with a different PollingStrategy for each config source\" >Config config = Config.create( ConfigSources.file(\"conf/dev.properties\") .pollingStrategy(PollingStrategies.regular(Duration.ofSeconds(2))) .optional(), ConfigSources.file(\"conf/config.properties\") .changeWatcher(FileSystemWatcher.create()) .optional(), ConfigSources.classpath(\"application.properties\") .pollingStrategy(PollingStrategies::nop)); Optional file source conf/dev.properties will be checked for changes every 2 seconds. Optional file source conf/config.properties will be watched by the Java WatchService for changes on filesystem. The classpath resource application.properties will not be checked for changes. PollingStrategies.nop() polling strategy is default. The polling strategies internally inform the config system when they detect changes in the monitored config sources (except that the nop strategy does nothing). Registering a Config Change Response To know when config sources have changed, your application must register its interest on the Config node of interest. The config system will then notify your application of any change within the subtree rooted at that node. In particular, if you register on the root node, then the config system notifies your code of changes anywhere in the config tree. You can register in either of two ways: register an action to be run upon each change, or subscribe to a Flow.Publisher that notifies of changes. Registering Actions A simple approach is for your application to register a function that should run when any change occurs. <markup lang=\"java\" title=\"Subscribe on greeting property changes via onChange method\" >config.get(\"greeting\") .onChange((changedNode) -&gt; { System.out.println(\"Node \" + changedNode.key() + \" has changed!\"); return true; }); Navigate to the Config node on which you want to register. Invoke the onChange method, passing a function ( Function&lt;Config, Boolean&gt; ). The config system invokes that function each time the subtree rooted at the greeting node changes. The changedNode is a new instance of Config representing the updated subtree rooted at greeting . The function should return true to continue being run on subsequent changes, false to stop. Subscribing to Events The config system also supports the flow publisher/subscriber model for applications that need more control over the pace at which the config system delivers config change events. Each Config instance exposes the Config.changes() method which returns a Flow.Publisher&lt;Config&gt; . Your application can invoke this method, then invoke subscribe on the returned Flow.Publisher , passing your own Flow.Subscriber implementation. The config system will invoke your subscriber&#8217;s methods as appropriate, most notably calling onNext whenever it detects a change in one of the underlying config sources for the config node of interest. Mote that your subscriber will be notified when a change occurs anywhere in the subtree represented by the Config node. <markup lang=\"java\" title=\"Subscribe on greeting property changes\" >config.get(\"greeting\") .changes() .subscribe(new Flow.Subscriber&lt;&gt;() { Flow.Subscription subscription; @Override public void onSubscribe(Flow.Subscription subscription) { this.subscription = subscription; subscription.request(1); } @Override public void onNext(Config changedNode) { System.out.println(\"Node \" + changedNode.key() + \" has changed!\"); subscription.request(1); } @Override public void onError(Throwable throwable) { } @Override public void onComplete() { } }); Navigate to the Config node on which you want to register. Invoke changes to get the Flow.Publisher of changes to the subtree rooted at the Config node. Subscribe to the publisher passing a custom Flow.Subscriber&lt;Config&gt; implementation. Request the first event delivery in onSubscribe method. The config system invokes onNext each time the subtree rooted at the greeting node changes. The changedNode is a new instance of Config representing the updated subtree rooted at greeting , regardless of where in the subtree the change actually occurred. Remember to request the next event delivery in onNext . The config system does not currently invoke onError . The config system invokes onComplete if all config sources indicate there will be no other change event . Note Your application does not need to subscribe to the new Config instance passed to your onNext method. The original subscription remains in force for changes to the \"new\" instance. ",
            "title": "Responding to Changes in Config Sources"
        },
        {
            "location": "se/config/mutability-support",
            "text": " Some applications do not need to respond to change as they happen. Instead, it&#8217;s sufficient that they simply have access to the current value for a particular key in the configuration. Each asXXX method on the Config class has a companion asXXXSupplier method. These supplier methods return Supplier&lt;XXX&gt; , and when your application invokes the supplier&#8217;s get method the config system returns the then-current value as stored in the config source. <markup lang=\"java\" title=\"Access greeting property as Supplier&lt;String&gt; \" >// Construct a Config with the appropriate PollingStrategy on each config source. Supplier&lt;String&gt; greetingSupplier = config.get(\"greeting\") .asString().supplier(); System.out.println(\"Always actual greeting value: \" + greetingSupplier.get()); Navigate to the Config node for which you want access to the always-current value. Retrieve and store the returned supplier for later use. Invoke the supplier&#8217;s get() method to retrieve the current value of the node. Important Supplier support requires that you create the Config object from config sources that have proper polling strategies set up. ",
            "title": "Accessing Always-current Values"
        },
        {
            "location": "se/config/property-mapping",
            "text": " Overview Converting Configuration to Simple Types Converting Configuration to Complex Types Advanced Conversions using Explicit Mapping Logic Conversions using JavaBean Deserialization ",
            "title": "Contents"
        },
        {
            "location": "se/config/property-mapping",
            "text": " Although config values are originally text, you can use the config system&#8217;s built-in conversions or add your own to translate text into Java primitive types and simple objects (such as Double ) and to express parts of the config tree as complex types ( List , Map , and custom types specific to your application). This section introduces how to use the built-in mappings and your own custom ones to convert to simple and complex types. ",
            "title": "Overview"
        },
        {
            "location": "se/config/property-mapping",
            "text": " The Config class itself provides many conversions to Java types. See the JavaDoc for the complete list. The methods which support Java primitive types and their related classes follow a common pattern. The examples in the table below deal with conversion to a boolean but the same pattern applies to many data types listed in the JavaDoc. Assume a local variable has been assigned something like <markup lang=\"java\" >Config config = Config.get(\"someKey\"); // shortcut method ConfigValue&lt;Boolean&gt; value = config.asBoolean(); // generic method (for any type) ConfigValue&lt;Boolean&gt; value2 = config.as(Boolean.class); Built-in Conversions to Simple Types (e.g., boolean) Java type Example usage 1 boolean boolean b = value.get(); 2 boolean defaultedB = value.orElse(true); 3 Optional&lt;Boolean&gt; ConfigValue already has all methods of an Optional. If actual optional is needed: Optional&lt;Boolean&gt; b = value.asOptional(); 4 Supplier&lt;Boolean&gt; Boolean b = value.supplier().get(); boolean defaultedB = value.supplier(true).get(); Supplier&lt;Optional&lt;Boolean&gt;&gt; Boolean b = value.optionalSupplier().get().orElse(Boolean.TRUE); Notes on Built-in Conversions to Simple Types 1 All conversions can throw MissingValueException (if no value exists at the requested key and no default is provided) and ConfigMappingException (if some error occurred while performing the data mapping). 2 The Config.asXXX methods internally use the Java-provided XXX.parseXXX methods, so here a missing or un-parseable string gives false because that is how Boolean.parseBoolean behaves. 3 User code defaults the value to true . 4 User code defaults the value to Boolean.TRUE if absent; otherwise parses the value using Boolean.parseBoolean . The numerous conversions defined on the Config class for other types (integers, doubles, etc.) will satisfy many of your application&#8217;s needs. The ConfigMappers class includes other related mappings from String (rather than from Config ) to Java types (described in the JavaDoc). For additional type mapping, you can use these methods defined on Config : <markup lang=\"java\" >T as(Class&lt;? extends T&gt; type); T as(Function&lt;Config, T&gt; mapper); T as(GenericType&lt;T&gt; genericType); which maps the current node to a type. The next example, and later ones below showing complex type mapping, use the example application.properties configuration from the config introduction. Part of that example includes this line: <markup >bl.initial-id = 10000000000 Your application can use Config.as to interpret the value as a BigDecimal : <markup lang=\"java\" >BigDecimal initialId = config.get(\"bl.initial-id\").as(BigDecimal.class); ",
            "title": "Converting Configuration to Simple Types"
        },
        {
            "location": "se/config/property-mapping",
            "text": " The Config class exposes several methods for mapping a structured config node to a Java List or Map . The JavaDoc contains complete details, but briefly your application can convert a structured Config node into: a List&lt;T&gt; of a given type a Map&lt;String, String&gt; in which each key is the fully-qualified key String for a config entry and the value is its String value ",
            "title": "Built-in Conversions to List and Map "
        },
        {
            "location": "se/config/property-mapping",
            "text": " Any time your application has a Config instance to map to the target class it invokes Config.as passing an instance of the corresponding conversion function: <markup lang=\"java\" >Config config = Config.get(\"web\"); ConfigValue&lt;WebConfig&gt; web = config.as(WebConfigMapper::map); You do not necessarily need a new instance of the mapper every time you want to use it. In this approach, everywhere your application needs to perform this conversion it specifies the mapper to use. If you decided to change which mapper to use you would need to update each of those places in your application. ",
            "title": "Use Custom Mapper Explicitly: Config.as method"
        },
        {
            "location": "se/config/property-mapping",
            "text": " In this approach, your application: Tells each Config.Builder that needs to know about the custom mapper by either: registering an instance of your mapper by invoking Config.Builder.addMapper , or implementing ConfigMapperProvider so it returns an instance of your mapper (see the JavaDoc for complete information) and creating or editing the file io.helidon.config.spi.ConfigMapperProvider so it contains a line with the fully-qualified class name of your ConfigMapperProvider . The config system will use the Java service loader to find and invoke all ConfigMapperProvider classes listed and add the mappers they provide to each Config.Builder automatically. Converts using the mapper by invoking the Config.as method which accepts the target type to convert to, not the mapper itself that does the conversion. If your application converts to the same target type in several places in the code, this approach allows you to change which mapper it uses by changing only the registration of the mapper, not each use of it. ",
            "title": "Register Custom Mapper Once, Use Implicitly: Config.as method"
        },
        {
            "location": "se/config/property-mapping",
            "text": " The following examples build on the example configuration from the application.properties example file in the introduction. <markup lang=\"java\" title=\"Java POJO to Hold web Properties Config\" >public class WebConfig { private boolean debug; private int pageSize; private double ratio; public WebConfig(boolean debug, int pageSize, double ratio) { this.debug = debug; this.pageSize = pageSize; this.ratio = ratio; } public boolean isDebug() { return debug; } public int getPageSize() { return pageSize; } public double getRatio() { return ratio; } } <markup lang=\"java\" title=\"Custom Mapper Class\" >public class WebConfigMapper implements Function&lt;Config, WebConfig&gt; { @Override public WebConfig apply(Config config) { return new WebConfig( config.get(\"debug\").asBoolean().orElse(false), config.get(\"page-size\").asInt().orElse(10), config.get(\"ratio\").asDouble().orElse(1.0) ); } } <markup lang=\"java\" title=\"Explicitly Using the Mapper\" >Config config = Config.create(classpath(\"application.properties\")); WebConfig web = config.get(\"web\") .as(new WebConfigMapper()) .get(); <markup lang=\"java\" title=\"Registering and Implicitly Using the Mapper\" >Config config = Config.builder(classpath(\"application.properties\")) .addMapper(WebConfig.class, new WebConfigMapper()) .build(); WebConfig web = config.get(\"web\") .as(WebConfig.class) .get(); Either of the two approaches just described will always work without requiring you to change the POJO class. ",
            "title": "Continuing the Web Example"
        },
        {
            "location": "se/config/property-mapping",
            "text": " Often your code will be simpler if you can treat parts of the configuration as custom, application-specific Java objects, rather than as a group of String keys and values. You will need customized conversions to do so. The config system provides many ways to accomplish this, described in the io.helidon.config package JavaDoc . Some of those approaches require that the target class&#8201;&#8212;&#8201;the class to which you want to convert the configuration data&#8201;&#8212;&#8201;have certain characteristics or that you add a method to the class to help do the mapping. You might want to avoid changing the target class else you might not even be able to if you do not control its source. Here are two approaches that will always work without requiring changes to the target class. For both approaches, you write your own conversion function. The difference is in how your application triggers the use of that mapper. Use Custom Mapper Explicitly: Config.as method Any time your application has a Config instance to map to the target class it invokes Config.as passing an instance of the corresponding conversion function: <markup lang=\"java\" >Config config = Config.get(\"web\"); ConfigValue&lt;WebConfig&gt; web = config.as(WebConfigMapper::map); You do not necessarily need a new instance of the mapper every time you want to use it. In this approach, everywhere your application needs to perform this conversion it specifies the mapper to use. If you decided to change which mapper to use you would need to update each of those places in your application. Register Custom Mapper Once, Use Implicitly: Config.as method In this approach, your application: Tells each Config.Builder that needs to know about the custom mapper by either: registering an instance of your mapper by invoking Config.Builder.addMapper , or implementing ConfigMapperProvider so it returns an instance of your mapper (see the JavaDoc for complete information) and creating or editing the file io.helidon.config.spi.ConfigMapperProvider so it contains a line with the fully-qualified class name of your ConfigMapperProvider . The config system will use the Java service loader to find and invoke all ConfigMapperProvider classes listed and add the mappers they provide to each Config.Builder automatically. Converts using the mapper by invoking the Config.as method which accepts the target type to convert to, not the mapper itself that does the conversion. If your application converts to the same target type in several places in the code, this approach allows you to change which mapper it uses by changing only the registration of the mapper, not each use of it. Continuing the Web Example The following examples build on the example configuration from the application.properties example file in the introduction. <markup lang=\"java\" title=\"Java POJO to Hold web Properties Config\" >public class WebConfig { private boolean debug; private int pageSize; private double ratio; public WebConfig(boolean debug, int pageSize, double ratio) { this.debug = debug; this.pageSize = pageSize; this.ratio = ratio; } public boolean isDebug() { return debug; } public int getPageSize() { return pageSize; } public double getRatio() { return ratio; } } <markup lang=\"java\" title=\"Custom Mapper Class\" >public class WebConfigMapper implements Function&lt;Config, WebConfig&gt; { @Override public WebConfig apply(Config config) { return new WebConfig( config.get(\"debug\").asBoolean().orElse(false), config.get(\"page-size\").asInt().orElse(10), config.get(\"ratio\").asDouble().orElse(1.0) ); } } <markup lang=\"java\" title=\"Explicitly Using the Mapper\" >Config config = Config.create(classpath(\"application.properties\")); WebConfig web = config.get(\"web\") .as(new WebConfigMapper()) .get(); <markup lang=\"java\" title=\"Registering and Implicitly Using the Mapper\" >Config config = Config.builder(classpath(\"application.properties\")) .addMapper(WebConfig.class, new WebConfigMapper()) .build(); WebConfig web = config.get(\"web\") .as(WebConfig.class) .get(); Either of the two approaches just described will always work without requiring you to change the POJO class. ",
            "title": "Custom Conversions"
        },
        {
            "location": "se/config/property-mapping",
            "text": " The hierarchical features section describes the tree structure used to represent config data. The config system can map subtrees of a config tree to complex Java types. Built-in Conversions to List and Map The Config class exposes several methods for mapping a structured config node to a Java List or Map . The JavaDoc contains complete details, but briefly your application can convert a structured Config node into: a List&lt;T&gt; of a given type a Map&lt;String, String&gt; in which each key is the fully-qualified key String for a config entry and the value is its String value Custom Conversions Often your code will be simpler if you can treat parts of the configuration as custom, application-specific Java objects, rather than as a group of String keys and values. You will need customized conversions to do so. The config system provides many ways to accomplish this, described in the io.helidon.config package JavaDoc . Some of those approaches require that the target class&#8201;&#8212;&#8201;the class to which you want to convert the configuration data&#8201;&#8212;&#8201;have certain characteristics or that you add a method to the class to help do the mapping. You might want to avoid changing the target class else you might not even be able to if you do not control its source. Here are two approaches that will always work without requiring changes to the target class. For both approaches, you write your own conversion function. The difference is in how your application triggers the use of that mapper. Use Custom Mapper Explicitly: Config.as method Any time your application has a Config instance to map to the target class it invokes Config.as passing an instance of the corresponding conversion function: <markup lang=\"java\" >Config config = Config.get(\"web\"); ConfigValue&lt;WebConfig&gt; web = config.as(WebConfigMapper::map); You do not necessarily need a new instance of the mapper every time you want to use it. In this approach, everywhere your application needs to perform this conversion it specifies the mapper to use. If you decided to change which mapper to use you would need to update each of those places in your application. Register Custom Mapper Once, Use Implicitly: Config.as method In this approach, your application: Tells each Config.Builder that needs to know about the custom mapper by either: registering an instance of your mapper by invoking Config.Builder.addMapper , or implementing ConfigMapperProvider so it returns an instance of your mapper (see the JavaDoc for complete information) and creating or editing the file io.helidon.config.spi.ConfigMapperProvider so it contains a line with the fully-qualified class name of your ConfigMapperProvider . The config system will use the Java service loader to find and invoke all ConfigMapperProvider classes listed and add the mappers they provide to each Config.Builder automatically. Converts using the mapper by invoking the Config.as method which accepts the target type to convert to, not the mapper itself that does the conversion. If your application converts to the same target type in several places in the code, this approach allows you to change which mapper it uses by changing only the registration of the mapper, not each use of it. Continuing the Web Example The following examples build on the example configuration from the application.properties example file in the introduction. <markup lang=\"java\" title=\"Java POJO to Hold web Properties Config\" >public class WebConfig { private boolean debug; private int pageSize; private double ratio; public WebConfig(boolean debug, int pageSize, double ratio) { this.debug = debug; this.pageSize = pageSize; this.ratio = ratio; } public boolean isDebug() { return debug; } public int getPageSize() { return pageSize; } public double getRatio() { return ratio; } } <markup lang=\"java\" title=\"Custom Mapper Class\" >public class WebConfigMapper implements Function&lt;Config, WebConfig&gt; { @Override public WebConfig apply(Config config) { return new WebConfig( config.get(\"debug\").asBoolean().orElse(false), config.get(\"page-size\").asInt().orElse(10), config.get(\"ratio\").asDouble().orElse(1.0) ); } } <markup lang=\"java\" title=\"Explicitly Using the Mapper\" >Config config = Config.create(classpath(\"application.properties\")); WebConfig web = config.get(\"web\") .as(new WebConfigMapper()) .get(); <markup lang=\"java\" title=\"Registering and Implicitly Using the Mapper\" >Config config = Config.builder(classpath(\"application.properties\")) .addMapper(WebConfig.class, new WebConfigMapper()) .build(); WebConfig web = config.get(\"web\") .as(WebConfig.class) .get(); Either of the two approaches just described will always work without requiring you to change the POJO class. ",
            "title": "Converting Configuration to Complex Types"
        },
        {
            "location": "se/config/property-mapping",
            "text": " If you can change the target class you can add any one of the following methods or constructors to the POJO class which the config system will find and use for mapping. Continuing with the WebConfig example introduced earlier: Methods Supporting Auto-mapping static WebConfig create(Config); static WebConfig from(Config); static WebConfig from(String); static WebConfig of(Config); static WebConfig of(String); static WebConfig valueOf(Config); static WebConfig valueOf(String); static WebConfig fromConfig(Config); static WebConfig fromString(String); Constructors Supporting Auto-mapping WebConfig(Config); WebConfig(String); If the config system finds any of these methods or constructors when the application invokes <markup lang=\"java\" >WebConfig wc = config.as(WebConfig.class).get(); it will invoke the one it found to map the config data to a new instance of the target class. You do not need to write a separate class to do the mapping or register it with the Config.Builder for the config instance. ",
            "title": "Adding the Mapping to the POJO"
        },
        {
            "location": "se/config/property-mapping",
            "text": " You can limit the changes to the POJO class by adding a single builder method to the POJO which returns a builder class for the POJO: <markup lang=\"java\" >public class WebConfig { static WebConfigBuilder builder() { return new WebConfigBuilder(); } } The builder class WebConfigBuilder is expected to be a Java Bean with bean properties named for the config properties of interest, and a method WebConfig build() which creates the mapped instance from the builder&#8217;s own bean properties. When your application invokes config.as(WebConfig.class) the config system finds and invokes the WebConfig.builder() method, assigns the bean properties on the returned builder from the config subtree rooted at config , and invokes the builder&#8217;s build() method yielding the resulting WebConfig instance. ",
            "title": "Writing a Builder Method and Class for the POJO"
        },
        {
            "location": "se/config/property-mapping",
            "text": " If the target Java class you want to use meets certain conditions&#8201;&#8212;&#8201;or if you can change it to meet one of those conditions&#8201;&#8212;&#8201;you might not need to write a separate mapper class. Instead, you add the mapping logic to the POJO itself in one of several ways and the config system uses Java reflection to search for those ways to perform the mapping. Your application facilitates this implicit mapping either by adding to the POJO class or by providing a builder class for it. This feature is available in Object mapping module, and is added through Java ServiceLoader mechanism. This is no longer part of core Config module, as it depends on reflection and introduces a lot of magic (see the list of supported mapping methods below, also uses reflection to invoke the methods and to map configuration values to fields/methods etc.). <markup lang=\"xml\" title=\"Config object mapping Dependency in pom.xml \" >&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.config&lt;/groupId&gt; &lt;artifactId&gt;helidon-config-object-mapping&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; Adding the Mapping to the POJO If you can change the target class you can add any one of the following methods or constructors to the POJO class which the config system will find and use for mapping. Continuing with the WebConfig example introduced earlier: Methods Supporting Auto-mapping static WebConfig create(Config); static WebConfig from(Config); static WebConfig from(String); static WebConfig of(Config); static WebConfig of(String); static WebConfig valueOf(Config); static WebConfig valueOf(String); static WebConfig fromConfig(Config); static WebConfig fromString(String); Constructors Supporting Auto-mapping WebConfig(Config); WebConfig(String); If the config system finds any of these methods or constructors when the application invokes <markup lang=\"java\" >WebConfig wc = config.as(WebConfig.class).get(); it will invoke the one it found to map the config data to a new instance of the target class. You do not need to write a separate class to do the mapping or register it with the Config.Builder for the config instance. Writing a Builder Method and Class for the POJO You can limit the changes to the POJO class by adding a single builder method to the POJO which returns a builder class for the POJO: <markup lang=\"java\" >public class WebConfig { static WebConfigBuilder builder() { return new WebConfigBuilder(); } } The builder class WebConfigBuilder is expected to be a Java Bean with bean properties named for the config properties of interest, and a method WebConfig build() which creates the mapped instance from the builder&#8217;s own bean properties. When your application invokes config.as(WebConfig.class) the config system finds and invokes the WebConfig.builder() method, assigns the bean properties on the returned builder from the config subtree rooted at config , and invokes the builder&#8217;s build() method yielding the resulting WebConfig instance. ",
            "title": "Advanced Conversions using Explicit Mapping Logic"
        },
        {
            "location": "se/config/property-mapping",
            "text": " If your POJO target class is already a JavaBean&#8201;&#8212;&#8201;or you can modify it to become one&#8201;&#8212;&#8201;you might be able to avoid writing any explicit mapping code yourself. The config system invokes the no-args constructor on the target class to create a new instance. It treats each public setter method and each public non-final field as a JavaBean property. The config system processes any non-primitive property recursively as a JavaBean. In this way the config system builds up the target object from the config data. By default, the system matches potential JavaBean property names with config keys in the configuration. Use the Value annotation to control some of JavaBean processing for a given property. Value Annotation Attribute Usage key Indicates which config key should match this JavaBean property withDefault String used for the bean property default value if none is set in the config withDefaultSupplier Supplier of the default bean property value if not is set in the config To exclude a bean property from the config system bean processing annotate it with Config.Transient . Here is an example using the app portion of the example configuration from the introduction. <markup lang=\"java\" title=\"Java bean to load app properties into via setters\" >public class AppConfig { private Instant timestamp; private String greeting; private int pageSize; private List&lt;Integer&gt; basicRange; public AppConfig() { } public void setGreeting(String greeting) { this.greeting = greeting; } public String getGreeting() { return greeting; } @Value(key = \"page-size\", withDefault = \"10\") public void setPageSize(int pageSize) { this.pageSize = pageSize; } public int getPageSize() { return pageSize; } @Value(key = \"basic-range\", withDefaultSupplier = BasicRangeSupplier.class) public void setBasicRange(List&lt;Integer&gt; basicRange) { this.basicRange = basicRange; } public List&lt;Integer&gt; getBasicRange() { return basicRange; } @Config.Transient public void setTimestamp(Instant timestamp) { this.timestamp = timestamp; } public Instant getTimestamp() { return timestamp; } public static class BasicRangeSupplier implements Supplier&lt;List&lt;Integer&gt;&gt; { @Override public List&lt;Integer&gt; get() { return List.of(-10, 10); } } } Public no-parameter constructor. Property greeting is not customized and will be set from the config node with the key greeting , if present in the config. Property pageSize is matched to the config key page-size . If the page-size config node does not exist, the pageSize bean property defaults to 10 . Property basicRange is matched to the config key basic-range . If the basic-range config node does not exist, a BasicRangeSupplier instance will provide the default value. The timestamp bean property is never set, even if the config contains a node with the key timestamp . BasicRangeSupplier is used to supply the List&lt;Integer&gt; default value. Here is an example of code loading config and mapping part of it to the AppConfig bean above. <markup lang=\"java\" title=\"Map app config node into AppConfig class\" >Config config = Config.create(classpath(\"application.conf\")); AppConfig app = config.get(\"app\") .as(AppConfig.class) .get(); //assert that all values are loaded from file assert app.getGreeting().equals(\"Hello\"); assert app.getPageSize() == 20; assert app.getBasicRange().size() == 2 &amp;&amp; app.getBasicRange().get(0) == -20 &amp;&amp; app.getBasicRange().get(1) == 20; //assert that Transient property is not set assert app.getTimestamp() == null; The config system finds no registered ConfigMapper for AppConfig and so applies the JavaBean pattern to convert the config to an AppConfig instance. Because the bean property timestamp was marked as transient, the config system did not set it. ",
            "title": "POJO as JavaBean"
        },
        {
            "location": "se/config/property-mapping",
            "text": " If the target class includes the public static method builder() that returns any object, then the config system will make sure that the return type has a method build() which returns an instance of the target class. If so, the config system treats the builder as a JavaBean and invokes the builder() method to instantiate the builder class, treats the builder as a JavaBean and maps the Config subtree to it, invokes the builder&#8217;s build() method to create the new instance of the target class. You can augment the target class with the public static builder() method: <markup lang=\"java\" title=\"JavaBean for app properties, via a Builder \" >public class AppConfig { private String greeting; private int pageSize; private List&lt;Integer&gt; basicRange; private AppConfig(String greeting, int pageSize, List&lt;Integer&gt; basicRange) { this.greeting = greeting; this.pageSize = pageSize; this.basicRange = basicRange; } public String getGreeting() { return greeting; } public int getPageSize() { return pageSize; } public List&lt;Integer&gt; getBasicRange() { return basicRange; } public static Builder builder() { return new Builder(); } public static class Builder { private String greeting; private int pageSize; private List&lt;Integer&gt; basicRange; private Builder() { } public void setGreeting(String greeting) { this.greeting = greeting; } @Value(key = \"page-size\", withDefault = \"10\") public void setPageSize(int pageSize) { this.pageSize = pageSize; } @Value(key = \"basic-range\", withDefaultSupplier = BasicRangeSupplier.class) public void setBasicRange(List&lt;Integer&gt; basicRange) { this.basicRange = basicRange; } public AppConfig build() { return new AppConfig(greeting, pageSize, basicRange); } } } The target class&#8217;s constructor can be private in this case because new instances are created from the inner class Builder which has access to `AppConfig&#8217;s private members. The target class contains public static method builder() which returns an object that itself exposes the method AppConfig build() , so the config system recognizes it. The config system treats the AppConfig.Builder (not the enclosing target class) as a JavaBean. The builder&#8217;s property greeting is not customized and is set from config node with greeting key, if one exists. The builder&#8217;s property pageSize maps to the config key page-size and defaults to 10 if absent. The builder&#8217;s property basicRange maps to the config key basic-range and uses a BasicRangeSupplier instance to get a default value if needed. Finally, the config system invokes the builder&#8217;s public method build() , creating the new instance of AppConfig for use by the application. ",
            "title": "Builder as JavaBean"
        },
        {
            "location": "se/config/property-mapping",
            "text": " Another option is to annotate the parameters to a factory method or to a constructor on the target class. You can add a factory method to the target class, a public static method from with parameters annotated to link them to the corresponding config keys. Or you can add or modify a constructor with parameters, similarly annotated to form the link from each parameter to the corresponding config key. Warning Be sure to annotate each parameter of the from method or constructor with @Value and specify the key to use for the mapping. The parameter names in the Java code are not always available at runtime to map to config keys. (They might be arg0 , arg1 , etc.) <markup lang=\"java\" title=\"Target Class with Factory Method from \" >public class AppConfig { private final String greeting; private final int pageSize; private final List&lt;Integer&gt; basicRange; private AppConfig(String greeting, int pageSize, List&lt;Integer&gt; basicRange) { this.greeting = greeting; this.pageSize = pageSize; this.basicRange = basicRange; } public String getGreeting() { return greeting; } public int getPageSize() { return pageSize; } public List&lt;Integer&gt; getBasicRange() { return basicRange; } public static AppConfig from( @Value(key = \"greeting\") String greeting, @Value(key = \"page-size\", withDefault = \"10\") int pageSize, @Value(key = \"basic-range\", withDefaultSupplier = BasicRangeSupplier.class) List&lt;Integer&gt; basicRange) { return new AppConfig(greeting, pageSize, basicRange); } } The target class constructor can be private because the factory method on the same class has access to it. The config system invokes the factory method from(&#8230;&#8203;) , passing arguments it has fetched from the correspondingly-named config subtrees. The factory method returns the new initialized AppConfig instance. Note the consistent use of @Value(key = \"&#8230;&#8203;\") on each parameter. Because the property greeting does not specify a default value the property is mandatory and must appear in the configuration source. Otherwise, the config system throws a ConfigMappingException . Alternatively, you can use an annotated constructor instead of a static factory method. Revising the example above, make the constructor public, annotate its parameters, and remove the now-unneeded from factory method. <markup lang=\"java\" title=\"Target Class with Annotated Public Constructor\" >public class AppConfig { public AppConfig( @Value(key = \"greeting\") String greeting, @Value(key = \"page-size\", withDefault = \"10\") int pageSize, @Value(key = \"basic-range\", withDefaultSupplier = BasicRangeSupplier.class) List&lt;Integer&gt; basicRange) { this.greeting = greeting; this.pageSize = pageSize; this.basicRange = basicRange; } } Constructor is public . Each parameter has the ConfigValue annotation to at least specify the config key name. When the application invokes config.as(AppConfig.class) , the config system locates the public annotated constructor and invokes it, passing as arguments the data it fetches from the configuration matching the annotation key names with the configuration keys. ",
            "title": "Target Class with Annotated Factory Method or Constructor"
        },
        {
            "location": "se/config/property-mapping",
            "text": " The config system can also interpret your classes as JavaBeans and use the normal bean naming conventions to map configuration data to your POJO classes, using one of these patterns: POJO as JavaBean - The config system treats the target class itself as a JavaBean, assigning values from the config to the bean properties of the POJO class. builder as JavaBean - The config system invokes the POJO&#8217;s builder() method to obtain a builder for that POJO type and treats the builder class as a JavaBean, assigning values from the config to the builder&#8217;s bean properties and then invoking the builder&#8217;s build method to create an instance of the target POJO class. POJO with factory method or decorated constructor - The config system finds a from method or a constructor on the POJO class itself which accepts annotated arguments, then invokes that method or constructor passing the specified arguments based on the config. The from method returns an instance of the POJO class initialized with the values passed as arguments. The following sections describe these patterns in more detail. This feature is available in Object mapping module, and is added through Java ServiceLoader mechanism. This is no longer part of core Config module, as it depends on reflection. <markup lang=\"xml\" title=\"Config object mapping Dependency in pom.xml \" >&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.config&lt;/groupId&gt; &lt;artifactId&gt;helidon-config-object-mapping&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; POJO as JavaBean If your POJO target class is already a JavaBean&#8201;&#8212;&#8201;or you can modify it to become one&#8201;&#8212;&#8201;you might be able to avoid writing any explicit mapping code yourself. The config system invokes the no-args constructor on the target class to create a new instance. It treats each public setter method and each public non-final field as a JavaBean property. The config system processes any non-primitive property recursively as a JavaBean. In this way the config system builds up the target object from the config data. By default, the system matches potential JavaBean property names with config keys in the configuration. Use the Value annotation to control some of JavaBean processing for a given property. Value Annotation Attribute Usage key Indicates which config key should match this JavaBean property withDefault String used for the bean property default value if none is set in the config withDefaultSupplier Supplier of the default bean property value if not is set in the config To exclude a bean property from the config system bean processing annotate it with Config.Transient . Here is an example using the app portion of the example configuration from the introduction. <markup lang=\"java\" title=\"Java bean to load app properties into via setters\" >public class AppConfig { private Instant timestamp; private String greeting; private int pageSize; private List&lt;Integer&gt; basicRange; public AppConfig() { } public void setGreeting(String greeting) { this.greeting = greeting; } public String getGreeting() { return greeting; } @Value(key = \"page-size\", withDefault = \"10\") public void setPageSize(int pageSize) { this.pageSize = pageSize; } public int getPageSize() { return pageSize; } @Value(key = \"basic-range\", withDefaultSupplier = BasicRangeSupplier.class) public void setBasicRange(List&lt;Integer&gt; basicRange) { this.basicRange = basicRange; } public List&lt;Integer&gt; getBasicRange() { return basicRange; } @Config.Transient public void setTimestamp(Instant timestamp) { this.timestamp = timestamp; } public Instant getTimestamp() { return timestamp; } public static class BasicRangeSupplier implements Supplier&lt;List&lt;Integer&gt;&gt; { @Override public List&lt;Integer&gt; get() { return List.of(-10, 10); } } } Public no-parameter constructor. Property greeting is not customized and will be set from the config node with the key greeting , if present in the config. Property pageSize is matched to the config key page-size . If the page-size config node does not exist, the pageSize bean property defaults to 10 . Property basicRange is matched to the config key basic-range . If the basic-range config node does not exist, a BasicRangeSupplier instance will provide the default value. The timestamp bean property is never set, even if the config contains a node with the key timestamp . BasicRangeSupplier is used to supply the List&lt;Integer&gt; default value. Here is an example of code loading config and mapping part of it to the AppConfig bean above. <markup lang=\"java\" title=\"Map app config node into AppConfig class\" >Config config = Config.create(classpath(\"application.conf\")); AppConfig app = config.get(\"app\") .as(AppConfig.class) .get(); //assert that all values are loaded from file assert app.getGreeting().equals(\"Hello\"); assert app.getPageSize() == 20; assert app.getBasicRange().size() == 2 &amp;&amp; app.getBasicRange().get(0) == -20 &amp;&amp; app.getBasicRange().get(1) == 20; //assert that Transient property is not set assert app.getTimestamp() == null; The config system finds no registered ConfigMapper for AppConfig and so applies the JavaBean pattern to convert the config to an AppConfig instance. Because the bean property timestamp was marked as transient, the config system did not set it. Builder as JavaBean If the target class includes the public static method builder() that returns any object, then the config system will make sure that the return type has a method build() which returns an instance of the target class. If so, the config system treats the builder as a JavaBean and invokes the builder() method to instantiate the builder class, treats the builder as a JavaBean and maps the Config subtree to it, invokes the builder&#8217;s build() method to create the new instance of the target class. You can augment the target class with the public static builder() method: <markup lang=\"java\" title=\"JavaBean for app properties, via a Builder \" >public class AppConfig { private String greeting; private int pageSize; private List&lt;Integer&gt; basicRange; private AppConfig(String greeting, int pageSize, List&lt;Integer&gt; basicRange) { this.greeting = greeting; this.pageSize = pageSize; this.basicRange = basicRange; } public String getGreeting() { return greeting; } public int getPageSize() { return pageSize; } public List&lt;Integer&gt; getBasicRange() { return basicRange; } public static Builder builder() { return new Builder(); } public static class Builder { private String greeting; private int pageSize; private List&lt;Integer&gt; basicRange; private Builder() { } public void setGreeting(String greeting) { this.greeting = greeting; } @Value(key = \"page-size\", withDefault = \"10\") public void setPageSize(int pageSize) { this.pageSize = pageSize; } @Value(key = \"basic-range\", withDefaultSupplier = BasicRangeSupplier.class) public void setBasicRange(List&lt;Integer&gt; basicRange) { this.basicRange = basicRange; } public AppConfig build() { return new AppConfig(greeting, pageSize, basicRange); } } } The target class&#8217;s constructor can be private in this case because new instances are created from the inner class Builder which has access to `AppConfig&#8217;s private members. The target class contains public static method builder() which returns an object that itself exposes the method AppConfig build() , so the config system recognizes it. The config system treats the AppConfig.Builder (not the enclosing target class) as a JavaBean. The builder&#8217;s property greeting is not customized and is set from config node with greeting key, if one exists. The builder&#8217;s property pageSize maps to the config key page-size and defaults to 10 if absent. The builder&#8217;s property basicRange maps to the config key basic-range and uses a BasicRangeSupplier instance to get a default value if needed. Finally, the config system invokes the builder&#8217;s public method build() , creating the new instance of AppConfig for use by the application. Target Class with Annotated Factory Method or Constructor Another option is to annotate the parameters to a factory method or to a constructor on the target class. You can add a factory method to the target class, a public static method from with parameters annotated to link them to the corresponding config keys. Or you can add or modify a constructor with parameters, similarly annotated to form the link from each parameter to the corresponding config key. Warning Be sure to annotate each parameter of the from method or constructor with @Value and specify the key to use for the mapping. The parameter names in the Java code are not always available at runtime to map to config keys. (They might be arg0 , arg1 , etc.) <markup lang=\"java\" title=\"Target Class with Factory Method from \" >public class AppConfig { private final String greeting; private final int pageSize; private final List&lt;Integer&gt; basicRange; private AppConfig(String greeting, int pageSize, List&lt;Integer&gt; basicRange) { this.greeting = greeting; this.pageSize = pageSize; this.basicRange = basicRange; } public String getGreeting() { return greeting; } public int getPageSize() { return pageSize; } public List&lt;Integer&gt; getBasicRange() { return basicRange; } public static AppConfig from( @Value(key = \"greeting\") String greeting, @Value(key = \"page-size\", withDefault = \"10\") int pageSize, @Value(key = \"basic-range\", withDefaultSupplier = BasicRangeSupplier.class) List&lt;Integer&gt; basicRange) { return new AppConfig(greeting, pageSize, basicRange); } } The target class constructor can be private because the factory method on the same class has access to it. The config system invokes the factory method from(&#8230;&#8203;) , passing arguments it has fetched from the correspondingly-named config subtrees. The factory method returns the new initialized AppConfig instance. Note the consistent use of @Value(key = \"&#8230;&#8203;\") on each parameter. Because the property greeting does not specify a default value the property is mandatory and must appear in the configuration source. Otherwise, the config system throws a ConfigMappingException . Alternatively, you can use an annotated constructor instead of a static factory method. Revising the example above, make the constructor public, annotate its parameters, and remove the now-unneeded from factory method. <markup lang=\"java\" title=\"Target Class with Annotated Public Constructor\" >public class AppConfig { public AppConfig( @Value(key = \"greeting\") String greeting, @Value(key = \"page-size\", withDefault = \"10\") int pageSize, @Value(key = \"basic-range\", withDefaultSupplier = BasicRangeSupplier.class) List&lt;Integer&gt; basicRange) { this.greeting = greeting; this.pageSize = pageSize; this.basicRange = basicRange; } } Constructor is public . Each parameter has the ConfigValue annotation to at least specify the config key name. When the application invokes config.as(AppConfig.class) , the config system locates the public annotated constructor and invokes it, passing as arguments the data it fetches from the configuration matching the annotation key names with the configuration keys. ",
            "title": "Conversions using JavaBean Deserialization"
        },
        {
            "location": "se/config/supported-formats",
            "text": " Overview Additional Config Formats and Parsers Additional Config Source Types ",
            "title": "Contents"
        },
        {
            "location": "se/config/supported-formats",
            "text": " Helidon Config provides several extension modules that support other configuration formats (parsers) and sources. This document describes how to include them and use them in your project. In each case you need to add module dependencies to your project and, in some cases, write your application accordingly. ",
            "title": "Overview"
        },
        {
            "location": "se/config/supported-formats",
            "text": " With each of the parsers described here, your application can either explicitly add a parser of the correct implementation to the Config.Builder , or rely on Java service loading and the config system&#8217;s matching of file types and media types to parsers. If your application creates a Config.Builder with parser services disabled (see disableParserServices then that builder will not find the Java services for the various parsers and so will be unable to match the file type or media type of sources with the corresponding parser automatically. So if you want to use automatic type matching with a given builder, do not invoke Config.Builder.disableParserServices() . ",
            "title": "Automatic Media Type and File Type Handling"
        },
        {
            "location": "se/config/supported-formats",
            "text": " Add the following dependency in your project: <markup lang=\"xml\" title=\"Config YAML Dependency in pom.xml \" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.config&lt;/groupId&gt; &lt;artifactId&gt;helidon-config-yaml&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"java\" title=\"Config YAML Dependency in module-info.java \" >module myModule { requires io.helidon.config.yaml; } ",
            "title": "Maven Coordinates"
        },
        {
            "location": "se/config/supported-formats",
            "text": " The YAML parser handles the following media type: application/x-yaml - YAML format (file type .yaml ) <markup lang=\"java\" title=\"Automatic selection\" >Config config = Config.create(classpath(\"application.yaml\")); The config system automatically maps the file type .yaml to the media type application/x-yaml which the Helidon YAML parser matches. <markup lang=\"java\" title=\"YAML parser specified - no file type on source\" >Config config = Config.create(classpath(\"my-config\") .parser(YamlConfigParserBuilder.buildDefault())); The media type of the source my-config is unknown, so the config system cannot choose a parser automatically. The config system will parse the resource my-config on the runtime classpath using the YAML parser instance created by the YamlConfigParserBuilder . The buildDefault() method creates a config parser with default behavior. <markup lang=\"java\" title=\"Media type specified\" >Config config = Config.create(classpath(\"my-config\") .mediaType(\"application/x-yaml\")); The media type of the source my-config is unknown, so the config system cannot choose a parser automatically. Specifying the media type for the config source allows the config system to use its matching algorithm with the available parsers to choose a parser for that type. <markup lang=\"java\" title=\"YAML parser specified because parser services disabled\" >Config config = Config.builder(classpath(\"application.yaml\")) .disableParserServices() .addParser(YamlConfigParserBuilder.buildDefault()) .build(); Disables automatic parser lookup and registration. Explicit registration of the YAML parser is therefore required. ",
            "title": "Using the YAML Parser"
        },
        {
            "location": "se/config/supported-formats",
            "text": " Maven Coordinates Add the following dependency in your project: <markup lang=\"xml\" title=\"Config YAML Dependency in pom.xml \" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.config&lt;/groupId&gt; &lt;artifactId&gt;helidon-config-yaml&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"java\" title=\"Config YAML Dependency in module-info.java \" >module myModule { requires io.helidon.config.yaml; } Using the YAML Parser The YAML parser handles the following media type: application/x-yaml - YAML format (file type .yaml ) <markup lang=\"java\" title=\"Automatic selection\" >Config config = Config.create(classpath(\"application.yaml\")); The config system automatically maps the file type .yaml to the media type application/x-yaml which the Helidon YAML parser matches. <markup lang=\"java\" title=\"YAML parser specified - no file type on source\" >Config config = Config.create(classpath(\"my-config\") .parser(YamlConfigParserBuilder.buildDefault())); The media type of the source my-config is unknown, so the config system cannot choose a parser automatically. The config system will parse the resource my-config on the runtime classpath using the YAML parser instance created by the YamlConfigParserBuilder . The buildDefault() method creates a config parser with default behavior. <markup lang=\"java\" title=\"Media type specified\" >Config config = Config.create(classpath(\"my-config\") .mediaType(\"application/x-yaml\")); The media type of the source my-config is unknown, so the config system cannot choose a parser automatically. Specifying the media type for the config source allows the config system to use its matching algorithm with the available parsers to choose a parser for that type. <markup lang=\"java\" title=\"YAML parser specified because parser services disabled\" >Config config = Config.builder(classpath(\"application.yaml\")) .disableParserServices() .addParser(YamlConfigParserBuilder.buildDefault()) .build(); Disables automatic parser lookup and registration. Explicit registration of the YAML parser is therefore required. ",
            "title": "YAML"
        },
        {
            "location": "se/config/supported-formats",
            "text": " Add the following dependency in your project: <markup lang=\"xml\" title=\"Config HOCON Dependency in pom.xml \" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.config&lt;/groupId&gt; &lt;artifactId&gt;helidon-config-hocon&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"java\" title=\"Config HOCON Dependency in module-info.java \" >module myModule { requires io.helidon.config.hocon; } ",
            "title": "Maven Coordinates"
        },
        {
            "location": "se/config/supported-formats",
            "text": " The parser handles the following media types: application/hocon - HOCON format (file type .conf ) application/json - JSON format (file type .json ) <markup lang=\"java\" title=\"Automatic selection\" >Config config = Config.create(classpath(\"application.conf\")); The config system automatically maps the file type .conf to the media type `application/hocon which the Helidon HOCON parser matches. The same module and parser supports file type .json and the media type application/json . <markup lang=\"java\" title=\"HOCON parser specified - no file type on source\" >Config config = Config.create(classpath(\"my-config\") .parser(HoconConfigParserBuilder.buildDefault())); the media type of the source `my-config`is unknown, so the config system cannot choose a parser automatically. The config system will parse the resource my-config using the HOCON parser created by the HoconConfigParserBuilder . The buildDefault() method creates a config parser with default behavior. <markup lang=\"java\" title=\"Media type specified\" >Config config = Config.create(classpath(\"my-config\") .mediaType(\"application/hocon\")); The media type of the source my-config is unknown, so the config system cannot choose a parser automatically. Specifying the media type for the config source allows the config system to use its matching algorithm with the available parsers to choose a parser for that type. <markup lang=\"java\" title=\"HOCON parser specified because parser services disabled\" >Config config = Config.builder(classpath(\"application.conf\")) .disableParserServices() .addParser(HoconConfigParserBuilder.buildDefault()) .build(); Disables automatic parser lookup and registration. Explicit registration of the HOCON parser is therefore required. <markup lang=\"java\" title=\"Customized HOCON parser\" >Config config = Config.builder(classpath(\"application.conf\")) .disableParserServices() .addParser(HoconConfigParserBuilder.create() .disableResolving() .build()) .build(); Creates new instance of the parser builder. Disables resolution of substitutions. (See the HOCON documentation .) Builds a new instance of the HOCON config parser. You can also specify ConfigResolveOptions using the HoconConfigParserBuilder.resolveOptions method. ",
            "title": "Using the HOCON/JSON Parser"
        },
        {
            "location": "se/config/supported-formats",
            "text": " The Helidon HOCON config module handles sources in the HOCON and JSON formats. Maven Coordinates Add the following dependency in your project: <markup lang=\"xml\" title=\"Config HOCON Dependency in pom.xml \" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.config&lt;/groupId&gt; &lt;artifactId&gt;helidon-config-hocon&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"java\" title=\"Config HOCON Dependency in module-info.java \" >module myModule { requires io.helidon.config.hocon; } Using the HOCON/JSON Parser The parser handles the following media types: application/hocon - HOCON format (file type .conf ) application/json - JSON format (file type .json ) <markup lang=\"java\" title=\"Automatic selection\" >Config config = Config.create(classpath(\"application.conf\")); The config system automatically maps the file type .conf to the media type `application/hocon which the Helidon HOCON parser matches. The same module and parser supports file type .json and the media type application/json . <markup lang=\"java\" title=\"HOCON parser specified - no file type on source\" >Config config = Config.create(classpath(\"my-config\") .parser(HoconConfigParserBuilder.buildDefault())); the media type of the source `my-config`is unknown, so the config system cannot choose a parser automatically. The config system will parse the resource my-config using the HOCON parser created by the HoconConfigParserBuilder . The buildDefault() method creates a config parser with default behavior. <markup lang=\"java\" title=\"Media type specified\" >Config config = Config.create(classpath(\"my-config\") .mediaType(\"application/hocon\")); The media type of the source my-config is unknown, so the config system cannot choose a parser automatically. Specifying the media type for the config source allows the config system to use its matching algorithm with the available parsers to choose a parser for that type. <markup lang=\"java\" title=\"HOCON parser specified because parser services disabled\" >Config config = Config.builder(classpath(\"application.conf\")) .disableParserServices() .addParser(HoconConfigParserBuilder.buildDefault()) .build(); Disables automatic parser lookup and registration. Explicit registration of the HOCON parser is therefore required. <markup lang=\"java\" title=\"Customized HOCON parser\" >Config config = Config.builder(classpath(\"application.conf\")) .disableParserServices() .addParser(HoconConfigParserBuilder.create() .disableResolving() .build()) .build(); Creates new instance of the parser builder. Disables resolution of substitutions. (See the HOCON documentation .) Builds a new instance of the HOCON config parser. You can also specify ConfigResolveOptions using the HoconConfigParserBuilder.resolveOptions method. ",
            "title": "HOCON/JSON"
        },
        {
            "location": "se/config/supported-formats",
            "text": " Automatic Media Type and File Type Handling With each of the parsers described here, your application can either explicitly add a parser of the correct implementation to the Config.Builder , or rely on Java service loading and the config system&#8217;s matching of file types and media types to parsers. If your application creates a Config.Builder with parser services disabled (see disableParserServices then that builder will not find the Java services for the various parsers and so will be unable to match the file type or media type of sources with the corresponding parser automatically. So if you want to use automatic type matching with a given builder, do not invoke Config.Builder.disableParserServices() . YAML Maven Coordinates Add the following dependency in your project: <markup lang=\"xml\" title=\"Config YAML Dependency in pom.xml \" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.config&lt;/groupId&gt; &lt;artifactId&gt;helidon-config-yaml&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"java\" title=\"Config YAML Dependency in module-info.java \" >module myModule { requires io.helidon.config.yaml; } Using the YAML Parser The YAML parser handles the following media type: application/x-yaml - YAML format (file type .yaml ) <markup lang=\"java\" title=\"Automatic selection\" >Config config = Config.create(classpath(\"application.yaml\")); The config system automatically maps the file type .yaml to the media type application/x-yaml which the Helidon YAML parser matches. <markup lang=\"java\" title=\"YAML parser specified - no file type on source\" >Config config = Config.create(classpath(\"my-config\") .parser(YamlConfigParserBuilder.buildDefault())); The media type of the source my-config is unknown, so the config system cannot choose a parser automatically. The config system will parse the resource my-config on the runtime classpath using the YAML parser instance created by the YamlConfigParserBuilder . The buildDefault() method creates a config parser with default behavior. <markup lang=\"java\" title=\"Media type specified\" >Config config = Config.create(classpath(\"my-config\") .mediaType(\"application/x-yaml\")); The media type of the source my-config is unknown, so the config system cannot choose a parser automatically. Specifying the media type for the config source allows the config system to use its matching algorithm with the available parsers to choose a parser for that type. <markup lang=\"java\" title=\"YAML parser specified because parser services disabled\" >Config config = Config.builder(classpath(\"application.yaml\")) .disableParserServices() .addParser(YamlConfigParserBuilder.buildDefault()) .build(); Disables automatic parser lookup and registration. Explicit registration of the YAML parser is therefore required. HOCON/JSON The Helidon HOCON config module handles sources in the HOCON and JSON formats. Maven Coordinates Add the following dependency in your project: <markup lang=\"xml\" title=\"Config HOCON Dependency in pom.xml \" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.config&lt;/groupId&gt; &lt;artifactId&gt;helidon-config-hocon&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"java\" title=\"Config HOCON Dependency in module-info.java \" >module myModule { requires io.helidon.config.hocon; } Using the HOCON/JSON Parser The parser handles the following media types: application/hocon - HOCON format (file type .conf ) application/json - JSON format (file type .json ) <markup lang=\"java\" title=\"Automatic selection\" >Config config = Config.create(classpath(\"application.conf\")); The config system automatically maps the file type .conf to the media type `application/hocon which the Helidon HOCON parser matches. The same module and parser supports file type .json and the media type application/json . <markup lang=\"java\" title=\"HOCON parser specified - no file type on source\" >Config config = Config.create(classpath(\"my-config\") .parser(HoconConfigParserBuilder.buildDefault())); the media type of the source `my-config`is unknown, so the config system cannot choose a parser automatically. The config system will parse the resource my-config using the HOCON parser created by the HoconConfigParserBuilder . The buildDefault() method creates a config parser with default behavior. <markup lang=\"java\" title=\"Media type specified\" >Config config = Config.create(classpath(\"my-config\") .mediaType(\"application/hocon\")); The media type of the source my-config is unknown, so the config system cannot choose a parser automatically. Specifying the media type for the config source allows the config system to use its matching algorithm with the available parsers to choose a parser for that type. <markup lang=\"java\" title=\"HOCON parser specified because parser services disabled\" >Config config = Config.builder(classpath(\"application.conf\")) .disableParserServices() .addParser(HoconConfigParserBuilder.buildDefault()) .build(); Disables automatic parser lookup and registration. Explicit registration of the HOCON parser is therefore required. <markup lang=\"java\" title=\"Customized HOCON parser\" >Config config = Config.builder(classpath(\"application.conf\")) .disableParserServices() .addParser(HoconConfigParserBuilder.create() .disableResolving() .build()) .build(); Creates new instance of the parser builder. Disables resolution of substitutions. (See the HOCON documentation .) Builds a new instance of the HOCON config parser. You can also specify ConfigResolveOptions using the HoconConfigParserBuilder.resolveOptions method. ",
            "title": "Additional Config Formats and Parsers"
        },
        {
            "location": "se/config/supported-formats",
            "text": " Add the following dependency to your project: <markup lang=\"xml\" title=\"Config Etcd Dependency in pom.xml \" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.config&lt;/groupId&gt; &lt;artifactId&gt;helidon-config-etcd&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"java\" title=\"Config Etcd Dependency in module-info.java \" >module myModule { requires io.helidon.config.etcd; } ",
            "title": "Maven Coordinates"
        },
        {
            "location": "se/config/supported-formats",
            "text": " To read configuration from an Etcd source, your application uses the EtcdConfigSourceBuilder . <markup lang=\"java\" title=\"Use Etcd config source\" >Config config = Config.create( EtcdConfigSourceBuilder .create(URI.create(\"http://my-etcd:2379\"), \"/config.yaml\", EtcdConfigSourceBuilder.EtcdApi.v3)); Use the factory method EtcdConfigSourceBuilder.create to initialize the builder. Specify the Etcd endpoint address. Specify the Etcd key of the configuration document. Version of the Etcd API to use; v2 and v3 are supported. The config system will use the YAML parser automatically in this example because the file type of the key is .yaml . The EtcdConfigSourceBuilder class extends AbstractParsableConfigSource.Builder and so supports the usual settings on config sources. ",
            "title": "Using the Etcd Config Source"
        },
        {
            "location": "se/config/supported-formats",
            "text": " The Etcd support includes a polling strategy designed for an etcd config source. <markup lang=\"java\" title=\"Use Etcd config source\" >Config config = Config.create( EtcdConfigSourceBuilder .create(URI.create(\"http://my-etcd:2379\"), \"/config.yaml\", EtcdApi.v3) .pollingStrategy(EtcdWatchPollingStrategy::new)); Use the etcd-specific polling strategy. ",
            "title": "Monitoring for Source Changes"
        },
        {
            "location": "se/config/supported-formats",
            "text": " The config system can load information about config sources from meta-configuration rather than requiring your application to construct the builder. To read meta-configuration from an Etcd source set the following required properties for the source: type to etcd , or class to io.helidon.config.etcd.EtcdConfigSourceBuilder uri (type URI ) - Etcd endpoint URI. key (type String ) - Etcd key that is associated with the configuration. api (type EtcdConfigSourceBuilder.EtcdApi , i.e. v2 or v3 ) - Etcd API version. Other optional properties are inherited from AbstractParsableConfigSource.Builder . (see javadoc ) <markup lang=\"java\" title=\"Load Config from meta-configuration\" >Config config = Config.loadSourcesFrom(classpath(\"config-meta-etcd.yaml\")); <markup lang=\"YAML\" title=\"Meta-config config-meta-etcd.yaml for the etcd source\" >sources: - type: \"etcd\" properties: uri: \"http://my-etcd:2379\" key: \"/config.yaml\" api: \"v3\" polling-strategy: class: \"io.helidon.config.etcd.EtcdWatchPollingStrategy\" etcd config source type Etcd source-specific (mandatory) properties : uri , key and api . Polling strategy EtcdWatchPollingStrategy is automatically initialized by specified mandatory properties . ",
            "title": "Loading Meta-configuration via Etcd"
        },
        {
            "location": "se/config/supported-formats",
            "text": " The Helidon Etcd config module supports reading configuration from a specified Etcd key. Maven Coordinates Add the following dependency to your project: <markup lang=\"xml\" title=\"Config Etcd Dependency in pom.xml \" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.config&lt;/groupId&gt; &lt;artifactId&gt;helidon-config-etcd&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"java\" title=\"Config Etcd Dependency in module-info.java \" >module myModule { requires io.helidon.config.etcd; } Using the Etcd Config Source To read configuration from an Etcd source, your application uses the EtcdConfigSourceBuilder . <markup lang=\"java\" title=\"Use Etcd config source\" >Config config = Config.create( EtcdConfigSourceBuilder .create(URI.create(\"http://my-etcd:2379\"), \"/config.yaml\", EtcdConfigSourceBuilder.EtcdApi.v3)); Use the factory method EtcdConfigSourceBuilder.create to initialize the builder. Specify the Etcd endpoint address. Specify the Etcd key of the configuration document. Version of the Etcd API to use; v2 and v3 are supported. The config system will use the YAML parser automatically in this example because the file type of the key is .yaml . The EtcdConfigSourceBuilder class extends AbstractParsableConfigSource.Builder and so supports the usual settings on config sources. Monitoring for Source Changes The Etcd support includes a polling strategy designed for an etcd config source. <markup lang=\"java\" title=\"Use Etcd config source\" >Config config = Config.create( EtcdConfigSourceBuilder .create(URI.create(\"http://my-etcd:2379\"), \"/config.yaml\", EtcdApi.v3) .pollingStrategy(EtcdWatchPollingStrategy::new)); Use the etcd-specific polling strategy. Loading Meta-configuration via Etcd The config system can load information about config sources from meta-configuration rather than requiring your application to construct the builder. To read meta-configuration from an Etcd source set the following required properties for the source: type to etcd , or class to io.helidon.config.etcd.EtcdConfigSourceBuilder uri (type URI ) - Etcd endpoint URI. key (type String ) - Etcd key that is associated with the configuration. api (type EtcdConfigSourceBuilder.EtcdApi , i.e. v2 or v3 ) - Etcd API version. Other optional properties are inherited from AbstractParsableConfigSource.Builder . (see javadoc ) <markup lang=\"java\" title=\"Load Config from meta-configuration\" >Config config = Config.loadSourcesFrom(classpath(\"config-meta-etcd.yaml\")); <markup lang=\"YAML\" title=\"Meta-config config-meta-etcd.yaml for the etcd source\" >sources: - type: \"etcd\" properties: uri: \"http://my-etcd:2379\" key: \"/config.yaml\" api: \"v3\" polling-strategy: class: \"io.helidon.config.etcd.EtcdWatchPollingStrategy\" etcd config source type Etcd source-specific (mandatory) properties : uri , key and api . Polling strategy EtcdWatchPollingStrategy is automatically initialized by specified mandatory properties . ",
            "title": "Etcd"
        },
        {
            "location": "se/config/supported-formats",
            "text": " Add the following dependency to your project: <markup lang=\"xml\" title=\"Config git Dependency in pom.xml \" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.config&lt;/groupId&gt; &lt;artifactId&gt;helidon-config-git&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"java\" title=\"Config git Dependency in module-info.java \" >module myModule { requires io.helidon.config.git; } ",
            "title": "Maven Coordinates"
        },
        {
            "location": "se/config/supported-formats",
            "text": " To read configuration from a git source, your application uses the GitConfigSourceBuilder . <markup lang=\"java\" title=\"Use git config source\" >Config config = Config.create( GitConfigSourceBuilder .create(\"application.conf\") .uri(URI.create(\"https://github.com/okosatka/test-config.git\")) .directory(Paths.get(\"/config\")) .branch(\"dev\")); Use the factory method GitConfigSourceBuilder.create to initialize the builder with a mandatory path to the configuration file. Specify the git repository URI. Specify a directory where the git repository is already cloned or it will be cloned. Specify the git branch. Note that the config system will use the HOCON parser in this example because the file type is .conf . Recall that for this to work the HOCON config module must be on module-path or classpath. The GitConfigSourceBuilder supports the usual source builder properties because it extends AbstractParsableConfigSource.Builder . ",
            "title": "Using the git Config Source"
        },
        {
            "location": "se/config/supported-formats",
            "text": " Your application can monitor changes to a configuration loaded from a git source associating the regular built-in polling strategy with the source. <markup lang=\"java\" title=\"Use of git config source with polling strategy\" >Config config = Config.create( GitConfigSourceBuilder .create(\"application.conf\") .uri(URI.create(\"https://github.com/okosatka/test-config.git\")) .pollingStrategy(PollingStrategies.regular(Duration.ofMinutes(5)))); Use PollingStrategies.regular(Duration duration) to monitor for config changes. You can also implement your own polling strategy by implementing PollingStrategy . See the mutability support and polling strategy discussions. ",
            "title": "Monitoring for Source Changes"
        },
        {
            "location": "se/config/supported-formats",
            "text": " The config system can load information about config sources from meta-configuration rather than requiring your application to construct the builder. To read meta-configuration from a git config source set the following properties for the source: type to git or class to io.helidon.config.git.GitConfigSourceBuilder path (type String ) - Relative path to the configuration file in repository. uri (type URI ) - URI to the git repository. directory (type Path ) - Directory with a cloned repository, by default a temporary directory. branch (type String ) - git branch (default is master ). The meta-configuration must set the path and one of uri or directory . Other optional properties are inherited from AbstractParsableConfigSource.Builder (see javadoc ) <markup lang=\"java\" title=\"Load Config from meta-configuration\" >Config config = Config.loadSourcesFrom(classpath(\"config-meta-git.yaml\")); <markup lang=\"YAML\" title=\"Meta-config config-meta-git.yaml for the git source\" >sources: - type: \"git\" properties: path: \"application.conf\" uri: \"https://github.com/okosatka/test-config.git\" directory: \"/config\" branch: \"dev\" polling-strategy: type: \"regular\" properties: interval: \"PT5M\" git config source type git source-specific properties: path , uri , directory and branch . Polling strategy regular with an interval, in Duration format, of 5 minutes in this example. ",
            "title": "Loading Meta-configuration via git"
        },
        {
            "location": "se/config/supported-formats",
            "text": " The Helidon git config module supports reading configuration from a git repository. Maven Coordinates Add the following dependency to your project: <markup lang=\"xml\" title=\"Config git Dependency in pom.xml \" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.config&lt;/groupId&gt; &lt;artifactId&gt;helidon-config-git&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"java\" title=\"Config git Dependency in module-info.java \" >module myModule { requires io.helidon.config.git; } Using the git Config Source To read configuration from a git source, your application uses the GitConfigSourceBuilder . <markup lang=\"java\" title=\"Use git config source\" >Config config = Config.create( GitConfigSourceBuilder .create(\"application.conf\") .uri(URI.create(\"https://github.com/okosatka/test-config.git\")) .directory(Paths.get(\"/config\")) .branch(\"dev\")); Use the factory method GitConfigSourceBuilder.create to initialize the builder with a mandatory path to the configuration file. Specify the git repository URI. Specify a directory where the git repository is already cloned or it will be cloned. Specify the git branch. Note that the config system will use the HOCON parser in this example because the file type is .conf . Recall that for this to work the HOCON config module must be on module-path or classpath. The GitConfigSourceBuilder supports the usual source builder properties because it extends AbstractParsableConfigSource.Builder . Monitoring for Source Changes Your application can monitor changes to a configuration loaded from a git source associating the regular built-in polling strategy with the source. <markup lang=\"java\" title=\"Use of git config source with polling strategy\" >Config config = Config.create( GitConfigSourceBuilder .create(\"application.conf\") .uri(URI.create(\"https://github.com/okosatka/test-config.git\")) .pollingStrategy(PollingStrategies.regular(Duration.ofMinutes(5)))); Use PollingStrategies.regular(Duration duration) to monitor for config changes. You can also implement your own polling strategy by implementing PollingStrategy . See the mutability support and polling strategy discussions. Loading Meta-configuration via git The config system can load information about config sources from meta-configuration rather than requiring your application to construct the builder. To read meta-configuration from a git config source set the following properties for the source: type to git or class to io.helidon.config.git.GitConfigSourceBuilder path (type String ) - Relative path to the configuration file in repository. uri (type URI ) - URI to the git repository. directory (type Path ) - Directory with a cloned repository, by default a temporary directory. branch (type String ) - git branch (default is master ). The meta-configuration must set the path and one of uri or directory . Other optional properties are inherited from AbstractParsableConfigSource.Builder (see javadoc ) <markup lang=\"java\" title=\"Load Config from meta-configuration\" >Config config = Config.loadSourcesFrom(classpath(\"config-meta-git.yaml\")); <markup lang=\"YAML\" title=\"Meta-config config-meta-git.yaml for the git source\" >sources: - type: \"git\" properties: path: \"application.conf\" uri: \"https://github.com/okosatka/test-config.git\" directory: \"/config\" branch: \"dev\" polling-strategy: type: \"regular\" properties: interval: \"PT5M\" git config source type git source-specific properties: path , uri , directory and branch . Polling strategy regular with an interval, in Duration format, of 5 minutes in this example. ",
            "title": "git"
        },
        {
            "location": "se/config/supported-formats",
            "text": " Etcd The Helidon Etcd config module supports reading configuration from a specified Etcd key. Maven Coordinates Add the following dependency to your project: <markup lang=\"xml\" title=\"Config Etcd Dependency in pom.xml \" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.config&lt;/groupId&gt; &lt;artifactId&gt;helidon-config-etcd&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"java\" title=\"Config Etcd Dependency in module-info.java \" >module myModule { requires io.helidon.config.etcd; } Using the Etcd Config Source To read configuration from an Etcd source, your application uses the EtcdConfigSourceBuilder . <markup lang=\"java\" title=\"Use Etcd config source\" >Config config = Config.create( EtcdConfigSourceBuilder .create(URI.create(\"http://my-etcd:2379\"), \"/config.yaml\", EtcdConfigSourceBuilder.EtcdApi.v3)); Use the factory method EtcdConfigSourceBuilder.create to initialize the builder. Specify the Etcd endpoint address. Specify the Etcd key of the configuration document. Version of the Etcd API to use; v2 and v3 are supported. The config system will use the YAML parser automatically in this example because the file type of the key is .yaml . The EtcdConfigSourceBuilder class extends AbstractParsableConfigSource.Builder and so supports the usual settings on config sources. Monitoring for Source Changes The Etcd support includes a polling strategy designed for an etcd config source. <markup lang=\"java\" title=\"Use Etcd config source\" >Config config = Config.create( EtcdConfigSourceBuilder .create(URI.create(\"http://my-etcd:2379\"), \"/config.yaml\", EtcdApi.v3) .pollingStrategy(EtcdWatchPollingStrategy::new)); Use the etcd-specific polling strategy. Loading Meta-configuration via Etcd The config system can load information about config sources from meta-configuration rather than requiring your application to construct the builder. To read meta-configuration from an Etcd source set the following required properties for the source: type to etcd , or class to io.helidon.config.etcd.EtcdConfigSourceBuilder uri (type URI ) - Etcd endpoint URI. key (type String ) - Etcd key that is associated with the configuration. api (type EtcdConfigSourceBuilder.EtcdApi , i.e. v2 or v3 ) - Etcd API version. Other optional properties are inherited from AbstractParsableConfigSource.Builder . (see javadoc ) <markup lang=\"java\" title=\"Load Config from meta-configuration\" >Config config = Config.loadSourcesFrom(classpath(\"config-meta-etcd.yaml\")); <markup lang=\"YAML\" title=\"Meta-config config-meta-etcd.yaml for the etcd source\" >sources: - type: \"etcd\" properties: uri: \"http://my-etcd:2379\" key: \"/config.yaml\" api: \"v3\" polling-strategy: class: \"io.helidon.config.etcd.EtcdWatchPollingStrategy\" etcd config source type Etcd source-specific (mandatory) properties : uri , key and api . Polling strategy EtcdWatchPollingStrategy is automatically initialized by specified mandatory properties . git The Helidon git config module supports reading configuration from a git repository. Maven Coordinates Add the following dependency to your project: <markup lang=\"xml\" title=\"Config git Dependency in pom.xml \" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.config&lt;/groupId&gt; &lt;artifactId&gt;helidon-config-git&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"java\" title=\"Config git Dependency in module-info.java \" >module myModule { requires io.helidon.config.git; } Using the git Config Source To read configuration from a git source, your application uses the GitConfigSourceBuilder . <markup lang=\"java\" title=\"Use git config source\" >Config config = Config.create( GitConfigSourceBuilder .create(\"application.conf\") .uri(URI.create(\"https://github.com/okosatka/test-config.git\")) .directory(Paths.get(\"/config\")) .branch(\"dev\")); Use the factory method GitConfigSourceBuilder.create to initialize the builder with a mandatory path to the configuration file. Specify the git repository URI. Specify a directory where the git repository is already cloned or it will be cloned. Specify the git branch. Note that the config system will use the HOCON parser in this example because the file type is .conf . Recall that for this to work the HOCON config module must be on module-path or classpath. The GitConfigSourceBuilder supports the usual source builder properties because it extends AbstractParsableConfigSource.Builder . Monitoring for Source Changes Your application can monitor changes to a configuration loaded from a git source associating the regular built-in polling strategy with the source. <markup lang=\"java\" title=\"Use of git config source with polling strategy\" >Config config = Config.create( GitConfigSourceBuilder .create(\"application.conf\") .uri(URI.create(\"https://github.com/okosatka/test-config.git\")) .pollingStrategy(PollingStrategies.regular(Duration.ofMinutes(5)))); Use PollingStrategies.regular(Duration duration) to monitor for config changes. You can also implement your own polling strategy by implementing PollingStrategy . See the mutability support and polling strategy discussions. Loading Meta-configuration via git The config system can load information about config sources from meta-configuration rather than requiring your application to construct the builder. To read meta-configuration from a git config source set the following properties for the source: type to git or class to io.helidon.config.git.GitConfigSourceBuilder path (type String ) - Relative path to the configuration file in repository. uri (type URI ) - URI to the git repository. directory (type Path ) - Directory with a cloned repository, by default a temporary directory. branch (type String ) - git branch (default is master ). The meta-configuration must set the path and one of uri or directory . Other optional properties are inherited from AbstractParsableConfigSource.Builder (see javadoc ) <markup lang=\"java\" title=\"Load Config from meta-configuration\" >Config config = Config.loadSourcesFrom(classpath(\"config-meta-git.yaml\")); <markup lang=\"YAML\" title=\"Meta-config config-meta-git.yaml for the git source\" >sources: - type: \"git\" properties: path: \"application.conf\" uri: \"https://github.com/okosatka/test-config.git\" directory: \"/config\" branch: \"dev\" polling-strategy: type: \"regular\" properties: interval: \"PT5M\" git config source type git source-specific properties: path , uri , directory and branch . Polling strategy regular with an interval, in Duration format, of 5 minutes in this example. ",
            "title": "Additional Config Source Types"
        },
        {
            "location": "se/cors",
            "text": " Overview Maven Coordinates API Configuration Examples Additional Information ",
            "title": "Contents"
        },
        {
            "location": "se/cors",
            "text": " Before you revise your application to add CORS support, you need to decide what type of cross-origin sharing you want to allow for each resource your application exposes. For example, suppose for a given resource you want to allow unrestricted sharing for GET, HEAD, and POST requests (what CORS refers to as \"simple\" requests), but permit other types of requests only from the two origins foo.com and there.com . Your application would implement two types of CORS sharing: more relaxed for the simple requests and stricter for others. Once you know the type of sharing you want to allow for each of your resources&#8201;&#8212;&#8201;including any from built-in services&#8201;&#8212;&#8201;you can change your application accordingly. ",
            "title": "Before You Begin"
        },
        {
            "location": "se/cors",
            "text": " The cross-origin resource sharing (CORS) protocol helps developers control if and how REST resources served by their applications can be shared across origins. Helidon SE includes an implementation of CORS that you can use to add CORS behavior to the services you develop. You can define your application&#8217;s CORS behavior programmatically using the Helidon CORS API alone, or together with configuration. Helidon also provides three built-in services that add their own endpoints to your application&#8201;&#8212;&#8201;health, metrics, and OpenAPI&#8201;&#8212;&#8201;that have integrated CORS support. By adding very little code to your application, you control how all the resources in your application&#8201;&#8212;&#8201;the ones you write and the ones provided by the Helidon built-in services&#8201;&#8212;&#8201;can be shared across origins. Before You Begin Before you revise your application to add CORS support, you need to decide what type of cross-origin sharing you want to allow for each resource your application exposes. For example, suppose for a given resource you want to allow unrestricted sharing for GET, HEAD, and POST requests (what CORS refers to as \"simple\" requests), but permit other types of requests only from the two origins foo.com and there.com . Your application would implement two types of CORS sharing: more relaxed for the simple requests and stricter for others. Once you know the type of sharing you want to allow for each of your resources&#8201;&#8212;&#8201;including any from built-in services&#8201;&#8212;&#8201;you can change your application accordingly. ",
            "title": "Overview"
        },
        {
            "location": "se/cors",
            "text": " To enable CORS add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webserver&lt;/groupId&gt; &lt;artifactId&gt;helidon-webserver-cors&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "se/cors",
            "text": " The Helidon SE Quickstart application lets you change the greeting by sending a PUT request to the /greet/greeting resource. This example, based on the QuickStart greeting app, uses the low-level CrossOriginConfig API and the CorsSupport API to influence the routing , thereby determining how that resource is shared. (If desired, you can use configuration instead of the low-level API.) The following code shows how to prepare your application&#8217;s routing to support metrics and health support, as well as CORS. <markup lang=\"java\" >private static Routing createRouting(Config config) { MetricsSupport metrics = MetricsSupport.create(); GreetService greetService = new GreetService(config); HealthSupport health = HealthSupport.builder() .addLiveness(HealthChecks.healthChecks()) // Adds a convenient set of checks .build(); CorsSupport corsSupport = CorsSupport.builder() .addCrossOriginConfig(CrossOriginConfig.builder() .allowOrigins(\"http://foo.com\", \"http://there.com\") .allowMethods(\"PUT\", \"DELETE\") .build()) .addCrossOriginConfig(CrossOriginConfig.create()) .build(); // Note: Add the CORS routing *before* registering the GreetService routing. return Routing.builder() .register(JsonSupport.create()) .register(health) // Health at \"/health\" .register(metrics) // Metrics at \"/metrics\" .register(\"/greet\", corsSupport, greetService) .build(); } Create a CorsSupport.Builder instance. Add a CrossOriginSupport instance (using its builder) to constrain resource sharing. List the origins (sites) allowed to share resources from this app. List the HTTP methods the constraint applies to. Build the CrossOriginSupport instance. Add a CrossOriginSupport instance that permits all sharing (the default). Build the CorsSupport instance. Register the new CorsSupport instance with&#8201;&#8212;&#8201;but in front of&#8201;&#8212;&#8201;the service which implements the business logic. The order of steps 2 and 6 above is important. When processing an incoming request, the Helidon CORS implementation scans the CrossOriginConfig instances in the order they were added to the CorsSupport object, stopping as soon as it finds a CrossOriginConfig instance for which allowMethods matches the HTTP method of the request. The few additional lines described above allow the greeting application to participate in CORS. ",
            "title": "Sample Routing Setup Using the CrossOriginConfig API"
        },
        {
            "location": "se/cors",
            "text": " Every Helidon SE application explicitly creates routing rules that govern how Helidon delivers each incoming request to the code that needs to respond. To add CORS behavior to endpoints, you need to make only minimal changes to how you set up the routing for those endpoints. Using the Helidon SE CORS API, you define the CORS behavior that you want and then include that behavior as you build the routing rules for the services in your application. The Helidon SE CORS API provides two key classes that you use in your application: CorsSupport - Represents information about resource sharing for a single resource. Typically, you create one CorsSupport instance for each distinct resource in your application (such as the /greet resource in the QuickStart greeting application) that should participate in CORS. CrossOriginConfig - Represents the details for a particular type of sharing, such as which origins are allowed to have access using which HTTP methods, etc. Create one instance of CrossOriginConfig for each different type of sharing you need. You associate one or more CrossOriginConfig objects with each CorsSupport object. You use the CorsSupport object when you construct the routing rules for the service. When your application is running and requests arrive, the Helidon CORS implementation enforces the CORS behavior represented by the CorsSupport object before routing the request to your endpoint code for the resource. Because Helidon SE does not use annotation processing to identify endpoints, you need to provide the CORS information for your application another way&#8201;&#8212;&#8201;by including CORS into the routing you construct for your application. For each distinct resource or subresource your application exposes: Create a CorsSupport instance corresponding to the resource. For each different type of sharing you want to provide for that resource: Create a CrossOriginConfig instance. The CrossOriginConfig Java class represents the details for a particular type of sharing, such as which origins are allowed to share via which HTTP methods, etc. Add the CrossOriginConfig to the CorsSupport instance for this resource. Use the resource&#8217;s CorsSupport object in setting up the routing rules for that resource. Each of these classes has an associated builder that you use in constructing instances of the class. The table below describes the methods on the CrossOriginConfig.Builder class and the configuration keys that map to the headers defined in the CORS protocol. (A later section discusses configuration .) builder method config key type default description CORS header name allowCredentials allow-credentials boolean false Sets the allow credentials flag. Access-Control-Allow-Credentials allowHeaders allow-headers string[] * Sets the allowed headers. Access-Control-Allow-Headers allowMethods allow-methods string[] * Sets the allowed methods. Access-Control-Allow-Methods allowOrigins allow-origins string[] * Sets the allowed origins. Access-Control-Allow-Origins exposeHeaders expose-headers string[] &#160; Sets the expose headers. Access-Control-Expose-Headers maxAgeSeconds max-age-seconds long 3600 Sets the maximum age. Access-Control-Max-Age enabled enabled boolean true Sets whether this config should be enabled or not. n/a If the cross-origin configuration is disabled ( enabled = false), then the Helidon CORS implementation ignores the cross-origin configuration entry. Sample Routing Setup Using the CrossOriginConfig API The Helidon SE Quickstart application lets you change the greeting by sending a PUT request to the /greet/greeting resource. This example, based on the QuickStart greeting app, uses the low-level CrossOriginConfig API and the CorsSupport API to influence the routing , thereby determining how that resource is shared. (If desired, you can use configuration instead of the low-level API.) The following code shows how to prepare your application&#8217;s routing to support metrics and health support, as well as CORS. <markup lang=\"java\" >private static Routing createRouting(Config config) { MetricsSupport metrics = MetricsSupport.create(); GreetService greetService = new GreetService(config); HealthSupport health = HealthSupport.builder() .addLiveness(HealthChecks.healthChecks()) // Adds a convenient set of checks .build(); CorsSupport corsSupport = CorsSupport.builder() .addCrossOriginConfig(CrossOriginConfig.builder() .allowOrigins(\"http://foo.com\", \"http://there.com\") .allowMethods(\"PUT\", \"DELETE\") .build()) .addCrossOriginConfig(CrossOriginConfig.create()) .build(); // Note: Add the CORS routing *before* registering the GreetService routing. return Routing.builder() .register(JsonSupport.create()) .register(health) // Health at \"/health\" .register(metrics) // Metrics at \"/metrics\" .register(\"/greet\", corsSupport, greetService) .build(); } Create a CorsSupport.Builder instance. Add a CrossOriginSupport instance (using its builder) to constrain resource sharing. List the origins (sites) allowed to share resources from this app. List the HTTP methods the constraint applies to. Build the CrossOriginSupport instance. Add a CrossOriginSupport instance that permits all sharing (the default). Build the CorsSupport instance. Register the new CorsSupport instance with&#8201;&#8212;&#8201;but in front of&#8201;&#8212;&#8201;the service which implements the business logic. The order of steps 2 and 6 above is important. When processing an incoming request, the Helidon CORS implementation scans the CrossOriginConfig instances in the order they were added to the CorsSupport object, stopping as soon as it finds a CrossOriginConfig instance for which allowMethods matches the HTTP method of the request. The few additional lines described above allow the greeting application to participate in CORS. ",
            "title": "API"
        },
        {
            "location": "se/cors",
            "text": " Support in Helidon for CORS configuration uses two closely-related cross-origin configuration formats: basic and mapped. Each format corresponds to a class in the Helidon CORS library. The basic format corresponds to the CrossOriginConfig class, and the mapped format corresponds to the MappedCrossOriginConfig class. ",
            "title": "Understanding the CORS Configuration Formats"
        },
        {
            "location": "se/cors",
            "text": " In configuration, Helidon represents basic CORS information as a section, identified by a configuration key of your choosing, that contains one or more key/value pairs. Each key-value pair assigns one characteristic of CORS behavior. The table below lists the configuration keys that identify the CORS characteristics. include::[tag=cors-config-table] The following example of basic cross-origin configuration, when loaded and used by the application, limits cross-origin resource sharing for PUT and DELETE operations to only foo.com and there.com : <markup lang=\"yaml\" >restrictive-cors: allow-origins: [\"http://foo.com\", \"http://there.com\"] allow-methods: [\"PUT\", \"DELETE\"] ",
            "title": "Basic Cross-Origin Configuration"
        },
        {
            "location": "se/cors",
            "text": " In some cases, you or your users might want to configure CORS behavior based on URL path matching. Helidon represents mapped CORS information as a section, identified by a configuration key of your choosing, that contains: An optional enabled setting which defaults to true and applies to the whole mapped CORS config section, and An optional paths subsection containing zero or more entries, each of which contains: a basic CORS config section, and a path-pattern path pattern that maps that basic CORS config section to the resource(s) it affects. You can use mapped configuration to your advantage if you want to allow your users to override the CORS behavior set up in the application code. The following example illustrates the mapped cross-origin configuration format. <markup lang=\"hocon\" >my-cors: paths: - path-pattern: /greeting allow-origins: [\"http://foo.com\", \"http://there.com\", \"http://other.com\"] allow-methods: [\"PUT\", \"DELETE\"] - path-pattern: / allow-methods: [\"GET\", \"HEAD\", \"OPTIONS\", \"POST\"] Assigns a unique identifier for this mapped CORS config section. Collects the sequence of entries, each of which maps a basic CORS config to a path pattern. Marks the beginning of an entry (the - character) and maps the associated basic CORS config to the /greeting subresource (the path-pattern key and value). Begins the basic CORS config section for /greeting ; it restricts sharing via PUT and DELETE to the listed origins. Marks the beginning of the next entry (the - character) and maps the associated basic CORS config to the top-level resource in the app (the path-pattern key and value). Begins the basic CORS config section for / ; it permits sharing of resources at the top-level path with all origins for the indicated HTTP methods. Path patterns can be any expression accepted by the PathMatcher class. Be sure to arrange the entries in the order that you want Helidon to check them. Helidon CORS support searches the cross-origin entries in the order you define them until it finds an entry that matches an incoming request&#8217;s path pattern and HTTP method. ",
            "title": "Mapped Cross-Origin Configuration"
        },
        {
            "location": "se/cors",
            "text": " You use configuration in combination with the Helidon CORS SE API to add CORS support to your resources. The example in Sample Routing Setup Using the CrossOriginConfig API uses the low-level Helidon CORS SE API to create a CrossOriginConfig instance that is then used as part of a CorsSupport instance to create the routing rules. As an alternative to using the low-level API, this example uses config to create the CrossOriginConfig instance instead. <markup lang=\"java\" >private static Routing createRouting(Config config) { MetricsSupport metrics = MetricsSupport.create(); GreetService greetService = new GreetService(config); HealthSupport health = HealthSupport.builder() .addLiveness(HealthChecks.healthChecks()) // Adds a convenient set of checks .build(); CorsSupport.Builder builder = CorsSupport.builder(); Config config = Config.create(); // Created from the current config sources config.get(\"my-cors\") .ifExists(builder::mappedConfig); config.get(\"restrictive-cors\") .ifExists(builder::config); builder.addCrossOriginConfig(CrossOriginConfig.create()); CorsSupport corsSupport = builder.build(); // Note: Add the CORS routing *before* registering the GreetService routing. return Routing.builder() .register(JsonSupport.create()) .register(health) // Health at \"/health\" .register(metrics) // Metrics at \"/metrics\" .register(\"/greet\", corsSupport, greetService) .build(); } If my-cors exists in the configuration, use it to add mapped CORS config to the CorsSupport builder. If restrictive-cors exists in the configuration, use it to add basic (not mapped) config to the builder. Provide default CORS handling for requests that do not match earlier entries. Obtain the finished CorsSupport instance. Use corsSupport in constructing the routing rules. As each request arrives, Helidon checks it against the cross-origin config instances in the order that your application added them to the CorsSupport.Builder . The my-cors mapped configuration acts as an override because the application added it to the builder first. If the my-cors config key does not appear in the configuration, then the code skips creating a CrossOriginConfig instance based on that configuration, and no overriding occurs. The CORS behavior that is established by the other CrossOriginConfig instance based on the restrictive-cors config (if present) prevails. Remember that if you set configuration in a file that you include as part of your application JAR file, then you need to rebuild and restart your application for any changes to take effect. ",
            "title": "Using CORS Configuration in the Application"
        },
        {
            "location": "se/cors",
            "text": " You can use configuration in combination with the Helidon CORS SE API to add CORS support to your resources by replacing some Java code with declarative configuration. This also gives your users a way to override the CORS behavior of your services without requiring the code to change. Understanding the CORS Configuration Formats Support in Helidon for CORS configuration uses two closely-related cross-origin configuration formats: basic and mapped. Each format corresponds to a class in the Helidon CORS library. The basic format corresponds to the CrossOriginConfig class, and the mapped format corresponds to the MappedCrossOriginConfig class. Basic Cross-Origin Configuration In configuration, Helidon represents basic CORS information as a section, identified by a configuration key of your choosing, that contains one or more key/value pairs. Each key-value pair assigns one characteristic of CORS behavior. The table below lists the configuration keys that identify the CORS characteristics. include::[tag=cors-config-table] The following example of basic cross-origin configuration, when loaded and used by the application, limits cross-origin resource sharing for PUT and DELETE operations to only foo.com and there.com : <markup lang=\"yaml\" >restrictive-cors: allow-origins: [\"http://foo.com\", \"http://there.com\"] allow-methods: [\"PUT\", \"DELETE\"] Mapped Cross-Origin Configuration In some cases, you or your users might want to configure CORS behavior based on URL path matching. Helidon represents mapped CORS information as a section, identified by a configuration key of your choosing, that contains: An optional enabled setting which defaults to true and applies to the whole mapped CORS config section, and An optional paths subsection containing zero or more entries, each of which contains: a basic CORS config section, and a path-pattern path pattern that maps that basic CORS config section to the resource(s) it affects. You can use mapped configuration to your advantage if you want to allow your users to override the CORS behavior set up in the application code. The following example illustrates the mapped cross-origin configuration format. <markup lang=\"hocon\" >my-cors: paths: - path-pattern: /greeting allow-origins: [\"http://foo.com\", \"http://there.com\", \"http://other.com\"] allow-methods: [\"PUT\", \"DELETE\"] - path-pattern: / allow-methods: [\"GET\", \"HEAD\", \"OPTIONS\", \"POST\"] Assigns a unique identifier for this mapped CORS config section. Collects the sequence of entries, each of which maps a basic CORS config to a path pattern. Marks the beginning of an entry (the - character) and maps the associated basic CORS config to the /greeting subresource (the path-pattern key and value). Begins the basic CORS config section for /greeting ; it restricts sharing via PUT and DELETE to the listed origins. Marks the beginning of the next entry (the - character) and maps the associated basic CORS config to the top-level resource in the app (the path-pattern key and value). Begins the basic CORS config section for / ; it permits sharing of resources at the top-level path with all origins for the indicated HTTP methods. Path patterns can be any expression accepted by the PathMatcher class. Be sure to arrange the entries in the order that you want Helidon to check them. Helidon CORS support searches the cross-origin entries in the order you define them until it finds an entry that matches an incoming request&#8217;s path pattern and HTTP method. Using CORS Configuration in the Application You use configuration in combination with the Helidon CORS SE API to add CORS support to your resources. The example in Sample Routing Setup Using the CrossOriginConfig API uses the low-level Helidon CORS SE API to create a CrossOriginConfig instance that is then used as part of a CorsSupport instance to create the routing rules. As an alternative to using the low-level API, this example uses config to create the CrossOriginConfig instance instead. <markup lang=\"java\" >private static Routing createRouting(Config config) { MetricsSupport metrics = MetricsSupport.create(); GreetService greetService = new GreetService(config); HealthSupport health = HealthSupport.builder() .addLiveness(HealthChecks.healthChecks()) // Adds a convenient set of checks .build(); CorsSupport.Builder builder = CorsSupport.builder(); Config config = Config.create(); // Created from the current config sources config.get(\"my-cors\") .ifExists(builder::mappedConfig); config.get(\"restrictive-cors\") .ifExists(builder::config); builder.addCrossOriginConfig(CrossOriginConfig.create()); CorsSupport corsSupport = builder.build(); // Note: Add the CORS routing *before* registering the GreetService routing. return Routing.builder() .register(JsonSupport.create()) .register(health) // Health at \"/health\" .register(metrics) // Metrics at \"/metrics\" .register(\"/greet\", corsSupport, greetService) .build(); } If my-cors exists in the configuration, use it to add mapped CORS config to the CorsSupport builder. If restrictive-cors exists in the configuration, use it to add basic (not mapped) config to the builder. Provide default CORS handling for requests that do not match earlier entries. Obtain the finished CorsSupport instance. Use corsSupport in constructing the routing rules. As each request arrives, Helidon checks it against the cross-origin config instances in the order that your application added them to the CorsSupport.Builder . The my-cors mapped configuration acts as an override because the application added it to the builder first. If the my-cors config key does not appear in the configuration, then the code skips creating a CrossOriginConfig instance based on that configuration, and no overriding occurs. The CORS behavior that is established by the other CrossOriginConfig instance based on the restrictive-cors config (if present) prevails. Remember that if you set configuration in a file that you include as part of your application JAR file, then you need to rebuild and restart your application for any changes to take effect. ",
            "title": "Configuration"
        },
        {
            "location": "se/cors",
            "text": " For a complete example, see Helidon SE CORS Example . ",
            "title": "Examples"
        },
        {
            "location": "se/cors",
            "text": " To use built-in services with CORS support and customize the CORS behavior: Add the built-in service or services to your application. The health, metrics, and OpenAPI services automatically include default CORS support. Add a dependency on the Helidon SE CORS artifact to your Maven pom.xml file. If you want the built-in services to support CORS, then you need to add the CORS dependency even if your own endpoints do not use CORS. Use the Helidon API or configuration to customize the CORS behavior as needed. The documentation for the individual built-in services describes how to add each service to your application, including adding a Maven dependency and including the service in your application&#8217;s routing rules. In your application&#8217;s configuration file, the configuration for each service appears under its own key. Helidon Service Documentation Configuration Key health health metrics metrics OpenAPI openapi The Helidon SE QuickStart example uses these services, so you can use that as a template for your own application, or use the example project itself to experiment with customizing the CORS behavior in the built-in services. ",
            "title": "Built-in Services with CORS"
        },
        {
            "location": "se/cors",
            "text": " You can also use configuration to control whether and how each of the built-in services works with CORS. Your application can pass configuration to the builder for each built-in service. In the configuration for the health, metrics, and OpenAPI services, you can add a section for CORS. The following example restricts sharing of the /health resource, provided by the health built-in service, to only the origin http://there.com . <markup lang=\"hocon\" >health: cors: allow-origins: [http://there.com] Modify your application to load the health config node and use it to construct the HealthSupport service. The following code shows this change in the the QuickStart SE example. <markup lang=\"java\" >HealthSupport health = HealthSupport.builder() .config(config.get(\"health\")) .addLiveness(HealthChecks.healthChecks()) // Adds a convenient set of checks .build(); Use the health config section (if present) to configure the health service. You have full control over the CORS configuration for a built-in Helidon service. Use a CORS config section as described in Using Configuration for CORS . ",
            "title": "Configuring CORS for Built-in Services"
        },
        {
            "location": "se/cors",
            "text": " Although services such as health, metrics, and OpenAPI are built into Helidon, to use them your application must create instances of the services and then use those instances in building your application&#8217;s routing rules. Recall that each service type has a Builder class. To control the CORS behavior of a built-in service using the API, follow these steps: Create a Builder for the type of service of interest. Build an instance of CrossOriginConfig with the settings you want. Invoke the builder.crossOriginConfig method, passing that CrossOriginConfig instance. Invoke the builder&#8217;s build method to initialize the service instance. Use the service instance in preparing the routing rules. The following excerpt shows changes to the Helidon SE QuickStart example which limit sharing of the /metrics endpoint to http://foo.com . <markup lang=\"java\" >private static Routing createRouting(Config config) { CrossOriginConfig.Builder metricsCrossOriginConfigBuilder = CrossOriginConfig.builder() .allowOrigins(\"http://foo.com\"); RestServiceSettings.Builder restServiceSettingsBuilder = RestServiceSettings.builder() .crossOriginConfig(metricsCrossOriginConfigBuilder); MetricsSupport metrics = MetricsSupport.builder() .restServiceSettings(restServiceSettingsBuilder) .build(); GreetService greetService = new GreetService(config); HealthSupport health = HealthSupport.builder() .addLiveness(HealthChecks.healthChecks()) // Adds a convenient set of checks .build(); return Routing.builder() .register(health) // Health at \"/health\" .register(metrics) // Metrics at \"/metrics\" .register(\"/greet\", greetService) .build(); } Create the CrossOriginConfig.Builder for metrics, limiting sharing to http://foo.com . Use the CrossOriginConfig.Builder instance in constructing the RestServiceSetting.Builder (which assigns common settings such as the CORS configuration and the web context for the service endpoint). Use the RestServiceSetting.Builder in preparing the MetricsSupport service. Use the MetricsSupport object in creating the routing rules. Configuring CORS for Built-in Services You can also use configuration to control whether and how each of the built-in services works with CORS. Your application can pass configuration to the builder for each built-in service. In the configuration for the health, metrics, and OpenAPI services, you can add a section for CORS. The following example restricts sharing of the /health resource, provided by the health built-in service, to only the origin http://there.com . <markup lang=\"hocon\" >health: cors: allow-origins: [http://there.com] Modify your application to load the health config node and use it to construct the HealthSupport service. The following code shows this change in the the QuickStart SE example. <markup lang=\"java\" >HealthSupport health = HealthSupport.builder() .config(config.get(\"health\")) .addLiveness(HealthChecks.healthChecks()) // Adds a convenient set of checks .build(); Use the health config section (if present) to configure the health service. You have full control over the CORS configuration for a built-in Helidon service. Use a CORS config section as described in Using Configuration for CORS . ",
            "title": "Using the API"
        },
        {
            "location": "se/cors",
            "text": " Using the API Although services such as health, metrics, and OpenAPI are built into Helidon, to use them your application must create instances of the services and then use those instances in building your application&#8217;s routing rules. Recall that each service type has a Builder class. To control the CORS behavior of a built-in service using the API, follow these steps: Create a Builder for the type of service of interest. Build an instance of CrossOriginConfig with the settings you want. Invoke the builder.crossOriginConfig method, passing that CrossOriginConfig instance. Invoke the builder&#8217;s build method to initialize the service instance. Use the service instance in preparing the routing rules. The following excerpt shows changes to the Helidon SE QuickStart example which limit sharing of the /metrics endpoint to http://foo.com . <markup lang=\"java\" >private static Routing createRouting(Config config) { CrossOriginConfig.Builder metricsCrossOriginConfigBuilder = CrossOriginConfig.builder() .allowOrigins(\"http://foo.com\"); RestServiceSettings.Builder restServiceSettingsBuilder = RestServiceSettings.builder() .crossOriginConfig(metricsCrossOriginConfigBuilder); MetricsSupport metrics = MetricsSupport.builder() .restServiceSettings(restServiceSettingsBuilder) .build(); GreetService greetService = new GreetService(config); HealthSupport health = HealthSupport.builder() .addLiveness(HealthChecks.healthChecks()) // Adds a convenient set of checks .build(); return Routing.builder() .register(health) // Health at \"/health\" .register(metrics) // Metrics at \"/metrics\" .register(\"/greet\", greetService) .build(); } Create the CrossOriginConfig.Builder for metrics, limiting sharing to http://foo.com . Use the CrossOriginConfig.Builder instance in constructing the RestServiceSetting.Builder (which assigns common settings such as the CORS configuration and the web context for the service endpoint). Use the RestServiceSetting.Builder in preparing the MetricsSupport service. Use the MetricsSupport object in creating the routing rules. Configuring CORS for Built-in Services You can also use configuration to control whether and how each of the built-in services works with CORS. Your application can pass configuration to the builder for each built-in service. In the configuration for the health, metrics, and OpenAPI services, you can add a section for CORS. The following example restricts sharing of the /health resource, provided by the health built-in service, to only the origin http://there.com . <markup lang=\"hocon\" >health: cors: allow-origins: [http://there.com] Modify your application to load the health config node and use it to construct the HealthSupport service. The following code shows this change in the the QuickStart SE example. <markup lang=\"java\" >HealthSupport health = HealthSupport.builder() .config(config.get(\"health\")) .addLiveness(HealthChecks.healthChecks()) // Adds a convenient set of checks .build(); Use the health config section (if present) to configure the health service. You have full control over the CORS configuration for a built-in Helidon service. Use a CORS config section as described in Using Configuration for CORS . ",
            "title": "Controlling CORS for Built-in Services"
        },
        {
            "location": "se/cors",
            "text": " Build and run the QuickStart application as usual. <markup lang=\"bash\" >mvn package java -jar target/helidon-quickstart-se.jar <markup lang=\"listing\" >WEB server is up! http://localhost:8080/greet ",
            "title": "Build and Run the Application"
        },
        {
            "location": "se/cors",
            "text": " The metrics service rejects attempts to access metrics on behalf of a disallowed origin. <markup lang=\"bash\" >curl -i -H \"Origin: http://other.com\" http://localhost:8080/metrics <markup lang=\"listing\" >HTTP/1.1 403 Forbidden Date: Mon, 11 May 2020 11:08:09 -0500 transfer-encoding: chunked connection: keep-alive But accesses from foo.com succeed. <markup lang=\"bash\" >curl -i -H \"Origin: http://foo.com\" http://localhost:8080/metrics <markup lang=\"listing\" >HTTP/1.1 200 OK Access-Control-Allow-Origin: http://foo.com Content-Type: text/plain Date: Mon, 11 May 2020 11:08:16 -0500 Vary: Origin connection: keep-alive content-length: 6065 # TYPE base_classloader_loadedClasses_count gauge # HELP base_classloader_loadedClasses_count Displays the number of classes that are currently loaded in the Java virtual machine. base_classloader_loadedClasses_count 3568 ",
            "title": "Retrieve Metrics"
        },
        {
            "location": "se/cors",
            "text": " The health service rejects requests from origins not specifically approved. <markup lang=\"bash\" >curl -i -H \"Origin: http://foo.com\" http://localhost:8080/health <markup lang=\"listing\" >HTTP/1.1 403 Forbidden Date: Mon, 11 May 2020 12:06:55 -0500 transfer-encoding: chunked connection: keep-alive And responds successfully only to cross-origin requests from http://there.com . <markup lang=\"bash\" >curl -i -H \"Origin: http://there.com\" http://localhost:8080/health <markup lang=\"listing\" >HTTP/1.1 200 OK Access-Control-Allow-Origin: http://there.com Content-Type: application/json Date: Mon, 11 May 2020 12:07:32 -0500 Vary: Origin connection: keep-alive content-length: 461 {\"outcome\":\"UP\",...} ",
            "title": "Retrieve Health"
        },
        {
            "location": "se/cors",
            "text": " If you have edited the Helidon SE QuickStart application as described in the previous topics and saved your changes, you can build and run the application. Once you do so you can execute curl commands to demonstrate the behavior changes in the metric and health services with the addition of the CORS functionality. Note the addition of the Origin header value in the curl commands, and the Access-Control-Allow-Origin in the successful responses. Build and Run the Application Build and run the QuickStart application as usual. <markup lang=\"bash\" >mvn package java -jar target/helidon-quickstart-se.jar <markup lang=\"listing\" >WEB server is up! http://localhost:8080/greet Retrieve Metrics The metrics service rejects attempts to access metrics on behalf of a disallowed origin. <markup lang=\"bash\" >curl -i -H \"Origin: http://other.com\" http://localhost:8080/metrics <markup lang=\"listing\" >HTTP/1.1 403 Forbidden Date: Mon, 11 May 2020 11:08:09 -0500 transfer-encoding: chunked connection: keep-alive But accesses from foo.com succeed. <markup lang=\"bash\" >curl -i -H \"Origin: http://foo.com\" http://localhost:8080/metrics <markup lang=\"listing\" >HTTP/1.1 200 OK Access-Control-Allow-Origin: http://foo.com Content-Type: text/plain Date: Mon, 11 May 2020 11:08:16 -0500 Vary: Origin connection: keep-alive content-length: 6065 # TYPE base_classloader_loadedClasses_count gauge # HELP base_classloader_loadedClasses_count Displays the number of classes that are currently loaded in the Java virtual machine. base_classloader_loadedClasses_count 3568 Retrieve Health The health service rejects requests from origins not specifically approved. <markup lang=\"bash\" >curl -i -H \"Origin: http://foo.com\" http://localhost:8080/health <markup lang=\"listing\" >HTTP/1.1 403 Forbidden Date: Mon, 11 May 2020 12:06:55 -0500 transfer-encoding: chunked connection: keep-alive And responds successfully only to cross-origin requests from http://there.com . <markup lang=\"bash\" >curl -i -H \"Origin: http://there.com\" http://localhost:8080/health <markup lang=\"listing\" >HTTP/1.1 200 OK Access-Control-Allow-Origin: http://there.com Content-Type: application/json Date: Mon, 11 May 2020 12:07:32 -0500 Vary: Origin connection: keep-alive content-length: 461 {\"outcome\":\"UP\",...} ",
            "title": "Accessing the Shared Resources"
        },
        {
            "location": "se/cors",
            "text": " Several built-in Helidon services&#8212;&#8203; health , metrics , and OpenAPI --have integrated CORS support. You can include these services in your application and control how those resources can be shared across origins. For example, several websites related to OpenAPI run a web application in your browser. You provide the URL for your application to the browser application. The browser application uses the URL to retrieve the OpenAPI document that describes the application&#8217;s endpoints directly from your application. The browser application then displays a user interface that you use to \"drive\" your application. That is, you provide input, have the web application send requests to your application endpoints, and then view the responses. This scenario is exactly the situation CORS addresses: an application in the browser from one origin&#8201;&#8212;&#8201;the user interface downloaded from the website&#8201;&#8212;&#8201;requests a resource from another origin&#8201;&#8212;&#8201;the /openapi endpoint which Helidon&#8217;s OpenAPI built-in service automatically adds to your application. Integrating CORS support into these built-in services allows such third-party web sites and their browser applications&#8201;&#8212;&#8201;or more generally, apps from any other origin&#8201;&#8212;&#8201;to work with your Helidon application. Because all three of these built-in Helidon services serve only GET endpoints, by default the integrated CORS support in all three services permits any origin to share their resources using GET , HEAD , and OPTIONS HTTP requests. You can customize the CORS set-up for these built-in services independently from each other using either the Helidon API, configuration, or both. You can use this override feature to control the CORS behavior of the built-in services even if you do not add CORS behavior to your own endpoints. Built-in Services with CORS To use built-in services with CORS support and customize the CORS behavior: Add the built-in service or services to your application. The health, metrics, and OpenAPI services automatically include default CORS support. Add a dependency on the Helidon SE CORS artifact to your Maven pom.xml file. If you want the built-in services to support CORS, then you need to add the CORS dependency even if your own endpoints do not use CORS. Use the Helidon API or configuration to customize the CORS behavior as needed. The documentation for the individual built-in services describes how to add each service to your application, including adding a Maven dependency and including the service in your application&#8217;s routing rules. In your application&#8217;s configuration file, the configuration for each service appears under its own key. Helidon Service Documentation Configuration Key health health metrics metrics OpenAPI openapi The Helidon SE QuickStart example uses these services, so you can use that as a template for your own application, or use the example project itself to experiment with customizing the CORS behavior in the built-in services. Controlling CORS for Built-in Services Using the API Although services such as health, metrics, and OpenAPI are built into Helidon, to use them your application must create instances of the services and then use those instances in building your application&#8217;s routing rules. Recall that each service type has a Builder class. To control the CORS behavior of a built-in service using the API, follow these steps: Create a Builder for the type of service of interest. Build an instance of CrossOriginConfig with the settings you want. Invoke the builder.crossOriginConfig method, passing that CrossOriginConfig instance. Invoke the builder&#8217;s build method to initialize the service instance. Use the service instance in preparing the routing rules. The following excerpt shows changes to the Helidon SE QuickStart example which limit sharing of the /metrics endpoint to http://foo.com . <markup lang=\"java\" >private static Routing createRouting(Config config) { CrossOriginConfig.Builder metricsCrossOriginConfigBuilder = CrossOriginConfig.builder() .allowOrigins(\"http://foo.com\"); RestServiceSettings.Builder restServiceSettingsBuilder = RestServiceSettings.builder() .crossOriginConfig(metricsCrossOriginConfigBuilder); MetricsSupport metrics = MetricsSupport.builder() .restServiceSettings(restServiceSettingsBuilder) .build(); GreetService greetService = new GreetService(config); HealthSupport health = HealthSupport.builder() .addLiveness(HealthChecks.healthChecks()) // Adds a convenient set of checks .build(); return Routing.builder() .register(health) // Health at \"/health\" .register(metrics) // Metrics at \"/metrics\" .register(\"/greet\", greetService) .build(); } Create the CrossOriginConfig.Builder for metrics, limiting sharing to http://foo.com . Use the CrossOriginConfig.Builder instance in constructing the RestServiceSetting.Builder (which assigns common settings such as the CORS configuration and the web context for the service endpoint). Use the RestServiceSetting.Builder in preparing the MetricsSupport service. Use the MetricsSupport object in creating the routing rules. Configuring CORS for Built-in Services You can also use configuration to control whether and how each of the built-in services works with CORS. Your application can pass configuration to the builder for each built-in service. In the configuration for the health, metrics, and OpenAPI services, you can add a section for CORS. The following example restricts sharing of the /health resource, provided by the health built-in service, to only the origin http://there.com . <markup lang=\"hocon\" >health: cors: allow-origins: [http://there.com] Modify your application to load the health config node and use it to construct the HealthSupport service. The following code shows this change in the the QuickStart SE example. <markup lang=\"java\" >HealthSupport health = HealthSupport.builder() .config(config.get(\"health\")) .addLiveness(HealthChecks.healthChecks()) // Adds a convenient set of checks .build(); Use the health config section (if present) to configure the health service. You have full control over the CORS configuration for a built-in Helidon service. Use a CORS config section as described in Using Configuration for CORS . Accessing the Shared Resources If you have edited the Helidon SE QuickStart application as described in the previous topics and saved your changes, you can build and run the application. Once you do so you can execute curl commands to demonstrate the behavior changes in the metric and health services with the addition of the CORS functionality. Note the addition of the Origin header value in the curl commands, and the Access-Control-Allow-Origin in the successful responses. Build and Run the Application Build and run the QuickStart application as usual. <markup lang=\"bash\" >mvn package java -jar target/helidon-quickstart-se.jar <markup lang=\"listing\" >WEB server is up! http://localhost:8080/greet Retrieve Metrics The metrics service rejects attempts to access metrics on behalf of a disallowed origin. <markup lang=\"bash\" >curl -i -H \"Origin: http://other.com\" http://localhost:8080/metrics <markup lang=\"listing\" >HTTP/1.1 403 Forbidden Date: Mon, 11 May 2020 11:08:09 -0500 transfer-encoding: chunked connection: keep-alive But accesses from foo.com succeed. <markup lang=\"bash\" >curl -i -H \"Origin: http://foo.com\" http://localhost:8080/metrics <markup lang=\"listing\" >HTTP/1.1 200 OK Access-Control-Allow-Origin: http://foo.com Content-Type: text/plain Date: Mon, 11 May 2020 11:08:16 -0500 Vary: Origin connection: keep-alive content-length: 6065 # TYPE base_classloader_loadedClasses_count gauge # HELP base_classloader_loadedClasses_count Displays the number of classes that are currently loaded in the Java virtual machine. base_classloader_loadedClasses_count 3568 Retrieve Health The health service rejects requests from origins not specifically approved. <markup lang=\"bash\" >curl -i -H \"Origin: http://foo.com\" http://localhost:8080/health <markup lang=\"listing\" >HTTP/1.1 403 Forbidden Date: Mon, 11 May 2020 12:06:55 -0500 transfer-encoding: chunked connection: keep-alive And responds successfully only to cross-origin requests from http://there.com . <markup lang=\"bash\" >curl -i -H \"Origin: http://there.com\" http://localhost:8080/health <markup lang=\"listing\" >HTTP/1.1 200 OK Access-Control-Allow-Origin: http://there.com Content-Type: application/json Date: Mon, 11 May 2020 12:07:32 -0500 Vary: Origin connection: keep-alive content-length: 461 {\"outcome\":\"UP\",...} ",
            "title": "Using CORS Support in Built-in Helidon Services"
        },
        {
            "location": "se/cors",
            "text": " Using CORS Support in Built-in Helidon Services Several built-in Helidon services&#8212;&#8203; health , metrics , and OpenAPI --have integrated CORS support. You can include these services in your application and control how those resources can be shared across origins. For example, several websites related to OpenAPI run a web application in your browser. You provide the URL for your application to the browser application. The browser application uses the URL to retrieve the OpenAPI document that describes the application&#8217;s endpoints directly from your application. The browser application then displays a user interface that you use to \"drive\" your application. That is, you provide input, have the web application send requests to your application endpoints, and then view the responses. This scenario is exactly the situation CORS addresses: an application in the browser from one origin&#8201;&#8212;&#8201;the user interface downloaded from the website&#8201;&#8212;&#8201;requests a resource from another origin&#8201;&#8212;&#8201;the /openapi endpoint which Helidon&#8217;s OpenAPI built-in service automatically adds to your application. Integrating CORS support into these built-in services allows such third-party web sites and their browser applications&#8201;&#8212;&#8201;or more generally, apps from any other origin&#8201;&#8212;&#8201;to work with your Helidon application. Because all three of these built-in Helidon services serve only GET endpoints, by default the integrated CORS support in all three services permits any origin to share their resources using GET , HEAD , and OPTIONS HTTP requests. You can customize the CORS set-up for these built-in services independently from each other using either the Helidon API, configuration, or both. You can use this override feature to control the CORS behavior of the built-in services even if you do not add CORS behavior to your own endpoints. Built-in Services with CORS To use built-in services with CORS support and customize the CORS behavior: Add the built-in service or services to your application. The health, metrics, and OpenAPI services automatically include default CORS support. Add a dependency on the Helidon SE CORS artifact to your Maven pom.xml file. If you want the built-in services to support CORS, then you need to add the CORS dependency even if your own endpoints do not use CORS. Use the Helidon API or configuration to customize the CORS behavior as needed. The documentation for the individual built-in services describes how to add each service to your application, including adding a Maven dependency and including the service in your application&#8217;s routing rules. In your application&#8217;s configuration file, the configuration for each service appears under its own key. Helidon Service Documentation Configuration Key health health metrics metrics OpenAPI openapi The Helidon SE QuickStart example uses these services, so you can use that as a template for your own application, or use the example project itself to experiment with customizing the CORS behavior in the built-in services. Controlling CORS for Built-in Services Using the API Although services such as health, metrics, and OpenAPI are built into Helidon, to use them your application must create instances of the services and then use those instances in building your application&#8217;s routing rules. Recall that each service type has a Builder class. To control the CORS behavior of a built-in service using the API, follow these steps: Create a Builder for the type of service of interest. Build an instance of CrossOriginConfig with the settings you want. Invoke the builder.crossOriginConfig method, passing that CrossOriginConfig instance. Invoke the builder&#8217;s build method to initialize the service instance. Use the service instance in preparing the routing rules. The following excerpt shows changes to the Helidon SE QuickStart example which limit sharing of the /metrics endpoint to http://foo.com . <markup lang=\"java\" >private static Routing createRouting(Config config) { CrossOriginConfig.Builder metricsCrossOriginConfigBuilder = CrossOriginConfig.builder() .allowOrigins(\"http://foo.com\"); RestServiceSettings.Builder restServiceSettingsBuilder = RestServiceSettings.builder() .crossOriginConfig(metricsCrossOriginConfigBuilder); MetricsSupport metrics = MetricsSupport.builder() .restServiceSettings(restServiceSettingsBuilder) .build(); GreetService greetService = new GreetService(config); HealthSupport health = HealthSupport.builder() .addLiveness(HealthChecks.healthChecks()) // Adds a convenient set of checks .build(); return Routing.builder() .register(health) // Health at \"/health\" .register(metrics) // Metrics at \"/metrics\" .register(\"/greet\", greetService) .build(); } Create the CrossOriginConfig.Builder for metrics, limiting sharing to http://foo.com . Use the CrossOriginConfig.Builder instance in constructing the RestServiceSetting.Builder (which assigns common settings such as the CORS configuration and the web context for the service endpoint). Use the RestServiceSetting.Builder in preparing the MetricsSupport service. Use the MetricsSupport object in creating the routing rules. Configuring CORS for Built-in Services You can also use configuration to control whether and how each of the built-in services works with CORS. Your application can pass configuration to the builder for each built-in service. In the configuration for the health, metrics, and OpenAPI services, you can add a section for CORS. The following example restricts sharing of the /health resource, provided by the health built-in service, to only the origin http://there.com . <markup lang=\"hocon\" >health: cors: allow-origins: [http://there.com] Modify your application to load the health config node and use it to construct the HealthSupport service. The following code shows this change in the the QuickStart SE example. <markup lang=\"java\" >HealthSupport health = HealthSupport.builder() .config(config.get(\"health\")) .addLiveness(HealthChecks.healthChecks()) // Adds a convenient set of checks .build(); Use the health config section (if present) to configure the health service. You have full control over the CORS configuration for a built-in Helidon service. Use a CORS config section as described in Using Configuration for CORS . Accessing the Shared Resources If you have edited the Helidon SE QuickStart application as described in the previous topics and saved your changes, you can build and run the application. Once you do so you can execute curl commands to demonstrate the behavior changes in the metric and health services with the addition of the CORS functionality. Note the addition of the Origin header value in the curl commands, and the Access-Control-Allow-Origin in the successful responses. Build and Run the Application Build and run the QuickStart application as usual. <markup lang=\"bash\" >mvn package java -jar target/helidon-quickstart-se.jar <markup lang=\"listing\" >WEB server is up! http://localhost:8080/greet Retrieve Metrics The metrics service rejects attempts to access metrics on behalf of a disallowed origin. <markup lang=\"bash\" >curl -i -H \"Origin: http://other.com\" http://localhost:8080/metrics <markup lang=\"listing\" >HTTP/1.1 403 Forbidden Date: Mon, 11 May 2020 11:08:09 -0500 transfer-encoding: chunked connection: keep-alive But accesses from foo.com succeed. <markup lang=\"bash\" >curl -i -H \"Origin: http://foo.com\" http://localhost:8080/metrics <markup lang=\"listing\" >HTTP/1.1 200 OK Access-Control-Allow-Origin: http://foo.com Content-Type: text/plain Date: Mon, 11 May 2020 11:08:16 -0500 Vary: Origin connection: keep-alive content-length: 6065 # TYPE base_classloader_loadedClasses_count gauge # HELP base_classloader_loadedClasses_count Displays the number of classes that are currently loaded in the Java virtual machine. base_classloader_loadedClasses_count 3568 Retrieve Health The health service rejects requests from origins not specifically approved. <markup lang=\"bash\" >curl -i -H \"Origin: http://foo.com\" http://localhost:8080/health <markup lang=\"listing\" >HTTP/1.1 403 Forbidden Date: Mon, 11 May 2020 12:06:55 -0500 transfer-encoding: chunked connection: keep-alive And responds successfully only to cross-origin requests from http://there.com . <markup lang=\"bash\" >curl -i -H \"Origin: http://there.com\" http://localhost:8080/health <markup lang=\"listing\" >HTTP/1.1 200 OK Access-Control-Allow-Origin: http://there.com Content-Type: application/json Date: Mon, 11 May 2020 12:07:32 -0500 Vary: Origin connection: keep-alive content-length: 461 {\"outcome\":\"UP\",...} ",
            "title": "Additional Information"
        },
        {
            "location": "se/dbclient",
            "text": " Overview Maven Coordinates Usage API Configuration Additional Information ",
            "title": "Contents"
        },
        {
            "location": "se/dbclient",
            "text": " The Helidon SE DB Client provides a unified, reactive API for working with databases in non-blocking way. ",
            "title": "Overview"
        },
        {
            "location": "se/dbclient",
            "text": " To enable DB Client add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.dbclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-dbclient&lt;/artifactId&gt; &lt;/dependency&gt; To use with a JDBC client also add the following dependency: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.dbclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-dbclient-jdbc&lt;/artifactId&gt; &lt;/dependency&gt; Or to use with MongoDB client add the following dependency: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.dbclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-dbclient-mongodb&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "se/dbclient",
            "text": " The DB Client simplifies how you work with databases by abstracting the type of the database. The API can be used both for relational and non-relational databases. ",
            "title": "Usage"
        },
        {
            "location": "se/dbclient",
            "text": " Database configuration abstraction Using Helidon configuration allows database implementation specific configuration options without the need to use database implementation specific APIs. This allows for seamless switching between databases based on configuration. Statement configuration abstraction Using Helidon configuration allows use of database specific statements. This allows usage of different databases on different environments without changing code. Unified API for data access and query Thanks to the statement configuration abstraction, we can invoke a statement against a relational or non-relations databases (such as MySQL and MongoDB) without modifying source code Reactive database access with backpressure Current we support natively reactive driver for MongoDB, and an executor service wrapped support for any JDBC driver. This allows for seamless use of JDBC drivers in a reactive non-blocking environment, including support for backpressure (result set is processed as requested by the query subscriber) Observability The API offers support for health checks, metrics and tracing. ",
            "title": "API"
        },
        {
            "location": "se/dbclient",
            "text": " For the DB Client using JDBC implementation and H2 database, you must include the following dependencies in your project: <markup lang=\"xml\" >&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.dbclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-dbclient&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.dbclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-dbclient-jdbc&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.h2database&lt;/groupId&gt; &lt;artifactId&gt;h2&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; Add the Helidon DB Client Specify JDBC or MongoDB Add the database JDBC driver (only for JDBC) ",
            "title": "Add the DB Client dependencies to the Maven pom.xml file."
        },
        {
            "location": "se/dbclient",
            "text": " The DB Client must be configured before you begin. In the example below we&#8217;ll use Helidon Config to set up JDBC-based client: <markup lang=\"yaml\" >db: source: \"jdbc\" connection: url: \"jdbc:mysql://127.0.0.1:3306/pokemon?useSSL=false\" username: \"user\" password: \"password\" statements: ping: \"DO 0\" select-all-pokemons: \"SELECT id, name FROM Pokemons\" Source: jdbc or mongoDb Connection: database connection parameters Statements: named statements to be used in application A ping statement used by health check ",
            "title": "Use Helidon Config to configure the client."
        },
        {
            "location": "se/dbclient",
            "text": " Before you begin you must add the DB Client dependencies and configure the client. Add the DB Client dependencies to the Maven pom.xml file. For the DB Client using JDBC implementation and H2 database, you must include the following dependencies in your project: <markup lang=\"xml\" >&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.dbclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-dbclient&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.dbclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-dbclient-jdbc&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.h2database&lt;/groupId&gt; &lt;artifactId&gt;h2&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; Add the Helidon DB Client Specify JDBC or MongoDB Add the database JDBC driver (only for JDBC) Use Helidon Config to configure the client. The DB Client must be configured before you begin. In the example below we&#8217;ll use Helidon Config to set up JDBC-based client: <markup lang=\"yaml\" >db: source: \"jdbc\" connection: url: \"jdbc:mysql://127.0.0.1:3306/pokemon?useSSL=false\" username: \"user\" password: \"password\" statements: ping: \"DO 0\" select-all-pokemons: \"SELECT id, name FROM Pokemons\" Source: jdbc or mongoDb Connection: database connection parameters Statements: named statements to be used in application A ping statement used by health check ",
            "title": "Configuration"
        },
        {
            "location": "se/dbclient",
            "text": " DBClient class has two methods to select whether statements will be executed in transaction or not: execute(Function&lt;DbExecute, T&gt; executor) inTransaction(Function&lt;DbTransaction, T&gt; executor) Both methods provide an executor (either DbExecute or DbTransaction ) and expect either Single or a Multi result, usually returned by one of their methods. ",
            "title": "Executor Selection"
        },
        {
            "location": "se/dbclient",
            "text": " DbExecute class offers many methods for various statements builders: DML statements: createDmlStatement , createNamedDmlStatement insert statements: createInsert , createNamedInsert update statements: createUpdate , createNamedUpdate delete statements: createDelete , createNamedDelete query statements: createQuery , createNamedQuery get statements: createGet , createNamedGet Methods with \"Named\" in their name ( create Named DmlStatement ) expect statement name from statements section of Config, or a named statement configured when the DbClient was created using a Builder . All statement builders offer methods to set statement parameters. Those parameters can be ordered parameters or named parameters. Ordered and named parameters can’t be mixed in a single statement. Note that get statements are query statements that allow zero to one results. ",
            "title": "Statement Building and Execution"
        },
        {
            "location": "se/dbclient",
            "text": " Ordered parameters are written down as ? in the statement text: <markup lang=\"sql\" >SELECT name FROM Pokemons WHERE id = ? The ordered parameters are equivalent to JDBC PreparedStatement parameters. Methods to set ordered parameters are: params(List&lt;?&gt; parameters) with all parameters as List params(Object… parameters) with all parameters as array indexedParam(Object parameters) POJO used with registered mapper addParam(Object parameter) with single parameter, can be called repeatedly ",
            "title": "Ordered Parameters"
        },
        {
            "location": "se/dbclient",
            "text": " Named parameters are written down as :&lt;name&gt; in the JDBC statements <markup lang=\"sql\" >SELECT name FROM Pokemons WHERE id = :id or as $&lt;name&gt; in the MongoDB statement: <markup lang=\"json\" >{ \"collection\": \"pokemons\", \"operation\": \"update\", \"value\": { \"$set\": { \"name\": \"$name\" } }, \"query\": { \"id\": \"$id\" } } Methods to set named parameters are: params(Map&lt;String, ?&gt; parameters) with all parameters as Map namedParam(Object parameters) POJO used with registered mapper addParam(String name, Object parameter) with single parameter, can be called repeatedly ",
            "title": "Named Parameters"
        },
        {
            "location": "se/dbclient",
            "text": " Execution of DML statements will always return Single&lt;Long&gt; with the number of modified records in the database. In following example, the number of modified records is printed to standard output: <markup lang=\"java\" >dbClient.execute(exec -&gt; exec .insert(\"INSERT INTO Pokemons (id, name) VALUES(?, ?)\", 1, \"Pikachu\")) .thenAccept(count -&gt; System.out.printf(\"Inserted %d records\", count)); ",
            "title": "DML Statement Result"
        },
        {
            "location": "se/dbclient",
            "text": " Execution of a query statement will always return Multi&lt;DbRow&gt;&gt; . Multi has several useful properties: It is an implementation of Flow.Publisher to process individual result rows using Flow.Subscriber&lt;DbRow&gt; Single&lt;List&lt;DbRow&gt;&gt; collectList() to collect all rows and return them as a promise of List&lt;DbRow&gt; &lt;U&gt; Multi&lt;U&gt; map(…) to map returned result using provided mapper ",
            "title": "Query Statement Result"
        },
        {
            "location": "se/dbclient",
            "text": " Statements are executed by calling execute() method after statement parameters are set. This method returns either a Single or Multi depending on statement type. The type returned also depends on statement type. JDBC query with ordered parameters and query that does not run in the transaction: <markup lang=\"java\" >dbClient.execute(exec -&gt; exec .createQuery(\"SELECT name FROM Pokemons WHERE id = ?\") .params(1) .execute() ); JDBC query with named parameters and the query runs in transaction: <markup lang=\"java\" >dbClient.inTransaction(tx -&gt; tx .createQuery(\"SELECT name FROM Pokemons WHERE id = :id\") .addParam(\"id\", 1) .execute() ); Both examples will return Multi&lt;DbRow&gt; with rows returned by the query. This example shows a MongoDB update statement with named parameters and the query does not run in transaction: <markup lang=\"java\" >dbClient.execute(exec -&gt; exec .createUpdate(\"{\\\"collection\\\": \\\"pokemons\\\",\" + \"\\\"value\\\":{$set:{\\\"name\\\":$name}},\" + \"\\\"query\\\":{id:$id}}\") .addParam(\"id\", 1) .addParam(\"name\", \"Pikachu\") .execute() ); This update statement will return Single&lt;Long&gt; with the number of modified records in the database. DML Statement Result Execution of DML statements will always return Single&lt;Long&gt; with the number of modified records in the database. In following example, the number of modified records is printed to standard output: <markup lang=\"java\" >dbClient.execute(exec -&gt; exec .insert(\"INSERT INTO Pokemons (id, name) VALUES(?, ?)\", 1, \"Pikachu\")) .thenAccept(count -&gt; System.out.printf(\"Inserted %d records\", count)); Query Statement Result Execution of a query statement will always return Multi&lt;DbRow&gt;&gt; . Multi has several useful properties: It is an implementation of Flow.Publisher to process individual result rows using Flow.Subscriber&lt;DbRow&gt; Single&lt;List&lt;DbRow&gt;&gt; collectList() to collect all rows and return them as a promise of List&lt;DbRow&gt; &lt;U&gt; Multi&lt;U&gt; map(…) to map returned result using provided mapper ",
            "title": "Statement Execution"
        },
        {
            "location": "se/dbclient",
            "text": " The Helidon DB Client API contains many methods to run various statements with parameters and to retrieve statement execution results. The following sections describe the options you can use to build and execute your statements. Executor Selection DBClient class has two methods to select whether statements will be executed in transaction or not: execute(Function&lt;DbExecute, T&gt; executor) inTransaction(Function&lt;DbTransaction, T&gt; executor) Both methods provide an executor (either DbExecute or DbTransaction ) and expect either Single or a Multi result, usually returned by one of their methods. Statement Building and Execution DbExecute class offers many methods for various statements builders: DML statements: createDmlStatement , createNamedDmlStatement insert statements: createInsert , createNamedInsert update statements: createUpdate , createNamedUpdate delete statements: createDelete , createNamedDelete query statements: createQuery , createNamedQuery get statements: createGet , createNamedGet Methods with \"Named\" in their name ( create Named DmlStatement ) expect statement name from statements section of Config, or a named statement configured when the DbClient was created using a Builder . All statement builders offer methods to set statement parameters. Those parameters can be ordered parameters or named parameters. Ordered and named parameters can’t be mixed in a single statement. Note that get statements are query statements that allow zero to one results. Ordered Parameters Ordered parameters are written down as ? in the statement text: <markup lang=\"sql\" >SELECT name FROM Pokemons WHERE id = ? The ordered parameters are equivalent to JDBC PreparedStatement parameters. Methods to set ordered parameters are: params(List&lt;?&gt; parameters) with all parameters as List params(Object… parameters) with all parameters as array indexedParam(Object parameters) POJO used with registered mapper addParam(Object parameter) with single parameter, can be called repeatedly Named Parameters Named parameters are written down as :&lt;name&gt; in the JDBC statements <markup lang=\"sql\" >SELECT name FROM Pokemons WHERE id = :id or as $&lt;name&gt; in the MongoDB statement: <markup lang=\"json\" >{ \"collection\": \"pokemons\", \"operation\": \"update\", \"value\": { \"$set\": { \"name\": \"$name\" } }, \"query\": { \"id\": \"$id\" } } Methods to set named parameters are: params(Map&lt;String, ?&gt; parameters) with all parameters as Map namedParam(Object parameters) POJO used with registered mapper addParam(String name, Object parameter) with single parameter, can be called repeatedly Statement Execution Statements are executed by calling execute() method after statement parameters are set. This method returns either a Single or Multi depending on statement type. The type returned also depends on statement type. JDBC query with ordered parameters and query that does not run in the transaction: <markup lang=\"java\" >dbClient.execute(exec -&gt; exec .createQuery(\"SELECT name FROM Pokemons WHERE id = ?\") .params(1) .execute() ); JDBC query with named parameters and the query runs in transaction: <markup lang=\"java\" >dbClient.inTransaction(tx -&gt; tx .createQuery(\"SELECT name FROM Pokemons WHERE id = :id\") .addParam(\"id\", 1) .execute() ); Both examples will return Multi&lt;DbRow&gt; with rows returned by the query. This example shows a MongoDB update statement with named parameters and the query does not run in transaction: <markup lang=\"java\" >dbClient.execute(exec -&gt; exec .createUpdate(\"{\\\"collection\\\": \\\"pokemons\\\",\" + \"\\\"value\\\":{$set:{\\\"name\\\":$name}},\" + \"\\\"query\\\":{id:$id}}\") .addParam(\"id\", 1) .addParam(\"name\", \"Pikachu\") .execute() ); This update statement will return Single&lt;Long&gt; with the number of modified records in the database. DML Statement Result Execution of DML statements will always return Single&lt;Long&gt; with the number of modified records in the database. In following example, the number of modified records is printed to standard output: <markup lang=\"java\" >dbClient.execute(exec -&gt; exec .insert(\"INSERT INTO Pokemons (id, name) VALUES(?, ?)\", 1, \"Pikachu\")) .thenAccept(count -&gt; System.out.printf(\"Inserted %d records\", count)); Query Statement Result Execution of a query statement will always return Multi&lt;DbRow&gt;&gt; . Multi has several useful properties: It is an implementation of Flow.Publisher to process individual result rows using Flow.Subscriber&lt;DbRow&gt; Single&lt;List&lt;DbRow&gt;&gt; collectList() to collect all rows and return them as a promise of List&lt;DbRow&gt; &lt;U&gt; Multi&lt;U&gt; map(…) to map returned result using provided mapper ",
            "title": "Using DB Client API Methods"
        },
        {
            "location": "se/dbclient",
            "text": " Now that you understand how to build and execute statements, try it for yourself. DB Client Examples . ",
            "title": "Additional Information"
        },
        {
            "location": "se/fault-tolerance",
            "text": " Overview Maven Coordinates API Configuration Examples Additional Information ",
            "title": "Contents"
        },
        {
            "location": "se/fault-tolerance",
            "text": " Helidon SE Fault Tolerance support is inspired by MicroProfile Fault Tolerance . The API defines the notion of a fault handler that can be combined with other handlers to improve application robustness. Handlers are created to manage error conditions (faults) that may occur in real-world application environments. Examples include service restarts, network delays, temporal infrastructure instabilities, etc. The interaction of multiple microservices bring some new challenges from distributed systems that require careful planning. Faults in distributed systems should be compartmentalized to avoid unnecessary service interruptions. For example, if comparable information can be obtained from multiples sources, a user request should not be denied when a subset of these sources is unreachable or offline. Similarly, if a non-essential source has been flagged as unreachable, an application should avoid continuous access to that source as that would result in much higher response times. In order to tackle the most common types of application faults, the Helidon SE Fault Tolerance API provides support for circuit breakers, retries, timeouts, bulkheads and fallbacks. In addition, the API makes it very easy to create and monitor asynchronous tasks that do not require explicit creation and management of threads or executors. For more information the reader is referred to the Fault Tolerance SE API Javadocs . ",
            "title": "Overview"
        },
        {
            "location": "se/fault-tolerance",
            "text": " To enable Fault Tolerance add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.fault-tolerance&lt;/groupId&gt; &lt;artifactId&gt;helidon-fault-tolerance&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "se/fault-tolerance",
            "text": " Asynchronous tasks can be created or forked by using an Async instance. A supplier of type T is provided as the argument when invoking this handler. For example: <markup lang=\"java\" >Single&lt;Thread&gt; s = Async.create().invoke(() -&gt; Thread.currentThread())); s.thenAccept(t -&gt; System.out.println(\"Async task executed in thread \" + t)); The supplier () &#8594; Thread.currentThread() is executed in a new thread and the value it produces printed by the consumer and passed to thenAccept . The method reference Thread::currentThread is a simplified way of providing a supplier in the example above. Asynchronous tasks are executed in a thread pool managed by the Helidon SE Fault Tolerance module. Thread pools are created during the initialization phase of class io.helidon.faulttolerance.FaultTolerance and can be configured for your application. ",
            "title": "Asynchronous"
        },
        {
            "location": "se/fault-tolerance",
            "text": " Temporal networking problems can sometimes be mitigated by simply retrying a certain task. A Retry handler is created using a RetryPolicy that indicates the number of retries, delay between retries, etc. <markup lang=\"java\" >Retry retry = Retry.builder() .retryPolicy(Retry.JitterRetryPolicy.builder() .calls(3) .delay(Duration.ofMillis(100)) .build()) .build(); retry.invoke(this::retryOnFailure); The sample code above will retry calls to the supplier this::retryOnFailure for up to 3 times with a 100 millisecond delay between them. The return type of method retryOnFailure in the example above must be CompletionStage&lt;T&gt; and the parameter to the retry handler&#8217;s invoke method Supplier&lt;? extends CompletionStage&lt;T&gt;&gt; . If the CompletionStage&lt;T&gt; returned by the method completes exceptionally, the call will be treated as a failure and retried until the maximum number of attempts is reached; finer control is possible by creating a retry policy and using methods such as applyOn(Class&lt;? extends Throwable&gt;&#8230;&#8203; classes) and skipOn(Class&lt;? extends Throwable&gt;&#8230;&#8203; classes) to control those exceptions on which to act and those that can be ignored. ",
            "title": "Retries"
        },
        {
            "location": "se/fault-tolerance",
            "text": " A request to a service that is inaccessible or simply unavailable should be bounded to ensure a certain quality of service and response time. Timeouts can be configured to avoid excessive waiting times. In addition, a fallback action can be defined if a timeout expires as we shall cover in the next section. The following is an example of using Timeout : <markup lang=\"java\" >Single&lt;T&gt; s = Timeout.create(Duration.ofMillis(10)).invoke(this::mayTakeVeryLong); s.handle((t, e) -&gt; { if (e instanceof TimeoutException) { // Invocation has timed out! } //... }); The example above monitors the call to method mayTakeVeryLong and reports a TimeoutException if the execution takes more than 10 milliseconds to complete. ",
            "title": "Timeouts"
        },
        {
            "location": "se/fault-tolerance",
            "text": " A fallback to a known result can sometimes be an alternative to reporting an error. For example, if we are unable to access a service we may fall back to the last result obtained from that service. A Fallback instance is created by providing a function that takes a Throwable and produces a CompletionStage&lt;T&gt; as shown next: <markup lang=\"java\" >Single&lt;T&gt; single = Fallback.create( throwable -&gt; Single.just(lastKnownValue).invoke(this::mayFail); single.thenAccept(t -&gt; { //... }); In this example, we register a function that can produce a Single&lt;T&gt; (which implements CompletionStage&lt;T&gt; ) if the call to this::mayFail completes exceptionally. ",
            "title": "Fallbacks"
        },
        {
            "location": "se/fault-tolerance",
            "text": " Failing to execute a certain task or call another service repeatedly can have a direct impact on application performance. It is often preferred to avoid calls to non-essential services by simply preventing that logic to execute altogether. A circuit breaker can be configured to monitor such calls and block attempts that are likely to fail, thus improving overall performance. Circuit breakers start in a closed state, letting calls to proceed normally; after detecting a certain number of errors during a pre-defined processing window, they can open to prevent additional failures. After a circuit has been opened, it can transition first to a half-open state before finally transitioning back to a closed state. The use of an intermediate state (half-open) makes transitions from open to close more progressive, and prevents a circuit breaker from eagerly transitioning to states without considering \"sufficient\" observations. Any failure while a circuit breaker is in half-open state will immediately cause it to transition back to an open state. Consider the following example in which this::mayFail is monitored by a circuit breaker: <markup lang=\"java\" >CircuitBreaker breaker = CircuitBreaker.builder() .volume(10) .errorRatio(30) .delay(Duration.ofMillis(200)) .successThreshold(2) .build(); Single&lt;T&gt; result = breaker.invoke(this::mayFail); The circuit breaker in this example defines a processing window of size 10, an error ratio of 30%, a duration to transition to half-open state of 200 milliseconds, and a success threshold to transition from half-open to closed state of 2 observations. It follows that, After completing the processing window, if at least 3 errors were detected, the circuit breaker will transition to the open state, thus blocking the execution of any subsequent calls. After 200 millis, the circuit breaker will transition back to half-open and enable calls to proceed again. If the next two calls after transitioning to half-open are successful, the circuit breaker will transition to closed state; otherwise, it will transition back to open state, waiting for another 200 milliseconds before attempting to transition to half-open again. A circuit breaker will throw a io.helidon.faulttolerance.CircuitBreakerOpenException if an attempt to make an invocation takes place while it is in open state. ",
            "title": "Circuit Breakers"
        },
        {
            "location": "se/fault-tolerance",
            "text": " Concurrent access to certain components may need to be limited to avoid excessive use of resources. For example, if an invocation that opens a network connection is allowed to execute concurrently without any restriction, and if the service on the other end is slow responding, it is possible for the rate at which network connections are opened to exceed the maximum number of connections allowed. Faults of this type can be prevented by guarding these invocations using a bulkhead. The origin of the name bulkhead comes from the partitions that comprise a ship&#8217;s hull. If some partition is somehow compromised (e.g., filled with water) it can be isolated in a manner not to affect the rest of the hull. A waiting queue can be associated with a bulkhead to handle tasks that are submitted when the bulkhead is already at full capacity. <markup lang=\"java\" >Bulkhead bulkhead = Bulkhead.builder() .limit(3) .queueLength(5) .build(); Single&lt;T&gt; single = bulkhead.invoke(this::usesResources); This example creates a bulkhead that limits concurrent execution to this:usesResources to at most 3, and with a queue of size 5. The bulkhead will report a io.helidon.faulttolerance.BulkheadException if unable to proceed with the call: either due to the limit being reached or the queue being at maximum capacity. ",
            "title": "Bulkheads"
        },
        {
            "location": "se/fault-tolerance",
            "text": " Method invocations can be guarded by any combination of the handlers presented above. For example, an invocation that times out can be retried a few times before resorting to a fallback value &mdash;assuming it never succeeds. The easiest way to achieve handler composition is by using a builder in the FaultTolerance class as shown in the following example: <markup lang=\"java\" >FaultTolerance.TypedBuilder&lt;T&gt; builder = FaultTolerance.typedBuilder(); // Create and add timeout Timeout timeout = Timeout.create(Duration.ofMillis(10)); builder.addTimeout(timeout); // Create and add retry Retry retry = Retry.builder() .retryPolicy(Retry.JitterRetryPolicy.builder() .calls(3) .delay(Duration.ofMillis(100)) .build()) .build(); builder.addRetry(retry); // Create and add fallback Fallback fallback = Fallback.create(throwable -&gt; Single.just(lastKnownValue)); builder.addFallback(fallback); // Finally call the method Single&lt;T&gt; single = builder.build().invoke(this::mayTakeVeryLong); The exact order in which handlers are added to a builder depends on the use case, but generally the order starting from innermost to outermost should be: bulkhead, timeout, circuit breaker, retry and fallback. That is, fallback is the first handler in the chain (the last to executed once a value is returned) and bulkhead is the last one (the first to be executed once a value is returned). This is the ordering used by the MicroProfile Fault Tolerance implementation in Helidon when a method is decorated with multiple annotations. ",
            "title": "Handler Composition"
        },
        {
            "location": "se/fault-tolerance",
            "text": " All the examples presented so far have focused on invocations returning a single value of type Single&lt;T&gt; . If the invocation in question can return more than one value (i.e., a Multi&lt;T&gt; ) then all that is needed is to use the method invokeMulti instead of invoke . The supplier passed to this method must return a Flow.Publisher&lt;T&gt; instead of a CompletionStage&lt;T&gt; . A Flow.Publisher&lt;T&gt; is a generalization of a Single&lt;T&gt; that can produce zero or more values. Note that a Flow.Publisher&lt;T&gt; , unlike a Single&lt;T&gt; , can report an error after producing one or more values, introducing additional challenges if all values must be processed transactionally, that is, in an all or nothing manner. The following example creates an instance of Retry and invokes the invokeMulti method, it then registers a subscriber to process the results: <markup lang=\"java\" >Retry retry = Retry.builder() .retryPolicy(Retry.JitterRetryPolicy.builder() .calls(2) .build()) .build(); Multi&lt;Integer&gt; multi = retry.invokeMulti(() -&gt; Multi.just(0, 1, 2)); IntSubscriber ts = new IntSubscriber(); multi.subscribe(ts); ts.request(Integer.MAX_VALUE); The call to Multi.just(0, 1, 2) simply returns a multi that produces the integers 0, 1 and 2. If an error was generated during this process, the policy will retry the call one more time &mdash;for a total of 2 calls. ",
            "title": "Revisiting Multi&#8217;s"
        },
        {
            "location": "se/fault-tolerance",
            "text": " The SE Fault Tolerance API is reactive in order to fit the overall processing model in Helidon SE. A task returns either a Single&lt;T&gt; or a Multi&lt;T&gt; . A Single&lt;T&gt; is a promise to produce zero or one value of type T or signal an error; while a Multi&lt;T&gt; is a promise to produce zero or more values of type T or signal an error. A Single&lt;T&gt; , like CompletableFuture&lt;T&gt; , extends CompletionStage&lt;T&gt; so conversion among these types is straightforward. In the sections that follow, we shall briefly explore each of the constructs provided by this API. Asynchronous Asynchronous tasks can be created or forked by using an Async instance. A supplier of type T is provided as the argument when invoking this handler. For example: <markup lang=\"java\" >Single&lt;Thread&gt; s = Async.create().invoke(() -&gt; Thread.currentThread())); s.thenAccept(t -&gt; System.out.println(\"Async task executed in thread \" + t)); The supplier () &#8594; Thread.currentThread() is executed in a new thread and the value it produces printed by the consumer and passed to thenAccept . The method reference Thread::currentThread is a simplified way of providing a supplier in the example above. Asynchronous tasks are executed in a thread pool managed by the Helidon SE Fault Tolerance module. Thread pools are created during the initialization phase of class io.helidon.faulttolerance.FaultTolerance and can be configured for your application. Retries Temporal networking problems can sometimes be mitigated by simply retrying a certain task. A Retry handler is created using a RetryPolicy that indicates the number of retries, delay between retries, etc. <markup lang=\"java\" >Retry retry = Retry.builder() .retryPolicy(Retry.JitterRetryPolicy.builder() .calls(3) .delay(Duration.ofMillis(100)) .build()) .build(); retry.invoke(this::retryOnFailure); The sample code above will retry calls to the supplier this::retryOnFailure for up to 3 times with a 100 millisecond delay between them. The return type of method retryOnFailure in the example above must be CompletionStage&lt;T&gt; and the parameter to the retry handler&#8217;s invoke method Supplier&lt;? extends CompletionStage&lt;T&gt;&gt; . If the CompletionStage&lt;T&gt; returned by the method completes exceptionally, the call will be treated as a failure and retried until the maximum number of attempts is reached; finer control is possible by creating a retry policy and using methods such as applyOn(Class&lt;? extends Throwable&gt;&#8230;&#8203; classes) and skipOn(Class&lt;? extends Throwable&gt;&#8230;&#8203; classes) to control those exceptions on which to act and those that can be ignored. Timeouts A request to a service that is inaccessible or simply unavailable should be bounded to ensure a certain quality of service and response time. Timeouts can be configured to avoid excessive waiting times. In addition, a fallback action can be defined if a timeout expires as we shall cover in the next section. The following is an example of using Timeout : <markup lang=\"java\" >Single&lt;T&gt; s = Timeout.create(Duration.ofMillis(10)).invoke(this::mayTakeVeryLong); s.handle((t, e) -&gt; { if (e instanceof TimeoutException) { // Invocation has timed out! } //... }); The example above monitors the call to method mayTakeVeryLong and reports a TimeoutException if the execution takes more than 10 milliseconds to complete. Fallbacks A fallback to a known result can sometimes be an alternative to reporting an error. For example, if we are unable to access a service we may fall back to the last result obtained from that service. A Fallback instance is created by providing a function that takes a Throwable and produces a CompletionStage&lt;T&gt; as shown next: <markup lang=\"java\" >Single&lt;T&gt; single = Fallback.create( throwable -&gt; Single.just(lastKnownValue).invoke(this::mayFail); single.thenAccept(t -&gt; { //... }); In this example, we register a function that can produce a Single&lt;T&gt; (which implements CompletionStage&lt;T&gt; ) if the call to this::mayFail completes exceptionally. Circuit Breakers Failing to execute a certain task or call another service repeatedly can have a direct impact on application performance. It is often preferred to avoid calls to non-essential services by simply preventing that logic to execute altogether. A circuit breaker can be configured to monitor such calls and block attempts that are likely to fail, thus improving overall performance. Circuit breakers start in a closed state, letting calls to proceed normally; after detecting a certain number of errors during a pre-defined processing window, they can open to prevent additional failures. After a circuit has been opened, it can transition first to a half-open state before finally transitioning back to a closed state. The use of an intermediate state (half-open) makes transitions from open to close more progressive, and prevents a circuit breaker from eagerly transitioning to states without considering \"sufficient\" observations. Any failure while a circuit breaker is in half-open state will immediately cause it to transition back to an open state. Consider the following example in which this::mayFail is monitored by a circuit breaker: <markup lang=\"java\" >CircuitBreaker breaker = CircuitBreaker.builder() .volume(10) .errorRatio(30) .delay(Duration.ofMillis(200)) .successThreshold(2) .build(); Single&lt;T&gt; result = breaker.invoke(this::mayFail); The circuit breaker in this example defines a processing window of size 10, an error ratio of 30%, a duration to transition to half-open state of 200 milliseconds, and a success threshold to transition from half-open to closed state of 2 observations. It follows that, After completing the processing window, if at least 3 errors were detected, the circuit breaker will transition to the open state, thus blocking the execution of any subsequent calls. After 200 millis, the circuit breaker will transition back to half-open and enable calls to proceed again. If the next two calls after transitioning to half-open are successful, the circuit breaker will transition to closed state; otherwise, it will transition back to open state, waiting for another 200 milliseconds before attempting to transition to half-open again. A circuit breaker will throw a io.helidon.faulttolerance.CircuitBreakerOpenException if an attempt to make an invocation takes place while it is in open state. Bulkheads Concurrent access to certain components may need to be limited to avoid excessive use of resources. For example, if an invocation that opens a network connection is allowed to execute concurrently without any restriction, and if the service on the other end is slow responding, it is possible for the rate at which network connections are opened to exceed the maximum number of connections allowed. Faults of this type can be prevented by guarding these invocations using a bulkhead. The origin of the name bulkhead comes from the partitions that comprise a ship&#8217;s hull. If some partition is somehow compromised (e.g., filled with water) it can be isolated in a manner not to affect the rest of the hull. A waiting queue can be associated with a bulkhead to handle tasks that are submitted when the bulkhead is already at full capacity. <markup lang=\"java\" >Bulkhead bulkhead = Bulkhead.builder() .limit(3) .queueLength(5) .build(); Single&lt;T&gt; single = bulkhead.invoke(this::usesResources); This example creates a bulkhead that limits concurrent execution to this:usesResources to at most 3, and with a queue of size 5. The bulkhead will report a io.helidon.faulttolerance.BulkheadException if unable to proceed with the call: either due to the limit being reached or the queue being at maximum capacity. Handler Composition Method invocations can be guarded by any combination of the handlers presented above. For example, an invocation that times out can be retried a few times before resorting to a fallback value &mdash;assuming it never succeeds. The easiest way to achieve handler composition is by using a builder in the FaultTolerance class as shown in the following example: <markup lang=\"java\" >FaultTolerance.TypedBuilder&lt;T&gt; builder = FaultTolerance.typedBuilder(); // Create and add timeout Timeout timeout = Timeout.create(Duration.ofMillis(10)); builder.addTimeout(timeout); // Create and add retry Retry retry = Retry.builder() .retryPolicy(Retry.JitterRetryPolicy.builder() .calls(3) .delay(Duration.ofMillis(100)) .build()) .build(); builder.addRetry(retry); // Create and add fallback Fallback fallback = Fallback.create(throwable -&gt; Single.just(lastKnownValue)); builder.addFallback(fallback); // Finally call the method Single&lt;T&gt; single = builder.build().invoke(this::mayTakeVeryLong); The exact order in which handlers are added to a builder depends on the use case, but generally the order starting from innermost to outermost should be: bulkhead, timeout, circuit breaker, retry and fallback. That is, fallback is the first handler in the chain (the last to executed once a value is returned) and bulkhead is the last one (the first to be executed once a value is returned). This is the ordering used by the MicroProfile Fault Tolerance implementation in Helidon when a method is decorated with multiple annotations. Revisiting Multi&#8217;s All the examples presented so far have focused on invocations returning a single value of type Single&lt;T&gt; . If the invocation in question can return more than one value (i.e., a Multi&lt;T&gt; ) then all that is needed is to use the method invokeMulti instead of invoke . The supplier passed to this method must return a Flow.Publisher&lt;T&gt; instead of a CompletionStage&lt;T&gt; . A Flow.Publisher&lt;T&gt; is a generalization of a Single&lt;T&gt; that can produce zero or more values. Note that a Flow.Publisher&lt;T&gt; , unlike a Single&lt;T&gt; , can report an error after producing one or more values, introducing additional challenges if all values must be processed transactionally, that is, in an all or nothing manner. The following example creates an instance of Retry and invokes the invokeMulti method, it then registers a subscriber to process the results: <markup lang=\"java\" >Retry retry = Retry.builder() .retryPolicy(Retry.JitterRetryPolicy.builder() .calls(2) .build()) .build(); Multi&lt;Integer&gt; multi = retry.invokeMulti(() -&gt; Multi.just(0, 1, 2)); IntSubscriber ts = new IntSubscriber(); multi.subscribe(ts); ts.request(Integer.MAX_VALUE); The call to Multi.just(0, 1, 2) simply returns a multi that produces the integers 0, 1 and 2. If an error was generated during this process, the policy will retry the call one more time &mdash;for a total of 2 calls. ",
            "title": "API"
        },
        {
            "location": "se/fault-tolerance",
            "text": " <div class=\"table__overflow elevation-1 flex sm7 \"> Property Type Description name String A name given to the task for debugging purposes. Default is Timeout-N . timeout Duration The timeout length as a Duration string. Default is PT10S or 10 seconds. current-thread boolean A flag indicating whether the task should execute in the current thread or not. Default is false . cancel-source boolean A flag indicating if this task&#8217;s source should be cancelled if the task is cancelled. Default is true . ",
            "title": "Timeout"
        },
        {
            "location": "se/fault-tolerance",
            "text": " <div class=\"table__overflow elevation-1 flex sm7 \"> Property Type Description name String A name given to the task for debugging purposes. Default is CircuitBreaker-N . delay Duration Delay to transition from half-open state. Default is PT5S or 5 seconds. error-ratio int Failure percentage to transition to open state. Default is 60. volume int Size of rolling window to calculate ratios. Size is 10. success-threshold int Number of successful calls to transition to closed state. Default is 1. cancel-source boolean A flag indicating if this task&#8217;s source should be cancelled if the task is cancelled. Default is true . ",
            "title": "Circuit Breaker"
        },
        {
            "location": "se/fault-tolerance",
            "text": " <div class=\"table__overflow elevation-1 flex sm7 \"> Property Type Description limit int Max number of parallel calls. Default is 10. name String A name given to the task for debugging purposes. Default is Bulkhead-N . queue-length int Length of queue for tasks waiting to enter. Default is 10. cancel-source boolean A flag indicating if this task&#8217;s source should be cancelled if the task is cancelled. Default is true . ",
            "title": "Bulkhead"
        },
        {
            "location": "se/fault-tolerance",
            "text": " <div class=\"table__overflow elevation-1 flex sm7 \"> Property Type Description calls int Number of retry attempts. Default is 3. delay Duration Delay between retries. Default is PT0.2S or 200 milliseconds. delay-factor double A delay multiplication factor applied after each retry. ",
            "title": "Delaying Retry Policy"
        },
        {
            "location": "se/fault-tolerance",
            "text": " <div class=\"table__overflow elevation-1 flex sm7 \"> Property Type Description calls int Number of retry attempts. Default is 3. delay Duration Delay between retries. Default is PT0.2S or 200 milliseconds. jitter Duration A random delay additive factor in the range [-jitter, +jitter] applied after each retry. ",
            "title": "Jitter Retry Policy"
        },
        {
            "location": "se/fault-tolerance",
            "text": " <div class=\"table__overflow elevation-1 flex sm7 \"> Property Type Description name String A name given to the task for debugging purposes. Default is Retry-N . overall-timeout Duration Timeout for overall retry execution. Default is PT1S or 1 second. delaying-retry-policy Config Config section describing delaying retry policy (see below). jitter-retry-policy Config Config section describing jitter retry policy (see below) cancel-source boolean A flag indicating if this task&#8217;s source should be cancelled if the task is cancelled. Default is true . Delaying Retry Policy <div class=\"table__overflow elevation-1 flex sm7 \"> Property Type Description calls int Number of retry attempts. Default is 3. delay Duration Delay between retries. Default is PT0.2S or 200 milliseconds. delay-factor double A delay multiplication factor applied after each retry. Jitter Retry Policy <div class=\"table__overflow elevation-1 flex sm7 \"> Property Type Description calls int Number of retry attempts. Default is 3. delay Duration Delay between retries. Default is PT0.2S or 200 milliseconds. jitter Duration A random delay additive factor in the range [-jitter, +jitter] applied after each retry. ",
            "title": "Retry"
        },
        {
            "location": "se/fault-tolerance",
            "text": " Each Fault Tolerance handler can be individually configured at build time. This is supported by calling the config method on the corresponding builder and specifying a config element. For example, a Timeout handler can be externally configured as follows: <markup lang=\"java\" > Timeout timeout = Timeout.builder() .config(config.get(\"timeout\")) .build(); and using the following config entry: <markup lang=\"yaml\" >timeout: timeout: \"PT20S\" current-thread: true name: \"MyTimeout\" cancel-source: false Note that the actual timeout value is of type Duration , hence the use of PT20S that represents a timeout of 20 seconds. See the Javadoc for the Duration class for more information. The following tables list all the config elements for each type of handler supported by this API. Timeout <div class=\"table__overflow elevation-1 flex sm7 \"> Property Type Description name String A name given to the task for debugging purposes. Default is Timeout-N . timeout Duration The timeout length as a Duration string. Default is PT10S or 10 seconds. current-thread boolean A flag indicating whether the task should execute in the current thread or not. Default is false . cancel-source boolean A flag indicating if this task&#8217;s source should be cancelled if the task is cancelled. Default is true . Circuit Breaker <div class=\"table__overflow elevation-1 flex sm7 \"> Property Type Description name String A name given to the task for debugging purposes. Default is CircuitBreaker-N . delay Duration Delay to transition from half-open state. Default is PT5S or 5 seconds. error-ratio int Failure percentage to transition to open state. Default is 60. volume int Size of rolling window to calculate ratios. Size is 10. success-threshold int Number of successful calls to transition to closed state. Default is 1. cancel-source boolean A flag indicating if this task&#8217;s source should be cancelled if the task is cancelled. Default is true . Bulkhead <div class=\"table__overflow elevation-1 flex sm7 \"> Property Type Description limit int Max number of parallel calls. Default is 10. name String A name given to the task for debugging purposes. Default is Bulkhead-N . queue-length int Length of queue for tasks waiting to enter. Default is 10. cancel-source boolean A flag indicating if this task&#8217;s source should be cancelled if the task is cancelled. Default is true . Retry <div class=\"table__overflow elevation-1 flex sm7 \"> Property Type Description name String A name given to the task for debugging purposes. Default is Retry-N . overall-timeout Duration Timeout for overall retry execution. Default is PT1S or 1 second. delaying-retry-policy Config Config section describing delaying retry policy (see below). jitter-retry-policy Config Config section describing jitter retry policy (see below) cancel-source boolean A flag indicating if this task&#8217;s source should be cancelled if the task is cancelled. Default is true . Delaying Retry Policy <div class=\"table__overflow elevation-1 flex sm7 \"> Property Type Description calls int Number of retry attempts. Default is 3. delay Duration Delay between retries. Default is PT0.2S or 200 milliseconds. delay-factor double A delay multiplication factor applied after each retry. Jitter Retry Policy <div class=\"table__overflow elevation-1 flex sm7 \"> Property Type Description calls int Number of retry attempts. Default is 3. delay Duration Delay between retries. Default is PT0.2S or 200 milliseconds. jitter Duration A random delay additive factor in the range [-jitter, +jitter] applied after each retry. ",
            "title": "Configuration"
        },
        {
            "location": "se/fault-tolerance",
            "text": " See section for examples. ",
            "title": "Examples"
        },
        {
            "location": "se/fault-tolerance",
            "text": " For additional information, see the Fault Tolerance SE API Javadocs . ",
            "title": "Additional Information"
        },
        {
            "location": "se/graphql",
            "text": " Overview Maven Coordinates API Configuration Examples Additional Information ",
            "title": "Contents"
        },
        {
            "location": "se/graphql",
            "text": " The Helidon GraphQL Server provides a framework for creating GraphQL applications that integrate with the Helidon WebServer. GraphQL is a query language to access server data. The Helidon GraphQL integration enables HTTP clients to issue queries over the network and retrieve data; it is an alternative to other protocols such as REST or GRPC. ",
            "title": "Overview"
        },
        {
            "location": "se/graphql",
            "text": " To enable GraphQL add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.graphql&lt;/groupId&gt; &lt;artifactId&gt;helidon-graphql-server&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "se/graphql",
            "text": " An instance of GraphQlSupport must be registered in the Helidon WebServer routes to enable GraphQL support in your application. In addition, a GraphQL schema needs to be specified to verify and execute queries. The following code fragment creates an instance of GraphQlSupport and registers it in the Helidon WebServer. <markup lang=\"java\" > WebServer server = WebServer.builder() .routing(Routing.builder() .register(GraphQlSupport.create(buildSchema())) .build()) .build(); By default, GraphQlSupport will reserve /graphql as the URI path to process queries. The buildSchema method creates the schema and defines 2 types of queries for this application: <markup lang=\"java\" >private static GraphQLSchema buildSchema() { String schema = \"type Query{\" + \"hello: String \" + \"helloInDifferentLanguages: [String] \" + \"}\"; SchemaParser schemaParser = new SchemaParser(); TypeDefinitionRegistry typeDefinitionRegistry = schemaParser.parse(schema); // DataFetcher to return various hellos in difference languages DataFetcher&lt;List&lt;String&gt;&gt; hellosDataFetcher = (DataFetcher&lt;List&lt;String&gt;&gt;) environment -&gt; List.of(\"Bonjour\", \"Hola\", \"Zdravstvuyte\", \"Nǐn hǎo\", \"Salve\", \"Gudday\", \"Konnichiwa\", \"Guten Tag\"); RuntimeWiring runtimeWiring = RuntimeWiring.newRuntimeWiring() .type(\"Query\", builder -&gt; builder.dataFetcher(\"hello\", new StaticDataFetcher(\"world\"))) .type(\"Query\", builder -&gt; builder.dataFetcher(\"helloInDifferentLanguages\", hellosDataFetcher)) .build(); SchemaGenerator schemaGenerator = new SchemaGenerator(); return schemaGenerator.makeExecutableSchema(typeDefinitionRegistry, runtimeWiring); } The following is a description of each of these steps: Define the GraphQL schema. Create a DataFetcher to return a list of hellos in different languages. Wire up the DataFetcher s. Generate the GraphQL schema. ",
            "title": "API"
        },
        {
            "location": "se/graphql",
            "text": " The following configuration keys can be used to set up integration with WebServer: key default value description graphql.web-context /graphql Context that serves the GraphQL endpoint. graphql.schema-uri /schema.graphql URI that serves the schema (under web context) graphql.cors &#160; CORS configuration for this service graphql.executor-service &#160; Configuration of ServerThreadPoolSupplier used to set up executor service The following configuration keys can be used to set up GraphQL invocation: key default value description graphql.default-error-message Server Error Error message to send to caller in case of error graphql.exception-white-list &#160; Array of checked exception classes that should return default error message graphql.exception-black-list &#160; Array of unchecked exception classes that should return message to caller (instead of default error message) ",
            "title": "Configuration"
        },
        {
            "location": "se/graphql",
            "text": " Using the schema defined in Section , you can probe the following endpoints: Hello world endpoint <markup lang=\"bash\" >curl -X POST http://127.0.0.1:PORT/graphql -d '{\"query\":\"query { hello }\"}' \"data\":{\"hello\":\"world\"}} Hello in different languages <markup lang=\"bash\" >curl -X POST http://127.0.0.1:PORT/graphql -d '{\"query\":\"query { helloInDifferentLanguages }\"}' {\"data\":{\"helloInDifferentLanguages\":[\"Bonjour\",\"Hola\",\"Zdravstvuyte\",\"Nǐn hǎo\",\"Salve\",\"Gudday\",\"Konnichiwa\",\"Guten Tag\"]}} ",
            "title": "Examples"
        },
        {
            "location": "se/graphql",
            "text": " GraphQL Javadocs ",
            "title": "Additional Information"
        },
        {
            "location": "se/grpc/client",
            "text": " Overview Maven Coordinates Usage Configuration Examples ",
            "title": "Contents"
        },
        {
            "location": "se/grpc/client",
            "text": " Helidon gRPC client provides a framework for creating gRPC client applications. The client framework allows a uniform way to access gRPC services that use either Protobuf or some custom serialization format. The benefits of using Helidon gRPC client Framework include: It provides a number of helper methods that make client implementation significantly simpler. It allows you to configure some of the Helidon value-added features, such as security , metrics collection and interceptors down to the method level. It allows you to easily specify custom marshallers for requests and responses if protobuf does not satisfy your needs. The class GrpcServiceClient acts as the client object for accessing a gRPC service. Creating a GrpcServiceClient involves: Creating a ClientServiceDescriptor which describes the methods in the service that this client can invoke. Creating a gRPC Channel through which the client communicates with the server. In later sections in this document, you will see how to customize both ClientServiceDescriptor and the Channel . ",
            "title": "Overview"
        },
        {
            "location": "se/grpc/client",
            "text": " To enable gRPC Client add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.grpc&lt;/groupId&gt; &lt;artifactId&gt;helidon-grpc-client&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "se/grpc/client",
            "text": " The first step to create a Helidon gRPC client application is to describe the set of methods in the gRPC service. Helidon gRPC client Framework (simply called the \"Client framework\" in the remainder of the document) provides a class called ClientServiceDescriptor to describe the set of methods of a service that the client may invoke. There are several ways to build and initialize a ClientServiceDescriptor . The first option is to initialize ClientServiceDescriptor using protoc generated artifacts like BindableService or io.grpc.ServiceDescriptor . This option is possible if the gRPC service was built using .proto file. In this case, the set of gRPC methods, their types and the appropriate marshallers are detected automatically. This is certainly the easiest way to initialize a ClientServiceDescriptor . The other option is to programmatically build the ClientServiceDescriptor . This option should be taken if the service was not built from protobuf files or if the protoc generated artifacts are not available to the client. The next step is to create a gRPC Channel to use to communicate with the server. Finally, we create an instance of GrpcServiceClient passing the ClientMethodDescriptor and the Channel instances. ",
            "title": "Client Implementation Basics"
        },
        {
            "location": "se/grpc/client",
            "text": " Let&#8217;s build a class called ProtoBasedStringServiceClient that invokes the various types of gRPC methods that our StringService offers. <markup lang=\"java\" >public class ProtoBasedStringServiceClient { private GrpcServiceClient client; public ProtoBasedStringServiceClient() { ClientServiceDescriptor desc = ClientServiceDescriptor .builder(StringService.getServiceDescriptor()) .build(); Channel channel = ManagedChannelBuilder.forAddress(\"localhost\", 1408) .usePlaintext().build(); this.client = GrpcServiceClient.create(channel, desc); } /** * Many gRPC methods take a {@link io.grpc.StreamObserver} as an argument. Lets * build a helper class that can be used in our example. */ public static class StringMessageStream&lt;T&gt; implements StreamObserver&lt;T&gt; { @Override public void onNext(T value) { System.out.println(\"Received : \" + value); } @Override public void onError(Throwable t) { t.printStracktrace(); } @Override public void onCompleted() { System.out.println(\"DONE\"); } } } Initialize the builder by specifying the StringService&#8217;s proto ServiceDescriptor . From the ServiceDescriptor , the builder detects the service name, the set of method names, the type of each method (like Unary, ServerStreaming, etc.), the request and response types (and hence their corresponding Marshallers), etc. We create a Channel to the service that is running on localhost:1408 . Finally, we create our GrpcServiceClient by using the above mentioned ClientServiceDescriptor . and Channel . This client reference will be used to invoke various gRPC methods in our StringService . We define a static inner class that implements the io.grpc.StreamObserver interface. An instance of this class can be used wherever a io.grpc.StreamObserver is required (like server streaming, bi-directional streaming methods). ",
            "title": "Creating and initializing a ClientServiceDescriptor for StringService (generated from protoc )"
        },
        {
            "location": "se/grpc/client",
            "text": " The Client Framework provides many helper methods to invoke gRPC unary methods. <markup lang=\"java\" >public class ProtoBasedStringServiceClient { private GrpcServiceClient client; public ProtoBasedStringServiceClient() { /* code omitted */ } public void invokeUnaryMethod() throws Exception { StringMessage input = StringMessage.newBuilder().setText(\"ABC\").build(); CompletableFuture&lt;String&gt; result = client.unary(\"Lower\", input); String lcase = client.blockingUnary(\"Lower\", input); StringMessageStream stream = new StringMessageStream&lt;StringMessage&gt;(); client.blockingUnary(\"Lower\", stream); } public static class StringMessageStream&lt;T&gt; { /* code omitted */ } } This variant of the unary API takes the method name and a request object and returns a CompletableFuture&lt;Response&gt; where &lt;Response&gt; is the response type. Here we invoke the Lower method passing the input StringMessage . This method returns a CompletableFuture&lt;StringMessage&gt; as its response thus allowing the client to obtain the result asynchronously. This is simply a wrapper around the above method. This method blocks until the result is available. Here, we invoke the unary method by passing the StringMessageStream whose onNext method will be called (once) when the result is available. ",
            "title": "Invoking a unary method on the StringService"
        },
        {
            "location": "se/grpc/client",
            "text": " Let&#8217;s invoke the Join method which causes the server to return a single result after the client has streamed the request values to the server. The gRPC API expects the client application to provide an instance of io.grpc.StreamObserver as an argument during the invocation of the client streaming method. In order to simplify the task of invoking Client Streaming methods, the Helidon Client Framework provides two methods to invoke gRPC client Streaming methods. The first variant takes an Iterable as argument which in turn is converted into a io.grpc.StreamObserver . The second variant takes a io.grpc.StreamObserver as argument. The first variant can be used if the number of values to be streamed in small and known a priori. <markup lang=\"java\" >public class ProtoBasedStringServiceClient { private GrpcServiceClient client; public ProtoBasedStringServiceClient() { /* code omitted */ } public void invokeClientStreamingWithIterable() throws Exception { String sentence = \"A simple invocation of a client streaming method\"; Collection&lt;StringMessage&gt; input = Arrays.stream(sentence.split(\" \")) .map(w -&gt; StringMessage.newBuilder().setText(w).build()) .collect(Collectors.toList()); CompletableFuture&lt;StringMessage&gt; result = grpcClient.clientStreaming(\"Join\", input); } public void invokeClientStreaming() throws Exception { String sentence = \"A simple invocation of a client streaming method\"; StringMessageStream responseStream = new StringMessageStream&lt;StringMessage&gt;(); StreamObserver&lt;StringMessage&gt; clientStream = grpcClient.clientStreaming(\"Join\", responseStream); for (String word : sentence.split(\" \")) { clientStream.onNext(StringMessage.newBuilder().setText(word).build()); } clientStream.onCompleted(); } public static class StringMessageStream&lt;T&gt; { /* code is omitted */ } } We prepare the collection that contains the values to be streamed. We call the first variant of the clientStreaming() method that takes the method name and the collection of values to be streamed from the client. Note: The above helper method is useful if the values to be streamed is fixed and small in number. If the number of values to be streamed is large (or unknown), then it is better to use this variant of the clientStreaming() method that takes a io.grpc.StreamObserver as an argument. This method returns a client stream through which the client can stream (potentially a large number of) value to the server. Once the client stream is obtained, the client streams the values using the onNext() method on the stream. When all values have been stream, the client invokes the onCompleted() method signal that all values have been streamed from the client. ",
            "title": "Invoking a client streaming method on the StringService"
        },
        {
            "location": "se/grpc/client",
            "text": " As mentioned above, the easiest way to create a ClientServiceDescriptor is to create it from an io.grpc.ServiceDescriptor or from a io.grpc.BindableService . It is fairly trivial to obtain these from a service generated from artifacts generated from protobuf IDL file. For this section we will assume the following proto file: <markup lang=\"proto\" >syntax = \"proto3\"; option java_package = \"io.helidon.grpc.client.test\"; service StringService { rpc Upper (StringMessage) returns (StringMessage) {} // (Unary) rpc Lower (StringMessage) returns (StringMessage) {} // (Unary) rpc Split (StringMessage) returns (stream StringMessage) {} // (Server Streaming) rpc Join (stream StringMessage) returns (StringMessage) {} // (Client Streaming) rpc Echo (stream StringMessage) returns (stream StringMessage) {} // (Bidirectional Streaming) } message StringMessage { string text = 1; } If you run it through protoc , it will generate a class (among other things) called StringService . Assuming that the StringService server is running on port 1408, here is how you can create a Helidon gRPC Client that uses the Client Framework to invoke various types of gRPC methods. Creating and initializing a ClientServiceDescriptor for StringService (generated from protoc ) Let&#8217;s build a class called ProtoBasedStringServiceClient that invokes the various types of gRPC methods that our StringService offers. <markup lang=\"java\" >public class ProtoBasedStringServiceClient { private GrpcServiceClient client; public ProtoBasedStringServiceClient() { ClientServiceDescriptor desc = ClientServiceDescriptor .builder(StringService.getServiceDescriptor()) .build(); Channel channel = ManagedChannelBuilder.forAddress(\"localhost\", 1408) .usePlaintext().build(); this.client = GrpcServiceClient.create(channel, desc); } /** * Many gRPC methods take a {@link io.grpc.StreamObserver} as an argument. Lets * build a helper class that can be used in our example. */ public static class StringMessageStream&lt;T&gt; implements StreamObserver&lt;T&gt; { @Override public void onNext(T value) { System.out.println(\"Received : \" + value); } @Override public void onError(Throwable t) { t.printStracktrace(); } @Override public void onCompleted() { System.out.println(\"DONE\"); } } } Initialize the builder by specifying the StringService&#8217;s proto ServiceDescriptor . From the ServiceDescriptor , the builder detects the service name, the set of method names, the type of each method (like Unary, ServerStreaming, etc.), the request and response types (and hence their corresponding Marshallers), etc. We create a Channel to the service that is running on localhost:1408 . Finally, we create our GrpcServiceClient by using the above mentioned ClientServiceDescriptor . and Channel . This client reference will be used to invoke various gRPC methods in our StringService . We define a static inner class that implements the io.grpc.StreamObserver interface. An instance of this class can be used wherever a io.grpc.StreamObserver is required (like server streaming, bi-directional streaming methods). Invoking a unary method on the StringService The Client Framework provides many helper methods to invoke gRPC unary methods. <markup lang=\"java\" >public class ProtoBasedStringServiceClient { private GrpcServiceClient client; public ProtoBasedStringServiceClient() { /* code omitted */ } public void invokeUnaryMethod() throws Exception { StringMessage input = StringMessage.newBuilder().setText(\"ABC\").build(); CompletableFuture&lt;String&gt; result = client.unary(\"Lower\", input); String lcase = client.blockingUnary(\"Lower\", input); StringMessageStream stream = new StringMessageStream&lt;StringMessage&gt;(); client.blockingUnary(\"Lower\", stream); } public static class StringMessageStream&lt;T&gt; { /* code omitted */ } } This variant of the unary API takes the method name and a request object and returns a CompletableFuture&lt;Response&gt; where &lt;Response&gt; is the response type. Here we invoke the Lower method passing the input StringMessage . This method returns a CompletableFuture&lt;StringMessage&gt; as its response thus allowing the client to obtain the result asynchronously. This is simply a wrapper around the above method. This method blocks until the result is available. Here, we invoke the unary method by passing the StringMessageStream whose onNext method will be called (once) when the result is available. Invoking a client streaming method on the StringService Let&#8217;s invoke the Join method which causes the server to return a single result after the client has streamed the request values to the server. The gRPC API expects the client application to provide an instance of io.grpc.StreamObserver as an argument during the invocation of the client streaming method. In order to simplify the task of invoking Client Streaming methods, the Helidon Client Framework provides two methods to invoke gRPC client Streaming methods. The first variant takes an Iterable as argument which in turn is converted into a io.grpc.StreamObserver . The second variant takes a io.grpc.StreamObserver as argument. The first variant can be used if the number of values to be streamed in small and known a priori. <markup lang=\"java\" >public class ProtoBasedStringServiceClient { private GrpcServiceClient client; public ProtoBasedStringServiceClient() { /* code omitted */ } public void invokeClientStreamingWithIterable() throws Exception { String sentence = \"A simple invocation of a client streaming method\"; Collection&lt;StringMessage&gt; input = Arrays.stream(sentence.split(\" \")) .map(w -&gt; StringMessage.newBuilder().setText(w).build()) .collect(Collectors.toList()); CompletableFuture&lt;StringMessage&gt; result = grpcClient.clientStreaming(\"Join\", input); } public void invokeClientStreaming() throws Exception { String sentence = \"A simple invocation of a client streaming method\"; StringMessageStream responseStream = new StringMessageStream&lt;StringMessage&gt;(); StreamObserver&lt;StringMessage&gt; clientStream = grpcClient.clientStreaming(\"Join\", responseStream); for (String word : sentence.split(\" \")) { clientStream.onNext(StringMessage.newBuilder().setText(word).build()); } clientStream.onCompleted(); } public static class StringMessageStream&lt;T&gt; { /* code is omitted */ } } We prepare the collection that contains the values to be streamed. We call the first variant of the clientStreaming() method that takes the method name and the collection of values to be streamed from the client. Note: The above helper method is useful if the values to be streamed is fixed and small in number. If the number of values to be streamed is large (or unknown), then it is better to use this variant of the clientStreaming() method that takes a io.grpc.StreamObserver as an argument. This method returns a client stream through which the client can stream (potentially a large number of) value to the server. Once the client stream is obtained, the client streams the values using the onNext() method on the stream. When all values have been stream, the client invokes the onCompleted() method signal that all values have been streamed from the client. ",
            "title": "Creating gRPC clients from protoc generated artifacts"
        },
        {
            "location": "se/grpc/client",
            "text": " Let&#8217;s invoke the \"Split\" method which causes the server to stream the results back. <markup lang=\"java\" >public class ProtoBasedStringServiceClient { private GrpcServiceClient client; public ProtoBasedStringServiceClient() { /* code omitted */ } public void invokeServerStreaming() throws Exception { String sentence = \"This sentence will be split into words and sent back to client\"; StringMessage input = StringMessage.newBuilder().setText(sentence).build(); StringMessageStream&lt;StringMessage&gt; observer = new StringMessageStream&lt;&gt;(); grpcClient.serverStreaming(\"Split\", input, observer); } public static class StringMessageStream&lt;T&gt; { /* code is omitted */ } } We prepare the input StringMessage that needs to be split. We create a StringMessageStream which will receive the results streamed from the server. We call the serverStreaming() passing the input and the StringMessageStream as arguments. The server sends a stream of words by calling the onNext() method on the StringMessageStream for each word. ",
            "title": "Invoking a server streaming method on the StringService (generated from protoc )"
        },
        {
            "location": "se/grpc/client",
            "text": " Now let&#8217;s invoke the Echo method in which both the client and the server have to stream the request and response. <markup lang=\"java\" >public class ProtoBasedStringServiceClient { private GrpcServiceClient client; public ProtoBasedStringServiceClient() { /* code omitted */ } public void invokeBidiStreaming() throws Exception { StringMessageStream&lt;StringMessage&gt; observer = new StringMessageStream&lt;&gt;(); StringMessageStream&lt;StringMessage&gt; clientStream = grpcClient .bidiStreaming(\"Echo\", observer); String sentence = \"Each word will be echoed back to the client by the server\"; for (String word : sentence.split(\" \")) { clientStream.onNext(StringMessage.newBuilder().setText(word).build()); } clientStream.onCompleted(); } public static class StringMessageStream&lt;T&gt; { /* code is omitted */ } } We create a StringMessageStream which will receive the results streamed from the server. We call the bidiStreaming() passing the observer as argument. The server will send its results through this stream (basically by calling the onNext() on the observer ). The method returns a (client) stream which should be used by the client to stream values to the server. We stream each word in our sentence to the server by calling the onNext() method on the clientStream . We call the onCompleted() method on the clientStream to signal that the client has streamed all its values. ",
            "title": "Invoking a bi-directional streaming method on the StringService (generated from protoc )"
        },
        {
            "location": "se/grpc/client",
            "text": " Assuming that the service is still running on port 1408, let&#8217;s see how to create our Client without using the StringService 's proto ServiceDescriptor . Since we are not going to use the StringService 's proto ServiceDescriptor , we need to describe the methods that the client needs to invoke. The Helidon client framework provides several methods to easily describe gRPC methods. For example, to register a unary method, we need to use the unary method and configure it to specify the request and response types. Other than describing the methods that our client will invoke, the rest of the code should be very similar to (or the same as) the previous section!! <markup lang=\"java\" >public class StringServiceClient { public static void main(String[] args) { ClientMethodDescriptor lower = ClientMethodDescriptor .unary(\"StringService\", \"Lower\") .requestType(StringMessage.class) .responseType(StringMessage.class) .build(); ClientMethodDescriptor join = ClientMethodDescriptor .clientStreaming(\"StringService\", \"Join\") .requestType(StringMessage.class) .responseType(StringMessage.class) .build(); ClientMethodDescriptor split = ClientMethodDescriptor .serverStreaming(\"StringService\", \"Split\") .requestType(StringMessage.class) .responseType(StringMessage.class) .build(); ClientMethodDescriptor echo = ClientMethodDescriptor .bidirectional(\"StringService\", \"Echo\") .requestType(StringMessage.class) .responseType(StringMessage.class) .build(); ClientServiceDescriptor serviceDesc = ClientServiceDescriptor .builder(StringService.class) .unary(lower) .clientStreaming(join) .serverStreaming(split) .bidirectional(echo) .build(); Channel channel = ManagedChannelBuilder.forAddress(\"localhost\", 1408) .usePlaintext().build(); GrpcServiceClient client = GrpcServiceClient.create(channel, serviceDesc); // ( } } Use the unary() method on ClientMethodDescriptor to create a builder for a gRPC unary method. The service name and the method name (\"Lower\") are specified. Set the request type of the method to be StringMessage (since the Lower method takes StringMessage as a parameter). Set the response type of the method to be StringMessage (since the Lower method returns a StringMessage as a parameter). Build the ClientMethodDescriptor . Note that the return value is a ClientMethodDescriptor that contains the correct marshaller for the request &amp; response types. Use the clientStreaming() method on ClientMethodDescriptor to create a builder for a gRPC client streaming method. The service name and the method name (\"Join\") are specified. Use the serverStreaming() method on ClientMethodDescriptor to create a builder for a gRPC server streaming method. The service name and the method name (\"Split\") are specified. Use the bidirectional() method on ClientMethodDescriptor to create a builder for a gRPC Bidi streaming method. The service name and the method name (\"Echo\") are specified. Create a ClientServiceDescriptor for a service named StringService and add all the defined ClientMethodDescriptor s. We create a Channel to the service that is running on localhost:1408 . Finally, we create our GrpcServiceClient by using the above-mentioned ClientServiceDescriptor and Channel . At this point the client object can be used to invoke any of the four types of methods we have seen in the earlier sections. ",
            "title": "Programmatically creating ClientServiceDescriptor for StringService"
        },
        {
            "location": "se/grpc/client",
            "text": " If your service is not using protobuf for serialization, then the client framework allows you to programmatically initialize ClientMethodDescriptor and create clients to invoke methods on the service. All you have to do is create the set of ClientMethodDescriptor s and the ClientServiceDescriptor as described in the previous section. Just do not set the request and response types in the ClientMethodDescriptor anymore. Furthermore, there is an API in the ClientServiceDescriptor that makes this even simpler where you can simply pass the method name. For example, to create a client streaming method called \"JoinString\" that uses some custom marshalling, simply call the clientStreaming(\"JoinString\") . <markup lang=\"java\" >public static void main(String[] args) throws Exception { ClientServiceDescriptor descriptor = ClientServiceDescriptor.builder(HelloService.class) .marshallerSupplier(new JsonbMarshaller.Supplier()) .clientStreaming(\"JoinString\") .build(); Channel channel = ManagedChannelBuilder.forAddress(\"localhost\", 1408) .usePlaintext() .build(); GrpcServiceClient client = GrpcServiceClient.create(channel, descriptor); String sentence = \"A simple invocation of a client streaming method\"; Collection&lt;StringMessage&gt; input = Arrays.stream(sentence.split(\" \")) .map(w -&gt; StringMessage.newBuilder().setText(w).build()) .collect(Collectors.toList()); CompletableFuture&lt;StringMessage&gt; result = grpcClient.clientStreaming(\"Join\", input); } Create a ClientServiceDescriptor for the HelloService . Specify a custom marshaller using the built-in JSON-B marshaller to serialize/deserialize requests and responses. Add the \"JoinString\" client streaming method to the ClientServiceDescriptor . Since we didn&#8217;t set the request or response type (like we did in the previous sections), the custom marshaller will be used for Marshalling and Unmarshalling the request and response values. Note that whether a ClientServiceDescriptor is built using protobuf artifacts or is built programmatically, the same set of APIs provided by the Client Framework can be used to invoke gRPC methods. ",
            "title": "Creating gRPC clients for non-protobuf services"
        },
        {
            "location": "se/grpc/client",
            "text": " Helidon gRPC supports Protobuf out of the box. The Protobuf marshaller will be used by default for any request and response classes that extend com.google.protobuf.MessageLite , which is the case for all classes generated from a proto file using protoc compiler. That means that you don&#8217;t need any special handling or configuration in order to support Protobuf serialization of requests and responses. ",
            "title": "Default Marshalling Support"
        },
        {
            "location": "se/grpc/client",
            "text": " You can set the custom marshaller supplier via the ClientServiceDescriptor.builder.marshallerSupplier() method: <markup lang=\"java\" title=\"Sample code for setting the marshaller on the ClientServiceDescriptor\" >ClientServiceDescriptor descriptor = ClientServiceDescriptor .builder(HelloService.class) .marshallerSupplier(new JsonbMarshaller.Supplier()) .clientStreaming(\"JoinString\") .build(); Specify the custom marshaller to use. ",
            "title": "Setting the custom marshaller"
        },
        {
            "location": "se/grpc/client",
            "text": " Helidon makes the use of custom marshallers trivial and provides one custom implementation, JsonbMarshaller , out of the box. You can also easily implement your own marshaller to support serialization formats that are not supported natively by Helidon, by implementing Marshaller and MarshallerSupplier interfaces. As an example, check out the source code of the built-in marshaller: JsonbMarshaller.java . Furthermore, Oracle Coherence CE provides a marshaller for a highly optimized, binary, platform independent Portable Object Format (POF). You can find more information about POF in Coherence documentation Setting the custom marshaller You can set the custom marshaller supplier via the ClientServiceDescriptor.builder.marshallerSupplier() method: <markup lang=\"java\" title=\"Sample code for setting the marshaller on the ClientServiceDescriptor\" >ClientServiceDescriptor descriptor = ClientServiceDescriptor .builder(HelloService.class) .marshallerSupplier(new JsonbMarshaller.Supplier()) .clientStreaming(\"JoinString\") .build(); Specify the custom marshaller to use. ",
            "title": "Custom Marshalling"
        },
        {
            "location": "se/grpc/client",
            "text": " Default Marshalling Support Helidon gRPC supports Protobuf out of the box. The Protobuf marshaller will be used by default for any request and response classes that extend com.google.protobuf.MessageLite , which is the case for all classes generated from a proto file using protoc compiler. That means that you don&#8217;t need any special handling or configuration in order to support Protobuf serialization of requests and responses. Custom Marshalling Helidon makes the use of custom marshallers trivial and provides one custom implementation, JsonbMarshaller , out of the box. You can also easily implement your own marshaller to support serialization formats that are not supported natively by Helidon, by implementing Marshaller and MarshallerSupplier interfaces. As an example, check out the source code of the built-in marshaller: JsonbMarshaller.java . Furthermore, Oracle Coherence CE provides a marshaller for a highly optimized, binary, platform independent Portable Object Format (POF). You can find more information about POF in Coherence documentation Setting the custom marshaller You can set the custom marshaller supplier via the ClientServiceDescriptor.builder.marshallerSupplier() method: <markup lang=\"java\" title=\"Sample code for setting the marshaller on the ClientServiceDescriptor\" >ClientServiceDescriptor descriptor = ClientServiceDescriptor .builder(HelloService.class) .marshallerSupplier(new JsonbMarshaller.Supplier()) .clientStreaming(\"JoinString\") .build(); Specify the custom marshaller to use. ",
            "title": "Marshalling"
        },
        {
            "location": "se/grpc/client",
            "text": " Client Implementation Basics The first step to create a Helidon gRPC client application is to describe the set of methods in the gRPC service. Helidon gRPC client Framework (simply called the \"Client framework\" in the remainder of the document) provides a class called ClientServiceDescriptor to describe the set of methods of a service that the client may invoke. There are several ways to build and initialize a ClientServiceDescriptor . The first option is to initialize ClientServiceDescriptor using protoc generated artifacts like BindableService or io.grpc.ServiceDescriptor . This option is possible if the gRPC service was built using .proto file. In this case, the set of gRPC methods, their types and the appropriate marshallers are detected automatically. This is certainly the easiest way to initialize a ClientServiceDescriptor . The other option is to programmatically build the ClientServiceDescriptor . This option should be taken if the service was not built from protobuf files or if the protoc generated artifacts are not available to the client. The next step is to create a gRPC Channel to use to communicate with the server. Finally, we create an instance of GrpcServiceClient passing the ClientMethodDescriptor and the Channel instances. Creating gRPC clients from protoc generated artifacts As mentioned above, the easiest way to create a ClientServiceDescriptor is to create it from an io.grpc.ServiceDescriptor or from a io.grpc.BindableService . It is fairly trivial to obtain these from a service generated from artifacts generated from protobuf IDL file. For this section we will assume the following proto file: <markup lang=\"proto\" >syntax = \"proto3\"; option java_package = \"io.helidon.grpc.client.test\"; service StringService { rpc Upper (StringMessage) returns (StringMessage) {} // (Unary) rpc Lower (StringMessage) returns (StringMessage) {} // (Unary) rpc Split (StringMessage) returns (stream StringMessage) {} // (Server Streaming) rpc Join (stream StringMessage) returns (StringMessage) {} // (Client Streaming) rpc Echo (stream StringMessage) returns (stream StringMessage) {} // (Bidirectional Streaming) } message StringMessage { string text = 1; } If you run it through protoc , it will generate a class (among other things) called StringService . Assuming that the StringService server is running on port 1408, here is how you can create a Helidon gRPC Client that uses the Client Framework to invoke various types of gRPC methods. Creating and initializing a ClientServiceDescriptor for StringService (generated from protoc ) Let&#8217;s build a class called ProtoBasedStringServiceClient that invokes the various types of gRPC methods that our StringService offers. <markup lang=\"java\" >public class ProtoBasedStringServiceClient { private GrpcServiceClient client; public ProtoBasedStringServiceClient() { ClientServiceDescriptor desc = ClientServiceDescriptor .builder(StringService.getServiceDescriptor()) .build(); Channel channel = ManagedChannelBuilder.forAddress(\"localhost\", 1408) .usePlaintext().build(); this.client = GrpcServiceClient.create(channel, desc); } /** * Many gRPC methods take a {@link io.grpc.StreamObserver} as an argument. Lets * build a helper class that can be used in our example. */ public static class StringMessageStream&lt;T&gt; implements StreamObserver&lt;T&gt; { @Override public void onNext(T value) { System.out.println(\"Received : \" + value); } @Override public void onError(Throwable t) { t.printStracktrace(); } @Override public void onCompleted() { System.out.println(\"DONE\"); } } } Initialize the builder by specifying the StringService&#8217;s proto ServiceDescriptor . From the ServiceDescriptor , the builder detects the service name, the set of method names, the type of each method (like Unary, ServerStreaming, etc.), the request and response types (and hence their corresponding Marshallers), etc. We create a Channel to the service that is running on localhost:1408 . Finally, we create our GrpcServiceClient by using the above mentioned ClientServiceDescriptor . and Channel . This client reference will be used to invoke various gRPC methods in our StringService . We define a static inner class that implements the io.grpc.StreamObserver interface. An instance of this class can be used wherever a io.grpc.StreamObserver is required (like server streaming, bi-directional streaming methods). Invoking a unary method on the StringService The Client Framework provides many helper methods to invoke gRPC unary methods. <markup lang=\"java\" >public class ProtoBasedStringServiceClient { private GrpcServiceClient client; public ProtoBasedStringServiceClient() { /* code omitted */ } public void invokeUnaryMethod() throws Exception { StringMessage input = StringMessage.newBuilder().setText(\"ABC\").build(); CompletableFuture&lt;String&gt; result = client.unary(\"Lower\", input); String lcase = client.blockingUnary(\"Lower\", input); StringMessageStream stream = new StringMessageStream&lt;StringMessage&gt;(); client.blockingUnary(\"Lower\", stream); } public static class StringMessageStream&lt;T&gt; { /* code omitted */ } } This variant of the unary API takes the method name and a request object and returns a CompletableFuture&lt;Response&gt; where &lt;Response&gt; is the response type. Here we invoke the Lower method passing the input StringMessage . This method returns a CompletableFuture&lt;StringMessage&gt; as its response thus allowing the client to obtain the result asynchronously. This is simply a wrapper around the above method. This method blocks until the result is available. Here, we invoke the unary method by passing the StringMessageStream whose onNext method will be called (once) when the result is available. Invoking a client streaming method on the StringService Let&#8217;s invoke the Join method which causes the server to return a single result after the client has streamed the request values to the server. The gRPC API expects the client application to provide an instance of io.grpc.StreamObserver as an argument during the invocation of the client streaming method. In order to simplify the task of invoking Client Streaming methods, the Helidon Client Framework provides two methods to invoke gRPC client Streaming methods. The first variant takes an Iterable as argument which in turn is converted into a io.grpc.StreamObserver . The second variant takes a io.grpc.StreamObserver as argument. The first variant can be used if the number of values to be streamed in small and known a priori. <markup lang=\"java\" >public class ProtoBasedStringServiceClient { private GrpcServiceClient client; public ProtoBasedStringServiceClient() { /* code omitted */ } public void invokeClientStreamingWithIterable() throws Exception { String sentence = \"A simple invocation of a client streaming method\"; Collection&lt;StringMessage&gt; input = Arrays.stream(sentence.split(\" \")) .map(w -&gt; StringMessage.newBuilder().setText(w).build()) .collect(Collectors.toList()); CompletableFuture&lt;StringMessage&gt; result = grpcClient.clientStreaming(\"Join\", input); } public void invokeClientStreaming() throws Exception { String sentence = \"A simple invocation of a client streaming method\"; StringMessageStream responseStream = new StringMessageStream&lt;StringMessage&gt;(); StreamObserver&lt;StringMessage&gt; clientStream = grpcClient.clientStreaming(\"Join\", responseStream); for (String word : sentence.split(\" \")) { clientStream.onNext(StringMessage.newBuilder().setText(word).build()); } clientStream.onCompleted(); } public static class StringMessageStream&lt;T&gt; { /* code is omitted */ } } We prepare the collection that contains the values to be streamed. We call the first variant of the clientStreaming() method that takes the method name and the collection of values to be streamed from the client. Note: The above helper method is useful if the values to be streamed is fixed and small in number. If the number of values to be streamed is large (or unknown), then it is better to use this variant of the clientStreaming() method that takes a io.grpc.StreamObserver as an argument. This method returns a client stream through which the client can stream (potentially a large number of) value to the server. Once the client stream is obtained, the client streams the values using the onNext() method on the stream. When all values have been stream, the client invokes the onCompleted() method signal that all values have been streamed from the client. Invoking a server streaming method on the StringService (generated from protoc ) Let&#8217;s invoke the \"Split\" method which causes the server to stream the results back. <markup lang=\"java\" >public class ProtoBasedStringServiceClient { private GrpcServiceClient client; public ProtoBasedStringServiceClient() { /* code omitted */ } public void invokeServerStreaming() throws Exception { String sentence = \"This sentence will be split into words and sent back to client\"; StringMessage input = StringMessage.newBuilder().setText(sentence).build(); StringMessageStream&lt;StringMessage&gt; observer = new StringMessageStream&lt;&gt;(); grpcClient.serverStreaming(\"Split\", input, observer); } public static class StringMessageStream&lt;T&gt; { /* code is omitted */ } } We prepare the input StringMessage that needs to be split. We create a StringMessageStream which will receive the results streamed from the server. We call the serverStreaming() passing the input and the StringMessageStream as arguments. The server sends a stream of words by calling the onNext() method on the StringMessageStream for each word. Invoking a bi-directional streaming method on the StringService (generated from protoc ) Now let&#8217;s invoke the Echo method in which both the client and the server have to stream the request and response. <markup lang=\"java\" >public class ProtoBasedStringServiceClient { private GrpcServiceClient client; public ProtoBasedStringServiceClient() { /* code omitted */ } public void invokeBidiStreaming() throws Exception { StringMessageStream&lt;StringMessage&gt; observer = new StringMessageStream&lt;&gt;(); StringMessageStream&lt;StringMessage&gt; clientStream = grpcClient .bidiStreaming(\"Echo\", observer); String sentence = \"Each word will be echoed back to the client by the server\"; for (String word : sentence.split(\" \")) { clientStream.onNext(StringMessage.newBuilder().setText(word).build()); } clientStream.onCompleted(); } public static class StringMessageStream&lt;T&gt; { /* code is omitted */ } } We create a StringMessageStream which will receive the results streamed from the server. We call the bidiStreaming() passing the observer as argument. The server will send its results through this stream (basically by calling the onNext() on the observer ). The method returns a (client) stream which should be used by the client to stream values to the server. We stream each word in our sentence to the server by calling the onNext() method on the clientStream . We call the onCompleted() method on the clientStream to signal that the client has streamed all its values. Programmatically creating ClientServiceDescriptor for StringService Assuming that the service is still running on port 1408, let&#8217;s see how to create our Client without using the StringService 's proto ServiceDescriptor . Since we are not going to use the StringService 's proto ServiceDescriptor , we need to describe the methods that the client needs to invoke. The Helidon client framework provides several methods to easily describe gRPC methods. For example, to register a unary method, we need to use the unary method and configure it to specify the request and response types. Other than describing the methods that our client will invoke, the rest of the code should be very similar to (or the same as) the previous section!! <markup lang=\"java\" >public class StringServiceClient { public static void main(String[] args) { ClientMethodDescriptor lower = ClientMethodDescriptor .unary(\"StringService\", \"Lower\") .requestType(StringMessage.class) .responseType(StringMessage.class) .build(); ClientMethodDescriptor join = ClientMethodDescriptor .clientStreaming(\"StringService\", \"Join\") .requestType(StringMessage.class) .responseType(StringMessage.class) .build(); ClientMethodDescriptor split = ClientMethodDescriptor .serverStreaming(\"StringService\", \"Split\") .requestType(StringMessage.class) .responseType(StringMessage.class) .build(); ClientMethodDescriptor echo = ClientMethodDescriptor .bidirectional(\"StringService\", \"Echo\") .requestType(StringMessage.class) .responseType(StringMessage.class) .build(); ClientServiceDescriptor serviceDesc = ClientServiceDescriptor .builder(StringService.class) .unary(lower) .clientStreaming(join) .serverStreaming(split) .bidirectional(echo) .build(); Channel channel = ManagedChannelBuilder.forAddress(\"localhost\", 1408) .usePlaintext().build(); GrpcServiceClient client = GrpcServiceClient.create(channel, serviceDesc); // ( } } Use the unary() method on ClientMethodDescriptor to create a builder for a gRPC unary method. The service name and the method name (\"Lower\") are specified. Set the request type of the method to be StringMessage (since the Lower method takes StringMessage as a parameter). Set the response type of the method to be StringMessage (since the Lower method returns a StringMessage as a parameter). Build the ClientMethodDescriptor . Note that the return value is a ClientMethodDescriptor that contains the correct marshaller for the request &amp; response types. Use the clientStreaming() method on ClientMethodDescriptor to create a builder for a gRPC client streaming method. The service name and the method name (\"Join\") are specified. Use the serverStreaming() method on ClientMethodDescriptor to create a builder for a gRPC server streaming method. The service name and the method name (\"Split\") are specified. Use the bidirectional() method on ClientMethodDescriptor to create a builder for a gRPC Bidi streaming method. The service name and the method name (\"Echo\") are specified. Create a ClientServiceDescriptor for a service named StringService and add all the defined ClientMethodDescriptor s. We create a Channel to the service that is running on localhost:1408 . Finally, we create our GrpcServiceClient by using the above-mentioned ClientServiceDescriptor and Channel . At this point the client object can be used to invoke any of the four types of methods we have seen in the earlier sections. Creating gRPC clients for non-protobuf services If your service is not using protobuf for serialization, then the client framework allows you to programmatically initialize ClientMethodDescriptor and create clients to invoke methods on the service. All you have to do is create the set of ClientMethodDescriptor s and the ClientServiceDescriptor as described in the previous section. Just do not set the request and response types in the ClientMethodDescriptor anymore. Furthermore, there is an API in the ClientServiceDescriptor that makes this even simpler where you can simply pass the method name. For example, to create a client streaming method called \"JoinString\" that uses some custom marshalling, simply call the clientStreaming(\"JoinString\") . <markup lang=\"java\" >public static void main(String[] args) throws Exception { ClientServiceDescriptor descriptor = ClientServiceDescriptor.builder(HelloService.class) .marshallerSupplier(new JsonbMarshaller.Supplier()) .clientStreaming(\"JoinString\") .build(); Channel channel = ManagedChannelBuilder.forAddress(\"localhost\", 1408) .usePlaintext() .build(); GrpcServiceClient client = GrpcServiceClient.create(channel, descriptor); String sentence = \"A simple invocation of a client streaming method\"; Collection&lt;StringMessage&gt; input = Arrays.stream(sentence.split(\" \")) .map(w -&gt; StringMessage.newBuilder().setText(w).build()) .collect(Collectors.toList()); CompletableFuture&lt;StringMessage&gt; result = grpcClient.clientStreaming(\"Join\", input); } Create a ClientServiceDescriptor for the HelloService . Specify a custom marshaller using the built-in JSON-B marshaller to serialize/deserialize requests and responses. Add the \"JoinString\" client streaming method to the ClientServiceDescriptor . Since we didn&#8217;t set the request or response type (like we did in the previous sections), the custom marshaller will be used for Marshalling and Unmarshalling the request and response values. Note that whether a ClientServiceDescriptor is built using protobuf artifacts or is built programmatically, the same set of APIs provided by the Client Framework can be used to invoke gRPC methods. Marshalling Default Marshalling Support Helidon gRPC supports Protobuf out of the box. The Protobuf marshaller will be used by default for any request and response classes that extend com.google.protobuf.MessageLite , which is the case for all classes generated from a proto file using protoc compiler. That means that you don&#8217;t need any special handling or configuration in order to support Protobuf serialization of requests and responses. Custom Marshalling Helidon makes the use of custom marshallers trivial and provides one custom implementation, JsonbMarshaller , out of the box. You can also easily implement your own marshaller to support serialization formats that are not supported natively by Helidon, by implementing Marshaller and MarshallerSupplier interfaces. As an example, check out the source code of the built-in marshaller: JsonbMarshaller.java . Furthermore, Oracle Coherence CE provides a marshaller for a highly optimized, binary, platform independent Portable Object Format (POF). You can find more information about POF in Coherence documentation Setting the custom marshaller You can set the custom marshaller supplier via the ClientServiceDescriptor.builder.marshallerSupplier() method: <markup lang=\"java\" title=\"Sample code for setting the marshaller on the ClientServiceDescriptor\" >ClientServiceDescriptor descriptor = ClientServiceDescriptor .builder(HelloService.class) .marshallerSupplier(new JsonbMarshaller.Supplier()) .clientStreaming(\"JoinString\") .build(); Specify the custom marshaller to use. ",
            "title": "Usage"
        },
        {
            "location": "se/grpc/client",
            "text": " The only way to configure the ClientServiceDescriptor is in your application code. <markup lang=\"java\" >ClientServiceDescriptor descriptor = ClientServiceDescriptor .builder(HelloService.class) .unary(\"SayHello\") .build(); Create a builder for a ClientServiceDescriptor for the HelloService . Specify that the HelloService has a unary method named SayHello . There are many other methods in this class that allow you to define ClientStreaming , ServerStreaming and Bidirectional methods. Build the ClientServiceDescriptor . ",
            "title": "Configuring the ClientServiceDescriptor"
        },
        {
            "location": "se/grpc/client",
            "text": " gRPC allows various channel configurations (deadlines, retries, interceptors etc.) Please refer to gRPC documentation: https://grpc.io/grpc-java/javadoc/io/grpc/ManagedChannelBuilder.html . ",
            "title": "Configuring the gRPC Channel"
        },
        {
            "location": "se/grpc/client",
            "text": " Configure the gRPC client using the Helidon configuration framework, either programmatically or via a configuration file. As mentioned earlier, creating a GrpcServiceClient involves: Creating a ClientServiceDescriptor which describes the methods in the service that this client can invoke. Creating a gRPC Channel through which the client communicates with the server. Configuring the ClientServiceDescriptor The only way to configure the ClientServiceDescriptor is in your application code. <markup lang=\"java\" >ClientServiceDescriptor descriptor = ClientServiceDescriptor .builder(HelloService.class) .unary(\"SayHello\") .build(); Create a builder for a ClientServiceDescriptor for the HelloService . Specify that the HelloService has a unary method named SayHello . There are many other methods in this class that allow you to define ClientStreaming , ServerStreaming and Bidirectional methods. Build the ClientServiceDescriptor . Configuring the gRPC Channel gRPC allows various channel configurations (deadlines, retries, interceptors etc.) Please refer to gRPC documentation: https://grpc.io/grpc-java/javadoc/io/grpc/ManagedChannelBuilder.html . ",
            "title": "Configuration"
        },
        {
            "location": "se/grpc/client",
            "text": " First, create and run a minimalist HelloService gRPC server application as described in the gRPC server quick start example . Assuming that the server is running on port 1408, create a client as follows: <markup lang=\"java\" >public static void main(String[] args) throws Exception { ClientServiceDescriptor descriptor = ClientServiceDescriptor.builder(HelloService.class) .marshallerSupplier(new JsonbMarshaller.Supplier()) .unary(\"SayHello\") .build(); Channel channel = ManagedChannelBuilder.forAddress(\"localhost\", 1408) .usePlaintext() .build(); GrpcServiceClient client = GrpcServiceClient.create(channel, descriptor); CompletionStage&lt;String&gt; future = client.unary(\"SayHello\", \"Helidon gRPC!!\"); System.out.println(future.get()); } Create a ClientServiceDescriptor for the HelloService . Specify a custom marshaller using the built-in JSON-B marshaller to serialize/deserialize request and response values. Add the SayHello unary method to the ClientServiceDescriptor which will use the specified custom marshaller. Create a gRPC Channel that will communicate with the server running in localhost and on port 1408 (using plaintext). Create the GrpcServiceClient that uses the above Channel and ClientServiceDescriptor . GrpcClientService represents a client that can be used to define the set of methods described by the specified ClientServiceDescriptor . In our case, the ClientServiceDescriptor defines one unary method called SayHello . Invoke the SayHello method which returns a CompletionStage&lt;String&gt; . Print the result. ",
            "title": "Quick Start"
        },
        {
            "location": "se/grpc/client",
            "text": " A set of gRPC client examples for Helidon SE can be found in the following links: Basic gRPC Standalone Client gRPC Server Metrics OpenTracing on a gRPC Server Basic Auth Security on a gRPC Server Attribute-Based Access Control (ABAC) security on a gRPC Server Outbound Security on a gRPC Server ",
            "title": "Additional gRPC client examples"
        },
        {
            "location": "se/grpc/client",
            "text": " Quick Start First, create and run a minimalist HelloService gRPC server application as described in the gRPC server quick start example . Assuming that the server is running on port 1408, create a client as follows: <markup lang=\"java\" >public static void main(String[] args) throws Exception { ClientServiceDescriptor descriptor = ClientServiceDescriptor.builder(HelloService.class) .marshallerSupplier(new JsonbMarshaller.Supplier()) .unary(\"SayHello\") .build(); Channel channel = ManagedChannelBuilder.forAddress(\"localhost\", 1408) .usePlaintext() .build(); GrpcServiceClient client = GrpcServiceClient.create(channel, descriptor); CompletionStage&lt;String&gt; future = client.unary(\"SayHello\", \"Helidon gRPC!!\"); System.out.println(future.get()); } Create a ClientServiceDescriptor for the HelloService . Specify a custom marshaller using the built-in JSON-B marshaller to serialize/deserialize request and response values. Add the SayHello unary method to the ClientServiceDescriptor which will use the specified custom marshaller. Create a gRPC Channel that will communicate with the server running in localhost and on port 1408 (using plaintext). Create the GrpcServiceClient that uses the above Channel and ClientServiceDescriptor . GrpcClientService represents a client that can be used to define the set of methods described by the specified ClientServiceDescriptor . In our case, the ClientServiceDescriptor defines one unary method called SayHello . Invoke the SayHello method which returns a CompletionStage&lt;String&gt; . Print the result. Additional gRPC client examples A set of gRPC client examples for Helidon SE can be found in the following links: Basic gRPC Standalone Client gRPC Server Metrics OpenTracing on a gRPC Server Basic Auth Security on a gRPC Server Attribute-Based Access Control (ABAC) security on a gRPC Server Outbound Security on a gRPC Server ",
            "title": "Examples"
        },
        {
            "location": "se/grpc/server",
            "text": " Overview Maven Coordinates Usage Configuration Examples ",
            "title": "Contents"
        },
        {
            "location": "se/grpc/server",
            "text": " The Helidon gRPC server provides a framework for creating gRPC applications. While it allows you to deploy any standard gRPC service that implements io.grpc.BindableService interface, including services generated from the Protobuf IDL files (and even allows you to customize them to a certain extent), using Helidon gRPC framework to implement your services has a number of benefits: It allows you to define both HTTP and gRPC services using a similar programming model, simplifying the learning curve for developers. It provides a number of helper methods that make service implementation significantly simpler. It allows you to configure some of the Helidon value-added features, such as security and metrics collection down to the method level. It allows you to easily specify custom marshallers for requests and responses if Protobuf does not satisfy your needs. It provides built-in support for health checks . ",
            "title": "Overview"
        },
        {
            "location": "se/grpc/server",
            "text": " To enable gRPC Server add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.grpc&lt;/groupId&gt; &lt;artifactId&gt;helidon-grpc-server&lt;/artifactId&gt; &lt;/dependency&gt; If gRPC server security is required as described in the section, add the following dependency to your project’s pom.xml: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.integration&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-integration-grpc&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "se/grpc/server",
            "text": " When registering a service, regardless of its type, you can customize its descriptor by providing a configuration consumer as a second argument to the register method. This is particularly useful when registering standard BindableService instances, as it allows you to add certain Helidon-specific behaviors, such as health checks and metrics to them: <markup lang=\"java\" >private static GrpcRouting createRouting(Config config) { return GrpcRouting.builder() .register(new GreetService(config)) .register(new EchoService(), service -&gt; { service.healthCheck(CustomHealthChecks::echoHealthCheck) .metered(); }) .build(); } Add custom health check to the service. Specify that all the calls to service methods should be metered. ",
            "title": "Customizing Service Definitions"
        },
        {
            "location": "se/grpc/server",
            "text": " GrpcRouting also allows you to specify custom interceptors that will be applied to all registered services. This is useful to configure features such as tracing, security and metrics collection, and we provide built-in interceptors for those purposes that you can simply register with the routing definition: <markup lang=\"java\" >private static GrpcRouting createRouting(Config config) { return GrpcRouting.builder() .intercept(GrpcMetrics.timed()) .register(new GreetService(config)) .register(new EchoService()) .register(new MathService()) .build(); } Register GrpcMetrics interceptor that will collect timers for all methods of all services (but can be overridden at the individual service or even method level). ",
            "title": "Specifying Global Interceptors"
        },
        {
            "location": "se/grpc/server",
            "text": " Unlike the webserver, which allows you to route requests based on path expression and the HTTP verb, the gRPC server always routes requests based on the service and method name. This makes routing configuration somewhat simpler&#8201;&#8212;&#8201;all you need to do is register your services: <markup lang=\"java\" >private static GrpcRouting createRouting(Config config) { return GrpcRouting.builder() .register(new GreetService(config)) .register(new EchoService()) .register(new MathService()) .build(); } Register GreetService instance. Register EchoService instance. Register MathService instance. Both \"standard\" gRPC services that implement io.grpc.BindableService interface (typically implemented by extending the generated server-side stub and overriding its methods), and Helidon gRPC services that implement io.helidon.grpc.server.GrpcService interface can be registered. The difference is that Helidon gRPC services allow you to customize behavior down to the method level, and provide a number of useful helper methods that make service implementation easier, as we&#8217;ll see in a moment. Customizing Service Definitions When registering a service, regardless of its type, you can customize its descriptor by providing a configuration consumer as a second argument to the register method. This is particularly useful when registering standard BindableService instances, as it allows you to add certain Helidon-specific behaviors, such as health checks and metrics to them: <markup lang=\"java\" >private static GrpcRouting createRouting(Config config) { return GrpcRouting.builder() .register(new GreetService(config)) .register(new EchoService(), service -&gt; { service.healthCheck(CustomHealthChecks::echoHealthCheck) .metered(); }) .build(); } Add custom health check to the service. Specify that all the calls to service methods should be metered. Specifying Global Interceptors GrpcRouting also allows you to specify custom interceptors that will be applied to all registered services. This is useful to configure features such as tracing, security and metrics collection, and we provide built-in interceptors for those purposes that you can simply register with the routing definition: <markup lang=\"java\" >private static GrpcRouting createRouting(Config config) { return GrpcRouting.builder() .intercept(GrpcMetrics.timed()) .register(new GreetService(config)) .register(new EchoService()) .register(new MathService()) .build(); } Register GrpcMetrics interceptor that will collect timers for all methods of all services (but can be overridden at the individual service or even method level). ",
            "title": "gRPC Server Routing"
        },
        {
            "location": "se/grpc/server",
            "text": " For this example, we will re-implement the EchoService above as a Protobuf service in echo.proto file. <markup lang=\"proto\" >syntax = \"proto3\"; option java_package = \"org.example.services.echo\"; service EchoService { rpc Echo (EchoRequest) returns (EchoResponse) {} } message EchoRequest { string message = 1; } message EchoResponse { string message = 1; } Based on this IDL, the gRPC compiler will generate message classes ( EchoRequest and EchoResponse ), client stubs that can be used to make RPC calls to the server, as well as the base class for the server-side service implementation. We can ignore the last one, and implement the service using Helidon gRPC framework instead. ",
            "title": "Define the Service IDL"
        },
        {
            "location": "se/grpc/server",
            "text": " The service implementation will be very similar to our original implementation: <markup lang=\"java\" >class EchoService implements GrpcService { @Override public void update(ServiceDescriptor.Rules rules) { rules.proto(Echo.getDescriptor()) .unary(\"Echo\", this::echo); } /** * Echo the message back to the caller. * * @param request the echo request containing the message to echo * @param observer the response observer */ public void echo(Echo.EchoRequest request, StreamObserver&lt;Echo.EchoResponse&gt; observer) { String message = request.getMessage(); Echo.EchoResponse response = Echo.EchoResponse.newBuilder().setMessage(message).build(); complete(observer, response); } } Specify the proto descriptor in order to provide necessary type information and enable Protobuf marshalling. Define unary method Echo and map it to the this::echo handler. Create a handler for the Echo method, using Protobuf message types for request and response. Extract message string from the request. Create the response containing extracted message. Send the response back to the client by completing response observer. ",
            "title": "Implement the Service"
        },
        {
            "location": "se/grpc/server",
            "text": " In order to implement Protobuf-based service, you would follow the official instructions on the gRPC web site, which boil down to the following: Define the Service IDL For this example, we will re-implement the EchoService above as a Protobuf service in echo.proto file. <markup lang=\"proto\" >syntax = \"proto3\"; option java_package = \"org.example.services.echo\"; service EchoService { rpc Echo (EchoRequest) returns (EchoResponse) {} } message EchoRequest { string message = 1; } message EchoResponse { string message = 1; } Based on this IDL, the gRPC compiler will generate message classes ( EchoRequest and EchoResponse ), client stubs that can be used to make RPC calls to the server, as well as the base class for the server-side service implementation. We can ignore the last one, and implement the service using Helidon gRPC framework instead. Implement the Service The service implementation will be very similar to our original implementation: <markup lang=\"java\" >class EchoService implements GrpcService { @Override public void update(ServiceDescriptor.Rules rules) { rules.proto(Echo.getDescriptor()) .unary(\"Echo\", this::echo); } /** * Echo the message back to the caller. * * @param request the echo request containing the message to echo * @param observer the response observer */ public void echo(Echo.EchoRequest request, StreamObserver&lt;Echo.EchoResponse&gt; observer) { String message = request.getMessage(); Echo.EchoResponse response = Echo.EchoResponse.newBuilder().setMessage(message).build(); complete(observer, response); } } Specify the proto descriptor in order to provide necessary type information and enable Protobuf marshalling. Define unary method Echo and map it to the this::echo handler. Create a handler for the Echo method, using Protobuf message types for request and response. Extract message string from the request. Create the response containing extracted message. Send the response back to the client by completing response observer. ",
            "title": "Implementing Protobuf Services"
        },
        {
            "location": "se/grpc/server",
            "text": " At the very basic level, all you need to do in order to implement a Helidon gRPC service is create a class that implements the io.helidon.grpc.server.GrpcService interface and define one or more methods for the service: <markup lang=\"java\" >class EchoService implements GrpcService { @Override public void update(ServiceDescriptor.Rules rules) { rules.marshallerSupplier(new JsonbMarshaller.Supplier()) .unary(\"Echo\", this::echo); } /** * Echo the message back to the caller. * * @param request the echo request containing the message to echo * @param observer the response observer */ public void echo(String request, StreamObserver&lt;String&gt; observer) { complete(observer, request); } } Specify a custom marshaller to marshall requests and responses. Define unary method Echo and map it to the this::echo handler. Create a handler for the Echo method. Send the request string back to the client by completing response observer. The complete method shown in the example above is just one of many helper methods available in the GrpcService class. See the full list here . The example above implements a service with a single unary method which will be exposed at the `EchoService/Echo' endpoint. The service explicitly defines a marshaller for requests and responses, so this implies that you will have to implement clients by hand and configure them to use the same marshaller as the server. Obviously, one of the major selling points of gRPC is that it makes it easy to generate clients for a number of languages (as long as you use Protobuf for marshalling), so let&#8217;s see how we would implement Protobuf enabled Helidon gRPC service. Implementing Protobuf Services In order to implement Protobuf-based service, you would follow the official instructions on the gRPC web site, which boil down to the following: Define the Service IDL For this example, we will re-implement the EchoService above as a Protobuf service in echo.proto file. <markup lang=\"proto\" >syntax = \"proto3\"; option java_package = \"org.example.services.echo\"; service EchoService { rpc Echo (EchoRequest) returns (EchoResponse) {} } message EchoRequest { string message = 1; } message EchoResponse { string message = 1; } Based on this IDL, the gRPC compiler will generate message classes ( EchoRequest and EchoResponse ), client stubs that can be used to make RPC calls to the server, as well as the base class for the server-side service implementation. We can ignore the last one, and implement the service using Helidon gRPC framework instead. Implement the Service The service implementation will be very similar to our original implementation: <markup lang=\"java\" >class EchoService implements GrpcService { @Override public void update(ServiceDescriptor.Rules rules) { rules.proto(Echo.getDescriptor()) .unary(\"Echo\", this::echo); } /** * Echo the message back to the caller. * * @param request the echo request containing the message to echo * @param observer the response observer */ public void echo(Echo.EchoRequest request, StreamObserver&lt;Echo.EchoResponse&gt; observer) { String message = request.getMessage(); Echo.EchoResponse response = Echo.EchoResponse.newBuilder().setMessage(message).build(); complete(observer, response); } } Specify the proto descriptor in order to provide necessary type information and enable Protobuf marshalling. Define unary method Echo and map it to the this::echo handler. Create a handler for the Echo method, using Protobuf message types for request and response. Extract message string from the request. Create the response containing extracted message. Send the response back to the client by completing response observer. ",
            "title": "Service Implementation"
        },
        {
            "location": "se/grpc/server",
            "text": " You can register interceptors globally, in which case they will be applied to all methods of all services, by simply adding them to the GrpcRouting instance: <markup lang=\"java\" >private static GrpcRouting createRouting(Config config) { return GrpcRouting.builder() .intercept(new LoggingInterceptor()) .register(new GreetService(config)) .register(new EchoService()) .build(); } Adds LoggingInterceptor to all methods of GreetService and EchoService . You can also register an interceptor for a specific service, either by implementing GrpcService.update method: <markup lang=\"java\" >public class MyService implements GrpcService { @Override public void update(ServiceDescriptor.Rules rules) { rules.intercept(new LoggingInterceptor()) .unary(\"MyMethod\", this::myMethod); } private &lt;ReqT, ResT&gt; void myMethod(ReqT request, StreamObserver&lt;ResT&gt; observer) { // do something } } Adds LoggingInterceptor to all methods of MyService . Or by configuring ServiceDescriptor externally, when creating GrpcRouting , which allows you to add interceptors to plain io.grpc.BindableService services as well: <markup lang=\"java\" >private static GrpcRouting createRouting(Config config) { return GrpcRouting.builder() .register(new GreetService(config), cfg -&gt; cfg.intercept(new LoggingInterceptor())) .register(new EchoService()) .build(); } Adds LoggingInterceptor to all methods of GreetService only. Finally, you can also register an interceptor at the method level: <markup lang=\"java\" >public class MyService implements GrpcService { @Override public void update(ServiceDescriptor.Rules rules) { rules.unary(\"MyMethod\", this::myMethod, cfg -&gt; cfg.intercept(new LoggingInterceptor())); } private &lt;ReqT, ResT&gt; void myMethod(ReqT request, StreamObserver&lt;ResT&gt; observer) { // do something } } Adds LoggingInterceptor to MyService::MyMethod only. ",
            "title": "Registering Interceptors"
        },
        {
            "location": "se/grpc/server",
            "text": " Helidon gRPC allows you to configure standard interceptors using io.grpc.ServerInterceptor . For example, you could implement an interceptor that logs each RPC call: <markup lang=\"java\" >class LoggingInterceptor implements ServerInterceptor { private static final Logger LOG = Logger.getLogger(LoggingInterceptor.class.getName()); @Override public &lt;ReqT, ResT&gt; ServerCall.Listener&lt;ReqT&gt; interceptCall(ServerCall&lt;ReqT, ResT&gt; call, Metadata metadata, ServerCallHandler&lt;ReqT, ResT&gt; handler) { LOG.info(() -&gt; \"CALL: \" + call.getMethodDescriptor()); return handler.startCall(call, metadata); } } Implement the interceptor class using io.grpc.ServerInterceptor . Implement the logging logic. The intercepted call is started. Registering Interceptors You can register interceptors globally, in which case they will be applied to all methods of all services, by simply adding them to the GrpcRouting instance: <markup lang=\"java\" >private static GrpcRouting createRouting(Config config) { return GrpcRouting.builder() .intercept(new LoggingInterceptor()) .register(new GreetService(config)) .register(new EchoService()) .build(); } Adds LoggingInterceptor to all methods of GreetService and EchoService . You can also register an interceptor for a specific service, either by implementing GrpcService.update method: <markup lang=\"java\" >public class MyService implements GrpcService { @Override public void update(ServiceDescriptor.Rules rules) { rules.intercept(new LoggingInterceptor()) .unary(\"MyMethod\", this::myMethod); } private &lt;ReqT, ResT&gt; void myMethod(ReqT request, StreamObserver&lt;ResT&gt; observer) { // do something } } Adds LoggingInterceptor to all methods of MyService . Or by configuring ServiceDescriptor externally, when creating GrpcRouting , which allows you to add interceptors to plain io.grpc.BindableService services as well: <markup lang=\"java\" >private static GrpcRouting createRouting(Config config) { return GrpcRouting.builder() .register(new GreetService(config), cfg -&gt; cfg.intercept(new LoggingInterceptor())) .register(new EchoService()) .build(); } Adds LoggingInterceptor to all methods of GreetService only. Finally, you can also register an interceptor at the method level: <markup lang=\"java\" >public class MyService implements GrpcService { @Override public void update(ServiceDescriptor.Rules rules) { rules.unary(\"MyMethod\", this::myMethod, cfg -&gt; cfg.intercept(new LoggingInterceptor())); } private &lt;ReqT, ResT&gt; void myMethod(ReqT request, StreamObserver&lt;ResT&gt; observer) { // do something } } Adds LoggingInterceptor to MyService::MyMethod only. ",
            "title": "Interceptors"
        },
        {
            "location": "se/grpc/server",
            "text": " All gRPC service health checks are managed by the Helidon gRPC server, and are automatically exposed to the gRPC clients using a custom implementation of the standard gRPC HealthService API. However, they can also be exposed to REST clients via the standard Helidon/Microprofile /health endpoint: <markup lang=\"java\" > GrpcServer grpcServer = GrpcServer.create(grpcServerConfig(), createRouting(config)); grpcServer.start(); HealthSupport health = HealthSupport.builder() .add(grpcServer.healthChecks()) .build(); Routing routing = Routing.builder() .register(health) .build(); WebServer.create(webServerConfig(), routing).start(); Create the GrpcServer instance. Start the gRPC server which will deploy all the services and register default and custom health checks. Add gRPC server managed health checks to HealthSupport instance. Add HealthSupport to the web server routing definition. Create and start the web server. All gRPC health checks will now be available via the /health REST endpoint, in addition to the standard gRPC HealthService ",
            "title": "Exposing Health Checks"
        },
        {
            "location": "se/grpc/server",
            "text": " Helidon gRPC services provide built-in support for Helidon Health Checks. Unless a custom health check is implemented by the service developer, each service deployed to the gRPC server will be provisioned with a default health check, which always returns status of UP . This allows all services, including the ones that don&#8217;t have a meaningful health check, to show up in the health report (or to be queried for health) without service developer having to do anything. However, services that do need custom health checks can easily define one, directly within GrpcService implementation: <markup lang=\"java\" >public class MyService implements GrpcService { @Override public void update(ServiceDescriptor.Rules rules) { rules.unary(\"MyMethod\", this::myMethod) .healthCheck(this::healthCheck); } private HealthC heckResponse healthCheck() { boolean fUp = isMyServiceUp(); return HealthCheckResponse .named(name()) .state(fUp) .withData(\"ts\", System.currentTimeMillis()) .build(); } private &lt;ReqT, ResT&gt; void myMethod(ReqT request, StreamObserver&lt;ResT&gt; observer) { // do something } } Configure a custom health check for the service. Determine the service status. Use service name as a health check name for consistency. Set the determined service status. Optionally provide additional metadata. You can also define custom health checks for an existing service, including plain io.grpc.BindableService implementations, using a service configurer inside the GrpcRouting definition: <markup lang=\"java\" >private static GrpcRouting createRouting() { return GrpcRouting.builder() .register(new EchoService(), cfg -&gt; cfg.healthCheck(MyCustomHealthChecks::echoHealthCheck)) .build(); } Configure custom health check for an existing or legacy service. Exposing Health Checks All gRPC service health checks are managed by the Helidon gRPC server, and are automatically exposed to the gRPC clients using a custom implementation of the standard gRPC HealthService API. However, they can also be exposed to REST clients via the standard Helidon/Microprofile /health endpoint: <markup lang=\"java\" > GrpcServer grpcServer = GrpcServer.create(grpcServerConfig(), createRouting(config)); grpcServer.start(); HealthSupport health = HealthSupport.builder() .add(grpcServer.healthChecks()) .build(); Routing routing = Routing.builder() .register(health) .build(); WebServer.create(webServerConfig(), routing).start(); Create the GrpcServer instance. Start the gRPC server which will deploy all the services and register default and custom health checks. Add gRPC server managed health checks to HealthSupport instance. Add HealthSupport to the web server routing definition. Create and start the web server. All gRPC health checks will now be available via the /health REST endpoint, in addition to the standard gRPC HealthService ",
            "title": "Service Health Checks"
        },
        {
            "location": "se/grpc/server",
            "text": " By default, the gRPC server only captures two vendor-level metrics: grpc.request.count and grpc.request.meter . These metrics provide an aggregate view of requests across all services, and serve as an indication of the overall server load. However, users can enable more fine-grained metrics by simply configuring a built-in GrpcMetrics interceptor within the routing: <markup lang=\"java\" >private static GrpcRouting createRouting(Config config) { return GrpcRouting.builder() .intercept(GrpcMetrics.timed()) .register(new GreetService(config)) .register(new EchoService()) .build(); } Capture the metrics for all methods of all services as a timer . In the example above we have chosen to create and keep a timer metric type for each method of each service. Alternatively, we could&#8217;ve chosen to use a counter , meter or a histogram instead. ",
            "title": "Enabling Metrics Capture"
        },
        {
            "location": "se/grpc/server",
            "text": " While global metrics capture is certainly useful, it is not always sufficient. Keeping a separate timer for each gRPC method may be excessive, so the user could decide to use a lighter-weight metric type, such as a counter or a meter . However, the user may still want to enable a histogram or a timer for some services, or even only some methods of some services. This can be easily accomplished by overriding the type of the captured metric at either the service or the method level: <markup lang=\"java\" >private static GrpcRouting createRouting(Config config) { return GrpcRouting.builder() .intercept(GrpcMetrics.counted()) .register(new MyService()) .build(); } public static class MyService implements GrpcService { @Override public void update(ServiceDescriptor.Rules rules) { rules .intercept(GrpcMetrics.metered()) .unary(\"MyMethod\", this::myMethod, cfg -&gt; cfg.intercept(GrpcMetrics.timer())); } private &lt;ReqT, ResT&gt; void myMethod(ReqT request, StreamObserver&lt;ResT&gt; observer) { // do something } } Use counter for all methods of all services, unless overridden. Use meter for all methods of MyService . Use timer for MyService::MyMethod . ",
            "title": "Overriding Metrics Capture"
        },
        {
            "location": "se/grpc/server",
            "text": " Collected metrics are stored in the standard Helidon metric registries, such as the vendor and application registries, and can be exposed via the standard /metrics REST API. <markup lang=\"java\" >Routing routing = Routing.builder() .register(MetricsSupport.create()) .build(); WebServer.create(webServerConfig(), routing) .start() Add the MetricsSupport instance to web server routing. Create and start the Helidon web server. See Helidon Metrics documentation for more details. ",
            "title": "Exposing Metrics Externally"
        },
        {
            "location": "se/grpc/server",
            "text": " To add tags to a metric, a Map of key/value tags can be supplied. <markup lang=\"java\" >Map&lt;String, String&gt; tagMap = new HashMap&lt;&gt;(); tagMap.put(\"keyOne\", \"valueOne\"); tagMap.put(\"keyTwo\", \"valueTwo\"); GrpcRouting routing = GrpcRouting.builder() .intercept(GrpcMetrics.counted().tags(tagMap)) .register(new MyService()) .build(); The tags() method is used to add the Map of tags to the metric. ",
            "title": "Adding Tags"
        },
        {
            "location": "se/grpc/server",
            "text": " A meaningful description can be added to a metric. <markup lang=\"java\" >GrpcRouting routing = GrpcRouting.builder() .intercept(GrpcMetrics.counted().description(\"Something useful\")) .register(new MyService()) .build(); The description() method is used to add the description to the metric. ",
            "title": "Adding a Description"
        },
        {
            "location": "se/grpc/server",
            "text": " A units value can be added to a metric. <markup lang=\"java\" >GrpcRouting routing = GrpcRouting.builder() .intercept(GrpcMetrics.timed().units(MetricUnits.SECONDS)) .register(new MyService()) .build(); The units() method is used to specify the metric units, the value of which is one of the constants from the org.eclipse.microprofile.metrics.MetricUnits class. ",
            "title": "Adding Metric Units"
        },
        {
            "location": "se/grpc/server",
            "text": " Helidon metrics contain metadata such as tags, a description, units etc. It is possible to add this additional metadata when specifying the metrics. Adding Tags To add tags to a metric, a Map of key/value tags can be supplied. <markup lang=\"java\" >Map&lt;String, String&gt; tagMap = new HashMap&lt;&gt;(); tagMap.put(\"keyOne\", \"valueOne\"); tagMap.put(\"keyTwo\", \"valueTwo\"); GrpcRouting routing = GrpcRouting.builder() .intercept(GrpcMetrics.counted().tags(tagMap)) .register(new MyService()) .build(); The tags() method is used to add the Map of tags to the metric. Adding a Description A meaningful description can be added to a metric. <markup lang=\"java\" >GrpcRouting routing = GrpcRouting.builder() .intercept(GrpcMetrics.counted().description(\"Something useful\")) .register(new MyService()) .build(); The description() method is used to add the description to the metric. Adding Metric Units A units value can be added to a metric. <markup lang=\"java\" >GrpcRouting routing = GrpcRouting.builder() .intercept(GrpcMetrics.timed().units(MetricUnits.SECONDS)) .register(new MyService()) .build(); The units() method is used to specify the metric units, the value of which is one of the constants from the org.eclipse.microprofile.metrics.MetricUnits class. ",
            "title": "Specifying Metric Metadata"
        },
        {
            "location": "se/grpc/server",
            "text": " By default, the metric name is the gRPC service name followed by a dot ('.') followed by the method name. It is possible to supply a function that can be used to override the default behaviour. The function should implement the io.helidon.grpc.metrics.GrpcMetrics.NamingFunction interface. <markup lang=\"java\" >@FunctionalInterface public interface NamingFunction { /** * Create a metric name. * * @param service the service descriptor * @param methodName the method name * @param metricType the metric type * @return the metric name */ String createName(ServiceDescriptor service, String methodName, MetricType metricType); } This is a functional interface so a lambda expression can be used too. <markup lang=\"java\" >GrpcRouting routing = GrpcRouting.builder() .intercept(GrpcMetrics.counted() .nameFunction((svc, method, metric) -&gt; \"grpc.\" + service.name() + '.' + method) The NamingFunction is just a lambda that returns the concatenated service name and method name with the prefix grpc. . So for a service \"Foo\" and method \"bar\", the above example would produce a name \"grpc.Foo.bar\". ",
            "title": "Overriding the Metric Name"
        },
        {
            "location": "se/grpc/server",
            "text": " The Helidon gRPC server has built-in support for metrics capture, which allows service developers to easily enable application-level metrics for their services. Enabling Metrics Capture By default, the gRPC server only captures two vendor-level metrics: grpc.request.count and grpc.request.meter . These metrics provide an aggregate view of requests across all services, and serve as an indication of the overall server load. However, users can enable more fine-grained metrics by simply configuring a built-in GrpcMetrics interceptor within the routing: <markup lang=\"java\" >private static GrpcRouting createRouting(Config config) { return GrpcRouting.builder() .intercept(GrpcMetrics.timed()) .register(new GreetService(config)) .register(new EchoService()) .build(); } Capture the metrics for all methods of all services as a timer . In the example above we have chosen to create and keep a timer metric type for each method of each service. Alternatively, we could&#8217;ve chosen to use a counter , meter or a histogram instead. Overriding Metrics Capture While global metrics capture is certainly useful, it is not always sufficient. Keeping a separate timer for each gRPC method may be excessive, so the user could decide to use a lighter-weight metric type, such as a counter or a meter . However, the user may still want to enable a histogram or a timer for some services, or even only some methods of some services. This can be easily accomplished by overriding the type of the captured metric at either the service or the method level: <markup lang=\"java\" >private static GrpcRouting createRouting(Config config) { return GrpcRouting.builder() .intercept(GrpcMetrics.counted()) .register(new MyService()) .build(); } public static class MyService implements GrpcService { @Override public void update(ServiceDescriptor.Rules rules) { rules .intercept(GrpcMetrics.metered()) .unary(\"MyMethod\", this::myMethod, cfg -&gt; cfg.intercept(GrpcMetrics.timer())); } private &lt;ReqT, ResT&gt; void myMethod(ReqT request, StreamObserver&lt;ResT&gt; observer) { // do something } } Use counter for all methods of all services, unless overridden. Use meter for all methods of MyService . Use timer for MyService::MyMethod . Exposing Metrics Externally Collected metrics are stored in the standard Helidon metric registries, such as the vendor and application registries, and can be exposed via the standard /metrics REST API. <markup lang=\"java\" >Routing routing = Routing.builder() .register(MetricsSupport.create()) .build(); WebServer.create(webServerConfig(), routing) .start() Add the MetricsSupport instance to web server routing. Create and start the Helidon web server. See Helidon Metrics documentation for more details. Specifying Metric Metadata Helidon metrics contain metadata such as tags, a description, units etc. It is possible to add this additional metadata when specifying the metrics. Adding Tags To add tags to a metric, a Map of key/value tags can be supplied. <markup lang=\"java\" >Map&lt;String, String&gt; tagMap = new HashMap&lt;&gt;(); tagMap.put(\"keyOne\", \"valueOne\"); tagMap.put(\"keyTwo\", \"valueTwo\"); GrpcRouting routing = GrpcRouting.builder() .intercept(GrpcMetrics.counted().tags(tagMap)) .register(new MyService()) .build(); The tags() method is used to add the Map of tags to the metric. Adding a Description A meaningful description can be added to a metric. <markup lang=\"java\" >GrpcRouting routing = GrpcRouting.builder() .intercept(GrpcMetrics.counted().description(\"Something useful\")) .register(new MyService()) .build(); The description() method is used to add the description to the metric. Adding Metric Units A units value can be added to a metric. <markup lang=\"java\" >GrpcRouting routing = GrpcRouting.builder() .intercept(GrpcMetrics.timed().units(MetricUnits.SECONDS)) .register(new MyService()) .build(); The units() method is used to specify the metric units, the value of which is one of the constants from the org.eclipse.microprofile.metrics.MetricUnits class. Overriding the Metric Name By default, the metric name is the gRPC service name followed by a dot ('.') followed by the method name. It is possible to supply a function that can be used to override the default behaviour. The function should implement the io.helidon.grpc.metrics.GrpcMetrics.NamingFunction interface. <markup lang=\"java\" >@FunctionalInterface public interface NamingFunction { /** * Create a metric name. * * @param service the service descriptor * @param methodName the method name * @param metricType the metric type * @return the metric name */ String createName(ServiceDescriptor service, String methodName, MetricType metricType); } This is a functional interface so a lambda expression can be used too. <markup lang=\"java\" >GrpcRouting routing = GrpcRouting.builder() .intercept(GrpcMetrics.counted() .nameFunction((svc, method, metric) -&gt; \"grpc.\" + service.name() + '.' + method) The NamingFunction is just a lambda that returns the concatenated service name and method name with the prefix grpc. . So for a service \"Foo\" and method \"bar\", the above example would produce a name \"grpc.Foo.bar\". ",
            "title": "Service Metrics"
        },
        {
            "location": "se/grpc/server",
            "text": " When using the Helidon SE gRPC client, API security can be configured for a gRPC service or at the individual method level. The client API has a custom CallCredentials implementation that integrates with the Helidon security APIs. <markup lang=\"java\" title=\"Example configuring client security for a service\" >Security security = Security.builder() .addProvider(HttpBasicAuthProvider.create(config.get(\"http-basic-auth\"))) .build(); GrpcClientSecurity clientSecurity = GrpcClientSecurity.builder(security.createContext(\"test.client\")) .property(HttpBasicAuthProvider.EP_PROPERTY_OUTBOUND_USER, user) .property(HttpBasicAuthProvider.EP_PROPERTY_OUTBOUND_PASSWORD, password) .build(); ClientServiceDescriptor descriptor = ClientServiceDescriptor .builder(StringService.class) .unary(\"Lower\") .callCredentials(clientSecurity) .build(); GrpcServiceClient client = GrpcServiceClient.create(channel, descriptor); String response = client.blockingUnary(\"Lower\", \"ABCD\"); Create the Helidon Security instance which, in this case, will use the basic auth provider. Create the GrpcClientSecurity gRPC CallCredentials adding the user and password property expected by the basic auth provider. Create the gRPC ClientServiceDescriptor for the StringService gRPC service. Set the GrpcClientSecurity instance as the call credentials for all methods of the service. Create a GrpcServiceClient that will allow methods to be called on the service. Call the \"Lower\" method which will use the configured basic auth credentials. <markup lang=\"java\" title=\"Example configuring client security for a specific method\" >GrpcClientSecurity clientSecurity = GrpcClientSecurity.builder(security.createContext(\"test.client\")) .property(HttpBasicAuthProvider.EP_PROPERTY_OUTBOUND_USER, user) .property(HttpBasicAuthProvider.EP_PROPERTY_OUTBOUND_PASSWORD, password) .build(); ClientServiceDescriptor descriptor = ClientServiceDescriptor .builder(StringService.class) .unary(\"Lower\") .unary(\"Upper\", rules -&gt; rules.callCredentials(clientSecurity)) .build(); Create the GrpcClientSecurity call credentials in the same way as above. Create the ClientServiceDescriptor , this time with two unary methods, \"Lower\" and \"Upper\". The \"Upper\" method is configured to use the GrpcClientSecurity call credentials, the \"Lower\" method will be called without any credentials. ",
            "title": "Client security"
        },
        {
            "location": "se/grpc/server",
            "text": " Outbound security covers three scenarios: Calling a secure gRPC service from inside a gRPC service method handler. Calling a secure gRPC service from inside a web server method handler. Calling a secure web endpoint from inside a gRPC service method handler. Within each scenario, credentials can be propagated if the gRPC/http method handler is executing within a security context or credentials can be overridden to provide a different set of credentials to use for calling the outbound endpoint. <markup lang=\"java\" title=\"Example calling a secure gRPC service from inside a gRPC service method handler\" >// Obtain the SecurityContext from the current gRPC call Context SecurityContext securityContext = GrpcSecurity.SECURITY_CONTEXT.get(); // Create a gRPC CallCredentials that will use the current request's // security context to configure outbound credentials GrpcClientSecurity clientSecurity = GrpcClientSecurity.create(securityContext); // Create the gRPC stub using the CallCredentials EchoServiceGrpc.EchoServiceBlockingStub stub = noCredsEchoStub.withCallCredentials(clientSecurity); <markup lang=\"java\" title=\"Example calling a secure gRPC service from inside a web server method handler\" >private static void propagateCredentialsWebRequest(ServerRequest req, ServerResponse res) { try { // Create a gRPC CallCredentials that will use the current request's // security context to configure outbound credentials GrpcClientSecurity clientSecurity = GrpcClientSecurity.create(req); // Create the gRPC stub using the CallCredentials EchoServiceGrpc.EchoServiceBlockingStub stub = noCredsEchoStub.withCallCredentials(clientSecurity); String message = req.queryParams().first(\"message\").orElse(null); Echo.EchoResponse echoResponse = stub.echo(Echo.EchoRequest.newBuilder().setMessage(message).build()); res.send(echoResponse.getMessage()); } catch (StatusRuntimeException e) { res.status(GrpcHelper.toHttpResponseStatus(e)).send(); } catch (Throwable thrown) { res.status(Http.ResponseStatus.create(500, thrown.getMessage())).send(); } } <markup lang=\"java\" title=\"Example calling a secure web endpoint from inside a gRPC service method handler\" >// Obtain the SecurityContext from the gRPC call Context SecurityContext securityContext = GrpcSecurity.SECURITY_CONTEXT.get(); // Use the SecurityContext as normal to make a http request Response webResponse = client.target(url) .path(\"/test\") .request() .property(ClientSecurity.PROPERTY_CONTEXT, securityContext) .get(); ",
            "title": "Outbound security"
        },
        {
            "location": "se/grpc/server",
            "text": " There are two steps to configure security with the gRPC server: Create the security instance and register it the with server. Protect the gRPC services of the server with various security features. <markup lang=\"java\" title=\"Example using builders\" >// gRPC server's routing GrpcRouting.builder() // This is step 1 - register security instance with gRPC server processing // security - instance of security either from config or from a builder // securityDefaults - default enforcement for each service that has a security definition .intercept(GrpcSecurity.create(security).securityDefaults(GrpcSecurity.authenticate())) // this is step 2 - protect a service // register and protect this service with authentication (from defaults) and role \"user\" .register(greetService, GrpcSecurity.rolesAllowed(\"user\")) .build(); <markup lang=\"java\" title=\"Example using builders for more fine grained method level security\" >// create the service descriptor ServiceDescriptor greetService = ServiceDescriptor.builder(new GreetService()) // Add an instance of gRPC security that will apply to all methods of // the service - in this case require the \"user\" role .intercept(GrpcSecurity.rolesAllowed(\"user\")) // Add an instance of gRPC security that will apply to the \"SetGreeting\" // method of the service - in this case require the \"admin\" role .intercept(\"SetGreeting\", GrpcSecurity.rolesAllowed(\"admin\")) .build(); // Create the gRPC server's routing GrpcRouting.builder() // This is step 1 - register security instance with gRPC server processing // security - instance of security either from config or from a builder // securityDefaults - default enforcement for each service that has a security definition .intercept(GrpcSecurity.create(security).securityDefaults(GrpcSecurity.authenticate())) // this is step 2 - add the service descriptor .register(greetService) .build(); <markup lang=\"java\" title=\"Example using configuration\" >GrpcRouting.builder() // helper method to load both security and gRPC server security from configuration .intercept(GrpcSecurity.create(config)) // continue with gRPC server route configuration... .register(new GreetService()) .build(); <markup lang=\"conf\" title=\"Example using configuration - configuration (HOCON)\" ># This may change in the future - to align with gRPC server configuration, # once it is supported security grpc-server: # Configuration of integration with gRPC server defaults: authenticate: true # Configuration security for individual services services: - name: \"GreetService\" defaults: roles-allowed: [\"user\"] # Configuration security for individual methods of the service methods: - name: \"SetGreeting\" roles-allowed: [\"admin\"] Client security When using the Helidon SE gRPC client, API security can be configured for a gRPC service or at the individual method level. The client API has a custom CallCredentials implementation that integrates with the Helidon security APIs. <markup lang=\"java\" title=\"Example configuring client security for a service\" >Security security = Security.builder() .addProvider(HttpBasicAuthProvider.create(config.get(\"http-basic-auth\"))) .build(); GrpcClientSecurity clientSecurity = GrpcClientSecurity.builder(security.createContext(\"test.client\")) .property(HttpBasicAuthProvider.EP_PROPERTY_OUTBOUND_USER, user) .property(HttpBasicAuthProvider.EP_PROPERTY_OUTBOUND_PASSWORD, password) .build(); ClientServiceDescriptor descriptor = ClientServiceDescriptor .builder(StringService.class) .unary(\"Lower\") .callCredentials(clientSecurity) .build(); GrpcServiceClient client = GrpcServiceClient.create(channel, descriptor); String response = client.blockingUnary(\"Lower\", \"ABCD\"); Create the Helidon Security instance which, in this case, will use the basic auth provider. Create the GrpcClientSecurity gRPC CallCredentials adding the user and password property expected by the basic auth provider. Create the gRPC ClientServiceDescriptor for the StringService gRPC service. Set the GrpcClientSecurity instance as the call credentials for all methods of the service. Create a GrpcServiceClient that will allow methods to be called on the service. Call the \"Lower\" method which will use the configured basic auth credentials. <markup lang=\"java\" title=\"Example configuring client security for a specific method\" >GrpcClientSecurity clientSecurity = GrpcClientSecurity.builder(security.createContext(\"test.client\")) .property(HttpBasicAuthProvider.EP_PROPERTY_OUTBOUND_USER, user) .property(HttpBasicAuthProvider.EP_PROPERTY_OUTBOUND_PASSWORD, password) .build(); ClientServiceDescriptor descriptor = ClientServiceDescriptor .builder(StringService.class) .unary(\"Lower\") .unary(\"Upper\", rules -&gt; rules.callCredentials(clientSecurity)) .build(); Create the GrpcClientSecurity call credentials in the same way as above. Create the ClientServiceDescriptor , this time with two unary methods, \"Lower\" and \"Upper\". The \"Upper\" method is configured to use the GrpcClientSecurity call credentials, the \"Lower\" method will be called without any credentials. Outbound security Outbound security covers three scenarios: Calling a secure gRPC service from inside a gRPC service method handler. Calling a secure gRPC service from inside a web server method handler. Calling a secure web endpoint from inside a gRPC service method handler. Within each scenario, credentials can be propagated if the gRPC/http method handler is executing within a security context or credentials can be overridden to provide a different set of credentials to use for calling the outbound endpoint. <markup lang=\"java\" title=\"Example calling a secure gRPC service from inside a gRPC service method handler\" >// Obtain the SecurityContext from the current gRPC call Context SecurityContext securityContext = GrpcSecurity.SECURITY_CONTEXT.get(); // Create a gRPC CallCredentials that will use the current request's // security context to configure outbound credentials GrpcClientSecurity clientSecurity = GrpcClientSecurity.create(securityContext); // Create the gRPC stub using the CallCredentials EchoServiceGrpc.EchoServiceBlockingStub stub = noCredsEchoStub.withCallCredentials(clientSecurity); <markup lang=\"java\" title=\"Example calling a secure gRPC service from inside a web server method handler\" >private static void propagateCredentialsWebRequest(ServerRequest req, ServerResponse res) { try { // Create a gRPC CallCredentials that will use the current request's // security context to configure outbound credentials GrpcClientSecurity clientSecurity = GrpcClientSecurity.create(req); // Create the gRPC stub using the CallCredentials EchoServiceGrpc.EchoServiceBlockingStub stub = noCredsEchoStub.withCallCredentials(clientSecurity); String message = req.queryParams().first(\"message\").orElse(null); Echo.EchoResponse echoResponse = stub.echo(Echo.EchoRequest.newBuilder().setMessage(message).build()); res.send(echoResponse.getMessage()); } catch (StatusRuntimeException e) { res.status(GrpcHelper.toHttpResponseStatus(e)).send(); } catch (Throwable thrown) { res.status(Http.ResponseStatus.create(500, thrown.getMessage())).send(); } } <markup lang=\"java\" title=\"Example calling a secure web endpoint from inside a gRPC service method handler\" >// Obtain the SecurityContext from the gRPC call Context SecurityContext securityContext = GrpcSecurity.SECURITY_CONTEXT.get(); // Use the SecurityContext as normal to make a http request Response webResponse = client.target(url) .path(\"/test\") .request() .property(ClientSecurity.PROPERTY_CONTEXT, securityContext) .get(); ",
            "title": "Bootstrapping"
        },
        {
            "location": "se/grpc/server",
            "text": " To enable server security, refer to the earlier section about Security maven coordinates for guidance on what dependency to add in the project&#8217;s pom.xml. Bootstrapping There are two steps to configure security with the gRPC server: Create the security instance and register it the with server. Protect the gRPC services of the server with various security features. <markup lang=\"java\" title=\"Example using builders\" >// gRPC server's routing GrpcRouting.builder() // This is step 1 - register security instance with gRPC server processing // security - instance of security either from config or from a builder // securityDefaults - default enforcement for each service that has a security definition .intercept(GrpcSecurity.create(security).securityDefaults(GrpcSecurity.authenticate())) // this is step 2 - protect a service // register and protect this service with authentication (from defaults) and role \"user\" .register(greetService, GrpcSecurity.rolesAllowed(\"user\")) .build(); <markup lang=\"java\" title=\"Example using builders for more fine grained method level security\" >// create the service descriptor ServiceDescriptor greetService = ServiceDescriptor.builder(new GreetService()) // Add an instance of gRPC security that will apply to all methods of // the service - in this case require the \"user\" role .intercept(GrpcSecurity.rolesAllowed(\"user\")) // Add an instance of gRPC security that will apply to the \"SetGreeting\" // method of the service - in this case require the \"admin\" role .intercept(\"SetGreeting\", GrpcSecurity.rolesAllowed(\"admin\")) .build(); // Create the gRPC server's routing GrpcRouting.builder() // This is step 1 - register security instance with gRPC server processing // security - instance of security either from config or from a builder // securityDefaults - default enforcement for each service that has a security definition .intercept(GrpcSecurity.create(security).securityDefaults(GrpcSecurity.authenticate())) // this is step 2 - add the service descriptor .register(greetService) .build(); <markup lang=\"java\" title=\"Example using configuration\" >GrpcRouting.builder() // helper method to load both security and gRPC server security from configuration .intercept(GrpcSecurity.create(config)) // continue with gRPC server route configuration... .register(new GreetService()) .build(); <markup lang=\"conf\" title=\"Example using configuration - configuration (HOCON)\" ># This may change in the future - to align with gRPC server configuration, # once it is supported security grpc-server: # Configuration of integration with gRPC server defaults: authenticate: true # Configuration security for individual services services: - name: \"GreetService\" defaults: roles-allowed: [\"user\"] # Configuration security for individual methods of the service methods: - name: \"SetGreeting\" roles-allowed: [\"admin\"] Client security When using the Helidon SE gRPC client, API security can be configured for a gRPC service or at the individual method level. The client API has a custom CallCredentials implementation that integrates with the Helidon security APIs. <markup lang=\"java\" title=\"Example configuring client security for a service\" >Security security = Security.builder() .addProvider(HttpBasicAuthProvider.create(config.get(\"http-basic-auth\"))) .build(); GrpcClientSecurity clientSecurity = GrpcClientSecurity.builder(security.createContext(\"test.client\")) .property(HttpBasicAuthProvider.EP_PROPERTY_OUTBOUND_USER, user) .property(HttpBasicAuthProvider.EP_PROPERTY_OUTBOUND_PASSWORD, password) .build(); ClientServiceDescriptor descriptor = ClientServiceDescriptor .builder(StringService.class) .unary(\"Lower\") .callCredentials(clientSecurity) .build(); GrpcServiceClient client = GrpcServiceClient.create(channel, descriptor); String response = client.blockingUnary(\"Lower\", \"ABCD\"); Create the Helidon Security instance which, in this case, will use the basic auth provider. Create the GrpcClientSecurity gRPC CallCredentials adding the user and password property expected by the basic auth provider. Create the gRPC ClientServiceDescriptor for the StringService gRPC service. Set the GrpcClientSecurity instance as the call credentials for all methods of the service. Create a GrpcServiceClient that will allow methods to be called on the service. Call the \"Lower\" method which will use the configured basic auth credentials. <markup lang=\"java\" title=\"Example configuring client security for a specific method\" >GrpcClientSecurity clientSecurity = GrpcClientSecurity.builder(security.createContext(\"test.client\")) .property(HttpBasicAuthProvider.EP_PROPERTY_OUTBOUND_USER, user) .property(HttpBasicAuthProvider.EP_PROPERTY_OUTBOUND_PASSWORD, password) .build(); ClientServiceDescriptor descriptor = ClientServiceDescriptor .builder(StringService.class) .unary(\"Lower\") .unary(\"Upper\", rules -&gt; rules.callCredentials(clientSecurity)) .build(); Create the GrpcClientSecurity call credentials in the same way as above. Create the ClientServiceDescriptor , this time with two unary methods, \"Lower\" and \"Upper\". The \"Upper\" method is configured to use the GrpcClientSecurity call credentials, the \"Lower\" method will be called without any credentials. Outbound security Outbound security covers three scenarios: Calling a secure gRPC service from inside a gRPC service method handler. Calling a secure gRPC service from inside a web server method handler. Calling a secure web endpoint from inside a gRPC service method handler. Within each scenario, credentials can be propagated if the gRPC/http method handler is executing within a security context or credentials can be overridden to provide a different set of credentials to use for calling the outbound endpoint. <markup lang=\"java\" title=\"Example calling a secure gRPC service from inside a gRPC service method handler\" >// Obtain the SecurityContext from the current gRPC call Context SecurityContext securityContext = GrpcSecurity.SECURITY_CONTEXT.get(); // Create a gRPC CallCredentials that will use the current request's // security context to configure outbound credentials GrpcClientSecurity clientSecurity = GrpcClientSecurity.create(securityContext); // Create the gRPC stub using the CallCredentials EchoServiceGrpc.EchoServiceBlockingStub stub = noCredsEchoStub.withCallCredentials(clientSecurity); <markup lang=\"java\" title=\"Example calling a secure gRPC service from inside a web server method handler\" >private static void propagateCredentialsWebRequest(ServerRequest req, ServerResponse res) { try { // Create a gRPC CallCredentials that will use the current request's // security context to configure outbound credentials GrpcClientSecurity clientSecurity = GrpcClientSecurity.create(req); // Create the gRPC stub using the CallCredentials EchoServiceGrpc.EchoServiceBlockingStub stub = noCredsEchoStub.withCallCredentials(clientSecurity); String message = req.queryParams().first(\"message\").orElse(null); Echo.EchoResponse echoResponse = stub.echo(Echo.EchoRequest.newBuilder().setMessage(message).build()); res.send(echoResponse.getMessage()); } catch (StatusRuntimeException e) { res.status(GrpcHelper.toHttpResponseStatus(e)).send(); } catch (Throwable thrown) { res.status(Http.ResponseStatus.create(500, thrown.getMessage())).send(); } } <markup lang=\"java\" title=\"Example calling a secure web endpoint from inside a gRPC service method handler\" >// Obtain the SecurityContext from the gRPC call Context SecurityContext securityContext = GrpcSecurity.SECURITY_CONTEXT.get(); // Use the SecurityContext as normal to make a http request Response webResponse = client.target(url) .path(\"/test\") .request() .property(ClientSecurity.PROPERTY_CONTEXT, securityContext) .get(); ",
            "title": "Security"
        },
        {
            "location": "se/grpc/server",
            "text": " Helidon gRPC supports Protobuf out of the box. The Protobuf marshaller will be used by default for any request and response classes that extend com.google.protobuf.MessageLite , which is the case for all classes generated from a proto file using protoc compiler. That means that you don&#8217;t need any special handling or configuration in order to support Protobuf serialization of requests and responses. ",
            "title": "Default Marshalling Support"
        },
        {
            "location": "se/grpc/server",
            "text": " You can implement the update method on your service&#8217;s class and set the custom marshaller supplier via the ServiceDescriptor.Rules.marshallerSupplier() method: <markup lang=\"java\" title=\"Sample code for setting the marshaller on the gRPC service\" >public class GreetServiceJava implements GrpcService { private String greeting; public GreetServiceJava(Config config) { this.greeting = config.get(\"app.greeting\").asString().orElse(\"Ciao\"); } @Override public void update(ServiceDescriptor.Rules rules) { rules.marshallerSupplier(new JsonbMarshaller.Supplier()) .unary(\"Greet\", this::greet) .unary(\"SetGreeting\", this::setGreeting); } // Implement Service methods } Specify the custom marshaller to use. ",
            "title": "Setting the custom marshaller"
        },
        {
            "location": "se/grpc/server",
            "text": " Helidon makes the use of custom marshallers trivial and provides one custom implementation, JsonbMarshaller , out of the box. You can also easily implement your own marshaller to support serialization formats that are not supported natively by Helidon, by implementing Marshaller and MarshallerSupplier interfaces. As an example, check out the source code of the built-in marshaller: JsonbMarshaller.java . Furthermore, Oracle Coherence CE provides a marshaller for a highly optimized, binary, platform independent Portable Object Format (POF). You can find more information about POF in Coherence documentation Setting the custom marshaller You can implement the update method on your service&#8217;s class and set the custom marshaller supplier via the ServiceDescriptor.Rules.marshallerSupplier() method: <markup lang=\"java\" title=\"Sample code for setting the marshaller on the gRPC service\" >public class GreetServiceJava implements GrpcService { private String greeting; public GreetServiceJava(Config config) { this.greeting = config.get(\"app.greeting\").asString().orElse(\"Ciao\"); } @Override public void update(ServiceDescriptor.Rules rules) { rules.marshallerSupplier(new JsonbMarshaller.Supplier()) .unary(\"Greet\", this::greet) .unary(\"SetGreeting\", this::setGreeting); } // Implement Service methods } Specify the custom marshaller to use. ",
            "title": "Custom Marshalling"
        },
        {
            "location": "se/grpc/server",
            "text": " Default Marshalling Support Helidon gRPC supports Protobuf out of the box. The Protobuf marshaller will be used by default for any request and response classes that extend com.google.protobuf.MessageLite , which is the case for all classes generated from a proto file using protoc compiler. That means that you don&#8217;t need any special handling or configuration in order to support Protobuf serialization of requests and responses. Custom Marshalling Helidon makes the use of custom marshallers trivial and provides one custom implementation, JsonbMarshaller , out of the box. You can also easily implement your own marshaller to support serialization formats that are not supported natively by Helidon, by implementing Marshaller and MarshallerSupplier interfaces. As an example, check out the source code of the built-in marshaller: JsonbMarshaller.java . Furthermore, Oracle Coherence CE provides a marshaller for a highly optimized, binary, platform independent Portable Object Format (POF). You can find more information about POF in Coherence documentation Setting the custom marshaller You can implement the update method on your service&#8217;s class and set the custom marshaller supplier via the ServiceDescriptor.Rules.marshallerSupplier() method: <markup lang=\"java\" title=\"Sample code for setting the marshaller on the gRPC service\" >public class GreetServiceJava implements GrpcService { private String greeting; public GreetServiceJava(Config config) { this.greeting = config.get(\"app.greeting\").asString().orElse(\"Ciao\"); } @Override public void update(ServiceDescriptor.Rules rules) { rules.marshallerSupplier(new JsonbMarshaller.Supplier()) .unary(\"Greet\", this::greet) .unary(\"SetGreeting\", this::setGreeting); } // Implement Service methods } Specify the custom marshaller to use. ",
            "title": "Marshalling"
        },
        {
            "location": "se/grpc/server",
            "text": " gRPC Server Routing Unlike the webserver, which allows you to route requests based on path expression and the HTTP verb, the gRPC server always routes requests based on the service and method name. This makes routing configuration somewhat simpler&#8201;&#8212;&#8201;all you need to do is register your services: <markup lang=\"java\" >private static GrpcRouting createRouting(Config config) { return GrpcRouting.builder() .register(new GreetService(config)) .register(new EchoService()) .register(new MathService()) .build(); } Register GreetService instance. Register EchoService instance. Register MathService instance. Both \"standard\" gRPC services that implement io.grpc.BindableService interface (typically implemented by extending the generated server-side stub and overriding its methods), and Helidon gRPC services that implement io.helidon.grpc.server.GrpcService interface can be registered. The difference is that Helidon gRPC services allow you to customize behavior down to the method level, and provide a number of useful helper methods that make service implementation easier, as we&#8217;ll see in a moment. Customizing Service Definitions When registering a service, regardless of its type, you can customize its descriptor by providing a configuration consumer as a second argument to the register method. This is particularly useful when registering standard BindableService instances, as it allows you to add certain Helidon-specific behaviors, such as health checks and metrics to them: <markup lang=\"java\" >private static GrpcRouting createRouting(Config config) { return GrpcRouting.builder() .register(new GreetService(config)) .register(new EchoService(), service -&gt; { service.healthCheck(CustomHealthChecks::echoHealthCheck) .metered(); }) .build(); } Add custom health check to the service. Specify that all the calls to service methods should be metered. Specifying Global Interceptors GrpcRouting also allows you to specify custom interceptors that will be applied to all registered services. This is useful to configure features such as tracing, security and metrics collection, and we provide built-in interceptors for those purposes that you can simply register with the routing definition: <markup lang=\"java\" >private static GrpcRouting createRouting(Config config) { return GrpcRouting.builder() .intercept(GrpcMetrics.timed()) .register(new GreetService(config)) .register(new EchoService()) .register(new MathService()) .build(); } Register GrpcMetrics interceptor that will collect timers for all methods of all services (but can be overridden at the individual service or even method level). Service Implementation At the very basic level, all you need to do in order to implement a Helidon gRPC service is create a class that implements the io.helidon.grpc.server.GrpcService interface and define one or more methods for the service: <markup lang=\"java\" >class EchoService implements GrpcService { @Override public void update(ServiceDescriptor.Rules rules) { rules.marshallerSupplier(new JsonbMarshaller.Supplier()) .unary(\"Echo\", this::echo); } /** * Echo the message back to the caller. * * @param request the echo request containing the message to echo * @param observer the response observer */ public void echo(String request, StreamObserver&lt;String&gt; observer) { complete(observer, request); } } Specify a custom marshaller to marshall requests and responses. Define unary method Echo and map it to the this::echo handler. Create a handler for the Echo method. Send the request string back to the client by completing response observer. The complete method shown in the example above is just one of many helper methods available in the GrpcService class. See the full list here . The example above implements a service with a single unary method which will be exposed at the `EchoService/Echo' endpoint. The service explicitly defines a marshaller for requests and responses, so this implies that you will have to implement clients by hand and configure them to use the same marshaller as the server. Obviously, one of the major selling points of gRPC is that it makes it easy to generate clients for a number of languages (as long as you use Protobuf for marshalling), so let&#8217;s see how we would implement Protobuf enabled Helidon gRPC service. Implementing Protobuf Services In order to implement Protobuf-based service, you would follow the official instructions on the gRPC web site, which boil down to the following: Define the Service IDL For this example, we will re-implement the EchoService above as a Protobuf service in echo.proto file. <markup lang=\"proto\" >syntax = \"proto3\"; option java_package = \"org.example.services.echo\"; service EchoService { rpc Echo (EchoRequest) returns (EchoResponse) {} } message EchoRequest { string message = 1; } message EchoResponse { string message = 1; } Based on this IDL, the gRPC compiler will generate message classes ( EchoRequest and EchoResponse ), client stubs that can be used to make RPC calls to the server, as well as the base class for the server-side service implementation. We can ignore the last one, and implement the service using Helidon gRPC framework instead. Implement the Service The service implementation will be very similar to our original implementation: <markup lang=\"java\" >class EchoService implements GrpcService { @Override public void update(ServiceDescriptor.Rules rules) { rules.proto(Echo.getDescriptor()) .unary(\"Echo\", this::echo); } /** * Echo the message back to the caller. * * @param request the echo request containing the message to echo * @param observer the response observer */ public void echo(Echo.EchoRequest request, StreamObserver&lt;Echo.EchoResponse&gt; observer) { String message = request.getMessage(); Echo.EchoResponse response = Echo.EchoResponse.newBuilder().setMessage(message).build(); complete(observer, response); } } Specify the proto descriptor in order to provide necessary type information and enable Protobuf marshalling. Define unary method Echo and map it to the this::echo handler. Create a handler for the Echo method, using Protobuf message types for request and response. Extract message string from the request. Create the response containing extracted message. Send the response back to the client by completing response observer. Interceptors Helidon gRPC allows you to configure standard interceptors using io.grpc.ServerInterceptor . For example, you could implement an interceptor that logs each RPC call: <markup lang=\"java\" >class LoggingInterceptor implements ServerInterceptor { private static final Logger LOG = Logger.getLogger(LoggingInterceptor.class.getName()); @Override public &lt;ReqT, ResT&gt; ServerCall.Listener&lt;ReqT&gt; interceptCall(ServerCall&lt;ReqT, ResT&gt; call, Metadata metadata, ServerCallHandler&lt;ReqT, ResT&gt; handler) { LOG.info(() -&gt; \"CALL: \" + call.getMethodDescriptor()); return handler.startCall(call, metadata); } } Implement the interceptor class using io.grpc.ServerInterceptor . Implement the logging logic. The intercepted call is started. Registering Interceptors You can register interceptors globally, in which case they will be applied to all methods of all services, by simply adding them to the GrpcRouting instance: <markup lang=\"java\" >private static GrpcRouting createRouting(Config config) { return GrpcRouting.builder() .intercept(new LoggingInterceptor()) .register(new GreetService(config)) .register(new EchoService()) .build(); } Adds LoggingInterceptor to all methods of GreetService and EchoService . You can also register an interceptor for a specific service, either by implementing GrpcService.update method: <markup lang=\"java\" >public class MyService implements GrpcService { @Override public void update(ServiceDescriptor.Rules rules) { rules.intercept(new LoggingInterceptor()) .unary(\"MyMethod\", this::myMethod); } private &lt;ReqT, ResT&gt; void myMethod(ReqT request, StreamObserver&lt;ResT&gt; observer) { // do something } } Adds LoggingInterceptor to all methods of MyService . Or by configuring ServiceDescriptor externally, when creating GrpcRouting , which allows you to add interceptors to plain io.grpc.BindableService services as well: <markup lang=\"java\" >private static GrpcRouting createRouting(Config config) { return GrpcRouting.builder() .register(new GreetService(config), cfg -&gt; cfg.intercept(new LoggingInterceptor())) .register(new EchoService()) .build(); } Adds LoggingInterceptor to all methods of GreetService only. Finally, you can also register an interceptor at the method level: <markup lang=\"java\" >public class MyService implements GrpcService { @Override public void update(ServiceDescriptor.Rules rules) { rules.unary(\"MyMethod\", this::myMethod, cfg -&gt; cfg.intercept(new LoggingInterceptor())); } private &lt;ReqT, ResT&gt; void myMethod(ReqT request, StreamObserver&lt;ResT&gt; observer) { // do something } } Adds LoggingInterceptor to MyService::MyMethod only. Service Health Checks Helidon gRPC services provide built-in support for Helidon Health Checks. Unless a custom health check is implemented by the service developer, each service deployed to the gRPC server will be provisioned with a default health check, which always returns status of UP . This allows all services, including the ones that don&#8217;t have a meaningful health check, to show up in the health report (or to be queried for health) without service developer having to do anything. However, services that do need custom health checks can easily define one, directly within GrpcService implementation: <markup lang=\"java\" >public class MyService implements GrpcService { @Override public void update(ServiceDescriptor.Rules rules) { rules.unary(\"MyMethod\", this::myMethod) .healthCheck(this::healthCheck); } private HealthC heckResponse healthCheck() { boolean fUp = isMyServiceUp(); return HealthCheckResponse .named(name()) .state(fUp) .withData(\"ts\", System.currentTimeMillis()) .build(); } private &lt;ReqT, ResT&gt; void myMethod(ReqT request, StreamObserver&lt;ResT&gt; observer) { // do something } } Configure a custom health check for the service. Determine the service status. Use service name as a health check name for consistency. Set the determined service status. Optionally provide additional metadata. You can also define custom health checks for an existing service, including plain io.grpc.BindableService implementations, using a service configurer inside the GrpcRouting definition: <markup lang=\"java\" >private static GrpcRouting createRouting() { return GrpcRouting.builder() .register(new EchoService(), cfg -&gt; cfg.healthCheck(MyCustomHealthChecks::echoHealthCheck)) .build(); } Configure custom health check for an existing or legacy service. Exposing Health Checks All gRPC service health checks are managed by the Helidon gRPC server, and are automatically exposed to the gRPC clients using a custom implementation of the standard gRPC HealthService API. However, they can also be exposed to REST clients via the standard Helidon/Microprofile /health endpoint: <markup lang=\"java\" > GrpcServer grpcServer = GrpcServer.create(grpcServerConfig(), createRouting(config)); grpcServer.start(); HealthSupport health = HealthSupport.builder() .add(grpcServer.healthChecks()) .build(); Routing routing = Routing.builder() .register(health) .build(); WebServer.create(webServerConfig(), routing).start(); Create the GrpcServer instance. Start the gRPC server which will deploy all the services and register default and custom health checks. Add gRPC server managed health checks to HealthSupport instance. Add HealthSupport to the web server routing definition. Create and start the web server. All gRPC health checks will now be available via the /health REST endpoint, in addition to the standard gRPC HealthService Service Metrics The Helidon gRPC server has built-in support for metrics capture, which allows service developers to easily enable application-level metrics for their services. Enabling Metrics Capture By default, the gRPC server only captures two vendor-level metrics: grpc.request.count and grpc.request.meter . These metrics provide an aggregate view of requests across all services, and serve as an indication of the overall server load. However, users can enable more fine-grained metrics by simply configuring a built-in GrpcMetrics interceptor within the routing: <markup lang=\"java\" >private static GrpcRouting createRouting(Config config) { return GrpcRouting.builder() .intercept(GrpcMetrics.timed()) .register(new GreetService(config)) .register(new EchoService()) .build(); } Capture the metrics for all methods of all services as a timer . In the example above we have chosen to create and keep a timer metric type for each method of each service. Alternatively, we could&#8217;ve chosen to use a counter , meter or a histogram instead. Overriding Metrics Capture While global metrics capture is certainly useful, it is not always sufficient. Keeping a separate timer for each gRPC method may be excessive, so the user could decide to use a lighter-weight metric type, such as a counter or a meter . However, the user may still want to enable a histogram or a timer for some services, or even only some methods of some services. This can be easily accomplished by overriding the type of the captured metric at either the service or the method level: <markup lang=\"java\" >private static GrpcRouting createRouting(Config config) { return GrpcRouting.builder() .intercept(GrpcMetrics.counted()) .register(new MyService()) .build(); } public static class MyService implements GrpcService { @Override public void update(ServiceDescriptor.Rules rules) { rules .intercept(GrpcMetrics.metered()) .unary(\"MyMethod\", this::myMethod, cfg -&gt; cfg.intercept(GrpcMetrics.timer())); } private &lt;ReqT, ResT&gt; void myMethod(ReqT request, StreamObserver&lt;ResT&gt; observer) { // do something } } Use counter for all methods of all services, unless overridden. Use meter for all methods of MyService . Use timer for MyService::MyMethod . Exposing Metrics Externally Collected metrics are stored in the standard Helidon metric registries, such as the vendor and application registries, and can be exposed via the standard /metrics REST API. <markup lang=\"java\" >Routing routing = Routing.builder() .register(MetricsSupport.create()) .build(); WebServer.create(webServerConfig(), routing) .start() Add the MetricsSupport instance to web server routing. Create and start the Helidon web server. See Helidon Metrics documentation for more details. Specifying Metric Metadata Helidon metrics contain metadata such as tags, a description, units etc. It is possible to add this additional metadata when specifying the metrics. Adding Tags To add tags to a metric, a Map of key/value tags can be supplied. <markup lang=\"java\" >Map&lt;String, String&gt; tagMap = new HashMap&lt;&gt;(); tagMap.put(\"keyOne\", \"valueOne\"); tagMap.put(\"keyTwo\", \"valueTwo\"); GrpcRouting routing = GrpcRouting.builder() .intercept(GrpcMetrics.counted().tags(tagMap)) .register(new MyService()) .build(); The tags() method is used to add the Map of tags to the metric. Adding a Description A meaningful description can be added to a metric. <markup lang=\"java\" >GrpcRouting routing = GrpcRouting.builder() .intercept(GrpcMetrics.counted().description(\"Something useful\")) .register(new MyService()) .build(); The description() method is used to add the description to the metric. Adding Metric Units A units value can be added to a metric. <markup lang=\"java\" >GrpcRouting routing = GrpcRouting.builder() .intercept(GrpcMetrics.timed().units(MetricUnits.SECONDS)) .register(new MyService()) .build(); The units() method is used to specify the metric units, the value of which is one of the constants from the org.eclipse.microprofile.metrics.MetricUnits class. Overriding the Metric Name By default, the metric name is the gRPC service name followed by a dot ('.') followed by the method name. It is possible to supply a function that can be used to override the default behaviour. The function should implement the io.helidon.grpc.metrics.GrpcMetrics.NamingFunction interface. <markup lang=\"java\" >@FunctionalInterface public interface NamingFunction { /** * Create a metric name. * * @param service the service descriptor * @param methodName the method name * @param metricType the metric type * @return the metric name */ String createName(ServiceDescriptor service, String methodName, MetricType metricType); } This is a functional interface so a lambda expression can be used too. <markup lang=\"java\" >GrpcRouting routing = GrpcRouting.builder() .intercept(GrpcMetrics.counted() .nameFunction((svc, method, metric) -&gt; \"grpc.\" + service.name() + '.' + method) The NamingFunction is just a lambda that returns the concatenated service name and method name with the prefix grpc. . So for a service \"Foo\" and method \"bar\", the above example would produce a name \"grpc.Foo.bar\". Security To enable server security, refer to the earlier section about Security maven coordinates for guidance on what dependency to add in the project&#8217;s pom.xml. Bootstrapping There are two steps to configure security with the gRPC server: Create the security instance and register it the with server. Protect the gRPC services of the server with various security features. <markup lang=\"java\" title=\"Example using builders\" >// gRPC server's routing GrpcRouting.builder() // This is step 1 - register security instance with gRPC server processing // security - instance of security either from config or from a builder // securityDefaults - default enforcement for each service that has a security definition .intercept(GrpcSecurity.create(security).securityDefaults(GrpcSecurity.authenticate())) // this is step 2 - protect a service // register and protect this service with authentication (from defaults) and role \"user\" .register(greetService, GrpcSecurity.rolesAllowed(\"user\")) .build(); <markup lang=\"java\" title=\"Example using builders for more fine grained method level security\" >// create the service descriptor ServiceDescriptor greetService = ServiceDescriptor.builder(new GreetService()) // Add an instance of gRPC security that will apply to all methods of // the service - in this case require the \"user\" role .intercept(GrpcSecurity.rolesAllowed(\"user\")) // Add an instance of gRPC security that will apply to the \"SetGreeting\" // method of the service - in this case require the \"admin\" role .intercept(\"SetGreeting\", GrpcSecurity.rolesAllowed(\"admin\")) .build(); // Create the gRPC server's routing GrpcRouting.builder() // This is step 1 - register security instance with gRPC server processing // security - instance of security either from config or from a builder // securityDefaults - default enforcement for each service that has a security definition .intercept(GrpcSecurity.create(security).securityDefaults(GrpcSecurity.authenticate())) // this is step 2 - add the service descriptor .register(greetService) .build(); <markup lang=\"java\" title=\"Example using configuration\" >GrpcRouting.builder() // helper method to load both security and gRPC server security from configuration .intercept(GrpcSecurity.create(config)) // continue with gRPC server route configuration... .register(new GreetService()) .build(); <markup lang=\"conf\" title=\"Example using configuration - configuration (HOCON)\" ># This may change in the future - to align with gRPC server configuration, # once it is supported security grpc-server: # Configuration of integration with gRPC server defaults: authenticate: true # Configuration security for individual services services: - name: \"GreetService\" defaults: roles-allowed: [\"user\"] # Configuration security for individual methods of the service methods: - name: \"SetGreeting\" roles-allowed: [\"admin\"] Client security When using the Helidon SE gRPC client, API security can be configured for a gRPC service or at the individual method level. The client API has a custom CallCredentials implementation that integrates with the Helidon security APIs. <markup lang=\"java\" title=\"Example configuring client security for a service\" >Security security = Security.builder() .addProvider(HttpBasicAuthProvider.create(config.get(\"http-basic-auth\"))) .build(); GrpcClientSecurity clientSecurity = GrpcClientSecurity.builder(security.createContext(\"test.client\")) .property(HttpBasicAuthProvider.EP_PROPERTY_OUTBOUND_USER, user) .property(HttpBasicAuthProvider.EP_PROPERTY_OUTBOUND_PASSWORD, password) .build(); ClientServiceDescriptor descriptor = ClientServiceDescriptor .builder(StringService.class) .unary(\"Lower\") .callCredentials(clientSecurity) .build(); GrpcServiceClient client = GrpcServiceClient.create(channel, descriptor); String response = client.blockingUnary(\"Lower\", \"ABCD\"); Create the Helidon Security instance which, in this case, will use the basic auth provider. Create the GrpcClientSecurity gRPC CallCredentials adding the user and password property expected by the basic auth provider. Create the gRPC ClientServiceDescriptor for the StringService gRPC service. Set the GrpcClientSecurity instance as the call credentials for all methods of the service. Create a GrpcServiceClient that will allow methods to be called on the service. Call the \"Lower\" method which will use the configured basic auth credentials. <markup lang=\"java\" title=\"Example configuring client security for a specific method\" >GrpcClientSecurity clientSecurity = GrpcClientSecurity.builder(security.createContext(\"test.client\")) .property(HttpBasicAuthProvider.EP_PROPERTY_OUTBOUND_USER, user) .property(HttpBasicAuthProvider.EP_PROPERTY_OUTBOUND_PASSWORD, password) .build(); ClientServiceDescriptor descriptor = ClientServiceDescriptor .builder(StringService.class) .unary(\"Lower\") .unary(\"Upper\", rules -&gt; rules.callCredentials(clientSecurity)) .build(); Create the GrpcClientSecurity call credentials in the same way as above. Create the ClientServiceDescriptor , this time with two unary methods, \"Lower\" and \"Upper\". The \"Upper\" method is configured to use the GrpcClientSecurity call credentials, the \"Lower\" method will be called without any credentials. Outbound security Outbound security covers three scenarios: Calling a secure gRPC service from inside a gRPC service method handler. Calling a secure gRPC service from inside a web server method handler. Calling a secure web endpoint from inside a gRPC service method handler. Within each scenario, credentials can be propagated if the gRPC/http method handler is executing within a security context or credentials can be overridden to provide a different set of credentials to use for calling the outbound endpoint. <markup lang=\"java\" title=\"Example calling a secure gRPC service from inside a gRPC service method handler\" >// Obtain the SecurityContext from the current gRPC call Context SecurityContext securityContext = GrpcSecurity.SECURITY_CONTEXT.get(); // Create a gRPC CallCredentials that will use the current request's // security context to configure outbound credentials GrpcClientSecurity clientSecurity = GrpcClientSecurity.create(securityContext); // Create the gRPC stub using the CallCredentials EchoServiceGrpc.EchoServiceBlockingStub stub = noCredsEchoStub.withCallCredentials(clientSecurity); <markup lang=\"java\" title=\"Example calling a secure gRPC service from inside a web server method handler\" >private static void propagateCredentialsWebRequest(ServerRequest req, ServerResponse res) { try { // Create a gRPC CallCredentials that will use the current request's // security context to configure outbound credentials GrpcClientSecurity clientSecurity = GrpcClientSecurity.create(req); // Create the gRPC stub using the CallCredentials EchoServiceGrpc.EchoServiceBlockingStub stub = noCredsEchoStub.withCallCredentials(clientSecurity); String message = req.queryParams().first(\"message\").orElse(null); Echo.EchoResponse echoResponse = stub.echo(Echo.EchoRequest.newBuilder().setMessage(message).build()); res.send(echoResponse.getMessage()); } catch (StatusRuntimeException e) { res.status(GrpcHelper.toHttpResponseStatus(e)).send(); } catch (Throwable thrown) { res.status(Http.ResponseStatus.create(500, thrown.getMessage())).send(); } } <markup lang=\"java\" title=\"Example calling a secure web endpoint from inside a gRPC service method handler\" >// Obtain the SecurityContext from the gRPC call Context SecurityContext securityContext = GrpcSecurity.SECURITY_CONTEXT.get(); // Use the SecurityContext as normal to make a http request Response webResponse = client.target(url) .path(\"/test\") .request() .property(ClientSecurity.PROPERTY_CONTEXT, securityContext) .get(); Marshalling Default Marshalling Support Helidon gRPC supports Protobuf out of the box. The Protobuf marshaller will be used by default for any request and response classes that extend com.google.protobuf.MessageLite , which is the case for all classes generated from a proto file using protoc compiler. That means that you don&#8217;t need any special handling or configuration in order to support Protobuf serialization of requests and responses. Custom Marshalling Helidon makes the use of custom marshallers trivial and provides one custom implementation, JsonbMarshaller , out of the box. You can also easily implement your own marshaller to support serialization formats that are not supported natively by Helidon, by implementing Marshaller and MarshallerSupplier interfaces. As an example, check out the source code of the built-in marshaller: JsonbMarshaller.java . Furthermore, Oracle Coherence CE provides a marshaller for a highly optimized, binary, platform independent Portable Object Format (POF). You can find more information about POF in Coherence documentation Setting the custom marshaller You can implement the update method on your service&#8217;s class and set the custom marshaller supplier via the ServiceDescriptor.Rules.marshallerSupplier() method: <markup lang=\"java\" title=\"Sample code for setting the marshaller on the gRPC service\" >public class GreetServiceJava implements GrpcService { private String greeting; public GreetServiceJava(Config config) { this.greeting = config.get(\"app.greeting\").asString().orElse(\"Ciao\"); } @Override public void update(ServiceDescriptor.Rules rules) { rules.marshallerSupplier(new JsonbMarshaller.Supplier()) .unary(\"Greet\", this::greet) .unary(\"SetGreeting\", this::setGreeting); } // Implement Service methods } Specify the custom marshaller to use. ",
            "title": "Usage"
        },
        {
            "location": "se/grpc/server",
            "text": " The easiest way to configure the gRPC server is in your application code. <markup lang=\"java\" >GrpcServerConfiguration configuration = GrpcServerConfiguration.builder() .port(8080) .build(); GrpcServer grpcServer = GrpcServer.create(configuration, routing); See all configuration options here . ",
            "title": "Configuring the gRPC server in your code"
        },
        {
            "location": "se/grpc/server",
            "text": " You can also define the gRPC server configuration in a file. Type: io.helidon.grpc.server.GrpcServerConfiguration ",
            "title": "Configuring the gRPC server in a configuration file"
        },
        {
            "location": "se/grpc/server",
            "text": " Optional configuration options key type default value description name string grpc.server Set the name of the gRPC server. Configuration key: `name` native boolean false Specify if native transport should be used. port int 1408 Sets server port. If port is 0 or less then any available ephemeral port will be used. Configuration key: `port` workers int Number of processors available to the JVM Sets a count of threads in pool used to process HTTP requests. Default value is CPU_COUNT * 2 . Configuration key: `workers` <markup lang=\"yaml\" title=\"GrpcServer configuration file example using application.yaml \" >grpc: port: 3333 Then, in your application code, load the configuration from that file. <markup lang=\"java\" title=\"GrpcServer initialization using the application.conf file located on the classpath\" >GrpcServerConfiguration configuration = GrpcServerConfiguration.create( Config.builder() .sources(classpath(\"application.conf\")) .build()); GrpcServer grpcServer = GrpcServer.create(configuration, routing); ",
            "title": "Configuration options"
        },
        {
            "location": "se/grpc/server",
            "text": " Configure the gRPC server using the Helidon configuration framework, either programmatically or via a configuration file. Configuring the gRPC server in your code The easiest way to configure the gRPC server is in your application code. <markup lang=\"java\" >GrpcServerConfiguration configuration = GrpcServerConfiguration.builder() .port(8080) .build(); GrpcServer grpcServer = GrpcServer.create(configuration, routing); See all configuration options here . Configuring the gRPC server in a configuration file You can also define the gRPC server configuration in a file. Type: io.helidon.grpc.server.GrpcServerConfiguration Configuration options Optional configuration options key type default value description name string grpc.server Set the name of the gRPC server. Configuration key: `name` native boolean false Specify if native transport should be used. port int 1408 Sets server port. If port is 0 or less then any available ephemeral port will be used. Configuration key: `port` workers int Number of processors available to the JVM Sets a count of threads in pool used to process HTTP requests. Default value is CPU_COUNT * 2 . Configuration key: `workers` <markup lang=\"yaml\" title=\"GrpcServer configuration file example using application.yaml \" >grpc: port: 3333 Then, in your application code, load the configuration from that file. <markup lang=\"java\" title=\"GrpcServer initialization using the application.conf file located on the classpath\" >GrpcServerConfiguration configuration = GrpcServerConfiguration.create( Config.builder() .sources(classpath(\"application.conf\")) .build()); GrpcServer grpcServer = GrpcServer.create(configuration, routing); ",
            "title": "Configuration"
        },
        {
            "location": "se/grpc/server",
            "text": " Here is the code for a minimalist gRPC application that runs on a default port (1408): <markup lang=\"java\" >public static void main(String[] args) throws Exception { GrpcServer grpcServer = GrpcServer .create(GrpcRouting.builder() .register(new HelloService()) .build()) .start() .toCompletableFuture() .get(10, TimeUnit.SECONDS); // Implement the simplest possible gRPC service. System.out.println(\"gRPC server started at: http://localhost:\" + grpcServer.port()); } static class HelloService implements GrpcService { @Override public void update(ServiceDescriptor.Rules rules) { rules.marshallerSupplier(new JsonbMarshaller.Supplier()) .unary(\"SayHello\", ((request, responseObserver) -&gt; complete(responseObserver, \"Hello \" + request))); } } Register the gRPC service. Start the server. Wait for the server to start while throwing possible errors as exceptions. The server is bound to a default port (1408). Implement the simplest possible gRPC service. Specify a custom marshaller using the built-in JsonB marshaller to marshall requests and responses. Add unary method HelloService/SayHello to the service definition. ",
            "title": "Quick Start"
        },
        {
            "location": "se/grpc/server",
            "text": " A set of gRPC server examples for Helidon SE can be found in the following links: Basic gRPC Server gRPC Server Metrics OpenTracing on a gRPC Server Basic Auth Security on a gRPC Server Attribute-Based Access Control (ABAC) security on a gRPC Server Outbound Security on a gRPC Server ",
            "title": "Additional gRPC server examples"
        },
        {
            "location": "se/grpc/server",
            "text": " Quick Start Here is the code for a minimalist gRPC application that runs on a default port (1408): <markup lang=\"java\" >public static void main(String[] args) throws Exception { GrpcServer grpcServer = GrpcServer .create(GrpcRouting.builder() .register(new HelloService()) .build()) .start() .toCompletableFuture() .get(10, TimeUnit.SECONDS); // Implement the simplest possible gRPC service. System.out.println(\"gRPC server started at: http://localhost:\" + grpcServer.port()); } static class HelloService implements GrpcService { @Override public void update(ServiceDescriptor.Rules rules) { rules.marshallerSupplier(new JsonbMarshaller.Supplier()) .unary(\"SayHello\", ((request, responseObserver) -&gt; complete(responseObserver, \"Hello \" + request))); } } Register the gRPC service. Start the server. Wait for the server to start while throwing possible errors as exceptions. The server is bound to a default port (1408). Implement the simplest possible gRPC service. Specify a custom marshaller using the built-in JsonB marshaller to marshall requests and responses. Add unary method HelloService/SayHello to the service definition. Additional gRPC server examples A set of gRPC server examples for Helidon SE can be found in the following links: Basic gRPC Server gRPC Server Metrics OpenTracing on a gRPC Server Basic Auth Security on a gRPC Server Attribute-Based Access Control (ABAC) security on a gRPC Server Outbound Security on a gRPC Server ",
            "title": "Examples"
        },
        {
            "location": "se/guides/config",
            "text": " This guide describes how to create a sample Helidon SE project that can be used to run some basic examples using both default and custom configuration. ",
            "title": "preambule"
        },
        {
            "location": "se/guides/config",
            "text": " For this 20 minute tutorial, you will need the following: <div class=\"table__overflow elevation-1 flex sm7 \"> A Helidon SE Application You can use your own application or use the Helidon SE Quickstart to create a sample application. Java&#160;SE&#160;17 ( Open&#160;JDK&#160;17 ) Helidon requires Java 17+. Maven 3.6.1+ Helidon requires Maven 3.6.1+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop . <markup lang=\"bash\" title=\"Verify Prerequisites\" >java -version mvn --version docker --version kubectl version --short <markup lang=\"bash\" title=\"Setting JAVA_HOME\" ># On Mac export JAVA_HOME=`/usr/libexec/java_home -v 17` # On Linux # Use the appropriate path to your JDK export JAVA_HOME=/usr/lib/jvm/jdk-17 ",
            "title": "What you need"
        },
        {
            "location": "se/guides/config",
            "text": " Use the Helidon SE Maven archetype to create a simple project that can be used for the examples in this guide. <markup lang=\"bash\" title=\"Run the Maven archetype:\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-se \\ -DarchetypeVersion=3.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-se \\ -Dpackage=io.helidon.examples.quickstart.se <markup lang=\"bash\" title=\"The project will be built and run from the helidon-quickstart-se directory:\" >cd helidon-quickstart-se ",
            "title": "Create a Sample Helidon SE Project"
        },
        {
            "location": "se/guides/config",
            "text": " Helidon configuration sources can use different formats for the configuration data. You can specify the format on a per-source bases, mixing and matching formats as required. Here are the supported formats, each with the extension name you should use. By default, Helidon will determine the media type based on the extension name. Java Property (.properties) JSON (.json) YAML (.yaml) HOCON (.conf) The remainder of this document will use these formats in examples and show you how to configure Helidon to parse them. ",
            "title": "Configuration Formats"
        },
        {
            "location": "se/guides/config",
            "text": " Helidon has an internal configuration, so you are not required to provide any configuration data for your application, though in practice you most likely would. By default, that configuration can be overridden from three sources: system properties, environment variables, and the contents of application.yaml in the classpath. For example, if you specify a custom server port in application.yaml then your server will listen on that port. In your application code, Helidon uses the default configuration when you create a default Config object. See the following code from the project you created. <markup lang=\"Java\" title=\"View Main.startServer :\" >Config config = Config.create(); The Config object is created with default settings. ",
            "title": "Default Configuration"
        },
        {
            "location": "se/guides/config",
            "text": " A system property has a higher precedence than application.yaml . <markup lang=\"bash\" title=\"Restart the application with a system property. The app.greeting environment variable is still set:\" >java -Dapp.greeting=\"HelloFromSystemProperty\" -jar target/helidon-quickstart-se.jar <markup lang=\"bash\" title=\"Invoke the endpoint below and check the response:\" >curl http://localhost:8080/greet <markup lang=\"json\" >{ \"message\": \"HelloFromSystemProperty World!\" } The system property took precedence over application.yaml . ",
            "title": "System Property Override"
        },
        {
            "location": "se/guides/config",
            "text": " An environment variable has a higher precedence than the system property. <markup lang=\"bash\" title=\"Set the environment variable and restart the application:\" >export APP_GREETING=HelloFromEnvironment java -Dapp.greeting=\"HelloFromSystemProperty\" -jar target/helidon-quickstart-se.jar <markup lang=\"bash\" title=\"Invoke the endpoint below and check the response:\" >curl http://localhost:8080/greet <markup lang=\"json\" >{ \"message\": \"HelloFromEnvironment World!\" } The environment variable APP_GREETING took precedence over the system property and the value in application.yaml . ",
            "title": "Environment Variable Override"
        },
        {
            "location": "se/guides/config",
            "text": " Change a configuration parameter in the default configuration resource file, application.yaml . There are no environment variable or system property overrides defined. <markup lang=\"bash\" title=\"Change app.greeting in resources/application.yaml as follows:\" >app: greeting: HelloFrom-application.yaml <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-se.jar <markup lang=\"bash\" title=\"Run the curl command in a new terminal window and check the response:\" >curl http://localhost:8080/greet <markup lang=\"json\" >{ \"message\": \"HelloFrom-application.yaml World!\" } The new app.greeting value in application.yaml is used. System Property Override A system property has a higher precedence than application.yaml . <markup lang=\"bash\" title=\"Restart the application with a system property. The app.greeting environment variable is still set:\" >java -Dapp.greeting=\"HelloFromSystemProperty\" -jar target/helidon-quickstart-se.jar <markup lang=\"bash\" title=\"Invoke the endpoint below and check the response:\" >curl http://localhost:8080/greet <markup lang=\"json\" >{ \"message\": \"HelloFromSystemProperty World!\" } The system property took precedence over application.yaml . Environment Variable Override An environment variable has a higher precedence than the system property. <markup lang=\"bash\" title=\"Set the environment variable and restart the application:\" >export APP_GREETING=HelloFromEnvironment java -Dapp.greeting=\"HelloFromSystemProperty\" -jar target/helidon-quickstart-se.jar <markup lang=\"bash\" title=\"Invoke the endpoint below and check the response:\" >curl http://localhost:8080/greet <markup lang=\"json\" >{ \"message\": \"HelloFromEnvironment World!\" } The environment variable APP_GREETING took precedence over the system property and the value in application.yaml . ",
            "title": "Default Configuration Resource"
        },
        {
            "location": "se/guides/config",
            "text": " In order to properly configure your application using configuration sources, you need to understand the precedence rules that Helidon uses to merge your configuration data. By default, Helidon will use the following sources in precedence order: Java system properties Environment variables Configuration specified in application.yaml If any of the Helidon required properties are not specified in one of these source, like server.port , then Helidon will use a default value. Because environment variable names are restricted to alphanumeric characters and underscore, Helidon adds aliases to the environment configuration source, allowing entries with dotted and/or hyphenated keys to be overridden. For example, this mapping allows an environment variable named \"APP_GREETING\" to override an entry key named \"app.greeting\". In the same way, an environment variable named \"APP_dash_GREETING\" will map to \"app-greeting\". See Advanced Config for more information. The following examples will demonstrate the default precedence order. Default Configuration Resource Change a configuration parameter in the default configuration resource file, application.yaml . There are no environment variable or system property overrides defined. <markup lang=\"bash\" title=\"Change app.greeting in resources/application.yaml as follows:\" >app: greeting: HelloFrom-application.yaml <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-se.jar <markup lang=\"bash\" title=\"Run the curl command in a new terminal window and check the response:\" >curl http://localhost:8080/greet <markup lang=\"json\" >{ \"message\": \"HelloFrom-application.yaml World!\" } The new app.greeting value in application.yaml is used. System Property Override A system property has a higher precedence than application.yaml . <markup lang=\"bash\" title=\"Restart the application with a system property. The app.greeting environment variable is still set:\" >java -Dapp.greeting=\"HelloFromSystemProperty\" -jar target/helidon-quickstart-se.jar <markup lang=\"bash\" title=\"Invoke the endpoint below and check the response:\" >curl http://localhost:8080/greet <markup lang=\"json\" >{ \"message\": \"HelloFromSystemProperty World!\" } The system property took precedence over application.yaml . Environment Variable Override An environment variable has a higher precedence than the system property. <markup lang=\"bash\" title=\"Set the environment variable and restart the application:\" >export APP_GREETING=HelloFromEnvironment java -Dapp.greeting=\"HelloFromSystemProperty\" -jar target/helidon-quickstart-se.jar <markup lang=\"bash\" title=\"Invoke the endpoint below and check the response:\" >curl http://localhost:8080/greet <markup lang=\"json\" >{ \"message\": \"HelloFromEnvironment World!\" } The environment variable APP_GREETING took precedence over the system property and the value in application.yaml . ",
            "title": "Source Precedence for Default Configuration"
        },
        {
            "location": "se/guides/config",
            "text": " Helidon provides a very flexible and comprehensive configuration system, offering you many application configuration choices. You can include configuration data from a variety of sources using different formats, like JSON and YAML. Furthermore, you can customize the precedence of sources and make them optional or mandatory. This guide introduces Helidon SE configuration and demonstrates the fundamental concepts using several examples. Refer to Helidon Config for the full configuration concepts documentation. Create a Sample Helidon SE Project Use the Helidon SE Maven archetype to create a simple project that can be used for the examples in this guide. <markup lang=\"bash\" title=\"Run the Maven archetype:\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-se \\ -DarchetypeVersion=3.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-se \\ -Dpackage=io.helidon.examples.quickstart.se <markup lang=\"bash\" title=\"The project will be built and run from the helidon-quickstart-se directory:\" >cd helidon-quickstart-se Configuration Formats Helidon configuration sources can use different formats for the configuration data. You can specify the format on a per-source bases, mixing and matching formats as required. Here are the supported formats, each with the extension name you should use. By default, Helidon will determine the media type based on the extension name. Java Property (.properties) JSON (.json) YAML (.yaml) HOCON (.conf) The remainder of this document will use these formats in examples and show you how to configure Helidon to parse them. Default Configuration Helidon has an internal configuration, so you are not required to provide any configuration data for your application, though in practice you most likely would. By default, that configuration can be overridden from three sources: system properties, environment variables, and the contents of application.yaml in the classpath. For example, if you specify a custom server port in application.yaml then your server will listen on that port. In your application code, Helidon uses the default configuration when you create a default Config object. See the following code from the project you created. <markup lang=\"Java\" title=\"View Main.startServer :\" >Config config = Config.create(); The Config object is created with default settings. Source Precedence for Default Configuration In order to properly configure your application using configuration sources, you need to understand the precedence rules that Helidon uses to merge your configuration data. By default, Helidon will use the following sources in precedence order: Java system properties Environment variables Configuration specified in application.yaml If any of the Helidon required properties are not specified in one of these source, like server.port , then Helidon will use a default value. Because environment variable names are restricted to alphanumeric characters and underscore, Helidon adds aliases to the environment configuration source, allowing entries with dotted and/or hyphenated keys to be overridden. For example, this mapping allows an environment variable named \"APP_GREETING\" to override an entry key named \"app.greeting\". In the same way, an environment variable named \"APP_dash_GREETING\" will map to \"app-greeting\". See Advanced Config for more information. The following examples will demonstrate the default precedence order. Default Configuration Resource Change a configuration parameter in the default configuration resource file, application.yaml . There are no environment variable or system property overrides defined. <markup lang=\"bash\" title=\"Change app.greeting in resources/application.yaml as follows:\" >app: greeting: HelloFrom-application.yaml <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-se.jar <markup lang=\"bash\" title=\"Run the curl command in a new terminal window and check the response:\" >curl http://localhost:8080/greet <markup lang=\"json\" >{ \"message\": \"HelloFrom-application.yaml World!\" } The new app.greeting value in application.yaml is used. System Property Override A system property has a higher precedence than application.yaml . <markup lang=\"bash\" title=\"Restart the application with a system property. The app.greeting environment variable is still set:\" >java -Dapp.greeting=\"HelloFromSystemProperty\" -jar target/helidon-quickstart-se.jar <markup lang=\"bash\" title=\"Invoke the endpoint below and check the response:\" >curl http://localhost:8080/greet <markup lang=\"json\" >{ \"message\": \"HelloFromSystemProperty World!\" } The system property took precedence over application.yaml . Environment Variable Override An environment variable has a higher precedence than the system property. <markup lang=\"bash\" title=\"Set the environment variable and restart the application:\" >export APP_GREETING=HelloFromEnvironment java -Dapp.greeting=\"HelloFromSystemProperty\" -jar target/helidon-quickstart-se.jar <markup lang=\"bash\" title=\"Invoke the endpoint below and check the response:\" >curl http://localhost:8080/greet <markup lang=\"json\" >{ \"message\": \"HelloFromEnvironment World!\" } The environment variable APP_GREETING took precedence over the system property and the value in application.yaml . ",
            "title": "Getting Started with Configuration"
        },
        {
            "location": "se/guides/config",
            "text": " Here is the full list of external config sources that you can use programmatically. Environment variables - the property is a name/value pair. Java system properties - the property is a name/value pair. Resources in the classpath - the contents of the resource is parsed according to its inferred format. File - the contents of the file is parsed according to its inferred format. Directory - each non-directory file in the directory becomes a config entry: the file name is the key. and the contents of that file are used as the corresponding config String value. A URL resource - contents is parsed according to its inferred format. You can also define custom sources, such as Git, and use them in your Helidon application. See Advanced Config for more information. ",
            "title": "Full List of Configuration Sources"
        },
        {
            "location": "se/guides/config",
            "text": " The first custom resource example demonstrates how to add a second internal configuration resource that is discovered in the classpath . The code needs to build a Config object, which in turn is used to build the Server object. The Config object can be built using a Config.Builder , which lets you inject any number of sources into the builder. Furthermore, you can set precedence for the sources. The first source has highest precedence, then the next has second highest, and so forth. <markup lang=\"text\" title=\"Add a resource file, named config.properties to the resources directory with the following contents:\" >app.greeting=HelloFrom-config.properties <markup lang=\"java\" title=\"Update the Main class; 1) Add new imports, 2) Replace the Config.create() call with buildConfig() , and 3) Add buildConfig method:\" >import static io.helidon.config.ConfigSources.classpath; //... static WebServer startServer() throws IOException { //... Config config = buildConfig(); private static Config buildConfig() { return Config.builder() .disableEnvironmentVariablesSource() .sources( classpath(\"config.properties\"), classpath(\"application.yaml\")) .build(); } Add new import statement. Call the new buildConfig method to build a Config object. Disable the environment variables as a source. Specify the new config.properties resource that is in the classpath . You must specify the existing application.yaml or Helidon will not use it as a configuration source even though it is considered a default source. <markup lang=\"bash\" title=\"Build and run the application (without the system property). Invoke the endpoint and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFrom-config.properties World!\" } The greeting was picked up from config.properties , overriding the value in application.yaml . It is important to remember that configuration from all sources is merged internally. If you have the same configuration property in multiple sources, then only the one with highest precedence will be used at runtime. This is true even the same property comes from sources with different formats. Swap the source order and run the test again. <markup lang=\"java\" title=\"Update the Main class and replace the buildConfig method:\" > private static Config buildConfig() { return Config.builder() .disableEnvironmentVariablesSource() .sources( classpath(\"application.yaml\"), classpath(\"config.properties\")) .build(); } Swap the source order, putting application.yaml first. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFrom-application.yaml World!\" } The file application.yaml was used to get the greeting since it now has precedence over config.properties . ",
            "title": "Classpath Sources"
        },
        {
            "location": "se/guides/config",
            "text": " You can move all or part of your configuration to external files, making them optional or mandatory. The obvious advantage to this approach is that you do not need to rebuild your application to change configuration. In the following example, the app.greeting configuration property will be added to config-file.properties . <markup lang=\"bash\" title=\"Unset the environment variable so that disableEnvironmentVariablesSource doesn&#8217;t need to be called:\" >unset APP_GREETING <markup lang=\"bash\" title=\"Create a file named config-file.properties in the helidon-quickstart-se directory with the following contents:\" >app.greeting=HelloFrom-config-file.properties <markup lang=\"java\" title=\"Update the Main class; 1) Add new import and 2) Replace the buildConfig method:\" >import static io.helidon.config.ConfigSources.file; ... private static Config buildConfig() { return Config.builder() .sources( file(\"config-file.properties\"), classpath(\"application.yaml\")) .build(); } Add a mandatory configuration file. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFrom-config-file.properties World!\" } The configuration property from the file config-file.properties takes precedence. If you want the configuration file to be optional, you must use the optional method with sources , otherwise Helidon will generate an error during startup as shown below. This is true for both file and classpath sources. By default, these sources are mandatory. <markup lang=\"java\" title=\"Update the Main class and replace the buildConfig method:\" > private static Config buildConfig() { return Config.builder() .sources( file(\"missing-file\"), classpath(\"application.yaml\")) .build(); } Specify a file that doesn&#8217;t exist. <markup lang=\"bash\" title=\"Build then start the application and you will see the following output:\" >Exception in thread \"main\" io.helidon.config.ConfigException: Cannot load data from mandatory source FileConfig[missing-file]. File `missing-file` not found. To fix this, use the optional method as shown below, then rerun the test. ... file(\"missing-file\").optional(), The missing-file configuration file is now optional. ",
            "title": "External File Sources"
        },
        {
            "location": "se/guides/config",
            "text": " If you have more than three sources, you can use the addSource method as shown below. <markup lang=\"java\" title=\"Update the Main class and replace the buildConfig method:\" > private static Config buildConfig() { return Config.builder() .addSource(directory(\"conf\")) .addSource(file(\"config-file.properties\")) .addSource(classpath(\"config.properties\").optional()) .addSource(classpath(\"application.yaml\")) .build(); } Add each config source using the addSource method. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFromFileInDirectoryConf World!\" } ",
            "title": "Exceeding Three Sources"
        },
        {
            "location": "se/guides/config",
            "text": " A directory source treats every file in the directory as a key, and the file contents as the value. The following example includes a directory source as highest precedence. <markup lang=\"bash\" title=\"Create a new directory helidon-quickstart-se/conf then create a file named app.greeting in that directory with the following contents:\" >HelloFromFileInDirectoryConf <markup lang=\"java\" title=\"Update the Main class; 1) Add new import and 2) Replace the buildConfig method:\" >import static io.helidon.config.ConfigSources.directory; ... private static Config buildConfig() { return Config.builder() .sources( directory(\"conf\"), classpath(\"config.properties\").optional(), classpath(\"application.yaml\")) .build(); } Add a mandatory configuration directory. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFromFileInDirectoryConf World!\" } The greeting was fetched from the file named app.greeting . Exceeding Three Sources If you have more than three sources, you can use the addSource method as shown below. <markup lang=\"java\" title=\"Update the Main class and replace the buildConfig method:\" > private static Config buildConfig() { return Config.builder() .addSource(directory(\"conf\")) .addSource(file(\"config-file.properties\")) .addSource(classpath(\"config.properties\").optional()) .addSource(classpath(\"application.yaml\")) .build(); } Add each config source using the addSource method. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFromFileInDirectoryConf World!\" } ",
            "title": "Directory Source"
        },
        {
            "location": "se/guides/config",
            "text": " Instead of directly specifying the configuration sources in your code, you can use a profile file that declares the configuration sources and their attributes. Simplest way to use a profile is to define a config-profile.yaml (and possible other files, such as config-profile-dev.yaml for dev profile) on classpath or on file system, and create config using Config.create() . The profile can be changed by a system property config.profile , or using an environment variable HELIDON_CONFIG_PROFILE . Profile file can use any supported format, following example is using YAML . <markup lang=\"yaml\" title=\"Create a file named config-profile.yaml in the helidon-quickstart-se directory with the following contents:\" >sources: - type: \"classpath\" properties: resource: \"application.yaml\" The source type. The name of the mandatory configuration resource. <markup lang=\"java\" title=\"Update the Main class and replace the buildConfig method:\" > private static Config buildConfig() { return Config.create(); } Will use config-profile.yaml by default <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFrom-application.yaml World!\" } The application.yaml resource file was used to get the greeting. The source precedence order in a profile file is the order of appearance in the file. This is demonstrated below where the config-file.properties has highest precedence. <markup lang=\"yaml\" title=\"Replace the contents of the config-profile.yaml file:\" >sources: - type: \"file\" properties: path: \"./config-file.properties\" - type: \"classpath\" properties: resource: \"application.yaml\" - type: \"file\" properties: path: \"optional-config-file\" optional: true The source type specifies a file. The name of the mandatory configuration file. Specify that the optional-config-file file is optional. <markup lang=\"bash\" title=\"Restart the application, then invoke the endpoint below and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFrom-config-file.properties World!\" } The config-file.properties source now takes precedence. When using a profile file, you need to explicitly include both environment variables and system properties as a source if you want to use them. <markup lang=\"bash\" title=\"Replace the contents of the config-profile.yaml file:\" >sources: - type: \"environment-variables\" - type: \"system-properties\" - type: \"classpath\" properties: resource: \"application.yaml\" - type: \"file\" properties: path: \"./config-file.properties\" Environment variables are now used as a source. System properties are now used as a source. You can re-run the previous tests that exercised environment variables and system properties. Swap the two types to see the precedence change. Be sure to unset APP_GREETING after you finish testing. ",
            "title": "Configuration Profiles"
        },
        {
            "location": "se/guides/config",
            "text": " To use custom configuration sources, your application needs to specify the sources when it creates Config object. By doing this, you are in full control of all configuration sources and precedence. By default, the environment variable and system property sources are enabled, but you can disable them using the disableEnvironmentVariablesSource and disableSystemPropertiesSource methods. This section will show you how to use a custom configuration with various sources, formats, and precedence rules. Full List of Configuration Sources Here is the full list of external config sources that you can use programmatically. Environment variables - the property is a name/value pair. Java system properties - the property is a name/value pair. Resources in the classpath - the contents of the resource is parsed according to its inferred format. File - the contents of the file is parsed according to its inferred format. Directory - each non-directory file in the directory becomes a config entry: the file name is the key. and the contents of that file are used as the corresponding config String value. A URL resource - contents is parsed according to its inferred format. You can also define custom sources, such as Git, and use them in your Helidon application. See Advanced Config for more information. Classpath Sources The first custom resource example demonstrates how to add a second internal configuration resource that is discovered in the classpath . The code needs to build a Config object, which in turn is used to build the Server object. The Config object can be built using a Config.Builder , which lets you inject any number of sources into the builder. Furthermore, you can set precedence for the sources. The first source has highest precedence, then the next has second highest, and so forth. <markup lang=\"text\" title=\"Add a resource file, named config.properties to the resources directory with the following contents:\" >app.greeting=HelloFrom-config.properties <markup lang=\"java\" title=\"Update the Main class; 1) Add new imports, 2) Replace the Config.create() call with buildConfig() , and 3) Add buildConfig method:\" >import static io.helidon.config.ConfigSources.classpath; //... static WebServer startServer() throws IOException { //... Config config = buildConfig(); private static Config buildConfig() { return Config.builder() .disableEnvironmentVariablesSource() .sources( classpath(\"config.properties\"), classpath(\"application.yaml\")) .build(); } Add new import statement. Call the new buildConfig method to build a Config object. Disable the environment variables as a source. Specify the new config.properties resource that is in the classpath . You must specify the existing application.yaml or Helidon will not use it as a configuration source even though it is considered a default source. <markup lang=\"bash\" title=\"Build and run the application (without the system property). Invoke the endpoint and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFrom-config.properties World!\" } The greeting was picked up from config.properties , overriding the value in application.yaml . It is important to remember that configuration from all sources is merged internally. If you have the same configuration property in multiple sources, then only the one with highest precedence will be used at runtime. This is true even the same property comes from sources with different formats. Swap the source order and run the test again. <markup lang=\"java\" title=\"Update the Main class and replace the buildConfig method:\" > private static Config buildConfig() { return Config.builder() .disableEnvironmentVariablesSource() .sources( classpath(\"application.yaml\"), classpath(\"config.properties\")) .build(); } Swap the source order, putting application.yaml first. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFrom-application.yaml World!\" } The file application.yaml was used to get the greeting since it now has precedence over config.properties . External File Sources You can move all or part of your configuration to external files, making them optional or mandatory. The obvious advantage to this approach is that you do not need to rebuild your application to change configuration. In the following example, the app.greeting configuration property will be added to config-file.properties . <markup lang=\"bash\" title=\"Unset the environment variable so that disableEnvironmentVariablesSource doesn&#8217;t need to be called:\" >unset APP_GREETING <markup lang=\"bash\" title=\"Create a file named config-file.properties in the helidon-quickstart-se directory with the following contents:\" >app.greeting=HelloFrom-config-file.properties <markup lang=\"java\" title=\"Update the Main class; 1) Add new import and 2) Replace the buildConfig method:\" >import static io.helidon.config.ConfigSources.file; ... private static Config buildConfig() { return Config.builder() .sources( file(\"config-file.properties\"), classpath(\"application.yaml\")) .build(); } Add a mandatory configuration file. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFrom-config-file.properties World!\" } The configuration property from the file config-file.properties takes precedence. If you want the configuration file to be optional, you must use the optional method with sources , otherwise Helidon will generate an error during startup as shown below. This is true for both file and classpath sources. By default, these sources are mandatory. <markup lang=\"java\" title=\"Update the Main class and replace the buildConfig method:\" > private static Config buildConfig() { return Config.builder() .sources( file(\"missing-file\"), classpath(\"application.yaml\")) .build(); } Specify a file that doesn&#8217;t exist. <markup lang=\"bash\" title=\"Build then start the application and you will see the following output:\" >Exception in thread \"main\" io.helidon.config.ConfigException: Cannot load data from mandatory source FileConfig[missing-file]. File `missing-file` not found. To fix this, use the optional method as shown below, then rerun the test. ... file(\"missing-file\").optional(), The missing-file configuration file is now optional. Directory Source A directory source treats every file in the directory as a key, and the file contents as the value. The following example includes a directory source as highest precedence. <markup lang=\"bash\" title=\"Create a new directory helidon-quickstart-se/conf then create a file named app.greeting in that directory with the following contents:\" >HelloFromFileInDirectoryConf <markup lang=\"java\" title=\"Update the Main class; 1) Add new import and 2) Replace the buildConfig method:\" >import static io.helidon.config.ConfigSources.directory; ... private static Config buildConfig() { return Config.builder() .sources( directory(\"conf\"), classpath(\"config.properties\").optional(), classpath(\"application.yaml\")) .build(); } Add a mandatory configuration directory. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFromFileInDirectoryConf World!\" } The greeting was fetched from the file named app.greeting . Exceeding Three Sources If you have more than three sources, you can use the addSource method as shown below. <markup lang=\"java\" title=\"Update the Main class and replace the buildConfig method:\" > private static Config buildConfig() { return Config.builder() .addSource(directory(\"conf\")) .addSource(file(\"config-file.properties\")) .addSource(classpath(\"config.properties\").optional()) .addSource(classpath(\"application.yaml\")) .build(); } Add each config source using the addSource method. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFromFileInDirectoryConf World!\" } Configuration Profiles Instead of directly specifying the configuration sources in your code, you can use a profile file that declares the configuration sources and their attributes. Simplest way to use a profile is to define a config-profile.yaml (and possible other files, such as config-profile-dev.yaml for dev profile) on classpath or on file system, and create config using Config.create() . The profile can be changed by a system property config.profile , or using an environment variable HELIDON_CONFIG_PROFILE . Profile file can use any supported format, following example is using YAML . <markup lang=\"yaml\" title=\"Create a file named config-profile.yaml in the helidon-quickstart-se directory with the following contents:\" >sources: - type: \"classpath\" properties: resource: \"application.yaml\" The source type. The name of the mandatory configuration resource. <markup lang=\"java\" title=\"Update the Main class and replace the buildConfig method:\" > private static Config buildConfig() { return Config.create(); } Will use config-profile.yaml by default <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFrom-application.yaml World!\" } The application.yaml resource file was used to get the greeting. The source precedence order in a profile file is the order of appearance in the file. This is demonstrated below where the config-file.properties has highest precedence. <markup lang=\"yaml\" title=\"Replace the contents of the config-profile.yaml file:\" >sources: - type: \"file\" properties: path: \"./config-file.properties\" - type: \"classpath\" properties: resource: \"application.yaml\" - type: \"file\" properties: path: \"optional-config-file\" optional: true The source type specifies a file. The name of the mandatory configuration file. Specify that the optional-config-file file is optional. <markup lang=\"bash\" title=\"Restart the application, then invoke the endpoint below and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFrom-config-file.properties World!\" } The config-file.properties source now takes precedence. When using a profile file, you need to explicitly include both environment variables and system properties as a source if you want to use them. <markup lang=\"bash\" title=\"Replace the contents of the config-profile.yaml file:\" >sources: - type: \"environment-variables\" - type: \"system-properties\" - type: \"classpath\" properties: resource: \"application.yaml\" - type: \"file\" properties: path: \"./config-file.properties\" Environment variables are now used as a source. System properties are now used as a source. You can re-run the previous tests that exercised environment variables and system properties. Swap the two types to see the precedence change. Be sure to unset APP_GREETING after you finish testing. ",
            "title": "Custom Configuration Sources"
        },
        {
            "location": "se/guides/config",
            "text": " The simplest way to access configuration data is using a key, as shown below in the GreetService class. The key can be composite as shown below: <markup lang=\"java\" title=\"View the GreetService constructor:\" > GreetService(Config config) { greeting.set(config.get(\"app.greeting\").asString().orElse(\"Ciao\")); } Get the app.greeting node using a composite key. You can also access the same greeting by navigating the nodes. <markup lang=\"java\" title=\"Replace the GreetService constructor with the following code:\" > GreetService(Config config) { greeting.set(config.get(\"app\").get(\"greeting\").asString().orElse(\"Ciao\")); } Get the app node, then get the child node, greeting . <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFrom-application.yaml World!\" } ",
            "title": "Accessing Config Using Keys or Navigation"
        },
        {
            "location": "se/guides/config",
            "text": " The Helidon Config class provides several methods that allow you to filter and customize the traversal of the configuration tree. The example below shows how to get the greeting node when you only know it is somewhere in the app subtree. <markup lang=\"bash\" title=\"Replace the contents of the config-profile.yaml file:\" >sources: - type: \"classpath\" properties: resource: \"application.yaml\" <markup lang=\"bash\" title=\"Replace the app section of the application.yaml resource file:\" >app: child1: child1-node child2: child2a: greeting: HelloFrom-application.yaml under child2a child3: child3-node <markup lang=\"java\" title=\"Update the GreetService.java file; 1) Add new imports and 2) Replace the GreetService constructor with the following:\" > import java.util.List; import java.util.stream.Collectors; GreetService(Config config) { List&lt;Config&gt; appGreetings = config.get(\"app\") .traverse() .filter(node -&gt; node.name().equals(\"greeting\")) .collect(Collectors.toList()); greeting.set(appGreetings.get(0).asString().get()); } Add new imports. Traverse the entire subtree of the app node. Include only nodes that have the name greeting . Add the greeting node to the collection. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFrom-application.yaml under child2a World!\" } ",
            "title": "Using Filters and Collections"
        },
        {
            "location": "se/guides/config",
            "text": " Even though in-memory config trees are immutable, the config system internally records configuration source metadata that allows it to watch sources for changes. Your application listens for updates to the underlying config sources and reacts to the changes. See Config Mutability Support for a full discussion on this topic. The following example demonstrates how to listen and react to configuration changes. <markup lang=\"yaml\" title=\"Replace the contents of the config-profile.yaml file:\" >sources: - type: \"file\" properties: path: \"./config-file.properties\" change-watcher: type: \"file\" - type: \"classpath\" properties: resource: \"application.yaml\" <markup lang=\"java\" title=\"Update the GreetService class; 1) Add new import and 2) Replace the GreetService constructor:\" >import java.util.function.Consumer; ... GreetService(Config config) { Config greetingConfig = config.get(\"app.greeting\"); greeting.set(greetingConfig.asString().orElse(\"Ciao\")); greetingConfig.onChange((Consumer&lt;Config&gt;) cfg -&gt; greeting.set(cfg.asString().orElse(\"Ciao\"))); } Get the greeting Config node. Register a listener that will get called by Helidon when the configuration changes. The listener will update the greeting with the new value. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFrom-config-file.properties World!\" } <markup lang=\"bash\" title=\"Update config-file.properties with the following contents:\" >app.greeting=Updated HelloFrom-config-file.properties <markup lang=\"bash\" title=\"After a few seconds, check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"Updated HelloFrom-config-file.properties World!\" } The application reacted to the change and updated the greeting. ",
            "title": "Reacting to Configuration Updates"
        },
        {
            "location": "se/guides/config",
            "text": " You have used Helidon to customize configuration behavior from your code using the Config and Config.Builder classes. As discussed previously, Helidon reads configuration from a config source, which uses a config parser to translate the source into an in-memory tree which represents the configuration’s structure and values. Helidon offers a variety of methods to access in-memory configuration. These can be categorized as key access or tree navigation . You have been using key access for all of the examples to this point. For example app.greeting is accessing the greeting child node of the app parent node. There are many options for access this data using navigation methods as described in Hierarchical Config and Advanced Config&gt; . Accessing Config Using Keys or Navigation The simplest way to access configuration data is using a key, as shown below in the GreetService class. The key can be composite as shown below: <markup lang=\"java\" title=\"View the GreetService constructor:\" > GreetService(Config config) { greeting.set(config.get(\"app.greeting\").asString().orElse(\"Ciao\")); } Get the app.greeting node using a composite key. You can also access the same greeting by navigating the nodes. <markup lang=\"java\" title=\"Replace the GreetService constructor with the following code:\" > GreetService(Config config) { greeting.set(config.get(\"app\").get(\"greeting\").asString().orElse(\"Ciao\")); } Get the app node, then get the child node, greeting . <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFrom-application.yaml World!\" } Using Filters and Collections The Helidon Config class provides several methods that allow you to filter and customize the traversal of the configuration tree. The example below shows how to get the greeting node when you only know it is somewhere in the app subtree. <markup lang=\"bash\" title=\"Replace the contents of the config-profile.yaml file:\" >sources: - type: \"classpath\" properties: resource: \"application.yaml\" <markup lang=\"bash\" title=\"Replace the app section of the application.yaml resource file:\" >app: child1: child1-node child2: child2a: greeting: HelloFrom-application.yaml under child2a child3: child3-node <markup lang=\"java\" title=\"Update the GreetService.java file; 1) Add new imports and 2) Replace the GreetService constructor with the following:\" > import java.util.List; import java.util.stream.Collectors; GreetService(Config config) { List&lt;Config&gt; appGreetings = config.get(\"app\") .traverse() .filter(node -&gt; node.name().equals(\"greeting\")) .collect(Collectors.toList()); greeting.set(appGreetings.get(0).asString().get()); } Add new imports. Traverse the entire subtree of the app node. Include only nodes that have the name greeting . Add the greeting node to the collection. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFrom-application.yaml under child2a World!\" } Reacting to Configuration Updates Even though in-memory config trees are immutable, the config system internally records configuration source metadata that allows it to watch sources for changes. Your application listens for updates to the underlying config sources and reacts to the changes. See Config Mutability Support for a full discussion on this topic. The following example demonstrates how to listen and react to configuration changes. <markup lang=\"yaml\" title=\"Replace the contents of the config-profile.yaml file:\" >sources: - type: \"file\" properties: path: \"./config-file.properties\" change-watcher: type: \"file\" - type: \"classpath\" properties: resource: \"application.yaml\" <markup lang=\"java\" title=\"Update the GreetService class; 1) Add new import and 2) Replace the GreetService constructor:\" >import java.util.function.Consumer; ... GreetService(Config config) { Config greetingConfig = config.get(\"app.greeting\"); greeting.set(greetingConfig.asString().orElse(\"Ciao\")); greetingConfig.onChange((Consumer&lt;Config&gt;) cfg -&gt; greeting.set(cfg.asString().orElse(\"Ciao\"))); } Get the greeting Config node. Register a listener that will get called by Helidon when the configuration changes. The listener will update the greeting with the new value. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"HelloFrom-config-file.properties World!\" } <markup lang=\"bash\" title=\"Update config-file.properties with the following contents:\" >app.greeting=Updated HelloFrom-config-file.properties <markup lang=\"bash\" title=\"After a few seconds, check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"Updated HelloFrom-config-file.properties World!\" } The application reacted to the change and updated the greeting. ",
            "title": "Accessing Config within an Application"
        },
        {
            "location": "se/guides/config",
            "text": " The following example uses a Kubernetes ConfigMap to pass the configuration data to your Helidon application deployed to Kubernetes. When the pod is created, Kubernetes will automatically create a local file within the container that has the contents of the configuration file used for the ConfigMap. This example will create the file at /etc/config/config-file.properties . <markup lang=\"bash\" title=\"Replace the app section of the application.yaml resource file:\" >app: greeting: \"Hello\" <markup lang=\"java\" title=\"Update the Main class and replace the buildConfig method:\" > private static Config buildConfig() { return Config.builder() .sources( file(\"/etc/config/config-file.properties\").optional(), classpath(\"application.yaml\")) .build(); } The app.greeting value will be fetched from /etc/config/config-file.properties within the container. The server port is specified in application.yaml within the helidon-quickstart-se.jar . <markup lang=\"java\" title=\"Replace the GreetService constructor with the following code:\" > GreetService(Config config) { greeting.set(config.get(\"app.greeting\").asString().orElse(\"Ciao\")); } <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"Hello World!\" } The greeting came from application.yaml since /etc/config/config-file.properties doesn&#8217;t exist. <markup lang=\"bash\" title=\"Stop the application and build the docker image:\" >docker build -t helidon-config-se . <markup lang=\"bash\" title=\"Generate a ConfigMap from config-file.properties :\" >kubectl create configmap helidon-configmap --from-file config-file.properties <markup lang=\"bash\" title=\"View the contents of the ConfigMap:\" >kubectl get configmap helidon-configmap -o yaml ... apiVersion: v1 data: config-file.properties: | app.greeting=Updated HelloFrom-config-file.properties kind: ConfigMap ... The file config-file.properties will be created within the Kubernetes container. The config-file.properties file will have this single property defined. <markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named k8s-config.yaml , with the following contents:\" >kind: Service apiVersion: v1 metadata: name: helidon-config labels: app: helidon-config spec: type: NodePort selector: app: helidon-config ports: - port: 8080 targetPort: 8080 name: http --- kind: Deployment apiVersion: apps/v1 metadata: name: helidon-config spec: replicas: 1 selector: matchLabels: app: helidon-config template: metadata: labels: app: helidon-config version: v1 spec: containers: - name: helidon-config image: helidon-config-se imagePullPolicy: IfNotPresent ports: - containerPort: 8080 volumeMounts: - name: config-volume mountPath: /etc/config volumes: - name: config-volume configMap: # Provide the name of the ConfigMap containing the files you want # to add to the container name: helidon-configmap A service of type NodePort that serves the default routes on port 8080 . A deployment with one replica of a pod. Mount the ConfigMap as a volume at /etc/config . This is where Kubernetes will create config-file.properties . Specify the ConfigMap which contains the configuration data. <markup lang=\"bash\" title=\"Create and deploy the application into Kubernetes:\" >kubectl apply -f ./k8s-config.yaml <markup lang=\"bash\" title=\"Get the service information:\" >kubectl get service/helidon-config <markup lang=\"bash\" >NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE helidon-config NodePort 10.99.159.2 &lt;none&gt; 8080:31143/TCP 8s A service of type NodePort that serves the default routes on port 31143 . <markup lang=\"bash\" title=\"Verify the configuration endpoint using port 31143 , your port will likely be different:\" >curl http://localhost:31143/greet ... { \"message\": \"Updated HelloFrom-config-file.properties World!\" } The greeting value from /etc/config/config-file.properties within the container was used. You can now delete the Kubernetes resources that were just created during this example. <markup lang=\"bash\" title=\"Delete the Kubernetes resources:\" >kubectl delete -f ./k8s-config.yaml kubectl delete configmap helidon-configmap ",
            "title": "Integration with Kubernetes"
        },
        {
            "location": "se/guides/config",
            "text": " This guide has demonstrated how to use basic Helidon configuration features. The full configuration documentation, starting with the introduction section at Helidon Config has much more information including the following: Architecture Parsers Extensions Filters Hierarchical Access Property Mapping Mutability Support and more&#8230;&#8203; Refer to the following references for additional information: Helidon Javadoc ",
            "title": "Summary"
        },
        {
            "location": "se/guides/dbclient",
            "text": " This guide describes the features of Helidon&#8217;s DB Client and how to create a sample Helidon SE project that can be used to run some basic examples using the Helidon DB Client. ",
            "title": "preambule"
        },
        {
            "location": "se/guides/dbclient",
            "text": " For this 15 minute tutorial, you will need the following: <div class=\"table__overflow elevation-1 flex sm7 \"> A Helidon SE Application You can use your own application or use the Helidon SE Quickstart to create a sample application. Java&#160;SE&#160;17 ( Open&#160;JDK&#160;17 ) Helidon requires Java 17+. Maven 3.6.1+ Helidon requires Maven 3.6.1+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop . <markup lang=\"bash\" title=\"Verify Prerequisites\" >java -version mvn --version docker --version kubectl version --short <markup lang=\"bash\" title=\"Setting JAVA_HOME\" ># On Mac export JAVA_HOME=`/usr/libexec/java_home -v 17` # On Linux # Use the appropriate path to your JDK export JAVA_HOME=/usr/lib/jvm/jdk-17 ",
            "title": "What You Need"
        },
        {
            "location": "se/guides/dbclient",
            "text": " The main features of Helidon DB Client are: Unified API for data access and query : The API was implemented as a layer above JDBC or MongoDB Reactive Streams Java Driver, so any relational databases with JDBC driver or MongoDB are supported. Reactive database access with non-reactive drivers : Most JDBC drivers are blocking. Using them in a reactive application is problematic. Helidon DB Client allows the use of blocking JDBC drivers in your reactive application by wrapping a blocking driver in an executor service. Observability : Support for health checks, metrics and tracing. Backpressure : Performs database operations only when it is requested by the consumer. This is propagated all the way to the TCP layer. Portability between relational database drivers : Works with native database statements that can be used inline in the code or defined as named statements in database configuration. By moving the native query code to configuration files, the Helidon DB Client allows you to switch to another database by changing the configuration files, not the code. ",
            "title": "Main Features"
        },
        {
            "location": "se/guides/dbclient",
            "text": " The Helidon DB Client simplifies how you work with databases in reactive applications. It provides a unified, reactive API for working with databases in a non-blocking way. Main Features The main features of Helidon DB Client are: Unified API for data access and query : The API was implemented as a layer above JDBC or MongoDB Reactive Streams Java Driver, so any relational databases with JDBC driver or MongoDB are supported. Reactive database access with non-reactive drivers : Most JDBC drivers are blocking. Using them in a reactive application is problematic. Helidon DB Client allows the use of blocking JDBC drivers in your reactive application by wrapping a blocking driver in an executor service. Observability : Support for health checks, metrics and tracing. Backpressure : Performs database operations only when it is requested by the consumer. This is propagated all the way to the TCP layer. Portability between relational database drivers : Works with native database statements that can be used inline in the code or defined as named statements in database configuration. By moving the native query code to configuration files, the Helidon DB Client allows you to switch to another database by changing the configuration files, not the code. ",
            "title": "Introduction"
        },
        {
            "location": "se/guides/dbclient",
            "text": " Create a new file in helidon-quickstart-se named Dockerfile.h2 . It will be used to create the H2 docker image to run H2 in a container. <markup lang=\"dockerfile\" title=\"Write the following content into the new file created\" >FROM openjdk:11-jre-slim ENV H2_VERSION \"1.4.199\" ADD \"https://repo1.maven.org/maven2/com/h2database/h2/${H2_VERSION}/h2-${H2_VERSION}.jar\" /opt/h2.jar COPY h2.server.properties /root/.h2.server.properties EXPOSE 8082 EXPOSE 9092 CMD java \\ -cp /opt/h2.jar \\ org.h2.tools.Server \\ -web -webDaemon -webAllowOthers -webPort 8082 \\ -tcp -tcpAllowOthers -tcpPort 9092 \\ -ifNotExists Create a new file h2.server.properties in the current directory. <markup lang=\"properties\" title=\"Copy the properties into the properties file.\" >webSSL=false webAllowOthers=true webPort=8082 0=Generic H2 (Server)|org.h2.Driver|jdbc\\:h2\\:tcp\\://localhost\\:9092/~/test|sa <markup lang=\"bash\" title=\"Build the H2 docker image\" >docker build -f Dockerfile.h2 . -t h2db <markup lang=\"bash\" title=\"Run the H2 docker image\" >docker run --rm -p 8082:8082 -p 9092:9092 --name=h2 h2db ",
            "title": "From Docker"
        },
        {
            "location": "se/guides/dbclient",
            "text": " Download the latest H2 version from the official website: https://www.h2database.com/html/main.html Note: Windows operating system users can download the Windows Installer. Unzip the downloaded file into your directory. Only the h2-{latest-version}.jar, located in the h2/bin folder, will be needed. Open a terminal window and run the following command to start H2: <markup lang=\"bash\" title=\"Replace {latest-version} with your current H2 version:\" >java -jar h2-\\{latest-version}.jar -webAllowOthers -tcpAllowOthers <markup lang=\"bash\" title=\"Terminal output\" >Web Console server running at http://127.0.1.1:8082 (others can connect) Opening in existing browser session. TCP server running at tcp://127.0.1.1:9092 (others can connect) PG server running at pg://127.0.1.1:5435 (only local connections) ",
            "title": "From the Command Line"
        },
        {
            "location": "se/guides/dbclient",
            "text": " H2 is a Java SQL database that is lightweight and easy to use. If H2 is not installed on your machine, here are few steps to quickly download and set it up: From Docker Create a new file in helidon-quickstart-se named Dockerfile.h2 . It will be used to create the H2 docker image to run H2 in a container. <markup lang=\"dockerfile\" title=\"Write the following content into the new file created\" >FROM openjdk:11-jre-slim ENV H2_VERSION \"1.4.199\" ADD \"https://repo1.maven.org/maven2/com/h2database/h2/${H2_VERSION}/h2-${H2_VERSION}.jar\" /opt/h2.jar COPY h2.server.properties /root/.h2.server.properties EXPOSE 8082 EXPOSE 9092 CMD java \\ -cp /opt/h2.jar \\ org.h2.tools.Server \\ -web -webDaemon -webAllowOthers -webPort 8082 \\ -tcp -tcpAllowOthers -tcpPort 9092 \\ -ifNotExists Create a new file h2.server.properties in the current directory. <markup lang=\"properties\" title=\"Copy the properties into the properties file.\" >webSSL=false webAllowOthers=true webPort=8082 0=Generic H2 (Server)|org.h2.Driver|jdbc\\:h2\\:tcp\\://localhost\\:9092/~/test|sa <markup lang=\"bash\" title=\"Build the H2 docker image\" >docker build -f Dockerfile.h2 . -t h2db <markup lang=\"bash\" title=\"Run the H2 docker image\" >docker run --rm -p 8082:8082 -p 9092:9092 --name=h2 h2db From the Command Line Download the latest H2 version from the official website: https://www.h2database.com/html/main.html Note: Windows operating system users can download the Windows Installer. Unzip the downloaded file into your directory. Only the h2-{latest-version}.jar, located in the h2/bin folder, will be needed. Open a terminal window and run the following command to start H2: <markup lang=\"bash\" title=\"Replace {latest-version} with your current H2 version:\" >java -jar h2-\\{latest-version}.jar -webAllowOthers -tcpAllowOthers <markup lang=\"bash\" title=\"Terminal output\" >Web Console server running at http://127.0.1.1:8082 (others can connect) Opening in existing browser session. TCP server running at tcp://127.0.1.1:9092 (others can connect) PG server running at pg://127.0.1.1:5435 (only local connections) ",
            "title": "Set Up the H2 database"
        },
        {
            "location": "se/guides/dbclient",
            "text": " Open the console at http://127.0.1.1:8082 in your favorite browser. It displays a login window. Select Generic H2 from Saved Settings . The following settings should be set by default: Driver Class: org.h2.Driver JDBC URL: jdbc:h2:tcp://localhost:9092/~/test User Name: sa Password: Password must stay empty. Click Connect , the browser displays a web page. The database is correctly set and running. ",
            "title": "Connect to the Database"
        },
        {
            "location": "se/guides/dbclient",
            "text": " Generate the project sources using the Helidon SE Maven archetype. The result is a simple project that can be used for the examples in this guide. <markup lang=\"bash\" title=\"Run the Maven archetype:\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-se \\ -DarchetypeVersion=3.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-se \\ -Dpackage=io.helidon.examples.quickstart.se A new directory named helidon-quickstart-se is created. <markup lang=\"bash\" title=\"Enter into this directory:\" >cd helidon-quickstart-se ",
            "title": "Create a Sample SE Project Using Maven Archetype"
        },
        {
            "location": "se/guides/dbclient",
            "text": " Navigate to the helidon-quickstart-se directory and open the pom.xml file to add the following Helidon dependencies required to use the DB Client: <markup lang=\"xml\" title=\"Copy these dependencies to pom.xml:\" >&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.dbclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-dbclient&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.dbclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-dbclient-jdbc&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.db&lt;/groupId&gt; &lt;artifactId&gt;h2&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.dbclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-dbclient-health&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.dbclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-dbclient-metrics&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.dbclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-dbclient-jsonp&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; DB Client API dependency. Using JDBC driver for this example. H2 driver dependency. Support for health check. Support for metrics. Support for Jsonp. ",
            "title": "Add Dependencies"
        },
        {
            "location": "se/guides/dbclient",
            "text": " To configure the application, Helidon uses the application.yaml . The DB Client configuration can be joined in the same file and is located here: src/main/resources . <markup lang=\"yaml\" title=\"Copy these properties into application.yaml\" >db: source: jdbc connection: url: \"jdbc:h2:tcp://localhost:9092/~/test\" username: \"sa\" password: statements: create-table: \"CREATE TABLE IF NOT EXISTS LIBRARY (NAME VARCHAR NOT NULL, INFO VARCHAR NOT NULL)\" insert-book: \"INSERT INTO LIBRARY (NAME, INFO) VALUES (:name, :info)\" select-book: \"SELECT INFO FROM LIBRARY WHERE NAME = ?\" delete-book: \"DELETE FROM LIBRARY WHERE NAME = ?\" Source property support two values: jdbc and mongo. Connection detail we used to set up H2. SQL statements to manage the database. ",
            "title": "Configure the DB Client"
        },
        {
            "location": "se/guides/dbclient",
            "text": " In the application Main.class , an instance of DbClient is created based on the configuration from application.yaml . <markup lang=\"java\" title=\"Create a DbClient in the Main.startServer method:\" >import io.helidon.dbclient.metrics.DbClientMetrics; import io.helidon.dbclient.DbClient; Config config = Config.create(); // Landmark to add DB client DbClient dbClient = DbClient.builder() .config(config.get(\"db\")) .addService(DbClientMetrics.counter().statementNames(\"select-book\")) .build(); Add import statements Configure the DB Client with the \"db\" section of application.yaml. Add a counter for metrics. The DB Client metric counter will be executed only for the select-book statement and it will check how many times it was invoked. At this point, the database is empty, and needs to be initialized. To achieve that, the DB Client can be used to create a table in the database. <markup lang=\"java\" title=\"Insert a createTable method below the dbClient:\" >DbClient dbClient = DbClient.builder() .config(config.get(\"db\")) .addService(DbClientMetrics.counter().statementNames(\"select-book\")) .build(); createTable(dbClient); <markup lang=\"java\" title=\"Use the DbClient to build a table:\" >private static void createTable(DbClient dbClient) { dbClient.execute(exec -&gt; exec.namedDml(\"create-table\")) .await(); } Use the \"create-table\" script to build a table with book name and information. The createTable is invoked only once and creates an empty table with two columns: name and info. The script is used to boostrap the server, so the await method is called in this particular case because the table must be created before the server starts. A new service can manage requests to interact with this table which represents our library.The services are registered in the createRouting method. <markup lang=\"java\" title=\"Modify the createRouting method:\" >import io.helidon.dbclient.health.DbClientHealthCheck; WebServer server = WebServer.builder(createRouting(config, dbClient)) .config(config.get(\"server\")) .addMediaSupport(JsonpSupport.create()) .build(); private static Routing createRouting(Config config, DbClient dbClient) { HealthSupport health = HealthSupport.builder() .addLiveness(DbClientHealthCheck.create(dbClient)) .build(); return Routing.builder() .register(health) // Health at \"/health\" .register(MetricsSupport.create()) // Metrics at \"/metrics\" .register(\"/greet\", new GreetService(config)) .register(\"/library\", new LibraryService(dbClient)) .build(); } Add dbClient as a parameter of createRouting method. Add Health check to control the application behavior. Register the LibraryService to the Routing. The library service does not yet exist, but you&#8217;ll creat it in the next step of the guide. It has a constructor with the DB Client as a parameter because it will manage the library. The DB Client health check uses the select-book statement from the configuration. As shown above, to create a DB Client health check, call the DbClientHealthCheck.create method and pass the concerned DbClient. Then add it to the health support builder and register it to the routing. ",
            "title": "Build and Set Up Helidon DB Client"
        },
        {
            "location": "se/guides/dbclient",
            "text": " Create LibraryService class into io.helidon.examples.quickstart.se package. <markup lang=\"java\" title=\"LibraryService class looks like this:\" >package io.helidon.examples.quickstart.se; import io.helidon.common.http.Http; import io.helidon.dbclient.DbClient; import io.helidon.webserver.Routing; import io.helidon.webserver.ServerRequest; import io.helidon.webserver.ServerResponse; import io.helidon.webserver.Service; public class LibraryService implements Service { private final DbClient dbClient; LibraryService(DbClient pDbClient){ this.dbClient = pDbClient; } } Add new import statement Declare the Helidon DB Client A DB Client instance is provided when LibraryService is instantiated. As the LibraryService implements io.helidon.webserver.Service , the update(Routing) method has to be implemented. It defines application endpoints and Http request which can be reached by clients. <markup lang=\"java\" title=\"Add update method to LibraryService\" >@Override public void update(Routing.Rules rules) { rules .get(\"/{name}\", this::getBook) .put(\"/{name}\", this::addBook) .delete(\"/{name}\", this::deleteBook) .get(\"/json/{name}\", this::getJsonBook); } Return information about the required book from the database. Add a book to the library. Remove a book from the library. Return the book information in Json format. To summarize, there is one endpoint that can manipulate books. The number of endpoints and application features can be changed from these rules by creating or modifying methods. {name} is a path parameter for the book name. The architecture of the application is defined, so the next step is to create these features. <markup lang=\"java\" title=\"Add getBook to the LibraryService:\" >private void getBook(ServerRequest serverRequest, ServerResponse serverResponse) { String bookName = serverRequest.path().param(\"name\"); dbClient.execute(exec -&gt; exec.namedGet(\"select-book\", bookName)) .thenAccept(row -&gt; { if (row.isPresent()) { serverResponse.send(row.get().column(\"INFO\").as(String.class)); } else { serverResponse.status(Http.Status.NOT_FOUND_404) .send(); } }) .exceptionally(serverResponse::send); } Get the book name from the path in the URL. Helidon DB Client executes the select-book SQL script from application.yaml. Sends book information to the client. Sends 404 HTTP status if no book was found for the given name. If an exception occurred during the process, it is sent to the client. The getBook method reach the book from the database and send the information to the client. The name of the book is located into the url path. If the book is not present in the database, a HTTP 404 is sent back. The execute(Function&lt;DbExecute, T&gt; executor) method is called on the dbClient instance to execute one statement. Nevertheless, it is possible to execute a set of tasks into a single execution unit by using inTransaction (Function&lt;DbTransaction, T&gt; executor) method. DbExecute class provides many builders to create statements such as, DML, insert, update, delete, query and get statements. For each statement there are two builders which can be regrouped in 2 categories. Builders with methods containing Named keyword, they use a statement defined in the configuration file. And builders without Named keyword, they use a statement passed as an argument. More information on the Helidon DB Client here . <markup lang=\"java\" title=\"Add getJsonBook to the LibraryService:\" >private void getJsonBook(ServerRequest serverRequest, ServerResponse serverResponse) { String bookName = serverRequest.path().param(\"name\"); dbClient.execute(exec -&gt; exec.namedGet(\"select-book\", bookName)) .thenAccept(row -&gt; { if (row.isPresent()) { serverResponse.send(row.get().as(JsonObject.class)); } else { serverResponse.status(Http.Status.NOT_FOUND_404) .send(); } }) .exceptionally(serverResponse::send); } Instead of sending the INFO content of the targeted book, the getJsonBook method send the whole row of the database as a JsonObject . <markup lang=\"java\" title=\"Add addBook to the LibraryService:\" >private void addBook(ServerRequest serverRequest, ServerResponse serverResponse) { String bookName = serverRequest.path().param(\"name\"); serverRequest.content() .as(String.class) .thenAccept(newValue -&gt; { dbClient.execute(exec -&gt; exec.createNamedInsert(\"insert-book\") .addParam(\"name\", bookName) .addParam(\"info\", newValue) .execute()) .thenAccept(count -&gt; serverResponse.status(Http.Status.CREATED_201).send()) .exceptionally(serverResponse::send); }); } The SQL statement requires the book name and its information. They are provided with addParam method. A new book was added to library, so a HTTP 201 code is returned. When a user adds a new book, it uses HTTP PUT method where the book name is in the URL and the information in the request content. To catch this content, the information is retrieved as a string and then the DB Client execute the insert-book script to add the book to the library. It requires two parameters, the book name and information which are passed to the dbClient thanks to addParam method. A HTTP 201 is sent back as a confirmation if no exception is thrown. <markup lang=\"java\" title=\"Add deleteBook to LibraryService:\" >private void deleteBook(ServerRequest serverRequest, ServerResponse serverResponse) { String bookName = serverRequest.path().param(\"name\"); dbClient.execute(exec -&gt; exec.namedDelete(\"delete-book\", bookName)) .thenAccept(count -&gt; serverResponse.status(Http.Status.NO_CONTENT_204).send()) .exceptionally(serverResponse::send); } Execute SQL script from application.yaml to remove a book from the library by its name. The required book was removed, so a HTTP 204 is sent. To remove a book from the library, use the \"delete-book\" script in the way than previously. If the book is removed successfully, a HTTP 204 is sent back. ",
            "title": "Create the Library service"
        },
        {
            "location": "se/guides/dbclient",
            "text": " This section describes how to configure and use the key features of the Helidon DB Client. Set Up the H2 database H2 is a Java SQL database that is lightweight and easy to use. If H2 is not installed on your machine, here are few steps to quickly download and set it up: From Docker Create a new file in helidon-quickstart-se named Dockerfile.h2 . It will be used to create the H2 docker image to run H2 in a container. <markup lang=\"dockerfile\" title=\"Write the following content into the new file created\" >FROM openjdk:11-jre-slim ENV H2_VERSION \"1.4.199\" ADD \"https://repo1.maven.org/maven2/com/h2database/h2/${H2_VERSION}/h2-${H2_VERSION}.jar\" /opt/h2.jar COPY h2.server.properties /root/.h2.server.properties EXPOSE 8082 EXPOSE 9092 CMD java \\ -cp /opt/h2.jar \\ org.h2.tools.Server \\ -web -webDaemon -webAllowOthers -webPort 8082 \\ -tcp -tcpAllowOthers -tcpPort 9092 \\ -ifNotExists Create a new file h2.server.properties in the current directory. <markup lang=\"properties\" title=\"Copy the properties into the properties file.\" >webSSL=false webAllowOthers=true webPort=8082 0=Generic H2 (Server)|org.h2.Driver|jdbc\\:h2\\:tcp\\://localhost\\:9092/~/test|sa <markup lang=\"bash\" title=\"Build the H2 docker image\" >docker build -f Dockerfile.h2 . -t h2db <markup lang=\"bash\" title=\"Run the H2 docker image\" >docker run --rm -p 8082:8082 -p 9092:9092 --name=h2 h2db From the Command Line Download the latest H2 version from the official website: https://www.h2database.com/html/main.html Note: Windows operating system users can download the Windows Installer. Unzip the downloaded file into your directory. Only the h2-{latest-version}.jar, located in the h2/bin folder, will be needed. Open a terminal window and run the following command to start H2: <markup lang=\"bash\" title=\"Replace {latest-version} with your current H2 version:\" >java -jar h2-\\{latest-version}.jar -webAllowOthers -tcpAllowOthers <markup lang=\"bash\" title=\"Terminal output\" >Web Console server running at http://127.0.1.1:8082 (others can connect) Opening in existing browser session. TCP server running at tcp://127.0.1.1:9092 (others can connect) PG server running at pg://127.0.1.1:5435 (only local connections) Connect to the Database Open the console at http://127.0.1.1:8082 in your favorite browser. It displays a login window. Select Generic H2 from Saved Settings . The following settings should be set by default: Driver Class: org.h2.Driver JDBC URL: jdbc:h2:tcp://localhost:9092/~/test User Name: sa Password: Password must stay empty. Click Connect , the browser displays a web page. The database is correctly set and running. Create a Sample SE Project Using Maven Archetype Generate the project sources using the Helidon SE Maven archetype. The result is a simple project that can be used for the examples in this guide. <markup lang=\"bash\" title=\"Run the Maven archetype:\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-se \\ -DarchetypeVersion=3.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-se \\ -Dpackage=io.helidon.examples.quickstart.se A new directory named helidon-quickstart-se is created. <markup lang=\"bash\" title=\"Enter into this directory:\" >cd helidon-quickstart-se Add Dependencies Navigate to the helidon-quickstart-se directory and open the pom.xml file to add the following Helidon dependencies required to use the DB Client: <markup lang=\"xml\" title=\"Copy these dependencies to pom.xml:\" >&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.dbclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-dbclient&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.dbclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-dbclient-jdbc&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.db&lt;/groupId&gt; &lt;artifactId&gt;h2&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.dbclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-dbclient-health&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.dbclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-dbclient-metrics&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.dbclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-dbclient-jsonp&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; DB Client API dependency. Using JDBC driver for this example. H2 driver dependency. Support for health check. Support for metrics. Support for Jsonp. Configure the DB Client To configure the application, Helidon uses the application.yaml . The DB Client configuration can be joined in the same file and is located here: src/main/resources . <markup lang=\"yaml\" title=\"Copy these properties into application.yaml\" >db: source: jdbc connection: url: \"jdbc:h2:tcp://localhost:9092/~/test\" username: \"sa\" password: statements: create-table: \"CREATE TABLE IF NOT EXISTS LIBRARY (NAME VARCHAR NOT NULL, INFO VARCHAR NOT NULL)\" insert-book: \"INSERT INTO LIBRARY (NAME, INFO) VALUES (:name, :info)\" select-book: \"SELECT INFO FROM LIBRARY WHERE NAME = ?\" delete-book: \"DELETE FROM LIBRARY WHERE NAME = ?\" Source property support two values: jdbc and mongo. Connection detail we used to set up H2. SQL statements to manage the database. Build and Set Up Helidon DB Client In the application Main.class , an instance of DbClient is created based on the configuration from application.yaml . <markup lang=\"java\" title=\"Create a DbClient in the Main.startServer method:\" >import io.helidon.dbclient.metrics.DbClientMetrics; import io.helidon.dbclient.DbClient; Config config = Config.create(); // Landmark to add DB client DbClient dbClient = DbClient.builder() .config(config.get(\"db\")) .addService(DbClientMetrics.counter().statementNames(\"select-book\")) .build(); Add import statements Configure the DB Client with the \"db\" section of application.yaml. Add a counter for metrics. The DB Client metric counter will be executed only for the select-book statement and it will check how many times it was invoked. At this point, the database is empty, and needs to be initialized. To achieve that, the DB Client can be used to create a table in the database. <markup lang=\"java\" title=\"Insert a createTable method below the dbClient:\" >DbClient dbClient = DbClient.builder() .config(config.get(\"db\")) .addService(DbClientMetrics.counter().statementNames(\"select-book\")) .build(); createTable(dbClient); <markup lang=\"java\" title=\"Use the DbClient to build a table:\" >private static void createTable(DbClient dbClient) { dbClient.execute(exec -&gt; exec.namedDml(\"create-table\")) .await(); } Use the \"create-table\" script to build a table with book name and information. The createTable is invoked only once and creates an empty table with two columns: name and info. The script is used to boostrap the server, so the await method is called in this particular case because the table must be created before the server starts. A new service can manage requests to interact with this table which represents our library.The services are registered in the createRouting method. <markup lang=\"java\" title=\"Modify the createRouting method:\" >import io.helidon.dbclient.health.DbClientHealthCheck; WebServer server = WebServer.builder(createRouting(config, dbClient)) .config(config.get(\"server\")) .addMediaSupport(JsonpSupport.create()) .build(); private static Routing createRouting(Config config, DbClient dbClient) { HealthSupport health = HealthSupport.builder() .addLiveness(DbClientHealthCheck.create(dbClient)) .build(); return Routing.builder() .register(health) // Health at \"/health\" .register(MetricsSupport.create()) // Metrics at \"/metrics\" .register(\"/greet\", new GreetService(config)) .register(\"/library\", new LibraryService(dbClient)) .build(); } Add dbClient as a parameter of createRouting method. Add Health check to control the application behavior. Register the LibraryService to the Routing. The library service does not yet exist, but you&#8217;ll creat it in the next step of the guide. It has a constructor with the DB Client as a parameter because it will manage the library. The DB Client health check uses the select-book statement from the configuration. As shown above, to create a DB Client health check, call the DbClientHealthCheck.create method and pass the concerned DbClient. Then add it to the health support builder and register it to the routing. Create the Library service Create LibraryService class into io.helidon.examples.quickstart.se package. <markup lang=\"java\" title=\"LibraryService class looks like this:\" >package io.helidon.examples.quickstart.se; import io.helidon.common.http.Http; import io.helidon.dbclient.DbClient; import io.helidon.webserver.Routing; import io.helidon.webserver.ServerRequest; import io.helidon.webserver.ServerResponse; import io.helidon.webserver.Service; public class LibraryService implements Service { private final DbClient dbClient; LibraryService(DbClient pDbClient){ this.dbClient = pDbClient; } } Add new import statement Declare the Helidon DB Client A DB Client instance is provided when LibraryService is instantiated. As the LibraryService implements io.helidon.webserver.Service , the update(Routing) method has to be implemented. It defines application endpoints and Http request which can be reached by clients. <markup lang=\"java\" title=\"Add update method to LibraryService\" >@Override public void update(Routing.Rules rules) { rules .get(\"/{name}\", this::getBook) .put(\"/{name}\", this::addBook) .delete(\"/{name}\", this::deleteBook) .get(\"/json/{name}\", this::getJsonBook); } Return information about the required book from the database. Add a book to the library. Remove a book from the library. Return the book information in Json format. To summarize, there is one endpoint that can manipulate books. The number of endpoints and application features can be changed from these rules by creating or modifying methods. {name} is a path parameter for the book name. The architecture of the application is defined, so the next step is to create these features. <markup lang=\"java\" title=\"Add getBook to the LibraryService:\" >private void getBook(ServerRequest serverRequest, ServerResponse serverResponse) { String bookName = serverRequest.path().param(\"name\"); dbClient.execute(exec -&gt; exec.namedGet(\"select-book\", bookName)) .thenAccept(row -&gt; { if (row.isPresent()) { serverResponse.send(row.get().column(\"INFO\").as(String.class)); } else { serverResponse.status(Http.Status.NOT_FOUND_404) .send(); } }) .exceptionally(serverResponse::send); } Get the book name from the path in the URL. Helidon DB Client executes the select-book SQL script from application.yaml. Sends book information to the client. Sends 404 HTTP status if no book was found for the given name. If an exception occurred during the process, it is sent to the client. The getBook method reach the book from the database and send the information to the client. The name of the book is located into the url path. If the book is not present in the database, a HTTP 404 is sent back. The execute(Function&lt;DbExecute, T&gt; executor) method is called on the dbClient instance to execute one statement. Nevertheless, it is possible to execute a set of tasks into a single execution unit by using inTransaction (Function&lt;DbTransaction, T&gt; executor) method. DbExecute class provides many builders to create statements such as, DML, insert, update, delete, query and get statements. For each statement there are two builders which can be regrouped in 2 categories. Builders with methods containing Named keyword, they use a statement defined in the configuration file. And builders without Named keyword, they use a statement passed as an argument. More information on the Helidon DB Client here . <markup lang=\"java\" title=\"Add getJsonBook to the LibraryService:\" >private void getJsonBook(ServerRequest serverRequest, ServerResponse serverResponse) { String bookName = serverRequest.path().param(\"name\"); dbClient.execute(exec -&gt; exec.namedGet(\"select-book\", bookName)) .thenAccept(row -&gt; { if (row.isPresent()) { serverResponse.send(row.get().as(JsonObject.class)); } else { serverResponse.status(Http.Status.NOT_FOUND_404) .send(); } }) .exceptionally(serverResponse::send); } Instead of sending the INFO content of the targeted book, the getJsonBook method send the whole row of the database as a JsonObject . <markup lang=\"java\" title=\"Add addBook to the LibraryService:\" >private void addBook(ServerRequest serverRequest, ServerResponse serverResponse) { String bookName = serverRequest.path().param(\"name\"); serverRequest.content() .as(String.class) .thenAccept(newValue -&gt; { dbClient.execute(exec -&gt; exec.createNamedInsert(\"insert-book\") .addParam(\"name\", bookName) .addParam(\"info\", newValue) .execute()) .thenAccept(count -&gt; serverResponse.status(Http.Status.CREATED_201).send()) .exceptionally(serverResponse::send); }); } The SQL statement requires the book name and its information. They are provided with addParam method. A new book was added to library, so a HTTP 201 code is returned. When a user adds a new book, it uses HTTP PUT method where the book name is in the URL and the information in the request content. To catch this content, the information is retrieved as a string and then the DB Client execute the insert-book script to add the book to the library. It requires two parameters, the book name and information which are passed to the dbClient thanks to addParam method. A HTTP 201 is sent back as a confirmation if no exception is thrown. <markup lang=\"java\" title=\"Add deleteBook to LibraryService:\" >private void deleteBook(ServerRequest serverRequest, ServerResponse serverResponse) { String bookName = serverRequest.path().param(\"name\"); dbClient.execute(exec -&gt; exec.namedDelete(\"delete-book\", bookName)) .thenAccept(count -&gt; serverResponse.status(Http.Status.NO_CONTENT_204).send()) .exceptionally(serverResponse::send); } Execute SQL script from application.yaml to remove a book from the library by its name. The required book was removed, so a HTTP 204 is sent. To remove a book from the library, use the \"delete-book\" script in the way than previously. If the book is removed successfully, a HTTP 204 is sent back. ",
            "title": "Getting Started with Helidon DB Client"
        },
        {
            "location": "se/guides/dbclient",
            "text": " This guide provided an introduction to the Helidon DB Client&#8217;s key features. If you want to learn more, see the Helidon DB Client samples in https://medium.com/helidon/helidon-db-client-e12bbdc85b7 . ",
            "title": "Summary"
        },
        {
            "location": "se/guides/dbclient",
            "text": " The application is ready to be built and run. <markup lang=\"bash\" title=\"Run the following to build the application:\" >mvn package Note that the tests are passing as the GreetService process was not modified. For the purposes of this demonstration, we only added independent new content to the existing application. Make sure H2 is running and start the Helidon quickstart with this command: <markup lang=\"bash\" title=\"Run the application\" >java -jar target/helidon-quickstart-se.jar Once the application starts, check the table LIBRARY is created in the H2 database. To do so, go to the H2 Server console and LIBRARY table should be present in the left column under jdbc:h2:tcp://localhost:9092/~/test . If it is not, try to refresh the page, and it should appear. Use curl to send request to the application: <markup lang=\"bash\" title=\"Get a book from the library\" >curl -i http://localhost:8080/library/SomeBook <markup lang=\"listing\" title=\"HTTP response\" >HTTP/1.1 404 Not Found Date: Tue, 12 Jan 2021 14:00:48 +0100 transfer-encoding: chunked connection: keep-alive There is currently no book inside the library, so the application returns a 404. Yet the application created an empty library table. Try to add a new book. <markup lang=\"bash\" title=\"Add a book from the library\" >curl -i -X PUT -d \"Fantasy\" http://localhost:8080/library/HarryPotter <markup lang=\"listing\" title=\"HTTP response\" >HTTP/1.1 201 Created Date: Tue, 12 Jan 2021 14:01:08 +0100 transfer-encoding: chunked connection: keep-alive This command creates an HTTP PUT request with the genre Fantasy content at the address http://localhost:8080/library/{book-name} . The 201 code means that Harry Potter book was successfully added to the library. You can now try to get it ! <markup lang=\"bash\" title=\"Get Harry Potter from the library\" >curl -i http://localhost:8080/library/HarryPotter <markup lang=\"listing\" title=\"HTTP response\" >HTTP/1.1 200 OK Content-Type: text/plain Date: Tue, 12 Jan 2021 14:01:14 +0100 connection: keep-alive content-length: 6 Fantasy The application accepted the request and returned an HTTP 200 OK with the book genre that was added earlier. <markup lang=\"bash\" title=\"Get Harry Potter from the library in Json\" >curl -i http://localhost:8080/library/json/HarryPotter <markup lang=\"listing\" title=\"HTTP response\" >HTTP/1.1 200 OK Content-Type: text/plain Date: Tue, 12 Jan 2021 14:01:14 +0100 connection: keep-alive content-length: 6 {\"INFO\":\"Fantasy\"} It returns the database row in a Json format for the Harry Potter book. Harry Potter can be removed from the library with the following: <markup lang=\"bash\" title=\"Remove Harry Potter from the library\" >curl -i -X DELETE http://localhost:8080/library/HarryPotter <markup lang=\"listing\" title=\"HTTP response\" >HTTP/1.1 204 No Content Date: Tue, 12 Jan 2021 14:01:22 +0100 connection: keep-alive The book had been removed from the library and confirmed by the 204 HTTP status. To check that the book was correctly deleted, try to get it again. <markup lang=\"bash\" title=\"Get Harry Potter from the library\" >curl -i http://localhost:8080/library/HarryPotter <markup lang=\"listing\" title=\"HTTP response\" >HTTP/1.1 404 Not Found Date: Tue, 12 Jan 2021 14:00:48 +0100 transfer-encoding: chunked connection: keep-alive The book is not found. We quickly checked, thanks to this suite of command, the application behavior. <markup lang=\"bash\" title=\"Check the health of your application:\" >curl http://localhost:8080/health <markup lang=\"json\" title=\"Response body\" >{ \"state\" : \"UP\", \"status\" : \"UP\", \"name\" : \"jdbc:h2\" } It confirms that the database is UP. <markup lang=\"bash\" title=\"Check the metrics of your application:\" >curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"Response body\" >{ \"db.counter.select-book\" : 4 } The select-book statement was invoked four times. Summary This guide provided an introduction to the Helidon DB Client&#8217;s key features. If you want to learn more, see the Helidon DB Client samples in https://medium.com/helidon/helidon-db-client-e12bbdc85b7 . ",
            "title": "Build and Run the Library Application"
        },
        {
            "location": "se/guides/graalnative",
            "text": " This guide describes how to build a GraalVM native image for a Helidon SE application. ",
            "title": "preambule"
        },
        {
            "location": "se/guides/graalnative",
            "text": " Native images are ahead-of-time compiled Java code that result in a self contained native executable. When used appropriately native images have dramatically faster startup and lower runtime memory overhead compared to a Java VM. In this guide you will learn how to build a native image locally on your machine, as well as using Docker. ",
            "title": "Introduction"
        },
        {
            "location": "se/guides/graalnative",
            "text": " For this 10 minute tutorial, you will need the following: <div class=\"table__overflow elevation-1 flex sm7 \"> A Helidon SE Application You can use your own application or use the Helidon SE Quickstart to create a sample application. Java&#160;SE&#160;17 ( Open&#160;JDK&#160;17 ) Helidon requires Java 17+. Maven 3.6.1+ Helidon requires Maven 3.6.1+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop . GraalVM CE 21.0.0 <markup lang=\"bash\" title=\"Verify Prerequisites\" >java -version mvn --version docker --version kubectl version --short <markup lang=\"bash\" title=\"Setting JAVA_HOME\" ># On Mac export JAVA_HOME=`/usr/libexec/java_home -v 17` # On Linux # Use the appropriate path to your JDK export JAVA_HOME=/usr/lib/jvm/jdk-17 ",
            "title": "What You Need"
        },
        {
            "location": "se/guides/graalnative",
            "text": " After downloading and installing GraalVM, set the GRAALVM_HOME environment variable to point at your GraalVM installation. <markup lang=\"bash\" ># Your path might be different export GRAALVM_HOME=/usr/local/graalvm-ce-21.3.0/Contents/Home/ Then install the optional native-image command: <markup lang=\"bash\" >$GRAALVM_HOME/bin/gu install native-image And verify: <markup lang=\"bash\" >$GRAALVM_HOME/bin/java -version $GRAALVM_HOME/bin/native-image --version ",
            "title": "Install GraalVM and the Native Image Command"
        },
        {
            "location": "se/guides/graalnative",
            "text": " Generate the project using the Helidon SE Quickstart Maven archetype. <markup lang=\"bash\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-se \\ -DarchetypeVersion=3.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-se \\ -Dpackage=io.helidon.examples.quickstart.se The archetype generates a Maven project in your current directory (for example, helidon-quickstart-se ). Change into this directory and build. <markup lang=\"bash\" >cd helidon-quickstart-se mvn package At this point you can run the application using the JVM: <markup lang=\"bash\" >java -jar target/helidon-quickstart-se.jar In another shell test an endpoint: <markup lang=\"bash\" >curl -X GET http://localhost:8080/greet The application should respond with {\"message\":\"Hello World!\"} Now stop the running application (by pressing Ctrl+C). For more information about the Quickstart application and other endpoints it supports see the Helidon SE Quickstart Guide . ",
            "title": "Generate the Project"
        },
        {
            "location": "se/guides/graalnative",
            "text": " Make sure you have GraalVM locally installed: <markup lang=\"bash\" >$GRAALVM_HOME/bin/native-image --version Build the native image using the native image profile: <markup lang=\"bash\" >mvn package -Pnative-image Tip This uses the helidon-maven-plugin to perform the native compilation using your installed copy of GraalVM. It might take a while to complete. Once it completes start the application using the native executable (no JVM!): <markup lang=\"bash\" >./target/helidon-quickstart-se Yep, it starts fast. You can exercise the application&#8217;s endpoints as before. ",
            "title": "Local build"
        },
        {
            "location": "se/guides/graalnative",
            "text": " Build the \"native\" Docker image <markup lang=\"bash\" >docker build -t helidon-quickstart-se-native -f Dockerfile.native . Tip This does a full build inside the Docker container. The first time you run it, it will take a while because it is downloading all of the Maven dependencies and caching them in a Docker layer. Subsequent builds will be much faster as long as you don&#8217;t change the pom.xml file. If the pom is modified then the dependencies will be re-downloaded. Start the application: <markup lang=\"bash\" >docker run --rm -p 8080:8080 helidon-quickstart-se-native:latest Again, it starts fast. You can exercise the application&#8217;s endpoints as before. ",
            "title": "Multi-stage Docker build"
        },
        {
            "location": "se/guides/graalnative",
            "text": " You can build a native executable in 2 different ways: With a local installation of GraalVM Using Docker Local build Make sure you have GraalVM locally installed: <markup lang=\"bash\" >$GRAALVM_HOME/bin/native-image --version Build the native image using the native image profile: <markup lang=\"bash\" >mvn package -Pnative-image Tip This uses the helidon-maven-plugin to perform the native compilation using your installed copy of GraalVM. It might take a while to complete. Once it completes start the application using the native executable (no JVM!): <markup lang=\"bash\" >./target/helidon-quickstart-se Yep, it starts fast. You can exercise the application&#8217;s endpoints as before. Multi-stage Docker build Build the \"native\" Docker image <markup lang=\"bash\" >docker build -t helidon-quickstart-se-native -f Dockerfile.native . Tip This does a full build inside the Docker container. The first time you run it, it will take a while because it is downloading all of the Maven dependencies and caching them in a Docker layer. Subsequent builds will be much faster as long as you don&#8217;t change the pom.xml file. If the pom is modified then the dependencies will be re-downloaded. Start the application: <markup lang=\"bash\" >docker run --rm -p 8080:8080 helidon-quickstart-se-native:latest Again, it starts fast. You can exercise the application&#8217;s endpoints as before. ",
            "title": "Building a Native Image"
        },
        {
            "location": "se/guides/graalnative",
            "text": " Native images are ideal for applications with high horizontal scalability requirements where the ability to rapidly scale out to numerous instances is important. That said, native images do have some limitations , and for long running applications where startup and footprint are less of a priority, the Java SE HotSpot VM might be more appropriate. For information about creating custom Java runtime images see Custom Runtime Images with jlink . ",
            "title": "When should I use Native Images?"
        },
        {
            "location": "se/guides/gradle-build",
            "text": " This guide describes Helidon&#8217;s support for Gradle projects. ",
            "title": "preambule"
        },
        {
            "location": "se/guides/gradle-build",
            "text": " While most of Helidon&#8217;s examples use Maven, you can also use Helidon with a Gradle project. We recommend Gradle 6+. ",
            "title": "Introduction"
        },
        {
            "location": "se/guides/gradle-build",
            "text": " The Helidon Quickstart Example contains a build.gradle file that you can use as an example for building your Helidon application using Gradle. ",
            "title": "Gradle Example"
        },
        {
            "location": "se/guides/gradle-build",
            "text": " Gradle supports using a Maven POM to perform dependency management. You can use the Helidon Dependencies POM for this purpose. Once you import the Helidon dependency management POM you can specify dependencies without providing a version. <markup lang=\"xml\" title=\"Using the Helidon Dependencies POM\" >dependencies { // import Helidon dependency management implementation platform(\"io.helidon:helidon-dependencies:${project.helidonversion}\") implementation 'io.helidon.microprofile.bundles:helidon-microprofile' implementation 'org.glassfish.jersey.media:jersey-media-json-binding' runtimeOnly 'org.jboss:jandex' runtimeOnly 'javax.activation:javax.activation-api' testCompileOnly 'org.junit.jupiter:junit-jupiter-api:' } ",
            "title": "Dependency Management"
        },
        {
            "location": "se/guides/health",
            "text": " This guide describes how to create a sample Helidon SE project that can be used to run some basic examples using both built-in and custom health checks. ",
            "title": "preambule"
        },
        {
            "location": "se/guides/health",
            "text": " Generate the project sources using the Helidon SE Maven archetype. The result is a simple project that can be used for the examples in this guide. <markup lang=\"bash\" title=\"Run the Maven archetype:\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-se \\ -DarchetypeVersion=3.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-se \\ -Dpackage=io.helidon.examples.quickstart.se ",
            "title": "Create a Sample SE Project"
        },
        {
            "location": "se/guides/health",
            "text": " Helidon has a set of built-in health checks that can be optionally enabled to report various health check statuses that are commonly used: deadlock detection available disk space available heap memory The following example will demonstrate how to use the built-in health checks. These examples are all executed from the root directory of your project (helidon-quickstart-se). <markup lang=\"xml\" title=\"Notice that the built-in health check dependency is already in the project&#8217;s pom.xml file:\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.health&lt;/groupId&gt; &lt;artifactId&gt;helidon-health-checks&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"java\" title=\"Have a look at Main.java , and the createRouting method:\" >private static Routing createRouting(Config config) { HealthSupport health = HealthSupport.builder() .addLiveness(HealthChecks.healthChecks()) .build(); return Routing.builder() .register(health) .build(); } Add built-in health checks (requires the helidon-health-checks dependency). Register the created health support with web server routing (adds the /health endpoint). <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-se.jar <markup lang=\"bash\" title=\"Verify the health endpoint in a new terminal window:\" >curl http://localhost:8080/health <markup lang=\"json\" title=\"JSON response:\" >{ \"status\": \"UP\", \"checks\": [ { \"name\": \"deadlock\", \"status\": \"UP\" }, { \"name\": \"diskSpace\", \"status\": \"UP\", \"data\": { \"free\": \"319.58 GB\", \"freeBytes\": 343144304640, \"percentFree\": \"68.63%\", \"total\": \"465.63 GB\", \"totalBytes\": 499963174912 } }, { \"name\": \"heapMemory\", \"status\": \"UP\", \"data\": { \"free\": \"196.84 MB\", \"freeBytes\": 206404016, \"max\": \"3.56 GB\", \"maxBytes\": 3817865216, \"percentFree\": \"98.66%\", \"total\": \"245.50 MB\", \"totalBytes\": 257425408 } } ] } ",
            "title": "Using the Built-In Health Checks"
        },
        {
            "location": "se/guides/health",
            "text": " You can create application specific custom health checks and integrate them with Helidon using the HealthSupport class, which is a WebServer service that contains a collection of registered HealthCheck instances. When queried, it invokes the registered health check and returns a response with a status code representing the overall state of the application. <markup lang=\"xml\" title=\"Notice the custom health checks dependency is already in the project&#8217;s pom.xml file:\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.health&lt;/groupId&gt; &lt;artifactId&gt;helidon-health&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"java\" title=\"Replace the HealthSupport builder in the Main.createRouting method:\" >HealthSupport health = HealthSupport.builder() .addLiveness(() -&gt; HealthCheckResponse.named(\"LivenessCheck\") .up() .withData(\"time\", System.currentTimeMillis()) .build()) .build(); Add a custom liveness health check. This example returns UP and current time. <markup lang=\"bash\" title=\"Build and run the application, then verify the custom health endpoint:\" >curl http://localhost:8080/health <markup lang=\"json\" title=\"JSON response:\" >{ \"status\": \"UP\", \"checks\": [ { \"name\": \"LivenessCheck\", \"status\": \"UP\", \"data\": { \"time\": 1546958376613 } } ] } ",
            "title": "Custom Liveness Health Checks"
        },
        {
            "location": "se/guides/health",
            "text": " You can add readiness checks to indicate that the application is ready to be used. In this example, the server will wait five seconds before it becomes ready. <markup lang=\"java\" title=\"Add a readyTime variable to the Main class, then set it five seconds after the application starts:\" >import java.util.concurrent.atomic.AtomicLong; public final class Main { private static AtomicLong readyTime = new AtomicLong(0); static WebServer startServer() throws IOException { server.start(); // Server threads are not daemon. No need to block. Just react. try { Thread.sleep(5000); } catch (InterruptedException e) { throw new RuntimeException(e); } readyTime.set(System.currentTimeMillis()); return server; Import AtomicLong. Declare the readyTime variable. Sleep five seconds. Set the readyTime to the time when the server became ready. <markup lang=\"java\" title=\"Add a readiness check to the HealhSupport builder in the Main.createRouting method:\" >HealthSupport health = HealthSupport.builder() .addLiveness(() -&gt; HealthCheckResponse.named(\"LivenessCheck\") .up() .withData(\"time\", System.currentTimeMillis()) .build()) .addReadiness(() -&gt; HealthCheckResponse.named(\"ReadinessCheck\") .status(readyTime.get() != 0 ) .withData( \"time\", readyTime.get()) .build()) .build(); Add the readiness check. <markup lang=\"bash\" title=\"Build and run the application. Issue the curl command with -v within five seconds and you see the application is not ready:\" >curl -v http://localhost:8080/health/ready <markup lang=\"json\" title=\"HTTP response:\" >... &lt; HTTP/1.1 503 Service Unavailable ... { \"status\": \"DOWN\", \"checks\": [ { \"name\": \"ReadinessCheck\", \"status\": \"DOWN\", \"data\": { \"time,\": 0 } } ] } The HTTP status is 503 since the application is not ready. <markup lang=\"bash\" title=\"After five seconds you will see the application is ready:\" >curl -v http://localhost:8080/health/ready <markup lang=\"json\" title=\"JSON response:\" >... &lt; HTTP/1.1 200 OK ... { \"status\": \"UP\", \"checks\": [ { \"name\": \"ReadinessCheck\", \"status\": \"UP\", \"data\": { \"time,\": 1566243562097 } } ] } The HTTP status is 200 indicating that the application is ready. ",
            "title": "Custom Readiness Health Checks"
        },
        {
            "location": "se/guides/health",
            "text": " You can create custom startup health checks to indicate when the application has fully started and, therefore, when the readiness and liveness checks are meaningful. This example reuses the readyTime field added above for the custom readiness check and adds a startup check that waits three additional seconds past the \"ready\" time before declaring the application started. <markup lang=\"java\" title=\"Add a startup check to the HealhSupport builder in the Main.createRouting method:\" >HealthSupport health = HealthSupport.builder() .addLiveness(() -&gt; HealthCheckResponse.named(\"LivenessCheck\") .up() .withData(\"time\", System.currentTimeMillis()) .build()) .addReadiness(() -&gt; HealthCheckResponse.named(\"ReadinessCheck\") .status(readyTime.get() != 0 ) .withData(\"time\", readyTime.get()) .build()) .addStartup(() -&gt; HealthCheckResponse.named(\"StartupCheck\") .status(readyTime.get() != 0 &amp;&amp; Duration.ofMillis(System.currentTimeMillis() - readyTime.get()).getSeconds() &gt;= 3) .withData(\"time\", readyTime.get()) .build()) .build(); Add the startup check. <markup lang=\"bash\" title=\"Build and run the application. Issue the curl command with -v within eight seconds and you see the application is not reported as started:\" >curl -v http://localhost:8080/health/started <markup lang=\"json\" title=\"HTTP response:\" >... &lt; HTTP/1.1 503 Service Unavailable ... { \"status\": \"DOWN\", \"checks\": [ { \"name\": \"StartupCheck\", \"status\": \"DOWN\", \"data\": { \"time\": 1566243562097 } } ] } The HTTP status is 503 since the application is not started. <markup lang=\"bash\" title=\"After eight seconds you will see the application is started:\" >curl -v http://localhost:8080/health/started <markup lang=\"json\" title=\"JSON response:\" >... &lt; HTTP/1.1 200 OK ... { \"status\": \"UP\", \"checks\": [ { \"name\": \"StartupCheck\", \"status\": \"UP\", \"data\": { \"time\": 1566243562097 } } ] } The HTTP status is 200 indicating that the application is started. When using the health check URLs, you can get the following health check data liveness only - http://localhost:8080/health/live readiness only - http://localhost:8080/health/ready startup only - http://localhost:8080/health/started all - http://localhost:8080/health <markup lang=\"bash\" title=\"Get all of liveness, readiness, and startup data from a single query:\" >curl http://localhost:8080/health <markup lang=\"json\" title=\"JSON response:\" >{ \"status\": \"UP\", \"checks\": [ { \"name\": \"LivenessCheck\", \"status\": \"UP\", \"data\": { \"time\": 1566244094548 } }, { \"name\": \"ReadinessCheck\", \"status\": \"UP\", \"data\": { \"time,\": 1566244093012 } }, { \"name\": \"StartupCheck\", \"status\": \"UP\", \"data\": { \"time\": 1566244093012 } } ] } ",
            "title": "Custom Startup Health Checks"
        },
        {
            "location": "se/guides/health",
            "text": " You can combine built-in and custom health checks using the same HealthSupport builder. <markup lang=\"java\" title=\"Register a custom health check in the Main.createRouting method:\" >HealthSupport health = HealthSupport.builder() .addLiveness(HealthChecks.healthChecks()) .addLiveness(() -&gt; HealthCheckResponse.named(\"LivenessCheck\") .up() .withData(\"time\", System.currentTimeMillis()) .build()) .addReadiness(() -&gt; HealthCheckResponse.named(\"ReadinessCheck\") .status(readyTime.get() != 0) .withData(\"time\", readyTime.get()) .build()) .addStartup(() -&gt; HealthCheckResponse.named(\"StartupCheck\") .status(readyTime.get() != 0 &amp;&amp; Duration.ofMillis(System.currentTimeMillis() - readyTime.get()).getSeconds() &gt;= 3) .withData(\"time\", readyTime.get()) .build()) .build(); Add the built-in health checks back to HealthSupport builder. <markup lang=\"bash\" title=\"Build and run the application, then verify the health endpoint. You will see both the built-in and custom health check data:\" >curl http://localhost:8080/health <markup lang=\"json\" title=\"JSON response:\" >{ \"status\": \"UP\", \"checks\": [ { \"name\": \"LivenessCheck\", \"status\": \"UP\", \"data\": { \"time\": 1566245527673 } }, { \"name\": \"ReadinessCheck\", \"status\": \"UP\", \"data\": { \"time,\": 1566245527620 }, { \"name\": \"StartupCheck\", \"status\": \"UP\", \"data\": { \"time,\": 1566245527620 } }, { \"name\": \"deadlock\", \"status\": \"UP\" }, { \"name\": \"diskSpace\", \"status\": \"UP\", \"data\": { \"free\": \"326.17 GB\", \"freeBytes\": 350224424960, \"percentFree\": \"70.05%\", \"total\": \"465.63 GB\", \"totalBytes\": 499963174912 } }, { \"name\": \"heapMemory\", \"status\": \"UP\", \"data\": { \"free\": \"247.76 MB\", \"freeBytes\": 259791680, \"max\": \"4.00 GB\", \"maxBytes\": 4294967296, \"percentFree\": \"99.80%\", \"total\": \"256.00 MB\", \"totalBytes\": 268435456 } } ] } ",
            "title": "Combine Built-In and Custom Health Checks"
        },
        {
            "location": "se/guides/health",
            "text": " You can use a custom URL path for heath checks by setting the WebContext . In the following example, only the liveness URL is changed, but you can do the same for the readiness, startup, and default health checks. <markup lang=\"java\" title=\"Register a custom URL path with the custom health check in the Main.createRouting method:\" >HealthSupport health = HealthSupport.builder() .webContext(\"/probe/live\") .addLiveness(() -&gt; HealthCheckResponse.named(\"livenessProbe\") .up() .withData(\"time\", System.currentTimeMillis()) .build()) .build(); Change the liveness URL path using a WebContext . <markup lang=\"bash\" title=\"Build and run the application, then verify that the liveness endpoint is using the /probe/live :\" >curl http://localhost:8080/probe/live <markup lang=\"json\" title=\"JSON response:\" >{ \"status\": \"UP\", \"checks\": [ { \"name\": \"livenessProbe\", \"status\": \"UP\", \"data\": { \"time\": 1546958376613 } } ] } ",
            "title": "Custom Health Check URL Path"
        },
        {
            "location": "se/guides/health",
            "text": " The following example shows how to integrate the Helidon health API in an application that implements health endpoints for the Kubernetes liveness, readiness, and startup probes. <markup lang=\"java\" title=\"Change the HealthSupport builder in the Main.createRouting method to use the built-in liveness checks and custom liveness, readiness, and startup checks:\" >HealthSupport health = HealthSupport.builder() .addLiveness(HealthChecks.healthChecks()) .addLiveness(() -&gt; HealthCheckResponse.named(\"LivenessCheck\") .up() .withData(\"time\", System.currentTimeMillis()) .build()) .addReadiness(() -&gt; HealthCheckResponse.named(\"ReadinessCheck\") .status(readyTime.get() != 0 ) .withData(\"time\", readyTime.get()) .build()) .addStartup(() -&gt; HealthCheckResponse.named(\"StartupCheck\") .status(readyTime.get() != 0 &amp;&amp; Duration.ofMillis(System.currentTimeMillis() - readyTime.get()).getSeconds() &gt;= 3) .withData(\"time\", readyTime.get()) .build()) .build(); Add built-in health checks. Add a custom liveness check. Add a custom readiness check. Add a custom startup check. <markup lang=\"bash\" title=\"Build and run the application, then verify the liveness, readiness, and started endpoints:\" >curl http://localhost:8080/health/live curl http://localhost:8080/health/ready curl http://localhost:8080/health/started <markup lang=\"bash\" title=\"Stop the application and build the docker image:\" >docker build -t helidon-quickstart-se . <markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named health.yaml , with the following content:\" >kind: Service apiVersion: v1 metadata: name: helidon-health labels: app: helidon-health spec: type: NodePort selector: app: helidon-health ports: - port: 8080 targetPort: 8080 name: http --- kind: Deployment apiVersion: apps/v1 metadata: name: helidon-health spec: replicas: 1 selector: matchLabels: app: helidon-health template: metadata: labels: app: helidon-health version: v1 spec: containers: - name: helidon-health image: helidon-quickstart-se imagePullPolicy: IfNotPresent ports: - containerPort: 8080 livenessProbe: httpGet: path: /health/live port: 8080 initialDelaySeconds: 5 periodSeconds: 10 timeoutSeconds: 3 failureThreshold: 3 readinessProbe: httpGet: path: /health/ready port: 8080 initialDelaySeconds: 5 periodSeconds: 2 timeoutSeconds: 3 startupProbe: httpGet: path: /health/started port: 8080 initialDelaySeconds: 8 periodSeconds: 10 timeoutSeconds: 3 failureThreshold: 3 --- A service of type NodePort that serves the default routes on port 8080 . A deployment with one replica of a pod. The HTTP endpoint for the liveness probe. The liveness probe configuration. The HTTP endpoint for the readiness probe. The readiness probe configuration. The HTTP endpoint for the startup probe. The startup probe configuration. <markup lang=\"bash\" title=\"Create and deploy the application into Kubernetes:\" >kubectl apply -f ./health.yaml <markup lang=\"bash\" title=\"Get the service information:\" >kubectl get service/helidon-health <markup lang=\"bash\" >NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE helidon-health NodePort 10.107.226.62 &lt;none&gt; 8080:30116/TCP 4s A service of type NodePort that serves the default routes on port 30116 . <markup lang=\"bash\" title=\"Verify the health endpoints using port '30116', your port may be different:\" >curl http://localhost:30116/health <markup lang=\"bash\" title=\"Delete the application, cleaning up Kubernetes resources:\" >kubectl delete -f ./health.yaml ",
            "title": "Using Liveness, Readiness, and Startup Health Checks with Kubernetes"
        },
        {
            "location": "se/guides/health",
            "text": " This guide demonstrated how to use health checks in a Helidon SE application as follows: Access the default health check Create and use custom readiness, liveness, and startup checks Customize the health check root path Integrate Helidon health check with Kubernetes Refer to the following reference for additional information: Helidon Javadoc ",
            "title": "Summary"
        },
        {
            "location": "se/guides/health",
            "text": " For this 15 minute tutorial, you will need the following: <div class=\"table__overflow elevation-1 flex sm7 \"> A Helidon SE Application You can use your own application or use the Helidon SE Quickstart to create a sample application. Java&#160;SE&#160;17 ( Open&#160;JDK&#160;17 ) Helidon requires Java 17+. Maven 3.6.1+ Helidon requires Maven 3.6.1+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop . <markup lang=\"bash\" title=\"Verify Prerequisites\" >java -version mvn --version docker --version kubectl version --short <markup lang=\"bash\" title=\"Setting JAVA_HOME\" ># On Mac export JAVA_HOME=`/usr/libexec/java_home -v 17` # On Linux # Use the appropriate path to your JDK export JAVA_HOME=/usr/lib/jvm/jdk-17 Create a Sample SE Project Generate the project sources using the Helidon SE Maven archetype. The result is a simple project that can be used for the examples in this guide. <markup lang=\"bash\" title=\"Run the Maven archetype:\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-se \\ -DarchetypeVersion=3.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-se \\ -Dpackage=io.helidon.examples.quickstart.se Using the Built-In Health Checks Helidon has a set of built-in health checks that can be optionally enabled to report various health check statuses that are commonly used: deadlock detection available disk space available heap memory The following example will demonstrate how to use the built-in health checks. These examples are all executed from the root directory of your project (helidon-quickstart-se). <markup lang=\"xml\" title=\"Notice that the built-in health check dependency is already in the project&#8217;s pom.xml file:\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.health&lt;/groupId&gt; &lt;artifactId&gt;helidon-health-checks&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"java\" title=\"Have a look at Main.java , and the createRouting method:\" >private static Routing createRouting(Config config) { HealthSupport health = HealthSupport.builder() .addLiveness(HealthChecks.healthChecks()) .build(); return Routing.builder() .register(health) .build(); } Add built-in health checks (requires the helidon-health-checks dependency). Register the created health support with web server routing (adds the /health endpoint). <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-se.jar <markup lang=\"bash\" title=\"Verify the health endpoint in a new terminal window:\" >curl http://localhost:8080/health <markup lang=\"json\" title=\"JSON response:\" >{ \"status\": \"UP\", \"checks\": [ { \"name\": \"deadlock\", \"status\": \"UP\" }, { \"name\": \"diskSpace\", \"status\": \"UP\", \"data\": { \"free\": \"319.58 GB\", \"freeBytes\": 343144304640, \"percentFree\": \"68.63%\", \"total\": \"465.63 GB\", \"totalBytes\": 499963174912 } }, { \"name\": \"heapMemory\", \"status\": \"UP\", \"data\": { \"free\": \"196.84 MB\", \"freeBytes\": 206404016, \"max\": \"3.56 GB\", \"maxBytes\": 3817865216, \"percentFree\": \"98.66%\", \"total\": \"245.50 MB\", \"totalBytes\": 257425408 } } ] } Custom Liveness Health Checks You can create application specific custom health checks and integrate them with Helidon using the HealthSupport class, which is a WebServer service that contains a collection of registered HealthCheck instances. When queried, it invokes the registered health check and returns a response with a status code representing the overall state of the application. <markup lang=\"xml\" title=\"Notice the custom health checks dependency is already in the project&#8217;s pom.xml file:\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.health&lt;/groupId&gt; &lt;artifactId&gt;helidon-health&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"java\" title=\"Replace the HealthSupport builder in the Main.createRouting method:\" >HealthSupport health = HealthSupport.builder() .addLiveness(() -&gt; HealthCheckResponse.named(\"LivenessCheck\") .up() .withData(\"time\", System.currentTimeMillis()) .build()) .build(); Add a custom liveness health check. This example returns UP and current time. <markup lang=\"bash\" title=\"Build and run the application, then verify the custom health endpoint:\" >curl http://localhost:8080/health <markup lang=\"json\" title=\"JSON response:\" >{ \"status\": \"UP\", \"checks\": [ { \"name\": \"LivenessCheck\", \"status\": \"UP\", \"data\": { \"time\": 1546958376613 } } ] } Custom Readiness Health Checks You can add readiness checks to indicate that the application is ready to be used. In this example, the server will wait five seconds before it becomes ready. <markup lang=\"java\" title=\"Add a readyTime variable to the Main class, then set it five seconds after the application starts:\" >import java.util.concurrent.atomic.AtomicLong; public final class Main { private static AtomicLong readyTime = new AtomicLong(0); static WebServer startServer() throws IOException { server.start(); // Server threads are not daemon. No need to block. Just react. try { Thread.sleep(5000); } catch (InterruptedException e) { throw new RuntimeException(e); } readyTime.set(System.currentTimeMillis()); return server; Import AtomicLong. Declare the readyTime variable. Sleep five seconds. Set the readyTime to the time when the server became ready. <markup lang=\"java\" title=\"Add a readiness check to the HealhSupport builder in the Main.createRouting method:\" >HealthSupport health = HealthSupport.builder() .addLiveness(() -&gt; HealthCheckResponse.named(\"LivenessCheck\") .up() .withData(\"time\", System.currentTimeMillis()) .build()) .addReadiness(() -&gt; HealthCheckResponse.named(\"ReadinessCheck\") .status(readyTime.get() != 0 ) .withData( \"time\", readyTime.get()) .build()) .build(); Add the readiness check. <markup lang=\"bash\" title=\"Build and run the application. Issue the curl command with -v within five seconds and you see the application is not ready:\" >curl -v http://localhost:8080/health/ready <markup lang=\"json\" title=\"HTTP response:\" >... &lt; HTTP/1.1 503 Service Unavailable ... { \"status\": \"DOWN\", \"checks\": [ { \"name\": \"ReadinessCheck\", \"status\": \"DOWN\", \"data\": { \"time,\": 0 } } ] } The HTTP status is 503 since the application is not ready. <markup lang=\"bash\" title=\"After five seconds you will see the application is ready:\" >curl -v http://localhost:8080/health/ready <markup lang=\"json\" title=\"JSON response:\" >... &lt; HTTP/1.1 200 OK ... { \"status\": \"UP\", \"checks\": [ { \"name\": \"ReadinessCheck\", \"status\": \"UP\", \"data\": { \"time,\": 1566243562097 } } ] } The HTTP status is 200 indicating that the application is ready. Custom Startup Health Checks You can create custom startup health checks to indicate when the application has fully started and, therefore, when the readiness and liveness checks are meaningful. This example reuses the readyTime field added above for the custom readiness check and adds a startup check that waits three additional seconds past the \"ready\" time before declaring the application started. <markup lang=\"java\" title=\"Add a startup check to the HealhSupport builder in the Main.createRouting method:\" >HealthSupport health = HealthSupport.builder() .addLiveness(() -&gt; HealthCheckResponse.named(\"LivenessCheck\") .up() .withData(\"time\", System.currentTimeMillis()) .build()) .addReadiness(() -&gt; HealthCheckResponse.named(\"ReadinessCheck\") .status(readyTime.get() != 0 ) .withData(\"time\", readyTime.get()) .build()) .addStartup(() -&gt; HealthCheckResponse.named(\"StartupCheck\") .status(readyTime.get() != 0 &amp;&amp; Duration.ofMillis(System.currentTimeMillis() - readyTime.get()).getSeconds() &gt;= 3) .withData(\"time\", readyTime.get()) .build()) .build(); Add the startup check. <markup lang=\"bash\" title=\"Build and run the application. Issue the curl command with -v within eight seconds and you see the application is not reported as started:\" >curl -v http://localhost:8080/health/started <markup lang=\"json\" title=\"HTTP response:\" >... &lt; HTTP/1.1 503 Service Unavailable ... { \"status\": \"DOWN\", \"checks\": [ { \"name\": \"StartupCheck\", \"status\": \"DOWN\", \"data\": { \"time\": 1566243562097 } } ] } The HTTP status is 503 since the application is not started. <markup lang=\"bash\" title=\"After eight seconds you will see the application is started:\" >curl -v http://localhost:8080/health/started <markup lang=\"json\" title=\"JSON response:\" >... &lt; HTTP/1.1 200 OK ... { \"status\": \"UP\", \"checks\": [ { \"name\": \"StartupCheck\", \"status\": \"UP\", \"data\": { \"time\": 1566243562097 } } ] } The HTTP status is 200 indicating that the application is started. When using the health check URLs, you can get the following health check data liveness only - http://localhost:8080/health/live readiness only - http://localhost:8080/health/ready startup only - http://localhost:8080/health/started all - http://localhost:8080/health <markup lang=\"bash\" title=\"Get all of liveness, readiness, and startup data from a single query:\" >curl http://localhost:8080/health <markup lang=\"json\" title=\"JSON response:\" >{ \"status\": \"UP\", \"checks\": [ { \"name\": \"LivenessCheck\", \"status\": \"UP\", \"data\": { \"time\": 1566244094548 } }, { \"name\": \"ReadinessCheck\", \"status\": \"UP\", \"data\": { \"time,\": 1566244093012 } }, { \"name\": \"StartupCheck\", \"status\": \"UP\", \"data\": { \"time\": 1566244093012 } } ] } Combine Built-In and Custom Health Checks You can combine built-in and custom health checks using the same HealthSupport builder. <markup lang=\"java\" title=\"Register a custom health check in the Main.createRouting method:\" >HealthSupport health = HealthSupport.builder() .addLiveness(HealthChecks.healthChecks()) .addLiveness(() -&gt; HealthCheckResponse.named(\"LivenessCheck\") .up() .withData(\"time\", System.currentTimeMillis()) .build()) .addReadiness(() -&gt; HealthCheckResponse.named(\"ReadinessCheck\") .status(readyTime.get() != 0) .withData(\"time\", readyTime.get()) .build()) .addStartup(() -&gt; HealthCheckResponse.named(\"StartupCheck\") .status(readyTime.get() != 0 &amp;&amp; Duration.ofMillis(System.currentTimeMillis() - readyTime.get()).getSeconds() &gt;= 3) .withData(\"time\", readyTime.get()) .build()) .build(); Add the built-in health checks back to HealthSupport builder. <markup lang=\"bash\" title=\"Build and run the application, then verify the health endpoint. You will see both the built-in and custom health check data:\" >curl http://localhost:8080/health <markup lang=\"json\" title=\"JSON response:\" >{ \"status\": \"UP\", \"checks\": [ { \"name\": \"LivenessCheck\", \"status\": \"UP\", \"data\": { \"time\": 1566245527673 } }, { \"name\": \"ReadinessCheck\", \"status\": \"UP\", \"data\": { \"time,\": 1566245527620 }, { \"name\": \"StartupCheck\", \"status\": \"UP\", \"data\": { \"time,\": 1566245527620 } }, { \"name\": \"deadlock\", \"status\": \"UP\" }, { \"name\": \"diskSpace\", \"status\": \"UP\", \"data\": { \"free\": \"326.17 GB\", \"freeBytes\": 350224424960, \"percentFree\": \"70.05%\", \"total\": \"465.63 GB\", \"totalBytes\": 499963174912 } }, { \"name\": \"heapMemory\", \"status\": \"UP\", \"data\": { \"free\": \"247.76 MB\", \"freeBytes\": 259791680, \"max\": \"4.00 GB\", \"maxBytes\": 4294967296, \"percentFree\": \"99.80%\", \"total\": \"256.00 MB\", \"totalBytes\": 268435456 } } ] } Custom Health Check URL Path You can use a custom URL path for heath checks by setting the WebContext . In the following example, only the liveness URL is changed, but you can do the same for the readiness, startup, and default health checks. <markup lang=\"java\" title=\"Register a custom URL path with the custom health check in the Main.createRouting method:\" >HealthSupport health = HealthSupport.builder() .webContext(\"/probe/live\") .addLiveness(() -&gt; HealthCheckResponse.named(\"livenessProbe\") .up() .withData(\"time\", System.currentTimeMillis()) .build()) .build(); Change the liveness URL path using a WebContext . <markup lang=\"bash\" title=\"Build and run the application, then verify that the liveness endpoint is using the /probe/live :\" >curl http://localhost:8080/probe/live <markup lang=\"json\" title=\"JSON response:\" >{ \"status\": \"UP\", \"checks\": [ { \"name\": \"livenessProbe\", \"status\": \"UP\", \"data\": { \"time\": 1546958376613 } } ] } Using Liveness, Readiness, and Startup Health Checks with Kubernetes The following example shows how to integrate the Helidon health API in an application that implements health endpoints for the Kubernetes liveness, readiness, and startup probes. <markup lang=\"java\" title=\"Change the HealthSupport builder in the Main.createRouting method to use the built-in liveness checks and custom liveness, readiness, and startup checks:\" >HealthSupport health = HealthSupport.builder() .addLiveness(HealthChecks.healthChecks()) .addLiveness(() -&gt; HealthCheckResponse.named(\"LivenessCheck\") .up() .withData(\"time\", System.currentTimeMillis()) .build()) .addReadiness(() -&gt; HealthCheckResponse.named(\"ReadinessCheck\") .status(readyTime.get() != 0 ) .withData(\"time\", readyTime.get()) .build()) .addStartup(() -&gt; HealthCheckResponse.named(\"StartupCheck\") .status(readyTime.get() != 0 &amp;&amp; Duration.ofMillis(System.currentTimeMillis() - readyTime.get()).getSeconds() &gt;= 3) .withData(\"time\", readyTime.get()) .build()) .build(); Add built-in health checks. Add a custom liveness check. Add a custom readiness check. Add a custom startup check. <markup lang=\"bash\" title=\"Build and run the application, then verify the liveness, readiness, and started endpoints:\" >curl http://localhost:8080/health/live curl http://localhost:8080/health/ready curl http://localhost:8080/health/started <markup lang=\"bash\" title=\"Stop the application and build the docker image:\" >docker build -t helidon-quickstart-se . <markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named health.yaml , with the following content:\" >kind: Service apiVersion: v1 metadata: name: helidon-health labels: app: helidon-health spec: type: NodePort selector: app: helidon-health ports: - port: 8080 targetPort: 8080 name: http --- kind: Deployment apiVersion: apps/v1 metadata: name: helidon-health spec: replicas: 1 selector: matchLabels: app: helidon-health template: metadata: labels: app: helidon-health version: v1 spec: containers: - name: helidon-health image: helidon-quickstart-se imagePullPolicy: IfNotPresent ports: - containerPort: 8080 livenessProbe: httpGet: path: /health/live port: 8080 initialDelaySeconds: 5 periodSeconds: 10 timeoutSeconds: 3 failureThreshold: 3 readinessProbe: httpGet: path: /health/ready port: 8080 initialDelaySeconds: 5 periodSeconds: 2 timeoutSeconds: 3 startupProbe: httpGet: path: /health/started port: 8080 initialDelaySeconds: 8 periodSeconds: 10 timeoutSeconds: 3 failureThreshold: 3 --- A service of type NodePort that serves the default routes on port 8080 . A deployment with one replica of a pod. The HTTP endpoint for the liveness probe. The liveness probe configuration. The HTTP endpoint for the readiness probe. The readiness probe configuration. The HTTP endpoint for the startup probe. The startup probe configuration. <markup lang=\"bash\" title=\"Create and deploy the application into Kubernetes:\" >kubectl apply -f ./health.yaml <markup lang=\"bash\" title=\"Get the service information:\" >kubectl get service/helidon-health <markup lang=\"bash\" >NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE helidon-health NodePort 10.107.226.62 &lt;none&gt; 8080:30116/TCP 4s A service of type NodePort that serves the default routes on port 30116 . <markup lang=\"bash\" title=\"Verify the health endpoints using port '30116', your port may be different:\" >curl http://localhost:30116/health <markup lang=\"bash\" title=\"Delete the application, cleaning up Kubernetes resources:\" >kubectl delete -f ./health.yaml Summary This guide demonstrated how to use health checks in a Helidon SE application as follows: Access the default health check Create and use custom readiness, liveness, and startup checks Customize the health check root path Integrate Helidon health check with Kubernetes Refer to the following reference for additional information: Helidon Javadoc ",
            "title": "What You Need"
        },
        {
            "location": "se/guides/jlink-image",
            "text": " This guide describes how to build a custom runtime image for your Helidon application using Helidon&#8217;s support for the JDK&#8217;s jlink tool. ",
            "title": "preambule"
        },
        {
            "location": "se/guides/jlink-image",
            "text": " JDK 9 introduced the jlink command that supports assembling a set of modules and their dependencies into a custom runtime image. The helidon-maven-plugin has support for easily creating a custom runtime image for your Helidon application resulting in a smaller, better performing runtime. In this guide you will learn how to build a custom runtime image locally on your machine, as well as how to build it in a Docker image. ",
            "title": "Introduction"
        },
        {
            "location": "se/guides/jlink-image",
            "text": " For this 10 minute tutorial, you will need the following: <div class=\"table__overflow elevation-1 flex sm7 \"> A Helidon SE Application You can use your own application or use the Helidon SE Quickstart to create a sample application. Java&#160;SE&#160;17 ( Open&#160;JDK&#160;17 ) Helidon requires Java 17+. Maven 3.6.1+ Helidon requires Maven 3.6.1+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop . <markup lang=\"bash\" title=\"Verify Prerequisites\" >java -version mvn --version docker --version kubectl version --short <markup lang=\"bash\" title=\"Setting JAVA_HOME\" ># On Mac export JAVA_HOME=`/usr/libexec/java_home -v 17` # On Linux # Use the appropriate path to your JDK export JAVA_HOME=/usr/lib/jvm/jdk-17 ",
            "title": "What You Need"
        },
        {
            "location": "se/guides/jlink-image",
            "text": " As noted in the prerequisites above, JDK 11 or newer is required. <markup lang=\"bash\" >$JAVA_HOME/bin/java --version Creating a custom runtime image requires that the JDK modules are present as *.jmod files, and some distributions do not provide them by default. Check the jmods directory to ensure they are present: <markup lang=\"bash\" >ls $JAVA_HOME/jmods OpenJDK on Linux RPM based distributions provide *.jmod files in separate java-*-openjdk-jmods packages. Debian based distributions provide *.jmod files only in the openjdk-*-jdk-headless packages. ",
            "title": "Verify JDK"
        },
        {
            "location": "se/guides/jlink-image",
            "text": " Generate the project using the Helidon SE Quickstart Maven archetype. <markup lang=\"bash\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-se \\ -DarchetypeVersion=3.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-se \\ -Dpackage=io.helidon.examples.quickstart.se The archetype generates a Maven project in your current directory (for example, helidon-quickstart-se ). Change into this directory and build. <markup lang=\"bash\" >cd helidon-quickstart-se mvn package At this point you can run the application using the JVM: <markup lang=\"bash\" >java -jar target/helidon-quickstart-se.jar In another shell test an endpoint: <markup lang=\"bash\" >curl -X GET http://localhost:8080/greet The application should respond with {\"message\":\"Hello World!\"} Now stop the running application (by pressing Ctrl+C). For more information about the Quickstart application and other endpoints it supports see the Helidon SE quickstart Guide . ",
            "title": "Generate the Project"
        },
        {
            "location": "se/guides/jlink-image",
            "text": " Build the custom runtime image using the jlink image profile: <markup lang=\"bash\" >mvn package -Pjlink-image Tip This uses the helidon-maven-plugin to perform the custom image generation. After the build completes it will report some statistics about the build including the reduction in image size. The target/helidon-quickstart-se-jri directory is a self contained custom image of your application. It contains your application, its runtime dependencies and the JDK modules it depends on. You can start your application using the provide start script: <markup lang=\"bash\" >./target/helidon-quickstart-se-jri/bin/start ",
            "title": "Local Build"
        },
        {
            "location": "se/guides/jlink-image",
            "text": " Also included in the custom image is a Class Data Sharing (CDS) archive that improves your application&#8217;s startup performance and in-memory footprint. You can learn more about Class Data Sharing in the JDK documentation . The CDS archive increases your image size to get these performance optimizations. It can be of significant size (tens of MB). The size of the CDS archive is reported at the end of the build output. If you&#8217;d rather have a smaller image size (with a slightly increased startup time) you can skip the creation of the CDS archive by executing your build like this: <markup lang=\"bash\" >mvn package -Pjlink-image -Djlink.image.addClassDataSharingArchive=false For more information on available configuration options see the helidon-maven-plugin documentation . ",
            "title": "Class Data Sharing (CDS) Archive"
        },
        {
            "location": "se/guides/jlink-image",
            "text": " To build a Docker image with a custom Java runtime image use the jlink Dockerfile included with the quickstart. <markup lang=\"bash\" >docker build -t helidon-quickstart-se-jri -f Dockerfile.jlink . Tip This does a full build inside the Docker container. The first time you run it, it will take a while because it is downloading all of the Maven dependencies and caching them in a Docker layer. Subsequent builds will be much faster as long as you don&#8217;t change the pom.xml file. If the pom is modified then the dependencies will be re-downloaded. Start the application: <markup lang=\"bash\" >docker run --rm -p 8080:8080 helidon-quickstart-se-jri:latest You can exercise the application&#8217;s endpoints as before. ",
            "title": "Multi-Stage Docker Build"
        },
        {
            "location": "se/guides/jlink-image",
            "text": " You can build a custom runtime image in 2 different ways: Locally, on your desktop Using Docker Local Build Build the custom runtime image using the jlink image profile: <markup lang=\"bash\" >mvn package -Pjlink-image Tip This uses the helidon-maven-plugin to perform the custom image generation. After the build completes it will report some statistics about the build including the reduction in image size. The target/helidon-quickstart-se-jri directory is a self contained custom image of your application. It contains your application, its runtime dependencies and the JDK modules it depends on. You can start your application using the provide start script: <markup lang=\"bash\" >./target/helidon-quickstart-se-jri/bin/start Class Data Sharing (CDS) Archive Also included in the custom image is a Class Data Sharing (CDS) archive that improves your application&#8217;s startup performance and in-memory footprint. You can learn more about Class Data Sharing in the JDK documentation . The CDS archive increases your image size to get these performance optimizations. It can be of significant size (tens of MB). The size of the CDS archive is reported at the end of the build output. If you&#8217;d rather have a smaller image size (with a slightly increased startup time) you can skip the creation of the CDS archive by executing your build like this: <markup lang=\"bash\" >mvn package -Pjlink-image -Djlink.image.addClassDataSharingArchive=false For more information on available configuration options see the helidon-maven-plugin documentation . Multi-Stage Docker Build To build a Docker image with a custom Java runtime image use the jlink Dockerfile included with the quickstart. <markup lang=\"bash\" >docker build -t helidon-quickstart-se-jri -f Dockerfile.jlink . Tip This does a full build inside the Docker container. The first time you run it, it will take a while because it is downloading all of the Maven dependencies and caching them in a Docker layer. Subsequent builds will be much faster as long as you don&#8217;t change the pom.xml file. If the pom is modified then the dependencies will be re-downloaded. Start the application: <markup lang=\"bash\" >docker run --rm -p 8080:8080 helidon-quickstart-se-jri:latest You can exercise the application&#8217;s endpoints as before. ",
            "title": "Building a Custom Runtime Image"
        },
        {
            "location": "se/guides/jlink-image",
            "text": " Custom runtime images are ideal for use when you want all of the runtime performance of the JDK JVM in a reasonably compact form. For cases where absolute minimal startup time and image size are required, then consider using GraalVM Native Images . ",
            "title": "Using Custom Runtime Images"
        },
        {
            "location": "se/guides/maven-build",
            "text": " This guide describes Helidon&#8217;s support for Maven projects. ",
            "title": "preambule"
        },
        {
            "location": "se/guides/maven-build",
            "text": " Helidon supports Maven by providing the following: The Helidon Application parent POM Dependency management via the Helidon BOM and Dependencies POMs The helidon-maven-plugin ",
            "title": "Introduction"
        },
        {
            "location": "se/guides/maven-build",
            "text": " Helidon examples and projects generated using the Helidon Quickstart use a Helidon application POM as their parent. This parent POM provides the following: Helidon dependency management. Maven plugin configurations to help in the building and packaging of your Helidon application. If you want to use your own parent POM, then take a look at the standalone quickstart example . This example has a stand-alone POM that you can pattern your own application POM after. For more details on Helidon application POMs see the Helidon&#8217;s Application POMS ",
            "title": "The Helidon Application POM"
        },
        {
            "location": "se/guides/maven-build",
            "text": " In Maven you use Dependency Management to manage the versions of the dependencies used by your project so that you do not need to specify versions when declaring project dependencies. Helidon provides two POMs that are used together for dependency management: The Helidon Bill of Materials (BOM) POM ( io.helidon:helidon-bom ): manages the version of Helidon artifacts (to align with the Helidon version). The Helidon Dependencies POM ( io.helidon:helidon-dependencies ): manages the versions of third party dependencies to ensure consistency across Helidon and your Helidon application. Inherits the Helidon BOM POM. When you use a Helidon Application POM as your project&#8217;s parent pom, you inherit Helidon&#8217;s dependency management. If you have your own parent, then you can import Helidon dependency management like this: <markup lang=\"xml\" title=\"Import Helidon Dependency Management\" >&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon&lt;/groupId&gt; &lt;artifactId&gt;helidon-dependencies&lt;/artifactId&gt; &lt;version&gt;3.0.2&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; You then declare dependencies on Helidon (and other) components without specifying a version. <markup lang=\"xml\" title=\"Component dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webserver&lt;/groupId&gt; &lt;artifactId&gt;helidon-webserver&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Dependency Management"
        },
        {
            "location": "se/guides/maven-build",
            "text": " You can override many of the plugin attributes by passing a system property to the mvn command: <markup lang=\"bash\" >mvn -Djlink.image.addClassDataSharingArchive=false package ",
            "title": "Pass Property on Command Line"
        },
        {
            "location": "se/guides/maven-build",
            "text": " Or you can set the properties in your project&#8217;s pom.xml: <markup lang=\"xml\" >&lt;properties&gt; &lt;jlink.image.addClassDataSharingArchive&gt;false&lt;/jlink.image.addClassDataSharingArchive&gt; &lt;native.image.reportExceptionStackTraces&gt;true&lt;/native.image.reportExceptionStackTraces&gt; &lt;/properties&gt; ",
            "title": "Set Property in pom.xml"
        },
        {
            "location": "se/guides/maven-build",
            "text": " For full control you can override the plugin&#8217;s configuration using pluginManagement : <markup lang=\"xml\" title=\"Turn off generation of the CDS Archive when generating a custom Java runtime image\" > &lt;build&gt; &lt;pluginManagement&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;io.helidon.build-tools&lt;/groupId&gt; &lt;artifactId&gt;helidon-maven-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;jlink-image&lt;/id&gt; &lt;configuration&gt; &lt;addClassDataSharingArchive&gt;false&lt;/addClassDataSharingArchive&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;/build&gt; <markup lang=\"xml\" title=\"Override final name of native image binary\" > &lt;build&gt; &lt;pluginManagement&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;io.helidon.build-tools&lt;/groupId&gt; &lt;artifactId&gt;helidon-maven-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;native-image&lt;/id&gt; &lt;configuration&gt; &lt;finalName&gt;my-fantastic-service&lt;/finalName&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;/build&gt; ",
            "title": "Override Plugin Configuration using pluginManagement "
        },
        {
            "location": "se/guides/maven-build",
            "text": " Helidon provides a Maven plugin that, among other things, provides the following goals: native-image: Build a GraalVM native image . jlink-image: Build a custom runtime Java image . For full documentation of the plugin please see the Helidon Maven Plugin README . If you use the Helidon application parent POM you will have this plugin configured for you. If you need to customize the helidon-maven-plugin you can do so in a few ways: Passing system properties to Maven on the command line. Setting system properties in your project&#8217;s pom.xml Overriding the plugin configuration by using pluginManagment Pass Property on Command Line You can override many of the plugin attributes by passing a system property to the mvn command: <markup lang=\"bash\" >mvn -Djlink.image.addClassDataSharingArchive=false package Set Property in pom.xml Or you can set the properties in your project&#8217;s pom.xml: <markup lang=\"xml\" >&lt;properties&gt; &lt;jlink.image.addClassDataSharingArchive&gt;false&lt;/jlink.image.addClassDataSharingArchive&gt; &lt;native.image.reportExceptionStackTraces&gt;true&lt;/native.image.reportExceptionStackTraces&gt; &lt;/properties&gt; Override Plugin Configuration using pluginManagement For full control you can override the plugin&#8217;s configuration using pluginManagement : <markup lang=\"xml\" title=\"Turn off generation of the CDS Archive when generating a custom Java runtime image\" > &lt;build&gt; &lt;pluginManagement&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;io.helidon.build-tools&lt;/groupId&gt; &lt;artifactId&gt;helidon-maven-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;jlink-image&lt;/id&gt; &lt;configuration&gt; &lt;addClassDataSharingArchive&gt;false&lt;/addClassDataSharingArchive&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;/build&gt; <markup lang=\"xml\" title=\"Override final name of native image binary\" > &lt;build&gt; &lt;pluginManagement&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;io.helidon.build-tools&lt;/groupId&gt; &lt;artifactId&gt;helidon-maven-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;native-image&lt;/id&gt; &lt;configuration&gt; &lt;finalName&gt;my-fantastic-service&lt;/finalName&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;/build&gt; ",
            "title": "The helidon-maven-plugin "
        },
        {
            "location": "se/guides/metrics",
            "text": " This guide describes how to create a sample Helidon {h1-prefix} project that can be used to run some basic examples using both built-in and custom metrics with Helidon. ",
            "title": "preambule"
        },
        {
            "location": "se/guides/metrics",
            "text": " Use the Helidon SE Maven archetype to create a simple project that can be used for the examples in this guide. <markup lang=\"bash\" title=\"Run the Maven archetype\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-se \\ -DarchetypeVersion=3.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-se \\ -Dpackage=io.helidon.examples.quickstart.se ",
            "title": "Create a Sample Helidon SE Project"
        },
        {
            "location": "se/guides/metrics",
            "text": " Helidon provides three scopes of metrics: base, vendor, and application. Here are the metric endpoints: /metrics/base - Base metrics data as specified by the MicroProfile Metrics specification. /metrics/vendor - Helidon-specific metrics data. /metrics/application - Application-specific metrics data. The /metrics endpoint will return data for all scopes. The built-in metrics fall into three categories: JVM behavior (in the base registry), basic key performance indicators for request handling (in the vendor registry), and thread pool utilization (also in the vendor registry). A later section describes the key performance indicator metrics in detail. The following example demonstrates how to use the other built-in metrics. All examples are executed from the root directory of your project (helidon-quickstart-se). The generated source code is already configured for both metrics and health checks, but the following example removes health checks. <markup lang=\"xml\" title=\"Notice that the metrics dependency is already in the project&#8217;s pom.xml file:\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"java\" title=\"Replace the Main.createRouting method with the following code:\" > private static Routing createRouting(Config config) { GreetService greetService = new GreetService(config); return Routing.builder() .register(MetricsSupport.create()) .register(\"/greet\", greetService) .build(); } Register the built-in base and vendor metrics. <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-se.jar Metrics can be returned in either text format (the default), or JSON. The text format uses OpenMetrics (Prometheus) Text Format, see https://prometheus.io/docs/instrumenting/exposition_formats/#text-format-details . <markup lang=\"bash\" title=\"Verify the metrics endpoint in a new terminal window:\" >curl http://localhost:8080/metrics <markup lang=\"text\" title=\"Text response:\" ># TYPE base:classloader_current_loaded_class_count counter # HELP base:classloader_current_loaded_class_count Displays the number of classes that are currently loaded in the Java virtual machine. base:classloader_current_loaded_class_count 7511 # TYPE base:classloader_total_loaded_class_count counter # HELP base:classloader_total_loaded_class_count Displays the total number of classes that have been loaded since the Java virtual machine has started execution. base:classloader_total_loaded_class_count 7512 You can get the same data in JSON format. <markup lang=\"bash\" title=\"Verify the metrics endpoint with an HTTP accept header:\" >curl -H \"Accept: application/json\" http://localhost:8080/metrics <markup lang=\"json\" title=\"JSON response:\" >{ \"base\": { \"classloader.currentLoadedClass.count\": 7534, \"classloader.totalLoadedClass.count\": 7538, \"classloader.totalUnloadedClass.count\": 1, \"cpu.availableProcessors\": 4, \"cpu.systemLoadAverage\": 2.83349609375, \"gc.PS MarkSweep.count\": 2, \"gc.PS MarkSweep.time\": 77, \"gc.PS Scavenge.count\": 5, \"gc.PS Scavenge.time\": 37, \"jvm.uptime\": 727588, \"memory.committedHeap\": 284164096, \"memory.maxHeap\": 3817865216, \"memory.usedHeap\": 53283088, \"thread.count\": 44, \"thread.daemon.count\": 35, \"thread.max.count\": 44 }, \"vendor\": { \"executor-service.active-count;poolIndex=0;supplierCategory=helidon-thread-pool-2;supplierIndex=0\": 0, \"executor-service.completed-task-count;poolIndex=0;supplierCategory=helidon-thread-pool-2;supplierIndex=0\": 0, \"executor-service.largest-pool-size;poolIndex=0;supplierCategory=helidon-thread-pool-2;supplierIndex=0\": 5, \"executor-service.pool-size;poolIndex=0;supplierCategory=helidon-thread-pool-2;supplierIndex=0\": 5, \"executor-service.queue.remaining-capacity;poolIndex=0;supplierCategory=helidon-thread-pool-2;supplierIndex=0\": 10000, \"executor-service.queue.size;poolIndex=0;supplierCategory=helidon-thread-pool-2;supplierIndex=0\": 0, \"executor-service.task-count;poolIndex=0;supplierCategory=helidon-thread-pool-2;supplierIndex=0\": 0, \"requests.count\": 6, \"requests.meter\": { \"count\": 6, \"meanRate\": 0.008275992296704147, \"oneMinRate\": 0.01576418632772332, \"fiveMinRate\": 0.006695060022357365, \"fifteenMinRate\": 0.0036382699664488415 } } } You can get a single metric by specifying the name in the URL path. <markup lang=\"bash\" title=\"Get the Helidon requests.meter metric:\" >curl -H \"Accept: application/json\" http://localhost:8080/metrics/vendor/requests.meter <markup lang=\"json\" title=\"JSON response:\" >{ \"requests.meter\": { \"count\": 6, \"meanRate\": 0.008275992296704147, \"oneMinRate\": 0.01576418632772332, \"fiveMinRate\": 0.006695060022357365, \"fifteenMinRate\": 0.0036382699664488415 } } You cannot get the individual fields of a metric. For example, you cannot target http://localhost:8080/metrics/vendor/requests.meter.count . The base metrics illustrated above provide some insight into the behavior of the JVM in which the server runs. The vendor metrics shown above appear in two groups: Helidon thread pools Helidon uses these thread pools for its own internal work, and your application can also use Helidon-managed thread pools if it needs to do work asynchronously. (See this example .) The metrics in this group show information about the thread pools which can help you assess how efficiently they are utilized. Helidon uses tags to distinguish the metrics which describe different thread pools. In some cases the specific metrics exposed depend on the particular type of thread pool. basic key performance indicators These metrics give an idea of the request traffic the server is handling. See the later section for more information on the basic and extended key performance indicator metrics. ",
            "title": "Using the Built-In Metrics"
        },
        {
            "location": "se/guides/metrics",
            "text": " By default, if your application depends on the helidon-metrics Maven module then full-featured metrics are enabled. You can disable the metrics subsystem entirely using configuration: <markup lang=\"properties\" title=\"Configuration properties file disabling metrics\" >metrics.enabled=false A Helidon SE application can disable metrics processing programmatically. <markup lang=\"java\" title=\"Disable all metrics behavior\" >import io.helidon.metrics.api.MetricsSettings; import io.helidon.metrics.serviceapi.MetricsSupport; import io.helidon.metrics.api.RegistryFactory; MetricsSettings metricsSettings = MetricsSettings.builder() .enabled(false) .build(); MetricsSupport metricsSupport = MetricsSupport.create(metricsSettings); RegistryFactory registryFactory = RegistryFactory.getInstance(metricsSettings); Create a MetricsSettings instance (via its Builder ) with the metrics subsystem disabled. Get a MetricsSupport service (usable in setting routing rules) that responds to the /metrics endpoint with 404 and an explanatory message. Get a RegistryFactory instance that provides MetricRegistry instances which register no-op metric objects (counters, timers, etc.). These builders and interfaces also have methods which accept Config objects representing the metrics node from the application configuration. With metrics processing disabled, Helidon never updates any metrics and the /metrics endpoints respond with 404 plus a message that the metrics subsystem is disabled. ",
            "title": "Disabling Metrics Subsystem Entirely"
        },
        {
            "location": "se/guides/metrics",
            "text": " Helidon contains several components and integrations which register and update metrics. Depending on how the component is written, you might be able to disable just that component&#8217;s use of metrics: <markup lang=\"properties\" title=\"Configuration properties file disabling a component&#8217;s use of metrics\" >some-component.metrics.enabled=false Check the documentation for a specific component to find out whether that component uses metrics and whether it allows you to disable that use. Your Helidon SE application can disable a metrics-capable component&#8217;s use of metrics programmatically. <markup lang=\"java\" title=\"Disable metrics use in a metrics-capable component\" >import io.helidon.metrics.api.ComponentMetricsSettings; ComponentMetricsSettings.Builder componentMetricsSettingsBuilder = ComponentMetricsSettings.builder() .enabled(false); SomeService someService = SomeService.builder() .componentMetricsSettings(componentMetricsSettingsBuilder) .build(); Create a ComponentMetricsSettings instance (via its Builder ) indicating that metrics usage should be disabled. Create an instance of the service with its metrics usage disabled. If you disable a component&#8217;s use of metrics, Helidon does not register the component&#8217;s metrics in the visible metrics registries nor do those metrics ever update their values. The response from the /metrics endpoint excludes that component&#8217;s metrics. Note that if you disable metrics processing entirely, no component updates its metrics regardless of any component-level metrics settings. ",
            "title": "Enabling and Disabling Metrics Usage by a Component"
        },
        {
            "location": "se/guides/metrics",
            "text": " To disable all metrics in a given registry type (application, vendor, or base), add one or more groups to the configuration: <markup lang=\"properties\" title=\"Disabling base and vendor metrics (properties format)\" >metrics.registries.0.type = base metrics.registries.0.enabled = false metrics.registries.1.type = vendor metrics.registries.1.enabled = false <markup lang=\"yaml\" title=\"Disabling base and vendor metrics (YAML format)\" >metrics: registries: - type: base enabled: false - type: vendor enables: false ",
            "title": "Disabling All Metrics of a Given Registry Type"
        },
        {
            "location": "se/guides/metrics",
            "text": " You can be even more selective. Within a registry type you can configure up to two regular expression patterns: one matching metric names to exclude , and one matching metric names to include . Helidon updates and reports a metric only if two conditions hold: the metric name does not match the exclude regex pattern (if you define one), and either there is no include regex pattern, or the metric name matches the include pattern. Caution Make sure any include regex pattern you specify matches all the metric names you want to capture. Suppose your application creates and updates a group of metrics with names such as myapp.xxx.queries , myapp.xxx.creates , myapp.xxx.updates , and myapp.xxx.deletes where xxx can be either supplier or customer . The following example gathers all metrics except those from your application regarding suppliers: <markup lang=\"properties\" title=\"Disabling metrics by name (properties format)\" >metrics.registries.0.type = application metrics.registries.0.filter.exclude = myapp\\.supplier\\..* The following settings select the particular subset of the metrics created in your application code representing updates of customers and suppliers: <markup lang=\"properties\" title=\"Enabling metrics by name (properties format)\" >metrics.registries.0.type = application metrics.registries.0.filter.include = myapp\\..*\\.updates If you use the YAML configuration format, enclose the regex patterns in single-quote marks: <markup lang=\"yaml\" title=\"Enabling metrics by name (YAML format)\" >metrics: registries: - type: application filter: include: 'myapp\\..*\\.updates' The next example selects only your application&#8217;s metrics while excluding those which refer to deletions: <markup lang=\"properties\" title=\"Combining include and exclude \" >metrics.registries.0.type = application metrics.registries.0.filter.include = myapp\\..* metrics.registries.0.filter.exclude = myapp\\..*/deletes Helidon would not update or report the metric myapp.supplier.queries , for example. To include metrics from your application for both updates and queries (but not for other operations), you could change the settings in the previous example to this: <markup >metrics.registries.0.type = application metrics.registries.0.filter.include = myapp\\..*\\.updates|myapp\\..*\\.queries metrics.registries.0.filter.exclude = myapp\\..*/deletes Your Helidon SE application can control the collection and reporting of metrics programmatically as well by preparing these settings objects: RegistryFilterSettings RegistrySettings MetricsSettings and using the resulting MetricsSettings to retrieve a suitable RegistryFactory . <markup lang=\"java\" title=\"Control metrics by registry type and name\" >import io.helidon.metrics.api.RegistryFilterSettings; import org.eclipse.microprofile.metrics.MetricRegistry; ... RegistryFilterSettings appFilterSettings = RegistryFilterSettings.builder() .include(\"myapp\\..*\\.updates\") .build(); RegistrySettings registrySettings = RegistrySettings.builder() .filterSettings(appFilterSettings) .build(); MetricsSettings metricsSettings = MetricsSettings.builder() .registrySettings(MetricRegistry.Type.APPLICATION, appFilterSettings) .build(); RegistryFactory rf = RegistryFactory.getInstance(metricsSettings); MetricRegistry registry = rf.getRegistry(MetricRegistry.Type.APPLICATION); Create the registry filter settings to include only those metrics with names indicating updates. Create the registry settings with that filter. Create the metrics settings, associating the registry settings with the APPLICATION metric registry. Set the overall metrics settings and retrieve a registry factory suitably initialized. Obtain a reference to the APPLICATION registry which is set up to create and report on only metrics with names starting with myapp.updates. . ",
            "title": "Controlling Metrics by Metric Name"
        },
        {
            "location": "se/guides/metrics",
            "text": " You can control the collection and reporting of metrics by registry type and metric name within registry type. Disabling All Metrics of a Given Registry Type To disable all metrics in a given registry type (application, vendor, or base), add one or more groups to the configuration: <markup lang=\"properties\" title=\"Disabling base and vendor metrics (properties format)\" >metrics.registries.0.type = base metrics.registries.0.enabled = false metrics.registries.1.type = vendor metrics.registries.1.enabled = false <markup lang=\"yaml\" title=\"Disabling base and vendor metrics (YAML format)\" >metrics: registries: - type: base enabled: false - type: vendor enables: false Controlling Metrics by Metric Name You can be even more selective. Within a registry type you can configure up to two regular expression patterns: one matching metric names to exclude , and one matching metric names to include . Helidon updates and reports a metric only if two conditions hold: the metric name does not match the exclude regex pattern (if you define one), and either there is no include regex pattern, or the metric name matches the include pattern. Caution Make sure any include regex pattern you specify matches all the metric names you want to capture. Suppose your application creates and updates a group of metrics with names such as myapp.xxx.queries , myapp.xxx.creates , myapp.xxx.updates , and myapp.xxx.deletes where xxx can be either supplier or customer . The following example gathers all metrics except those from your application regarding suppliers: <markup lang=\"properties\" title=\"Disabling metrics by name (properties format)\" >metrics.registries.0.type = application metrics.registries.0.filter.exclude = myapp\\.supplier\\..* The following settings select the particular subset of the metrics created in your application code representing updates of customers and suppliers: <markup lang=\"properties\" title=\"Enabling metrics by name (properties format)\" >metrics.registries.0.type = application metrics.registries.0.filter.include = myapp\\..*\\.updates If you use the YAML configuration format, enclose the regex patterns in single-quote marks: <markup lang=\"yaml\" title=\"Enabling metrics by name (YAML format)\" >metrics: registries: - type: application filter: include: 'myapp\\..*\\.updates' The next example selects only your application&#8217;s metrics while excluding those which refer to deletions: <markup lang=\"properties\" title=\"Combining include and exclude \" >metrics.registries.0.type = application metrics.registries.0.filter.include = myapp\\..* metrics.registries.0.filter.exclude = myapp\\..*/deletes Helidon would not update or report the metric myapp.supplier.queries , for example. To include metrics from your application for both updates and queries (but not for other operations), you could change the settings in the previous example to this: <markup >metrics.registries.0.type = application metrics.registries.0.filter.include = myapp\\..*\\.updates|myapp\\..*\\.queries metrics.registries.0.filter.exclude = myapp\\..*/deletes Your Helidon SE application can control the collection and reporting of metrics programmatically as well by preparing these settings objects: RegistryFilterSettings RegistrySettings MetricsSettings and using the resulting MetricsSettings to retrieve a suitable RegistryFactory . <markup lang=\"java\" title=\"Control metrics by registry type and name\" >import io.helidon.metrics.api.RegistryFilterSettings; import org.eclipse.microprofile.metrics.MetricRegistry; ... RegistryFilterSettings appFilterSettings = RegistryFilterSettings.builder() .include(\"myapp\\..*\\.updates\") .build(); RegistrySettings registrySettings = RegistrySettings.builder() .filterSettings(appFilterSettings) .build(); MetricsSettings metricsSettings = MetricsSettings.builder() .registrySettings(MetricRegistry.Type.APPLICATION, appFilterSettings) .build(); RegistryFactory rf = RegistryFactory.getInstance(metricsSettings); MetricRegistry registry = rf.getRegistry(MetricRegistry.Type.APPLICATION); Create the registry filter settings to include only those metrics with names indicating updates. Create the registry settings with that filter. Create the metrics settings, associating the registry settings with the APPLICATION metric registry. Set the overall metrics settings and retrieve a registry factory suitably initialized. Obtain a reference to the APPLICATION registry which is set up to create and report on only metrics with names starting with myapp.updates. . ",
            "title": "Controlling Metrics By Registry Type and Metric Name"
        },
        {
            "location": "se/guides/metrics",
            "text": " Any time you include the Helidon metrics module in your application, Helidon tracks two basic performance indicator metrics: a Counter of all requests received ( requests.count ), and a Meter of all requests received ( requests.meter ). Helidon SE also includes additional, extended KPI metrics which are disabled by default: current number of requests in-flight - a ConcurrentGauge ( requests.inFlight ) of requests currently being processed long-running requests - a Meter ( requests.longRunning ) measuring the rate at which Helidon processes requests which take at least a given amount of time to complete; configurable, defaults to 10000 milliseconds (10 seconds) load - a Meter ( requests.load ) measuring the rate at which requests are worked on (as opposed to received) deferred - a Meter ( requests.deferred ) measuring the rate at which a request&#8217;s processing is delayed after Helidon receives the request You can enable and control these metrics using configuration: <markup lang=\"properties\" title=\"Configuration properties file controlling extended KPI metrics\" >metrics.key-performance-indicators.extended = true metrics.key-performance-indicators.long-running.threshold-ms = 2000 Your Helidon SE application can also control the KPI settings programmatically. <markup lang=\"java\" title=\"Assign KPI metrics behavior from code\" >import io.helidon.metrics.api.KeyPerformanceIndicatorMetricsSettings; import io.helidon.metrics.api.MetricsSettings; import io.helidon.metrics.serviceapi.MetricsSupport; import io.helidon.metrics.api.RegistryFactory; ... KeyPerformanceIndicatorMetricsSettings.Builder kpiSettingsBuilder = KeyPerformanceIndicatorMetricsSettings.builder() .extended(true) .longRunningThresholdMs(2000); MetricsSettings metricsSettings = MetricsSettings.builder() .keyPerformanceIndicatorSettings(kpiSettingsBuilder) .build(); Create a KeyPerformanceIndicatorMetricsSettings instance (via its Builder ) with non-default values. Create a MetricsSettings instance reflecting the KPI settings. ",
            "title": "Collecting Basic and Extended Key Performance Indicator (KPI) Metrics"
        },
        {
            "location": "se/guides/metrics",
            "text": " By adding a metrics section to your application configuration you can control how the Helidon metrics subsystem behaves in any of several ways. Disable metrics subsystem entirely . Identify groups of metrics to control: registered by a particular component , and by metric registry (application, vendor, and base) and within a registry by metric names which match patterns you provide. Select whether to collect extended key performance indicator metrics . Your Helidon SE application can also control metrics processing programmatically as described in the following sections. Disabling Metrics Subsystem Entirely By default, if your application depends on the helidon-metrics Maven module then full-featured metrics are enabled. You can disable the metrics subsystem entirely using configuration: <markup lang=\"properties\" title=\"Configuration properties file disabling metrics\" >metrics.enabled=false A Helidon SE application can disable metrics processing programmatically. <markup lang=\"java\" title=\"Disable all metrics behavior\" >import io.helidon.metrics.api.MetricsSettings; import io.helidon.metrics.serviceapi.MetricsSupport; import io.helidon.metrics.api.RegistryFactory; MetricsSettings metricsSettings = MetricsSettings.builder() .enabled(false) .build(); MetricsSupport metricsSupport = MetricsSupport.create(metricsSettings); RegistryFactory registryFactory = RegistryFactory.getInstance(metricsSettings); Create a MetricsSettings instance (via its Builder ) with the metrics subsystem disabled. Get a MetricsSupport service (usable in setting routing rules) that responds to the /metrics endpoint with 404 and an explanatory message. Get a RegistryFactory instance that provides MetricRegistry instances which register no-op metric objects (counters, timers, etc.). These builders and interfaces also have methods which accept Config objects representing the metrics node from the application configuration. With metrics processing disabled, Helidon never updates any metrics and the /metrics endpoints respond with 404 plus a message that the metrics subsystem is disabled. Enabling and Disabling Metrics Usage by a Component Helidon contains several components and integrations which register and update metrics. Depending on how the component is written, you might be able to disable just that component&#8217;s use of metrics: <markup lang=\"properties\" title=\"Configuration properties file disabling a component&#8217;s use of metrics\" >some-component.metrics.enabled=false Check the documentation for a specific component to find out whether that component uses metrics and whether it allows you to disable that use. Your Helidon SE application can disable a metrics-capable component&#8217;s use of metrics programmatically. <markup lang=\"java\" title=\"Disable metrics use in a metrics-capable component\" >import io.helidon.metrics.api.ComponentMetricsSettings; ComponentMetricsSettings.Builder componentMetricsSettingsBuilder = ComponentMetricsSettings.builder() .enabled(false); SomeService someService = SomeService.builder() .componentMetricsSettings(componentMetricsSettingsBuilder) .build(); Create a ComponentMetricsSettings instance (via its Builder ) indicating that metrics usage should be disabled. Create an instance of the service with its metrics usage disabled. If you disable a component&#8217;s use of metrics, Helidon does not register the component&#8217;s metrics in the visible metrics registries nor do those metrics ever update their values. The response from the /metrics endpoint excludes that component&#8217;s metrics. Note that if you disable metrics processing entirely, no component updates its metrics regardless of any component-level metrics settings. Controlling Metrics By Registry Type and Metric Name You can control the collection and reporting of metrics by registry type and metric name within registry type. Disabling All Metrics of a Given Registry Type To disable all metrics in a given registry type (application, vendor, or base), add one or more groups to the configuration: <markup lang=\"properties\" title=\"Disabling base and vendor metrics (properties format)\" >metrics.registries.0.type = base metrics.registries.0.enabled = false metrics.registries.1.type = vendor metrics.registries.1.enabled = false <markup lang=\"yaml\" title=\"Disabling base and vendor metrics (YAML format)\" >metrics: registries: - type: base enabled: false - type: vendor enables: false Controlling Metrics by Metric Name You can be even more selective. Within a registry type you can configure up to two regular expression patterns: one matching metric names to exclude , and one matching metric names to include . Helidon updates and reports a metric only if two conditions hold: the metric name does not match the exclude regex pattern (if you define one), and either there is no include regex pattern, or the metric name matches the include pattern. Caution Make sure any include regex pattern you specify matches all the metric names you want to capture. Suppose your application creates and updates a group of metrics with names such as myapp.xxx.queries , myapp.xxx.creates , myapp.xxx.updates , and myapp.xxx.deletes where xxx can be either supplier or customer . The following example gathers all metrics except those from your application regarding suppliers: <markup lang=\"properties\" title=\"Disabling metrics by name (properties format)\" >metrics.registries.0.type = application metrics.registries.0.filter.exclude = myapp\\.supplier\\..* The following settings select the particular subset of the metrics created in your application code representing updates of customers and suppliers: <markup lang=\"properties\" title=\"Enabling metrics by name (properties format)\" >metrics.registries.0.type = application metrics.registries.0.filter.include = myapp\\..*\\.updates If you use the YAML configuration format, enclose the regex patterns in single-quote marks: <markup lang=\"yaml\" title=\"Enabling metrics by name (YAML format)\" >metrics: registries: - type: application filter: include: 'myapp\\..*\\.updates' The next example selects only your application&#8217;s metrics while excluding those which refer to deletions: <markup lang=\"properties\" title=\"Combining include and exclude \" >metrics.registries.0.type = application metrics.registries.0.filter.include = myapp\\..* metrics.registries.0.filter.exclude = myapp\\..*/deletes Helidon would not update or report the metric myapp.supplier.queries , for example. To include metrics from your application for both updates and queries (but not for other operations), you could change the settings in the previous example to this: <markup >metrics.registries.0.type = application metrics.registries.0.filter.include = myapp\\..*\\.updates|myapp\\..*\\.queries metrics.registries.0.filter.exclude = myapp\\..*/deletes Your Helidon SE application can control the collection and reporting of metrics programmatically as well by preparing these settings objects: RegistryFilterSettings RegistrySettings MetricsSettings and using the resulting MetricsSettings to retrieve a suitable RegistryFactory . <markup lang=\"java\" title=\"Control metrics by registry type and name\" >import io.helidon.metrics.api.RegistryFilterSettings; import org.eclipse.microprofile.metrics.MetricRegistry; ... RegistryFilterSettings appFilterSettings = RegistryFilterSettings.builder() .include(\"myapp\\..*\\.updates\") .build(); RegistrySettings registrySettings = RegistrySettings.builder() .filterSettings(appFilterSettings) .build(); MetricsSettings metricsSettings = MetricsSettings.builder() .registrySettings(MetricRegistry.Type.APPLICATION, appFilterSettings) .build(); RegistryFactory rf = RegistryFactory.getInstance(metricsSettings); MetricRegistry registry = rf.getRegistry(MetricRegistry.Type.APPLICATION); Create the registry filter settings to include only those metrics with names indicating updates. Create the registry settings with that filter. Create the metrics settings, associating the registry settings with the APPLICATION metric registry. Set the overall metrics settings and retrieve a registry factory suitably initialized. Obtain a reference to the APPLICATION registry which is set up to create and report on only metrics with names starting with myapp.updates. . Collecting Basic and Extended Key Performance Indicator (KPI) Metrics Any time you include the Helidon metrics module in your application, Helidon tracks two basic performance indicator metrics: a Counter of all requests received ( requests.count ), and a Meter of all requests received ( requests.meter ). Helidon SE also includes additional, extended KPI metrics which are disabled by default: current number of requests in-flight - a ConcurrentGauge ( requests.inFlight ) of requests currently being processed long-running requests - a Meter ( requests.longRunning ) measuring the rate at which Helidon processes requests which take at least a given amount of time to complete; configurable, defaults to 10000 milliseconds (10 seconds) load - a Meter ( requests.load ) measuring the rate at which requests are worked on (as opposed to received) deferred - a Meter ( requests.deferred ) measuring the rate at which a request&#8217;s processing is delayed after Helidon receives the request You can enable and control these metrics using configuration: <markup lang=\"properties\" title=\"Configuration properties file controlling extended KPI metrics\" >metrics.key-performance-indicators.extended = true metrics.key-performance-indicators.long-running.threshold-ms = 2000 Your Helidon SE application can also control the KPI settings programmatically. <markup lang=\"java\" title=\"Assign KPI metrics behavior from code\" >import io.helidon.metrics.api.KeyPerformanceIndicatorMetricsSettings; import io.helidon.metrics.api.MetricsSettings; import io.helidon.metrics.serviceapi.MetricsSupport; import io.helidon.metrics.api.RegistryFactory; ... KeyPerformanceIndicatorMetricsSettings.Builder kpiSettingsBuilder = KeyPerformanceIndicatorMetricsSettings.builder() .extended(true) .longRunningThresholdMs(2000); MetricsSettings metricsSettings = MetricsSettings.builder() .keyPerformanceIndicatorSettings(kpiSettingsBuilder) .build(); Create a KeyPerformanceIndicatorMetricsSettings instance (via its Builder ) with non-default values. Create a MetricsSettings instance reflecting the KPI settings. ",
            "title": "Controlling Metrics Behavior"
        },
        {
            "location": "se/guides/metrics",
            "text": " Each metric has associated metadata that describes: name: The name of the metric. units: The unit of the metric such as time (seconds, millisecond), size (bytes, megabytes), etc. type: The type of metric: Counter , Timer , Meter , Histogram , SimpleTimer , or Gauge . You can get the metadata for any scope, such as /metrics/base , as shown below: <markup lang=\"bash\" title=\"Get the metrics metadata using HTTP OPTIONS method:\" > curl -X OPTIONS -H \"Accept: application/json\" http://localhost:8080/metrics/base <markup lang=\"json\" title=\"JSON response (truncated):\" >{ \"classloader.currentLoadedClass.count\": { \"unit\": \"none\", \"type\": \"counter\", \"description\": \"Displays the number of classes that are currently loaded in the Java virtual machine.\", \"displayName\": \"Current Loaded Class Count\" }, \"jvm.uptime\": { \"unit\": \"milliseconds\", \"type\": \"gauge\", \"description\": \"Displays the start time of the Java virtual machine in milliseconds. This attribute displays the approximate time when the Java virtual machine started.\", \"displayName\": \"JVM Uptime\" }, \"memory.usedHeap\": { \"unit\": \"bytes\", \"type\": \"gauge\", \"description\": \"Displays the amount of used heap memory in bytes.\", \"displayName\": \"Used Heap Memory\" } } ",
            "title": "Metrics Metadata"
        },
        {
            "location": "se/guides/metrics",
            "text": " The Counter metric is a monotonically increasing or decreasing number. The following example will demonstrate how to use a Counter to track the number of times the /cards endpoint is called. <markup lang=\"java\" title=\"Create a new class named GreetingCards with the following code:\" >package io.helidon.examples.quickstart.se; import io.helidon.metrics.RegistryFactory; import io.helidon.webserver.Routing; import io.helidon.webserver.ServerRequest; import io.helidon.webserver.ServerResponse; import io.helidon.webserver.Service; import java.util.Collections; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import org.eclipse.microprofile.metrics.Counter; import org.eclipse.microprofile.metrics.MetricRegistry; public class GreetingCards implements Service { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); private final Counter cardCounter; GreetingCards() { RegistryFactory metricsRegistry = RegistryFactory.getInstance(); MetricRegistry appRegistry = metricsRegistry.getRegistry(MetricRegistry.Type.APPLICATION); cardCounter = appRegistry.counter(\"cardCount\"); } @Override public void update(Routing.Rules rules) { rules.get(\"/\", this::getDefaultMessageHandler); } private void getDefaultMessageHandler(ServerRequest request, ServerResponse response) { cardCounter.inc(); sendResponse(response, \"Here are some cards ...\"); } private void sendResponse(ServerResponse response, String msg) { JsonObject returnObject = JSON.createObjectBuilder().add(\"message\", msg).build(); response.send(returnObject); } } Import metrics classes. Declare a Counter member variable. Create and register the Counter metric in the MetricRegistry . This Counter will exist for the lifetime of the application. Increment the count. <markup lang=\"java\" title=\"Update the Main.createRouting method as follows:\" > private static Routing createRouting(Config config) { MetricsSupport metrics = MetricsSupport.create(); GreetService greetService = new GreetService(config); HealthSupport health = HealthSupport.builder() .addLiveness(HealthChecks.healthChecks()) // Adds a convenient set of checks .build(); return Routing.builder() .register(health) // Health at \"/health\" .register(metrics) // Metrics at \"/metrics\" .register(\"/greet\", greetService) .register(\"/cards\", new GreetingCards()) .build(); } Add the GreetingCards service to the Routing.builder . Helidon will route any REST requests with the /cards root path to the GreetingCards service. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints below:\" >curl http://localhost:8080/cards curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response:\" >{ \"cardCount\": 1 } The count value is one since the method was called once. ",
            "title": "Counter Metric"
        },
        {
            "location": "se/guides/metrics",
            "text": " The Meter metric is used to measure throughput, the number of times an event occurs within a certain time period. When a Meter object is created, its internal clock starts running. That clock is used to calculate the various rates stored this metric. The Meter also includes the count field from the Counter metric. When you mark an event, the count is incremented. The following example marks an event each time the /cards endpoint is called. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.se; import io.helidon.metrics.RegistryFactory; import io.helidon.webserver.Routing; import io.helidon.webserver.ServerRequest; import io.helidon.webserver.ServerResponse; import io.helidon.webserver.Service; import java.util.Collections; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import org.eclipse.microprofile.metrics.Meter; import org.eclipse.microprofile.metrics.MetricRegistry; public class GreetingCards implements Service { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); private final Meter cardMeter; GreetingCards() { RegistryFactory metricsRegistry = RegistryFactory.getInstance(); MetricRegistry appRegistry = metricsRegistry.getRegistry(MetricRegistry.Type.APPLICATION); cardMeter = appRegistry.meter(\"cardMeter\"); } @Override public void update(Routing.Rules rules) { rules.get(\"/\", this::getDefaultMessageHandler); } private void getDefaultMessageHandler(ServerRequest request, ServerResponse response) { cardMeter.mark(); sendResponse(response, \"Here are some cards ...\"); } private void sendResponse(ServerResponse response, String msg) { JsonObject returnObject = JSON.createObjectBuilder().add(\"message\", msg).build(); response.send(returnObject); } } Import metrics classes. Declare a Meter member variable. Create and register the Meter metric in the MetricRegistry . Mark the occurrence of an event. Note: you can specify a count parameter such as mark(100) to mark multiple events. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints below:\" >curl http://localhost:8080/cards curl http://localhost:8080/cards curl http://localhost:8080/cards curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response:\" >{ \"cardMeter\": { \"count\": 3, \"meanRate\": 0.17566568722974535, \"oneMinRate\": 0.04413761384322548, \"fiveMinRate\": 0.009753212003766951, \"fifteenMinRate\": 0.0033056752265846544 } } The Meter metric has a set of fields to show various rates, along with the count. The /cards endpoint was called three times. ",
            "title": "Meter Metric"
        },
        {
            "location": "se/guides/metrics",
            "text": " (See also Simple timer metric .) The Timer metric aggregates durations, provides timing statistics, and includes throughput statistics using an internal Meter metric. The Timer measures duration in nanoseconds. In the following example, a Timer metric is used to measure the duration of a method&#8217;s execution. Whenever the REST /cards endpoint is called, the Timer will be updated with additional timing information. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.se; import io.helidon.metrics.RegistryFactory; import io.helidon.webserver.Routing; import io.helidon.webserver.ServerRequest; import io.helidon.webserver.ServerResponse; import io.helidon.webserver.Service; import java.util.Collections; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import org.eclipse.microprofile.metrics.MetricRegistry; import org.eclipse.microprofile.metrics.Timer; public class GreetingCards implements Service { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); private final Timer cardTimer; GreetingCards() { RegistryFactory metricsRegistry = RegistryFactory.getInstance(); MetricRegistry appRegistry = metricsRegistry.getRegistry(MetricRegistry.Type.APPLICATION); cardTimer = appRegistry.timer(\"cardTimer\"); } @Override public void update(Routing.Rules rules) { rules.get(\"/\", this::getDefaultMessageHandler); } private void getDefaultMessageHandler(ServerRequest request, ServerResponse response) { Timer.Context timerContext = cardTimer.time(); sendResponse(response, \"Here are some cards ...\"); response.whenSent().thenAccept(res -&gt; timerContext.stop()); } private void sendResponse(ServerResponse response, String msg) { JsonObject returnObject = JSON.createObjectBuilder().add(\"message\", msg).build(); response.send(returnObject); } } Import metrics classes. Declare a Timer member variable. Create and register the Timer metric in the MetricRegistry . Start the timer. Stop the timer. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints below:\" >curl http://localhost:8080/cards curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response:\" >{ \"cardTimer\": { \"count\": 1, \"elapsedTime\": 26683406, \"meanRate\": 0.05669258258076838, \"oneMinRate\": 0, \"fiveMinRate\": 0, \"fifteenMinRate\": 0, \"min\": 26683406, \"max\": 26683406, \"mean\": 26683406, \"stddev\": 0, \"p50\": 26683406, \"p75\": 26683406, \"p95\": 26683406, \"p98\": 26683406, \"p99\": 26683406, \"p999\": 26683406 } } The first several fields (except for elapsedTime ) are the same ones used by Meter . The elapsedTime field and the rest starting with min are the Timer fields that measure the duration of the getDefaultMessageHandler method. Some of these values will change each time you invoke the /cards endpoint. ",
            "title": "Timer Metric"
        },
        {
            "location": "se/guides/metrics",
            "text": " The Histogram metric calculates the distribution of a set of values within ranges. This metric does not relate to time at all. The following example will record a set of random numbers in a Histogram metric when the /cards endpoint is invoked. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.se; import io.helidon.metrics.RegistryFactory; import io.helidon.webserver.Routing; import io.helidon.webserver.ServerRequest; import io.helidon.webserver.ServerResponse; import io.helidon.webserver.Service; import java.util.Collections; import java.util.Random; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import org.eclipse.microprofile.metrics.Histogram; import org.eclipse.microprofile.metrics.MetricRegistry; public class GreetingCards implements Service { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); private final Histogram cardHistogram; GreetingCards() { RegistryFactory metricsRegistry = RegistryFactory.getInstance(); MetricRegistry appRegistry = metricsRegistry.getRegistry(MetricRegistry.Type.APPLICATION); cardHistogram = appRegistry.histogram(\"cardHistogram\"); } @Override public void update(Routing.Rules rules) { rules.get(\"/\", this::getDefaultMessageHandler); } private void getDefaultMessageHandler(ServerRequest request, ServerResponse response) { Random r = new Random(); for (int i = 0; i &lt; 1000; i++) { cardHistogram.update(1 + r.nextInt(25)); } sendResponse(response, \"Here are some cards ...\"); } private void sendResponse(ServerResponse response, String msg) { JsonObject returnObject = JSON.createObjectBuilder().add(\"message\", msg).build(); response.send(returnObject); } } Import metrics classes. Declare a Histogram member variable. Create and register the Histogram metric in the MetricRegistry . Update the Histogram metric with a random number. Loop, loading the histogram with numbers. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints below:\" >curl http://localhost:8080/cards curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response:\" >{ \"cardHistogram\": { \"count\": 1000, \"min\": 1, \"max\": 25, \"mean\": 12.743999999999915, \"stddev\": 7.308793607702962, \"p50\": 13.0, \"p75\": 19.0, \"p95\": 24.0, \"p98\": 25.0, \"p99\": 25.0, \"p999\": 25.0 } } This is the histogram data. Some of these values will change each time you invoke the /cards endpoint. ",
            "title": "Histogram Metric"
        },
        {
            "location": "se/guides/metrics",
            "text": " The Gauge metric measures a discreet value at a point in time, such as a temperature. The metric is not normally tied to a REST endpoint, rather it should be registered during application startup. When the /metrics/application endpoint is invoked, Helidon will call the getValue method of each registered Gauge . The following example demonstrates how a Gauge is used to get the current temperature. <markup lang=\"java\" title=\"Add new imports to Main.java and replace the Main.createRouting method with the following code:\" >import io.helidon.metrics.RegistryFactory; import java.util.Random; import org.eclipse.microprofile.metrics.Gauge; import org.eclipse.microprofile.metrics.MetricRegistry; ... private static Routing createRouting(Config config) { MetricsSupport metrics = MetricsSupport.create(); RegistryFactory metricsRegistry = RegistryFactory.getInstance(); MetricRegistry appRegistry = metricsRegistry.getRegistry(MetricRegistry.Type.APPLICATION); appRegistry.register(\"temperature\", (Gauge&lt;Integer&gt;)() -&gt; new Random().nextInt(100)); GreetService greetService = new GreetService(config); return Routing.builder() .register(JsonSupport.create()) .register(metrics) // Metrics at \"/metrics\" .register(\"/greet\", greetService) .register(\"/cards\", new GreetingCards()) .build(); } Register the Gauge , providing a lambda function that will return a random temperature. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code to use the Counter metric which will simplify the JSON output:\" >package io.helidon.examples.quickstart.se; import io.helidon.metrics.RegistryFactory; import io.helidon.webserver.Routing; import io.helidon.webserver.ServerRequest; import io.helidon.webserver.ServerResponse; import io.helidon.webserver.Service; import java.util.Collections; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import org.eclipse.microprofile.metrics.Counter; import org.eclipse.microprofile.metrics.MetricRegistry; public class GreetingCards implements Service { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); private final Counter cardCounter; GreetingCards() { RegistryFactory metricsRegistry = RegistryFactory.getInstance(); MetricRegistry appRegistry = metricsRegistry.getRegistry(MetricRegistry.Type.APPLICATION); cardCounter = appRegistry.counter(\"cardCount\"); } @Override public void update(Routing.Rules rules) { rules.get(\"/\", this::getDefaultMessageHandler); } private void getDefaultMessageHandler(ServerRequest request, ServerResponse response) { cardCounter.inc(); sendResponse(response, \"Here are some cards ...\"); } private void sendResponse(ServerResponse response, String msg) { JsonObject returnObject = JSON.createObjectBuilder().add(\"message\", msg).build(); response.send(returnObject); } } <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints below:\" >curl http://localhost:8080/cards curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response from /metrics/application :\" >{ \"cardCount\": 1, \"temperature\": 11 } The current temperature is returned. Invoke the /metrics/application endpoint again and you should get a different value. ",
            "title": "Gauge Metric"
        },
        {
            "location": "se/guides/metrics",
            "text": " The SimpleTimer metric counts invocations and accumulates duration (in seconds). It also records the minimum and maximum values sampled during the previous complete minute. In the following example, a SimpleTimer metric is used to count and measure the duration of a method&#8217;s execution. Whenever the REST /cards endpoint is called, the SimpleTimer updates its count and total elapsed time. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.se; import io.helidon.metrics.RegistryFactory; import io.helidon.webserver.Routing; import io.helidon.webserver.ServerRequest; import io.helidon.webserver.ServerResponse; import io.helidon.webserver.Service; import java.util.Collections; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import org.eclipse.microprofile.metrics.MetricRegistry; import org.eclipse.microprofile.metrics.SimpleTimer; // &lt;!&gt; public class GreetingCards implements Service { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); private final SimpleTimer cardTimer; GreetingCards() { RegistryFactory metricsRegistry = RegistryFactory.getInstance(); MetricRegistry appRegistry = metricsRegistry.getRegistry(MetricRegistry.Type.APPLICATION); cardTimer = appRegistry.simpleTimer(\"cardSimpleTimer\"); } @Override public void update(Routing.Rules rules) { rules.get(\"/\", this::getDefaultMessageHandler); } private void getDefaultMessageHandler(ServerRequest request, ServerResponse response) { cardTimer.time(() -&gt; sendResponse(response, \"Here are some cards ...\")); } private void sendResponse(ServerResponse response, String msg) { JsonObject returnObject = JSON.createObjectBuilder().add(\"message\", msg).build(); response.send(returnObject); } } Import metrics classes, particularly the SimpleTimer interface for this example. Declare a SimpleTimer member variable. Create and register the SimpleTimer metric in the MetricRegistry . Wrap the business logic in the simple timer&#8217;s time method which updates the count and the total elapsed time. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints below:\" >curl http://localhost:8080/cards curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response:\" >{ \"cardSimpleTimer\": { \"count\": 1, \"elapsedTime\": 13455720, \"maxTimeDuration\": null, \"minTimeDuration\": null } } How many times the getDefaultMessageHandler method ran. Cumulative time spent in the getDefaultMessageHandler method during its executions. Simple timers report the minimum and maximum durations recorded over the preceding complete minute. The JSON output contains null for these values if the simple timer recorded no observations during the preceding complete minute. If you retrieve the metrics again shortly after the current minute has completed, the simple timer reports useful values. <markup lang=\"json\" title=\"JSON response after the current minute completes:\" >{ \"cardSimpleTimer\": { \"count\": 1, \"elapsedTime\": 13455720, \"maxTimeDuration\": 13455720, \"minTimeDuration\": 13455720 } } If you again wait until the next complete minute without accessing the greeting card endpoint again and rerun the metrics query, the simple timer reports null values again because there was no activity in the preceding complete minute. ",
            "title": "Simple Timer Metric"
        },
        {
            "location": "se/guides/metrics",
            "text": " This section demonstrates how to use application-specific metrics and integrate them with Helidon. It is the application&#8217;s responsibility to create and update the metrics at runtime. The application has complete control over when and how each metric is used. For example, an application may use the same counter for multiple methods, or one counter per method. Helidon maintains an application MetricRegistry which is used to manage all of the application metrics. Helidon returns these metrics in response to a /metrics/application REST request. In all of these examples, the scope and lifetime of the metric is at the application-level. Each metric, except Gauge , is updated in response to a REST request and the contents of the metric is cumulative. Counter Metric The Counter metric is a monotonically increasing or decreasing number. The following example will demonstrate how to use a Counter to track the number of times the /cards endpoint is called. <markup lang=\"java\" title=\"Create a new class named GreetingCards with the following code:\" >package io.helidon.examples.quickstart.se; import io.helidon.metrics.RegistryFactory; import io.helidon.webserver.Routing; import io.helidon.webserver.ServerRequest; import io.helidon.webserver.ServerResponse; import io.helidon.webserver.Service; import java.util.Collections; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import org.eclipse.microprofile.metrics.Counter; import org.eclipse.microprofile.metrics.MetricRegistry; public class GreetingCards implements Service { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); private final Counter cardCounter; GreetingCards() { RegistryFactory metricsRegistry = RegistryFactory.getInstance(); MetricRegistry appRegistry = metricsRegistry.getRegistry(MetricRegistry.Type.APPLICATION); cardCounter = appRegistry.counter(\"cardCount\"); } @Override public void update(Routing.Rules rules) { rules.get(\"/\", this::getDefaultMessageHandler); } private void getDefaultMessageHandler(ServerRequest request, ServerResponse response) { cardCounter.inc(); sendResponse(response, \"Here are some cards ...\"); } private void sendResponse(ServerResponse response, String msg) { JsonObject returnObject = JSON.createObjectBuilder().add(\"message\", msg).build(); response.send(returnObject); } } Import metrics classes. Declare a Counter member variable. Create and register the Counter metric in the MetricRegistry . This Counter will exist for the lifetime of the application. Increment the count. <markup lang=\"java\" title=\"Update the Main.createRouting method as follows:\" > private static Routing createRouting(Config config) { MetricsSupport metrics = MetricsSupport.create(); GreetService greetService = new GreetService(config); HealthSupport health = HealthSupport.builder() .addLiveness(HealthChecks.healthChecks()) // Adds a convenient set of checks .build(); return Routing.builder() .register(health) // Health at \"/health\" .register(metrics) // Metrics at \"/metrics\" .register(\"/greet\", greetService) .register(\"/cards\", new GreetingCards()) .build(); } Add the GreetingCards service to the Routing.builder . Helidon will route any REST requests with the /cards root path to the GreetingCards service. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints below:\" >curl http://localhost:8080/cards curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response:\" >{ \"cardCount\": 1 } The count value is one since the method was called once. Meter Metric The Meter metric is used to measure throughput, the number of times an event occurs within a certain time period. When a Meter object is created, its internal clock starts running. That clock is used to calculate the various rates stored this metric. The Meter also includes the count field from the Counter metric. When you mark an event, the count is incremented. The following example marks an event each time the /cards endpoint is called. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.se; import io.helidon.metrics.RegistryFactory; import io.helidon.webserver.Routing; import io.helidon.webserver.ServerRequest; import io.helidon.webserver.ServerResponse; import io.helidon.webserver.Service; import java.util.Collections; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import org.eclipse.microprofile.metrics.Meter; import org.eclipse.microprofile.metrics.MetricRegistry; public class GreetingCards implements Service { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); private final Meter cardMeter; GreetingCards() { RegistryFactory metricsRegistry = RegistryFactory.getInstance(); MetricRegistry appRegistry = metricsRegistry.getRegistry(MetricRegistry.Type.APPLICATION); cardMeter = appRegistry.meter(\"cardMeter\"); } @Override public void update(Routing.Rules rules) { rules.get(\"/\", this::getDefaultMessageHandler); } private void getDefaultMessageHandler(ServerRequest request, ServerResponse response) { cardMeter.mark(); sendResponse(response, \"Here are some cards ...\"); } private void sendResponse(ServerResponse response, String msg) { JsonObject returnObject = JSON.createObjectBuilder().add(\"message\", msg).build(); response.send(returnObject); } } Import metrics classes. Declare a Meter member variable. Create and register the Meter metric in the MetricRegistry . Mark the occurrence of an event. Note: you can specify a count parameter such as mark(100) to mark multiple events. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints below:\" >curl http://localhost:8080/cards curl http://localhost:8080/cards curl http://localhost:8080/cards curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response:\" >{ \"cardMeter\": { \"count\": 3, \"meanRate\": 0.17566568722974535, \"oneMinRate\": 0.04413761384322548, \"fiveMinRate\": 0.009753212003766951, \"fifteenMinRate\": 0.0033056752265846544 } } The Meter metric has a set of fields to show various rates, along with the count. The /cards endpoint was called three times. Timer Metric (See also Simple timer metric .) The Timer metric aggregates durations, provides timing statistics, and includes throughput statistics using an internal Meter metric. The Timer measures duration in nanoseconds. In the following example, a Timer metric is used to measure the duration of a method&#8217;s execution. Whenever the REST /cards endpoint is called, the Timer will be updated with additional timing information. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.se; import io.helidon.metrics.RegistryFactory; import io.helidon.webserver.Routing; import io.helidon.webserver.ServerRequest; import io.helidon.webserver.ServerResponse; import io.helidon.webserver.Service; import java.util.Collections; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import org.eclipse.microprofile.metrics.MetricRegistry; import org.eclipse.microprofile.metrics.Timer; public class GreetingCards implements Service { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); private final Timer cardTimer; GreetingCards() { RegistryFactory metricsRegistry = RegistryFactory.getInstance(); MetricRegistry appRegistry = metricsRegistry.getRegistry(MetricRegistry.Type.APPLICATION); cardTimer = appRegistry.timer(\"cardTimer\"); } @Override public void update(Routing.Rules rules) { rules.get(\"/\", this::getDefaultMessageHandler); } private void getDefaultMessageHandler(ServerRequest request, ServerResponse response) { Timer.Context timerContext = cardTimer.time(); sendResponse(response, \"Here are some cards ...\"); response.whenSent().thenAccept(res -&gt; timerContext.stop()); } private void sendResponse(ServerResponse response, String msg) { JsonObject returnObject = JSON.createObjectBuilder().add(\"message\", msg).build(); response.send(returnObject); } } Import metrics classes. Declare a Timer member variable. Create and register the Timer metric in the MetricRegistry . Start the timer. Stop the timer. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints below:\" >curl http://localhost:8080/cards curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response:\" >{ \"cardTimer\": { \"count\": 1, \"elapsedTime\": 26683406, \"meanRate\": 0.05669258258076838, \"oneMinRate\": 0, \"fiveMinRate\": 0, \"fifteenMinRate\": 0, \"min\": 26683406, \"max\": 26683406, \"mean\": 26683406, \"stddev\": 0, \"p50\": 26683406, \"p75\": 26683406, \"p95\": 26683406, \"p98\": 26683406, \"p99\": 26683406, \"p999\": 26683406 } } The first several fields (except for elapsedTime ) are the same ones used by Meter . The elapsedTime field and the rest starting with min are the Timer fields that measure the duration of the getDefaultMessageHandler method. Some of these values will change each time you invoke the /cards endpoint. Histogram Metric The Histogram metric calculates the distribution of a set of values within ranges. This metric does not relate to time at all. The following example will record a set of random numbers in a Histogram metric when the /cards endpoint is invoked. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.se; import io.helidon.metrics.RegistryFactory; import io.helidon.webserver.Routing; import io.helidon.webserver.ServerRequest; import io.helidon.webserver.ServerResponse; import io.helidon.webserver.Service; import java.util.Collections; import java.util.Random; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import org.eclipse.microprofile.metrics.Histogram; import org.eclipse.microprofile.metrics.MetricRegistry; public class GreetingCards implements Service { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); private final Histogram cardHistogram; GreetingCards() { RegistryFactory metricsRegistry = RegistryFactory.getInstance(); MetricRegistry appRegistry = metricsRegistry.getRegistry(MetricRegistry.Type.APPLICATION); cardHistogram = appRegistry.histogram(\"cardHistogram\"); } @Override public void update(Routing.Rules rules) { rules.get(\"/\", this::getDefaultMessageHandler); } private void getDefaultMessageHandler(ServerRequest request, ServerResponse response) { Random r = new Random(); for (int i = 0; i &lt; 1000; i++) { cardHistogram.update(1 + r.nextInt(25)); } sendResponse(response, \"Here are some cards ...\"); } private void sendResponse(ServerResponse response, String msg) { JsonObject returnObject = JSON.createObjectBuilder().add(\"message\", msg).build(); response.send(returnObject); } } Import metrics classes. Declare a Histogram member variable. Create and register the Histogram metric in the MetricRegistry . Update the Histogram metric with a random number. Loop, loading the histogram with numbers. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints below:\" >curl http://localhost:8080/cards curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response:\" >{ \"cardHistogram\": { \"count\": 1000, \"min\": 1, \"max\": 25, \"mean\": 12.743999999999915, \"stddev\": 7.308793607702962, \"p50\": 13.0, \"p75\": 19.0, \"p95\": 24.0, \"p98\": 25.0, \"p99\": 25.0, \"p999\": 25.0 } } This is the histogram data. Some of these values will change each time you invoke the /cards endpoint. Gauge Metric The Gauge metric measures a discreet value at a point in time, such as a temperature. The metric is not normally tied to a REST endpoint, rather it should be registered during application startup. When the /metrics/application endpoint is invoked, Helidon will call the getValue method of each registered Gauge . The following example demonstrates how a Gauge is used to get the current temperature. <markup lang=\"java\" title=\"Add new imports to Main.java and replace the Main.createRouting method with the following code:\" >import io.helidon.metrics.RegistryFactory; import java.util.Random; import org.eclipse.microprofile.metrics.Gauge; import org.eclipse.microprofile.metrics.MetricRegistry; ... private static Routing createRouting(Config config) { MetricsSupport metrics = MetricsSupport.create(); RegistryFactory metricsRegistry = RegistryFactory.getInstance(); MetricRegistry appRegistry = metricsRegistry.getRegistry(MetricRegistry.Type.APPLICATION); appRegistry.register(\"temperature\", (Gauge&lt;Integer&gt;)() -&gt; new Random().nextInt(100)); GreetService greetService = new GreetService(config); return Routing.builder() .register(JsonSupport.create()) .register(metrics) // Metrics at \"/metrics\" .register(\"/greet\", greetService) .register(\"/cards\", new GreetingCards()) .build(); } Register the Gauge , providing a lambda function that will return a random temperature. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code to use the Counter metric which will simplify the JSON output:\" >package io.helidon.examples.quickstart.se; import io.helidon.metrics.RegistryFactory; import io.helidon.webserver.Routing; import io.helidon.webserver.ServerRequest; import io.helidon.webserver.ServerResponse; import io.helidon.webserver.Service; import java.util.Collections; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import org.eclipse.microprofile.metrics.Counter; import org.eclipse.microprofile.metrics.MetricRegistry; public class GreetingCards implements Service { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); private final Counter cardCounter; GreetingCards() { RegistryFactory metricsRegistry = RegistryFactory.getInstance(); MetricRegistry appRegistry = metricsRegistry.getRegistry(MetricRegistry.Type.APPLICATION); cardCounter = appRegistry.counter(\"cardCount\"); } @Override public void update(Routing.Rules rules) { rules.get(\"/\", this::getDefaultMessageHandler); } private void getDefaultMessageHandler(ServerRequest request, ServerResponse response) { cardCounter.inc(); sendResponse(response, \"Here are some cards ...\"); } private void sendResponse(ServerResponse response, String msg) { JsonObject returnObject = JSON.createObjectBuilder().add(\"message\", msg).build(); response.send(returnObject); } } <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints below:\" >curl http://localhost:8080/cards curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response from /metrics/application :\" >{ \"cardCount\": 1, \"temperature\": 11 } The current temperature is returned. Invoke the /metrics/application endpoint again and you should get a different value. Simple Timer Metric The SimpleTimer metric counts invocations and accumulates duration (in seconds). It also records the minimum and maximum values sampled during the previous complete minute. In the following example, a SimpleTimer metric is used to count and measure the duration of a method&#8217;s execution. Whenever the REST /cards endpoint is called, the SimpleTimer updates its count and total elapsed time. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.se; import io.helidon.metrics.RegistryFactory; import io.helidon.webserver.Routing; import io.helidon.webserver.ServerRequest; import io.helidon.webserver.ServerResponse; import io.helidon.webserver.Service; import java.util.Collections; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import org.eclipse.microprofile.metrics.MetricRegistry; import org.eclipse.microprofile.metrics.SimpleTimer; // &lt;!&gt; public class GreetingCards implements Service { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); private final SimpleTimer cardTimer; GreetingCards() { RegistryFactory metricsRegistry = RegistryFactory.getInstance(); MetricRegistry appRegistry = metricsRegistry.getRegistry(MetricRegistry.Type.APPLICATION); cardTimer = appRegistry.simpleTimer(\"cardSimpleTimer\"); } @Override public void update(Routing.Rules rules) { rules.get(\"/\", this::getDefaultMessageHandler); } private void getDefaultMessageHandler(ServerRequest request, ServerResponse response) { cardTimer.time(() -&gt; sendResponse(response, \"Here are some cards ...\")); } private void sendResponse(ServerResponse response, String msg) { JsonObject returnObject = JSON.createObjectBuilder().add(\"message\", msg).build(); response.send(returnObject); } } Import metrics classes, particularly the SimpleTimer interface for this example. Declare a SimpleTimer member variable. Create and register the SimpleTimer metric in the MetricRegistry . Wrap the business logic in the simple timer&#8217;s time method which updates the count and the total elapsed time. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints below:\" >curl http://localhost:8080/cards curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response:\" >{ \"cardSimpleTimer\": { \"count\": 1, \"elapsedTime\": 13455720, \"maxTimeDuration\": null, \"minTimeDuration\": null } } How many times the getDefaultMessageHandler method ran. Cumulative time spent in the getDefaultMessageHandler method during its executions. Simple timers report the minimum and maximum durations recorded over the preceding complete minute. The JSON output contains null for these values if the simple timer recorded no observations during the preceding complete minute. If you retrieve the metrics again shortly after the current minute has completed, the simple timer reports useful values. <markup lang=\"json\" title=\"JSON response after the current minute completes:\" >{ \"cardSimpleTimer\": { \"count\": 1, \"elapsedTime\": 13455720, \"maxTimeDuration\": 13455720, \"minTimeDuration\": 13455720 } } If you again wait until the next complete minute without accessing the greeting card endpoint again and rerun the metrics query, the simple timer reports null values again because there was no activity in the preceding complete minute. ",
            "title": "Application-Specific Metrics Data"
        },
        {
            "location": "se/guides/metrics",
            "text": " The following example shows how to integrate the Helidon SE application with Kubernetes. <markup lang=\"bash\" title=\"Stop the application and build the docker image:\" >docker build -t helidon-metrics-se . <markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named metrics.yaml , with the following content:\" >kind: Service apiVersion: v1 metadata: name: helidon-metrics labels: app: helidon-metrics annotations: prometheus.io/scrape: true spec: type: NodePort selector: app: helidon-metrics ports: - port: 8080 targetPort: 8080 name: http --- kind: Deployment apiVersion: apps/v1 metadata: name: helidon-metrics spec: replicas: 1 selector: matchLabels: app: helidon-metrics template: metadata: labels: app: helidon-metrics version: v1 spec: containers: - name: helidon-metrics image: helidon-metrics-se imagePullPolicy: IfNotPresent ports: - containerPort: 8080 A service of type NodePort that serves the default routes on port 8080 . An annotation that will allow Prometheus to discover and scrape the application pod. A deployment with one replica of a pod. <markup lang=\"bash\" title=\"Create and deploy the application into Kubernetes:\" >kubectl apply -f ./metrics.yaml <markup lang=\"bash\" title=\"Get the service information:\" >kubectl get service/helidon-metrics <markup lang=\"bash\" >NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE helidon-metrics NodePort 10.99.159.2 &lt;none&gt; 8080:31143/TCP 8s A service of type NodePort that serves the default routes on port 31143 . <markup lang=\"bash\" title=\"Verify the metrics endpoint using port 30116 , your port will likely be different:\" >curl http://localhost:31143/metrics Leave the application running in Kubernetes since it will be used for Prometheus integration. ",
            "title": "Kubernetes Integration"
        },
        {
            "location": "se/guides/metrics",
            "text": " The metrics service that you just deployed into Kubernetes is already annotated with prometheus.io/scrape: . This will allow Prometheus to discover the service and scrape the metrics. This example shows how to install Prometheus into Kubernetes, then verify that it discovered the Helidon metrics in your application. <markup lang=\"bash\" title=\"Install Prometheus and wait until the pod is ready:\" >helm install stable/prometheus --name metrics export POD_NAME=$(kubectl get pods --namespace default -l \"app=prometheus,component=server\" -o jsonpath=\"{.items[0].metadata.name}\") kubectl get pod $POD_NAME You will see output similar to the following. Repeat the kubectl get pod command until you see 2/2 and Running . This may take up to one minute. <markup lang=\"bash\" >metrics-prometheus-server-5fc5dc86cb-79lk4 2/2 Running 0 46s <markup lang=\"bash\" title=\"Create a port-forward so you can access the server URL:\" >kubectl --namespace default port-forward $POD_NAME 7090:9090 Now open your browser and navigate to http://localhost:7090/targets . Search for helidon on the page and you will see your Helidon application as one of the Prometheus targets. ",
            "title": "Prometheus Integration"
        },
        {
            "location": "se/guides/metrics",
            "text": " You can now delete the Kubernetes resources that were just created during this example. <markup lang=\"bash\" title=\"Delete the Prometheus Kubernetes resources:\" >helm delete --purge metrics <markup lang=\"bash\" title=\"Delete the application Kubernetes resources:\" >kubectl delete -f ./metrics.yaml ",
            "title": "Final Cleanup"
        },
        {
            "location": "se/guides/metrics",
            "text": " Kubernetes Integration The following example shows how to integrate the Helidon SE application with Kubernetes. <markup lang=\"bash\" title=\"Stop the application and build the docker image:\" >docker build -t helidon-metrics-se . <markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named metrics.yaml , with the following content:\" >kind: Service apiVersion: v1 metadata: name: helidon-metrics labels: app: helidon-metrics annotations: prometheus.io/scrape: true spec: type: NodePort selector: app: helidon-metrics ports: - port: 8080 targetPort: 8080 name: http --- kind: Deployment apiVersion: apps/v1 metadata: name: helidon-metrics spec: replicas: 1 selector: matchLabels: app: helidon-metrics template: metadata: labels: app: helidon-metrics version: v1 spec: containers: - name: helidon-metrics image: helidon-metrics-se imagePullPolicy: IfNotPresent ports: - containerPort: 8080 A service of type NodePort that serves the default routes on port 8080 . An annotation that will allow Prometheus to discover and scrape the application pod. A deployment with one replica of a pod. <markup lang=\"bash\" title=\"Create and deploy the application into Kubernetes:\" >kubectl apply -f ./metrics.yaml <markup lang=\"bash\" title=\"Get the service information:\" >kubectl get service/helidon-metrics <markup lang=\"bash\" >NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE helidon-metrics NodePort 10.99.159.2 &lt;none&gt; 8080:31143/TCP 8s A service of type NodePort that serves the default routes on port 31143 . <markup lang=\"bash\" title=\"Verify the metrics endpoint using port 30116 , your port will likely be different:\" >curl http://localhost:31143/metrics Leave the application running in Kubernetes since it will be used for Prometheus integration. Prometheus Integration The metrics service that you just deployed into Kubernetes is already annotated with prometheus.io/scrape: . This will allow Prometheus to discover the service and scrape the metrics. This example shows how to install Prometheus into Kubernetes, then verify that it discovered the Helidon metrics in your application. <markup lang=\"bash\" title=\"Install Prometheus and wait until the pod is ready:\" >helm install stable/prometheus --name metrics export POD_NAME=$(kubectl get pods --namespace default -l \"app=prometheus,component=server\" -o jsonpath=\"{.items[0].metadata.name}\") kubectl get pod $POD_NAME You will see output similar to the following. Repeat the kubectl get pod command until you see 2/2 and Running . This may take up to one minute. <markup lang=\"bash\" >metrics-prometheus-server-5fc5dc86cb-79lk4 2/2 Running 0 46s <markup lang=\"bash\" title=\"Create a port-forward so you can access the server URL:\" >kubectl --namespace default port-forward $POD_NAME 7090:9090 Now open your browser and navigate to http://localhost:7090/targets . Search for helidon on the page and you will see your Helidon application as one of the Prometheus targets. Final Cleanup You can now delete the Kubernetes resources that were just created during this example. <markup lang=\"bash\" title=\"Delete the Prometheus Kubernetes resources:\" >helm delete --purge metrics <markup lang=\"bash\" title=\"Delete the application Kubernetes resources:\" >kubectl delete -f ./metrics.yaml ",
            "title": "Integration with Kubernetes and Prometheus"
        },
        {
            "location": "se/guides/metrics",
            "text": " This guide demonstrated how to use metrics in a Helidon SE application using various combinations of metrics and scopes. Access metrics for all three scopes: base, vendor, and application Configure metrics that are updated by the application when an application REST endpoint is invoked Configure a Gauge metric Integrate Helidon metrics with Kubernetes and Prometheus Refer to the following references for additional information: MicroProfile Metrics specification MicroProfile Metrics Javadoc Helidon Javadoc ",
            "title": "Summary"
        },
        {
            "location": "se/guides/metrics",
            "text": " For this 30 minute tutorial, you will need the following: <div class=\"table__overflow elevation-1 flex sm7 \"> A Helidon SE Application You can use your own application or use the Helidon SE Quickstart to create a sample application. Java&#160;SE&#160;17 ( Open&#160;JDK&#160;17 ) Helidon requires Java 17+. Maven 3.6.1+ Helidon requires Maven 3.6.1+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop . Helm To manage Kubernetes applications. <markup lang=\"bash\" title=\"Verify Prerequisites\" >java -version mvn --version docker --version kubectl version --short <markup lang=\"bash\" title=\"Setting JAVA_HOME\" ># On Mac export JAVA_HOME=`/usr/libexec/java_home -v 17` # On Linux # Use the appropriate path to your JDK export JAVA_HOME=/usr/lib/jvm/jdk-17 Create a Sample Helidon SE Project Use the Helidon SE Maven archetype to create a simple project that can be used for the examples in this guide. <markup lang=\"bash\" title=\"Run the Maven archetype\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-se \\ -DarchetypeVersion=3.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-se \\ -Dpackage=io.helidon.examples.quickstart.se Using the Built-In Metrics Helidon provides three scopes of metrics: base, vendor, and application. Here are the metric endpoints: /metrics/base - Base metrics data as specified by the MicroProfile Metrics specification. /metrics/vendor - Helidon-specific metrics data. /metrics/application - Application-specific metrics data. The /metrics endpoint will return data for all scopes. The built-in metrics fall into three categories: JVM behavior (in the base registry), basic key performance indicators for request handling (in the vendor registry), and thread pool utilization (also in the vendor registry). A later section describes the key performance indicator metrics in detail. The following example demonstrates how to use the other built-in metrics. All examples are executed from the root directory of your project (helidon-quickstart-se). The generated source code is already configured for both metrics and health checks, but the following example removes health checks. <markup lang=\"xml\" title=\"Notice that the metrics dependency is already in the project&#8217;s pom.xml file:\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"java\" title=\"Replace the Main.createRouting method with the following code:\" > private static Routing createRouting(Config config) { GreetService greetService = new GreetService(config); return Routing.builder() .register(MetricsSupport.create()) .register(\"/greet\", greetService) .build(); } Register the built-in base and vendor metrics. <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-se.jar Metrics can be returned in either text format (the default), or JSON. The text format uses OpenMetrics (Prometheus) Text Format, see https://prometheus.io/docs/instrumenting/exposition_formats/#text-format-details . <markup lang=\"bash\" title=\"Verify the metrics endpoint in a new terminal window:\" >curl http://localhost:8080/metrics <markup lang=\"text\" title=\"Text response:\" ># TYPE base:classloader_current_loaded_class_count counter # HELP base:classloader_current_loaded_class_count Displays the number of classes that are currently loaded in the Java virtual machine. base:classloader_current_loaded_class_count 7511 # TYPE base:classloader_total_loaded_class_count counter # HELP base:classloader_total_loaded_class_count Displays the total number of classes that have been loaded since the Java virtual machine has started execution. base:classloader_total_loaded_class_count 7512 You can get the same data in JSON format. <markup lang=\"bash\" title=\"Verify the metrics endpoint with an HTTP accept header:\" >curl -H \"Accept: application/json\" http://localhost:8080/metrics <markup lang=\"json\" title=\"JSON response:\" >{ \"base\": { \"classloader.currentLoadedClass.count\": 7534, \"classloader.totalLoadedClass.count\": 7538, \"classloader.totalUnloadedClass.count\": 1, \"cpu.availableProcessors\": 4, \"cpu.systemLoadAverage\": 2.83349609375, \"gc.PS MarkSweep.count\": 2, \"gc.PS MarkSweep.time\": 77, \"gc.PS Scavenge.count\": 5, \"gc.PS Scavenge.time\": 37, \"jvm.uptime\": 727588, \"memory.committedHeap\": 284164096, \"memory.maxHeap\": 3817865216, \"memory.usedHeap\": 53283088, \"thread.count\": 44, \"thread.daemon.count\": 35, \"thread.max.count\": 44 }, \"vendor\": { \"executor-service.active-count;poolIndex=0;supplierCategory=helidon-thread-pool-2;supplierIndex=0\": 0, \"executor-service.completed-task-count;poolIndex=0;supplierCategory=helidon-thread-pool-2;supplierIndex=0\": 0, \"executor-service.largest-pool-size;poolIndex=0;supplierCategory=helidon-thread-pool-2;supplierIndex=0\": 5, \"executor-service.pool-size;poolIndex=0;supplierCategory=helidon-thread-pool-2;supplierIndex=0\": 5, \"executor-service.queue.remaining-capacity;poolIndex=0;supplierCategory=helidon-thread-pool-2;supplierIndex=0\": 10000, \"executor-service.queue.size;poolIndex=0;supplierCategory=helidon-thread-pool-2;supplierIndex=0\": 0, \"executor-service.task-count;poolIndex=0;supplierCategory=helidon-thread-pool-2;supplierIndex=0\": 0, \"requests.count\": 6, \"requests.meter\": { \"count\": 6, \"meanRate\": 0.008275992296704147, \"oneMinRate\": 0.01576418632772332, \"fiveMinRate\": 0.006695060022357365, \"fifteenMinRate\": 0.0036382699664488415 } } } You can get a single metric by specifying the name in the URL path. <markup lang=\"bash\" title=\"Get the Helidon requests.meter metric:\" >curl -H \"Accept: application/json\" http://localhost:8080/metrics/vendor/requests.meter <markup lang=\"json\" title=\"JSON response:\" >{ \"requests.meter\": { \"count\": 6, \"meanRate\": 0.008275992296704147, \"oneMinRate\": 0.01576418632772332, \"fiveMinRate\": 0.006695060022357365, \"fifteenMinRate\": 0.0036382699664488415 } } You cannot get the individual fields of a metric. For example, you cannot target http://localhost:8080/metrics/vendor/requests.meter.count . The base metrics illustrated above provide some insight into the behavior of the JVM in which the server runs. The vendor metrics shown above appear in two groups: Helidon thread pools Helidon uses these thread pools for its own internal work, and your application can also use Helidon-managed thread pools if it needs to do work asynchronously. (See this example .) The metrics in this group show information about the thread pools which can help you assess how efficiently they are utilized. Helidon uses tags to distinguish the metrics which describe different thread pools. In some cases the specific metrics exposed depend on the particular type of thread pool. basic key performance indicators These metrics give an idea of the request traffic the server is handling. See the later section for more information on the basic and extended key performance indicator metrics. Controlling Metrics Behavior By adding a metrics section to your application configuration you can control how the Helidon metrics subsystem behaves in any of several ways. Disable metrics subsystem entirely . Identify groups of metrics to control: registered by a particular component , and by metric registry (application, vendor, and base) and within a registry by metric names which match patterns you provide. Select whether to collect extended key performance indicator metrics . Your Helidon SE application can also control metrics processing programmatically as described in the following sections. Disabling Metrics Subsystem Entirely By default, if your application depends on the helidon-metrics Maven module then full-featured metrics are enabled. You can disable the metrics subsystem entirely using configuration: <markup lang=\"properties\" title=\"Configuration properties file disabling metrics\" >metrics.enabled=false A Helidon SE application can disable metrics processing programmatically. <markup lang=\"java\" title=\"Disable all metrics behavior\" >import io.helidon.metrics.api.MetricsSettings; import io.helidon.metrics.serviceapi.MetricsSupport; import io.helidon.metrics.api.RegistryFactory; MetricsSettings metricsSettings = MetricsSettings.builder() .enabled(false) .build(); MetricsSupport metricsSupport = MetricsSupport.create(metricsSettings); RegistryFactory registryFactory = RegistryFactory.getInstance(metricsSettings); Create a MetricsSettings instance (via its Builder ) with the metrics subsystem disabled. Get a MetricsSupport service (usable in setting routing rules) that responds to the /metrics endpoint with 404 and an explanatory message. Get a RegistryFactory instance that provides MetricRegistry instances which register no-op metric objects (counters, timers, etc.). These builders and interfaces also have methods which accept Config objects representing the metrics node from the application configuration. With metrics processing disabled, Helidon never updates any metrics and the /metrics endpoints respond with 404 plus a message that the metrics subsystem is disabled. Enabling and Disabling Metrics Usage by a Component Helidon contains several components and integrations which register and update metrics. Depending on how the component is written, you might be able to disable just that component&#8217;s use of metrics: <markup lang=\"properties\" title=\"Configuration properties file disabling a component&#8217;s use of metrics\" >some-component.metrics.enabled=false Check the documentation for a specific component to find out whether that component uses metrics and whether it allows you to disable that use. Your Helidon SE application can disable a metrics-capable component&#8217;s use of metrics programmatically. <markup lang=\"java\" title=\"Disable metrics use in a metrics-capable component\" >import io.helidon.metrics.api.ComponentMetricsSettings; ComponentMetricsSettings.Builder componentMetricsSettingsBuilder = ComponentMetricsSettings.builder() .enabled(false); SomeService someService = SomeService.builder() .componentMetricsSettings(componentMetricsSettingsBuilder) .build(); Create a ComponentMetricsSettings instance (via its Builder ) indicating that metrics usage should be disabled. Create an instance of the service with its metrics usage disabled. If you disable a component&#8217;s use of metrics, Helidon does not register the component&#8217;s metrics in the visible metrics registries nor do those metrics ever update their values. The response from the /metrics endpoint excludes that component&#8217;s metrics. Note that if you disable metrics processing entirely, no component updates its metrics regardless of any component-level metrics settings. Controlling Metrics By Registry Type and Metric Name You can control the collection and reporting of metrics by registry type and metric name within registry type. Disabling All Metrics of a Given Registry Type To disable all metrics in a given registry type (application, vendor, or base), add one or more groups to the configuration: <markup lang=\"properties\" title=\"Disabling base and vendor metrics (properties format)\" >metrics.registries.0.type = base metrics.registries.0.enabled = false metrics.registries.1.type = vendor metrics.registries.1.enabled = false <markup lang=\"yaml\" title=\"Disabling base and vendor metrics (YAML format)\" >metrics: registries: - type: base enabled: false - type: vendor enables: false Controlling Metrics by Metric Name You can be even more selective. Within a registry type you can configure up to two regular expression patterns: one matching metric names to exclude , and one matching metric names to include . Helidon updates and reports a metric only if two conditions hold: the metric name does not match the exclude regex pattern (if you define one), and either there is no include regex pattern, or the metric name matches the include pattern. Caution Make sure any include regex pattern you specify matches all the metric names you want to capture. Suppose your application creates and updates a group of metrics with names such as myapp.xxx.queries , myapp.xxx.creates , myapp.xxx.updates , and myapp.xxx.deletes where xxx can be either supplier or customer . The following example gathers all metrics except those from your application regarding suppliers: <markup lang=\"properties\" title=\"Disabling metrics by name (properties format)\" >metrics.registries.0.type = application metrics.registries.0.filter.exclude = myapp\\.supplier\\..* The following settings select the particular subset of the metrics created in your application code representing updates of customers and suppliers: <markup lang=\"properties\" title=\"Enabling metrics by name (properties format)\" >metrics.registries.0.type = application metrics.registries.0.filter.include = myapp\\..*\\.updates If you use the YAML configuration format, enclose the regex patterns in single-quote marks: <markup lang=\"yaml\" title=\"Enabling metrics by name (YAML format)\" >metrics: registries: - type: application filter: include: 'myapp\\..*\\.updates' The next example selects only your application&#8217;s metrics while excluding those which refer to deletions: <markup lang=\"properties\" title=\"Combining include and exclude \" >metrics.registries.0.type = application metrics.registries.0.filter.include = myapp\\..* metrics.registries.0.filter.exclude = myapp\\..*/deletes Helidon would not update or report the metric myapp.supplier.queries , for example. To include metrics from your application for both updates and queries (but not for other operations), you could change the settings in the previous example to this: <markup >metrics.registries.0.type = application metrics.registries.0.filter.include = myapp\\..*\\.updates|myapp\\..*\\.queries metrics.registries.0.filter.exclude = myapp\\..*/deletes Your Helidon SE application can control the collection and reporting of metrics programmatically as well by preparing these settings objects: RegistryFilterSettings RegistrySettings MetricsSettings and using the resulting MetricsSettings to retrieve a suitable RegistryFactory . <markup lang=\"java\" title=\"Control metrics by registry type and name\" >import io.helidon.metrics.api.RegistryFilterSettings; import org.eclipse.microprofile.metrics.MetricRegistry; ... RegistryFilterSettings appFilterSettings = RegistryFilterSettings.builder() .include(\"myapp\\..*\\.updates\") .build(); RegistrySettings registrySettings = RegistrySettings.builder() .filterSettings(appFilterSettings) .build(); MetricsSettings metricsSettings = MetricsSettings.builder() .registrySettings(MetricRegistry.Type.APPLICATION, appFilterSettings) .build(); RegistryFactory rf = RegistryFactory.getInstance(metricsSettings); MetricRegistry registry = rf.getRegistry(MetricRegistry.Type.APPLICATION); Create the registry filter settings to include only those metrics with names indicating updates. Create the registry settings with that filter. Create the metrics settings, associating the registry settings with the APPLICATION metric registry. Set the overall metrics settings and retrieve a registry factory suitably initialized. Obtain a reference to the APPLICATION registry which is set up to create and report on only metrics with names starting with myapp.updates. . Collecting Basic and Extended Key Performance Indicator (KPI) Metrics Any time you include the Helidon metrics module in your application, Helidon tracks two basic performance indicator metrics: a Counter of all requests received ( requests.count ), and a Meter of all requests received ( requests.meter ). Helidon SE also includes additional, extended KPI metrics which are disabled by default: current number of requests in-flight - a ConcurrentGauge ( requests.inFlight ) of requests currently being processed long-running requests - a Meter ( requests.longRunning ) measuring the rate at which Helidon processes requests which take at least a given amount of time to complete; configurable, defaults to 10000 milliseconds (10 seconds) load - a Meter ( requests.load ) measuring the rate at which requests are worked on (as opposed to received) deferred - a Meter ( requests.deferred ) measuring the rate at which a request&#8217;s processing is delayed after Helidon receives the request You can enable and control these metrics using configuration: <markup lang=\"properties\" title=\"Configuration properties file controlling extended KPI metrics\" >metrics.key-performance-indicators.extended = true metrics.key-performance-indicators.long-running.threshold-ms = 2000 Your Helidon SE application can also control the KPI settings programmatically. <markup lang=\"java\" title=\"Assign KPI metrics behavior from code\" >import io.helidon.metrics.api.KeyPerformanceIndicatorMetricsSettings; import io.helidon.metrics.api.MetricsSettings; import io.helidon.metrics.serviceapi.MetricsSupport; import io.helidon.metrics.api.RegistryFactory; ... KeyPerformanceIndicatorMetricsSettings.Builder kpiSettingsBuilder = KeyPerformanceIndicatorMetricsSettings.builder() .extended(true) .longRunningThresholdMs(2000); MetricsSettings metricsSettings = MetricsSettings.builder() .keyPerformanceIndicatorSettings(kpiSettingsBuilder) .build(); Create a KeyPerformanceIndicatorMetricsSettings instance (via its Builder ) with non-default values. Create a MetricsSettings instance reflecting the KPI settings. Metrics Metadata Each metric has associated metadata that describes: name: The name of the metric. units: The unit of the metric such as time (seconds, millisecond), size (bytes, megabytes), etc. type: The type of metric: Counter , Timer , Meter , Histogram , SimpleTimer , or Gauge . You can get the metadata for any scope, such as /metrics/base , as shown below: <markup lang=\"bash\" title=\"Get the metrics metadata using HTTP OPTIONS method:\" > curl -X OPTIONS -H \"Accept: application/json\" http://localhost:8080/metrics/base <markup lang=\"json\" title=\"JSON response (truncated):\" >{ \"classloader.currentLoadedClass.count\": { \"unit\": \"none\", \"type\": \"counter\", \"description\": \"Displays the number of classes that are currently loaded in the Java virtual machine.\", \"displayName\": \"Current Loaded Class Count\" }, \"jvm.uptime\": { \"unit\": \"milliseconds\", \"type\": \"gauge\", \"description\": \"Displays the start time of the Java virtual machine in milliseconds. This attribute displays the approximate time when the Java virtual machine started.\", \"displayName\": \"JVM Uptime\" }, \"memory.usedHeap\": { \"unit\": \"bytes\", \"type\": \"gauge\", \"description\": \"Displays the amount of used heap memory in bytes.\", \"displayName\": \"Used Heap Memory\" } } Application-Specific Metrics Data This section demonstrates how to use application-specific metrics and integrate them with Helidon. It is the application&#8217;s responsibility to create and update the metrics at runtime. The application has complete control over when and how each metric is used. For example, an application may use the same counter for multiple methods, or one counter per method. Helidon maintains an application MetricRegistry which is used to manage all of the application metrics. Helidon returns these metrics in response to a /metrics/application REST request. In all of these examples, the scope and lifetime of the metric is at the application-level. Each metric, except Gauge , is updated in response to a REST request and the contents of the metric is cumulative. Counter Metric The Counter metric is a monotonically increasing or decreasing number. The following example will demonstrate how to use a Counter to track the number of times the /cards endpoint is called. <markup lang=\"java\" title=\"Create a new class named GreetingCards with the following code:\" >package io.helidon.examples.quickstart.se; import io.helidon.metrics.RegistryFactory; import io.helidon.webserver.Routing; import io.helidon.webserver.ServerRequest; import io.helidon.webserver.ServerResponse; import io.helidon.webserver.Service; import java.util.Collections; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import org.eclipse.microprofile.metrics.Counter; import org.eclipse.microprofile.metrics.MetricRegistry; public class GreetingCards implements Service { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); private final Counter cardCounter; GreetingCards() { RegistryFactory metricsRegistry = RegistryFactory.getInstance(); MetricRegistry appRegistry = metricsRegistry.getRegistry(MetricRegistry.Type.APPLICATION); cardCounter = appRegistry.counter(\"cardCount\"); } @Override public void update(Routing.Rules rules) { rules.get(\"/\", this::getDefaultMessageHandler); } private void getDefaultMessageHandler(ServerRequest request, ServerResponse response) { cardCounter.inc(); sendResponse(response, \"Here are some cards ...\"); } private void sendResponse(ServerResponse response, String msg) { JsonObject returnObject = JSON.createObjectBuilder().add(\"message\", msg).build(); response.send(returnObject); } } Import metrics classes. Declare a Counter member variable. Create and register the Counter metric in the MetricRegistry . This Counter will exist for the lifetime of the application. Increment the count. <markup lang=\"java\" title=\"Update the Main.createRouting method as follows:\" > private static Routing createRouting(Config config) { MetricsSupport metrics = MetricsSupport.create(); GreetService greetService = new GreetService(config); HealthSupport health = HealthSupport.builder() .addLiveness(HealthChecks.healthChecks()) // Adds a convenient set of checks .build(); return Routing.builder() .register(health) // Health at \"/health\" .register(metrics) // Metrics at \"/metrics\" .register(\"/greet\", greetService) .register(\"/cards\", new GreetingCards()) .build(); } Add the GreetingCards service to the Routing.builder . Helidon will route any REST requests with the /cards root path to the GreetingCards service. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints below:\" >curl http://localhost:8080/cards curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response:\" >{ \"cardCount\": 1 } The count value is one since the method was called once. Meter Metric The Meter metric is used to measure throughput, the number of times an event occurs within a certain time period. When a Meter object is created, its internal clock starts running. That clock is used to calculate the various rates stored this metric. The Meter also includes the count field from the Counter metric. When you mark an event, the count is incremented. The following example marks an event each time the /cards endpoint is called. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.se; import io.helidon.metrics.RegistryFactory; import io.helidon.webserver.Routing; import io.helidon.webserver.ServerRequest; import io.helidon.webserver.ServerResponse; import io.helidon.webserver.Service; import java.util.Collections; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import org.eclipse.microprofile.metrics.Meter; import org.eclipse.microprofile.metrics.MetricRegistry; public class GreetingCards implements Service { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); private final Meter cardMeter; GreetingCards() { RegistryFactory metricsRegistry = RegistryFactory.getInstance(); MetricRegistry appRegistry = metricsRegistry.getRegistry(MetricRegistry.Type.APPLICATION); cardMeter = appRegistry.meter(\"cardMeter\"); } @Override public void update(Routing.Rules rules) { rules.get(\"/\", this::getDefaultMessageHandler); } private void getDefaultMessageHandler(ServerRequest request, ServerResponse response) { cardMeter.mark(); sendResponse(response, \"Here are some cards ...\"); } private void sendResponse(ServerResponse response, String msg) { JsonObject returnObject = JSON.createObjectBuilder().add(\"message\", msg).build(); response.send(returnObject); } } Import metrics classes. Declare a Meter member variable. Create and register the Meter metric in the MetricRegistry . Mark the occurrence of an event. Note: you can specify a count parameter such as mark(100) to mark multiple events. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints below:\" >curl http://localhost:8080/cards curl http://localhost:8080/cards curl http://localhost:8080/cards curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response:\" >{ \"cardMeter\": { \"count\": 3, \"meanRate\": 0.17566568722974535, \"oneMinRate\": 0.04413761384322548, \"fiveMinRate\": 0.009753212003766951, \"fifteenMinRate\": 0.0033056752265846544 } } The Meter metric has a set of fields to show various rates, along with the count. The /cards endpoint was called three times. Timer Metric (See also Simple timer metric .) The Timer metric aggregates durations, provides timing statistics, and includes throughput statistics using an internal Meter metric. The Timer measures duration in nanoseconds. In the following example, a Timer metric is used to measure the duration of a method&#8217;s execution. Whenever the REST /cards endpoint is called, the Timer will be updated with additional timing information. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.se; import io.helidon.metrics.RegistryFactory; import io.helidon.webserver.Routing; import io.helidon.webserver.ServerRequest; import io.helidon.webserver.ServerResponse; import io.helidon.webserver.Service; import java.util.Collections; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import org.eclipse.microprofile.metrics.MetricRegistry; import org.eclipse.microprofile.metrics.Timer; public class GreetingCards implements Service { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); private final Timer cardTimer; GreetingCards() { RegistryFactory metricsRegistry = RegistryFactory.getInstance(); MetricRegistry appRegistry = metricsRegistry.getRegistry(MetricRegistry.Type.APPLICATION); cardTimer = appRegistry.timer(\"cardTimer\"); } @Override public void update(Routing.Rules rules) { rules.get(\"/\", this::getDefaultMessageHandler); } private void getDefaultMessageHandler(ServerRequest request, ServerResponse response) { Timer.Context timerContext = cardTimer.time(); sendResponse(response, \"Here are some cards ...\"); response.whenSent().thenAccept(res -&gt; timerContext.stop()); } private void sendResponse(ServerResponse response, String msg) { JsonObject returnObject = JSON.createObjectBuilder().add(\"message\", msg).build(); response.send(returnObject); } } Import metrics classes. Declare a Timer member variable. Create and register the Timer metric in the MetricRegistry . Start the timer. Stop the timer. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints below:\" >curl http://localhost:8080/cards curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response:\" >{ \"cardTimer\": { \"count\": 1, \"elapsedTime\": 26683406, \"meanRate\": 0.05669258258076838, \"oneMinRate\": 0, \"fiveMinRate\": 0, \"fifteenMinRate\": 0, \"min\": 26683406, \"max\": 26683406, \"mean\": 26683406, \"stddev\": 0, \"p50\": 26683406, \"p75\": 26683406, \"p95\": 26683406, \"p98\": 26683406, \"p99\": 26683406, \"p999\": 26683406 } } The first several fields (except for elapsedTime ) are the same ones used by Meter . The elapsedTime field and the rest starting with min are the Timer fields that measure the duration of the getDefaultMessageHandler method. Some of these values will change each time you invoke the /cards endpoint. Histogram Metric The Histogram metric calculates the distribution of a set of values within ranges. This metric does not relate to time at all. The following example will record a set of random numbers in a Histogram metric when the /cards endpoint is invoked. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.se; import io.helidon.metrics.RegistryFactory; import io.helidon.webserver.Routing; import io.helidon.webserver.ServerRequest; import io.helidon.webserver.ServerResponse; import io.helidon.webserver.Service; import java.util.Collections; import java.util.Random; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import org.eclipse.microprofile.metrics.Histogram; import org.eclipse.microprofile.metrics.MetricRegistry; public class GreetingCards implements Service { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); private final Histogram cardHistogram; GreetingCards() { RegistryFactory metricsRegistry = RegistryFactory.getInstance(); MetricRegistry appRegistry = metricsRegistry.getRegistry(MetricRegistry.Type.APPLICATION); cardHistogram = appRegistry.histogram(\"cardHistogram\"); } @Override public void update(Routing.Rules rules) { rules.get(\"/\", this::getDefaultMessageHandler); } private void getDefaultMessageHandler(ServerRequest request, ServerResponse response) { Random r = new Random(); for (int i = 0; i &lt; 1000; i++) { cardHistogram.update(1 + r.nextInt(25)); } sendResponse(response, \"Here are some cards ...\"); } private void sendResponse(ServerResponse response, String msg) { JsonObject returnObject = JSON.createObjectBuilder().add(\"message\", msg).build(); response.send(returnObject); } } Import metrics classes. Declare a Histogram member variable. Create and register the Histogram metric in the MetricRegistry . Update the Histogram metric with a random number. Loop, loading the histogram with numbers. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints below:\" >curl http://localhost:8080/cards curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response:\" >{ \"cardHistogram\": { \"count\": 1000, \"min\": 1, \"max\": 25, \"mean\": 12.743999999999915, \"stddev\": 7.308793607702962, \"p50\": 13.0, \"p75\": 19.0, \"p95\": 24.0, \"p98\": 25.0, \"p99\": 25.0, \"p999\": 25.0 } } This is the histogram data. Some of these values will change each time you invoke the /cards endpoint. Gauge Metric The Gauge metric measures a discreet value at a point in time, such as a temperature. The metric is not normally tied to a REST endpoint, rather it should be registered during application startup. When the /metrics/application endpoint is invoked, Helidon will call the getValue method of each registered Gauge . The following example demonstrates how a Gauge is used to get the current temperature. <markup lang=\"java\" title=\"Add new imports to Main.java and replace the Main.createRouting method with the following code:\" >import io.helidon.metrics.RegistryFactory; import java.util.Random; import org.eclipse.microprofile.metrics.Gauge; import org.eclipse.microprofile.metrics.MetricRegistry; ... private static Routing createRouting(Config config) { MetricsSupport metrics = MetricsSupport.create(); RegistryFactory metricsRegistry = RegistryFactory.getInstance(); MetricRegistry appRegistry = metricsRegistry.getRegistry(MetricRegistry.Type.APPLICATION); appRegistry.register(\"temperature\", (Gauge&lt;Integer&gt;)() -&gt; new Random().nextInt(100)); GreetService greetService = new GreetService(config); return Routing.builder() .register(JsonSupport.create()) .register(metrics) // Metrics at \"/metrics\" .register(\"/greet\", greetService) .register(\"/cards\", new GreetingCards()) .build(); } Register the Gauge , providing a lambda function that will return a random temperature. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code to use the Counter metric which will simplify the JSON output:\" >package io.helidon.examples.quickstart.se; import io.helidon.metrics.RegistryFactory; import io.helidon.webserver.Routing; import io.helidon.webserver.ServerRequest; import io.helidon.webserver.ServerResponse; import io.helidon.webserver.Service; import java.util.Collections; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import org.eclipse.microprofile.metrics.Counter; import org.eclipse.microprofile.metrics.MetricRegistry; public class GreetingCards implements Service { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); private final Counter cardCounter; GreetingCards() { RegistryFactory metricsRegistry = RegistryFactory.getInstance(); MetricRegistry appRegistry = metricsRegistry.getRegistry(MetricRegistry.Type.APPLICATION); cardCounter = appRegistry.counter(\"cardCount\"); } @Override public void update(Routing.Rules rules) { rules.get(\"/\", this::getDefaultMessageHandler); } private void getDefaultMessageHandler(ServerRequest request, ServerResponse response) { cardCounter.inc(); sendResponse(response, \"Here are some cards ...\"); } private void sendResponse(ServerResponse response, String msg) { JsonObject returnObject = JSON.createObjectBuilder().add(\"message\", msg).build(); response.send(returnObject); } } <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints below:\" >curl http://localhost:8080/cards curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response from /metrics/application :\" >{ \"cardCount\": 1, \"temperature\": 11 } The current temperature is returned. Invoke the /metrics/application endpoint again and you should get a different value. Simple Timer Metric The SimpleTimer metric counts invocations and accumulates duration (in seconds). It also records the minimum and maximum values sampled during the previous complete minute. In the following example, a SimpleTimer metric is used to count and measure the duration of a method&#8217;s execution. Whenever the REST /cards endpoint is called, the SimpleTimer updates its count and total elapsed time. <markup lang=\"java\" title=\"Update the GreetingCards class with the following code:\" >package io.helidon.examples.quickstart.se; import io.helidon.metrics.RegistryFactory; import io.helidon.webserver.Routing; import io.helidon.webserver.ServerRequest; import io.helidon.webserver.ServerResponse; import io.helidon.webserver.Service; import java.util.Collections; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import org.eclipse.microprofile.metrics.MetricRegistry; import org.eclipse.microprofile.metrics.SimpleTimer; // &lt;!&gt; public class GreetingCards implements Service { private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); private final SimpleTimer cardTimer; GreetingCards() { RegistryFactory metricsRegistry = RegistryFactory.getInstance(); MetricRegistry appRegistry = metricsRegistry.getRegistry(MetricRegistry.Type.APPLICATION); cardTimer = appRegistry.simpleTimer(\"cardSimpleTimer\"); } @Override public void update(Routing.Rules rules) { rules.get(\"/\", this::getDefaultMessageHandler); } private void getDefaultMessageHandler(ServerRequest request, ServerResponse response) { cardTimer.time(() -&gt; sendResponse(response, \"Here are some cards ...\")); } private void sendResponse(ServerResponse response, String msg) { JsonObject returnObject = JSON.createObjectBuilder().add(\"message\", msg).build(); response.send(returnObject); } } Import metrics classes, particularly the SimpleTimer interface for this example. Declare a SimpleTimer member variable. Create and register the SimpleTimer metric in the MetricRegistry . Wrap the business logic in the simple timer&#8217;s time method which updates the count and the total elapsed time. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoints below:\" >curl http://localhost:8080/cards curl -H \"Accept: application/json\" http://localhost:8080/metrics/application <markup lang=\"json\" title=\"JSON response:\" >{ \"cardSimpleTimer\": { \"count\": 1, \"elapsedTime\": 13455720, \"maxTimeDuration\": null, \"minTimeDuration\": null } } How many times the getDefaultMessageHandler method ran. Cumulative time spent in the getDefaultMessageHandler method during its executions. Simple timers report the minimum and maximum durations recorded over the preceding complete minute. The JSON output contains null for these values if the simple timer recorded no observations during the preceding complete minute. If you retrieve the metrics again shortly after the current minute has completed, the simple timer reports useful values. <markup lang=\"json\" title=\"JSON response after the current minute completes:\" >{ \"cardSimpleTimer\": { \"count\": 1, \"elapsedTime\": 13455720, \"maxTimeDuration\": 13455720, \"minTimeDuration\": 13455720 } } If you again wait until the next complete minute without accessing the greeting card endpoint again and rerun the metrics query, the simple timer reports null values again because there was no activity in the preceding complete minute. Integration with Kubernetes and Prometheus Kubernetes Integration The following example shows how to integrate the Helidon SE application with Kubernetes. <markup lang=\"bash\" title=\"Stop the application and build the docker image:\" >docker build -t helidon-metrics-se . <markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named metrics.yaml , with the following content:\" >kind: Service apiVersion: v1 metadata: name: helidon-metrics labels: app: helidon-metrics annotations: prometheus.io/scrape: true spec: type: NodePort selector: app: helidon-metrics ports: - port: 8080 targetPort: 8080 name: http --- kind: Deployment apiVersion: apps/v1 metadata: name: helidon-metrics spec: replicas: 1 selector: matchLabels: app: helidon-metrics template: metadata: labels: app: helidon-metrics version: v1 spec: containers: - name: helidon-metrics image: helidon-metrics-se imagePullPolicy: IfNotPresent ports: - containerPort: 8080 A service of type NodePort that serves the default routes on port 8080 . An annotation that will allow Prometheus to discover and scrape the application pod. A deployment with one replica of a pod. <markup lang=\"bash\" title=\"Create and deploy the application into Kubernetes:\" >kubectl apply -f ./metrics.yaml <markup lang=\"bash\" title=\"Get the service information:\" >kubectl get service/helidon-metrics <markup lang=\"bash\" >NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE helidon-metrics NodePort 10.99.159.2 &lt;none&gt; 8080:31143/TCP 8s A service of type NodePort that serves the default routes on port 31143 . <markup lang=\"bash\" title=\"Verify the metrics endpoint using port 30116 , your port will likely be different:\" >curl http://localhost:31143/metrics Leave the application running in Kubernetes since it will be used for Prometheus integration. Prometheus Integration The metrics service that you just deployed into Kubernetes is already annotated with prometheus.io/scrape: . This will allow Prometheus to discover the service and scrape the metrics. This example shows how to install Prometheus into Kubernetes, then verify that it discovered the Helidon metrics in your application. <markup lang=\"bash\" title=\"Install Prometheus and wait until the pod is ready:\" >helm install stable/prometheus --name metrics export POD_NAME=$(kubectl get pods --namespace default -l \"app=prometheus,component=server\" -o jsonpath=\"{.items[0].metadata.name}\") kubectl get pod $POD_NAME You will see output similar to the following. Repeat the kubectl get pod command until you see 2/2 and Running . This may take up to one minute. <markup lang=\"bash\" >metrics-prometheus-server-5fc5dc86cb-79lk4 2/2 Running 0 46s <markup lang=\"bash\" title=\"Create a port-forward so you can access the server URL:\" >kubectl --namespace default port-forward $POD_NAME 7090:9090 Now open your browser and navigate to http://localhost:7090/targets . Search for helidon on the page and you will see your Helidon application as one of the Prometheus targets. Final Cleanup You can now delete the Kubernetes resources that were just created during this example. <markup lang=\"bash\" title=\"Delete the Prometheus Kubernetes resources:\" >helm delete --purge metrics <markup lang=\"bash\" title=\"Delete the application Kubernetes resources:\" >kubectl delete -f ./metrics.yaml Summary This guide demonstrated how to use metrics in a Helidon SE application using various combinations of metrics and scopes. Access metrics for all three scopes: base, vendor, and application Configure metrics that are updated by the application when an application REST endpoint is invoked Configure a Gauge metric Integrate Helidon metrics with Kubernetes and Prometheus Refer to the following references for additional information: MicroProfile Metrics specification MicroProfile Metrics Javadoc Helidon Javadoc ",
            "title": "What You Need"
        },
        {
            "location": "se/guides/migration",
            "text": " In Helidon 2 we have made some changes to APIs and runtime behavior. This guide will help you migrate a Helidon SE 1.x application to 2.x. ",
            "title": "preambule"
        },
        {
            "location": "se/guides/migration",
            "text": " Java 11 is no longer supported in Helidon 3. Java 17 or newer is required. ",
            "title": "Java 11 Runtime"
        },
        {
            "location": "se/guides/migration",
            "text": " We have upgraded to OpenTracing version 0.33.0 that is not backward compatible. OpenTracing introduced the following breaking changes: Removed Replacement ScopeManager.active() Tracer.activeSpan() ScopeManager.activate(Span, boolean) ScopeManager.activate(Span) - second parameter is now always false SpanBuilder.startActive() Tracer.activateSpan(Span) TextMapExtractAdapter and TextMapInjectAdapter TextMapAdapter Module name changed opentracing.api io.opentracing.api (same for noop and util ) If you use the TracerBuilder abstraction in Helidon and have no custom Spans, there is no change required ",
            "title": "Tracing"
        },
        {
            "location": "se/guides/migration",
            "text": " When the OIDC provider is configured to use cookie (default configuration) to carry authentication information, the cookie Same-Site is now set to Lax (used to be Strict ). This is to prevent infinite redirects, as browsers would refuse to set the cookie on redirected requests (due to this setting). Only in the case of the frontend host and identity host match, we leave Strict as the default ",
            "title": "Security: OIDC"
        },
        {
            "location": "se/guides/migration",
            "text": " Some methods that act as getters of type T have been modified to return Optional&lt;T&gt; . You will need to change your code to handle the Optional return type. For example ServerRequest.spanContext() in 1.x had a return type of SpanContext . In 2.x it has a return type of Optional&lt;SpanContext&gt; . So if you had code like: <markup lang=\"java\" title=\"Helidon 1.x Code\" >Span myNewSpan = GlobalTracer.get() .buildSpan(“my-operation”) .asChildOf(serverRequest.spanContext()) .start(); you will need to change it to something like: <markup lang=\"java\" title=\"Helidon 2.x Code\" >Tracer.SpanBuilder spanBuilder = serverRequest.tracer() .buildSpan(\"my-operation\"); serverRequest.spanContext().ifPresent(spanBuilder::asChildOf); Span myNewSpan = spanBuilder.start(); Note the use of ifPresent() on the returned Optional&lt;SpanContext&gt; . ",
            "title": "Getters"
        },
        {
            "location": "se/guides/migration",
            "text": " File watching is now done through a ChangeWatcher - use of PollingStrategies.watch() needs to be refactored to FileSystemWatcher.create() and the method to configure it on config source builder has changed to changeWatcher(ChangeWatcher) . Methods on ConfigSources now return specific builders (they used to return AbstractParsableConfigSource.Builder with a complex type declaration). If you store such a builder in a variable, either change it to the correct type, or use var Some APIs were cleaned up to be aligned with the development guidelines of Helidon. When using Git config source, or etcd config source, the factory methods moved to the config source itself, and the builder now accepts all configuration options through methods The API of config source builders has been cleaned, so now only methods that are relevant to a specific config source type can be invoked on such a builder. Previously you could configure a polling strategy on a source that did not support polling There is a small change in behavior of Helidon Config vs. MicroProfile Config: The MP TCK require that system properties are fully mutable (e.g. as soon as the property is changed, it must be used), so MP Config methods work in this manner (with a certain performance overhead). Helidon Config treats System properties as a mutable config source, with a (optional) time based polling strategy. So the change is reflected as well, though not immediately (this is only relevant if you use change notifications). CompositeConfigSource has been removed from Config . If you need to configure MerginStrategy , you can do it now on Config Builder Example of advanced configuration of config: <markup lang=\"java\" >Config.builder() // system properties with a polling strategy of 10 seconds .addSource(ConfigSources.systemProperties() .pollingStrategy(PollingStrategies.regular(Duration.ofSeconds(10)))) // environment variables .addSource(ConfigSources.environmentVariables()) // optional file config source with change watcher .addSource(ConfigSources.file(Paths.get(\"/conf/app.yaml\")) .optional() .changeWatcher(FileSystemWatcher.create())) // classpath config source .addSource(ConfigSources.classpath(\"application.yaml\")) // map config source (also supports polling strategy) .addSource(ConfigSources.create(Map.of(\"key\", \"value\"))) .build(); ",
            "title": "Configuration"
        },
        {
            "location": "se/guides/migration",
            "text": " The configuration approach to Resource class was using prefixes which was not aligned with our approach to configuration. All usages were refactored as follows: The Resource class expects a config node resource that will be used to read it The feature set remains unchanged - we support path, classpath, url, content as plain text, and content as base64 Classes using resources are changed as well, such as KeyConfig - see details below ",
            "title": "Resource Class When Loaded from Config"
        },
        {
            "location": "se/guides/migration",
            "text": " In Helidon 1.x support for JSON and other media types was configured when constructing webserver.Routing using the register method. In Helidon 2 Media Support has been refactored so that it can be shared between the Helidon WebServer and WebClient . You now specify media support as part of the WebServer build: <markup lang=\"java\" >WebServer.builder() .addMediaSupport(JsonpSupport.create()) //registers reader and writer for Json-P .build() This replaces Routing.builder().register(JsonSupport.create())&#8230;&#8203; The new JSON MediaSupport classes are: io.helidon.media.jsonp.JsonpSupport in module io.helidon.media:helidon-media-jsonp io.helidon.media.jsonb.JsonbSupport in module io.helidon.media:helidon-media-jsonb io.helidon.media.jackson.JacksonSupport in module io.helidon.media:helidon-media-jackson ",
            "title": "Media Support"
        },
        {
            "location": "se/guides/migration",
            "text": " Removed Replacement io.helidon.common.reactive.ReactiveStreamsAdapter org.reactivestreams.FlowAdapters ",
            "title": "Reactive"
        },
        {
            "location": "se/guides/migration",
            "text": " Configuration has been updated to use the new Resource approach: oidc-metadata.resource is the new key for loading oidc-metadata from local resource sign-jwk.resource is the new key for loading signing JWK resource ",
            "title": "Security: OidcConfig"
        },
        {
            "location": "se/guides/migration",
            "text": " Configuration has been updated to use the new Resource approach: jwk.resource is the new key for loading JWK for verifying signatures jwt.resource is also used for outbound as key for loading JWK for signing tokens ",
            "title": "Security: JwtProvider and JwtAuthProvider"
        },
        {
            "location": "se/guides/migration",
            "text": " The configuration has been updated to have a nicer tree structure: Example of a public key from keystore: <markup lang=\"yaml\" >keystore: cert.alias: \"service_cert\" resource.path: \"/conf/keystore.p12\" type: \"PKCS12\" passphrase: \"password\" Example of a private key from keystore: <markup lang=\"yaml\" >keystore: key: alias: \"myPrivateKey\" passphrase: \"password\" resource.resource-path: \"keystore/keystore.p12\" passphrase: \"password\" Example of a pem resource with private key and certificate chain: <markup lang=\"yaml\" >pem: key: passphrase: \"password\" resource.resource-path: \"keystore/id_rsa.p8\" cert-chain: resource.resource-path: \"keystore/public_key_cert.pem\" ",
            "title": "PKI Key Configuration"
        },
        {
            "location": "se/guides/migration",
            "text": " Configuration has been updated to use the new Resource approach: tls-cert.resource is the new key for certificate tls-key.resource is the new key for private key tl-ca-cert is the the new key for certificate ",
            "title": "GrpcTlsDescriptor"
        },
        {
            "location": "se/guides/migration",
            "text": " There is a new class io.helidon.webserver.WebServerTls that can be used to configure TLS for a WebServer socket. Class io.helidon.webserver.SSLContextBuilder has been deprecated and will be removed. The class uses a Builder pattern: <markup lang=\"java\" >WebServerTls.builder() .privateKey(KeyConfig.keystoreBuilder() .keystore(Resource.create(\"certificate.p12\")) .keystorePassphrase(\"helidon\") The builder or built instance can be registered with a socket configuration builder including the WebServer.Builder itself: <markup lang=\"java\" >WebServer.builder(routing()) .tls(webServerTls) .build(); ",
            "title": "SSL/TLS"
        },
        {
            "location": "se/guides/migration",
            "text": " Additional socket configuration has changed both in config and in API. The configuration now accepts following structure: <markup lang=\"yaml\" >server: port: 8000 sockets: - name: \"admin\" port: 8001 - name: \"static\" port: 8002 enabled: false Socket name is now a value of a property, allowing more freedom in naming. The default socket name is implicit (and set to @default ). We have added the enabled flag to support disabling sockets through configuration. To add socket using a builder, you can use: <markup lang=\"java\" >WebServer.builder() .addSocket(SocketConfigurationBuilder.builder() .port(8001) .name(\"admin\"))); There is also a specialized method to add a socket and routing together, to remove mapping through a name. ",
            "title": "Additional Sockets"
        },
        {
            "location": "se/guides/migration",
            "text": " io.helidon.webserver.ServerConfiguration.Builder is no longer used to configure WebServer . Most methods from this class have been moved to WebServer.Builder or deprecated. Example of a simple WebServer setup: <markup lang=\"java\" >WebServer.builder() .port(8001) .host(\"localhost\") .routing(createRouting()) .build(); ",
            "title": "Deprecation of ServerConfiguration"
        },
        {
            "location": "se/guides/migration",
            "text": " io.helidon.webserver.WebServer.Builder - all methods that accept ServerConfiguration or its builder are deprecated, please use methods on WebServer.Builder instead io.helidon.webserver.WebServer.Builder - all methods for socket configuration that accept a name and socket are deprecated, socket name is now part of socket configuration itself io.helidon.webserver.ResponseHeaders.whenSend() - please use whenSent() io.helidon.webserver.Routing.createServer(ServerConfiguration) - please use WebServer.builder() io.helidon.webserver.Routing.createServer() - please use WebServer.builder() io.helidon.webserver.SocketConfiguration.DEFAULT - use a builder to create a named configuration io.helidon.webserver.SocketConfiguration.Builder.ssl(SSLContext) - use `WebServerTls instead io.helidon.webserver.SocketConfiguration.Builder.enabledSSlProtocols(String&#8230;&#8203;) - use `WebServerTls instead ",
            "title": "Other Significant WebServer Deprecations"
        },
        {
            "location": "se/guides/migration",
            "text": " SSL/TLS There is a new class io.helidon.webserver.WebServerTls that can be used to configure TLS for a WebServer socket. Class io.helidon.webserver.SSLContextBuilder has been deprecated and will be removed. The class uses a Builder pattern: <markup lang=\"java\" >WebServerTls.builder() .privateKey(KeyConfig.keystoreBuilder() .keystore(Resource.create(\"certificate.p12\")) .keystorePassphrase(\"helidon\") The builder or built instance can be registered with a socket configuration builder including the WebServer.Builder itself: <markup lang=\"java\" >WebServer.builder(routing()) .tls(webServerTls) .build(); Additional Sockets Additional socket configuration has changed both in config and in API. The configuration now accepts following structure: <markup lang=\"yaml\" >server: port: 8000 sockets: - name: \"admin\" port: 8001 - name: \"static\" port: 8002 enabled: false Socket name is now a value of a property, allowing more freedom in naming. The default socket name is implicit (and set to @default ). We have added the enabled flag to support disabling sockets through configuration. To add socket using a builder, you can use: <markup lang=\"java\" >WebServer.builder() .addSocket(SocketConfigurationBuilder.builder() .port(8001) .name(\"admin\"))); There is also a specialized method to add a socket and routing together, to remove mapping through a name. Deprecation of ServerConfiguration io.helidon.webserver.ServerConfiguration.Builder is no longer used to configure WebServer . Most methods from this class have been moved to WebServer.Builder or deprecated. Example of a simple WebServer setup: <markup lang=\"java\" >WebServer.builder() .port(8001) .host(\"localhost\") .routing(createRouting()) .build(); Other Significant WebServer Deprecations io.helidon.webserver.WebServer.Builder - all methods that accept ServerConfiguration or its builder are deprecated, please use methods on WebServer.Builder instead io.helidon.webserver.WebServer.Builder - all methods for socket configuration that accept a name and socket are deprecated, socket name is now part of socket configuration itself io.helidon.webserver.ResponseHeaders.whenSend() - please use whenSent() io.helidon.webserver.Routing.createServer(ServerConfiguration) - please use WebServer.builder() io.helidon.webserver.Routing.createServer() - please use WebServer.builder() io.helidon.webserver.SocketConfiguration.DEFAULT - use a builder to create a named configuration io.helidon.webserver.SocketConfiguration.Builder.ssl(SSLContext) - use `WebServerTls instead io.helidon.webserver.SocketConfiguration.Builder.enabledSSlProtocols(String&#8230;&#8203;) - use `WebServerTls instead ",
            "title": "WebServer Configuration"
        },
        {
            "location": "se/guides/migration_3x",
            "text": " In Helidon 3 we have made some changes to APIs and runtime behavior. This guide will help you upgrade a Helidon SE 2.x application to 3.x. ",
            "title": "preambule"
        },
        {
            "location": "se/guides/migration_3x",
            "text": " Java 11 is no longer supported in Helidon 3. Java 17 or newer is required. Please follow the instructions in Prerequisites for proper installation. ",
            "title": "Java 17 Runtime"
        },
        {
            "location": "se/guides/migration_3x",
            "text": " Handling routes based on the protocol version is now possible by registering specific routes on routing builder. For further information check WebServer Documentation ",
            "title": "New Routing"
        },
        {
            "location": "se/guides/migration_3x",
            "text": " Helidon support of HTTP/2 is no longer experimental. HTTP/2 had to be explicitly enabled by configuration in Helidon 2.x: <markup lang=\"yaml\" title=\"Enabling Http/2 support in Helidon 2\" >server: port: 8080 host: 0.0.0.0 experimental: enable-http2: true http2-max-content-length: 16384 In Helidon 3.x, HTTP/2 is automatically enabled when an artifact with HTTP/2 support is available in the classpath. <markup lang=\"xml\" title=\"Enabling HTTP/2 support in Helidon 3 by adding dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webserver&lt;/groupId&gt; &lt;artifactId&gt;helidon-webserver-http2&lt;/artifactId&gt; &lt;/dependency&gt; By adding the Helidon WebServer dependency in Helidon 3.x, you can upgrade HTTP/1 to HTTP/2, use without prior knowledge the HTTP/2 Cleartext (H2C) client, and extend HTTP/2 with Application-Layer Protocol Negotiation (ALPN) over TLS. In Helidon 2.x, max content length was configurable with server.experimental.http2-max-content-length . In Helidon 3.x max content length can be configured with server.max-upgrade-content-length globally or per socket with the same max-upgrade-content-length key. <markup lang=\"yaml\" title=\"Max upgrade content length in Helidon 3\" >server: port: 8080 host: 0.0.0.0 max-upgrade-content-length: 16384 For more information, see WebServer Documentation ",
            "title": "HTTP/2 Support"
        },
        {
            "location": "se/guides/migration_3x",
            "text": " Helidon SE support is now based on the WebSocketRouting class which enables Helidon application to configure routing for both annotated and programmatic WebSocket endpoints. TyrusSupport is now deprecated. Websocket support in now placed in a different artifact. <markup lang=\"xml\" title=\"Helidon 2.x WebSocket support dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webserver&lt;/groupId&gt; &lt;artifactId&gt;helidon-webserver-tyrus&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"xml\" title=\"Helidon 3.x WebSocket support dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webserver&lt;/groupId&gt; &lt;artifactId&gt;helidon-webserver-websocket&lt;/artifactId&gt; &lt;/dependency&gt; In Helidon 2.x, WebSocket routing is defined by registering TyrusSupport as an additional service: <markup lang=\"java\" title=\"Helidon 2 WebSocket route registering\" >WebServer.builder(Routing.builder() .register(\"/rest\", new SomeRestService()) .register(\"/websocket\",TyrusSupport.builder() .register(ServerEndpointConfig.Builder .create(MessageBoardEndpoint.class, \"/\") .encoders(encoders) .build()) .build() )) .port(8080) .build(); Traditional REST routing service registration WebSocket setup with Tyrus service In Helidon 3, WebSocket routing is defined by adding another routing: <markup lang=\"java\" title=\"Helidon 3 WebSocket route registering\" >WebServer.builder() .routing(r -&gt; r .register(\"/rest\", new SomeRestService()) ) .addRouting(WebSocketRouting.builder() .endpoint(\"/websocket\", ServerEndpointConfig.Builder .create(MessageBoardEndpoint.class, \"/board\") .encoders(encoders) .build()) .build()) .port(8080) Traditional REST routing service registration WebSocket routing setup ",
            "title": "WebSocket"
        },
        {
            "location": "se/guides/migration_3x",
            "text": " Deprecations in the following classes: Resource - old configuration approach (since 2.0) Method Optional&lt;Resource&gt; create(Config, String) is removed. Use create(Config) instead; ThreadPoolSupplier - Named thread pools (since 2.4.2) Method ThreadPoolSupplier create(Config) is removed. Use create(Config, String) instead; Method ThreadPoolSupplier create() is removed. Use create(String) instead; Configuration changes: <markup lang=\"yaml\" ># old (deprecated approach) - kept so existing applications may work resources-prefix: test-1.resource-path: \"src/test/resources/sample.txt\" test-2.resource-resource-path: \"sample.txt\" test-3.resource-url: \"file:./src/test/resources/sample.txt\" test-4.resource-content-plain: \"content\" test-5.resource-content: \"YWJjZGVmZ8SNxZnFvsO6xa8=\" # new approach that does not use a prefix resources: test-1.resource.path: \"src/test/resources/sample.txt\" test-2.resource.resource-path: \"sample.txt\" ",
            "title": "Helidon Common"
        },
        {
            "location": "se/guides/migration_3x",
            "text": " Deprecations in the following classes: ContentReaders - Methods with alternatives (since 2.0) ContentTypeCharset - Class with alternative (since 2.0) ContentWriters - Methods with alternatives (since 2.0) MessageBodyReaderContext - Methods with alternatives (since 2.0) MessageBodyWriterContext - Methods with alternatives (since 2.0) ReadableByteChannelPublisher - Class with alternative (since 2.0) ",
            "title": "Media Common"
        },
        {
            "location": "se/guides/migration_3x",
            "text": " Deprecations in the following classes: MetricsSupport - 3 methods, replacing Config with metrics settings Method MetricsSupport create(MetricsSettings, RestServiceSettings) has new parameter; New method MetricsSupport create(MetricsSettings) ; New method MetricsSupport.Builder&lt;?&gt; builder() ; KeyPerformanceIndicatorMetricsSettings - new class in metrics API, for backward compatibility only Interface KeyPerformanceIndicatorMetricsSettings - marked for removal ; Interface KeyPerformanceIndicatorMetricsSettingsCompatibility - marked for removal ; RegistryFactory - New class in metrics API, for backward compatibility only Method RegistryFactory create() - marked for removal ; Method RegistryFactory create(Config config) - marked for removal ; Method RegistryFactory getInstance() - marked for removal ; Method RegistryFactory getInstance(Config config) - marked for removal ; ",
            "title": "Metrics"
        },
        {
            "location": "se/guides/migration_3x",
            "text": " Deprecations in the following class: DataPropagationProvider - clearData should use new method Method void clearData() - marked for removal, use void clearData(T data) instead; ",
            "title": "Common Context"
        },
        {
            "location": "se/guides/migration_3x",
            "text": " Deprecations: JavaMarshaller - removed support for JavaMarshaller New default marshaller supplier will throw an exception if the code falls to where the JavaMarshaller was returned before to inform developer of the change ",
            "title": "GRPC Core"
        },
        {
            "location": "se/guides/migration_3x",
            "text": " Deprecations in the following class: CoordinatorClient - multiple methods removed Method Single&lt;URI&gt; start(String, long) - removed; Method Single&lt;URI&gt; start(URI, String, long) - removed; Method Single&lt;Optional&lt;URI&gt;&gt; join(URI, long, Participant) - removed; Method Single&lt;Void&gt; cancel(URI) - removed; Method Single&lt;Void&gt; close(URI) - removed; Method Single&lt;Void&gt; leave(URI, Participant) - removed; Method Single&lt;LRAStatus&gt; status(URI) - removed; Headers - class removed ",
            "title": "LRA"
        },
        {
            "location": "se/guides/migration_3x",
            "text": " Deprecations in the following class: FormerHealthProbe - class marked for removal MessagingCdiExtension - Alternative methods used Method Map&lt;String, Boolean&gt; channelsLiveness() - marked for removal; Method Map&lt;String, Boolean&gt; channelsReadiness() - marked for removal; ",
            "title": "MP Messaging"
        },
        {
            "location": "se/guides/migration_3x",
            "text": " Deprecations in the following class: Jwt - Audience can be a list (since 2.4.0) Method Builder audience(String) - removed, use addAudience(String) instead; ",
            "title": "JWT"
        },
        {
            "location": "se/guides/migration_3x",
            "text": " Deprecations in the following class: MetricUtil - multiple methods removed Method public static &lt;E extends Member &amp; AnnotatedElement, A extends Annotation&gt; LookupResult&lt;A&gt; lookupAnnotation(E, Class&lt;? extends Annotation&gt;, Class&lt;?&gt;) - removed; Method &lt;A extends Annotation&gt; LookupResult&lt;A&gt; lookupAnnotation(AnnotatedType&lt;?&gt;, AnnotatedMethod&lt;?&gt;, Class&lt;A&gt;) - removed; Method &lt;E extends Member &amp; AnnotatedElement&gt; void registerMetric(MetricRegistry, E, Class&lt;?&gt;, Annotation, MatchingType) - removed; Method &lt;E extends Member &amp; AnnotatedElement&gt; void registerMetric(E, Class&lt;?&gt;, LookupResult&lt;? extends Annotation&gt;) - removed; Method &lt;E extends Member &amp; AnnotatedElement&gt; void registerMetric(E, Class&lt;?&gt;, Annotation, MatchingType) - removed; Method MetricsCdiExtension - multiple methods removed Method &lt;E extends Member &amp; AnnotatedElement&gt; void registerMetric(E, Class&lt;?&gt;, LookupResult&lt;? extends Annotation&gt;) - removed; Method &lt;E extends Member &amp; AnnotatedElement&gt; void registerMetricInternal(List&lt;RegistrationPrep&gt;, E, Class&lt;?&gt;, LookupResult&lt;? extends Annotation&gt;, Executable) - removed; Method void registerMetricsForAnnotatedSitesFromGrpcTest() - removed; Method recordMetricAnnotatedClass(@Observes @WithAnnotations({Counted.class, Metered.class, Timed.class, ConcurrentGauge.class, SimplyTimed.class, Gauge.class}) ProcessAnnotatedType&lt;?&gt;) - removed; Method &lt;T extends org.eclipse.microprofile.metrics.Metric&gt; MetricType getMetricType(T) - removed; ",
            "title": "MP Metrics"
        },
        {
            "location": "se/guides/migration_3x",
            "text": " backwardCompatibleEol - set to false ",
            "title": "HTTP Signature Security Provider"
        },
        {
            "location": "se/guides/migration_3x",
            "text": " Deprecations in the following class: HelidonRestServiceSupport - method configureEndpoint(Rules) deprecated. ",
            "title": "Service Common"
        },
        {
            "location": "se/guides/migration_3x",
            "text": " io.helidon.webserver.staticcontent.* in WebServer - moved to a separate module. Fully removed from WebServer module. ",
            "title": "WebServer"
        },
        {
            "location": "se/guides/migration_3x",
            "text": " The custom Helidon OCI clients have been deprecated. Use the OCI Java SDK instead. If you use Helidon MP you can inject OCI SDK clients by adding the dependency io.helidon.integrations.oci.sdk:helidon-integrations-oci-sdk-cdi . See Resolving compatibility issue with OCI SDK for detailed information on how to work around this issue. The MultiPart buffered readers have been deprecated. Use the MultiPart stream readers instead. Helidon Common Deprecations in the following classes: Resource - old configuration approach (since 2.0) Method Optional&lt;Resource&gt; create(Config, String) is removed. Use create(Config) instead; ThreadPoolSupplier - Named thread pools (since 2.4.2) Method ThreadPoolSupplier create(Config) is removed. Use create(Config, String) instead; Method ThreadPoolSupplier create() is removed. Use create(String) instead; Configuration changes: <markup lang=\"yaml\" ># old (deprecated approach) - kept so existing applications may work resources-prefix: test-1.resource-path: \"src/test/resources/sample.txt\" test-2.resource-resource-path: \"sample.txt\" test-3.resource-url: \"file:./src/test/resources/sample.txt\" test-4.resource-content-plain: \"content\" test-5.resource-content: \"YWJjZGVmZ8SNxZnFvsO6xa8=\" # new approach that does not use a prefix resources: test-1.resource.path: \"src/test/resources/sample.txt\" test-2.resource.resource-path: \"sample.txt\" Media Common Deprecations in the following classes: ContentReaders - Methods with alternatives (since 2.0) ContentTypeCharset - Class with alternative (since 2.0) ContentWriters - Methods with alternatives (since 2.0) MessageBodyReaderContext - Methods with alternatives (since 2.0) MessageBodyWriterContext - Methods with alternatives (since 2.0) ReadableByteChannelPublisher - Class with alternative (since 2.0) Metrics Deprecations in the following classes: MetricsSupport - 3 methods, replacing Config with metrics settings Method MetricsSupport create(MetricsSettings, RestServiceSettings) has new parameter; New method MetricsSupport create(MetricsSettings) ; New method MetricsSupport.Builder&lt;?&gt; builder() ; KeyPerformanceIndicatorMetricsSettings - new class in metrics API, for backward compatibility only Interface KeyPerformanceIndicatorMetricsSettings - marked for removal ; Interface KeyPerformanceIndicatorMetricsSettingsCompatibility - marked for removal ; RegistryFactory - New class in metrics API, for backward compatibility only Method RegistryFactory create() - marked for removal ; Method RegistryFactory create(Config config) - marked for removal ; Method RegistryFactory getInstance() - marked for removal ; Method RegistryFactory getInstance(Config config) - marked for removal ; Common Context Deprecations in the following class: DataPropagationProvider - clearData should use new method Method void clearData() - marked for removal, use void clearData(T data) instead; GRPC Core Deprecations: JavaMarshaller - removed support for JavaMarshaller New default marshaller supplier will throw an exception if the code falls to where the JavaMarshaller was returned before to inform developer of the change LRA Deprecations in the following class: CoordinatorClient - multiple methods removed Method Single&lt;URI&gt; start(String, long) - removed; Method Single&lt;URI&gt; start(URI, String, long) - removed; Method Single&lt;Optional&lt;URI&gt;&gt; join(URI, long, Participant) - removed; Method Single&lt;Void&gt; cancel(URI) - removed; Method Single&lt;Void&gt; close(URI) - removed; Method Single&lt;Void&gt; leave(URI, Participant) - removed; Method Single&lt;LRAStatus&gt; status(URI) - removed; Headers - class removed MP Messaging Deprecations in the following class: FormerHealthProbe - class marked for removal MessagingCdiExtension - Alternative methods used Method Map&lt;String, Boolean&gt; channelsLiveness() - marked for removal; Method Map&lt;String, Boolean&gt; channelsReadiness() - marked for removal; JWT Deprecations in the following class: Jwt - Audience can be a list (since 2.4.0) Method Builder audience(String) - removed, use addAudience(String) instead; MP Metrics Deprecations in the following class: MetricUtil - multiple methods removed Method public static &lt;E extends Member &amp; AnnotatedElement, A extends Annotation&gt; LookupResult&lt;A&gt; lookupAnnotation(E, Class&lt;? extends Annotation&gt;, Class&lt;?&gt;) - removed; Method &lt;A extends Annotation&gt; LookupResult&lt;A&gt; lookupAnnotation(AnnotatedType&lt;?&gt;, AnnotatedMethod&lt;?&gt;, Class&lt;A&gt;) - removed; Method &lt;E extends Member &amp; AnnotatedElement&gt; void registerMetric(MetricRegistry, E, Class&lt;?&gt;, Annotation, MatchingType) - removed; Method &lt;E extends Member &amp; AnnotatedElement&gt; void registerMetric(E, Class&lt;?&gt;, LookupResult&lt;? extends Annotation&gt;) - removed; Method &lt;E extends Member &amp; AnnotatedElement&gt; void registerMetric(E, Class&lt;?&gt;, Annotation, MatchingType) - removed; Method MetricsCdiExtension - multiple methods removed Method &lt;E extends Member &amp; AnnotatedElement&gt; void registerMetric(E, Class&lt;?&gt;, LookupResult&lt;? extends Annotation&gt;) - removed; Method &lt;E extends Member &amp; AnnotatedElement&gt; void registerMetricInternal(List&lt;RegistrationPrep&gt;, E, Class&lt;?&gt;, LookupResult&lt;? extends Annotation&gt;, Executable) - removed; Method void registerMetricsForAnnotatedSitesFromGrpcTest() - removed; Method recordMetricAnnotatedClass(@Observes @WithAnnotations({Counted.class, Metered.class, Timed.class, ConcurrentGauge.class, SimplyTimed.class, Gauge.class}) ProcessAnnotatedType&lt;?&gt;) - removed; Method &lt;T extends org.eclipse.microprofile.metrics.Metric&gt; MetricType getMetricType(T) - removed; HTTP Signature Security Provider backwardCompatibleEol - set to false Service Common Deprecations in the following class: HelidonRestServiceSupport - method configureEndpoint(Rules) deprecated. WebServer io.helidon.webserver.staticcontent.* in WebServer - moved to a separate module. Fully removed from WebServer module. ",
            "title": "Deprecations and API Changes"
        },
        {
            "location": "se/guides/overview",
            "text": " Quickstart SE Create your first Helidon SE application in under 5 minutes. ",
            "title": "Getting Started"
        },
        {
            "location": "se/guides/overview",
            "text": " Config Guide Learn how to configure a Helidon SE application. Health Check Guide Learn how to use Helidon SE built-in and custom health checks. Metrics Guide Learn how to use Helidon SE built-in and application metrics. Tracing Guide Learn how to trace a Helidon SE application. OIDC Guide Learn how to set up an OIDC Helidon SE application Helidon SE Upgrade Guide Learn how to Upgrade your Helidon SE application Helidon SE WebClient Guide Learn how to use the Helidon SE Reactive WebClient Helidon SE DB Client Guide Learn how to use the Helidon SE Reactive DB Client Helidon SE Performance Tuning Guide Learn how to tune your Helidon SE application ",
            "title": "Helidon SE Guides"
        },
        {
            "location": "se/guides/overview",
            "text": " Maven Guide Using Helidon in your Maven project. Gradle Guide Using Helidon in your Gradle project. GraalVM Native Images Learn how to build a GraalVM native image for your Helidon application both on your desktop and as part of a Docker image. Custom Runtime Images using jlink Learn how to build a custom runtime Java image for your Helidon application both on your desktop and as part of a Docker image. Building Container Images with Jib Learn how to use Jib to create a container image without Docker. Deploying to OKE Learn how to deploy your application to Oracle Cloud Infrastructure Container Engine for Kubernetes (OKE). ",
            "title": "Build and Deploy"
        },
        {
            "location": "se/guides/performance-tuning",
            "text": " In this guide you fill find basic advice for performance tuning of your Helidon application. Most of them target Netty tuning, as Helidon is based on it. You should also consider configuring/tuning Java heap size as per any Java application. ",
            "title": "preambule"
        },
        {
            "location": "se/guides/performance-tuning",
            "text": " The Netty worker thread-pool is what handles your incoming requests. It defaults to 2*NCPU. To set it to something else you can set worker-count in resources/application.yaml : <markup lang=\"yaml\" >server: port: 8080 host: 0.0.0.0 worker-count: 2 ",
            "title": "Configure Netty worker thread pool size"
        },
        {
            "location": "se/guides/performance-tuning",
            "text": " In some situations Netty can aggressively allocate memory per request. This has been addressed in recent versions of Helidon and Netty, but if you are running an earlier version set this system property when you start your Helidon application: <markup lang=\"bash\" >-Dio.netty.allocator.maxOrder=6 You can try smaller numbers. ",
            "title": "Configure Netty&#8217;s maxOrder (Helidon 2.4.1 or earlier)"
        },
        {
            "location": "se/guides/quickstart",
            "text": " This guide describes a basic example of an Helidon SE application using Docker and Kubernetes. ",
            "title": "preambule"
        },
        {
            "location": "se/guides/quickstart",
            "text": " For this 5 minute tutorial, you will need the following: <div class=\"table__overflow elevation-1 flex sm7 \"> A Helidon SE Application You can use your own application or use the Helidon SE Quickstart to create a sample application. Java&#160;SE&#160;17 ( Open&#160;JDK&#160;17 ) Helidon requires Java 17+. Maven 3.6.1+ Helidon requires Maven 3.6.1+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop . <markup lang=\"bash\" title=\"Verify Prerequisites\" >java -version mvn --version docker --version kubectl version --short <markup lang=\"bash\" title=\"Setting JAVA_HOME\" ># On Mac export JAVA_HOME=`/usr/libexec/java_home -v 17` # On Linux # Use the appropriate path to your JDK export JAVA_HOME=/usr/lib/jvm/jdk-17 ",
            "title": "What You Need"
        },
        {
            "location": "se/guides/quickstart",
            "text": " Generate the project sources using one (or both) of the Helidon Maven archetypes. The result is a simple project that shows the basics of configuring the WebServer and implementing basic routing rules. <markup lang=\"bash\" title=\"Run the Maven archetype\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-se \\ -DarchetypeVersion=3.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-se \\ -Dpackage=io.helidon.examples.quickstart.se The archetype generates a Maven project in your current directory (for example, helidon-quickstart-se ). Change into this directory. <markup lang=\"bash\" >cd helidon-quickstart-se If you want to use the generated project as a starter for your own application, then you can replace groupId, artifactId and package with values appropriate for your application. <markup lang=\"bash\" title=\"Build the Application\" >mvn package The project builds an application jar for the example and saves all runtime dependencies in the target/libs directory. This means you can easily start the application by running the application jar file: <markup lang=\"bash\" title=\"Run the application\" >java -jar target/helidon-quickstart-se.jar The example is a very simple \"Hello World\" greeting service. It supports GET requests for generating a greeting message, and a PUT request for changing the greeting itself. The response is encoded using JSON. For example: <markup lang=\"bash\" title=\"Try the Application\" >curl -X GET http://localhost:8080/greet {\"message\":\"Hello World!\"} curl -X GET http://localhost:8080/greet/Joe {\"message\":\"Hello Joe!\"} curl -X PUT -H \"Content-Type: application/json\" -d '{\"greeting\" : \"Hola\"}' http://localhost:8080/greet/greeting curl -X GET http://localhost:8080/greet/Jose {\"message\":\"Hola Jose!\"} ",
            "title": "Generate The Project"
        },
        {
            "location": "se/guides/quickstart",
            "text": " Helidon provides built-in support for health and metrics endpoints. <markup lang=\"bash\" title=\"Health\" >curl -s -X GET http://localhost:8080/health <markup lang=\"bash\" title=\"Metrics in Prometheus Format\" >curl -s -X GET http://localhost:8080/metrics <markup lang=\"bash\" title=\"Metrics in JSON Format\" >curl -H 'Accept: application/json' -X GET http://localhost:8080/metrics ",
            "title": "Health and Metrics"
        },
        {
            "location": "se/guides/quickstart",
            "text": " The project also contains a Dockerfile so that you can easily build and run a Docker image. To build the Docker image, you need to have Docker installed and running on your system. <markup lang=\"bash\" title=\"Docker build\" >docker build -t helidon-quickstart-se . <markup lang=\"bash\" title=\"Run Docker Image\" >docker run --rm -p 8080:8080 helidon-quickstart-se:latest Then you can try the application as you did before. ",
            "title": "Build a Docker Image"
        },
        {
            "location": "se/guides/quickstart",
            "text": " If you don&#8217;t have access to a Kubernetes cluster, you can install one on your desktop . Then deploy the example: <markup lang=\"bash\" title=\"Verify connectivity to cluster\" >kubectl cluster-info kubectl get nodes <markup lang=\"bash\" title=\"Deploy the application to Kubernetes\" >kubectl create -f app.yaml kubectl get pods # Wait for quickstart pod to be RUNNING The step above created a service that is exposed into any node port. Lookup the service to find the port. <markup lang=\"bash\" title=\"Lookup the service\" >kubectl get service helidon-quickstart-se Note the PORTs. You can now exercise the application as you did before but use the second port number (the NodePort) instead of 8080. For example: <markup lang=\"bash\" >curl -X GET http://localhost:31431/greet After you&#8217;re done, cleanup. <markup lang=\"bash\" title=\"Remove the application from Kubernetes\" >kubectl delete -f app.yaml ",
            "title": "Deploy the application to Kubernetes"
        },
        {
            "location": "se/guides/quickstart",
            "text": " Helidon also includes support for GraalVM Native Images and Java Custom Runtime Images. For more information see: GraalVM Native Images Custom Runtime Images using jlink ",
            "title": "Building Native and Custom Runtime Images"
        },
        {
            "location": "se/guides/quickstart",
            "text": " With the Helidon CLI you can create additional types of Helidon applications and use the \"dev loop\" to do fast, iterative development. Try it now . ",
            "title": "The Helidon CLI"
        },
        {
            "location": "se/guides/security-oidc",
            "text": " This guide describes how to setup Keycloak and Helidon to secure your application with OIDC security provider. ",
            "title": "preambule"
        },
        {
            "location": "se/guides/security-oidc",
            "text": " For this 20 minute tutorial, you will need the following: <div class=\"table__overflow elevation-1 flex sm7 \"> A Helidon SE Application You can use your own application or use the Helidon SE Quickstart to create a sample application. Java&#160;SE&#160;17 ( Open&#160;JDK&#160;17 ) Helidon requires Java 17+. Maven 3.6.1+ Helidon requires Maven 3.6.1+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop . <markup lang=\"bash\" title=\"Verify Prerequisites\" >java -version mvn --version docker --version kubectl version --short <markup lang=\"bash\" title=\"Setting JAVA_HOME\" ># On Mac export JAVA_HOME=`/usr/libexec/java_home -v 17` # On Linux # Use the appropriate path to your JDK export JAVA_HOME=/usr/lib/jvm/jdk-17 In addition, you will need to install and configure the following: Introduction Keycloak Installation Setup Keycloak Setup Helidon Test Keycloak process with Postman Restrict access to a specific role ",
            "title": "What You Need"
        },
        {
            "location": "se/guides/security-oidc",
            "text": " This guide describes the steps required to protect your whole application or a specific area with Open ID Connect (OIDC) security. OIDC is a secure mechanism for an application to contact an identity service. Its built on top of OAuth 2.0 and provides full-fledged authentication and authorization protocols. ",
            "title": "Introduction"
        },
        {
            "location": "se/guides/security-oidc",
            "text": " To install Keycloak with Docker, open a terminal and make sure the port 8080 is free. <markup lang=\"bash\" title=\"Enter the following command\" >docker run -p 8080:8080 -e KEYCLOAK_USER=admin -e KEYCLOAK_PASSWORD=admin quay.io/keycloak/keycloak:11.0.2 This will start Keycloak on local port 8080. It will create the admin user with username admin and password admin Feel free to modify 11.0.2 by any keycloak version of your wish. If you are running docker behind a proxy server, make sure it is either configured into docker or disabled. Otherwise, you might face a connection timeout because docker cannot download the required data. To verify that Keycloak is running correctly, go to the admin console : http://localhost:8080/auth/admin Log in using the username and password mentioned above: admin . You should be logged in successfully, and it prompts the admin console. ",
            "title": "On Docker"
        },
        {
            "location": "se/guides/security-oidc",
            "text": " Download the last version of Keycloak from Keycloak website : https://www.keycloak.org/downloads In the table Server choose Standalone server distribution. ZIP or Tar format are available, click on either to download Keycloak. After extracting the archive file, you should have a directory named keycloak followed by the version. For example, if you chose version 11.0.2, the folder must be named keycloak-11.0.2. Open keycloak folder to make it your current directory. <markup lang=\"bash\" title=\"Run this command from command prompt to open the directory:\" >cd keycloak-11.0.2 ",
            "title": "On JDK"
        },
        {
            "location": "se/guides/security-oidc",
            "text": " On Docker To install Keycloak with Docker, open a terminal and make sure the port 8080 is free. <markup lang=\"bash\" title=\"Enter the following command\" >docker run -p 8080:8080 -e KEYCLOAK_USER=admin -e KEYCLOAK_PASSWORD=admin quay.io/keycloak/keycloak:11.0.2 This will start Keycloak on local port 8080. It will create the admin user with username admin and password admin Feel free to modify 11.0.2 by any keycloak version of your wish. If you are running docker behind a proxy server, make sure it is either configured into docker or disabled. Otherwise, you might face a connection timeout because docker cannot download the required data. To verify that Keycloak is running correctly, go to the admin console : http://localhost:8080/auth/admin Log in using the username and password mentioned above: admin . You should be logged in successfully, and it prompts the admin console. On JDK Download the last version of Keycloak from Keycloak website : https://www.keycloak.org/downloads In the table Server choose Standalone server distribution. ZIP or Tar format are available, click on either to download Keycloak. After extracting the archive file, you should have a directory named keycloak followed by the version. For example, if you chose version 11.0.2, the folder must be named keycloak-11.0.2. Open keycloak folder to make it your current directory. <markup lang=\"bash\" title=\"Run this command from command prompt to open the directory:\" >cd keycloak-11.0.2 ",
            "title": "Keycloak Installation"
        },
        {
            "location": "se/guides/security-oidc",
            "text": " You need to create an admin user because it does not come by default when installing Keycloak. To do this, open http://localhost:8080/auth in your favorite browser. A window Welcome to Keycloak should be prompted. If not, check if any error appear in the terminal. Fill the form by adding Username and Password. Click on Create to create the admin user. Above Administration Console should be printed \"User created\" in a green rectangle. To check that the admin user was created correctly, click on Administration user which should redirect you to a Login form. Enter the Username and Password created earlier to log in. After successfully logged in, the admin console is prompted. ",
            "title": "Create an Admin User"
        },
        {
            "location": "se/guides/security-oidc",
            "text": " To start keycloak and have it ready for further steps, run the following command. <markup lang=\"bash\" title=\"On Linux run:\" >bin/standalone.sh <markup lang=\"bash\" title=\"On Windows run:\" >bin/standalone.bat Keycloak runs on localhost:8080 by default. Create an Admin User You need to create an admin user because it does not come by default when installing Keycloak. To do this, open http://localhost:8080/auth in your favorite browser. A window Welcome to Keycloak should be prompted. If not, check if any error appear in the terminal. Fill the form by adding Username and Password. Click on Create to create the admin user. Above Administration Console should be printed \"User created\" in a green rectangle. To check that the admin user was created correctly, click on Administration user which should redirect you to a Login form. Enter the Username and Password created earlier to log in. After successfully logged in, the admin console is prompted. ",
            "title": "Start Keycloak"
        },
        {
            "location": "se/guides/security-oidc",
            "text": " A realm is the place where groups of applications, and their environment, can be created. It gathers : One or several applications One or several users Sessions Events Clients and their scopes By default, there is a realm called Master . It is used to manage Keycloak. It is not recommended to associate your application with this realm as it could disturb Keycloak functioning. To create a new realm to manage your application: Open Keycloak admin console http://localhost:8080/auth/admin . Hover the mouse over the dropdown in the top-left corner where it says Master , and press Add realm . Fill the form by adding the realm name, myRealm for example. Click on Create to create the new realm. To verify that your realm is created, on the top-left corner where it said Master previously should be now your realm name or myRealm is you followed the example. To switch from a realm to another, hover the realm name, and the other realm created appear in the dropdown. Click on any realm name to change the current realm. Make sure all configuration or modification are saved before changing the current realm or be subject to lose your configuration. ",
            "title": "Create a Realm"
        },
        {
            "location": "se/guides/security-oidc",
            "text": " Initially there are no users in a new realm. An unlimited number of user can be created per realm. A realm contains resources such as client which can be accessed by users. To create a new user: Open the Keycloak admin console: http://localhost:8080/auth/admin Click on Users in the left menu Press Add user Fill the form (Username is the only mandatory field) with this value Username: myUser Click Save A new user is just created but it needs a password to be able to login. To initialize it, do this: Click on Credentials at the top of the page, under Myuser . Fill Password and Password confirmation with the user password of your choice. If the Temporary field is set to ON , the user has to update password on next login. Click ON to make it OFF and prevent it. Press Set Password . A pop-up window is popping off. Click on Set Password to confirm the new password. To verify that the new user is created correctly: Open the Keycloak account console: http://localhost:8080/auth/realms/myRealm/account . Login with myUser and password chosen earlier. You should now be logged-in to the account console where users can manage their accounts. ",
            "title": "Create a User"
        },
        {
            "location": "se/guides/security-oidc",
            "text": " To create your first client: Open the Keycloak admin console: http://localhost:8080/auth/admin . Make sure the current realm is myRealm and not Master . Navigate to the left menu, into configure section, click on Clients . This window displays a table with every client from the realm. Click on Create . Fill the following: Client ID : myClientID Client Protocol : openid-connect Press Save Modify Access type : confidential Update Valid Redirect URIs : http://localhost:7987/* Click on + to add the new URI. Click on Save . A new tab named Credentials is created. Click on it to access this new tab. Select Client Authenticator : Client ID and Secret Click on generate secret to generate client secret. Keycloak is now configured and ready. Keep keycloak running on your terminal and open a new tab to setup Helidon. ",
            "title": "Create a Client"
        },
        {
            "location": "se/guides/security-oidc",
            "text": " To setup Keycloak properly, go to the admin console: http://localhost:8080/auth/admin If you are using Docker, use Username admin and password admin as it is the default admin user. Otherwise, use the username and password you used to create the admin user. Create a Realm A realm is the place where groups of applications, and their environment, can be created. It gathers : One or several applications One or several users Sessions Events Clients and their scopes By default, there is a realm called Master . It is used to manage Keycloak. It is not recommended to associate your application with this realm as it could disturb Keycloak functioning. To create a new realm to manage your application: Open Keycloak admin console http://localhost:8080/auth/admin . Hover the mouse over the dropdown in the top-left corner where it says Master , and press Add realm . Fill the form by adding the realm name, myRealm for example. Click on Create to create the new realm. To verify that your realm is created, on the top-left corner where it said Master previously should be now your realm name or myRealm is you followed the example. To switch from a realm to another, hover the realm name, and the other realm created appear in the dropdown. Click on any realm name to change the current realm. Make sure all configuration or modification are saved before changing the current realm or be subject to lose your configuration. Create a User Initially there are no users in a new realm. An unlimited number of user can be created per realm. A realm contains resources such as client which can be accessed by users. To create a new user: Open the Keycloak admin console: http://localhost:8080/auth/admin Click on Users in the left menu Press Add user Fill the form (Username is the only mandatory field) with this value Username: myUser Click Save A new user is just created but it needs a password to be able to login. To initialize it, do this: Click on Credentials at the top of the page, under Myuser . Fill Password and Password confirmation with the user password of your choice. If the Temporary field is set to ON , the user has to update password on next login. Click ON to make it OFF and prevent it. Press Set Password . A pop-up window is popping off. Click on Set Password to confirm the new password. To verify that the new user is created correctly: Open the Keycloak account console: http://localhost:8080/auth/realms/myRealm/account . Login with myUser and password chosen earlier. You should now be logged-in to the account console where users can manage their accounts. Create a Client To create your first client: Open the Keycloak admin console: http://localhost:8080/auth/admin . Make sure the current realm is myRealm and not Master . Navigate to the left menu, into configure section, click on Clients . This window displays a table with every client from the realm. Click on Create . Fill the following: Client ID : myClientID Client Protocol : openid-connect Press Save Modify Access type : confidential Update Valid Redirect URIs : http://localhost:7987/* Click on + to add the new URI. Click on Save . A new tab named Credentials is created. Click on it to access this new tab. Select Client Authenticator : Client ID and Secret Click on generate secret to generate client secret. Keycloak is now configured and ready. Keep keycloak running on your terminal and open a new tab to setup Helidon. ",
            "title": "Setup Keycloak"
        },
        {
            "location": "se/guides/security-oidc",
            "text": " Update the pom.xml file and add the following Helidon dependency to the &lt;dependencies&gt; section. <markup lang=\"xml\" title=\"Add the following dependency to pom.xml :\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-oidc&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Update Project Dependencies"
        },
        {
            "location": "se/guides/security-oidc",
            "text": " The OIDC security provider configuration can be joined to helidon configuration file. This file is located here: src/main/resources/application.yaml . It can be easily used to configure the web server without modifying application code. <markup lang=\"yaml\" title=\"Add the following line to application.yaml\" >security: providers: - abac: # Adds ABAC Provider - it does not require any configuration - oidc: client-id: \"myClientID\" client-secret: \"Client secret generated into Keycloak client credential\" identity-uri: \"http://localhost:8080/auth/realms/myRealm\" audience: \"account\" header-use: \"true\" # proxy-host should be defined if you operate behind a proxy, can be removed otherwise proxy-host: \"\" frontend-uri: \"http://localhost:7987\" server-type: \"oidc\" web-server: # protected paths on the web server paths: - path: \"/greet\" methods: [\"get\"] authenticate: true client-id must be the same as the one configure in keycloak. The client secret generate by Keycloak during Create a client section. identity-uri is used to redirect the user to keycloak. frontend-uri will direct you back to the application. paths section defines the protected application&#8217;s path. Make sure keycloak and the application are not running on the same port. The application port value can be changed into application.yaml. <markup lang=\"yaml\" title=\"Change these properties to configure the server host and port\" >server: port: 7987 host: localhost If the port 7987 is already used, check what port is free on your machine. <markup lang=\"yaml\" title=\"Replace the old port into application.yaml\" >server: port: \"{Your-new-port}\" frontend-uri: \"http://localhost:{Your-new-port}\" ",
            "title": "Add OIDC Security Properties"
        },
        {
            "location": "se/guides/security-oidc",
            "text": " Once the properties are added, the web server must be setup. The Main.createRouting method gather all configuration properties. <markup lang=\"java\" title=\"Add the following to Main.createRouting method\" >import io.helidon.security.Security; import io.helidon.security.integration.webserver.WebSecurity; import io.helidon.security.providers.oidc.OidcSupport; Security security = Security.create(config.get(\"security\")); return Routing.builder() .register(WebSecurity.create(security, config.get(\"security\"))) .register(OidcSupport.create(config)) Create the Helidon Security instance using configuration. Register Helidon WebSecurity instance using security instance and configuration. Register Helidon OidcSupport instance. That code is extracting security properties from application.yaml into two steps. First the Security instance is used to bootstrap security, so the WebSecurity instance can integrate security into Web Server. Then, OidcSupport instance registers the endpoint to which OIDC redirects browser after a successful login. Helidon sample is now setup and ready. ",
            "title": "Configure Web Server"
        },
        {
            "location": "se/guides/security-oidc",
            "text": " Use the Helidon SE Maven archetype to create a simple project. It will be used as an example to show how to setup Helidon. Replace 3.0.2 by the latest helidon version. It will download the quickstart project into the current directory. <markup lang=\"bash\" title=\"Run the Maven archetype\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-se \\ -DarchetypeVersion=3.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-se \\ -Dpackage=io.helidon.examples.quickstart.se <markup lang=\"bash\" title=\"The project will be built and run from the helidon-quickstart-se directory:\" >cd helidon-quickstart-se Update Project Dependencies Update the pom.xml file and add the following Helidon dependency to the &lt;dependencies&gt; section. <markup lang=\"xml\" title=\"Add the following dependency to pom.xml :\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-oidc&lt;/artifactId&gt; &lt;/dependency&gt; Add OIDC Security Properties The OIDC security provider configuration can be joined to helidon configuration file. This file is located here: src/main/resources/application.yaml . It can be easily used to configure the web server without modifying application code. <markup lang=\"yaml\" title=\"Add the following line to application.yaml\" >security: providers: - abac: # Adds ABAC Provider - it does not require any configuration - oidc: client-id: \"myClientID\" client-secret: \"Client secret generated into Keycloak client credential\" identity-uri: \"http://localhost:8080/auth/realms/myRealm\" audience: \"account\" header-use: \"true\" # proxy-host should be defined if you operate behind a proxy, can be removed otherwise proxy-host: \"\" frontend-uri: \"http://localhost:7987\" server-type: \"oidc\" web-server: # protected paths on the web server paths: - path: \"/greet\" methods: [\"get\"] authenticate: true client-id must be the same as the one configure in keycloak. The client secret generate by Keycloak during Create a client section. identity-uri is used to redirect the user to keycloak. frontend-uri will direct you back to the application. paths section defines the protected application&#8217;s path. Make sure keycloak and the application are not running on the same port. The application port value can be changed into application.yaml. <markup lang=\"yaml\" title=\"Change these properties to configure the server host and port\" >server: port: 7987 host: localhost If the port 7987 is already used, check what port is free on your machine. <markup lang=\"yaml\" title=\"Replace the old port into application.yaml\" >server: port: \"{Your-new-port}\" frontend-uri: \"http://localhost:{Your-new-port}\" Configure Web Server Once the properties are added, the web server must be setup. The Main.createRouting method gather all configuration properties. <markup lang=\"java\" title=\"Add the following to Main.createRouting method\" >import io.helidon.security.Security; import io.helidon.security.integration.webserver.WebSecurity; import io.helidon.security.providers.oidc.OidcSupport; Security security = Security.create(config.get(\"security\")); return Routing.builder() .register(WebSecurity.create(security, config.get(\"security\"))) .register(OidcSupport.create(config)) Create the Helidon Security instance using configuration. Register Helidon WebSecurity instance using security instance and configuration. Register Helidon OidcSupport instance. That code is extracting security properties from application.yaml into two steps. First the Security instance is used to bootstrap security, so the WebSecurity instance can integrate security into Web Server. Then, OidcSupport instance registers the endpoint to which OIDC redirects browser after a successful login. Helidon sample is now setup and ready. ",
            "title": "Setup Helidon"
        },
        {
            "location": "se/guides/security-oidc",
            "text": " The Authorization Code flow is suitable for browser-based applications. It is composed of three main steps: The browser visits the application. The user is not logged in, so it redirects the browser to Keycloak which requires username and password for authentication. Keycloak authenticates the user and returns a temporary authorization code as a query parameter in the URL. The authorization code is used to get access and refresh token from Keycloak token endpoint. For the first step, paste the following URL into your browser: http://localhost:8080/auth/realms/myRealm/protocol/openid-connect/auth?client_id=myClientID&amp;response_type=code . The first part of the url http:/../auth is the Keycloak endpoint to request an authorization code. Two query parameters are provided, the client id and the response type. Press enter and Keycloak responds with different URL containing a query parameter code . You successfully received the authorization code. In order to achieve the third step, we can use Postman to exchange the authorization code for tokens. In Postman, select the Http POST method. Keycloak endpoint to get token is the following: http://localhost:8080/auth/realms/myRealm/protocol/openid-connect/token . In the body of the request, select x-www-form-urlencoded type. Add the following data: <markup lang=\"json\" title=\"Enter the key:value\" >[{\"key\":\"grant_type\",\"value\":\"authorization_code\"}, {\"key\":\"client_id\",\"value\":\"myClientID\"}, {\"key\":\"client_secret\",\"value\":\"client secret\"}, {\"key\":\"code\",\"value\":\"authorization code\"}] Do not forget to replace the client secret by its value (generated during Create a Client), and authorization code by the code value in the query parameter. Send the request by pressing Send . Keycloak returns an access token and a refresh token. ",
            "title": "Authorization Code Flow"
        },
        {
            "location": "se/guides/security-oidc",
            "text": " The Direct Access Grants flow is used by REST clients that want to request tokens on behalf of a user. To use Postman to make this request on behalf of myuser , select the GET method and enter this URL: http://localhost:7987/greet/ . Under Authorization tab, select authorization type`OAuth 2.0`. Under it, complete the sentence Add authorization data to with Request Headers , and complete the required fields. <markup lang=\"json\" title=\"Enter the following information:\" >[{\"key\":\"Header Prefix\",\"value\":\"bearer\"}, {\"key\":\"Grant type\",\"value\":\"Password Credentials\"}, {\"key\":\"Access Token URL\",\"value\":\"http://localhost:8080/auth/realms/myRealm/protocol/openid-connect/token\"}, {\"key\":\"Client ID\",\"value\":\"myClientID\"}, {\"key\":\"Client Secret\",\"value\":\"client secret\"}, {\"key\":\"Username\",\"value\":\"myuser\"}, {\"key\":\"Password\",\"value\":\"password\"}, {\"key\":\"Scope\",\"value\":\"openid\"}, {\"key\":\"Client Authentication\",\"value\":\"Send as Basic Auth Header\"}] Again, make sure to replace client secret by the actual client secret. Click on Get New Access Token . A popup window appears with Authentication complete, click on proceed to display access, refresh and identity token. Copy and paste the access token to Access Token field and press Send . Helidon greeting application sends back Hello World ! . ",
            "title": "Resource Owner Password Credentials Grant (Direct Access Grants)"
        },
        {
            "location": "se/guides/security-oidc",
            "text": " At this stage of the application, tests cannot pass because of OIDC security. The only way to authenticate a user is through the front end of that server which can be accessed with the browser for example. In order to keep security and test the application locally, a new security provider must be setup. By adding specific configuration to the tests, it is possible to override the application configuration. The following explains how to set a basic authentication instead of oidc security provider only for the tests. Which means, at the end of this guide, the application will be secured by oidc security provider, and the tests will use basic authentication. <markup lang=\"xml\" title=\"Add the following dependency to pom.xml :\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-http-auth&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; In the test folder helidon-quickstart-se/src/test : <markup lang=\"bash\" title=\"Create a new directory and another one inside\" >mkdir resources cd resources touch application.yaml Open the application.yaml file <markup lang=\"yaml\" title=\"Copy these properties into application.yaml\" >app: greeting: \"Hello\" server: port: 7987 host: localhost security: providers: - abac: # Adds ABAC Provider - it does not require any configuration - http-basic-auth: users: - login: \"jack\" password: \"jackIsGreat\" - oidc: client-id: \"Your client ID\" client-secret: \"Your client secret\" identity-uri: \"http://localhost:8080/auth/realms/myRealm\" audience: \"account\" frontend-uri: \"http://localhost:7987\" server-type: \"oidc\" web-server: # protected paths on the web server - do not include paths served by Jersey, as those are protected directly paths: - path: \"/greet\" methods: [\"get\"] authenticate: true Replace this field by your Keycloak client ID. Replace this field by your Keycloak client Password. Add the http-basic-auth properties in the security &#8594; providers property section. This configuration will be used by the tests instead of the java/resources/application.yaml . In the MainTest.java file, tests need to be modified to check the application security when accessing /greet path with a GET method. <markup lang=\"java\" title=\"Import the following class:\" >import java.util.Base64; import io.helidon.common.http.Http; <markup lang=\"java\" title=\"Replace the first webclient call by this one into testHelloWorld method:\" >webClient.get() .path(\"/greet\") .request() .thenAccept(response -&gt; Assertions.assertEquals(401,response.status().code())) .toCompletableFuture() .get(); This piece of code uses the webclient to access the application on /greet path with a GET method. The http basic authentication security protects this path, so the client should receive an HTTP 401 code for unauthorized. Only jack user has access to this part of the application. <markup lang=\"java\" title=\"Add new check to the testHelloWorld method:\" >webClient.get() .path(\"/greet\") .headers(headers -&gt; { String encoding = Base64.getEncoder().encodeToString(\"jack:jackIsGreat\".getBytes()); headers.add(Http.Header.AUTHORIZATION, \"Basic \" + encoding); return headers; }) .request(JsonObject.class) .thenAccept(jsonObject -&gt; Assertions.assertEquals(\"Hello World!\", jsonObject.getString(\"message\"))) .toCompletableFuture() .get(); The username and password are encoded and placed inside the header in order to authenticate as jack to access the application. If the authentication is successful, the application send the Hello World back as a JsonObject . Now, the project can be build without skipping test. <markup lang=\"bash\" title=\"Build the project\" >mvn clean install ",
            "title": "Update Tests to the Secure Environment"
        },
        {
            "location": "se/guides/security-oidc",
            "text": " To give less access to an endpoint, it is possible to configure user role. So the application will only grant access to the user with the required role. Add a user and roles to the helidon-quickstart-se/src/test/resources/application.yaml . <markup lang=\"yaml\" title=\"Add jack role and create a new user named john:\" >- http-basic-auth: users: - login: \"jack\" password: \"jackIsGreat\" roles: [ \"admin\", \"user\" ] - login: \"john\" password: \"johnPassword\" roles: [ \"user\" ] Into the web-server section, the roles-allowed parameter defines which roles have access to the protected path and method. <markup lang=\"yaml\" title=\"Add admin role\" >web-server: # protected paths on the web server - do not include paths served by Jersey, as those are protected directly paths: - path: \"/greet\" methods: [\"get\"] roles-allowed: \"admin\" authenticate: true Now, only Jack has access to secure endpoint as he has an admin role. Jhon, as a simple user, can not access it. Once it is done, go to the tests to check the application behavior. The test from previous section is still passing as jack has access. The user john has only the user role so when accessing protected endpoint, a 403 (Forbidden) http code is returned. <markup lang=\"java\" title=\"Check that john does not have access\" >webClient.get() .path(\"/greet\") .headers(headers -&gt; { String encoding = Base64.getEncoder().encodeToString(\"john:johnPassword\".getBytes()); headers.add(Http.Header.AUTHORIZATION,\"Basic \" + encoding); return headers; }) .request() .thenAccept(response -&gt; Assertions.assertEquals(403, response.status().code())) .toCompletableFuture() .get(); <markup lang=\"bash\" title=\"Build the project\" >mvn clean install The tests pass, and your application is secured with specific roles in addition to user IDs. ",
            "title": "Restrict Access to a Specific Role"
        },
        {
            "location": "se/guides/security-oidc",
            "text": " Keycloak supports many authentication and authorization flows, but only two of them will be shown. This section describes another way you can get an access token or refresh a token or identity token. The identity token contains information about the user. The access token contains access information that the application can use to determine what resources the user is allowed to access. Once expired, the refresh token allows the application to obtain a new access token. As these tokens contain sensitive information, they are valid for a very short period. It is possible to make them last longer in order to let you manipulate them with Postman. To do so: Open the Postman Console. Click on the Realm Setting in the left menu. Navigate to the Tokens tab. You can increase the access token lifespan. Authorization Code Flow The Authorization Code flow is suitable for browser-based applications. It is composed of three main steps: The browser visits the application. The user is not logged in, so it redirects the browser to Keycloak which requires username and password for authentication. Keycloak authenticates the user and returns a temporary authorization code as a query parameter in the URL. The authorization code is used to get access and refresh token from Keycloak token endpoint. For the first step, paste the following URL into your browser: http://localhost:8080/auth/realms/myRealm/protocol/openid-connect/auth?client_id=myClientID&amp;response_type=code . The first part of the url http:/../auth is the Keycloak endpoint to request an authorization code. Two query parameters are provided, the client id and the response type. Press enter and Keycloak responds with different URL containing a query parameter code . You successfully received the authorization code. In order to achieve the third step, we can use Postman to exchange the authorization code for tokens. In Postman, select the Http POST method. Keycloak endpoint to get token is the following: http://localhost:8080/auth/realms/myRealm/protocol/openid-connect/token . In the body of the request, select x-www-form-urlencoded type. Add the following data: <markup lang=\"json\" title=\"Enter the key:value\" >[{\"key\":\"grant_type\",\"value\":\"authorization_code\"}, {\"key\":\"client_id\",\"value\":\"myClientID\"}, {\"key\":\"client_secret\",\"value\":\"client secret\"}, {\"key\":\"code\",\"value\":\"authorization code\"}] Do not forget to replace the client secret by its value (generated during Create a Client), and authorization code by the code value in the query parameter. Send the request by pressing Send . Keycloak returns an access token and a refresh token. Resource Owner Password Credentials Grant (Direct Access Grants) The Direct Access Grants flow is used by REST clients that want to request tokens on behalf of a user. To use Postman to make this request on behalf of myuser , select the GET method and enter this URL: http://localhost:7987/greet/ . Under Authorization tab, select authorization type`OAuth 2.0`. Under it, complete the sentence Add authorization data to with Request Headers , and complete the required fields. <markup lang=\"json\" title=\"Enter the following information:\" >[{\"key\":\"Header Prefix\",\"value\":\"bearer\"}, {\"key\":\"Grant type\",\"value\":\"Password Credentials\"}, {\"key\":\"Access Token URL\",\"value\":\"http://localhost:8080/auth/realms/myRealm/protocol/openid-connect/token\"}, {\"key\":\"Client ID\",\"value\":\"myClientID\"}, {\"key\":\"Client Secret\",\"value\":\"client secret\"}, {\"key\":\"Username\",\"value\":\"myuser\"}, {\"key\":\"Password\",\"value\":\"password\"}, {\"key\":\"Scope\",\"value\":\"openid\"}, {\"key\":\"Client Authentication\",\"value\":\"Send as Basic Auth Header\"}] Again, make sure to replace client secret by the actual client secret. Click on Get New Access Token . A popup window appears with Authentication complete, click on proceed to display access, refresh and identity token. Copy and paste the access token to Access Token field and press Send . Helidon greeting application sends back Hello World ! . Update Tests to the Secure Environment At this stage of the application, tests cannot pass because of OIDC security. The only way to authenticate a user is through the front end of that server which can be accessed with the browser for example. In order to keep security and test the application locally, a new security provider must be setup. By adding specific configuration to the tests, it is possible to override the application configuration. The following explains how to set a basic authentication instead of oidc security provider only for the tests. Which means, at the end of this guide, the application will be secured by oidc security provider, and the tests will use basic authentication. <markup lang=\"xml\" title=\"Add the following dependency to pom.xml :\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-http-auth&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; In the test folder helidon-quickstart-se/src/test : <markup lang=\"bash\" title=\"Create a new directory and another one inside\" >mkdir resources cd resources touch application.yaml Open the application.yaml file <markup lang=\"yaml\" title=\"Copy these properties into application.yaml\" >app: greeting: \"Hello\" server: port: 7987 host: localhost security: providers: - abac: # Adds ABAC Provider - it does not require any configuration - http-basic-auth: users: - login: \"jack\" password: \"jackIsGreat\" - oidc: client-id: \"Your client ID\" client-secret: \"Your client secret\" identity-uri: \"http://localhost:8080/auth/realms/myRealm\" audience: \"account\" frontend-uri: \"http://localhost:7987\" server-type: \"oidc\" web-server: # protected paths on the web server - do not include paths served by Jersey, as those are protected directly paths: - path: \"/greet\" methods: [\"get\"] authenticate: true Replace this field by your Keycloak client ID. Replace this field by your Keycloak client Password. Add the http-basic-auth properties in the security &#8594; providers property section. This configuration will be used by the tests instead of the java/resources/application.yaml . In the MainTest.java file, tests need to be modified to check the application security when accessing /greet path with a GET method. <markup lang=\"java\" title=\"Import the following class:\" >import java.util.Base64; import io.helidon.common.http.Http; <markup lang=\"java\" title=\"Replace the first webclient call by this one into testHelloWorld method:\" >webClient.get() .path(\"/greet\") .request() .thenAccept(response -&gt; Assertions.assertEquals(401,response.status().code())) .toCompletableFuture() .get(); This piece of code uses the webclient to access the application on /greet path with a GET method. The http basic authentication security protects this path, so the client should receive an HTTP 401 code for unauthorized. Only jack user has access to this part of the application. <markup lang=\"java\" title=\"Add new check to the testHelloWorld method:\" >webClient.get() .path(\"/greet\") .headers(headers -&gt; { String encoding = Base64.getEncoder().encodeToString(\"jack:jackIsGreat\".getBytes()); headers.add(Http.Header.AUTHORIZATION, \"Basic \" + encoding); return headers; }) .request(JsonObject.class) .thenAccept(jsonObject -&gt; Assertions.assertEquals(\"Hello World!\", jsonObject.getString(\"message\"))) .toCompletableFuture() .get(); The username and password are encoded and placed inside the header in order to authenticate as jack to access the application. If the authentication is successful, the application send the Hello World back as a JsonObject . Now, the project can be build without skipping test. <markup lang=\"bash\" title=\"Build the project\" >mvn clean install Restrict Access to a Specific Role To give less access to an endpoint, it is possible to configure user role. So the application will only grant access to the user with the required role. Add a user and roles to the helidon-quickstart-se/src/test/resources/application.yaml . <markup lang=\"yaml\" title=\"Add jack role and create a new user named john:\" >- http-basic-auth: users: - login: \"jack\" password: \"jackIsGreat\" roles: [ \"admin\", \"user\" ] - login: \"john\" password: \"johnPassword\" roles: [ \"user\" ] Into the web-server section, the roles-allowed parameter defines which roles have access to the protected path and method. <markup lang=\"yaml\" title=\"Add admin role\" >web-server: # protected paths on the web server - do not include paths served by Jersey, as those are protected directly paths: - path: \"/greet\" methods: [\"get\"] roles-allowed: \"admin\" authenticate: true Now, only Jack has access to secure endpoint as he has an admin role. Jhon, as a simple user, can not access it. Once it is done, go to the tests to check the application behavior. The test from previous section is still passing as jack has access. The user john has only the user role so when accessing protected endpoint, a 403 (Forbidden) http code is returned. <markup lang=\"java\" title=\"Check that john does not have access\" >webClient.get() .path(\"/greet\") .headers(headers -&gt; { String encoding = Base64.getEncoder().encodeToString(\"john:johnPassword\".getBytes()); headers.add(Http.Header.AUTHORIZATION,\"Basic \" + encoding); return headers; }) .request() .thenAccept(response -&gt; Assertions.assertEquals(403, response.status().code())) .toCompletableFuture() .get(); <markup lang=\"bash\" title=\"Build the project\" >mvn clean install The tests pass, and your application is secured with specific roles in addition to user IDs. ",
            "title": "Test Keycloak Process with Postman"
        },
        {
            "location": "se/guides/security-oidc",
            "text": "<markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-se.jar The tests must be skipped, otherwise it produces test failure. As the /greet endpoint for GET request is now protected, its access is limited, and the tests are not built to take oidc security in account. Open your favourite browser and try to access http://localhost:7987/greet/Michael . You should not be redirected and receive greeting from the application. Enter the following into URL : http://localhost:7987/greet . Keycloak redirect you to its login page. Enter the username and associated password: Username : myUser Password : password After successful log in, keycloak redirect you to the http://localhost:7987/greet endpoint and print Hello word. Press Ctrl+C to stop the application. From the actual settings, the user needs to log in only once, then Keycloak saves all the connection data. Test Keycloak Process with Postman Keycloak supports many authentication and authorization flows, but only two of them will be shown. This section describes another way you can get an access token or refresh a token or identity token. The identity token contains information about the user. The access token contains access information that the application can use to determine what resources the user is allowed to access. Once expired, the refresh token allows the application to obtain a new access token. As these tokens contain sensitive information, they are valid for a very short period. It is possible to make them last longer in order to let you manipulate them with Postman. To do so: Open the Postman Console. Click on the Realm Setting in the left menu. Navigate to the Tokens tab. You can increase the access token lifespan. Authorization Code Flow The Authorization Code flow is suitable for browser-based applications. It is composed of three main steps: The browser visits the application. The user is not logged in, so it redirects the browser to Keycloak which requires username and password for authentication. Keycloak authenticates the user and returns a temporary authorization code as a query parameter in the URL. The authorization code is used to get access and refresh token from Keycloak token endpoint. For the first step, paste the following URL into your browser: http://localhost:8080/auth/realms/myRealm/protocol/openid-connect/auth?client_id=myClientID&amp;response_type=code . The first part of the url http:/../auth is the Keycloak endpoint to request an authorization code. Two query parameters are provided, the client id and the response type. Press enter and Keycloak responds with different URL containing a query parameter code . You successfully received the authorization code. In order to achieve the third step, we can use Postman to exchange the authorization code for tokens. In Postman, select the Http POST method. Keycloak endpoint to get token is the following: http://localhost:8080/auth/realms/myRealm/protocol/openid-connect/token . In the body of the request, select x-www-form-urlencoded type. Add the following data: <markup lang=\"json\" title=\"Enter the key:value\" >[{\"key\":\"grant_type\",\"value\":\"authorization_code\"}, {\"key\":\"client_id\",\"value\":\"myClientID\"}, {\"key\":\"client_secret\",\"value\":\"client secret\"}, {\"key\":\"code\",\"value\":\"authorization code\"}] Do not forget to replace the client secret by its value (generated during Create a Client), and authorization code by the code value in the query parameter. Send the request by pressing Send . Keycloak returns an access token and a refresh token. Resource Owner Password Credentials Grant (Direct Access Grants) The Direct Access Grants flow is used by REST clients that want to request tokens on behalf of a user. To use Postman to make this request on behalf of myuser , select the GET method and enter this URL: http://localhost:7987/greet/ . Under Authorization tab, select authorization type`OAuth 2.0`. Under it, complete the sentence Add authorization data to with Request Headers , and complete the required fields. <markup lang=\"json\" title=\"Enter the following information:\" >[{\"key\":\"Header Prefix\",\"value\":\"bearer\"}, {\"key\":\"Grant type\",\"value\":\"Password Credentials\"}, {\"key\":\"Access Token URL\",\"value\":\"http://localhost:8080/auth/realms/myRealm/protocol/openid-connect/token\"}, {\"key\":\"Client ID\",\"value\":\"myClientID\"}, {\"key\":\"Client Secret\",\"value\":\"client secret\"}, {\"key\":\"Username\",\"value\":\"myuser\"}, {\"key\":\"Password\",\"value\":\"password\"}, {\"key\":\"Scope\",\"value\":\"openid\"}, {\"key\":\"Client Authentication\",\"value\":\"Send as Basic Auth Header\"}] Again, make sure to replace client secret by the actual client secret. Click on Get New Access Token . A popup window appears with Authentication complete, click on proceed to display access, refresh and identity token. Copy and paste the access token to Access Token field and press Send . Helidon greeting application sends back Hello World ! . Update Tests to the Secure Environment At this stage of the application, tests cannot pass because of OIDC security. The only way to authenticate a user is through the front end of that server which can be accessed with the browser for example. In order to keep security and test the application locally, a new security provider must be setup. By adding specific configuration to the tests, it is possible to override the application configuration. The following explains how to set a basic authentication instead of oidc security provider only for the tests. Which means, at the end of this guide, the application will be secured by oidc security provider, and the tests will use basic authentication. <markup lang=\"xml\" title=\"Add the following dependency to pom.xml :\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-http-auth&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; In the test folder helidon-quickstart-se/src/test : <markup lang=\"bash\" title=\"Create a new directory and another one inside\" >mkdir resources cd resources touch application.yaml Open the application.yaml file <markup lang=\"yaml\" title=\"Copy these properties into application.yaml\" >app: greeting: \"Hello\" server: port: 7987 host: localhost security: providers: - abac: # Adds ABAC Provider - it does not require any configuration - http-basic-auth: users: - login: \"jack\" password: \"jackIsGreat\" - oidc: client-id: \"Your client ID\" client-secret: \"Your client secret\" identity-uri: \"http://localhost:8080/auth/realms/myRealm\" audience: \"account\" frontend-uri: \"http://localhost:7987\" server-type: \"oidc\" web-server: # protected paths on the web server - do not include paths served by Jersey, as those are protected directly paths: - path: \"/greet\" methods: [\"get\"] authenticate: true Replace this field by your Keycloak client ID. Replace this field by your Keycloak client Password. Add the http-basic-auth properties in the security &#8594; providers property section. This configuration will be used by the tests instead of the java/resources/application.yaml . In the MainTest.java file, tests need to be modified to check the application security when accessing /greet path with a GET method. <markup lang=\"java\" title=\"Import the following class:\" >import java.util.Base64; import io.helidon.common.http.Http; <markup lang=\"java\" title=\"Replace the first webclient call by this one into testHelloWorld method:\" >webClient.get() .path(\"/greet\") .request() .thenAccept(response -&gt; Assertions.assertEquals(401,response.status().code())) .toCompletableFuture() .get(); This piece of code uses the webclient to access the application on /greet path with a GET method. The http basic authentication security protects this path, so the client should receive an HTTP 401 code for unauthorized. Only jack user has access to this part of the application. <markup lang=\"java\" title=\"Add new check to the testHelloWorld method:\" >webClient.get() .path(\"/greet\") .headers(headers -&gt; { String encoding = Base64.getEncoder().encodeToString(\"jack:jackIsGreat\".getBytes()); headers.add(Http.Header.AUTHORIZATION, \"Basic \" + encoding); return headers; }) .request(JsonObject.class) .thenAccept(jsonObject -&gt; Assertions.assertEquals(\"Hello World!\", jsonObject.getString(\"message\"))) .toCompletableFuture() .get(); The username and password are encoded and placed inside the header in order to authenticate as jack to access the application. If the authentication is successful, the application send the Hello World back as a JsonObject . Now, the project can be build without skipping test. <markup lang=\"bash\" title=\"Build the project\" >mvn clean install Restrict Access to a Specific Role To give less access to an endpoint, it is possible to configure user role. So the application will only grant access to the user with the required role. Add a user and roles to the helidon-quickstart-se/src/test/resources/application.yaml . <markup lang=\"yaml\" title=\"Add jack role and create a new user named john:\" >- http-basic-auth: users: - login: \"jack\" password: \"jackIsGreat\" roles: [ \"admin\", \"user\" ] - login: \"john\" password: \"johnPassword\" roles: [ \"user\" ] Into the web-server section, the roles-allowed parameter defines which roles have access to the protected path and method. <markup lang=\"yaml\" title=\"Add admin role\" >web-server: # protected paths on the web server - do not include paths served by Jersey, as those are protected directly paths: - path: \"/greet\" methods: [\"get\"] roles-allowed: \"admin\" authenticate: true Now, only Jack has access to secure endpoint as he has an admin role. Jhon, as a simple user, can not access it. Once it is done, go to the tests to check the application behavior. The test from previous section is still passing as jack has access. The user john has only the user role so when accessing protected endpoint, a 403 (Forbidden) http code is returned. <markup lang=\"java\" title=\"Check that john does not have access\" >webClient.get() .path(\"/greet\") .headers(headers -&gt; { String encoding = Base64.getEncoder().encodeToString(\"john:johnPassword\".getBytes()); headers.add(Http.Header.AUTHORIZATION,\"Basic \" + encoding); return headers; }) .request() .thenAccept(response -&gt; Assertions.assertEquals(403, response.status().code())) .toCompletableFuture() .get(); <markup lang=\"bash\" title=\"Build the project\" >mvn clean install The tests pass, and your application is secured with specific roles in addition to user IDs. ",
            "title": "Build the Application"
        },
        {
            "location": "se/guides/tracing",
            "text": " This guide describes how to create a sample Helidon SE project that can be used to run some basic examples using tracing with a Helidon SE application. ",
            "title": "preambule"
        },
        {
            "location": "se/guides/tracing",
            "text": " For this 30 minute tutorial, you will need the following: <div class=\"table__overflow elevation-1 flex sm7 \"> A Helidon SE Application You can use your own application or use the Helidon SE Quickstart to create a sample application. Java&#160;SE&#160;17 ( Open&#160;JDK&#160;17 ) Helidon requires Java 17+. Maven 3.6.1+ Helidon requires Maven 3.6.1+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop . <markup lang=\"bash\" title=\"Verify Prerequisites\" >java -version mvn --version docker --version kubectl version --short <markup lang=\"bash\" title=\"Setting JAVA_HOME\" ># On Mac export JAVA_HOME=`/usr/libexec/java_home -v 17` # On Linux # Use the appropriate path to your JDK export JAVA_HOME=/usr/lib/jvm/jdk-17 ",
            "title": "What You Need"
        },
        {
            "location": "se/guides/tracing",
            "text": " This section explains a few concepts that you need to understand before you get started with tracing. In the context of this document, a service is synonymous with an application. A span is the basic unit of work done within a single service, on a single host. Every span has a name, starting timestamp, and duration. For example, the work done by a REST endpoint is a span. A span is associated to a single service, but its descendants can belong to different services and hosts. A trace contains a collection of spans from one or more services, running on one or more hosts. For example, if you trace a service endpoint that calls another service, then the trace would contain spans from both services. Within a trace, spans are organized as a directed acyclic graph (DAG) and can belong to multiple services, running on multiple hosts. The OpenTracing Data Model describes the details at The OpenTracing Semantic Specification . Spans are automatically created by Helidon as needed during execution of the REST request. ",
            "title": "Tracing Concepts"
        },
        {
            "location": "se/guides/tracing",
            "text": " Distributed tracing is a critical feature of micro-service based applications, since it traces workflow both within a service and across multiple services. This provides insight to sequence and timing data for specific blocks of work, which helps you identify performance and operational issues. Helidon SE includes support for distributed tracing through the OpenTracing API . Tracing is integrated with WebServer, gRPC Server, and Security using either the Zipkin or Jaeger tracers. Tracing Concepts This section explains a few concepts that you need to understand before you get started with tracing. In the context of this document, a service is synonymous with an application. A span is the basic unit of work done within a single service, on a single host. Every span has a name, starting timestamp, and duration. For example, the work done by a REST endpoint is a span. A span is associated to a single service, but its descendants can belong to different services and hosts. A trace contains a collection of spans from one or more services, running on one or more hosts. For example, if you trace a service endpoint that calls another service, then the trace would contain spans from both services. Within a trace, spans are organized as a directed acyclic graph (DAG) and can belong to multiple services, running on multiple hosts. The OpenTracing Data Model describes the details at The OpenTracing Semantic Specification . Spans are automatically created by Helidon as needed during execution of the REST request. ",
            "title": "Introduction"
        },
        {
            "location": "se/guides/tracing",
            "text": " Use the Helidon SE Maven archetype to create a simple project that can be used for the examples in this guide. <markup lang=\"bash\" title=\"Run the Maven archetype:\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-se \\ -DarchetypeVersion=3.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-se \\ -Dpackage=io.helidon.examples.quickstart.se <markup lang=\"bash\" title=\"The project will be built and run from the helidon-quickstart-se directory:\" >cd helidon-quickstart-se ",
            "title": "Create a Sample Helidon SE Project"
        },
        {
            "location": "se/guides/tracing",
            "text": " First, you need to run the Zipkin tracer. Helidon will communicate with this tracer at runtime. <markup lang=\"bash\" title=\"Run Zipkin within a docker container, then check the Zipkin server health:\" >docker run -d --name zipkin -p 9411:9411 openzipkin/zipkin Run the Zipkin docker image named openzipkin/zipkin . <markup lang=\"bash\" title=\"Check the Zipkin server health:\" >curl http://localhost:9411/health Invoke the Zipkin REST API to check the Zipkin server health. <markup lang=\"json\" >{ \"status\": \"UP\", \"zipkin\": { \"status\": \"UP\", \"details\": { \"InMemoryStorage{}\": { \"status\": \"UP\" } } } } All status fields should be UP . ",
            "title": "Set up Zipkin"
        },
        {
            "location": "se/guides/tracing",
            "text": " Update the pom.xml file and add the following Zipkin dependency to the &lt;dependencies&gt; section ( not &lt;dependencyManagement&gt; ). This will enable Helidon to use Zipkin at the default host and port, localhost:9411 . <markup lang=\"xml\" title=\"Add the following dependency to pom.xml :\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-zipkin&lt;/artifactId&gt; &lt;/dependency&gt; All spans sent by Helidon to Zipkin need to be associated with a service. Specify the service name below. <markup lang=\"bash\" title=\"Add the following line to resources/application.yaml :\" >tracing: service: helidon-se-1 <markup lang=\"java\" title=\"Update the Main class; Add Tracer to the WebServer builder\" >import io.helidon.tracing.TracerBuilder; ... WebServer server = WebServer.builder(createRouting(config)) .config(config.get(\"server\")) .tracer(TracerBuilder.create(config.get(\"tracing\")).build()) .addMediaSupport(JsonpSupport.create()) .build(); Add a new import statement. Build and register a Tracer object using the tracing configuration. <markup lang=\"java\" title=\"Update the GreetService class; 1) Add a new import and 2) Replace the getDefaultMessageHandler method:\" >import io.opentracing.Span; ... private void getDefaultMessageHandler(ServerRequest request, ServerResponse response) { var spanBuilder = request.tracer() .buildSpan(\"getDefaultMessageHandler\"); request.spanContext().ifPresent(spanBuilder::asChildOf); Span span = spanBuilder.start(); try { sendResponse(response, \"World\"); } finally { span.finish(); } } Add new import statement. Get the Tracer object from the request. Build a new span named getDefaultMessageHandler . Make the new span a child of the current span. Start the span. The current timestamp is used as the starting time for the span. Finish the span. The current timestamp is used as the ending time for the span. <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-se.jar <markup lang=\"bash\" title=\"Run the curl command in a new terminal window and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"Hello World!\" } ",
            "title": "Enable Tracing in the Helidon Application"
        },
        {
            "location": "se/guides/tracing",
            "text": " Because you had tracing enabled, the previous /greet endpoint invocation resulted in a new trace being created. Let&#8217;s get the trace data that was generated using the Zipkin API. First, get the service information. <markup lang=\"bash\" title=\"Run the curl command and check the response:\" >curl http://localhost:9411/api/v2/services ... [\"helidon-se-1\"] This is the tracing service name specified in resources/application.yaml . Each span used by a service has a name, which is unique within a trace. If you invoke the /greet endpoint multiple times, you will still get the same set of names. <markup lang=\"bash\" title=\"Invoke the endpoint below and check the response:\" > curl -X GET \"http://localhost:9411/api/v2/spans?serviceName=helidon-se-1\" -H \"accept: application/json\" ... [ \"content-write\", \"getdefaultmessagehandler\", \"http request\" ] Get the span names for the helidon-se-1 service. These are the span names. If you invoke the /greet endpoint again, then invoke the /spans endpoint, you will get the same response. Next, get the spans in the trace as shown below. <markup lang=\"bash\" title=\"Invoke the endpoint below and check the response:\" > curl -X GET \"http://localhost:9411/api/v2/traces?serviceName=helidon-se-1&amp;limit=1\" -H \"accept: application/json\" ... [ [ { \"traceId\": \"f193adb3f2bab3b3\", \"parentId\": \"f193adb3f2bab3b3\", \"id\": \"1536021daf3845e1\", \"kind\": \"SERVER\", \"name\": \"content-write\", \"timestamp\": 1568245972222815, \"duration\": 527, \"localEndpoint\": { \"serviceName\": \"helidon-se-1\", \"ipv4\": \"192.168.1.115\" }, \"tags\": { \"response.type\": \"org.glassfish.json.JsonObjectBuilderImpl$JsonObjectImpl\" } }, ... (truncated) ] Get the newest trace only, using the limit=1 query param. There are other query params that let you restrict results to a specific time window. The request will return 3 spans, one for each name. Each span has a parentId field, except the http request span, which is the root. ",
            "title": "Viewing Tracing Using Zipkin REST API"
        },
        {
            "location": "se/guides/tracing",
            "text": " The tracing output data is verbose and can be difficult to interpret using the REST API, especially since it represents a structure of spans. Zipkin provides a web-based UI at http://localhost:9411/zipkin , where you can see a visual representation of the same data and the relationship between spans within a trace. Click on the UI refresh button (the search icon) as shown in the image below. Notice that you can change the look-back time to restrict the trace list. Trace refresh The image below shows the trace summary, including start time and duration of each trace. There are two traces, each one generated in response to a curl http://localhost:8080/greet invocation. The oldest trace will have a much longer duration since there is one-time initialization that occurs. Tracing list view Click on a trace and you will see the trace detail page where the spans are listed. You can clearly see the root span and the relationship among all the spans in the trace, along with timing information. Trace detail page A parent span might not depend on the result of the child. This is called a FollowsFrom reference, see Open Tracing Semantic Spec . You can examine span details by clicking on the span row. Refer to the image below, which shows the span details, including timing information. You can see times for each space relative to the root span. These rows are annotated with Server Start and Server Finish , as shown in the third column. Span detail page ",
            "title": "Viewing Tracing Using Zipkin UI"
        },
        {
            "location": "se/guides/tracing",
            "text": " Helidon automatically traces across services, providing that the services use the same tracer, for example, the same instance of Zipkin. This means a single trace can include spans from multiple services and hosts. OpenTracing uses a SpanContext to propagate tracing information across process boundaries. When you make client API calls, Helidon will internally call OpenTracing APIs to propagate the SpanContext . There is nothing you need to do in your application to make this work. To demonstrate distributed tracing, you will need to create a second project, where the server listens on port 8081. Create a new root directory to hold this new project, then do the following steps, similar to what you did at the start of this guide: ",
            "title": "Tracing Across Services"
        },
        {
            "location": "se/guides/tracing",
            "text": "<markup lang=\"bash\" title=\"Run the Maven archetype:\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-se \\ -DarchetypeVersion=3.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-se-2 \\ -Dpackage=io.helidon.examples.quickstart.se <markup lang=\"bash\" title=\"The project will be built and run from the helidon-quickstart-se directory:\" >cd helidon-quickstart-se-2 <markup lang=\"xml\" title=\"Add the following dependency to pom.xml :\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-zipkin&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"bash\" title=\"Replace resources/application.yaml with the following:\" >app: greeting: \"Hello From SE-2\" tracing: service: \"helidon-se-2\" server: port: 8081 host: 0.0.0.0 <markup lang=\"java\" title=\"Update the Main class; Add Tracer to the WebServer builder\" >import io.helidon.tracing.TracerBuilder; ... WebServer server = WebServer.builder(createRouting(config)) .config(config.get(\"server\")) .tracer(TracerBuilder.create(config.get(\"tracing\")).build()) .addMediaSupport(JsonpSupport.create()) .build(); <markup lang=\"java\" title=\"Update the GreetService class; 1) Add new import and 2) Replace the getDefaultMessageHandler method:\" >import io.opentracing.Span; //... private void getDefaultMessageHandler(ServerRequest request, ServerResponse response) { var spanBuilder = request.tracer() .buildSpan(\"getDefaultMessageHandler\"); request.spanContext().ifPresent(spanBuilder::asChildOf); Span span = spanBuilder.start(); try { sendResponse(response, \"World\"); } finally { span.finish(); } } <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-se-2.jar <markup lang=\"bash\" title=\"Run the curl command in a new terminal window and check the response ( notice the port is 8081 ) :\" >curl http://localhost:8081/greet ... { \"message\": \"Hello From SE-2 World!\" } ",
            "title": "Create the Second Service"
        },
        {
            "location": "se/guides/tracing",
            "text": " Once you have validated that the second service is running correctly, you need to modify the original application to call it. <markup lang=\"xml\" title=\"Add the following dependency to pom.xml :\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.integration&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-integration-jersey&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-jersey-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.glassfish.jersey.core&lt;/groupId&gt; &lt;artifactId&gt;jersey-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.glassfish.jersey.inject&lt;/groupId&gt; &lt;artifactId&gt;jersey-hk2&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"java\" title=\"Replace the GreetService class with the following code:\" >package io.helidon.examples.quickstart.se; import io.helidon.common.http.Http; import io.helidon.config.Config; import io.helidon.tracing.jersey.client.ClientTracingFilter; import io.helidon.webserver.Routing; import io.helidon.webserver.ServerRequest; import io.helidon.webserver.ServerResponse; import io.helidon.webserver.Service; import io.opentracing.Span; import java.util.Collections; import java.util.concurrent.atomic.AtomicReference; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.client.Client; import jakarta.ws.rs.client.ClientBuilder; import jakarta.ws.rs.client.Invocation; import jakarta.ws.rs.client.WebTarget; public class GreetService implements Service { private final AtomicReference&lt;String&gt; greeting = new AtomicReference&lt;&gt;(); private WebTarget webTarget; private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); GreetService(Config config) { greeting.set(config.get(\"app.greeting\").asString().orElse(\"Ciao\")); Client jaxRsClient = ClientBuilder.newBuilder().build(); webTarget = jaxRsClient.target(\"http://localhost:8081/greet\"); } @Override public void update(Routing.Rules rules) { rules .get(\"/\", this::getDefaultMessageHandler) .get(\"/outbound\", this::outboundMessageHandler) .put(\"/greeting\", this::updateGreetingHandler); } private void getDefaultMessageHandler(ServerRequest request, ServerResponse response) { var spanBuilder = request.tracer() .buildSpan(\"getDefaultMessageHandler\"); request.spanContext().ifPresent(spanBuilder::asChildOf); Span span = spanBuilder.start(); try { sendResponse(response, \"World\"); } finally { span.finish(); } } private void sendResponse(ServerResponse response, String name) { String msg = String.format(\"%s %s!\", greeting.get(), name); JsonObject returnObject = JSON.createObjectBuilder().add(\"message\", msg).build(); response.send(returnObject); } private void updateGreetingFromJson(JsonObject jo, ServerResponse response) { if (!jo.containsKey(\"greeting\")) { JsonObject jsonErrorObject = JSON.createObjectBuilder().add(\"error\", \"No greeting provided\").build(); response.status(Http.Status.BAD_REQUEST_400).send(jsonErrorObject); return; } greeting.set(jo.getString(\"greeting\")); response.status(Http.Status.NO_CONTENT_204).send(); } private void outboundMessageHandler(ServerRequest request, ServerResponse response) { Invocation.Builder requestBuilder = webTarget.request(); var spanBuilder = request.tracer() .buildSpan(\"outboundMessageHandler\"); request.spanContext().ifPresent(spanBuilder::asChildOf); Span span = spanBuilder.start(); try { requestBuilder.property( ClientTracingFilter.CURRENT_SPAN_CONTEXT_PROPERTY_NAME, request.spanContext()); requestBuilder .rx() .get(String.class) .thenAccept(response::send) .exceptionally( throwable -&gt; { // process exception response.status(Http.Status.INTERNAL_SERVER_ERROR_500); response.send(\"Failed with: \" + throwable); return null; }); } finally { span.finish(); } } private void updateGreetingHandler(ServerRequest request, ServerResponse response) { request.content().as(JsonObject.class).thenAccept(jo -&gt; updateGreetingFromJson(jo, response)); } } Add outboundMessageHandler to the routing rules. Create and start a span that is a child of the current span. Set a property with the SpanContext . Invoke the second service. Stop the span. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl -i http://localhost:8080/greet/outbound ... { \"message\": \"Hello From SE-2 World!\" } The request went to the service on 8080 , which then invoked the service at 8081 to get the greeting. Notice the greeting came from the second service. Refresh the Zipkin UI trace listing page and notice that there is a trace across two services. Tracing multiple service list view Click on the trace with two services to see the detail view. Tracing across multiple services detail view In the image above, you can see that the trace includes spans from two services. You will notice there is a gap before the sixth span, which is a get operation. This is a one-time client initialization delay. Run the /outbound curl command again and look at the new trace to see that the delay no longer exists. You can now stop your second service, it is not longer used in this guide. ",
            "title": "Modify the First Service"
        },
        {
            "location": "se/guides/tracing",
            "text": " The examples in this guide demonstrate how to integrate tracing with Helidon, how to view traces, how to trace across multiple services, and how to integrate with tracing with Kubernetes. All examples use Zipkin and traces will be viewed using both the Zipkin API and UI. Create a Sample Helidon SE Project Use the Helidon SE Maven archetype to create a simple project that can be used for the examples in this guide. <markup lang=\"bash\" title=\"Run the Maven archetype:\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-se \\ -DarchetypeVersion=3.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-se \\ -Dpackage=io.helidon.examples.quickstart.se <markup lang=\"bash\" title=\"The project will be built and run from the helidon-quickstart-se directory:\" >cd helidon-quickstart-se Set up Zipkin First, you need to run the Zipkin tracer. Helidon will communicate with this tracer at runtime. <markup lang=\"bash\" title=\"Run Zipkin within a docker container, then check the Zipkin server health:\" >docker run -d --name zipkin -p 9411:9411 openzipkin/zipkin Run the Zipkin docker image named openzipkin/zipkin . <markup lang=\"bash\" title=\"Check the Zipkin server health:\" >curl http://localhost:9411/health Invoke the Zipkin REST API to check the Zipkin server health. <markup lang=\"json\" >{ \"status\": \"UP\", \"zipkin\": { \"status\": \"UP\", \"details\": { \"InMemoryStorage{}\": { \"status\": \"UP\" } } } } All status fields should be UP . Enable Tracing in the Helidon Application Update the pom.xml file and add the following Zipkin dependency to the &lt;dependencies&gt; section ( not &lt;dependencyManagement&gt; ). This will enable Helidon to use Zipkin at the default host and port, localhost:9411 . <markup lang=\"xml\" title=\"Add the following dependency to pom.xml :\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-zipkin&lt;/artifactId&gt; &lt;/dependency&gt; All spans sent by Helidon to Zipkin need to be associated with a service. Specify the service name below. <markup lang=\"bash\" title=\"Add the following line to resources/application.yaml :\" >tracing: service: helidon-se-1 <markup lang=\"java\" title=\"Update the Main class; Add Tracer to the WebServer builder\" >import io.helidon.tracing.TracerBuilder; ... WebServer server = WebServer.builder(createRouting(config)) .config(config.get(\"server\")) .tracer(TracerBuilder.create(config.get(\"tracing\")).build()) .addMediaSupport(JsonpSupport.create()) .build(); Add a new import statement. Build and register a Tracer object using the tracing configuration. <markup lang=\"java\" title=\"Update the GreetService class; 1) Add a new import and 2) Replace the getDefaultMessageHandler method:\" >import io.opentracing.Span; ... private void getDefaultMessageHandler(ServerRequest request, ServerResponse response) { var spanBuilder = request.tracer() .buildSpan(\"getDefaultMessageHandler\"); request.spanContext().ifPresent(spanBuilder::asChildOf); Span span = spanBuilder.start(); try { sendResponse(response, \"World\"); } finally { span.finish(); } } Add new import statement. Get the Tracer object from the request. Build a new span named getDefaultMessageHandler . Make the new span a child of the current span. Start the span. The current timestamp is used as the starting time for the span. Finish the span. The current timestamp is used as the ending time for the span. <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-se.jar <markup lang=\"bash\" title=\"Run the curl command in a new terminal window and check the response:\" >curl http://localhost:8080/greet ... { \"message\": \"Hello World!\" } Viewing Tracing Using Zipkin REST API Because you had tracing enabled, the previous /greet endpoint invocation resulted in a new trace being created. Let&#8217;s get the trace data that was generated using the Zipkin API. First, get the service information. <markup lang=\"bash\" title=\"Run the curl command and check the response:\" >curl http://localhost:9411/api/v2/services ... [\"helidon-se-1\"] This is the tracing service name specified in resources/application.yaml . Each span used by a service has a name, which is unique within a trace. If you invoke the /greet endpoint multiple times, you will still get the same set of names. <markup lang=\"bash\" title=\"Invoke the endpoint below and check the response:\" > curl -X GET \"http://localhost:9411/api/v2/spans?serviceName=helidon-se-1\" -H \"accept: application/json\" ... [ \"content-write\", \"getdefaultmessagehandler\", \"http request\" ] Get the span names for the helidon-se-1 service. These are the span names. If you invoke the /greet endpoint again, then invoke the /spans endpoint, you will get the same response. Next, get the spans in the trace as shown below. <markup lang=\"bash\" title=\"Invoke the endpoint below and check the response:\" > curl -X GET \"http://localhost:9411/api/v2/traces?serviceName=helidon-se-1&amp;limit=1\" -H \"accept: application/json\" ... [ [ { \"traceId\": \"f193adb3f2bab3b3\", \"parentId\": \"f193adb3f2bab3b3\", \"id\": \"1536021daf3845e1\", \"kind\": \"SERVER\", \"name\": \"content-write\", \"timestamp\": 1568245972222815, \"duration\": 527, \"localEndpoint\": { \"serviceName\": \"helidon-se-1\", \"ipv4\": \"192.168.1.115\" }, \"tags\": { \"response.type\": \"org.glassfish.json.JsonObjectBuilderImpl$JsonObjectImpl\" } }, ... (truncated) ] Get the newest trace only, using the limit=1 query param. There are other query params that let you restrict results to a specific time window. The request will return 3 spans, one for each name. Each span has a parentId field, except the http request span, which is the root. Viewing Tracing Using Zipkin UI The tracing output data is verbose and can be difficult to interpret using the REST API, especially since it represents a structure of spans. Zipkin provides a web-based UI at http://localhost:9411/zipkin , where you can see a visual representation of the same data and the relationship between spans within a trace. Click on the UI refresh button (the search icon) as shown in the image below. Notice that you can change the look-back time to restrict the trace list. Trace refresh The image below shows the trace summary, including start time and duration of each trace. There are two traces, each one generated in response to a curl http://localhost:8080/greet invocation. The oldest trace will have a much longer duration since there is one-time initialization that occurs. Tracing list view Click on a trace and you will see the trace detail page where the spans are listed. You can clearly see the root span and the relationship among all the spans in the trace, along with timing information. Trace detail page A parent span might not depend on the result of the child. This is called a FollowsFrom reference, see Open Tracing Semantic Spec . You can examine span details by clicking on the span row. Refer to the image below, which shows the span details, including timing information. You can see times for each space relative to the root span. These rows are annotated with Server Start and Server Finish , as shown in the third column. Span detail page Tracing Across Services Helidon automatically traces across services, providing that the services use the same tracer, for example, the same instance of Zipkin. This means a single trace can include spans from multiple services and hosts. OpenTracing uses a SpanContext to propagate tracing information across process boundaries. When you make client API calls, Helidon will internally call OpenTracing APIs to propagate the SpanContext . There is nothing you need to do in your application to make this work. To demonstrate distributed tracing, you will need to create a second project, where the server listens on port 8081. Create a new root directory to hold this new project, then do the following steps, similar to what you did at the start of this guide: Create the Second Service <markup lang=\"bash\" title=\"Run the Maven archetype:\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-se \\ -DarchetypeVersion=3.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-se-2 \\ -Dpackage=io.helidon.examples.quickstart.se <markup lang=\"bash\" title=\"The project will be built and run from the helidon-quickstart-se directory:\" >cd helidon-quickstart-se-2 <markup lang=\"xml\" title=\"Add the following dependency to pom.xml :\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-zipkin&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"bash\" title=\"Replace resources/application.yaml with the following:\" >app: greeting: \"Hello From SE-2\" tracing: service: \"helidon-se-2\" server: port: 8081 host: 0.0.0.0 <markup lang=\"java\" title=\"Update the Main class; Add Tracer to the WebServer builder\" >import io.helidon.tracing.TracerBuilder; ... WebServer server = WebServer.builder(createRouting(config)) .config(config.get(\"server\")) .tracer(TracerBuilder.create(config.get(\"tracing\")).build()) .addMediaSupport(JsonpSupport.create()) .build(); <markup lang=\"java\" title=\"Update the GreetService class; 1) Add new import and 2) Replace the getDefaultMessageHandler method:\" >import io.opentracing.Span; //... private void getDefaultMessageHandler(ServerRequest request, ServerResponse response) { var spanBuilder = request.tracer() .buildSpan(\"getDefaultMessageHandler\"); request.spanContext().ifPresent(spanBuilder::asChildOf); Span span = spanBuilder.start(); try { sendResponse(response, \"World\"); } finally { span.finish(); } } <markup lang=\"bash\" title=\"Build the application, skipping unit tests, then run it:\" >mvn package -DskipTests=true java -jar target/helidon-quickstart-se-2.jar <markup lang=\"bash\" title=\"Run the curl command in a new terminal window and check the response ( notice the port is 8081 ) :\" >curl http://localhost:8081/greet ... { \"message\": \"Hello From SE-2 World!\" } Modify the First Service Once you have validated that the second service is running correctly, you need to modify the original application to call it. <markup lang=\"xml\" title=\"Add the following dependency to pom.xml :\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.integration&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-integration-jersey&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-jersey-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.glassfish.jersey.core&lt;/groupId&gt; &lt;artifactId&gt;jersey-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.glassfish.jersey.inject&lt;/groupId&gt; &lt;artifactId&gt;jersey-hk2&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"java\" title=\"Replace the GreetService class with the following code:\" >package io.helidon.examples.quickstart.se; import io.helidon.common.http.Http; import io.helidon.config.Config; import io.helidon.tracing.jersey.client.ClientTracingFilter; import io.helidon.webserver.Routing; import io.helidon.webserver.ServerRequest; import io.helidon.webserver.ServerResponse; import io.helidon.webserver.Service; import io.opentracing.Span; import java.util.Collections; import java.util.concurrent.atomic.AtomicReference; import jakarta.json.Json; import jakarta.json.JsonBuilderFactory; import jakarta.json.JsonObject; import jakarta.ws.rs.client.Client; import jakarta.ws.rs.client.ClientBuilder; import jakarta.ws.rs.client.Invocation; import jakarta.ws.rs.client.WebTarget; public class GreetService implements Service { private final AtomicReference&lt;String&gt; greeting = new AtomicReference&lt;&gt;(); private WebTarget webTarget; private static final JsonBuilderFactory JSON = Json.createBuilderFactory(Collections.emptyMap()); GreetService(Config config) { greeting.set(config.get(\"app.greeting\").asString().orElse(\"Ciao\")); Client jaxRsClient = ClientBuilder.newBuilder().build(); webTarget = jaxRsClient.target(\"http://localhost:8081/greet\"); } @Override public void update(Routing.Rules rules) { rules .get(\"/\", this::getDefaultMessageHandler) .get(\"/outbound\", this::outboundMessageHandler) .put(\"/greeting\", this::updateGreetingHandler); } private void getDefaultMessageHandler(ServerRequest request, ServerResponse response) { var spanBuilder = request.tracer() .buildSpan(\"getDefaultMessageHandler\"); request.spanContext().ifPresent(spanBuilder::asChildOf); Span span = spanBuilder.start(); try { sendResponse(response, \"World\"); } finally { span.finish(); } } private void sendResponse(ServerResponse response, String name) { String msg = String.format(\"%s %s!\", greeting.get(), name); JsonObject returnObject = JSON.createObjectBuilder().add(\"message\", msg).build(); response.send(returnObject); } private void updateGreetingFromJson(JsonObject jo, ServerResponse response) { if (!jo.containsKey(\"greeting\")) { JsonObject jsonErrorObject = JSON.createObjectBuilder().add(\"error\", \"No greeting provided\").build(); response.status(Http.Status.BAD_REQUEST_400).send(jsonErrorObject); return; } greeting.set(jo.getString(\"greeting\")); response.status(Http.Status.NO_CONTENT_204).send(); } private void outboundMessageHandler(ServerRequest request, ServerResponse response) { Invocation.Builder requestBuilder = webTarget.request(); var spanBuilder = request.tracer() .buildSpan(\"outboundMessageHandler\"); request.spanContext().ifPresent(spanBuilder::asChildOf); Span span = spanBuilder.start(); try { requestBuilder.property( ClientTracingFilter.CURRENT_SPAN_CONTEXT_PROPERTY_NAME, request.spanContext()); requestBuilder .rx() .get(String.class) .thenAccept(response::send) .exceptionally( throwable -&gt; { // process exception response.status(Http.Status.INTERNAL_SERVER_ERROR_500); response.send(\"Failed with: \" + throwable); return null; }); } finally { span.finish(); } } private void updateGreetingHandler(ServerRequest request, ServerResponse response) { request.content().as(JsonObject.class).thenAccept(jo -&gt; updateGreetingFromJson(jo, response)); } } Add outboundMessageHandler to the routing rules. Create and start a span that is a child of the current span. Set a property with the SpanContext . Invoke the second service. Stop the span. <markup lang=\"bash\" title=\"Build and run the application, then invoke the endpoint and check the response:\" >curl -i http://localhost:8080/greet/outbound ... { \"message\": \"Hello From SE-2 World!\" } The request went to the service on 8080 , which then invoked the service at 8081 to get the greeting. Notice the greeting came from the second service. Refresh the Zipkin UI trace listing page and notice that there is a trace across two services. Tracing multiple service list view Click on the trace with two services to see the detail view. Tracing across multiple services detail view In the image above, you can see that the trace includes spans from two services. You will notice there is a gap before the sixth span, which is a get operation. This is a one-time client initialization delay. Run the /outbound curl command again and look at the new trace to see that the delay no longer exists. You can now stop your second service, it is not longer used in this guide. ",
            "title": "Getting Started with Tracing"
        },
        {
            "location": "se/guides/tracing",
            "text": "<markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named zipkin.yaml , with the following contents:\" >apiVersion: v1 kind: Service metadata: name: zipkin spec: ports: - port: 9411 protocol: TCP selector: app: zipkin --- kind: Pod apiVersion: v1 metadata: name: zipkin labels: app: zipkin spec: containers: - name: zipkin image: openzipkin/zipkin imagePullPolicy: IfNotPresent ports: - containerPort: 9411 <markup lang=\"bash\" title=\"Create the Zipkin pod and ClusterIP service:\" >kubectl apply -f ./zipkin.yaml <markup lang=\"bash\" title=\"Create a Zipkin external server to view the UI and expose it on port 9142:\" >kubectl expose pod zipkin --name=zipkin-external --port=9412 --target-port=9411 --type=LoadBalancer Navigate to http://localhost:9412/zipkin to validate that you can access Zipkin running in Kubernetes. It may take a few seconds before it is ready. ",
            "title": "Deploy Zipkin into Kubernetes"
        },
        {
            "location": "se/guides/tracing",
            "text": "<markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named tracing.yaml , with the following contents:\" >kind: Service apiVersion: v1 metadata: name: helidon-tracing labels: app: helidon-tracing spec: type: NodePort selector: app: helidon-tracing ports: - port: 8080 targetPort: 8080 name: http --- kind: Deployment apiVersion: apps/v1 metadata: name: helidon-tracing spec: replicas: 1 selector: matchLabels: app: helidon-tracing template: metadata: labels: app: helidon-tracing version: v1 spec: containers: - name: helidon-tracing image: helidon-tracing-se imagePullPolicy: IfNotPresent ports: - containerPort: 8080 A service of type NodePort that serves the default routes on port 8080 . A deployment with one replica of a pod. <markup lang=\"bash\" title=\"Create and deploy the application into Kubernetes:\" >kubectl apply -f ./tracing.yaml ",
            "title": "Deploy Your Helidon Application into Kubernetes"
        },
        {
            "location": "se/guides/tracing",
            "text": "<markup lang=\"bash\" title=\"Get the application service information:\" >kubectl get service/helidon-tracing <markup lang=\"bash\" >NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE helidon-tracing NodePort 10.99.159.2 &lt;none&gt; 8080:31143/TCP 8s A service of type NodePort that serves the default routes on port 31143 . <markup lang=\"bash\" title=\"Verify the tracing endpoint using port 31143 , your port will likely be different:\" >curl http://localhost:31143/greet ... { \"message\": \"Hello World!\" } Access the Zipkin UI at http://localhost:9412/zipkin and click on the refresh icon to see the trace that was just created. ",
            "title": "Access Your Application and the Zipkin Trace"
        },
        {
            "location": "se/guides/tracing",
            "text": " You can now delete the Kubernetes resources that were just created during this example. <markup lang=\"bash\" title=\"Delete the Kubernetes resources:\" >kubectl delete -f ./zipkin.yaml kubectl delete -f ./tracing.yaml kubectl delete service zipkin-external docker rm -f zipkin ",
            "title": "Cleanup"
        },
        {
            "location": "se/guides/tracing",
            "text": " The following example demonstrate how to use Zipkin from a Helidon application running in Kubernetes. <markup lang=\"bash\" title=\"Replace the tracing configuration in resources/application.yaml with the following:\" > tracing: service: helidon-se-1 host: zipkin Helidon service helidon-se-1 will connect to the Zipkin server at host name zipkin . <markup lang=\"bash\" title=\"Stop the application and build the docker image for your application:\" >docker build -t helidon-tracing-se . Deploy Zipkin into Kubernetes <markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named zipkin.yaml , with the following contents:\" >apiVersion: v1 kind: Service metadata: name: zipkin spec: ports: - port: 9411 protocol: TCP selector: app: zipkin --- kind: Pod apiVersion: v1 metadata: name: zipkin labels: app: zipkin spec: containers: - name: zipkin image: openzipkin/zipkin imagePullPolicy: IfNotPresent ports: - containerPort: 9411 <markup lang=\"bash\" title=\"Create the Zipkin pod and ClusterIP service:\" >kubectl apply -f ./zipkin.yaml <markup lang=\"bash\" title=\"Create a Zipkin external server to view the UI and expose it on port 9142:\" >kubectl expose pod zipkin --name=zipkin-external --port=9412 --target-port=9411 --type=LoadBalancer Navigate to http://localhost:9412/zipkin to validate that you can access Zipkin running in Kubernetes. It may take a few seconds before it is ready. Deploy Your Helidon Application into Kubernetes <markup lang=\"yaml\" title=\"Create the Kubernetes YAML specification, named tracing.yaml , with the following contents:\" >kind: Service apiVersion: v1 metadata: name: helidon-tracing labels: app: helidon-tracing spec: type: NodePort selector: app: helidon-tracing ports: - port: 8080 targetPort: 8080 name: http --- kind: Deployment apiVersion: apps/v1 metadata: name: helidon-tracing spec: replicas: 1 selector: matchLabels: app: helidon-tracing template: metadata: labels: app: helidon-tracing version: v1 spec: containers: - name: helidon-tracing image: helidon-tracing-se imagePullPolicy: IfNotPresent ports: - containerPort: 8080 A service of type NodePort that serves the default routes on port 8080 . A deployment with one replica of a pod. <markup lang=\"bash\" title=\"Create and deploy the application into Kubernetes:\" >kubectl apply -f ./tracing.yaml Access Your Application and the Zipkin Trace <markup lang=\"bash\" title=\"Get the application service information:\" >kubectl get service/helidon-tracing <markup lang=\"bash\" >NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE helidon-tracing NodePort 10.99.159.2 &lt;none&gt; 8080:31143/TCP 8s A service of type NodePort that serves the default routes on port 31143 . <markup lang=\"bash\" title=\"Verify the tracing endpoint using port 31143 , your port will likely be different:\" >curl http://localhost:31143/greet ... { \"message\": \"Hello World!\" } Access the Zipkin UI at http://localhost:9412/zipkin and click on the refresh icon to see the trace that was just created. Cleanup You can now delete the Kubernetes resources that were just created during this example. <markup lang=\"bash\" title=\"Delete the Kubernetes resources:\" >kubectl delete -f ./zipkin.yaml kubectl delete -f ./tracing.yaml kubectl delete service zipkin-external docker rm -f zipkin ",
            "title": "Integration with Kubernetes"
        },
        {
            "location": "se/guides/tracing",
            "text": " This guide has demonstrated how to use the Helidon SE tracing feature with Zipkin. You have learned to do the following: Enable tracing within a service Use tracing with JAX-RS Use the Zipkin REST API and UI Use tracing across multiple services Integrate tracing with Kubernetes Refer to the following references for additional information: MicroProfile OpenTracing specification MicroProfile OpenTracing Javadoc Helidon Javadoc ",
            "title": "Summary"
        },
        {
            "location": "se/guides/webclient",
            "text": " This guide describes how to create a sample Helidon SE project that can be used to run some basic examples using WebClient. ",
            "title": "preambule"
        },
        {
            "location": "se/guides/webclient",
            "text": " Helidon&#8217;s WebClient is used to perform HTTP REST requests to target endpoints and handle their responses. Built on top of a reactive approach, you are no longer blocked while waiting for the data. Note : WebClient is still experimental and not intended for production use. APIs and features are not yet fully tested and are subject to change. WebClient provides the following features: Reactive : As mentioned, the code execution is not blocked by waiting for server response when a request is performed. To avoid memory overflow, the client has built-in back-pressure support. User-friendly : Every client and request is created by a builder pattern, so it improves readability and code maintenance. Following redirects : The WebClient is able to follow the redirect chain and perform requests on the correct endpoint for you. You no longer have to point your client to the correct/final endpoint. Tracing, metrics and security propagation : When you configure the Helidon WebServer to use tracing, metrics and security, the settings are automatically propagated to the WebClient and used during request/response. ",
            "title": "WebClient Features"
        },
        {
            "location": "se/guides/webclient",
            "text": " Generate the project sources using the Helidon SE Maven archetype. The result is a simple project that can be used for the examples in this guide. <markup lang=\"bash\" title=\"Run the Maven archetype:\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-se \\ -DarchetypeVersion=3.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-se \\ -Dpackage=io.helidon.examples.quickstart.se You should now have a directory called helidon-quickstart-se . <markup lang=\"bash\" title=\"Open this directory\" >cd helidon-quickstart-se The Helidon quickstart is a greeting application supporting several HTTP requests such as GET and PUT. Using it will be time saving and allow us to focus on the WebClient features and how to use it. ",
            "title": "Create a sample SE project"
        },
        {
            "location": "se/guides/webclient",
            "text": " In the pom.xml, remove the test scope under the WebClient dependency as it will be used not only in the tests. <markup lang=\"xml\" title=\"Remove test scope:\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-webclient&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;!-- Remove this line --&gt; &lt;/dependency&gt; ",
            "title": "Modify pom dependency"
        },
        {
            "location": "se/guides/webclient",
            "text": " In io.helidon.examples.quickstart.se package, create a new class named ClientExample. This class will use the WebClient to send request to the greeting application. <markup lang=\"java\" title=\"Create ClientExample class:\" >package io.helidon.examples.quickstart.se; public class ClientExample { public static void main(String[] args) { } } Add the following code to create a WebClient instance. The builder approach allows you to create the WebClient with specific settings and improves the readability and simplicity of the code. <markup lang=\"java\" title=\"Add WebClient instance to the main method:\" >import io.helidon.media.jsonp.JsonpSupport; import io.helidon.webclient.WebClient; WebClient webClient = WebClient.builder() .baseUri(\"http://localhost:8080\") .addMediaSupport(JsonpSupport.create()) .build(); The base URI of the outbound requests. Register a support for Jsonp. By default, the Helidon quickstart application runs on localhost:8080. If you changed the host name or port number make sure to modify the base URI as well. Once built, the WebClient can be used to send a GET request to the greeting application. <markup lang=\"java\" title=\"Send a GET request to the target endpoint:\" >webClient.get() .path(\"/greet\") .request(String.class) .peek(System.out::println) .await(); Create a HTTP GET request. Target endpoint path. Execute the request and return Single with response entity handled as a String. Print the response in the console. Wait for server response because of reactive approach. The path method joins /greet to the WebClient base URI. The target URI for this request becomes http://localhost:8080/greet where the response should be a greeting message. Received response entity will be automatically handled as a String. If no specific type is put into the method request(), WebClientResponse is returned by default. This WebClientResponse object contains response code, headers and non-handled entity. ",
            "title": "Add ClientExample class"
        },
        {
            "location": "se/guides/webclient",
            "text": "<markup lang=\"bash\" title=\"Build the quickstart:\" >mvn package This command will create helidon-quickstart-se.jar in the target folder. <markup lang=\"bash\" title=\"Run the greeting application first:\" >java -cp target/helidon-quickstart-se.jar io.helidon.examples.quickstart.se.Main Open a new command prompt or terminal and run the ClientExample class you just created. <markup lang=\"bash\" title=\"Run the greeting application first:\" >java -cp target/helidon-quickstart-se.jar io.helidon.examples.quickstart.se.ClientExample <markup lang=\"bash\" title=\"Output:\" >{\"message\":\"Hello World!\"} When the ClientExample finishes its execution, you can stop the Main class by pressing ctrl+c . ",
            "title": "Run the application"
        },
        {
            "location": "se/guides/webclient",
            "text": " In practice, String is not the most useful return type, since it usually needs some more handling. In this case it could be more interesting to return an object such as JsonObject. In the previous step JSON support was added to the WebClient so that it could be used instead of String. <markup lang=\"java\" title=\"Replace String by JsonObject:\" >import javax.json.JsonObject; webClient.get() .path(\"/greet/David\") .request(JsonObject.class) .peek(System.out::println) .await(); Request a JsonObject as return value. In the URI, the String following greet is a path parameter which allows the application to greet someone. <markup lang=\"bash\" title=\"Output:\" >{\"message\":\"Hello David!\"} This time, a JsonObject is printed out in the console. It is possible to change the greeting itself by using a PUT request to /greet/greeting endpoint from the base URI. <markup lang=\"java\" title=\"Modify the application greeting:\" >import javax.json.Json; JsonObject entity = Json.createObjectBuilder() .add(\"greeting\", \"Bonjour\") .build(); webClient.put() .path(\"/greet/greeting\") .submit(entity) .thenCompose(response -&gt; webClient.get() .path(\"/greet/David\") .request(JsonObject.class)) .thenAccept(System.out::println) .await(); Create a JsonObject with key greeting and value bonjour . Create a PUT request. Submit the JsonObject created earlier. Once done, make a GET call to verify the modification was processed to the greeting. According to the quickstart documentation, a JSON object can be sent to the application to change the greeting following this structure: {\"greeting\" : \"value\"} . The first three lines of code create the JsonObject with the required content. This time, we use the PUT request and submit methods to push the new greeting. One way to check the greeting modification is to execute GET request again and display obtained response. The thenCompose method will execute a GET request after the PUT request is executed. <markup lang=\"bash\" title=\"Output:\" >{\"message\":\"Bonjour David!\"} ",
            "title": "Discover other WebClient functionality"
        },
        {
            "location": "se/guides/webclient",
            "text": " Create a sample SE project Generate the project sources using the Helidon SE Maven archetype. The result is a simple project that can be used for the examples in this guide. <markup lang=\"bash\" title=\"Run the Maven archetype:\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-se \\ -DarchetypeVersion=3.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-se \\ -Dpackage=io.helidon.examples.quickstart.se You should now have a directory called helidon-quickstart-se . <markup lang=\"bash\" title=\"Open this directory\" >cd helidon-quickstart-se The Helidon quickstart is a greeting application supporting several HTTP requests such as GET and PUT. Using it will be time saving and allow us to focus on the WebClient features and how to use it. Modify pom dependency In the pom.xml, remove the test scope under the WebClient dependency as it will be used not only in the tests. <markup lang=\"xml\" title=\"Remove test scope:\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-webclient&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;!-- Remove this line --&gt; &lt;/dependency&gt; Add ClientExample class In io.helidon.examples.quickstart.se package, create a new class named ClientExample. This class will use the WebClient to send request to the greeting application. <markup lang=\"java\" title=\"Create ClientExample class:\" >package io.helidon.examples.quickstart.se; public class ClientExample { public static void main(String[] args) { } } Add the following code to create a WebClient instance. The builder approach allows you to create the WebClient with specific settings and improves the readability and simplicity of the code. <markup lang=\"java\" title=\"Add WebClient instance to the main method:\" >import io.helidon.media.jsonp.JsonpSupport; import io.helidon.webclient.WebClient; WebClient webClient = WebClient.builder() .baseUri(\"http://localhost:8080\") .addMediaSupport(JsonpSupport.create()) .build(); The base URI of the outbound requests. Register a support for Jsonp. By default, the Helidon quickstart application runs on localhost:8080. If you changed the host name or port number make sure to modify the base URI as well. Once built, the WebClient can be used to send a GET request to the greeting application. <markup lang=\"java\" title=\"Send a GET request to the target endpoint:\" >webClient.get() .path(\"/greet\") .request(String.class) .peek(System.out::println) .await(); Create a HTTP GET request. Target endpoint path. Execute the request and return Single with response entity handled as a String. Print the response in the console. Wait for server response because of reactive approach. The path method joins /greet to the WebClient base URI. The target URI for this request becomes http://localhost:8080/greet where the response should be a greeting message. Received response entity will be automatically handled as a String. If no specific type is put into the method request(), WebClientResponse is returned by default. This WebClientResponse object contains response code, headers and non-handled entity. Run the application <markup lang=\"bash\" title=\"Build the quickstart:\" >mvn package This command will create helidon-quickstart-se.jar in the target folder. <markup lang=\"bash\" title=\"Run the greeting application first:\" >java -cp target/helidon-quickstart-se.jar io.helidon.examples.quickstart.se.Main Open a new command prompt or terminal and run the ClientExample class you just created. <markup lang=\"bash\" title=\"Run the greeting application first:\" >java -cp target/helidon-quickstart-se.jar io.helidon.examples.quickstart.se.ClientExample <markup lang=\"bash\" title=\"Output:\" >{\"message\":\"Hello World!\"} When the ClientExample finishes its execution, you can stop the Main class by pressing ctrl+c . Discover other WebClient functionality In practice, String is not the most useful return type, since it usually needs some more handling. In this case it could be more interesting to return an object such as JsonObject. In the previous step JSON support was added to the WebClient so that it could be used instead of String. <markup lang=\"java\" title=\"Replace String by JsonObject:\" >import javax.json.JsonObject; webClient.get() .path(\"/greet/David\") .request(JsonObject.class) .peek(System.out::println) .await(); Request a JsonObject as return value. In the URI, the String following greet is a path parameter which allows the application to greet someone. <markup lang=\"bash\" title=\"Output:\" >{\"message\":\"Hello David!\"} This time, a JsonObject is printed out in the console. It is possible to change the greeting itself by using a PUT request to /greet/greeting endpoint from the base URI. <markup lang=\"java\" title=\"Modify the application greeting:\" >import javax.json.Json; JsonObject entity = Json.createObjectBuilder() .add(\"greeting\", \"Bonjour\") .build(); webClient.put() .path(\"/greet/greeting\") .submit(entity) .thenCompose(response -&gt; webClient.get() .path(\"/greet/David\") .request(JsonObject.class)) .thenAccept(System.out::println) .await(); Create a JsonObject with key greeting and value bonjour . Create a PUT request. Submit the JsonObject created earlier. Once done, make a GET call to verify the modification was processed to the greeting. According to the quickstart documentation, a JSON object can be sent to the application to change the greeting following this structure: {\"greeting\" : \"value\"} . The first three lines of code create the JsonObject with the required content. This time, we use the PUT request and submit methods to push the new greeting. One way to check the greeting modification is to execute GET request again and display obtained response. The thenCompose method will execute a GET request after the PUT request is executed. <markup lang=\"bash\" title=\"Output:\" >{\"message\":\"Bonjour David!\"} ",
            "title": "WebClient Usage"
        },
        {
            "location": "se/guides/webclient",
            "text": " There is a specific dependency to use WebClient metrics in your application. <markup lang=\"xml\" title=\"Add the following dependency to pom.xml:\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-webclient-metrics&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Add metrics dependency"
        },
        {
            "location": "se/guides/webclient",
            "text": " It is possible to register metrics on WebClient directly into the code. The following example shows a general method that can be used with any metric. <markup lang=\"java\" title=\"Example of metric creation:\" >import io.helidon.common.http.Http; import io.helidon.metrics.RegistryFactory; import io.helidon.webclient.metrics.WebClientMetrics; import io.helidon.webclient.spi.WebClientService; import org.eclipse.microprofile.metrics.MetricRegistry; import org.eclipse.microprofile.metrics|.Counter; |.Meter; |.Timer; |.ConcurrentGauge; public static void main(String[] args) { MetricRegistry metricFactory = RegistryFactory.getInstance() .getRegistry(MetricRegistry.Type.APPLICATION); String metricName = \"metric.GET.localhost\"; Counter counter = metricFactory|.counter(metricName); |.meter(metricName) |.timer(metricName) |.concurrentGauge(metricName) WebClientService clientServiceMetric = WebClientMetrics|.counter() |.meter() |.timer() |.gaugeInProgress() .methods(Http.Method.GET) // OPTIONAL .success(true) // OPTIONAL .errors(true) // OPTIONAL .description(\"Metric Description\") // OPTIONAL .nameFormat(\"counter.%1$s.%2$s\") .build(); Choose the metric name. Create a metric from metricFactory . Build a WebClient Service for counting the GET requests. The metric name can indicate what is measured. In this example, the metric target GET requests on the localhost. In order to pass this information to the webclient, the nameFormat method extracts it from the metric name. Otherwise, the metric name can also have nothing in common with its job. In this case, the methods with OPTIONAL comment are not required to be used. The methods will target the chosen HTTP request type. While success and error will respectively measure if a request is successful or failed. The description will add a metric description. <markup lang=\"java\" title=\"Add the metric service to the WebClient:\" >WebClient webClient = WebClient.builder() .baseUri(\"http://localhost:8080\") .addMediaSupport(JsonpSupport.create()) .addService(clientServiceMetric) .build(); Register the metric service to the webclient. Simply use the addService method to add the metric to the WebClient on which the metrics will be measured. <markup lang=\"java\" title=\"Print the metric count at the end of the main method:\" >System.out.println(metricName + \": \" + counter.getCount()); To quickly check metrics are set up correctly, print the counter at the end of the main method. In this guide, the WebClient uses GET and PUT requests, so metrics can be applied on. ",
            "title": "Set up metrics on WebClient instance"
        },
        {
            "location": "se/guides/webclient",
            "text": " Using the configuration file can reduce the code complexity and make the metrics simpler to use. There is no need to modify the source code but only the configuration file to measure other values. The application.yaml file is the default configuration file for Helidon. It can be used to set up metrics settings. <markup lang=\"yaml\" title=\"Example of metric configuration:\" >client: services: config: metrics: - type: METER name-format: \"client.meter.overall\" - type: TIMER # meter per method name-format: \"client.meter.%1$s\" - methods: [\"GET\"] type: COUNTER errors: false name-format: \"client.counter.%1$s.success\" description: \"Counter of successful GET requests\" - methods: [\"PUT\", \"POST\", \"DELETE\"] type: COUNTER success: false name-format: \"wc.counter.%1$s.error\" description: \"Counter of failed PUT, POST and DELETE requests\" - methods: [\"GET\"] type: GAUGE_IN_PROGRESS name-format: \"client.inprogress.%2$s\" description: \"In progress requests to host\" The metrics are located under client.services.config.metrics . The metric setting can start either by its type or methods. The configuration file uses the same keywords as the programmatic way. type defines the kind of metric. <markup lang=\"java\" title=\"Add the metric service to the WebClient:\" >Config config = Config.create(); WebClient webClient = WebClient.builder() .baseUri(\"http://localhost:8080\") .config(config.get(\"client\")) .addMediaSupport(JsonpSupport.create()) .build(); Create a Helidon Config instance from default file application.yaml . Configure the WebClient with the client section from application.yaml . As demonstrated, using the configuration file reduces the amount of code needed in the source code. For more information about metrics, see the Helidon Metrics Guide . ",
            "title": "Set up metrics with configuration files"
        },
        {
            "location": "se/guides/webclient",
            "text": " WebClient, like other Helidon components, supports Metrics. The following example introduces the different metrics that can be used to measure WebClient activity. There are two ways to set up metrics: programmatically on the WebClient instance or manually using the configuration file. Add metrics dependency There is a specific dependency to use WebClient metrics in your application. <markup lang=\"xml\" title=\"Add the following dependency to pom.xml:\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-webclient-metrics&lt;/artifactId&gt; &lt;/dependency&gt; Set up metrics on WebClient instance It is possible to register metrics on WebClient directly into the code. The following example shows a general method that can be used with any metric. <markup lang=\"java\" title=\"Example of metric creation:\" >import io.helidon.common.http.Http; import io.helidon.metrics.RegistryFactory; import io.helidon.webclient.metrics.WebClientMetrics; import io.helidon.webclient.spi.WebClientService; import org.eclipse.microprofile.metrics.MetricRegistry; import org.eclipse.microprofile.metrics|.Counter; |.Meter; |.Timer; |.ConcurrentGauge; public static void main(String[] args) { MetricRegistry metricFactory = RegistryFactory.getInstance() .getRegistry(MetricRegistry.Type.APPLICATION); String metricName = \"metric.GET.localhost\"; Counter counter = metricFactory|.counter(metricName); |.meter(metricName) |.timer(metricName) |.concurrentGauge(metricName) WebClientService clientServiceMetric = WebClientMetrics|.counter() |.meter() |.timer() |.gaugeInProgress() .methods(Http.Method.GET) // OPTIONAL .success(true) // OPTIONAL .errors(true) // OPTIONAL .description(\"Metric Description\") // OPTIONAL .nameFormat(\"counter.%1$s.%2$s\") .build(); Choose the metric name. Create a metric from metricFactory . Build a WebClient Service for counting the GET requests. The metric name can indicate what is measured. In this example, the metric target GET requests on the localhost. In order to pass this information to the webclient, the nameFormat method extracts it from the metric name. Otherwise, the metric name can also have nothing in common with its job. In this case, the methods with OPTIONAL comment are not required to be used. The methods will target the chosen HTTP request type. While success and error will respectively measure if a request is successful or failed. The description will add a metric description. <markup lang=\"java\" title=\"Add the metric service to the WebClient:\" >WebClient webClient = WebClient.builder() .baseUri(\"http://localhost:8080\") .addMediaSupport(JsonpSupport.create()) .addService(clientServiceMetric) .build(); Register the metric service to the webclient. Simply use the addService method to add the metric to the WebClient on which the metrics will be measured. <markup lang=\"java\" title=\"Print the metric count at the end of the main method:\" >System.out.println(metricName + \": \" + counter.getCount()); To quickly check metrics are set up correctly, print the counter at the end of the main method. In this guide, the WebClient uses GET and PUT requests, so metrics can be applied on. Set up metrics with configuration files Using the configuration file can reduce the code complexity and make the metrics simpler to use. There is no need to modify the source code but only the configuration file to measure other values. The application.yaml file is the default configuration file for Helidon. It can be used to set up metrics settings. <markup lang=\"yaml\" title=\"Example of metric configuration:\" >client: services: config: metrics: - type: METER name-format: \"client.meter.overall\" - type: TIMER # meter per method name-format: \"client.meter.%1$s\" - methods: [\"GET\"] type: COUNTER errors: false name-format: \"client.counter.%1$s.success\" description: \"Counter of successful GET requests\" - methods: [\"PUT\", \"POST\", \"DELETE\"] type: COUNTER success: false name-format: \"wc.counter.%1$s.error\" description: \"Counter of failed PUT, POST and DELETE requests\" - methods: [\"GET\"] type: GAUGE_IN_PROGRESS name-format: \"client.inprogress.%2$s\" description: \"In progress requests to host\" The metrics are located under client.services.config.metrics . The metric setting can start either by its type or methods. The configuration file uses the same keywords as the programmatic way. type defines the kind of metric. <markup lang=\"java\" title=\"Add the metric service to the WebClient:\" >Config config = Config.create(); WebClient webClient = WebClient.builder() .baseUri(\"http://localhost:8080\") .config(config.get(\"client\")) .addMediaSupport(JsonpSupport.create()) .build(); Create a Helidon Config instance from default file application.yaml . Configure the WebClient with the client section from application.yaml . As demonstrated, using the configuration file reduces the amount of code needed in the source code. For more information about metrics, see the Helidon Metrics Guide . ",
            "title": "WebClient Metrics"
        },
        {
            "location": "se/guides/webclient",
            "text": " For this 15 minute tutorial, you will need the following: <div class=\"table__overflow elevation-1 flex sm7 \"> A Helidon SE Application You can use your own application or use the Helidon SE Quickstart to create a sample application. Java&#160;SE&#160;17 ( Open&#160;JDK&#160;17 ) Helidon requires Java 17+. Maven 3.6.1+ Helidon requires Maven 3.6.1+. Docker 18.09+ You need Docker if you want to build and deploy Docker containers. Kubectl 1.16.5+ If you want to deploy to Kubernetes, you need kubectl and a Kubernetes cluster (you can install one on your desktop . <markup lang=\"bash\" title=\"Verify Prerequisites\" >java -version mvn --version docker --version kubectl version --short <markup lang=\"bash\" title=\"Setting JAVA_HOME\" ># On Mac export JAVA_HOME=`/usr/libexec/java_home -v 17` # On Linux # Use the appropriate path to your JDK export JAVA_HOME=/usr/lib/jvm/jdk-17 WebClient features WebClient usage WebClient Metrics WebClient Features Helidon&#8217;s WebClient is used to perform HTTP REST requests to target endpoints and handle their responses. Built on top of a reactive approach, you are no longer blocked while waiting for the data. Note : WebClient is still experimental and not intended for production use. APIs and features are not yet fully tested and are subject to change. WebClient provides the following features: Reactive : As mentioned, the code execution is not blocked by waiting for server response when a request is performed. To avoid memory overflow, the client has built-in back-pressure support. User-friendly : Every client and request is created by a builder pattern, so it improves readability and code maintenance. Following redirects : The WebClient is able to follow the redirect chain and perform requests on the correct endpoint for you. You no longer have to point your client to the correct/final endpoint. Tracing, metrics and security propagation : When you configure the Helidon WebServer to use tracing, metrics and security, the settings are automatically propagated to the WebClient and used during request/response. WebClient Usage Create a sample SE project Generate the project sources using the Helidon SE Maven archetype. The result is a simple project that can be used for the examples in this guide. <markup lang=\"bash\" title=\"Run the Maven archetype:\" >mvn -U archetype:generate -DinteractiveMode=false \\ -DarchetypeGroupId=io.helidon.archetypes \\ -DarchetypeArtifactId=helidon-quickstart-se \\ -DarchetypeVersion=3.0.2 \\ -DgroupId=io.helidon.examples \\ -DartifactId=helidon-quickstart-se \\ -Dpackage=io.helidon.examples.quickstart.se You should now have a directory called helidon-quickstart-se . <markup lang=\"bash\" title=\"Open this directory\" >cd helidon-quickstart-se The Helidon quickstart is a greeting application supporting several HTTP requests such as GET and PUT. Using it will be time saving and allow us to focus on the WebClient features and how to use it. Modify pom dependency In the pom.xml, remove the test scope under the WebClient dependency as it will be used not only in the tests. <markup lang=\"xml\" title=\"Remove test scope:\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-webclient&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;!-- Remove this line --&gt; &lt;/dependency&gt; Add ClientExample class In io.helidon.examples.quickstart.se package, create a new class named ClientExample. This class will use the WebClient to send request to the greeting application. <markup lang=\"java\" title=\"Create ClientExample class:\" >package io.helidon.examples.quickstart.se; public class ClientExample { public static void main(String[] args) { } } Add the following code to create a WebClient instance. The builder approach allows you to create the WebClient with specific settings and improves the readability and simplicity of the code. <markup lang=\"java\" title=\"Add WebClient instance to the main method:\" >import io.helidon.media.jsonp.JsonpSupport; import io.helidon.webclient.WebClient; WebClient webClient = WebClient.builder() .baseUri(\"http://localhost:8080\") .addMediaSupport(JsonpSupport.create()) .build(); The base URI of the outbound requests. Register a support for Jsonp. By default, the Helidon quickstart application runs on localhost:8080. If you changed the host name or port number make sure to modify the base URI as well. Once built, the WebClient can be used to send a GET request to the greeting application. <markup lang=\"java\" title=\"Send a GET request to the target endpoint:\" >webClient.get() .path(\"/greet\") .request(String.class) .peek(System.out::println) .await(); Create a HTTP GET request. Target endpoint path. Execute the request and return Single with response entity handled as a String. Print the response in the console. Wait for server response because of reactive approach. The path method joins /greet to the WebClient base URI. The target URI for this request becomes http://localhost:8080/greet where the response should be a greeting message. Received response entity will be automatically handled as a String. If no specific type is put into the method request(), WebClientResponse is returned by default. This WebClientResponse object contains response code, headers and non-handled entity. Run the application <markup lang=\"bash\" title=\"Build the quickstart:\" >mvn package This command will create helidon-quickstart-se.jar in the target folder. <markup lang=\"bash\" title=\"Run the greeting application first:\" >java -cp target/helidon-quickstart-se.jar io.helidon.examples.quickstart.se.Main Open a new command prompt or terminal and run the ClientExample class you just created. <markup lang=\"bash\" title=\"Run the greeting application first:\" >java -cp target/helidon-quickstart-se.jar io.helidon.examples.quickstart.se.ClientExample <markup lang=\"bash\" title=\"Output:\" >{\"message\":\"Hello World!\"} When the ClientExample finishes its execution, you can stop the Main class by pressing ctrl+c . Discover other WebClient functionality In practice, String is not the most useful return type, since it usually needs some more handling. In this case it could be more interesting to return an object such as JsonObject. In the previous step JSON support was added to the WebClient so that it could be used instead of String. <markup lang=\"java\" title=\"Replace String by JsonObject:\" >import javax.json.JsonObject; webClient.get() .path(\"/greet/David\") .request(JsonObject.class) .peek(System.out::println) .await(); Request a JsonObject as return value. In the URI, the String following greet is a path parameter which allows the application to greet someone. <markup lang=\"bash\" title=\"Output:\" >{\"message\":\"Hello David!\"} This time, a JsonObject is printed out in the console. It is possible to change the greeting itself by using a PUT request to /greet/greeting endpoint from the base URI. <markup lang=\"java\" title=\"Modify the application greeting:\" >import javax.json.Json; JsonObject entity = Json.createObjectBuilder() .add(\"greeting\", \"Bonjour\") .build(); webClient.put() .path(\"/greet/greeting\") .submit(entity) .thenCompose(response -&gt; webClient.get() .path(\"/greet/David\") .request(JsonObject.class)) .thenAccept(System.out::println) .await(); Create a JsonObject with key greeting and value bonjour . Create a PUT request. Submit the JsonObject created earlier. Once done, make a GET call to verify the modification was processed to the greeting. According to the quickstart documentation, a JSON object can be sent to the application to change the greeting following this structure: {\"greeting\" : \"value\"} . The first three lines of code create the JsonObject with the required content. This time, we use the PUT request and submit methods to push the new greeting. One way to check the greeting modification is to execute GET request again and display obtained response. The thenCompose method will execute a GET request after the PUT request is executed. <markup lang=\"bash\" title=\"Output:\" >{\"message\":\"Bonjour David!\"} WebClient Metrics WebClient, like other Helidon components, supports Metrics. The following example introduces the different metrics that can be used to measure WebClient activity. There are two ways to set up metrics: programmatically on the WebClient instance or manually using the configuration file. Add metrics dependency There is a specific dependency to use WebClient metrics in your application. <markup lang=\"xml\" title=\"Add the following dependency to pom.xml:\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-webclient-metrics&lt;/artifactId&gt; &lt;/dependency&gt; Set up metrics on WebClient instance It is possible to register metrics on WebClient directly into the code. The following example shows a general method that can be used with any metric. <markup lang=\"java\" title=\"Example of metric creation:\" >import io.helidon.common.http.Http; import io.helidon.metrics.RegistryFactory; import io.helidon.webclient.metrics.WebClientMetrics; import io.helidon.webclient.spi.WebClientService; import org.eclipse.microprofile.metrics.MetricRegistry; import org.eclipse.microprofile.metrics|.Counter; |.Meter; |.Timer; |.ConcurrentGauge; public static void main(String[] args) { MetricRegistry metricFactory = RegistryFactory.getInstance() .getRegistry(MetricRegistry.Type.APPLICATION); String metricName = \"metric.GET.localhost\"; Counter counter = metricFactory|.counter(metricName); |.meter(metricName) |.timer(metricName) |.concurrentGauge(metricName) WebClientService clientServiceMetric = WebClientMetrics|.counter() |.meter() |.timer() |.gaugeInProgress() .methods(Http.Method.GET) // OPTIONAL .success(true) // OPTIONAL .errors(true) // OPTIONAL .description(\"Metric Description\") // OPTIONAL .nameFormat(\"counter.%1$s.%2$s\") .build(); Choose the metric name. Create a metric from metricFactory . Build a WebClient Service for counting the GET requests. The metric name can indicate what is measured. In this example, the metric target GET requests on the localhost. In order to pass this information to the webclient, the nameFormat method extracts it from the metric name. Otherwise, the metric name can also have nothing in common with its job. In this case, the methods with OPTIONAL comment are not required to be used. The methods will target the chosen HTTP request type. While success and error will respectively measure if a request is successful or failed. The description will add a metric description. <markup lang=\"java\" title=\"Add the metric service to the WebClient:\" >WebClient webClient = WebClient.builder() .baseUri(\"http://localhost:8080\") .addMediaSupport(JsonpSupport.create()) .addService(clientServiceMetric) .build(); Register the metric service to the webclient. Simply use the addService method to add the metric to the WebClient on which the metrics will be measured. <markup lang=\"java\" title=\"Print the metric count at the end of the main method:\" >System.out.println(metricName + \": \" + counter.getCount()); To quickly check metrics are set up correctly, print the counter at the end of the main method. In this guide, the WebClient uses GET and PUT requests, so metrics can be applied on. Set up metrics with configuration files Using the configuration file can reduce the code complexity and make the metrics simpler to use. There is no need to modify the source code but only the configuration file to measure other values. The application.yaml file is the default configuration file for Helidon. It can be used to set up metrics settings. <markup lang=\"yaml\" title=\"Example of metric configuration:\" >client: services: config: metrics: - type: METER name-format: \"client.meter.overall\" - type: TIMER # meter per method name-format: \"client.meter.%1$s\" - methods: [\"GET\"] type: COUNTER errors: false name-format: \"client.counter.%1$s.success\" description: \"Counter of successful GET requests\" - methods: [\"PUT\", \"POST\", \"DELETE\"] type: COUNTER success: false name-format: \"wc.counter.%1$s.error\" description: \"Counter of failed PUT, POST and DELETE requests\" - methods: [\"GET\"] type: GAUGE_IN_PROGRESS name-format: \"client.inprogress.%2$s\" description: \"In progress requests to host\" The metrics are located under client.services.config.metrics . The metric setting can start either by its type or methods. The configuration file uses the same keywords as the programmatic way. type defines the kind of metric. <markup lang=\"java\" title=\"Add the metric service to the WebClient:\" >Config config = Config.create(); WebClient webClient = WebClient.builder() .baseUri(\"http://localhost:8080\") .config(config.get(\"client\")) .addMediaSupport(JsonpSupport.create()) .build(); Create a Helidon Config instance from default file application.yaml . Configure the WebClient with the client section from application.yaml . As demonstrated, using the configuration file reduces the amount of code needed in the source code. For more information about metrics, see the Helidon Metrics Guide . ",
            "title": "What you need"
        },
        {
            "location": "se/health",
            "text": " Overview Maven Coordinates API Configuration Examples Additional Information ",
            "title": "Contents"
        },
        {
            "location": "se/health",
            "text": " It’s a good practice to monitor your microservice’s health, to ensure that it is available and performs correctly. Applications implement health checks to expose health status that is collected at regular intervals by external tooling, such as orchestrators like Kubernetes. The orchestrator may then take action, such as restarting your application if the health check fails. A typical health check combines the statuses of all the dependencies that affect availability and the ability to perform correctly: network latency storage database other services used by your application ",
            "title": "Overview"
        },
        {
            "location": "se/health",
            "text": " To enable Health Checks add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.health&lt;/groupId&gt; &lt;artifactId&gt;helidon-health&lt;/artifactId&gt; &lt;/dependency&gt; Optional dependency to use built-in health checks: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.health&lt;/groupId&gt; &lt;artifactId&gt;helidon-health-checks&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "se/health",
            "text": " You can use Helidon-provided health checks to report various common health check statuses: Built-in health check Health check name JavaDoc Config properties Default config value deadlock detection deadlock DeadlockHealthCheck n/a n/a available disk space diskSpace DiskSpaceHealthCheck helidon.healthCheck.diskSpace.thresholdPercent + helidon.healthCheck.diskSpace.path 99.999 + / available heap memory heapMemory HeapMemoryHealthCheck helidon.healthCheck.heapMemory.thresholdPercent 98 The following code adds the default built-in health checks to your application: <markup lang=\"java\" >HealthSupport health = HealthSupport.builder() .addLiveness(HealthChecks.healthChecks()) .build(); Routing.builder() .register(health) .build(); Add built-in health checks using defaults (requires the helidon-health-checks dependency). Register the created HealthSupport with web server routing (adds the /health endpoint). You can control the thresholds for built-in health checks in either of two ways: Create the health checks individually using their builders instead of using the HealthChecks convenience class. Follow the JavaDoc links in the table above. Using configuration as explained in . ",
            "title": "Built-in health checks"
        },
        {
            "location": "se/health",
            "text": " The liveness probe is used to verify the container has become unresponsive. For example, it can be used to detect deadlocks or analyze heap usage. When Kubernetes gives up on a liveness probe, the corresponding pod is restarted. The liveness probe can result in repeated restarts in certain cases. For example, if the probe is implemented to check all the dependencies strictly, then it can fail repeatedly for temporary issues. Repeated restarts can also occur if timeoutSeconds or periodSeconds is too low. We recommend the following: Avoid checking dependencies in a liveness probe. Set timeoutSeconds to avoid excessive probe failures. Acknowledge startup times with initialDelaySeconds . ",
            "title": "Liveness probe"
        },
        {
            "location": "se/health",
            "text": " The readiness probe is used to avoid routing requests to the pod until it is ready to accept traffic. When Kubernetes gives up on a readiness probe, the pod is not restarted, traffic is not routed to the pod anymore. In certain cases, the readiness probe can cause all the pods to be removed from service routing. For example, if the probe is implemented to check all the dependencies strictly, then it can fail repeatedly for temporary issues. This issue can also occur if timeoutSeconds or periodSeconds is too low. We recommend the following: Be conservative when checking shared dependencies. Be aggressive when checking local dependencies. Set failureThreshold according to periodSeconds in order to accommodate temporary errors. ",
            "title": "Readiness probe"
        },
        {
            "location": "se/health",
            "text": " The startup probe prevents Kubernetes from prematurely checking the other probes if the application takes a long time to start. Otherwise, Kubernetes might misinterpret a failed liveness or readiness probe and shut down the container when, in fact, the application is still coming up. ",
            "title": "Startup probe"
        },
        {
            "location": "se/health",
            "text": " Probes is the term used by Kubernetes to describe health checks for containers ( Kubernetes documentation ). There are three types of probes: liveness : Indicates whether the container is running readiness : Indicates whether the container is ready to service requests startup : Indicates whether the application in the container has started You can implement probes using the following mechanisms: Running a command inside a container Sending an HTTP request to a container Opening a TCP socket to a container A microservice exposed to HTTP traffic will typically implement both the liveness probe and the readiness probe using HTTP requests. If the microservice takes a significant time to initialize itself, you can also define a startup probe, in which case Kubernetes does not check liveness or readiness probes until the startup probe returns success. You can configure several parameters for probes. The following are the most relevant parameters: <div class=\"table__overflow elevation-1 flex sm7 \"> initialDelaySeconds Number of seconds after the container has started before liveness or readiness probes are initiated. periodSeconds Probe interval. Default to 10 seconds. Minimum value is 1. timeoutSeconds Number of seconds after which the probe times out. Defaults to 1 second. Minimum value is 1 failureThreshold Number of consecutive failures after which the probe should stop. Default: 3. Minimum: 1. Liveness probe The liveness probe is used to verify the container has become unresponsive. For example, it can be used to detect deadlocks or analyze heap usage. When Kubernetes gives up on a liveness probe, the corresponding pod is restarted. The liveness probe can result in repeated restarts in certain cases. For example, if the probe is implemented to check all the dependencies strictly, then it can fail repeatedly for temporary issues. Repeated restarts can also occur if timeoutSeconds or periodSeconds is too low. We recommend the following: Avoid checking dependencies in a liveness probe. Set timeoutSeconds to avoid excessive probe failures. Acknowledge startup times with initialDelaySeconds . Readiness probe The readiness probe is used to avoid routing requests to the pod until it is ready to accept traffic. When Kubernetes gives up on a readiness probe, the pod is not restarted, traffic is not routed to the pod anymore. In certain cases, the readiness probe can cause all the pods to be removed from service routing. For example, if the probe is implemented to check all the dependencies strictly, then it can fail repeatedly for temporary issues. This issue can also occur if timeoutSeconds or periodSeconds is too low. We recommend the following: Be conservative when checking shared dependencies. Be aggressive when checking local dependencies. Set failureThreshold according to periodSeconds in order to accommodate temporary errors. Startup probe The startup probe prevents Kubernetes from prematurely checking the other probes if the application takes a long time to start. Otherwise, Kubernetes might misinterpret a failed liveness or readiness probe and shut down the container when, in fact, the application is still coming up. ",
            "title": "Kubernetes probes"
        },
        {
            "location": "se/health",
            "text": " Failed probes are recorded as events associated with their corresponding pods. The event message contains only the status code. <markup lang=\"bash\" title=\"Get the events of a single pod:\" >POD_NAME=$(kubectl get pod -l app=acme -o jsonpath='{.items[0].metadata.name}') kubectl get event --field-selector involvedObject.name=${POD_NAME} Get the effective pod name by filtering pods with the label app=acme . Filter the events for the pod. Create log messages in your health check implementation when setting a DOWN status. This will allow you to correlate the cause of a failed probe. ",
            "title": "Troubleshooting probes"
        },
        {
            "location": "se/health",
            "text": " A health check is a Java functional interface that returns a HealthCheckResponse instance. You can choose to implement a health check inline with a lambda expression or you can reference a method with the double colon operator :: . <markup lang=\"java\" title=\"Health check with a lambda expression:\" >HealthCheck hc = () -&gt; HealthCheckResponse .named(\"exampleHealthCheck\") .up() .build(); <markup lang=\"java\" title=\"Health check with method reference:\" >HealthCheckResponse exampleHealthCheck() { return HealthCheckResponse .named(\"exampleHealthCheck\") .up() .build(); } HealthCheck hc = this::exampleHealthCheck; HealthSupport is a WebServer service that contains a collection of registered HealthCheck instances. When queried, it invokes the registered health check and returns a response with a status code representing the overall status of the application. Health status codes <div class=\"table__overflow elevation-1 flex sm7 \"> 200 The application is healthy (with health check details in the response). 204 The application is healthy (with no health check details in the response). 503 The application is not healthy. 500 An error occurred while reporting the health. HTTP GET responses include JSON content showing the detailed results of all the health checks which the server executed after receiving the request. HTTP HEAD requests return only the status with no payload. The following code snippets show how to register health checks while building an instance of HealthSupport : <markup lang=\"java\" title=\"Create the health support service:\" >HealthSupport health = HealthSupport.builder() .addLiveness(hc) // hc created above .build(); <markup lang=\"java\" title=\"Create a custom health check:\" >HealthSupport health = HealthSupport.builder() .addLiveness(() -&gt; HealthCheckResponse.named(\"exampleHealthCheck\") .up() .withData(\"time\", System.currentTimeMillis()) .build()) .build(); The custom health check above returns a status of UP and the current time. After creating the HealthCheck and registering it in a HealthSupport , we must add the latter to the WebServer routes as follows: <markup lang=\"java\" >Routing.builder() .register(health) .build(); Here is a sample response to the custom health check registered above: <markup lang=\"json\" title=\"JSON response:\" >{ \"status\": \"UP\", \"checks\": [ { \"name\": \"exampleHealthCheck\", \"status\": \"UP\", \"data\": { \"time\": 1546958376613 } } ] } Balance collecting a lot of information with the need to avoid overloading the application and overwhelming users. The following table provides a summary of the Health Check API classes. Health check API classes org.eclipse.microprofile.health.HealthCheck Java functional interface representing the logic of a single health check org.eclipse.microprofile.health.HealthCheckResponse Result of a health check invocation that contains a status and a description. org.eclipse.microprofile.health.HealthCheckResponseBuilder Builder class to create HealthCheckResponse instances io.helidon.health.HealthSupport WebServer service that exposes /health and invokes the registered health checks io.helidon.health.HealthSupport.Builder Builder class to create HealthSupport instances Built-in health checks You can use Helidon-provided health checks to report various common health check statuses: Built-in health check Health check name JavaDoc Config properties Default config value deadlock detection deadlock DeadlockHealthCheck n/a n/a available disk space diskSpace DiskSpaceHealthCheck helidon.healthCheck.diskSpace.thresholdPercent + helidon.healthCheck.diskSpace.path 99.999 + / available heap memory heapMemory HeapMemoryHealthCheck helidon.healthCheck.heapMemory.thresholdPercent 98 The following code adds the default built-in health checks to your application: <markup lang=\"java\" >HealthSupport health = HealthSupport.builder() .addLiveness(HealthChecks.healthChecks()) .build(); Routing.builder() .register(health) .build(); Add built-in health checks using defaults (requires the helidon-health-checks dependency). Register the created HealthSupport with web server routing (adds the /health endpoint). You can control the thresholds for built-in health checks in either of two ways: Create the health checks individually using their builders instead of using the HealthChecks convenience class. Follow the JavaDoc links in the table above. Using configuration as explained in . Kubernetes probes Probes is the term used by Kubernetes to describe health checks for containers ( Kubernetes documentation ). There are three types of probes: liveness : Indicates whether the container is running readiness : Indicates whether the container is ready to service requests startup : Indicates whether the application in the container has started You can implement probes using the following mechanisms: Running a command inside a container Sending an HTTP request to a container Opening a TCP socket to a container A microservice exposed to HTTP traffic will typically implement both the liveness probe and the readiness probe using HTTP requests. If the microservice takes a significant time to initialize itself, you can also define a startup probe, in which case Kubernetes does not check liveness or readiness probes until the startup probe returns success. You can configure several parameters for probes. The following are the most relevant parameters: <div class=\"table__overflow elevation-1 flex sm7 \"> initialDelaySeconds Number of seconds after the container has started before liveness or readiness probes are initiated. periodSeconds Probe interval. Default to 10 seconds. Minimum value is 1. timeoutSeconds Number of seconds after which the probe times out. Defaults to 1 second. Minimum value is 1 failureThreshold Number of consecutive failures after which the probe should stop. Default: 3. Minimum: 1. Liveness probe The liveness probe is used to verify the container has become unresponsive. For example, it can be used to detect deadlocks or analyze heap usage. When Kubernetes gives up on a liveness probe, the corresponding pod is restarted. The liveness probe can result in repeated restarts in certain cases. For example, if the probe is implemented to check all the dependencies strictly, then it can fail repeatedly for temporary issues. Repeated restarts can also occur if timeoutSeconds or periodSeconds is too low. We recommend the following: Avoid checking dependencies in a liveness probe. Set timeoutSeconds to avoid excessive probe failures. Acknowledge startup times with initialDelaySeconds . Readiness probe The readiness probe is used to avoid routing requests to the pod until it is ready to accept traffic. When Kubernetes gives up on a readiness probe, the pod is not restarted, traffic is not routed to the pod anymore. In certain cases, the readiness probe can cause all the pods to be removed from service routing. For example, if the probe is implemented to check all the dependencies strictly, then it can fail repeatedly for temporary issues. This issue can also occur if timeoutSeconds or periodSeconds is too low. We recommend the following: Be conservative when checking shared dependencies. Be aggressive when checking local dependencies. Set failureThreshold according to periodSeconds in order to accommodate temporary errors. Startup probe The startup probe prevents Kubernetes from prematurely checking the other probes if the application takes a long time to start. Otherwise, Kubernetes might misinterpret a failed liveness or readiness probe and shut down the container when, in fact, the application is still coming up. Troubleshooting probes Failed probes are recorded as events associated with their corresponding pods. The event message contains only the status code. <markup lang=\"bash\" title=\"Get the events of a single pod:\" >POD_NAME=$(kubectl get pod -l app=acme -o jsonpath='{.items[0].metadata.name}') kubectl get event --field-selector involvedObject.name=${POD_NAME} Get the effective pod name by filtering pods with the label app=acme . Filter the events for the pod. Create log messages in your health check implementation when setting a DOWN status. This will allow you to correlate the cause of a failed probe. ",
            "title": "API"
        },
        {
            "location": "se/health",
            "text": " Built-in health checks can be configured using the config property keys described in this table . Further, you can suppress one or more of the built-in health checks by setting the configuration item helidon.health.exclude to a comma-separated list of the health check names (from this table ) you want to exclude. ",
            "title": "Configuration"
        },
        {
            "location": "se/health",
            "text": " Accessing the Helidon-provided /health endpoint reports the health of your application as shown below: <markup lang=\"json\" title=\"JSON response.\" >{ \"status\": \"UP\", \"checks\": [ { \"name\": \"deadlock\", \"status\": \"UP\" }, { \"name\": \"diskSpace\", \"status\": \"UP\", \"data\": { \"free\": \"211.00 GB\", \"freeBytes\": 226563444736, \"percentFree\": \"45.31%\", \"total\": \"465.72 GB\", \"totalBytes\": 500068036608 } }, { \"name\": \"heapMemory\", \"status\": \"UP\", \"data\": { \"free\": \"215.15 MB\", \"freeBytes\": 225600496, \"max\": \"3.56 GB\", \"maxBytes\": 3817865216, \"percentFree\": \"99.17%\", \"total\": \"245.50 MB\", \"totalBytes\": 257425408 } } ] } ",
            "title": "JSON response example"
        },
        {
            "location": "se/health",
            "text": " This example shows the usage of the Helidon health API in an application that implements health endpoints for the liveness and readiness probes. Note that the application code dissociates the health endpoints from the default routes, so that the health endpoints are not exposed by the service. An example YAML specification is also provided for the Kubernetes service and deployment. <markup lang=\"java\" title=\"Application code:\" >Routing healthRouting = Routing.builder() .register(JsonSupport.create()) .register(HealthSupport.builder() .webContext(\"/live\") .addLiveness(HealthChecks.healthChecks()) .build()) .register(HealthSupport.builder() .webContext(\"/ready\") .addReadiness(() -&gt; HealthCheckResponse.named(\"database\").up().build()) .build()) .build(); Routing defaultRouting = Routing.builder() .any((req, res) -&gt; res.send(\"It works!\")) .build(); WebServer server = WebServer.builder(defaultRouting) .config(WebServer.builder() .port(8080) .addSocket(\"health\", SocketConfiguration.builder() .port(8081) .build()) .build()) .addNamedRouting(\"health\", healthRouting) .build(); server.start(); The health service for the liveness probe is exposed at /live . Using the built-in health checks for the liveness probe. The health service for the readiness probe is exposed at /ready . Using a custom health check for a pseudo database that is always UP . The default route: returns It works! for any request. The server uses port 8080 for the default routes. A socket configuration named health using port 8081 . Route the health services exclusively on the health socket. <markup lang=\"yaml\" title=\"Kubernetes descriptor:\" >kind: Service apiVersion: v1 metadata: name: acme labels: app: acme spec: type: NodePort selector: app: acme ports: - port: 8080 targetPort: 8080 name: http --- kind: Deployment apiVersion: apps/v1 metadata: name: acme spec: replicas: 1 selector: matchLabels: app: acme template: metadata: name: acme labels: name: acme spec: containers: - name: acme image: acme imagePullPolicy: IfNotPresent ports: - containerPort: 8080 livenessProbe: httpGet: path: /live port: 8081 initialDelaySeconds: 3 periodSeconds: 10 timeoutSeconds: 3 failureThreshold: 3 readinessProbe: httpGet: path: /ready port: 8081 initialDelaySeconds: 10 periodSeconds: 30 timeoutSeconds: 10 --- A service of type NodePort that serves the default routes on port 8080 . A deployment with one replica of a pod. The HTTP endpoint for the liveness probe. The liveness probe configuration. The HTTP endpoint for the readiness probe. The readiness probe configuration. ",
            "title": "Kubernetes example"
        },
        {
            "location": "se/health",
            "text": " JSON response example Accessing the Helidon-provided /health endpoint reports the health of your application as shown below: <markup lang=\"json\" title=\"JSON response.\" >{ \"status\": \"UP\", \"checks\": [ { \"name\": \"deadlock\", \"status\": \"UP\" }, { \"name\": \"diskSpace\", \"status\": \"UP\", \"data\": { \"free\": \"211.00 GB\", \"freeBytes\": 226563444736, \"percentFree\": \"45.31%\", \"total\": \"465.72 GB\", \"totalBytes\": 500068036608 } }, { \"name\": \"heapMemory\", \"status\": \"UP\", \"data\": { \"free\": \"215.15 MB\", \"freeBytes\": 225600496, \"max\": \"3.56 GB\", \"maxBytes\": 3817865216, \"percentFree\": \"99.17%\", \"total\": \"245.50 MB\", \"totalBytes\": 257425408 } } ] } Kubernetes example This example shows the usage of the Helidon health API in an application that implements health endpoints for the liveness and readiness probes. Note that the application code dissociates the health endpoints from the default routes, so that the health endpoints are not exposed by the service. An example YAML specification is also provided for the Kubernetes service and deployment. <markup lang=\"java\" title=\"Application code:\" >Routing healthRouting = Routing.builder() .register(JsonSupport.create()) .register(HealthSupport.builder() .webContext(\"/live\") .addLiveness(HealthChecks.healthChecks()) .build()) .register(HealthSupport.builder() .webContext(\"/ready\") .addReadiness(() -&gt; HealthCheckResponse.named(\"database\").up().build()) .build()) .build(); Routing defaultRouting = Routing.builder() .any((req, res) -&gt; res.send(\"It works!\")) .build(); WebServer server = WebServer.builder(defaultRouting) .config(WebServer.builder() .port(8080) .addSocket(\"health\", SocketConfiguration.builder() .port(8081) .build()) .build()) .addNamedRouting(\"health\", healthRouting) .build(); server.start(); The health service for the liveness probe is exposed at /live . Using the built-in health checks for the liveness probe. The health service for the readiness probe is exposed at /ready . Using a custom health check for a pseudo database that is always UP . The default route: returns It works! for any request. The server uses port 8080 for the default routes. A socket configuration named health using port 8081 . Route the health services exclusively on the health socket. <markup lang=\"yaml\" title=\"Kubernetes descriptor:\" >kind: Service apiVersion: v1 metadata: name: acme labels: app: acme spec: type: NodePort selector: app: acme ports: - port: 8080 targetPort: 8080 name: http --- kind: Deployment apiVersion: apps/v1 metadata: name: acme spec: replicas: 1 selector: matchLabels: app: acme template: metadata: name: acme labels: name: acme spec: containers: - name: acme image: acme imagePullPolicy: IfNotPresent ports: - containerPort: 8080 livenessProbe: httpGet: path: /live port: 8081 initialDelaySeconds: 3 periodSeconds: 10 timeoutSeconds: 3 failureThreshold: 3 readinessProbe: httpGet: path: /ready port: 8081 initialDelaySeconds: 10 periodSeconds: 30 timeoutSeconds: 10 --- A service of type NodePort that serves the default routes on port 8080 . A deployment with one replica of a pod. The HTTP endpoint for the liveness probe. The liveness probe configuration. The HTTP endpoint for the readiness probe. The readiness probe configuration. ",
            "title": "Examples"
        },
        {
            "location": "se/health",
            "text": " Health Checks SE API JavaDocs . ",
            "title": "Additional Information"
        },
        {
            "location": "se/integrations/hcv",
            "text": " Overview Maven Coordinates Usage Examples Local Testing References ",
            "title": "Contents"
        },
        {
            "location": "se/integrations/hcv",
            "text": " HashiCorp Vault is a commonly used Vault in many microservices. The APIs are REST-based and Helidon implements them using reactive client. ",
            "title": "Overview"
        },
        {
            "location": "se/integrations/hcv",
            "text": " To enable HashiCorp Vault add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.vault&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-vault&lt;/artifactId&gt; &lt;/dependency&gt; The following is a list of maven coordinates of all Vault modules available: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.vault.auths&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-vault-auths-token&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.vault.auths&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-vault-auths-approle&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.vault.auths&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-vault-auths-k8s&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.vault.secrets&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-vault-secrets-kv1&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.vault.secrets&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-vault-secrets-kv2&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.vault.secrets&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-vault-secrets-cubbyhole&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.vault.secrets&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-vault-secrets-transit&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.vault.secrets&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-vault-secrets-database&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.vault.sys&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-vault-sys&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "se/integrations/hcv",
            "text": " New secret engines and authentication methods can be implemented quite easily, as the integration is based on service providers (using ServiceLoader). This gives us (or you, as the users) the option to add new secret engines and/or authentication methods without adding a plethora of methods to the Vault class. See the following SPIs: <markup lang=\"properties\" >io.helidon.integrations.vault.spi.AuthMethodProvider io.helidon.integrations.vault.spi.SecretsEngineProvider io.helidon.integrations.vault.spi.SysProvider io.helidon.integrations.vault.spi.VaultAuth io.helidon.integrations.vault.spi.InjectionProvider ",
            "title": "Extensibility"
        },
        {
            "location": "se/integrations/hcv",
            "text": " Vault integration supports the following: Secret Engines : Key/Value version 2, Key/Value version 1, Cubbyhole, PKI, Transit, Database Authentication Methods : Token, Kubernetes (k8s), AppRole Other Sys Operations and Configurations Each of these features is implemented as a separate module, with the Vault class binding them together. Code to set up Vault and obtain a specific secret engine: <markup lang=\"java\" >Vault vault = Vault.builder() .config(config.get(\"vault\")) .build(); Kv2SecretsRx secrets = vault.secrets(Kv2SecretsRx.ENGINE); Similar code can be used for any secret engine available: Kv2SecretsRx - Key/Value Version 2 Secrets (versioned secrets, default) Kv1SecretsRx - Key/Value Version 1 Secrets (unversioned secrets, legacy) CubbyholeSecretsRx - Cubbyhole secrets (token bound secrets) DbSecretsRx - Database secrets (for generating temporary DB credentials) PkiSecretsRx - PKI secrets (for generating keys and X.509 certificates) TransitSecretsRx - Transit operations (encryption, signatures, HMAC) In addition to these features, Vault itself can be authenticated as follows: Token authentication - token is configured when connecting to Vault vault: address: \"http://localhost:8200\" token: \"my-token\" AppRole authentication - AppRole ID and secret ID are configured, integration exchanges these for a temporary token that is used to connect to Vault vault: auth: app-role: role-id: \"app-role-id\" secret-id: app-role-secret-id K8s authentication - the k8s JWT token is discovered on current node and used to obtain a temporary token that is used to connect to Vault vault: auth: k8s: token-role: \"my-role\" The token role must be configured in Vault Minimal configuration to connect to Vault: Code to get the Sys operations of Vault: <markup lang=\"java\" >SysRx sys = vault.sys(SysRx.API); Extensibility New secret engines and authentication methods can be implemented quite easily, as the integration is based on service providers (using ServiceLoader). This gives us (or you, as the users) the option to add new secret engines and/or authentication methods without adding a plethora of methods to the Vault class. See the following SPIs: <markup lang=\"properties\" >io.helidon.integrations.vault.spi.AuthMethodProvider io.helidon.integrations.vault.spi.SecretsEngineProvider io.helidon.integrations.vault.spi.SysProvider io.helidon.integrations.vault.spi.VaultAuth io.helidon.integrations.vault.spi.InjectionProvider ",
            "title": "Usage"
        },
        {
            "location": "se/integrations/hcv",
            "text": " Configure the Vault object using token base configuration: <markup lang=\"java\" >Config config = buildConfig(); Vault tokenVault = Vault.builder() .config(config.get(\"vault.token\")) .updateWebClient(it -&gt; it.connectTimeout(5, TimeUnit.SECONDS) .readTimeout(5, TimeUnit.SECONDS)) .build(); Then WebService has to be configured with endpoints routing registered: <markup lang=\"java\" >SysRx sys = tokenVault.sys(SysRx.API); WebServer webServer = WebServer.builder() .config(config.get(\"server\")) .routing(Routing.builder() .register(\"/cubbyhole\", new CubbyholeService(sys, tokenVault.secrets(CubbyholeSecretsRx.ENGINE))) .register(\"/kv1\", new Kv1Service(sys, tokenVault.secrets(Kv1SecretsRx.ENGINE))) .register(\"/kv2\", new Kv2Service(sys, tokenVault.secrets(Kv2SecretsRx.ENGINE))) .register(\"/transit\", new TransitService(sys, tokenVault.secrets(TransitSecretsRx.ENGINE)))) .build() .start() .await(); AppRole-based and Kubernetes authentications are available. ",
            "title": "Usage with WebServer"
        },
        {
            "location": "se/integrations/hcv",
            "text": " Cubbyhole secrets engine operations: <markup lang=\"java\" >@Override public void update(Routing.Rules rules) { rules.get(\"/create\", this::createSecrets) .get(\"/secrets/{path:.*}\", this::getSecret); } private void createSecrets(ServerRequest req, ServerResponse res) { secrets.create(\"first/secret\", Map.of(\"key\", \"secretValue\")) .thenAccept(ignored -&gt; res.send(\"Created secret on path /first/secret\")) .exceptionally(res::send); } private void getSecret(ServerRequest req, ServerResponse res) { String path = req.path().param(\"path\"); secrets.get(path) .thenAccept(secret -&gt; { if (secret.isPresent()) { // using toString so we do not need to depend on JSON-B res.send(secret.get().values().toString()); } else { res.status(Http.Status.NOT_FOUND_404); res.send(); } }) .exceptionally(res::send); } Create a secret from request entity. Get the secret on a specified path. ",
            "title": "Cubbyhole secrets"
        },
        {
            "location": "se/integrations/hcv",
            "text": " Key/Value version 1 secrets engine operations: <markup lang=\"java\" >@Override public void update(Routing.Rules rules) { rules.get(\"/enable\", this::enableEngine) .get(\"/create\", this::createSecrets) .get(\"/secrets/{path:.*}\", this::getSecret) .delete(\"/secrets/{path:.*}\", this::deleteSecret) .get(\"/disable\", this::disableEngine); } private void disableEngine(ServerRequest req, ServerResponse res) { sys.disableEngine(Kv1SecretsRx.ENGINE) .thenAccept(ignored -&gt; res.send(\"KV1 Secret engine disabled\")) .exceptionally(res::send); } private void enableEngine(ServerRequest req, ServerResponse res) { sys.enableEngine(Kv1SecretsRx.ENGINE) .thenAccept(ignored -&gt; res.send(\"KV1 Secret engine enabled\")) .exceptionally(res::send); } private void createSecrets(ServerRequest req, ServerResponse res) { secrets.create(\"first/secret\", Map.of(\"key\", \"secretValue\")) .thenAccept(ignored -&gt; res.send(\"Created secret on path /first/secret\")) .exceptionally(res::send); } private void deleteSecret(ServerRequest req, ServerResponse res) { String path = req.path().param(\"path\"); secrets.delete(path) .thenAccept(ignored -&gt; res.send(\"Deleted secret on path \" + path)); } private void getSecret(ServerRequest req, ServerResponse res) { String path = req.path().param(\"path\"); secrets.get(path) .thenAccept(secret -&gt; { if (secret.isPresent()) { // using toString so we do not need to depend on JSON-B res.send(secret.get().values().toString()); } else { res.status(Http.Status.NOT_FOUND_404); res.send(); } }) .exceptionally(res::send); } Disable the secrets engine on the default path. Enable the secrets engine on the default path. Create a secret from request entity. Delete the secret on a specified path. Get the secret on a specified path. ",
            "title": "KV1 Secrets"
        },
        {
            "location": "se/integrations/hcv",
            "text": " Key/Value version 2 secrets engine operations: <markup lang=\"java\" >@Override public void update(Routing.Rules rules) { rules.get(\"/create\", this::createSecrets) .get(\"/secrets/{path:.*}\", this::getSecret) .delete(\"/secrets/{path:.*}\", this::deleteSecret); } private void createSecrets(ServerRequest req, ServerResponse res) { secrets.create(\"first/secret\", Map.of(\"key\", \"secretValue\")) .thenAccept(ignored -&gt; res.send(\"Created secret on path /first/secret\")) .exceptionally(res::send); } private void deleteSecret(ServerRequest req, ServerResponse res) { String path = req.path().param(\"path\"); secrets.deleteAll(path) .thenAccept(ignored -&gt; res.send(\"Deleted secret on path \" + path)); } private void getSecret(ServerRequest req, ServerResponse res) { String path = req.path().param(\"path\"); secrets.get(path) .thenAccept(secret -&gt; { if (secret.isPresent()) { // using toString so we do not need to depend on JSON-B Kv2Secret kv2Secret = secret.get(); res.send(\"Version \" + kv2Secret.metadata().version() + \", secret: \" + kv2Secret.values().toString()); } else { res.status(Http.Status.NOT_FOUND_404); res.send(); } }) .exceptionally(res::send); } Create a secret from request entity. Delete the secret on a specified path. Get the secret on a specified path. ",
            "title": "KV2 Secrets"
        },
        {
            "location": "se/integrations/hcv",
            "text": " Transit secrets engine operations: <markup lang=\"bash\" >@Override public void update(Routing.Rules rules) { rules.get(\"/enable\", this::enableEngine) .get(\"/keys\", this::createKeys) .delete(\"/keys\", this::deleteKeys) .get(\"/batch\", this::batch) .get(\"/encrypt/{text:.*}\", this::encryptSecret) .get(\"/decrypt/{text:.*}\", this::decryptSecret) .get(\"/sign\", this::sign) .get(\"/hmac\", this::hmac) .get(\"/verify/sign/{text:.*}\", this::verify) .get(\"/verify/hmac/{text:.*}\", this::verifyHmac) .get(\"/disable\", this::disableEngine); } private void enableEngine(ServerRequest req, ServerResponse res) { sys.enableEngine(TransitSecretsRx.ENGINE) .thenAccept(ignored -&gt; res.send(\"Transit Secret engine enabled\")) .exceptionally(res::send); } private void disableEngine(ServerRequest req, ServerResponse res) { sys.disableEngine(TransitSecretsRx.ENGINE) .thenAccept(ignored -&gt; res.send(\"Transit Secret engine disabled\")) .exceptionally(res::send); } private void createKeys(ServerRequest req, ServerResponse res) { CreateKey.Request request = CreateKey.Request.builder() .name(ENCRYPTION_KEY); secrets.createKey(request) .flatMapSingle(ignored -&gt; secrets.createKey(CreateKey.Request.builder() .name(SIGNATURE_KEY) .type(\"rsa-2048\"))) .forSingle(ignored -&gt; res.send(\"Created keys\")) .exceptionally(res::send); } private void deleteKeys(ServerRequest req, ServerResponse res) { secrets.updateKeyConfig(UpdateKeyConfig.Request.builder() .name(ENCRYPTION_KEY) .allowDeletion(true)) .peek(ignored -&gt; System.out.println(\"Updated key config\")) .flatMapSingle(ignored -&gt; secrets.deleteKey(DeleteKey.Request.create(ENCRYPTION_KEY))) .forSingle(ignored -&gt; res.send(\"Deleted key.\")) .exceptionally(res::send); } private void encryptSecret(ServerRequest req, ServerResponse res) { String secret = req.path().param(\"text\"); secrets.encrypt(Encrypt.Request.builder() .encryptionKeyName(ENCRYPTION_KEY) .data(Base64Value.create(secret))) .forSingle(response -&gt; res.send(response.encrypted().cipherText())) .exceptionally(res::send); } private void decryptSecret(ServerRequest req, ServerResponse res) { String encrypted = req.path().param(\"text\"); secrets.decrypt(Decrypt.Request.builder() .encryptionKeyName(ENCRYPTION_KEY) .cipherText(encrypted)) .forSingle(response -&gt; res.send(String.valueOf(response.decrypted().toDecodedString()))) .exceptionally(res::send); } private void hmac(ServerRequest req, ServerResponse res) { secrets.hmac(Hmac.Request.builder() .hmacKeyName(ENCRYPTION_KEY) .data(SECRET_STRING)) .forSingle(response -&gt; res.send(response.hmac())) .exceptionally(res::send); } private void sign(ServerRequest req, ServerResponse res) { secrets.sign(Sign.Request.builder() .signatureKeyName(SIGNATURE_KEY) .data(SECRET_STRING)) .forSingle(response -&gt; res.send(response.signature())) .exceptionally(res::send); } private void verifyHmac(ServerRequest req, ServerResponse res) { String hmac = req.path().param(\"text\"); secrets.verify(Verify.Request.builder() .digestKeyName(ENCRYPTION_KEY) .data(SECRET_STRING) .hmac(hmac)) .forSingle(response -&gt; res.send(\"Valid: \" + response.isValid())) .exceptionally(res::send); } private void verify(ServerRequest req, ServerResponse res) { String signature = req.path().param(\"text\"); secrets.verify(Verify.Request.builder() .digestKeyName(SIGNATURE_KEY) .data(SECRET_STRING) .signature(signature)) .forSingle(response -&gt; res.send(\"Valid: \" + response.isValid())) .exceptionally(res::send); } Enable the secrets engine on the default path. Disable the secrets engine on the default path. Create the encryption and signature keys. Delete the encryption and signature keys. Encrypt a secret. Decrypt a secret. Create an HMAC for text. Create a signature for text. Verify HMAC. Verify signature. ",
            "title": "Transit secrets"
        },
        {
            "location": "se/integrations/hcv",
            "text": " In order to use Kubernetes authentication: <markup lang=\"java\" >class K8sExample { private static final String SECRET_PATH = \"k8s/example/secret\"; private static final String POLICY_NAME = \"k8s_policy\"; private final Vault tokenVault; private final String k8sAddress; private final Config config; private final SysRx sys; private Vault k8sVault; K8sExample(Vault tokenVault, Config config) { this.tokenVault = tokenVault; this.sys = tokenVault.sys(SysRx.API); this.k8sAddress = config.get(\"cluster-address\").asString().get(); this.config = config; } public Single&lt;String&gt; run() { /* The following tasks must be run before we authenticate */ return enableK8sAuth() // Now we can login using k8s - must run within a k8s cluster (or you need the k8s configuration files locally) .flatMapSingle(ignored -&gt; workWithSecrets()) // Now back to token based Vault, as we will clean up .flatMapSingle(ignored -&gt; disableK8sAuth()) .map(ignored -&gt; \"k8s example finished successfully.\"); } private Single&lt;ApiResponse&gt; workWithSecrets() { Kv2SecretsRx secrets = k8sVault.secrets(Kv2SecretsRx.ENGINE); return secrets.create(SECRET_PATH, Map.of(\"secret-key\", \"secretValue\", \"secret-user\", \"username\")) .flatMapSingle(ignored -&gt; secrets.get(SECRET_PATH)) .peek(secret -&gt; { if (secret.isPresent()) { Kv2Secret kv2Secret = secret.get(); System.out.println(\"k8s first secret: \" + kv2Secret.value(\"secret-key\")); System.out.println(\"k8s second secret: \" + kv2Secret.value(\"secret-user\")); } else { System.out.println(\"k8s secret not found\"); } }).flatMapSingle(ignored -&gt; secrets.deleteAll(SECRET_PATH)); } private Single&lt;ApiResponse&gt; disableK8sAuth() { return sys.deletePolicy(POLICY_NAME) .flatMapSingle(ignored -&gt; sys.disableAuth(K8sAuthRx.AUTH_METHOD.defaultPath())); } private Single&lt;ApiResponse&gt; enableK8sAuth() { // enable the method return sys.enableAuth(K8sAuthRx.AUTH_METHOD) // add policy .flatMapSingle(ignored -&gt; sys.createPolicy(POLICY_NAME, VaultPolicy.POLICY)) .flatMapSingle(ignored -&gt; tokenVault.auth(K8sAuthRx.AUTH_METHOD) .configure(ConfigureK8s.Request.builder() .address(k8sAddress))) .flatMapSingle(ignored -&gt; tokenVault.auth(K8sAuthRx.AUTH_METHOD) // this must be the same role name as is defined in application.yaml .createRole(CreateRole.Request.builder() .roleName(\"my-role\") .addBoundServiceAccountName(\"*\") .addBoundServiceAccountNamespace(\"default\") .addTokenPolicy(POLICY_NAME))) .peek(ignored -&gt; k8sVault = Vault.create(config)) .map(Function.identity()); } } Run the Kubernetes Authentication by enabling it. Create Kubernetes secrets. Disable Kubernetes authentication if needed. Function used to enable Kubernetes authentication. ",
            "title": "Authentication with Kubernetes"
        },
        {
            "location": "se/integrations/hcv",
            "text": " The following example shows usage of Vault to encrypt a secret. Usage with WebServer Configure the Vault object using token base configuration: <markup lang=\"java\" >Config config = buildConfig(); Vault tokenVault = Vault.builder() .config(config.get(\"vault.token\")) .updateWebClient(it -&gt; it.connectTimeout(5, TimeUnit.SECONDS) .readTimeout(5, TimeUnit.SECONDS)) .build(); Then WebService has to be configured with endpoints routing registered: <markup lang=\"java\" >SysRx sys = tokenVault.sys(SysRx.API); WebServer webServer = WebServer.builder() .config(config.get(\"server\")) .routing(Routing.builder() .register(\"/cubbyhole\", new CubbyholeService(sys, tokenVault.secrets(CubbyholeSecretsRx.ENGINE))) .register(\"/kv1\", new Kv1Service(sys, tokenVault.secrets(Kv1SecretsRx.ENGINE))) .register(\"/kv2\", new Kv2Service(sys, tokenVault.secrets(Kv2SecretsRx.ENGINE))) .register(\"/transit\", new TransitService(sys, tokenVault.secrets(TransitSecretsRx.ENGINE)))) .build() .start() .await(); AppRole-based and Kubernetes authentications are available. Cubbyhole secrets Cubbyhole secrets engine operations: <markup lang=\"java\" >@Override public void update(Routing.Rules rules) { rules.get(\"/create\", this::createSecrets) .get(\"/secrets/{path:.*}\", this::getSecret); } private void createSecrets(ServerRequest req, ServerResponse res) { secrets.create(\"first/secret\", Map.of(\"key\", \"secretValue\")) .thenAccept(ignored -&gt; res.send(\"Created secret on path /first/secret\")) .exceptionally(res::send); } private void getSecret(ServerRequest req, ServerResponse res) { String path = req.path().param(\"path\"); secrets.get(path) .thenAccept(secret -&gt; { if (secret.isPresent()) { // using toString so we do not need to depend on JSON-B res.send(secret.get().values().toString()); } else { res.status(Http.Status.NOT_FOUND_404); res.send(); } }) .exceptionally(res::send); } Create a secret from request entity. Get the secret on a specified path. KV1 Secrets Key/Value version 1 secrets engine operations: <markup lang=\"java\" >@Override public void update(Routing.Rules rules) { rules.get(\"/enable\", this::enableEngine) .get(\"/create\", this::createSecrets) .get(\"/secrets/{path:.*}\", this::getSecret) .delete(\"/secrets/{path:.*}\", this::deleteSecret) .get(\"/disable\", this::disableEngine); } private void disableEngine(ServerRequest req, ServerResponse res) { sys.disableEngine(Kv1SecretsRx.ENGINE) .thenAccept(ignored -&gt; res.send(\"KV1 Secret engine disabled\")) .exceptionally(res::send); } private void enableEngine(ServerRequest req, ServerResponse res) { sys.enableEngine(Kv1SecretsRx.ENGINE) .thenAccept(ignored -&gt; res.send(\"KV1 Secret engine enabled\")) .exceptionally(res::send); } private void createSecrets(ServerRequest req, ServerResponse res) { secrets.create(\"first/secret\", Map.of(\"key\", \"secretValue\")) .thenAccept(ignored -&gt; res.send(\"Created secret on path /first/secret\")) .exceptionally(res::send); } private void deleteSecret(ServerRequest req, ServerResponse res) { String path = req.path().param(\"path\"); secrets.delete(path) .thenAccept(ignored -&gt; res.send(\"Deleted secret on path \" + path)); } private void getSecret(ServerRequest req, ServerResponse res) { String path = req.path().param(\"path\"); secrets.get(path) .thenAccept(secret -&gt; { if (secret.isPresent()) { // using toString so we do not need to depend on JSON-B res.send(secret.get().values().toString()); } else { res.status(Http.Status.NOT_FOUND_404); res.send(); } }) .exceptionally(res::send); } Disable the secrets engine on the default path. Enable the secrets engine on the default path. Create a secret from request entity. Delete the secret on a specified path. Get the secret on a specified path. KV2 Secrets Key/Value version 2 secrets engine operations: <markup lang=\"java\" >@Override public void update(Routing.Rules rules) { rules.get(\"/create\", this::createSecrets) .get(\"/secrets/{path:.*}\", this::getSecret) .delete(\"/secrets/{path:.*}\", this::deleteSecret); } private void createSecrets(ServerRequest req, ServerResponse res) { secrets.create(\"first/secret\", Map.of(\"key\", \"secretValue\")) .thenAccept(ignored -&gt; res.send(\"Created secret on path /first/secret\")) .exceptionally(res::send); } private void deleteSecret(ServerRequest req, ServerResponse res) { String path = req.path().param(\"path\"); secrets.deleteAll(path) .thenAccept(ignored -&gt; res.send(\"Deleted secret on path \" + path)); } private void getSecret(ServerRequest req, ServerResponse res) { String path = req.path().param(\"path\"); secrets.get(path) .thenAccept(secret -&gt; { if (secret.isPresent()) { // using toString so we do not need to depend on JSON-B Kv2Secret kv2Secret = secret.get(); res.send(\"Version \" + kv2Secret.metadata().version() + \", secret: \" + kv2Secret.values().toString()); } else { res.status(Http.Status.NOT_FOUND_404); res.send(); } }) .exceptionally(res::send); } Create a secret from request entity. Delete the secret on a specified path. Get the secret on a specified path. Transit secrets Transit secrets engine operations: <markup lang=\"bash\" >@Override public void update(Routing.Rules rules) { rules.get(\"/enable\", this::enableEngine) .get(\"/keys\", this::createKeys) .delete(\"/keys\", this::deleteKeys) .get(\"/batch\", this::batch) .get(\"/encrypt/{text:.*}\", this::encryptSecret) .get(\"/decrypt/{text:.*}\", this::decryptSecret) .get(\"/sign\", this::sign) .get(\"/hmac\", this::hmac) .get(\"/verify/sign/{text:.*}\", this::verify) .get(\"/verify/hmac/{text:.*}\", this::verifyHmac) .get(\"/disable\", this::disableEngine); } private void enableEngine(ServerRequest req, ServerResponse res) { sys.enableEngine(TransitSecretsRx.ENGINE) .thenAccept(ignored -&gt; res.send(\"Transit Secret engine enabled\")) .exceptionally(res::send); } private void disableEngine(ServerRequest req, ServerResponse res) { sys.disableEngine(TransitSecretsRx.ENGINE) .thenAccept(ignored -&gt; res.send(\"Transit Secret engine disabled\")) .exceptionally(res::send); } private void createKeys(ServerRequest req, ServerResponse res) { CreateKey.Request request = CreateKey.Request.builder() .name(ENCRYPTION_KEY); secrets.createKey(request) .flatMapSingle(ignored -&gt; secrets.createKey(CreateKey.Request.builder() .name(SIGNATURE_KEY) .type(\"rsa-2048\"))) .forSingle(ignored -&gt; res.send(\"Created keys\")) .exceptionally(res::send); } private void deleteKeys(ServerRequest req, ServerResponse res) { secrets.updateKeyConfig(UpdateKeyConfig.Request.builder() .name(ENCRYPTION_KEY) .allowDeletion(true)) .peek(ignored -&gt; System.out.println(\"Updated key config\")) .flatMapSingle(ignored -&gt; secrets.deleteKey(DeleteKey.Request.create(ENCRYPTION_KEY))) .forSingle(ignored -&gt; res.send(\"Deleted key.\")) .exceptionally(res::send); } private void encryptSecret(ServerRequest req, ServerResponse res) { String secret = req.path().param(\"text\"); secrets.encrypt(Encrypt.Request.builder() .encryptionKeyName(ENCRYPTION_KEY) .data(Base64Value.create(secret))) .forSingle(response -&gt; res.send(response.encrypted().cipherText())) .exceptionally(res::send); } private void decryptSecret(ServerRequest req, ServerResponse res) { String encrypted = req.path().param(\"text\"); secrets.decrypt(Decrypt.Request.builder() .encryptionKeyName(ENCRYPTION_KEY) .cipherText(encrypted)) .forSingle(response -&gt; res.send(String.valueOf(response.decrypted().toDecodedString()))) .exceptionally(res::send); } private void hmac(ServerRequest req, ServerResponse res) { secrets.hmac(Hmac.Request.builder() .hmacKeyName(ENCRYPTION_KEY) .data(SECRET_STRING)) .forSingle(response -&gt; res.send(response.hmac())) .exceptionally(res::send); } private void sign(ServerRequest req, ServerResponse res) { secrets.sign(Sign.Request.builder() .signatureKeyName(SIGNATURE_KEY) .data(SECRET_STRING)) .forSingle(response -&gt; res.send(response.signature())) .exceptionally(res::send); } private void verifyHmac(ServerRequest req, ServerResponse res) { String hmac = req.path().param(\"text\"); secrets.verify(Verify.Request.builder() .digestKeyName(ENCRYPTION_KEY) .data(SECRET_STRING) .hmac(hmac)) .forSingle(response -&gt; res.send(\"Valid: \" + response.isValid())) .exceptionally(res::send); } private void verify(ServerRequest req, ServerResponse res) { String signature = req.path().param(\"text\"); secrets.verify(Verify.Request.builder() .digestKeyName(SIGNATURE_KEY) .data(SECRET_STRING) .signature(signature)) .forSingle(response -&gt; res.send(\"Valid: \" + response.isValid())) .exceptionally(res::send); } Enable the secrets engine on the default path. Disable the secrets engine on the default path. Create the encryption and signature keys. Delete the encryption and signature keys. Encrypt a secret. Decrypt a secret. Create an HMAC for text. Create a signature for text. Verify HMAC. Verify signature. Authentication with Kubernetes In order to use Kubernetes authentication: <markup lang=\"java\" >class K8sExample { private static final String SECRET_PATH = \"k8s/example/secret\"; private static final String POLICY_NAME = \"k8s_policy\"; private final Vault tokenVault; private final String k8sAddress; private final Config config; private final SysRx sys; private Vault k8sVault; K8sExample(Vault tokenVault, Config config) { this.tokenVault = tokenVault; this.sys = tokenVault.sys(SysRx.API); this.k8sAddress = config.get(\"cluster-address\").asString().get(); this.config = config; } public Single&lt;String&gt; run() { /* The following tasks must be run before we authenticate */ return enableK8sAuth() // Now we can login using k8s - must run within a k8s cluster (or you need the k8s configuration files locally) .flatMapSingle(ignored -&gt; workWithSecrets()) // Now back to token based Vault, as we will clean up .flatMapSingle(ignored -&gt; disableK8sAuth()) .map(ignored -&gt; \"k8s example finished successfully.\"); } private Single&lt;ApiResponse&gt; workWithSecrets() { Kv2SecretsRx secrets = k8sVault.secrets(Kv2SecretsRx.ENGINE); return secrets.create(SECRET_PATH, Map.of(\"secret-key\", \"secretValue\", \"secret-user\", \"username\")) .flatMapSingle(ignored -&gt; secrets.get(SECRET_PATH)) .peek(secret -&gt; { if (secret.isPresent()) { Kv2Secret kv2Secret = secret.get(); System.out.println(\"k8s first secret: \" + kv2Secret.value(\"secret-key\")); System.out.println(\"k8s second secret: \" + kv2Secret.value(\"secret-user\")); } else { System.out.println(\"k8s secret not found\"); } }).flatMapSingle(ignored -&gt; secrets.deleteAll(SECRET_PATH)); } private Single&lt;ApiResponse&gt; disableK8sAuth() { return sys.deletePolicy(POLICY_NAME) .flatMapSingle(ignored -&gt; sys.disableAuth(K8sAuthRx.AUTH_METHOD.defaultPath())); } private Single&lt;ApiResponse&gt; enableK8sAuth() { // enable the method return sys.enableAuth(K8sAuthRx.AUTH_METHOD) // add policy .flatMapSingle(ignored -&gt; sys.createPolicy(POLICY_NAME, VaultPolicy.POLICY)) .flatMapSingle(ignored -&gt; tokenVault.auth(K8sAuthRx.AUTH_METHOD) .configure(ConfigureK8s.Request.builder() .address(k8sAddress))) .flatMapSingle(ignored -&gt; tokenVault.auth(K8sAuthRx.AUTH_METHOD) // this must be the same role name as is defined in application.yaml .createRole(CreateRole.Request.builder() .roleName(\"my-role\") .addBoundServiceAccountName(\"*\") .addBoundServiceAccountNamespace(\"default\") .addTokenPolicy(POLICY_NAME))) .peek(ignored -&gt; k8sVault = Vault.create(config)) .map(Function.identity()); } } Run the Kubernetes Authentication by enabling it. Create Kubernetes secrets. Disable Kubernetes authentication if needed. Function used to enable Kubernetes authentication. ",
            "title": "Examples"
        },
        {
            "location": "se/integrations/hcv",
            "text": " Vault is available as a docker image, so to test locally, you can simply: <markup lang=\"bash\" >docker run -e VAULT_DEV_ROOT_TOKEN_ID=my-token -d --name=vault -p8200:8200 vault This will create a Vault docker image, run it in background and open it on localhost:8200 with a custom root token my-token, using name vault. This is of course only suitable for local testing, as the root token has too many rights, but it can be easily used with the examples below. ",
            "title": "Local testing"
        },
        {
            "location": "se/integrations/hcv",
            "text": " Hashicorp Vault Usage Examples ",
            "title": "References"
        },
        {
            "location": "se/integrations/neo4j",
            "text": " Overview Maven Coordinates Usage Configuration Examples Additional Information References ",
            "title": "Contents"
        },
        {
            "location": "se/integrations/neo4j",
            "text": " Neo4j is a graph database management system developed by Neo4j, Inc. It is an ACID-compliant transactional database with native graph storage and processing. Neo4j is available in a GPL3-licensed open-source “community edition”. ",
            "title": "Overview"
        },
        {
            "location": "se/integrations/neo4j",
            "text": " To enable Neo4j add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.neo4j&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-neo4j&lt;/artifactId&gt; &lt;/dependency&gt; Check Neo4j Metrics Propagation and Neo4j Health Checks for additional dependencies for Neo4j Metrics and Health Checks integration. ",
            "title": "Maven Coordinates"
        },
        {
            "location": "se/integrations/neo4j",
            "text": " The support for Neo4j is implemented in Neo4j driver level. Just add the dependency, add configuration in application.yaml file and Neo4j driver will be configured by Helidon and can be used with Neo4j support object. To implement Neo4j, you must first provide the connection properties as shown below: <markup lang=\"properties\" >neo4j: uri: bolt://localhost:7687 authentication: username: neo4j password: secret pool: metricsEnabled: true Then just get the driver: <markup lang=\"java\" >Neo4j neo4j = Neo4j.create(config.get(\"neo4j\")); Driver neo4jDriver = neo4j.driver(); The driver can be used according to the Neo4j documentation . ",
            "title": "Usage"
        },
        {
            "location": "se/integrations/neo4j",
            "text": " MicroProfile configuration options: key type default value description mp.jwt.verify.publickey string &#160; The property allows the Public Verification Key text itself to be supplied as a string. authentication.username string &#160; Neo4j authentication user name authentication.password string &#160; Neo4j authentication password authentication.enabled boolean TRUE If Neo4j authentication is enabled encrypted boolean FALSE If Neo4j encryption is enabled pool.metricsEnabled boolean FALSE If Neo4J metrics is enabled pool.logLeakedSessions boolean &#160; Log leaking sessions pool.maxConnectionPoolSize string &#160; Maximum connection pool size pool.idleTimeBeforeConnectionTest string &#160; Idle time before connection test pool.maxConnectionLifetime string &#160; Connection lifetime in seconds pool.connectionAcquisitionTimeout string &#160; Connection Acquisition Timeout trustsettings.trustStrategy string &#160; Trust Strategy: Trust All certificates, TRUST_ALL_CERTIFICATES , Trust custom certificates - TRUST_CUSTOM_CA_SIGNED_CERTIFICATES , Trust system CA - TRUST_SYSTEM_CA_SIGNED_CERTIFICATES trustsettings.certificate string &#160; Path to trusted certificate trustsettings.hostnameVerificationEnabled string FALSE If hostname verification is enabled. ",
            "title": "Configuration"
        },
        {
            "location": "se/integrations/neo4j",
            "text": " This example implements a simple Neo4j REST service using MicroProfile. For this example a working Neo4j database is required. The Neo4j Movie database is used for this example. Bring up a Neo4j instance via Docker <markup lang=\"bash\" >docker run --publish=7474:7474 --publish=7687:7687 -e 'NEO4J_AUTH=neo4j/secret' neo4j:latest Go to the Neo4j browser and play the first step of the movies graph: :play movies Now go to the pom.xml and add the following dependencies: <markup lang=\"xml\" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.neo4j&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-neo4j&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.neo4j&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-neo4j-metrics&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.neo4j&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-neo4j-health&lt;/artifactId&gt; &lt;/dependency&gt; Next add the connection configuration properties for Neo4j: <markup lang=\"properties\" >neo4j: uri: bolt://localhost:7687 authentication: username: neo4j password: secret pool: metricsEnabled: true This includes both connection information and enables Neo4j metrics propagation. Finally, we are able to use the Neo4j driver. <markup lang=\"java\" >@ApplicationScoped public class MovieRepository { private final Driver driver; public MovieRepository(Driver driver) { this.driver = driver; } public List&lt;Movie&gt; findAll() { try (var session = driver.session()) { var query = \"\" + \"match (m:Movie) \" + \"match (m) &lt;- [:DIRECTED] - (d:Person) \" + \"match (m) &lt;- [r:ACTED_IN] - (a:Person) \" + \"return m, collect(d) as directors, collect({name:a.name, roles: r.roles}) as actors\"; return session.readTransaction(tx -&gt; tx.run(query).list(r -&gt; { var movieNode = r.get(\"m\").asNode(); var directors = r.get(\"directors\").asList(v -&gt; { var personNode = v.asNode(); return new Person(personNode.get(\"born\").asInt(), personNode.get(\"name\").asString()); }); var actors = r.get(\"actors\").asList(v -&gt; { return new Actor(v.get(\"name\").asString(), v.get(\"roles\").asList(Value::asString)); }); var m = new Movie(movieNode.get(\"title\").asString(), movieNode.get(\"tagline\").asString()); m.setReleased(movieNode.get(\"released\").asInt()); m.setDirectorss(directors); m.setActors(actors); return m; })); } } } Constructor with Neo4j driver parameter Use Neo4j driver to extract all Movies Movies can now be returned as JSON objects: <markup lang=\"java\" >public class MovieService implements Service { private final MovieRepository movieRepository; public MovieService(MovieRepository movieRepository) { this.movieRepository = movieRepository; } @Override public void update(Routing.Rules rules) { rules.get(\"/api/movies\", this::findMoviesHandler); } private void findMoviesHandler(ServerRequest request, ServerResponse response) { response.send(this.movieRepository.findAll()); } } To use the service, as well as to add metrics and health support, the following routing should be created: <markup lang=\"java\" >private static Routing createRouting(Config config) { MetricsSupport metrics = MetricsSupport.create(); Neo4j neo4j = Neo4j.create(config.get(\"neo4j\")); // registers all metrics Neo4jMetricsSupport.builder() .driver(neo4j.driver()) .build() .initialize(); Neo4jHealthCheck healthCheck = Neo4jHealthCheck.create(neo4j.driver()); Driver neo4jDriver = neo4j.driver(); MovieService movieService = new MovieService(new MovieRepository(neo4jDriver)); HealthSupport health = HealthSupport.builder() .addLiveness(HealthChecks.healthChecks()) // Adds a convenient set of checks .addReadiness(healthCheck) .build(); return Routing.builder() .register(health) // Health at \"/health\" .register(metrics) // Metrics at \"/metrics\" .register(movieService) .build(); } Use of Neo4j support object to initialise and configure the driver. Use of Neo4jMetricsSupport to add Neo4j metrics to /metrics output. Use of Neo4jHealthCheck to add Neo4j health support. Initialize MovieService with Neo4j driver. Register the services in Routing . Now build and run with JDK17+ <markup lang=\"bash\" >mvn package java -jar target/helidon-examples-integration-neo4j-mp.jar Exercise the application: <markup lang=\"bash\" >curl -X GET http://localhost:8080/movies {. . .} # Try health and metrics curl -s -X GET http://localhost:8080/health {\"outcome\":\"UP\",... . . . # Prometheus Format curl -s -X GET http://localhost:8080/metrics # TYPE base:gc_g1_young_generation_count gauge . . . # JSON Format curl -H 'Accept: application/json' -X GET http://localhost:8080/metrics {\"base\":... . . . Full example code is available in Helidon GitHub Repository . ",
            "title": "Examples"
        },
        {
            "location": "se/integrations/neo4j",
            "text": " Neo4j metrics can be propagated to the user as MicroProfile metrics. This is implemented in a separate Maven module. Just add: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.neo4j&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-neo4j-metrics&lt;/artifactId&gt; &lt;/dependency&gt; Works with Neo4j Integration main dependency described in Maven Coordinates . To enable metrics in Neo4j, add the following property to application.yaml : <markup lang=\"yaml\" >pool: metricsEnabled: true Finally, to initialize metrics run: <markup lang=\"java\" >Neo4jMetricsSupport.builder() .driver(neo4j.driver()) .build() .initialize(); Neo4j metrics will be automatically added to the output of the /metrics endpoint. ",
            "title": "Neo4j Metrics Propagation"
        },
        {
            "location": "se/integrations/neo4j",
            "text": " If your application is highly dependent on Neo4j database, health and liveness checks are essential for this application to work correctly. MicroProfile Health checks for Neo4j are implemented in a separate Maven module: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.neo4j&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-neo4j-health&lt;/artifactId&gt; &lt;/dependency&gt; Works with Neo4j Integration main dependency described in Maven Coordinates . To enable health checks run the following code: <markup lang=\"java\" >Neo4jHealthCheck healthCheck = Neo4jHealthCheck.create(neo4j.driver()); HealthSupport health = HealthSupport.builder() .addReadiness(healthCheck) .build(); Health checks for Neo4j will be included in /health endpoint output. ",
            "title": "Neo4j Health Checks"
        },
        {
            "location": "se/integrations/neo4j",
            "text": " Neo4j Metrics Propagation Neo4j metrics can be propagated to the user as MicroProfile metrics. This is implemented in a separate Maven module. Just add: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.neo4j&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-neo4j-metrics&lt;/artifactId&gt; &lt;/dependency&gt; Works with Neo4j Integration main dependency described in Maven Coordinates . To enable metrics in Neo4j, add the following property to application.yaml : <markup lang=\"yaml\" >pool: metricsEnabled: true Finally, to initialize metrics run: <markup lang=\"java\" >Neo4jMetricsSupport.builder() .driver(neo4j.driver()) .build() .initialize(); Neo4j metrics will be automatically added to the output of the /metrics endpoint. Neo4j Health Checks If your application is highly dependent on Neo4j database, health and liveness checks are essential for this application to work correctly. MicroProfile Health checks for Neo4j are implemented in a separate Maven module: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.neo4j&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-neo4j-health&lt;/artifactId&gt; &lt;/dependency&gt; Works with Neo4j Integration main dependency described in Maven Coordinates . To enable health checks run the following code: <markup lang=\"java\" >Neo4jHealthCheck healthCheck = Neo4jHealthCheck.create(neo4j.driver()); HealthSupport health = HealthSupport.builder() .addReadiness(healthCheck) .build(); Health checks for Neo4j will be included in /health endpoint output. ",
            "title": "Additional Information"
        },
        {
            "location": "se/integrations/neo4j",
            "text": " Neo4j official website Neo4j Java developer guide ",
            "title": "References"
        },
        {
            "location": "se/integrations/oci",
            "text": " Overview Usage Examples References ",
            "title": "Contents"
        },
        {
            "location": "se/integrations/oci",
            "text": " Helidon SE OCI Integration provides easy access to Oracle Cloud Infrastructure using the OCI Java SDK. OCI SDK uses JAX-RS Client 2.1.6 (javax package names), which makes it incompatible with Helidon 3 applications and any application that uses JAX-RS 3 (jakarta package naming). See Resolving compatibility issue with OCI SDK for detailed information on how to work around this issue. ",
            "title": "Overview"
        },
        {
            "location": "se/integrations/oci",
            "text": " Authentication with OCI is abstracted through AuthenticationDetailsProvider . If your environment is already set up to work with the OCI SDK or the OCI command line, then it is very likely you do not need to do any additional configuration. It is recommended that you do this first, and verify your configuration by using the OCI CLI to access the service. <markup lang=\"java\" >ConfigFile config = ConfigFileReader.parse(\"~/.oci/config\", \"DEFAULT\"); AuthenticationDetailsProvider authProvider = new ConfigFileAuthenticationDetailsProvider(config); You also need to add the following dependency to your application for this <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;com.oracle.oci.sdk&lt;/groupId&gt; &lt;artifactId&gt;oci-java-sdk-common&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Configuring the OCI SDK Client"
        },
        {
            "location": "se/integrations/oci",
            "text": " Once you have authentication with OCI configured, you can use it to access any OCI service supported by the OCI SDK. You will need to add dependencies for the specific ODI SDK clients you will use. ",
            "title": "Accessing OCI Services"
        },
        {
            "location": "se/integrations/oci",
            "text": " It is recommended that you use the OCI Java SDK directly, in particular the Async clients. All you need to do is configure and create an OCI SDK Client object. The configuration primarily consists of setting up authenticate with OCI. Configuring the OCI SDK Client Authentication with OCI is abstracted through AuthenticationDetailsProvider . If your environment is already set up to work with the OCI SDK or the OCI command line, then it is very likely you do not need to do any additional configuration. It is recommended that you do this first, and verify your configuration by using the OCI CLI to access the service. <markup lang=\"java\" >ConfigFile config = ConfigFileReader.parse(\"~/.oci/config\", \"DEFAULT\"); AuthenticationDetailsProvider authProvider = new ConfigFileAuthenticationDetailsProvider(config); You also need to add the following dependency to your application for this <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;com.oracle.oci.sdk&lt;/groupId&gt; &lt;artifactId&gt;oci-java-sdk-common&lt;/artifactId&gt; &lt;/dependency&gt; Accessing OCI Services Once you have authentication with OCI configured, you can use it to access any OCI service supported by the OCI SDK. You will need to add dependencies for the specific ODI SDK clients you will use. ",
            "title": "Usage"
        },
        {
            "location": "se/integrations/oci",
            "text": " Now you can create OCI SDK Clients. <markup lang=\"java\" >ConfigFile config = ConfigFileReader.parse(\"~/.oci/config\", \"DEFAULT\"); AuthenticationDetailsProvider authProvider = new ConfigFileAuthenticationDetailsProvider(config); ObjectStorageAsync objectStorageAsyncClient = new ObjectStorageAsyncClient(authProvider); ",
            "title": "Creating an Object Storage Client"
        },
        {
            "location": "se/integrations/oci",
            "text": " Once you have created an ObjectStorage client you can use it as described in: OCI SDK Object Storage Javadocs OCI Object Storage Overview ",
            "title": "Using the Object Storage client"
        },
        {
            "location": "se/integrations/oci",
            "text": " With Helidon 3.x, we are now implementing the MicroProfile 5.0 Platform and selected Jakarta EE 9.1 specifications. We are also going away from javax.* packages and fully embracing jakarta.* package. However, the current release 2.37.0 of OCI Java SDK is still using javax.* packages which created compatibility issues e.g. Helidon 3 uses JAX-RS 3.0.0 (jakarta package names) and the corresponding Jersey implementation. OCI SDK 2.37.0 uses JAX-RS Client 2.1.6 (javax package names) and the corresponding Jersey implementation. Therefore, the OCI SDK is incompatible with Helidon 3 applications and any application that uses JAX-RS 3. We have filed an issue with OCI SDK team, see https://github.com/oracle/oci-java-sdk/issues/371 for details on this. OCI SDK team has provided us with shaded jar as workaround as mentioned in the issue. Now, when you want to use modules from OCI SDK in your application, instead of using individual modules as defined in our OCI integration documentation, you need to use full shaded jar. <markup lang=\"xml\" > &lt;dependency&gt; &lt;groupId&gt;com.oracle.oci.sdk&lt;/groupId&gt; &lt;artifactId&gt;oci-java-sdk-shaded-full&lt;/artifactId&gt; &lt;version&gt;2.37.0&lt;/version&gt; &lt;/dependency&gt; Since the full shaded jar doesn&#8217;t bring in its transitive dependencies, you will also need to define following dependencies in your application so that it works at runtime. <markup lang=\"xml\" > &lt;dependency&gt; &lt;groupId&gt;org.bouncycastle&lt;/groupId&gt; &lt;artifactId&gt;bcpkix-jdk15on&lt;/artifactId&gt; &lt;version&gt;1.70&lt;/version&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-jdk14&lt;/artifactId&gt; &lt;version&gt;1.7.32&lt;/version&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; Please refer to our OCI SDK Usage Examples to see this in action. ",
            "title": "Resolving javax and jakarta package compatibility issue with OCI SDK"
        },
        {
            "location": "se/integrations/oci",
            "text": " This example describes how to access OCI Object Storage. As mentioned above in , you need to add a dependency on the OCI SDK Object Storage API: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;com.oracle.oci.sdk&lt;/groupId&gt; &lt;artifactId&gt;oci-java-sdk-objectstorage&lt;/artifactId&gt; &lt;/dependency&gt; Creating an Object Storage Client Now you can create OCI SDK Clients. <markup lang=\"java\" >ConfigFile config = ConfigFileReader.parse(\"~/.oci/config\", \"DEFAULT\"); AuthenticationDetailsProvider authProvider = new ConfigFileAuthenticationDetailsProvider(config); ObjectStorageAsync objectStorageAsyncClient = new ObjectStorageAsyncClient(authProvider); Using the Object Storage client Once you have created an ObjectStorage client you can use it as described in: OCI SDK Object Storage Javadocs OCI Object Storage Overview Resolving javax and jakarta package compatibility issue with OCI SDK With Helidon 3.x, we are now implementing the MicroProfile 5.0 Platform and selected Jakarta EE 9.1 specifications. We are also going away from javax.* packages and fully embracing jakarta.* package. However, the current release 2.37.0 of OCI Java SDK is still using javax.* packages which created compatibility issues e.g. Helidon 3 uses JAX-RS 3.0.0 (jakarta package names) and the corresponding Jersey implementation. OCI SDK 2.37.0 uses JAX-RS Client 2.1.6 (javax package names) and the corresponding Jersey implementation. Therefore, the OCI SDK is incompatible with Helidon 3 applications and any application that uses JAX-RS 3. We have filed an issue with OCI SDK team, see https://github.com/oracle/oci-java-sdk/issues/371 for details on this. OCI SDK team has provided us with shaded jar as workaround as mentioned in the issue. Now, when you want to use modules from OCI SDK in your application, instead of using individual modules as defined in our OCI integration documentation, you need to use full shaded jar. <markup lang=\"xml\" > &lt;dependency&gt; &lt;groupId&gt;com.oracle.oci.sdk&lt;/groupId&gt; &lt;artifactId&gt;oci-java-sdk-shaded-full&lt;/artifactId&gt; &lt;version&gt;2.37.0&lt;/version&gt; &lt;/dependency&gt; Since the full shaded jar doesn&#8217;t bring in its transitive dependencies, you will also need to define following dependencies in your application so that it works at runtime. <markup lang=\"xml\" > &lt;dependency&gt; &lt;groupId&gt;org.bouncycastle&lt;/groupId&gt; &lt;artifactId&gt;bcpkix-jdk15on&lt;/artifactId&gt; &lt;version&gt;1.70&lt;/version&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-jdk14&lt;/artifactId&gt; &lt;version&gt;1.7.32&lt;/version&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; Please refer to our OCI SDK Usage Examples to see this in action. ",
            "title": "Examples"
        },
        {
            "location": "se/integrations/oci",
            "text": " OCI SDK Usage Examples OCI Documentation ] ",
            "title": "References"
        },
        {
            "location": "se/introduction",
            "text": " Helidon SE is a compact toolkit that embraces the latest Java SE features: reactive streams, asynchronous and functional programming, and fluent-style APIs. ",
            "title": "preambule"
        },
        {
            "location": "se/introduction",
            "text": " The REST framework for Helidon SE is the Helidon WebServer. It is built on top of Netty and uses a straight forward request routing API. Helidon SE supports a number of additional Helidon features: save Ahead-of-Time Compilation (AOT) Use GraalVM native image to compile Helidon applications into a native executable. settings Config A flexible configuration framework with support for multiple sources and formats. share CORS Add support for CORS to your application using a Helidon module. storage DB Client Provides a unified, reactive API for working with databases in non-blocking way. graphic_eq GraphQL Build GraphQL servers. swap_horiz gRPC Build gRPC servers and clients. favorite_outline Health Checks Expose health statuses of your applications. av_timer Metrics Instrumentation to expose metrics of your applications. donut_large OpenAPI Support OpenAPI from your application. message Reactive Messaging Use prepared tools for repetitive use case scenarios. waves Reactive Streams APIs to work with reactive streams in Helidon. security Security A tool-chain to handle authentication, authorization and context propagation. timeline Tracing Profile and monitor your applications across multiple services. http WebClient HTTP client that handles responses to the HTTP requests in a reactive way. settings_ethernet WebServer A programmatic HTTP API with reactive features, powered by Netty. timeline WebSocket Enables Java applications to participate in WebSocket interactions as both servers and clients. ",
            "title": "Components"
        },
        {
            "location": "se/introduction",
            "text": " In case you need to upgrade the version of Helidon, follow the migration guides . upgrade Helidon SE 2.x Migration Guide Follow this guide to migrate your application from Helidon 1.x to 2.x. upgrade Helidon SE 3.x Migration Guide Follow this guide to migrate your application from Helidon 2.x to 3.x. ",
            "title": "Migration"
        },
        {
            "location": "se/introduction",
            "text": " Try the Helidon SE quickstart guides to get your first Helidon SE application up and running in minutes. explore Guides Follow step-by-step guides to build your applications using Helidon SE. link Javadocs Browse the Helidon Javadocs. ",
            "title": "Next Steps"
        },
        {
            "location": "se/metrics/metrics-capable-components",
            "text": " Overview Usage Examples ",
            "title": "Contents"
        },
        {
            "location": "se/metrics/metrics-capable-components",
            "text": " The Helidon metrics API This API allows your code to register, look-up, remove, and update metrics using the RegistryFactory , MetricRegistry , and individual metrics interfaces. The Helidon metrics REST service API This API allows your code to set up and respond to the /metrics endpoint so clients can retreive metrics information. ",
            "title": "APIs"
        },
        {
            "location": "se/metrics/metrics-capable-components",
            "text": " Implementations of the Helidon metrics API. Helidon provides two&#8212;&#8203;minimal and full-featured&#8212;&#8203;and selects which one to use at runtime, based on what components are present on the runtime path and whether metrics is configured to be enabled or disabled. You control which implementation your Helidon SE service uses by which dependency you add to your project. Implementations of the Helidon metrics REST service API. Helidon provides two&#8212;&#8203;minimal and full-featured&#8212;&#8203;and selects which one to use at runtime. Your Helidon SE app provides this feature (if at all) by explicitly using the MetricsSupport interface. Most Helidon SE applications are web-based and their developers choose to expose the built-in metrics web service. But by separating the parts of metrics this way, Helidon allows non-web apps to work with metrics as well, just without the web service support. As you plan and write Helidon components and applications, you make some choices about exactly how your code will use metrics. This document gives some background information, describes each option and its effect, and provides some code examples. ",
            "title": "Implementations of the APIs"
        },
        {
            "location": "se/metrics/metrics-capable-components",
            "text": " This document explains Helidon SE metrics-capable components and applications and describes how to create and control them. Think of Helidon metrics in several related but different parts: APIs The Helidon metrics API This API allows your code to register, look-up, remove, and update metrics using the RegistryFactory , MetricRegistry , and individual metrics interfaces. The Helidon metrics REST service API This API allows your code to set up and respond to the /metrics endpoint so clients can retreive metrics information. Implementations of the APIs Implementations of the Helidon metrics API. Helidon provides two&#8212;&#8203;minimal and full-featured&#8212;&#8203;and selects which one to use at runtime, based on what components are present on the runtime path and whether metrics is configured to be enabled or disabled. You control which implementation your Helidon SE service uses by which dependency you add to your project. Implementations of the Helidon metrics REST service API. Helidon provides two&#8212;&#8203;minimal and full-featured&#8212;&#8203;and selects which one to use at runtime. Your Helidon SE app provides this feature (if at all) by explicitly using the MetricsSupport interface. Most Helidon SE applications are web-based and their developers choose to expose the built-in metrics web service. But by separating the parts of metrics this way, Helidon allows non-web apps to work with metrics as well, just without the web service support. As you plan and write Helidon components and applications, you make some choices about exactly how your code will use metrics. This document gives some background information, describes each option and its effect, and provides some code examples. ",
            "title": "Overview"
        },
        {
            "location": "se/metrics/metrics-capable-components",
            "text": " We can place each Helidon component and Helidon application into one of three categories based on how it relies on metrics. The type of module dictates the compile-time dependency you declare in the project pom.xml . Types of Metrics Usage Registers, updates, removes metrics? Refers to metrics values? Category times times metrics-independent check times metrics-capable check check metrics-dependent Whenever possible, if your component or application uses metrics, then write it as metrics-capable code. ",
            "title": "Categorizing Metrics Usage"
        },
        {
            "location": "se/metrics/metrics-capable-components",
            "text": " Helidon provides two metrics implementations: Full-featured metrics allows registering, removing, and updating metrics and observing metrics' changing values. The helidon-metrics component contains full-featured metrics. Minimal metrics supports registering, removing, and updating metrics. The metrics objects provided by the minimal implementation are no-ops: their values never change. The minimal implementation is part of the helidon-metrics-api component. Any code compiled with helidon-metrics-api can assume that the runtime path will include the minimal implementation. Both implementations support all the operations of the RegistryFactory and the MetricRegistry . The full implementation provides fully-functional metrics instances (counters, timers, etc.). In the minimal implementations, metrics do not update their values. For Helidon to use the full implementation, two conditions must hold: The helidon-metrics component must be on the runtime path. Metrics must be enabled, using either a builder or configuration. (Enabled is the default.) Otherwise, provided that the runtime path includes helidon-metrics-api , Helidon activates the minimal implementation. ",
            "title": "Understanding the Two Metrics Implementations"
        },
        {
            "location": "se/metrics/metrics-capable-components",
            "text": " Helidon includes two implementations of support for the metrics web service endpoint /metrics (or whatever context value is configured). The full-service implementation sends responses which describe the metadata and current values for the metrics registered in metric registries. The helidon-metrics component contains this implementation. The helidon-metrics-service-api component contains the API for the metrics web service support (the MetricsSupport interface) and also a minimal implementation. This implementation simply responds with 404 and an explanatory message that metrics are disabled. Any code compiled with helidon-metrics-service-api can assume that the runtime path will contain the minimal implementation. Helidon activates the full implementation if the runtime path includes the full implementation and metrics is configured as enabled; Helidon uses the minimal implementation otherwise. ",
            "title": "Understanding the Two Metrics Service Implementations"
        },
        {
            "location": "se/metrics/metrics-capable-components",
            "text": " Using either builder-style settings or configuration, your component or Helidon SE application can let end users control at runtime whether Helidon should use full-featured metrics. If an end user sets metrics.enabled to false , then Helidon activates the minimal metrics and metrics service implementations provided they are in the runtime path. Further, users can set component-name.metrics.enabled to false which disables metrics for just that component so long as the component was written to check that setting and act on it accordingly. ",
            "title": "Enabling and Disabling Metrics"
        },
        {
            "location": "se/metrics/metrics-capable-components",
            "text": " Include this dependency: <markup lang=\"xml\" title=\"Dependency for Helidon metrics API\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics-api&lt;/artifactId&gt; &lt;/dependency&gt; This module defines the metrics API: RegistryFactory , MetricRegistry , and the various metrics themselves. To permit the use of the built-in metrics web service support for the /metrics endpoint, add this dependency: <markup lang=\"xml\" title=\"Dependency for metrics web service support\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics-service-api&lt;/artifactId&gt; &lt;/dependency&gt; This module defines the metrics web service API: MetricsSupport . Use the MetricsSupport interface from helidon-metrics-service-api in your SE app initialization code to create a service you can register with the web server. (See the example below .) Declare an explicit runtime dependency on the full-featured metrics implementation: <markup lang=\"xml\" title=\"Dependency for full metrics and metrics service implementations\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; ",
            "title": "Declaring Dependencies"
        },
        {
            "location": "se/metrics/metrics-capable-components",
            "text": " Whoever packages and deploys your application or component can control what code will be on the runtime path and whether metrics is enabled or not. As a result, wherever possible, construct your modules which use metrics so that they do not make decisions based on the values of metrics; that is, design them to be metrics-capable, not metrics-dependent. Doing so allows your code to operate regardless of whether the full-featured metrics implementation is active at runtime. Declaring Dependencies Include this dependency: <markup lang=\"xml\" title=\"Dependency for Helidon metrics API\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics-api&lt;/artifactId&gt; &lt;/dependency&gt; This module defines the metrics API: RegistryFactory , MetricRegistry , and the various metrics themselves. To permit the use of the built-in metrics web service support for the /metrics endpoint, add this dependency: <markup lang=\"xml\" title=\"Dependency for metrics web service support\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics-service-api&lt;/artifactId&gt; &lt;/dependency&gt; This module defines the metrics web service API: MetricsSupport . Use the MetricsSupport interface from helidon-metrics-service-api in your SE app initialization code to create a service you can register with the web server. (See the example below .) Declare an explicit runtime dependency on the full-featured metrics implementation: <markup lang=\"xml\" title=\"Dependency for full metrics and metrics service implementations\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; ",
            "title": "Designing and Writing Metrics-capable Applications and Components"
        },
        {
            "location": "se/metrics/metrics-capable-components",
            "text": " Write your SE application similarly, but do not use the ComponentMetricsSettings . Instead, build a MetricsSettings object from the configuration. <markup lang=\"java\" title=\"Example code to support disabling metrics usage in a component\" >import io.helidon.config.Config; import io.helidon.metrics.api.MetricsSettings; import io.helidon.metrics.api.RegistryFactory; import io.helidon.webserver.WebServer; import org.eclipse.microprofile.metrics.MetricRegistry; public class MyApp { private static MetricsSettings metricsSettings; static MetricRegistry metricRegistry; public static void main(final String[] args) { startServer(); } static Single&lt;WebServer&gt; startServer() { Config config = Config.create(); metricsSettings = MetricsSettings.builder() .config(config) .build(); metricRegistry = RegistryFactory.getInstance(metricsSettings) .getRegistry(MetricRegistry.Type.APPLICATION); WebServer server = WebServer.builder(createRouting(config)) .config(config.get(\"server\")) .addMediaSupport(JsonpSupport.create()) .build(); return server.start(); } private static Routing createRouting(Config config) { RestServiceSettings restServiceSettings = RestServiceSettings.create(config); MetricsSupport metricsSupport = MetricsSupport.create(metricsSettings, restServiceSettings); GreetService greetService = new GreetService(config); return Routing.builder() .register(metricsSupport) .register(\"/greet\", greetService) .build(); } } Create and save MetricsSettings from config. Use MetricsSettings to get a suitable RegistryFactory , and use that to get the application registry. Pass config to createRouting which returns the Routing to initialize the web server. Use the config to create RestServiceSettings which controls the routing name, web context, and CORS set-up for the metrics endpoint. Create the MetricsSupport instance using the metrics and REST service settings. Add the properly initialized MetricsSupport instance as a service to the routing, along with the app&#8217;s own service. Helidon uses the enabled value from MetricsSettings in providing the correct implementations of both the RegistryFactory and the MetricsSupport . ",
            "title": "Writing and Packaging a Metrics-capable Helidon SE Application "
        },
        {
            "location": "se/metrics/metrics-capable-components",
            "text": " The way you write a metrics-capable module depends on whether it is a component (that is, not an application) or an application . Writing and Packaging a Metrics-capable Helidon SE Application Write your SE application similarly, but do not use the ComponentMetricsSettings . Instead, build a MetricsSettings object from the configuration. <markup lang=\"java\" title=\"Example code to support disabling metrics usage in a component\" >import io.helidon.config.Config; import io.helidon.metrics.api.MetricsSettings; import io.helidon.metrics.api.RegistryFactory; import io.helidon.webserver.WebServer; import org.eclipse.microprofile.metrics.MetricRegistry; public class MyApp { private static MetricsSettings metricsSettings; static MetricRegistry metricRegistry; public static void main(final String[] args) { startServer(); } static Single&lt;WebServer&gt; startServer() { Config config = Config.create(); metricsSettings = MetricsSettings.builder() .config(config) .build(); metricRegistry = RegistryFactory.getInstance(metricsSettings) .getRegistry(MetricRegistry.Type.APPLICATION); WebServer server = WebServer.builder(createRouting(config)) .config(config.get(\"server\")) .addMediaSupport(JsonpSupport.create()) .build(); return server.start(); } private static Routing createRouting(Config config) { RestServiceSettings restServiceSettings = RestServiceSettings.create(config); MetricsSupport metricsSupport = MetricsSupport.create(metricsSettings, restServiceSettings); GreetService greetService = new GreetService(config); return Routing.builder() .register(metricsSupport) .register(\"/greet\", greetService) .build(); } } Create and save MetricsSettings from config. Use MetricsSettings to get a suitable RegistryFactory , and use that to get the application registry. Pass config to createRouting which returns the Routing to initialize the web server. Use the config to create RestServiceSettings which controls the routing name, web context, and CORS set-up for the metrics endpoint. Create the MetricsSupport instance using the metrics and REST service settings. Add the properly initialized MetricsSupport instance as a service to the routing, along with the app&#8217;s own service. Helidon uses the enabled value from MetricsSettings in providing the correct implementations of both the RegistryFactory and the MetricsSupport . ",
            "title": "Writing Metrics-capable Code"
        },
        {
            "location": "se/metrics/metrics-capable-components",
            "text": " This section helps you decide how incorporate metrics into your software by describing the categories of metrics usage, explaining generally how Helidon implements metrics, and illustrating how to write the metrics-related code accordingly. Categorizing Metrics Usage We can place each Helidon component and Helidon application into one of three categories based on how it relies on metrics. The type of module dictates the compile-time dependency you declare in the project pom.xml . Types of Metrics Usage Registers, updates, removes metrics? Refers to metrics values? Category times times metrics-independent check times metrics-capable check check metrics-dependent Whenever possible, if your component or application uses metrics, then write it as metrics-capable code. Understanding the Two Metrics Implementations Helidon provides two metrics implementations: Full-featured metrics allows registering, removing, and updating metrics and observing metrics' changing values. The helidon-metrics component contains full-featured metrics. Minimal metrics supports registering, removing, and updating metrics. The metrics objects provided by the minimal implementation are no-ops: their values never change. The minimal implementation is part of the helidon-metrics-api component. Any code compiled with helidon-metrics-api can assume that the runtime path will include the minimal implementation. Both implementations support all the operations of the RegistryFactory and the MetricRegistry . The full implementation provides fully-functional metrics instances (counters, timers, etc.). In the minimal implementations, metrics do not update their values. For Helidon to use the full implementation, two conditions must hold: The helidon-metrics component must be on the runtime path. Metrics must be enabled, using either a builder or configuration. (Enabled is the default.) Otherwise, provided that the runtime path includes helidon-metrics-api , Helidon activates the minimal implementation. Understanding the Two Metrics Service Implementations Helidon includes two implementations of support for the metrics web service endpoint /metrics (or whatever context value is configured). The full-service implementation sends responses which describe the metadata and current values for the metrics registered in metric registries. The helidon-metrics component contains this implementation. The helidon-metrics-service-api component contains the API for the metrics web service support (the MetricsSupport interface) and also a minimal implementation. This implementation simply responds with 404 and an explanatory message that metrics are disabled. Any code compiled with helidon-metrics-service-api can assume that the runtime path will contain the minimal implementation. Helidon activates the full implementation if the runtime path includes the full implementation and metrics is configured as enabled; Helidon uses the minimal implementation otherwise. Enabling and Disabling Metrics Using either builder-style settings or configuration, your component or Helidon SE application can let end users control at runtime whether Helidon should use full-featured metrics. If an end user sets metrics.enabled to false , then Helidon activates the minimal metrics and metrics service implementations provided they are in the runtime path. Further, users can set component-name.metrics.enabled to false which disables metrics for just that component so long as the component was written to check that setting and act on it accordingly. Designing and Writing Metrics-capable Applications and Components Whoever packages and deploys your application or component can control what code will be on the runtime path and whether metrics is enabled or not. As a result, wherever possible, construct your modules which use metrics so that they do not make decisions based on the values of metrics; that is, design them to be metrics-capable, not metrics-dependent. Doing so allows your code to operate regardless of whether the full-featured metrics implementation is active at runtime. Declaring Dependencies Include this dependency: <markup lang=\"xml\" title=\"Dependency for Helidon metrics API\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics-api&lt;/artifactId&gt; &lt;/dependency&gt; This module defines the metrics API: RegistryFactory , MetricRegistry , and the various metrics themselves. To permit the use of the built-in metrics web service support for the /metrics endpoint, add this dependency: <markup lang=\"xml\" title=\"Dependency for metrics web service support\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics-service-api&lt;/artifactId&gt; &lt;/dependency&gt; This module defines the metrics web service API: MetricsSupport . Use the MetricsSupport interface from helidon-metrics-service-api in your SE app initialization code to create a service you can register with the web server. (See the example below .) Declare an explicit runtime dependency on the full-featured metrics implementation: <markup lang=\"xml\" title=\"Dependency for full metrics and metrics service implementations\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; Writing Metrics-capable Code The way you write a metrics-capable module depends on whether it is a component (that is, not an application) or an application . Writing and Packaging a Metrics-capable Helidon SE Application Write your SE application similarly, but do not use the ComponentMetricsSettings . Instead, build a MetricsSettings object from the configuration. <markup lang=\"java\" title=\"Example code to support disabling metrics usage in a component\" >import io.helidon.config.Config; import io.helidon.metrics.api.MetricsSettings; import io.helidon.metrics.api.RegistryFactory; import io.helidon.webserver.WebServer; import org.eclipse.microprofile.metrics.MetricRegistry; public class MyApp { private static MetricsSettings metricsSettings; static MetricRegistry metricRegistry; public static void main(final String[] args) { startServer(); } static Single&lt;WebServer&gt; startServer() { Config config = Config.create(); metricsSettings = MetricsSettings.builder() .config(config) .build(); metricRegistry = RegistryFactory.getInstance(metricsSettings) .getRegistry(MetricRegistry.Type.APPLICATION); WebServer server = WebServer.builder(createRouting(config)) .config(config.get(\"server\")) .addMediaSupport(JsonpSupport.create()) .build(); return server.start(); } private static Routing createRouting(Config config) { RestServiceSettings restServiceSettings = RestServiceSettings.create(config); MetricsSupport metricsSupport = MetricsSupport.create(metricsSettings, restServiceSettings); GreetService greetService = new GreetService(config); return Routing.builder() .register(metricsSupport) .register(\"/greet\", greetService) .build(); } } Create and save MetricsSettings from config. Use MetricsSettings to get a suitable RegistryFactory , and use that to get the application registry. Pass config to createRouting which returns the Routing to initialize the web server. Use the config to create RestServiceSettings which controls the routing name, web context, and CORS set-up for the metrics endpoint. Create the MetricsSupport instance using the metrics and REST service settings. Add the properly initialized MetricsSupport instance as a service to the routing, along with the app&#8217;s own service. Helidon uses the enabled value from MetricsSettings in providing the correct implementations of both the RegistryFactory and the MetricsSupport . ",
            "title": "Usage"
        },
        {
            "location": "se/metrics/metrics-capable-components",
            "text": " The following example shows how useful metrics-capable code can be in the context of building Docker images. You (or others) could assemble a Docker image with your metrics-capable app as its top layer or your metrics-capable component in a middle layer, built on a lower layer containing several Helidon modules including the full metrics implementation. When that Docker image runs, your app will run with full-featured metrics support. Separately, someone could build a similar Docker image which does not include the Helidon metrics implementation. In this Docker image, your app or component will run successfully but will not incur the overhead of actually updating the metrics it uses. Users can create different Docker images, some with full metrics support and some without, which all use a single version of your metrics-capable app or component which runs properly in either environment without change. ",
            "title": "Examples"
        },
        {
            "location": "se/metrics/metrics-capable-components",
            "text": " By writing a metrics-capable app or component, you give packagers and deployers of your code the flexibility to include or exclude the full metrics implementation at runtime as they see fit. Because your one module works correctly in either environment: The consumers of your app benefit by not needing to understand and choose between two different implementations of your module, or having to add both your main module and an optional add-on which adds metrics support to your module. You benefit by writing and maintaining a single module, not two: one that is metrics-independent and one that is metrics-dependent. ",
            "title": "Advantages of Writing Metrics-capable Modules"
        },
        {
            "location": "se/metrics/metrics-capable-components",
            "text": " Advantages of Writing Metrics-capable Modules By writing a metrics-capable app or component, you give packagers and deployers of your code the flexibility to include or exclude the full metrics implementation at runtime as they see fit. Because your one module works correctly in either environment: The consumers of your app benefit by not needing to understand and choose between two different implementations of your module, or having to add both your main module and an optional add-on which adds metrics support to your module. You benefit by writing and maintaining a single module, not two: one that is metrics-independent and one that is metrics-dependent. ",
            "title": "Additional Information"
        },
        {
            "location": "se/metrics/metrics",
            "text": " Overview Maven Coordinates Usage API Configuration Examples Additional Information ",
            "title": "Contents"
        },
        {
            "location": "se/metrics/metrics",
            "text": " Helidon SE metrics is inspired by&#8212;&#8203;but does not fully implement&#8212;&#8203;the MicroProfile Metrics specification. In particular, the Helidon metrics subsystem furnishes a unified way for Helidon servers to export monitoring data&#8212;&#8203;telemetry&#8212;&#8203;to management agents, and a unified Java API which all application programmers can use to register and update metrics to expose telemetry data from their services. Learn more about the MicroProfile Metrics specification . ",
            "title": "Overview"
        },
        {
            "location": "se/metrics/metrics",
            "text": " Helidon gives you flexibility in how you make metrics available to your service. This document explains your options. ",
            "title": "Other packaging options"
        },
        {
            "location": "se/metrics/metrics",
            "text": " To enable metrics add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" title=\"Packaging full-featured metrics\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics&lt;/artifactId&gt; &lt;/dependency&gt; Adding this dependency packages the full-featured metrics implementation with your service. Other packaging options Helidon gives you flexibility in how you make metrics available to your service. This document explains your options. ",
            "title": "Maven Coordinates"
        },
        {
            "location": "se/metrics/metrics",
            "text": " You add metrics to your service by writing code which explicitly invokes the metrics API to register metrics, retrieve previously-registered metrics, and update metric values. Later sections of this document describe how to do this. ",
            "title": "Instrumenting Your Service"
        },
        {
            "location": "se/metrics/metrics",
            "text": " Helidon distinguishes among three general types , or scopes, of metrics, as described in the MP metrics specification . Types (scopes) of metrics Type/scope Typical Usage base Mandated by the MP metrics specification, such as OS or Java runtime measurements (available heap, disk space, etc.). vendor Implemented by vendors, including the REST.request metrics and other key performance indicator measurements (described in later sections). application Declared via annotations or programmatically registered by your service code. When you add metrics annotations to your service code, Helidon registers the resulting metrics as type application . ",
            "title": "Categorizing Types of Metrics"
        },
        {
            "location": "se/metrics/metrics",
            "text": " A metric registry collects registered metrics of a given type. Helidon supports three registries, one for each of the three metrics types. When you add code to your service to create a metric programmatically, the code first locates the appropriate registry and then registers the metric with that registry. ",
            "title": "Metric Registries"
        },
        {
            "location": "se/metrics/metrics",
            "text": " When you add the metrics dependency to your project, Helidon automatically provides a built-in REST endpoint /metrics which responds with a report of the registered metrics and their values. Clients can request a particular output format. Formats for /metrics output Format Requested by OpenMetrics (Prometheus) default ( text/plain ) JSON Header Accept: application/json Clients can also limit the report by appending the metric type to the path: /metrics/base /metrics/vendor /metrics/application Further, clients can narrow down to a specific metric name by adding the name as a subpath such as /metrics/application/myCount . <markup lang=\"bash\" title=\"Example Reporting: Prometheus format\" >curl -s -H 'Accept: text/plain' -X GET http://localhost:8080/metrics/ # TYPE base:classloader_total_loaded_class_count counter # HELP base:classloader_total_loaded_class_count Displays the total number of classes that have been loaded since the Java virtual machine has started execution. base:classloader_total_loaded_class_count 3157 <markup lang=\"bash\" title=\"Example Reporting: JSON format\" >curl -s -H 'Accept: application/json' -X GET http://localhost:8080/metrics/ { \"base\" : { \"memory.maxHeap\" : 3817865216, \"memory.committedHeap\" : 335544320, } } In addition to your application metrics, the reports contain other metrics of interest such as system and VM information. ",
            "title": "Retrieving Metrics Reports from your Service"
        },
        {
            "location": "se/metrics/metrics",
            "text": " To enable the metrics REST endpoint: Create an instance of MetricsSupport , either directly as shown below or using its Builder . Include the MetricsSupport instance in your application&#8217;s routing. <markup lang=\"java\" >import io.helidon.metrics.serviceapi.MetricsSupport; Routing.builder() .register(MetricsSupport.create()) .register(\"/myapp\", new MyService()) .build(); ",
            "title": "Enabling the MetricsSupport REST Service"
        },
        {
            "location": "se/metrics/metrics",
            "text": " Instrumenting Your Service You add metrics to your service by writing code which explicitly invokes the metrics API to register metrics, retrieve previously-registered metrics, and update metric values. Later sections of this document describe how to do this. Categorizing Types of Metrics Helidon distinguishes among three general types , or scopes, of metrics, as described in the MP metrics specification . Types (scopes) of metrics Type/scope Typical Usage base Mandated by the MP metrics specification, such as OS or Java runtime measurements (available heap, disk space, etc.). vendor Implemented by vendors, including the REST.request metrics and other key performance indicator measurements (described in later sections). application Declared via annotations or programmatically registered by your service code. When you add metrics annotations to your service code, Helidon registers the resulting metrics as type application . Metric Registries A metric registry collects registered metrics of a given type. Helidon supports three registries, one for each of the three metrics types. When you add code to your service to create a metric programmatically, the code first locates the appropriate registry and then registers the metric with that registry. Retrieving Metrics Reports from your Service When you add the metrics dependency to your project, Helidon automatically provides a built-in REST endpoint /metrics which responds with a report of the registered metrics and their values. Clients can request a particular output format. Formats for /metrics output Format Requested by OpenMetrics (Prometheus) default ( text/plain ) JSON Header Accept: application/json Clients can also limit the report by appending the metric type to the path: /metrics/base /metrics/vendor /metrics/application Further, clients can narrow down to a specific metric name by adding the name as a subpath such as /metrics/application/myCount . <markup lang=\"bash\" title=\"Example Reporting: Prometheus format\" >curl -s -H 'Accept: text/plain' -X GET http://localhost:8080/metrics/ # TYPE base:classloader_total_loaded_class_count counter # HELP base:classloader_total_loaded_class_count Displays the total number of classes that have been loaded since the Java virtual machine has started execution. base:classloader_total_loaded_class_count 3157 <markup lang=\"bash\" title=\"Example Reporting: JSON format\" >curl -s -H 'Accept: application/json' -X GET http://localhost:8080/metrics/ { \"base\" : { \"memory.maxHeap\" : 3817865216, \"memory.committedHeap\" : 335544320, } } In addition to your application metrics, the reports contain other metrics of interest such as system and VM information. Enabling the MetricsSupport REST Service To enable the metrics REST endpoint: Create an instance of MetricsSupport , either directly as shown below or using its Builder . Include the MetricsSupport instance in your application&#8217;s routing. <markup lang=\"java\" >import io.helidon.metrics.serviceapi.MetricsSupport; Routing.builder() .register(MetricsSupport.create()) .register(\"/myapp\", new MyService()) .build(); ",
            "title": "Usage"
        },
        {
            "location": "se/metrics/metrics",
            "text": " The Helidon Metrics API is aligned with the MicroProfile Metrics API . That API defines the classes and interfaces for metric types, metric registries, and other related items. Helidon Metrics reuses that API for classes and interfaces (but not for annotations which Helidon SE does not support). The following table summarizes the metric types. Metric Types Metric Type Usage Counter Monotonically increasing count of events. ConcurrentGauge Increasing and decreasing measurement of currently-executing blocks of code. Gauge Access to a value managed by other code in the service. Meter Count of invocations and how frequently invocations have occurred. SimpleTimer Count of invocations and the total duration consumed by those invocations. Timer Frequency of invocations and the distribution of how long the invocations take. Each metric type has its own set of methods for updating and retrieving the metric&#8217;s value. ",
            "title": "Helidon Metrics API"
        },
        {
            "location": "se/metrics/metrics",
            "text": " To register or look up metrics programmatically, your service code uses one of the three MetricRegistry instances (base, vendor, and application) which Helidon furnishes automatically. To get a MetricRegistry reference, first get a Helidon RegistryFactory . Then invoke getRegistry on the RegistryFactory instance. The MetricRegistry allows your code to register new metrics, look up previously-registered metrics, and remove metrics. ",
            "title": "The MetricRegistry API"
        },
        {
            "location": "se/metrics/metrics",
            "text": " To work with Helidon Metrics in your code, follow these steps: Use a static method on the RegistryFactory to get a reference to the MetricRegistry instance you want to use. Use the MetricRegistry instance to register new metrics and look up previously-registered metrics. Use the metric reference returned from the MetricRegistry to update the metric or get its value. You can also use the MetricRegistry to remove an existing metric. Helidon Metrics API The Helidon Metrics API is aligned with the MicroProfile Metrics API . That API defines the classes and interfaces for metric types, metric registries, and other related items. Helidon Metrics reuses that API for classes and interfaces (but not for annotations which Helidon SE does not support). The following table summarizes the metric types. Metric Types Metric Type Usage Counter Monotonically increasing count of events. ConcurrentGauge Increasing and decreasing measurement of currently-executing blocks of code. Gauge Access to a value managed by other code in the service. Meter Count of invocations and how frequently invocations have occurred. SimpleTimer Count of invocations and the total duration consumed by those invocations. Timer Frequency of invocations and the distribution of how long the invocations take. Each metric type has its own set of methods for updating and retrieving the metric&#8217;s value. The MetricRegistry API To register or look up metrics programmatically, your service code uses one of the three MetricRegistry instances (base, vendor, and application) which Helidon furnishes automatically. To get a MetricRegistry reference, first get a Helidon RegistryFactory . Then invoke getRegistry on the RegistryFactory instance. The MetricRegistry allows your code to register new metrics, look up previously-registered metrics, and remove metrics. ",
            "title": "API"
        },
        {
            "location": "se/metrics/metrics",
            "text": " Optional configuration options key type default value description appName string &#160; Sets the value for the _app tag to be applied to all metrics. base BaseMetricsSettings &#160; Set the base metrics settings. cors CrossOriginConfig &#160; Sets the cross-origin config builder for use in establishing CORS support for the service endpoints. enabled boolean &#160; Sets whether metrics should be enabled. key-performance-indicators KeyPerformanceIndicatorMetricsSettings &#160; Set the KPI metrics settings. registries Map&lt;string, RegistrySettings&gt; &#160; Sets the registry settings for the specified registry type. routing string &#160; Sets the routing name to use for setting up the service&#8217;s endpoint. tags Map&lt;string, string&gt; &#160; Sets the global tags to be applied to all metrics. web-context string &#160; Sets the web context to use for the service&#8217;s endpoint. ",
            "title": "Configuration options"
        },
        {
            "location": "se/metrics/metrics",
            "text": " To control how the Helidon metrics subsystem behaves, add a metrics section to your configuration file, such as application.yaml . Type: io.helidon.metrics.serviceapi.MetricsSupport Configuration options Optional configuration options key type default value description appName string &#160; Sets the value for the _app tag to be applied to all metrics. base BaseMetricsSettings &#160; Set the base metrics settings. cors CrossOriginConfig &#160; Sets the cross-origin config builder for use in establishing CORS support for the service endpoints. enabled boolean &#160; Sets whether metrics should be enabled. key-performance-indicators KeyPerformanceIndicatorMetricsSettings &#160; Set the KPI metrics settings. registries Map&lt;string, RegistrySettings&gt; &#160; Sets the registry settings for the specified registry type. routing string &#160; Sets the routing name to use for setting up the service&#8217;s endpoint. tags Map&lt;string, string&gt; &#160; Sets the global tags to be applied to all metrics. web-context string &#160; Sets the web context to use for the service&#8217;s endpoint. ",
            "title": "Configuration"
        },
        {
            "location": "se/metrics/metrics",
            "text": " The following example illustrates registering and updating a new Counter in application code. <markup lang=\"java\" title=\"Define and use a Counter \" >import io.helidon.metrics.api.RegistryFactory; import org.eclipse.microprofile.metrics.Counter; import org.eclipse.microprofile.metrics.MetricRegistry; //... public class MyService implements Service { private final MetricRegistry registry = RegistryFactory.getInstance() .getRegistry(MetricRegistry.Type.APPLICATION); private final Counter accessCtr = registry.counter(\"accessctr\"); @Override public void update(Routing.Rules rules) { rules .any(this::countAccess) .get(\"/\", this::myGet); } private void countAccess(ServerRequest request, ServerResponse response) { accessCtr.inc(); request.next(); } } Get the application metric registry. Create a counter in that registry. Increment the counter for every request. Helidon-provided endpoints for /metrics do their work synchronously, using the same thread on which the request arrived via Netty. To prevent performance degradation, avoid including long-running code that can be invoked by these handlers while Helidon is responding to the metric. For example, if you implement your own application-specific metric types, you will write logic to format the JSON and OpenMetrics output for those metric types. Helidon invokes this formatting logic whenever a client accesses the /metrics endpoints, so make that formatting code as efficient as possible. ",
            "title": "Example Application Code"
        },
        {
            "location": "se/metrics/metrics",
            "text": "<markup lang=\"yaml\" title=\"Disabling metrics entirely\" >metrics: enabled: false Helidon does not update metrics, and the /metrics endpoints respond with 404 plus a message that the metrics subsystem is disabled. ",
            "title": "Disable Metrics Subsystem"
        },
        {
            "location": "se/metrics/metrics",
            "text": " You can be even more selective. Within a registry type you can configure up to two regular expression patterns: one matching metric names to exclude , and one matching metric names to include . Helidon updates and reports a metric only if two conditions hold: the metric name does not match the exclude regex pattern (if you define one), and either there is no include regex pattern, or the metric name matches the include pattern. Note Make sure any include regex pattern you specify matches all the metric names you want to capture. Suppose your application creates and updates a group of metrics with names such as myapp.xxx.queries , myapp.xxx.creates , myapp.xxx.updates , and myapp.xxx.deletes where xxx can be either supplier or customer . The following example gathers all metrics except those from your application regarding suppliers although supplier updates are included : <markup lang=\"yaml\" title=\"Disabling and enabling metrics by name\" >metrics: registries: - type: application filter: exclude: \"myapp\\.supplier\\..*\" include: \"myapp\\.supplier\\.updates\" This setting excludes metrics with names starting with myapp.supplier except for the metric myapp.supplier.updates . The exclude and include values are regular expressions. ",
            "title": "Disable Selected Metrics"
        },
        {
            "location": "se/metrics/metrics",
            "text": " Any time you include the Helidon metrics module in your application, Helidon tracks two basic performance indicator metrics: a Counter of all requests received ( requests.count ), and a Meter of all requests received ( requests.meter ). Helidon SE also includes additional, extended KPI metrics which are disabled by default: current number of requests in-flight - a ConcurrentGauge ( requests.inFlight ) of requests currently being processed long-running requests - a Meter ( requests.longRunning ) measuring the rate at which Helidon processes requests which take at least a given amount of time to complete; configurable, defaults to 10000 milliseconds (10 seconds) load - a Meter ( requests.load ) measuring the rate at which requests are worked on (as opposed to received) deferred - a Meter ( requests.deferred ) measuring the rate at which a request&#8217;s processing is delayed after Helidon receives the request You can enable and control these metrics using configuration: <markup lang=\"yaml\" title=\"Controlling extended KPI metrics\" >metrics: key-performance-indicators: extended: true long-running: threshold-ms: 2000 ",
            "title": "Collecting Basic and Extended Key Performance Indicator (KPI) Metrics"
        },
        {
            "location": "se/metrics/metrics",
            "text": " Metrics configuration is quite extensive and powerful and, therefore, a bit complicated. The rest of this section illustrates some of the most common scenarios: Disable metrics entirely. Selectively enable or disable metrics by metric registry type and, within type, by name. Choose whether to collect extended key performance indicator metrics. Disable Metrics Subsystem <markup lang=\"yaml\" title=\"Disabling metrics entirely\" >metrics: enabled: false Helidon does not update metrics, and the /metrics endpoints respond with 404 plus a message that the metrics subsystem is disabled. Disable Selected Metrics You can be even more selective. Within a registry type you can configure up to two regular expression patterns: one matching metric names to exclude , and one matching metric names to include . Helidon updates and reports a metric only if two conditions hold: the metric name does not match the exclude regex pattern (if you define one), and either there is no include regex pattern, or the metric name matches the include pattern. Note Make sure any include regex pattern you specify matches all the metric names you want to capture. Suppose your application creates and updates a group of metrics with names such as myapp.xxx.queries , myapp.xxx.creates , myapp.xxx.updates , and myapp.xxx.deletes where xxx can be either supplier or customer . The following example gathers all metrics except those from your application regarding suppliers although supplier updates are included : <markup lang=\"yaml\" title=\"Disabling and enabling metrics by name\" >metrics: registries: - type: application filter: exclude: \"myapp\\.supplier\\..*\" include: \"myapp\\.supplier\\.updates\" This setting excludes metrics with names starting with myapp.supplier except for the metric myapp.supplier.updates . The exclude and include values are regular expressions. Collecting Basic and Extended Key Performance Indicator (KPI) Metrics Any time you include the Helidon metrics module in your application, Helidon tracks two basic performance indicator metrics: a Counter of all requests received ( requests.count ), and a Meter of all requests received ( requests.meter ). Helidon SE also includes additional, extended KPI metrics which are disabled by default: current number of requests in-flight - a ConcurrentGauge ( requests.inFlight ) of requests currently being processed long-running requests - a Meter ( requests.longRunning ) measuring the rate at which Helidon processes requests which take at least a given amount of time to complete; configurable, defaults to 10000 milliseconds (10 seconds) load - a Meter ( requests.load ) measuring the rate at which requests are worked on (as opposed to received) deferred - a Meter ( requests.deferred ) measuring the rate at which a request&#8217;s processing is delayed after Helidon receives the request You can enable and control these metrics using configuration: <markup lang=\"yaml\" title=\"Controlling extended KPI metrics\" >metrics: key-performance-indicators: extended: true long-running: threshold-ms: 2000 ",
            "title": "Example Configuration"
        },
        {
            "location": "se/metrics/metrics",
            "text": " Helidon SE includes several prewritten example applications illustrating aspects of metrics: Enabling/disabling metrics using MetricsSettings Controlling key performance indicator metrics using configuration and KeyPerformanceIndicatorMetricsSettings . The rest of this section shows how to add a metric to your code and how to configure the Helidon metrics subsystem. Example Application Code The following example illustrates registering and updating a new Counter in application code. <markup lang=\"java\" title=\"Define and use a Counter \" >import io.helidon.metrics.api.RegistryFactory; import org.eclipse.microprofile.metrics.Counter; import org.eclipse.microprofile.metrics.MetricRegistry; //... public class MyService implements Service { private final MetricRegistry registry = RegistryFactory.getInstance() .getRegistry(MetricRegistry.Type.APPLICATION); private final Counter accessCtr = registry.counter(\"accessctr\"); @Override public void update(Routing.Rules rules) { rules .any(this::countAccess) .get(\"/\", this::myGet); } private void countAccess(ServerRequest request, ServerResponse response) { accessCtr.inc(); request.next(); } } Get the application metric registry. Create a counter in that registry. Increment the counter for every request. Helidon-provided endpoints for /metrics do their work synchronously, using the same thread on which the request arrived via Netty. To prevent performance degradation, avoid including long-running code that can be invoked by these handlers while Helidon is responding to the metric. For example, if you implement your own application-specific metric types, you will write logic to format the JSON and OpenMetrics output for those metric types. Helidon invokes this formatting logic whenever a client accesses the /metrics endpoints, so make that formatting code as efficient as possible. Example Configuration Metrics configuration is quite extensive and powerful and, therefore, a bit complicated. The rest of this section illustrates some of the most common scenarios: Disable metrics entirely. Selectively enable or disable metrics by metric registry type and, within type, by name. Choose whether to collect extended key performance indicator metrics. Disable Metrics Subsystem <markup lang=\"yaml\" title=\"Disabling metrics entirely\" >metrics: enabled: false Helidon does not update metrics, and the /metrics endpoints respond with 404 plus a message that the metrics subsystem is disabled. Disable Selected Metrics You can be even more selective. Within a registry type you can configure up to two regular expression patterns: one matching metric names to exclude , and one matching metric names to include . Helidon updates and reports a metric only if two conditions hold: the metric name does not match the exclude regex pattern (if you define one), and either there is no include regex pattern, or the metric name matches the include pattern. Note Make sure any include regex pattern you specify matches all the metric names you want to capture. Suppose your application creates and updates a group of metrics with names such as myapp.xxx.queries , myapp.xxx.creates , myapp.xxx.updates , and myapp.xxx.deletes where xxx can be either supplier or customer . The following example gathers all metrics except those from your application regarding suppliers although supplier updates are included : <markup lang=\"yaml\" title=\"Disabling and enabling metrics by name\" >metrics: registries: - type: application filter: exclude: \"myapp\\.supplier\\..*\" include: \"myapp\\.supplier\\.updates\" This setting excludes metrics with names starting with myapp.supplier except for the metric myapp.supplier.updates . The exclude and include values are regular expressions. Collecting Basic and Extended Key Performance Indicator (KPI) Metrics Any time you include the Helidon metrics module in your application, Helidon tracks two basic performance indicator metrics: a Counter of all requests received ( requests.count ), and a Meter of all requests received ( requests.meter ). Helidon SE also includes additional, extended KPI metrics which are disabled by default: current number of requests in-flight - a ConcurrentGauge ( requests.inFlight ) of requests currently being processed long-running requests - a Meter ( requests.longRunning ) measuring the rate at which Helidon processes requests which take at least a given amount of time to complete; configurable, defaults to 10000 milliseconds (10 seconds) load - a Meter ( requests.load ) measuring the rate at which requests are worked on (as opposed to received) deferred - a Meter ( requests.deferred ) measuring the rate at which a request&#8217;s processing is delayed after Helidon receives the request You can enable and control these metrics using configuration: <markup lang=\"yaml\" title=\"Controlling extended KPI metrics\" >metrics: key-performance-indicators: extended: true long-running: threshold-ms: 2000 ",
            "title": "Examples"
        },
        {
            "location": "se/metrics/metrics",
            "text": "<markup lang=\"xml\" title=\"Dependency for Helidon Prometheus API support\" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics-prometheus&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "se/metrics/metrics",
            "text": " Your application code uses the Prometheus API to manage metrics. To expose those metrics to clients via a REST endpoint, your code uses the PrometheusSupport interface which Helidon provides. ",
            "title": "Usage"
        },
        {
            "location": "se/metrics/metrics",
            "text": " Your code creates a PrometheusSupport object either using a static factory method (shown in the following example) or by using its Builder . <markup lang=\"java\" >import io.helidon.metrics.prometheus.PrometheusSupport; Routing.builder() .register(PrometheusSupport.create()) .register(\"/myapp\", new MyService()) .build(); This example uses the default Prometheus CollectorRegistry . By default, the PrometheusSupport and exposes its REST endpoint at the path /metrics . Use the builder obtained by PrometheusSupport.builder() to configure a different CollectorRegistry or a different path. ",
            "title": "API"
        },
        {
            "location": "se/metrics/metrics",
            "text": " Helidon provides optional support for the Prometheus metrics API. To use it, your service registers Prometheus support with your routing set-up. You can customize its configuration. For information about using Prometheus, see the Prometheus documentation: https://prometheus.io/docs/introduction/overview/ . Helidon&#8217;s fully-functional, built-in metrics implementation supports Prometheus (OpenMetrics) output. Use the optional support described in this section only if you want to use the Prometheus API from your application code. Maven Coordinates <markup lang=\"xml\" title=\"Dependency for Helidon Prometheus API support\" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics-prometheus&lt;/artifactId&gt; &lt;/dependency&gt; Usage Your application code uses the Prometheus API to manage metrics. To expose those metrics to clients via a REST endpoint, your code uses the PrometheusSupport interface which Helidon provides. API Your code creates a PrometheusSupport object either using a static factory method (shown in the following example) or by using its Builder . <markup lang=\"java\" >import io.helidon.metrics.prometheus.PrometheusSupport; Routing.builder() .register(PrometheusSupport.create()) .register(\"/myapp\", new MyService()) .build(); This example uses the default Prometheus CollectorRegistry . By default, the PrometheusSupport and exposes its REST endpoint at the path /metrics . Use the builder obtained by PrometheusSupport.builder() to configure a different CollectorRegistry or a different path. ",
            "title": "Support for the Prometheus Metrics API"
        },
        {
            "location": "se/metrics/metrics",
            "text": " Support for the Prometheus Metrics API Helidon provides optional support for the Prometheus metrics API. To use it, your service registers Prometheus support with your routing set-up. You can customize its configuration. For information about using Prometheus, see the Prometheus documentation: https://prometheus.io/docs/introduction/overview/ . Helidon&#8217;s fully-functional, built-in metrics implementation supports Prometheus (OpenMetrics) output. Use the optional support described in this section only if you want to use the Prometheus API from your application code. Maven Coordinates <markup lang=\"xml\" title=\"Dependency for Helidon Prometheus API support\" > &lt;dependency&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics-prometheus&lt;/artifactId&gt; &lt;/dependency&gt; Usage Your application code uses the Prometheus API to manage metrics. To expose those metrics to clients via a REST endpoint, your code uses the PrometheusSupport interface which Helidon provides. API Your code creates a PrometheusSupport object either using a static factory method (shown in the following example) or by using its Builder . <markup lang=\"java\" >import io.helidon.metrics.prometheus.PrometheusSupport; Routing.builder() .register(PrometheusSupport.create()) .register(\"/myapp\", new MyService()) .build(); This example uses the default Prometheus CollectorRegistry . By default, the PrometheusSupport and exposes its REST endpoint at the path /metrics . Use the builder obtained by PrometheusSupport.builder() to configure a different CollectorRegistry or a different path. ",
            "title": "Additional Information"
        },
        {
            "location": "se/metrics/micrometer",
            "text": " Overview Maven Coordinates Usage API Configuration Examples Additional Information ",
            "title": "Contents"
        },
        {
            "location": "se/metrics/micrometer",
            "text": " Helidon SE simplifies how you can use Micrometer for application-specific metrics: The endpoint /micrometer : A configurable endpoint that exposes metrics according to which Micrometer meter registry responds to the HTTP request. The MicrometerSupport class: A convenience class for enrolling Micrometer meter registries your application creates explicitly or for selecting which built-in Micrometer meter registries to use. Configuration to tailor the Prometheus and other Micrometer meter registries. In Helidon 3.0.2, Micrometer support is separate from the Helidon SE metrics API and the built-in Helidon metrics. ",
            "title": "Overview"
        },
        {
            "location": "se/metrics/micrometer",
            "text": " To enable Micrometer support add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.integrations.micrometer&lt;/groupId&gt; &lt;artifactId&gt;helidon-integrations-micrometer&lt;/artifactId&gt; &lt;/dependency&gt; Micrometer supports different types of meter registries which have different output styles and formats. Helidon provides built-in support for the Prometheus meter registry. To use other meter registry types, you will need to add dependencies for them to your pom.xml and, optionally, add code to your application or add configuration to set them up as you wish. ",
            "title": "Maven Coordinates"
        },
        {
            "location": "se/metrics/micrometer",
            "text": " Your code can create, look up, and update metrics programmatically using the Micrometer MeterRegistry API. The Micrometer concepts document provides a good starting point for learning how to use Micrometer&#8217;s interfaces and classes. ",
            "title": "Registering and Updating Meters"
        },
        {
            "location": "se/metrics/micrometer",
            "text": " Your application can easily have Helidon create a REST endpoint which clients can access to retrieve Micrometer metrics, by default at the /micrometer endpoint. Within Helidon, each type of meter registry is paired with some code that examines the incoming HTTP request to /micrometer and decides whether the request matches up with the associated meter registry. The first pairing that accepts the request returns the response. You will need to take advantage of this if your application uses additional meter registries beyond what Helidon automatically provides and you want those meter registries reflected in the output from the /micrometer REST endpoint. ",
            "title": "Accessing the Helidon Micrometer Endpoint"
        },
        {
            "location": "se/metrics/micrometer",
            "text": " Your application registers and updates Micrometer meters using annotations or direct use of the Micrometer API. Your users retrieve Micrometer meters using an endpoint which Helidon creates automatically. Registering and Updating Meters Your code can create, look up, and update metrics programmatically using the Micrometer MeterRegistry API. The Micrometer concepts document provides a good starting point for learning how to use Micrometer&#8217;s interfaces and classes. Accessing the Helidon Micrometer Endpoint Your application can easily have Helidon create a REST endpoint which clients can access to retrieve Micrometer metrics, by default at the /micrometer endpoint. Within Helidon, each type of meter registry is paired with some code that examines the incoming HTTP request to /micrometer and decides whether the request matches up with the associated meter registry. The first pairing that accepts the request returns the response. You will need to take advantage of this if your application uses additional meter registries beyond what Helidon automatically provides and you want those meter registries reflected in the output from the /micrometer REST endpoint. ",
            "title": "Usage"
        },
        {
            "location": "se/metrics/micrometer",
            "text": " Helidon provides no special API for dealing with Micrometer meters and meter registries beyond what Micrometer offers itself. Helidon does give you an easy way to expose a REST endpoint to report the meters stored in the Micrometer meter registry. The MicrometerSupport interface exposes static methods to directly create an instance of MicrometerSupport and to return a Builder instance so your code can fine-tune how the REST service behaves. ",
            "title": "The Helidon Micrometer API"
        },
        {
            "location": "se/metrics/micrometer",
            "text": " The Helidon Micrometer API Helidon provides no special API for dealing with Micrometer meters and meter registries beyond what Micrometer offers itself. Helidon does give you an easy way to expose a REST endpoint to report the meters stored in the Micrometer meter registry. The MicrometerSupport interface exposes static methods to directly create an instance of MicrometerSupport and to return a Builder instance so your code can fine-tune how the REST service behaves. ",
            "title": "API"
        },
        {
            "location": "se/metrics/micrometer",
            "text": " Optional configuration options key type default value description cors CrossOriginConfig &#160; Sets the cross-origin config builder for use in establishing CORS support for the service endpoints. routing string &#160; Sets the routing name to use for setting up the service&#8217;s endpoint. web-context string &#160; Sets the web context to use for the service&#8217;s endpoint. By default, Helidon Micrometer integration exposes the /micrometer endpoint. You can override the path using the Builder or the micrometer.web-context configuration key. <markup lang=\"yaml\" title=\"Overriding the default Micrometer path\" >micrometer: web-context: my-micrometer ",
            "title": "Configuration options"
        },
        {
            "location": "se/metrics/micrometer",
            "text": " You can configure the Helidon Micrometer REST service as you can other built-in Helidon services by adding configuration settings under the micrometer top-level key. Type: io.helidon.integrations.micrometer.MicrometerSupport <markup lang=\"text\" title=\"Config key\" >micrometer Configuration options Optional configuration options key type default value description cors CrossOriginConfig &#160; Sets the cross-origin config builder for use in establishing CORS support for the service endpoints. routing string &#160; Sets the routing name to use for setting up the service&#8217;s endpoint. web-context string &#160; Sets the web context to use for the service&#8217;s endpoint. By default, Helidon Micrometer integration exposes the /micrometer endpoint. You can override the path using the Builder or the micrometer.web-context configuration key. <markup lang=\"yaml\" title=\"Overriding the default Micrometer path\" >micrometer: web-context: my-micrometer ",
            "title": "Configuration"
        },
        {
            "location": "se/metrics/micrometer",
            "text": "<markup lang=\"java\" title=\"Initialize Micrometer support\" >import io.helidon.integrations.micrometer.MicrometerSupport; MicrometerSupport micrometerSupport = MicrometerSupport.create(); Routing.builder() .register(micrometerSupport) .register(\"/myapp\", new MyService(micrometerSupport.registry())) .build(); Create the MicrometerSupport instance, using the default built-in Prometheus meter registry. Register the MicrometerSupport instance as a service; by default, MicrometerSupport exposes the endpoint as /micrometer . Pass the MicrometerSupport object&#8217;s meter registry to your service for use in creating and updating meters. ",
            "title": "Register an Instance of MicrometerSupport with the Web Server"
        },
        {
            "location": "se/metrics/micrometer",
            "text": " Unless you specify otherwise, Helidon uses defaults for any built-in Micrometer meter registry. For example, Helidon configures the built-in Prometheus registry using PrometheusConfig.DEFAULT . You can override these defaults in either of two ways: Using the MicrometerSupport.Builder class Using configuration ",
            "title": "Overriding Defaults for Built-in Meter Registry Types"
        },
        {
            "location": "se/metrics/micrometer",
            "text": " Use the MicrometerSupport.Builder class to set up Micrometer support however your application needs. The builder lets you: Provide your own Micrometer meter registry configuration that MicrometerSupport uses to create a built-in meter registry, or Instantiate a Micrometer meter registry yourself, configured however you want, and add it to the MicrometerSupport object&#8217;s collection of meter registries <markup lang=\"java\" title=\"Overriding defaults for built-in meter registries using MicrometerSupport.Builder \" >PrometheusConfig myPrometheusConfig = ...; MicrometerSupport support = MicrometerSupport.builder() .enrollBuiltInRegistry( MicrometerSupport.BuiltInRegistryType.PROMETHEUS, myPrometheusConfig) .build(); Create the meter registry configuration however you need. Enroll the PROMETHEUS built-in registry type with your custom configuration. ",
            "title": "Using MicrometerSupport.Builder "
        },
        {
            "location": "se/metrics/micrometer",
            "text": " To use configuration to control the selection and behavior of Helidon&#8217;s built-in Micrometer meter registries, include in your configuration (such as application.yaml ) a micrometer.builtin-registries section. <markup lang=\"yaml\" title=\"Enroll Prometheus built-in meter registry using default configuration\" >micrometer: builtin-registries: - type: prometheus <markup lang=\"yaml\" title=\"Enroll Prometheus built-in meter registry with non-default configuration\" >micrometer: builtin-registries: - type: prometheus prefix: myPrefix Note that the first config example is equivalent to the default Helidon Micrometer behavior; Helidon by default supports the Prometheus meter registry. The configuration keys that are valid for the builtin-registries child entries depend on the type of Micrometer meter registry. For example, support in Helidon for the Prometheus meter registry respects the prefix configuration setting but other meter registries might not and might support other settings. Refer to the documentation for the meter registry you want to configure to find out what items apply to that registry type. Helidon does not validate the configuration keys you specify for meter registries. ",
            "title": "Using Configuration"
        },
        {
            "location": "se/metrics/micrometer",
            "text": "<markup lang=\"java\" title=\"Define and use a Counter \" >import io.micrometer.core.instrument.Counter; public class MyService implements Service { private final Counter requestCounter; public MyService(MicrometerMeterRegistry registry) { requestCounter = registry.counter(\"allRequests\"); } @Override public void update(Routing.Rules rules) { rules .any(this::countRequests) .get(\"/\", this::myGet); } private void countRequests(ServerRequest request, ServerResponse response) { requestCounter.increment(); request.next(); } } Use the Micrometer meter registry to create the request counter. Add routing for any request to invoke the method which counts requests by updating the counter. Update the counter and then delegate the rest of the request processing to the next handler in the chain. The example above enrolls the built-in Prometheus meter registry with the default Prometheus registry configuration. You can change the default setup for built-in registries, and you can enroll other meter registries your application creates itself. Overriding Defaults for Built-in Meter Registry Types Unless you specify otherwise, Helidon uses defaults for any built-in Micrometer meter registry. For example, Helidon configures the built-in Prometheus registry using PrometheusConfig.DEFAULT . You can override these defaults in either of two ways: Using the MicrometerSupport.Builder class Using configuration Using MicrometerSupport.Builder Use the MicrometerSupport.Builder class to set up Micrometer support however your application needs. The builder lets you: Provide your own Micrometer meter registry configuration that MicrometerSupport uses to create a built-in meter registry, or Instantiate a Micrometer meter registry yourself, configured however you want, and add it to the MicrometerSupport object&#8217;s collection of meter registries <markup lang=\"java\" title=\"Overriding defaults for built-in meter registries using MicrometerSupport.Builder \" >PrometheusConfig myPrometheusConfig = ...; MicrometerSupport support = MicrometerSupport.builder() .enrollBuiltInRegistry( MicrometerSupport.BuiltInRegistryType.PROMETHEUS, myPrometheusConfig) .build(); Create the meter registry configuration however you need. Enroll the PROMETHEUS built-in registry type with your custom configuration. Using Configuration To use configuration to control the selection and behavior of Helidon&#8217;s built-in Micrometer meter registries, include in your configuration (such as application.yaml ) a micrometer.builtin-registries section. <markup lang=\"yaml\" title=\"Enroll Prometheus built-in meter registry using default configuration\" >micrometer: builtin-registries: - type: prometheus <markup lang=\"yaml\" title=\"Enroll Prometheus built-in meter registry with non-default configuration\" >micrometer: builtin-registries: - type: prometheus prefix: myPrefix Note that the first config example is equivalent to the default Helidon Micrometer behavior; Helidon by default supports the Prometheus meter registry. The configuration keys that are valid for the builtin-registries child entries depend on the type of Micrometer meter registry. For example, support in Helidon for the Prometheus meter registry respects the prefix configuration setting but other meter registries might not and might support other settings. Refer to the documentation for the meter registry you want to configure to find out what items apply to that registry type. Helidon does not validate the configuration keys you specify for meter registries. ",
            "title": "Create and Update Meters in your Application Service"
        },
        {
            "location": "se/metrics/micrometer",
            "text": " To create additional types of registries and enroll them with MicrometerSupport , you need to: Write a Handler Each meter registry has its own way of producing output. Write your handler so that it has a reference to the meter registry it should use and so that its accept method sets the payload in the HTTP response using the registry&#8217;s mechanism for creating output. Write a Function which accepts a ServerRequest and returns an Optional&lt;Handler&gt; Typically, the function examines the request&#8212;&#8203;the Content-Type , query parameters, etc.--to decide whether the corresponding handler should respond to the request. If so, your function should instantiate your Handler and return an Optional.of(theHandlerInstance) ; otherwise, your function should return Optional.empty() . When MicrometerSupport receives a request, it invokes the functions of all the enrolled registries, stopping as soon as one function provides a handler. MicrometerSupport then delegates to that handler to create and send the response. Pass the Handler and Function to the MicrometerSupport.enrollRegistry method to enroll them <markup lang=\"java\" title=\"Creating and enrolling your own Micrometer meter registry\" >MeterRegistry myRegistry = new PrometheusMeterRegistry(myPrometheusConfig); MicrometerSupport support = MicrometerSupport.builder() .enrollRegistry(myRegistry, request -&gt; request .headers() .bestAccepted(MediaType.TEXT_PLAIN).isPresent() ? Optional.of((req, resp) -&gt; resp.send(myRegistry.scrape())) : Optional.empty()) .build(); Create the meter registry. This example uses a Prometheus registry but it can be any extension of MeterRegistry . Provide the function that checks if the ServerRequest accepts content that your meter registry can produce (e.g., either text/plain or unspecified is normally an indication for Prometheus-style output) and returns the appropriate Optional&lt; Handler &gt; . A very simple in-line Handler that sets the response entity from the Prometheus registry&#8217;s scrape() method. ",
            "title": "Enrolling other Micrometer meter registries"
        },
        {
            "location": "se/metrics/micrometer",
            "text": " Your application can easily have Helidon create a REST endpoint which clients can access to retrieve Micrometer metrics, by default at the /micrometer endpoint. Within Helidon, each type of meter registry is paired with some code that examines the incoming HTTP request to /micrometer and decides whether the request matches up with the associated meter registry. The first pairing that accepts the request returns the response. You will need to take advantage of this if your application uses additional meter registries beyond what Helidon automatically provides and you want those meter registries reflected in the output from the /micrometer REST endpoint. When MicrometerSupport receives a request at the endpoint, it looks for the first enrolled meter registry for which the corresponding Function&lt;ServerRequest, Optional&lt;Handler&gt;&gt; returns a non-empty Handler . Helidon invokes that Handler which must retrieve the metrics output from its meter registry and set and send the response. Note that the Handler which your function returns typically has a reference to the meter registry it will use in preparing the response. ",
            "title": "Accessing the Helidon Micrometer Endpoint"
        },
        {
            "location": "se/metrics/micrometer",
            "text": " Helidon SE includes an example application which uses Micrometer support. The rest of this section takes you through the process of changing your application to use Helidon SE integration with Micrometer: Register an instance of MicrometerSupport with the web server. Create meters using the meter registry managed by Helidon&#8217;s MicrometerSupport and then update and query those meters. Register an Instance of MicrometerSupport with the Web Server <markup lang=\"java\" title=\"Initialize Micrometer support\" >import io.helidon.integrations.micrometer.MicrometerSupport; MicrometerSupport micrometerSupport = MicrometerSupport.create(); Routing.builder() .register(micrometerSupport) .register(\"/myapp\", new MyService(micrometerSupport.registry())) .build(); Create the MicrometerSupport instance, using the default built-in Prometheus meter registry. Register the MicrometerSupport instance as a service; by default, MicrometerSupport exposes the endpoint as /micrometer . Pass the MicrometerSupport object&#8217;s meter registry to your service for use in creating and updating meters. Create and Update Meters in your Application Service <markup lang=\"java\" title=\"Define and use a Counter \" >import io.micrometer.core.instrument.Counter; public class MyService implements Service { private final Counter requestCounter; public MyService(MicrometerMeterRegistry registry) { requestCounter = registry.counter(\"allRequests\"); } @Override public void update(Routing.Rules rules) { rules .any(this::countRequests) .get(\"/\", this::myGet); } private void countRequests(ServerRequest request, ServerResponse response) { requestCounter.increment(); request.next(); } } Use the Micrometer meter registry to create the request counter. Add routing for any request to invoke the method which counts requests by updating the counter. Update the counter and then delegate the rest of the request processing to the next handler in the chain. The example above enrolls the built-in Prometheus meter registry with the default Prometheus registry configuration. You can change the default setup for built-in registries, and you can enroll other meter registries your application creates itself. Overriding Defaults for Built-in Meter Registry Types Unless you specify otherwise, Helidon uses defaults for any built-in Micrometer meter registry. For example, Helidon configures the built-in Prometheus registry using PrometheusConfig.DEFAULT . You can override these defaults in either of two ways: Using the MicrometerSupport.Builder class Using configuration Using MicrometerSupport.Builder Use the MicrometerSupport.Builder class to set up Micrometer support however your application needs. The builder lets you: Provide your own Micrometer meter registry configuration that MicrometerSupport uses to create a built-in meter registry, or Instantiate a Micrometer meter registry yourself, configured however you want, and add it to the MicrometerSupport object&#8217;s collection of meter registries <markup lang=\"java\" title=\"Overriding defaults for built-in meter registries using MicrometerSupport.Builder \" >PrometheusConfig myPrometheusConfig = ...; MicrometerSupport support = MicrometerSupport.builder() .enrollBuiltInRegistry( MicrometerSupport.BuiltInRegistryType.PROMETHEUS, myPrometheusConfig) .build(); Create the meter registry configuration however you need. Enroll the PROMETHEUS built-in registry type with your custom configuration. Using Configuration To use configuration to control the selection and behavior of Helidon&#8217;s built-in Micrometer meter registries, include in your configuration (such as application.yaml ) a micrometer.builtin-registries section. <markup lang=\"yaml\" title=\"Enroll Prometheus built-in meter registry using default configuration\" >micrometer: builtin-registries: - type: prometheus <markup lang=\"yaml\" title=\"Enroll Prometheus built-in meter registry with non-default configuration\" >micrometer: builtin-registries: - type: prometheus prefix: myPrefix Note that the first config example is equivalent to the default Helidon Micrometer behavior; Helidon by default supports the Prometheus meter registry. The configuration keys that are valid for the builtin-registries child entries depend on the type of Micrometer meter registry. For example, support in Helidon for the Prometheus meter registry respects the prefix configuration setting but other meter registries might not and might support other settings. Refer to the documentation for the meter registry you want to configure to find out what items apply to that registry type. Helidon does not validate the configuration keys you specify for meter registries. Enrolling other Micrometer meter registries To create additional types of registries and enroll them with MicrometerSupport , you need to: Write a Handler Each meter registry has its own way of producing output. Write your handler so that it has a reference to the meter registry it should use and so that its accept method sets the payload in the HTTP response using the registry&#8217;s mechanism for creating output. Write a Function which accepts a ServerRequest and returns an Optional&lt;Handler&gt; Typically, the function examines the request&#8212;&#8203;the Content-Type , query parameters, etc.--to decide whether the corresponding handler should respond to the request. If so, your function should instantiate your Handler and return an Optional.of(theHandlerInstance) ; otherwise, your function should return Optional.empty() . When MicrometerSupport receives a request, it invokes the functions of all the enrolled registries, stopping as soon as one function provides a handler. MicrometerSupport then delegates to that handler to create and send the response. Pass the Handler and Function to the MicrometerSupport.enrollRegistry method to enroll them <markup lang=\"java\" title=\"Creating and enrolling your own Micrometer meter registry\" >MeterRegistry myRegistry = new PrometheusMeterRegistry(myPrometheusConfig); MicrometerSupport support = MicrometerSupport.builder() .enrollRegistry(myRegistry, request -&gt; request .headers() .bestAccepted(MediaType.TEXT_PLAIN).isPresent() ? Optional.of((req, resp) -&gt; resp.send(myRegistry.scrape())) : Optional.empty()) .build(); Create the meter registry. This example uses a Prometheus registry but it can be any extension of MeterRegistry . Provide the function that checks if the ServerRequest accepts content that your meter registry can produce (e.g., either text/plain or unspecified is normally an indication for Prometheus-style output) and returns the appropriate Optional&lt; Handler &gt; . A very simple in-line Handler that sets the response entity from the Prometheus registry&#8217;s scrape() method. Accessing the Helidon Micrometer Endpoint Your application can easily have Helidon create a REST endpoint which clients can access to retrieve Micrometer metrics, by default at the /micrometer endpoint. Within Helidon, each type of meter registry is paired with some code that examines the incoming HTTP request to /micrometer and decides whether the request matches up with the associated meter registry. The first pairing that accepts the request returns the response. You will need to take advantage of this if your application uses additional meter registries beyond what Helidon automatically provides and you want those meter registries reflected in the output from the /micrometer REST endpoint. When MicrometerSupport receives a request at the endpoint, it looks for the first enrolled meter registry for which the corresponding Function&lt;ServerRequest, Optional&lt;Handler&gt;&gt; returns a non-empty Handler . Helidon invokes that Handler which must retrieve the metrics output from its meter registry and set and send the response. Note that the Handler which your function returns typically has a reference to the meter registry it will use in preparing the response. ",
            "title": "Examples"
        },
        {
            "location": "se/metrics/micrometer",
            "text": " The Micrometer website describes the project as a whole and has links to more information. ",
            "title": "Additional Information"
        },
        {
            "location": "se/metrics/prometheus-exemplar-support",
            "text": " Overview Maven Coordinates Usage Examples Additional Information ",
            "title": "Contents"
        },
        {
            "location": "se/metrics/prometheus-exemplar-support",
            "text": " A metric typically reflects the usage of a single point in your service processing multiple requests over time. A value such as the total time consumed by a given REST endpoint underscores the aggregate nature of metric values; Helidon accumulates the time from all requests in the total duration. Tracing, on the other hand, captures the usage of multiple parts of your code as your service responds to a single request. Metrics and tracing come together in Helidon&#8217;s support for examplars. Note exemplar - one that serves as a model or example &#8201;&#8212;&#8201;Merriam-Webster Dictionary In the context of metrics, an exemplar for a given metric is a specific sample which, in some sense, made a typical contribution to the metric&#8217;s value. For example, an exemplar for a SimpleTimer might be a sample in which the duration it contributed to the value of a SimpleTimer is near the mean of the durations over all samples. The metrics output identifies the exemplar sample using the trace ID of the trace which triggered that sample. ",
            "title": "Overview"
        },
        {
            "location": "se/metrics/prometheus-exemplar-support",
            "text": " To enable OpenMetrics exemplar support add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.metrics&lt;/groupId&gt; &lt;artifactId&gt;helidon-metrics-trace-exemplar&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; Also, include the Helidon integration module for a tracing implementation (such as Helidon Zipkin ) <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-zipkin&lt;/artifactId&gt; &lt;/dependency&gt; Add the Helidon tracing component itself: <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "se/metrics/prometheus-exemplar-support",
            "text": " Helidon automatically records a sample (label, value, and timestamp) with each update to a histogram, simple timer, or counter. When a client accesses the /metrics endpoint, Helidon adds the label, value, and timestamp to the OpenMetrics response. Helidon adds an exemplar to the output for each statistical value&#8212;&#8203;such as minimum, maximum, mean, and quantiles&#8212;&#8203;for histograms, timers, simple times, and for counters. The exemplar information in the output describes a single, actual sample that is representative of the statistical value. Helidon chooses the representative examplar for each value using information that is already recorded for each type of metric: Selection of exemplars for types of metrics Metric Value Type Example Sample Selected as Exemplar corresponds directly to a specific sample minimum or maximum of a value any sample with that exact value collects samples into bins (quantiles) histogram (as with timers) any sample from the bin maintains running statistics counts, totals most recent sample computes its value from multiple samples mean sample for which its value is at least as close as other samples to the statistical calculation In cases with multiple representative samples (for example, two samples' values are equally close to the mean), Helidon chooses one of them arbitrarily. ",
            "title": "Interpreting Exemplars"
        },
        {
            "location": "se/metrics/prometheus-exemplar-support",
            "text": " In the OpenMetrics output, an exemplar actually appears as a comment appended to the normal OpenMetrics output. <markup title=\"OpenMetrics format with exemplars\" > metric-identifier metric-value # exemplar-label sample-timestamp Even downstream consumers of OpenMetrics output that do not recognize the exemplar format should continue to work correctly (as long as they do recognize comments). But some consumers, such as trace collectors and their U/Is, understand the exemplar format, and they allow you to browse metrics and then navigate directly to the trace for the metric&#8217;s exemplar. ",
            "title": "Output Format"
        },
        {
            "location": "se/metrics/prometheus-exemplar-support",
            "text": " Once you add the appropriate dependencies to your project, exemplar support runs automatically as part of Helidon metrics. You do not need to change your application or configuration. Interpreting Exemplars Helidon automatically records a sample (label, value, and timestamp) with each update to a histogram, simple timer, or counter. When a client accesses the /metrics endpoint, Helidon adds the label, value, and timestamp to the OpenMetrics response. Helidon adds an exemplar to the output for each statistical value&#8212;&#8203;such as minimum, maximum, mean, and quantiles&#8212;&#8203;for histograms, timers, simple times, and for counters. The exemplar information in the output describes a single, actual sample that is representative of the statistical value. Helidon chooses the representative examplar for each value using information that is already recorded for each type of metric: Selection of exemplars for types of metrics Metric Value Type Example Sample Selected as Exemplar corresponds directly to a specific sample minimum or maximum of a value any sample with that exact value collects samples into bins (quantiles) histogram (as with timers) any sample from the bin maintains running statistics counts, totals most recent sample computes its value from multiple samples mean sample for which its value is at least as close as other samples to the statistical calculation In cases with multiple representative samples (for example, two samples' values are equally close to the mean), Helidon chooses one of them arbitrarily. Output Format In the OpenMetrics output, an exemplar actually appears as a comment appended to the normal OpenMetrics output. <markup title=\"OpenMetrics format with exemplars\" > metric-identifier metric-value # exemplar-label sample-timestamp Even downstream consumers of OpenMetrics output that do not recognize the exemplar format should continue to work correctly (as long as they do recognize comments). But some consumers, such as trace collectors and their U/Is, understand the exemplar format, and they allow you to browse metrics and then navigate directly to the trace for the metric&#8217;s exemplar. ",
            "title": "Usage"
        },
        {
            "location": "se/metrics/prometheus-exemplar-support",
            "text": " Helidon includes an example application , based on the QuickStart application, which illustrates exemplar support. Once you enable exemplar support you can see the exemplars in the metrics output. # TYPE application_getTimer_mean_seconds gauge application_getTimer_mean_seconds 8.303030623354298E-4 # {trace_id=\"067632454fe4e8d1\"} 1.14701E-4 1617723032.570000 # TYPE application_getTimer_max_seconds gauge application_getTimer_max_seconds 0.003952636 # {trace_id=\"fce183094e471633\"} 0.003952636 1617723030.108000 # TYPE application_getTimer_min_seconds gauge application_getTimer_min_seconds 5.5254E-5 # {trace_id=\"0b1a4bf22b4e47fd\"} 5.5254E-5 1617723033.311000 The first exemplar is a sample with value at least as close to the mean for that timer as any other sample. This second exemplar is for an exact sample with value the same as the maximum value the timer has observed. # TYPE application_globalRequestTracker_total counter # HELP application_globalRequestTracker_total application_globalRequestTracker_total 4 # {trace_id=\"daf26fe35fee9917\"} 0.001183992 1617725180.234000 # TYPE application_globalRequestTracker_elapsedTime_seconds gauge application_globalRequestTracker_elapsedTime_seconds 0.030309068 # {trace_id=\"daf26fe35fee9917\"} 0.001183992 1617725180.234000 The exemplar for a SimpleTimer is the same for the total and the elapsedTime sub metrics: always the most recent sample which updated the SimpleTimer . ",
            "title": "Examples"
        },
        {
            "location": "se/metrics/prometheus-exemplar-support",
            "text": " Brief discussion of exemplars in the OpenMetrics spec ",
            "title": "Additional Information"
        },
        {
            "location": "se/openapi",
            "text": " Overview Maven Coordinates Usage API Configuration Examples Additional Information ",
            "title": "Contents"
        },
        {
            "location": "se/openapi",
            "text": " The OpenAPI specification defines a standard way to express the interface exposed by a REST service. The MicroProfile OpenAPI spec explains how MicroProfile embraces OpenAPI, adding annotations, configuration, and a service provider interface (SPI). OpenAPI support in Helidon SE draws its inspiration from MicroProfile OpenAPI but does not implement the spec because Helidon SE does not support annotations. The OpenAPI support in Helidon SE performs two main tasks: Build an in-memory model of the REST API your service implements. Expose the model in text format (typically YAML) via the /openapi endpoint. To construct the model, Helidon gathers information about the service API from whichever of these sources are present in the application: a model reader The SPI defines an interface you can implement in your application for programmatically providing part or all of the model; a static OpenAPI document file packaged as part of your service; a filter class The SPI defines an interface you can implement in your application which can mask parts of the model. ",
            "title": "Overview"
        },
        {
            "location": "se/openapi",
            "text": " To enable OpenAPI add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.openapi&lt;/groupId&gt; &lt;artifactId&gt;helidon-openapi&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "se/openapi",
            "text": " Helidon SE provides the OpenAPISupport class which your application uses to assemble the in-memory model and expose the /openapi endpoint to clients. You can create an instance either using a static create method or by instantiating its Builder . The example below illustrates one way to do this. ",
            "title": "Register OpenAPISupport in your application routing"
        },
        {
            "location": "se/openapi",
            "text": " Add a static file at META-INF/openapi.yml , META-INF/openapi.yaml , or META-INF/openapi.json . Tools such as Swagger let you describe your app&#8217;s API and they then generate an OpenAPI document file which you can include in your application so OpenAPI can use it. ",
            "title": "Provide a static OpenAPI file"
        },
        {
            "location": "se/openapi",
            "text": " Write a Java class that implements the OpenAPI org.eclipse.microprofile.openapi.OASModelReader interface. Your model reader code programmatically adds elements to the internal model that OpenAPI builds. Change your application&#8217;s MP configuration to set mp.openapi.model.reader as the fully-qualified class name of your class. ",
            "title": "Write and configure a model reader class"
        },
        {
            "location": "se/openapi",
            "text": " Write a Java class that implements the OpenAPI org.eclipse.microprofile.openapi.OASFilter interface. As OpenAPI composes its internal model, it invokes your filter with each model element before adding the element to the model. Your filter can accept the element as-is, modify it, or suppress it. Change your application&#8217;s configuration to set mp.openapi.filter as the full-qualified class name of your class. ",
            "title": "Write and configure a filter class"
        },
        {
            "location": "se/openapi",
            "text": " OpenAPI support in Helidon SE largely follows the MicroProfile OpenAPI spec . But because Helidon SE does not process annotations, your application supplies data for the OpenAPI model in the other ways listed earlier. Provide a static OpenAPI file Add a static file at META-INF/openapi.yml , META-INF/openapi.yaml , or META-INF/openapi.json . Tools such as Swagger let you describe your app&#8217;s API and they then generate an OpenAPI document file which you can include in your application so OpenAPI can use it. Write and configure a model reader class Write a Java class that implements the OpenAPI org.eclipse.microprofile.openapi.OASModelReader interface. Your model reader code programmatically adds elements to the internal model that OpenAPI builds. Change your application&#8217;s MP configuration to set mp.openapi.model.reader as the fully-qualified class name of your class. Write and configure a filter class Write a Java class that implements the OpenAPI org.eclipse.microprofile.openapi.OASFilter interface. As OpenAPI composes its internal model, it invokes your filter with each model element before adding the element to the model. Your filter can accept the element as-is, modify it, or suppress it. Change your application&#8217;s configuration to set mp.openapi.filter as the full-qualified class name of your class. ",
            "title": "Furnish OpenAPI information about your endpoints"
        },
        {
            "location": "se/openapi",
            "text": " If you implement either a model reader or a filter, add this dependency to your pom.xml : <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;org.eclipse.microprofile.openapi&lt;/groupId&gt; &lt;artifactId&gt;microprofile-openapi-api&lt;/artifactId&gt; &lt;version&gt;{microprofile-openapi-version}&lt;/version&gt; &lt;/dependency&gt; ",
            "title": "Add OpenAPI dependency"
        },
        {
            "location": "se/openapi",
            "text": " Register OpenAPISupport in your application routing Helidon SE provides the OpenAPISupport class which your application uses to assemble the in-memory model and expose the /openapi endpoint to clients. You can create an instance either using a static create method or by instantiating its Builder . The example below illustrates one way to do this. Furnish OpenAPI information about your endpoints OpenAPI support in Helidon SE largely follows the MicroProfile OpenAPI spec . But because Helidon SE does not process annotations, your application supplies data for the OpenAPI model in the other ways listed earlier. Provide a static OpenAPI file Add a static file at META-INF/openapi.yml , META-INF/openapi.yaml , or META-INF/openapi.json . Tools such as Swagger let you describe your app&#8217;s API and they then generate an OpenAPI document file which you can include in your application so OpenAPI can use it. Write and configure a model reader class Write a Java class that implements the OpenAPI org.eclipse.microprofile.openapi.OASModelReader interface. Your model reader code programmatically adds elements to the internal model that OpenAPI builds. Change your application&#8217;s MP configuration to set mp.openapi.model.reader as the fully-qualified class name of your class. Write and configure a filter class Write a Java class that implements the OpenAPI org.eclipse.microprofile.openapi.OASFilter interface. As OpenAPI composes its internal model, it invokes your filter with each model element before adding the element to the model. Your filter can accept the element as-is, modify it, or suppress it. Change your application&#8217;s configuration to set mp.openapi.filter as the full-qualified class name of your class. Add OpenAPI dependency If you implement either a model reader or a filter, add this dependency to your pom.xml : <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;org.eclipse.microprofile.openapi&lt;/groupId&gt; &lt;artifactId&gt;microprofile-openapi-api&lt;/artifactId&gt; &lt;version&gt;{microprofile-openapi-version}&lt;/version&gt; &lt;/dependency&gt; ",
            "title": "Changing your application"
        },
        {
            "location": "se/openapi",
            "text": " Once you add the SE OpenAPI dependency to your project and add code to create the OpenAPISupport object to your routing, your application will automatically respond to the built-in endpoint&#8201;&#8212;&#8201; /openapi &#8201;&#8212;&#8201;and it will return the OpenAPI document describing the endpoints in your application. By default, per the MicroProfile OpenAPI spec, the default format of the OpenAPI document is YAML. There is not yet an adopted IANA YAML media type, but a proposed one specifically for OpenAPI documents that has some support is application/vnd.oai.openapi . That is what Helidon returns, by default. In addition, a client can specify the HTTP header Accept as either application/vnd.oai.openapi+json or application/json to request JSON. Alternatively, the client can pass the query parameter format as either JSON or YAML to receive application/json or application/vnd.oai.openapi (YAML) output, respectively. ",
            "title": "Accessing the REST Endpoint"
        },
        {
            "location": "se/openapi",
            "text": " You can very simply add support for OpenAPI to your Helidon SE application. This document shows what changes you need to make to your application and how to access the OpenAPI document for your application at runtime. Changing your application Register OpenAPISupport in your application routing Helidon SE provides the OpenAPISupport class which your application uses to assemble the in-memory model and expose the /openapi endpoint to clients. You can create an instance either using a static create method or by instantiating its Builder . The example below illustrates one way to do this. Furnish OpenAPI information about your endpoints OpenAPI support in Helidon SE largely follows the MicroProfile OpenAPI spec . But because Helidon SE does not process annotations, your application supplies data for the OpenAPI model in the other ways listed earlier. Provide a static OpenAPI file Add a static file at META-INF/openapi.yml , META-INF/openapi.yaml , or META-INF/openapi.json . Tools such as Swagger let you describe your app&#8217;s API and they then generate an OpenAPI document file which you can include in your application so OpenAPI can use it. Write and configure a model reader class Write a Java class that implements the OpenAPI org.eclipse.microprofile.openapi.OASModelReader interface. Your model reader code programmatically adds elements to the internal model that OpenAPI builds. Change your application&#8217;s MP configuration to set mp.openapi.model.reader as the fully-qualified class name of your class. Write and configure a filter class Write a Java class that implements the OpenAPI org.eclipse.microprofile.openapi.OASFilter interface. As OpenAPI composes its internal model, it invokes your filter with each model element before adding the element to the model. Your filter can accept the element as-is, modify it, or suppress it. Change your application&#8217;s configuration to set mp.openapi.filter as the full-qualified class name of your class. Add OpenAPI dependency If you implement either a model reader or a filter, add this dependency to your pom.xml : <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;org.eclipse.microprofile.openapi&lt;/groupId&gt; &lt;artifactId&gt;microprofile-openapi-api&lt;/artifactId&gt; &lt;version&gt;{microprofile-openapi-version}&lt;/version&gt; &lt;/dependency&gt; Accessing the REST Endpoint Once you add the SE OpenAPI dependency to your project and add code to create the OpenAPISupport object to your routing, your application will automatically respond to the built-in endpoint&#8201;&#8212;&#8201; /openapi &#8201;&#8212;&#8201;and it will return the OpenAPI document describing the endpoints in your application. By default, per the MicroProfile OpenAPI spec, the default format of the OpenAPI document is YAML. There is not yet an adopted IANA YAML media type, but a proposed one specifically for OpenAPI documents that has some support is application/vnd.oai.openapi . That is what Helidon returns, by default. In addition, a client can specify the HTTP header Accept as either application/vnd.oai.openapi+json or application/json to request JSON. Alternatively, the client can pass the query parameter format as either JSON or YAML to receive application/json or application/vnd.oai.openapi (YAML) output, respectively. ",
            "title": "Usage"
        },
        {
            "location": "se/openapi",
            "text": " The MicroProfile OpenAPI JavaDocs give full details of the classes and interfaces you can use in your code. Remember that, although the JavaDocs describe annotations, Helidon SE does not support them. Helidon SE provides an API for creating and setting up the REST endpoint which serves OpenAPI documents to clients at the /openapi path. Use either static methods on OpenAPISupport or use its Builder to create an instance of OpenAPISupport . Then add that instance to your application&#8217;s routing. The example below shows how to do this. ",
            "title": "API"
        },
        {
            "location": "se/openapi",
            "text": " Optional configuration options key type default value description application-path-disable boolean false Sets whether the app path search should be disabled. cors CrossOriginConfig &#160; Assigns the CORS settings for the OpenAPI endpoint. custom-schema-registry-class string &#160; Sets the custom schema registry class. filter string &#160; Sets the developer-provided OpenAPI filter class name. model.reader string &#160; Sets the developer-provided OpenAPI model reader class name. schema.* string &#160; Sets the schema for the indicated fully-qualified class name (represented here by '*'); value is the schema in JSON format. Repeat for multiple classes. servers string[&#93; &#160; Sets servers. servers.operation.* string[&#93; &#160; Sets alternative servers to service the indicated operation (represented here by '*'). Repeat for multiple operations. servers.path.* string[&#93; &#160; Sets alternative servers to service all operations at the indicated path (represented here by '*'). Repeat for multiple paths. static-file string META-INF/openapi.* Sets the file system path of the static OpenAPI document file. Default types are json , yaml , and yml . web-context string /openapi Sets the web context path for the OpenAPI endpoint. ",
            "title": "Configuration options"
        },
        {
            "location": "se/openapi",
            "text": " Helidon SE OpenAPI configuration supports the following settings: Type: io.helidon.openapi.SEOpenAPISupport <markup lang=\"text\" title=\"Config key\" >openapi Configuration options Optional configuration options key type default value description application-path-disable boolean false Sets whether the app path search should be disabled. cors CrossOriginConfig &#160; Assigns the CORS settings for the OpenAPI endpoint. custom-schema-registry-class string &#160; Sets the custom schema registry class. filter string &#160; Sets the developer-provided OpenAPI filter class name. model.reader string &#160; Sets the developer-provided OpenAPI model reader class name. schema.* string &#160; Sets the schema for the indicated fully-qualified class name (represented here by '*'); value is the schema in JSON format. Repeat for multiple classes. servers string[&#93; &#160; Sets servers. servers.operation.* string[&#93; &#160; Sets alternative servers to service the indicated operation (represented here by '*'). Repeat for multiple operations. servers.path.* string[&#93; &#160; Sets alternative servers to service all operations at the indicated path (represented here by '*'). Repeat for multiple paths. static-file string META-INF/openapi.* Sets the file system path of the static OpenAPI document file. Default types are json , yaml , and yml . web-context string /openapi Sets the web context path for the OpenAPI endpoint. ",
            "title": "Configuration"
        },
        {
            "location": "se/openapi",
            "text": "<markup lang=\"java\" title=\"Java Code to Register OpenAPISupport for Routing\" >Config config = Config.create(); return Routing.builder() .register(JsonSupport.create()) .register(OpenAPISupport.create(config)) .register(health) // Health at \"/health\" .register(metrics) // Metrics at \"/metrics\" .register(\"/greet\", greetService) .build(); Adds the OpenAPISupport service to your server. If you need more control over the OpenAPISupport instance, invoke OpenAPISupport.builder() to get an OpenAPISupport.Builder object and work with it. ",
            "title": "Register OpenAPISupport "
        },
        {
            "location": "se/openapi",
            "text": " Helidon SE provides a complete OpenAPI example based on the SE QuickStart sample app which includes a model reader and a filter. Most Helidon SE applications need only to create and register OpenAPISupport . Register OpenAPISupport <markup lang=\"java\" title=\"Java Code to Register OpenAPISupport for Routing\" >Config config = Config.create(); return Routing.builder() .register(JsonSupport.create()) .register(OpenAPISupport.create(config)) .register(health) // Health at \"/health\" .register(metrics) // Metrics at \"/metrics\" .register(\"/greet\", greetService) .build(); Adds the OpenAPISupport service to your server. If you need more control over the OpenAPISupport instance, invoke OpenAPISupport.builder() to get an OpenAPISupport.Builder object and work with it. ",
            "title": "Examples"
        },
        {
            "location": "se/openapi",
            "text": " A Jandex index stores information about the classes and methods in your app and what annotations they have. It allows CDI to process annotations faster during your application&#8217;s start-up. Add the Jandex maven plug-in to the &lt;build&gt;&lt;plugins&gt; section of your pom.xml : <markup lang=\"xml\" >&lt;plugin&gt; &lt;groupId&gt;org.jboss.jandex&lt;/groupId&gt; &lt;artifactId&gt;jandex-maven-plugin&lt;/artifactId&gt; &lt;version&gt;{jandex-plugin-version}&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;make-index&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;jandex&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; When you build your app maven should include the index META-INF/jandex.idx in the JAR. Note If you do not modify your build to create the index then the Helidon MP OpenAPI runtime automatically creates one in memory during app start-up. This slows down your app start-up and, depending on how CDI is configured, might inadvertently miss information. We strongly recommend using the Jandex plug-in to build the index into your app. ",
            "title": "Building the Jandex index"
        },
        {
            "location": "se/openapi",
            "text": " Building the Jandex index A Jandex index stores information about the classes and methods in your app and what annotations they have. It allows CDI to process annotations faster during your application&#8217;s start-up. Add the Jandex maven plug-in to the &lt;build&gt;&lt;plugins&gt; section of your pom.xml : <markup lang=\"xml\" >&lt;plugin&gt; &lt;groupId&gt;org.jboss.jandex&lt;/groupId&gt; &lt;artifactId&gt;jandex-maven-plugin&lt;/artifactId&gt; &lt;version&gt;{jandex-plugin-version}&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;make-index&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;jandex&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; When you build your app maven should include the index META-INF/jandex.idx in the JAR. Note If you do not modify your build to create the index then the Helidon MP OpenAPI runtime automatically creates one in memory during app start-up. This slows down your app start-up and, depending on how CDI is configured, might inadvertently miss information. We strongly recommend using the Jandex plug-in to build the index into your app. ",
            "title": "Additional Information"
        },
        {
            "location": "se/reactive-messaging",
            "text": " Overview Maven Coordinates Usage Channel Processor Message Connectors Kafka Connector JMS Connector AQ Connector Configuration Reference ",
            "title": "Contents"
        },
        {
            "location": "se/reactive-messaging",
            "text": " Asynchronous messaging is a commonly used form of communication in the world of microservices. While it is possible to start building your reactive streams directly by combining operators and connecting them to reactive APIs, with Helidon SE Reactive Messaging, you can now use prepared tools for repetitive use case scenarios . ",
            "title": "Overview"
        },
        {
            "location": "se/reactive-messaging",
            "text": " To enable Reactive Messaging add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.messaging&lt;/groupId&gt; &lt;artifactId&gt;helidon-messaging&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "se/reactive-messaging",
            "text": " A channel is a named pair of Publisher and Subscriber . Channels can be connected together by processors . Registering a Publisher or Subscriber for a channel can be done by Messaging API, or configured implicitly using registered connectors to generate the Publisher or Subscriber . <markup lang=\"java\" title=\"Example of simple channel:\" >Channel&lt;String&gt; channel1 = Channel.create(\"channel1\"); Messaging.builder() .publisher(channel1, Multi.just(\"message 1\", \"message 2\") .map(Message::of)) .listener(channel1, s -&gt; System.out.println(\"Intecepted message \" + s)) .build() .start(); ",
            "title": "Channel"
        },
        {
            "location": "se/reactive-messaging",
            "text": " Processor is a typical reactive processor acting as a Subscriber to upstream and as a Publisher to downstream. In terms of reactive messaging, it is able to connect two channels to one reactive stream. <markup lang=\"java\" title=\"Example of processor usage:\" >Channel&lt;String&gt; firstChannel = Channel.create(\"first-channel\"); Channel&lt;String&gt; secondChannel = Channel.create(\"second-channel\"); Messaging.builder() .publisher(secondChannel, ReactiveStreams.of(\"test1\", \"test2\", \"test3\") .map(Message::of)) .processor(secondChannel, firstChannel, ReactiveStreams.&lt;Message&lt;String&gt;&gt;builder() .map(Message::getPayload) .map(String::toUpperCase) .map(Message::of) ) .subscriber(firstChannel, ReactiveStreams.&lt;Message&lt;String&gt;&gt;builder() .peek(Message::ack) .map(Message::getPayload) .forEach(s -&gt; System.out.println(\"Consuming message \" + s))) .build() .start(); &gt;Consuming message TEST1 &gt;Consuming message TEST2 &gt;Consuming message TEST3 ",
            "title": "Processor"
        },
        {
            "location": "se/reactive-messaging",
            "text": " Reactive Messaging in Helidon SE uses the same concept of message wrapping as MicroProfile messaging. The only notable difference is that SE Messaging does almost no implicit or automatic acknowledgement due to no magic philosophy of Helidon SE. The only exception to this are the variants of the methods Messaging.Builder#listener and Messaging.Builder#processor configured with consumer or function parameters which will conveniently unwrap the payload for you. Once the payload is automatically unwrapped, it is not possible to do a manual acknowledgement, therefore an implicit acknowledgement is executed before the callback. ",
            "title": "Message"
        },
        {
            "location": "se/reactive-messaging",
            "text": " An explicit config for channel&#8217;s publisher is possible with Channel.Builder#publisherConfig(Config config) and for a subscriber with the Channel.Builder#subscriberConfig(Config config) . The supplied Helidon Config is merged with the mandatory attributes and any implicit configuration found. The resulting configuration is then served to the Connector. <markup lang=\"java\" title=\"Example consuming from Kafka connector with explicit config:\" >String kafkaServer = config.get(\"app.kafka.bootstrap.servers\").asString().get(); String topic = config.get(\"app.kafka.topic\").asString().get(); Channel&lt;String&gt; fromKafka = Channel.&lt;String&gt;builder() .name(\"from-kafka\") .publisherConfig(KafkaConnector.configBuilder() .bootstrapServers(kafkaServer) .groupId(\"example-group-\" + session.getId()) .topic(topic) .autoOffsetReset(KafkaConfigBuilder.AutoOffsetReset.LATEST) .enableAutoCommit(true) .keyDeserializer(StringDeserializer.class) .valueDeserializer(StringDeserializer.class) .build() ) .build(); KafkaConnector kafkaConnector = KafkaConnector.create(); Messaging messaging = Messaging.builder() .connector(kafkaConnector) .listener(fromKafka, payload -&gt; { System.out.println(\"Kafka says: \" + payload); }) .build() .start(); Prepare channel for connecting kafka connector with specific publisher configuration &#8594; listener, Channel &#8594; connector mapping is automatic when using KafkaConnector.configBuilder() Prepare Kafka connector, can be used by any channel ",
            "title": "Explicit Config for Messaging Connector"
        },
        {
            "location": "se/reactive-messaging",
            "text": " Implicit config without any hard-coding is possible with Helidon Config following notation of MicroProfile Reactive Messaging . <markup lang=\"yaml\" title=\"Example of channel to connector mapping config with custom properties:\" >mp.messaging.incoming.from-connector-channel.connector: example-connector mp.messaging.incoming.from-connector-channel.first-test-prop: foo mp.messaging.connector.example-connector.second-test-prop: bar Channel &#8594; Connector mapping Channel configuration properties Connector configuration properties <markup lang=\"java\" title=\"Example consuming from connector:\" >Config config = Config.create(); Messaging.builder() .config(config) .connector(new ExampleConnector()) .listener(Channel.create(\"from-connector-channel\"), s -&gt; System.out.println(\"Consuming: \" + s)) .build() .start(); &gt; Consuming: foo &gt; Consuming: bar ",
            "title": "Implicit Config for Messaging Connector"
        },
        {
            "location": "se/reactive-messaging",
            "text": " A messaging connector in Helidon SE can be configured explicitly by API or implicitly by config following the notation of MicroProfile Reactive Messaging . Configuration that is supplied to connector by the Messaging implementation must include two mandatory attributes: channel-name which is the name of the channel that has the connector configured as Publisher or Subscriber, or Channel.create('name-of-channel') in case of explicit configuration or mp.messaging.incoming.name-of-channel.connector: connector-name in case of implicit config connector name of the connector @Connector(\"connector-name\") <markup lang=\"java\" title=\"Example connector accessing configuration:\" >@Connector(\"example-connector\") public class ExampleConnector implements IncomingConnectorFactory { @Override public PublisherBuilder&lt;? extends Message&lt;?&gt;&gt; getPublisherBuilder(final Config config) { String firstPropValue = config.getValue(\"first-test-prop\", String.class); String secondPropValue = config.getValue(\"second-test-prop\", String.class); return ReactiveStreams.of(firstPropValue, secondPropValue) .map(Message::of); } } Config context is merged from channel and connector contexts Explicit Config for Messaging Connector An explicit config for channel&#8217;s publisher is possible with Channel.Builder#publisherConfig(Config config) and for a subscriber with the Channel.Builder#subscriberConfig(Config config) . The supplied Helidon Config is merged with the mandatory attributes and any implicit configuration found. The resulting configuration is then served to the Connector. <markup lang=\"java\" title=\"Example consuming from Kafka connector with explicit config:\" >String kafkaServer = config.get(\"app.kafka.bootstrap.servers\").asString().get(); String topic = config.get(\"app.kafka.topic\").asString().get(); Channel&lt;String&gt; fromKafka = Channel.&lt;String&gt;builder() .name(\"from-kafka\") .publisherConfig(KafkaConnector.configBuilder() .bootstrapServers(kafkaServer) .groupId(\"example-group-\" + session.getId()) .topic(topic) .autoOffsetReset(KafkaConfigBuilder.AutoOffsetReset.LATEST) .enableAutoCommit(true) .keyDeserializer(StringDeserializer.class) .valueDeserializer(StringDeserializer.class) .build() ) .build(); KafkaConnector kafkaConnector = KafkaConnector.create(); Messaging messaging = Messaging.builder() .connector(kafkaConnector) .listener(fromKafka, payload -&gt; { System.out.println(\"Kafka says: \" + payload); }) .build() .start(); Prepare channel for connecting kafka connector with specific publisher configuration &#8594; listener, Channel &#8594; connector mapping is automatic when using KafkaConnector.configBuilder() Prepare Kafka connector, can be used by any channel Implicit Config for Messaging Connector Implicit config without any hard-coding is possible with Helidon Config following notation of MicroProfile Reactive Messaging . <markup lang=\"yaml\" title=\"Example of channel to connector mapping config with custom properties:\" >mp.messaging.incoming.from-connector-channel.connector: example-connector mp.messaging.incoming.from-connector-channel.first-test-prop: foo mp.messaging.connector.example-connector.second-test-prop: bar Channel &#8594; Connector mapping Channel configuration properties Connector configuration properties <markup lang=\"java\" title=\"Example consuming from connector:\" >Config config = Config.create(); Messaging.builder() .config(config) .connector(new ExampleConnector()) .listener(Channel.create(\"from-connector-channel\"), s -&gt; System.out.println(\"Consuming: \" + s)) .build() .start(); &gt; Consuming: foo &gt; Consuming: bar ",
            "title": "Configuration for Messaging Connector"
        },
        {
            "location": "se/reactive-messaging",
            "text": " A connector for Reactive Messaging is a factory that produces Publishers and Subscribers for Channels in Reactive Messaging. Messaging connector is just an implementation of IncomingConnectorFactory , OutgoingConnectorFactory or both. <markup lang=\"java\" title=\"Example connector example-connector :\" >@Connector(\"example-connector\") public class ExampleConnector implements IncomingConnectorFactory, OutgoingConnectorFactory { @Override public PublisherBuilder&lt;? extends Message&lt;?&gt;&gt; getPublisherBuilder(Config config) { return ReactiveStreams.of(\"foo\", \"bar\") .map(Message::of); } @Override public SubscriberBuilder&lt;? extends Message&lt;?&gt;, Void&gt; getSubscriberBuilder(Config config) { return ReactiveStreams.&lt;Message&lt;?&gt;&gt;builder() .map(Message::getPayload) .forEach(o -&gt; System.out.println(\"Connector says: \" + o)); } } <markup lang=\"yaml\" title=\"Example of channel to connector mapping config:\" >mp.messaging.outgoing.to-connector-channel.connector: example-connector mp.messaging.incoming.from-connector-channel.connector: example-connector <markup lang=\"java\" title=\"Example producing to connector:\" >Config config = Config.create(); Messaging.builder() .config(config) .connector(new ExampleConnector()) .publisher(Channel.create(\"to-connector-channel\"), ReactiveStreams.of(\"fee\", \"fie\") .map(Message::of) ) .build() .start(); &gt; Connector says: fee &gt; Connector says: fie <markup lang=\"java\" title=\"Example consuming from connector:\" >Messaging.builder() .connector(new ExampleConnector()) .subscriber(Channel.create(\"from-connector-channel\"), ReactiveStreams.&lt;Message&lt;String&gt;&gt;builder() .peek(Message::ack) .map(Message::getPayload) .forEach(s -&gt; System.out.println(\"Consuming: \" + s)) ) .build() .start(); &gt; Consuming: foo &gt; Consuming: bar Configuration for Messaging Connector A messaging connector in Helidon SE can be configured explicitly by API or implicitly by config following the notation of MicroProfile Reactive Messaging . Configuration that is supplied to connector by the Messaging implementation must include two mandatory attributes: channel-name which is the name of the channel that has the connector configured as Publisher or Subscriber, or Channel.create('name-of-channel') in case of explicit configuration or mp.messaging.incoming.name-of-channel.connector: connector-name in case of implicit config connector name of the connector @Connector(\"connector-name\") <markup lang=\"java\" title=\"Example connector accessing configuration:\" >@Connector(\"example-connector\") public class ExampleConnector implements IncomingConnectorFactory { @Override public PublisherBuilder&lt;? extends Message&lt;?&gt;&gt; getPublisherBuilder(final Config config) { String firstPropValue = config.getValue(\"first-test-prop\", String.class); String secondPropValue = config.getValue(\"second-test-prop\", String.class); return ReactiveStreams.of(firstPropValue, secondPropValue) .map(Message::of); } } Config context is merged from channel and connector contexts Explicit Config for Messaging Connector An explicit config for channel&#8217;s publisher is possible with Channel.Builder#publisherConfig(Config config) and for a subscriber with the Channel.Builder#subscriberConfig(Config config) . The supplied Helidon Config is merged with the mandatory attributes and any implicit configuration found. The resulting configuration is then served to the Connector. <markup lang=\"java\" title=\"Example consuming from Kafka connector with explicit config:\" >String kafkaServer = config.get(\"app.kafka.bootstrap.servers\").asString().get(); String topic = config.get(\"app.kafka.topic\").asString().get(); Channel&lt;String&gt; fromKafka = Channel.&lt;String&gt;builder() .name(\"from-kafka\") .publisherConfig(KafkaConnector.configBuilder() .bootstrapServers(kafkaServer) .groupId(\"example-group-\" + session.getId()) .topic(topic) .autoOffsetReset(KafkaConfigBuilder.AutoOffsetReset.LATEST) .enableAutoCommit(true) .keyDeserializer(StringDeserializer.class) .valueDeserializer(StringDeserializer.class) .build() ) .build(); KafkaConnector kafkaConnector = KafkaConnector.create(); Messaging messaging = Messaging.builder() .connector(kafkaConnector) .listener(fromKafka, payload -&gt; { System.out.println(\"Kafka says: \" + payload); }) .build() .start(); Prepare channel for connecting kafka connector with specific publisher configuration &#8594; listener, Channel &#8594; connector mapping is automatic when using KafkaConnector.configBuilder() Prepare Kafka connector, can be used by any channel Implicit Config for Messaging Connector Implicit config without any hard-coding is possible with Helidon Config following notation of MicroProfile Reactive Messaging . <markup lang=\"yaml\" title=\"Example of channel to connector mapping config with custom properties:\" >mp.messaging.incoming.from-connector-channel.connector: example-connector mp.messaging.incoming.from-connector-channel.first-test-prop: foo mp.messaging.connector.example-connector.second-test-prop: bar Channel &#8594; Connector mapping Channel configuration properties Connector configuration properties <markup lang=\"java\" title=\"Example consuming from connector:\" >Config config = Config.create(); Messaging.builder() .config(config) .connector(new ExampleConnector()) .listener(Channel.create(\"from-connector-channel\"), s -&gt; System.out.println(\"Consuming: \" + s)) .build() .start(); &gt; Consuming: foo &gt; Consuming: bar ",
            "title": "Messaging Connector"
        },
        {
            "location": "se/reactive-messaging",
            "text": " As the API is the same for MicroProfile Reactive Messaging connectors, all that is needed to make connector work in both ways is annotating it with @ApplicationScoped . Such connector is treated as a bean in Helidon MP. For specific information about creating messaging connectors for Helidon MP visit MicroProfile Reactive Messaging . ",
            "title": "Reusability in MP Messaging"
        },
        {
            "location": "se/reactive-messaging",
            "text": " Connecting streams to Kafka with Reactive Messaging couldn&#8217;t be easier. ",
            "title": "Reactive Kafka Connector"
        },
        {
            "location": "se/reactive-messaging",
            "text": "<markup lang=\"java\" title=\"Example of consuming from Kafka:\" >String kafkaServer = config.get(\"app.kafka.bootstrap.servers\").asString().get(); String topic = config.get(\"app.kafka.topic\").asString().get(); Channel&lt;String&gt; fromKafka = Channel.&lt;String&gt;builder() .name(\"from-kafka\") .publisherConfig(KafkaConnector.configBuilder() .bootstrapServers(kafkaServer) .groupId(\"example-group-\" + session.getId()) .topic(topic) .autoOffsetReset(KafkaConfigBuilder.AutoOffsetReset.LATEST) .enableAutoCommit(true) .keyDeserializer(StringDeserializer.class) .valueDeserializer(StringDeserializer.class) .build() ) .build(); KafkaConnector kafkaConnector = KafkaConnector.create(); Messaging messaging = Messaging.builder() .connector(kafkaConnector) .listener(fromKafka, payload -&gt; { System.out.println(\"Kafka says: \" + payload); }) .build() .start(); Prepare a channel for connecting kafka connector with specific publisher configuration &#8594; listener Channel &#8594; connector mapping is automatic when using KafkaConnector.configBuilder() Prepare Kafka connector, can be used by any channel <markup lang=\"java\" title=\"Example of producing to Kafka:\" >String kafkaServer = config.get(\"app.kafka.bootstrap.servers\").asString().get(); String topic = config.get(\"app.kafka.topic\").asString().get(); Channel&lt;String&gt; toKafka = Channel.&lt;String&gt;builder() .subscriberConfig(KafkaConnector.configBuilder() .bootstrapServers(kafkaServer) .topic(topic) .keySerializer(StringSerializer.class) .valueSerializer(StringSerializer.class) .build() ).build(); KafkaConnector kafkaConnector = KafkaConnector.create(); messaging = Messaging.builder() .publisher(toKafka, Multi.just(\"test1\", \"test2\").map(Message::of)) .connector(kafkaConnector) .build() .start(); Prepare a channel for connecting kafka connector with specific publisher configuration &#8594; listener Channel &#8594; connector mapping is automatic when using KafkaConnector.configBuilder() Prepare Kafka connector, can be used by any channel ",
            "title": "Explicit Config with Config Builder for Kafka Connector"
        },
        {
            "location": "se/reactive-messaging",
            "text": "<markup lang=\"yaml\" title=\"Example of connector config:\" >mp.messaging: incoming.from-kafka: connector: helidon-kafka topic: messaging-test-topic-1 auto.offset.reset: latest enable.auto.commit: true group.id: example-group-id outgoing.to-kafka: connector: helidon-kafka topic: messaging-test-topic-1 connector: helidon-kafka: bootstrap.servers: localhost:9092 key.serializer: org.apache.kafka.common.serialization.StringSerializer value.serializer: org.apache.kafka.common.serialization.StringSerializer key.deserializer: org.apache.kafka.common.serialization.StringDeserializer value.deserializer: org.apache.kafka.common.serialization.StringDeserializer Kafka client consumer&#8217;s property auto.offset.reset configuration for from-kafka channel only Kafka client&#8217;s property bootstrap.servers configuration for all channels using the connector <markup lang=\"java\" title=\"Example of consuming from Kafka:\" >Config config = Config.create(); Channel&lt;String&gt; fromKafka = Channel.create(\"from-kafka\"); KafkaConnector kafkaConnector = KafkaConnector.create(); Messaging messaging = Messaging.builder() .config(config) .connector(kafkaConnector) .listener(fromKafka, payload -&gt; { System.out.println(\"Kafka says: \" + payload); }) .build() .start(); Prepare Kafka connector, can be used by any channel <markup lang=\"java\" title=\"Example of producing to Kafka:\" >Config config = Config.create(); Channel&lt;String&gt; toKafka = Channel.create(\"to-kafka\"); KafkaConnector kafkaConnector = KafkaConnector.create(); messaging = Messaging.builder() .config(config) .publisher(toKafka, Multi.just(\"test1\", \"test2\").map(Message::of)) .connector(kafkaConnector) .build() .start(); Prepare Kafka connector, can be used by any channel Don&#8217;t forget to check out the examples with pre-configured Kafka docker image, for easy testing: https://github.com/oracle/helidon/tree/master/examples/messaging ",
            "title": "Implicit Helidon Config for Kafka Connector"
        },
        {
            "location": "se/reactive-messaging",
            "text": "<markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.messaging.kafka&lt;/groupId&gt; &lt;artifactId&gt;helidon-messaging-kafka&lt;/artifactId&gt; &lt;/dependency&gt; Reactive Kafka Connector Connecting streams to Kafka with Reactive Messaging couldn&#8217;t be easier. Explicit Config with Config Builder for Kafka Connector <markup lang=\"java\" title=\"Example of consuming from Kafka:\" >String kafkaServer = config.get(\"app.kafka.bootstrap.servers\").asString().get(); String topic = config.get(\"app.kafka.topic\").asString().get(); Channel&lt;String&gt; fromKafka = Channel.&lt;String&gt;builder() .name(\"from-kafka\") .publisherConfig(KafkaConnector.configBuilder() .bootstrapServers(kafkaServer) .groupId(\"example-group-\" + session.getId()) .topic(topic) .autoOffsetReset(KafkaConfigBuilder.AutoOffsetReset.LATEST) .enableAutoCommit(true) .keyDeserializer(StringDeserializer.class) .valueDeserializer(StringDeserializer.class) .build() ) .build(); KafkaConnector kafkaConnector = KafkaConnector.create(); Messaging messaging = Messaging.builder() .connector(kafkaConnector) .listener(fromKafka, payload -&gt; { System.out.println(\"Kafka says: \" + payload); }) .build() .start(); Prepare a channel for connecting kafka connector with specific publisher configuration &#8594; listener Channel &#8594; connector mapping is automatic when using KafkaConnector.configBuilder() Prepare Kafka connector, can be used by any channel <markup lang=\"java\" title=\"Example of producing to Kafka:\" >String kafkaServer = config.get(\"app.kafka.bootstrap.servers\").asString().get(); String topic = config.get(\"app.kafka.topic\").asString().get(); Channel&lt;String&gt; toKafka = Channel.&lt;String&gt;builder() .subscriberConfig(KafkaConnector.configBuilder() .bootstrapServers(kafkaServer) .topic(topic) .keySerializer(StringSerializer.class) .valueSerializer(StringSerializer.class) .build() ).build(); KafkaConnector kafkaConnector = KafkaConnector.create(); messaging = Messaging.builder() .publisher(toKafka, Multi.just(\"test1\", \"test2\").map(Message::of)) .connector(kafkaConnector) .build() .start(); Prepare a channel for connecting kafka connector with specific publisher configuration &#8594; listener Channel &#8594; connector mapping is automatic when using KafkaConnector.configBuilder() Prepare Kafka connector, can be used by any channel Implicit Helidon Config for Kafka Connector <markup lang=\"yaml\" title=\"Example of connector config:\" >mp.messaging: incoming.from-kafka: connector: helidon-kafka topic: messaging-test-topic-1 auto.offset.reset: latest enable.auto.commit: true group.id: example-group-id outgoing.to-kafka: connector: helidon-kafka topic: messaging-test-topic-1 connector: helidon-kafka: bootstrap.servers: localhost:9092 key.serializer: org.apache.kafka.common.serialization.StringSerializer value.serializer: org.apache.kafka.common.serialization.StringSerializer key.deserializer: org.apache.kafka.common.serialization.StringDeserializer value.deserializer: org.apache.kafka.common.serialization.StringDeserializer Kafka client consumer&#8217;s property auto.offset.reset configuration for from-kafka channel only Kafka client&#8217;s property bootstrap.servers configuration for all channels using the connector <markup lang=\"java\" title=\"Example of consuming from Kafka:\" >Config config = Config.create(); Channel&lt;String&gt; fromKafka = Channel.create(\"from-kafka\"); KafkaConnector kafkaConnector = KafkaConnector.create(); Messaging messaging = Messaging.builder() .config(config) .connector(kafkaConnector) .listener(fromKafka, payload -&gt; { System.out.println(\"Kafka says: \" + payload); }) .build() .start(); Prepare Kafka connector, can be used by any channel <markup lang=\"java\" title=\"Example of producing to Kafka:\" >Config config = Config.create(); Channel&lt;String&gt; toKafka = Channel.create(\"to-kafka\"); KafkaConnector kafkaConnector = KafkaConnector.create(); messaging = Messaging.builder() .config(config) .publisher(toKafka, Multi.just(\"test1\", \"test2\").map(Message::of)) .connector(kafkaConnector) .build() .start(); Prepare Kafka connector, can be used by any channel Don&#8217;t forget to check out the examples with pre-configured Kafka docker image, for easy testing: https://github.com/oracle/helidon/tree/master/examples/messaging ",
            "title": "Kafka Connector"
        },
        {
            "location": "se/reactive-messaging",
            "text": " Connecting streams to JMS with Reactive Messaging couldn&#8217;t be easier. ",
            "title": "Reactive JMS Connector"
        },
        {
            "location": "se/reactive-messaging",
            "text": "<markup lang=\"java\" title=\"Example of consuming from JMS:\" >Channel&lt;String&gt; fromJms = Channel.&lt;String&gt;builder() .name(\"from-jms\") .publisherConfig(JmsConnector.configBuilder() .jndiInitialFactory(ActiveMQInitialContextFactory.class) .jndiProviderUrl(\"tcp://127.0.0.1:61616\") .type(JmsConfigBuilder.Type.QUEUE) .destination(\"se-example-queue-1\") .build() ) .build(); JmsConnector jmsConnector = JmsConnector.create(); Messaging messaging = Messaging.builder() .connector(jmsConnector) .listener(fromJms, payload -&gt; { System.out.println(\"Jms says: \" + payload); }) .build() .start(); Prepare a channel for connecting jms connector with specific publisher configuration &#8594; listener Channel &#8594; connector mapping is automatic when using JmsConnector.configBuilder() Prepare JMS connector, can be used by any channel <markup lang=\"java\" title=\"Example of producing to JMS:\" >Channel&lt;String&gt; toJms = Channel.&lt;String&gt;builder() .subscriberConfig(JmsConnector.configBuilder() .jndiInitialFactory(ActiveMQInitialContextFactory.class) .jndiProviderUrl(\"tcp://127.0.0.1:61616\") .type(JmsConfigBuilder.Type.QUEUE) .destination(\"se-example-queue-1\") .build() ).build(); JmsConnector jmsConnector = JmsConnector.create(); messaging = Messaging.builder() .publisher(toJms, Multi.just(\"test1\", \"test2\").map(Message::of)) .connector(jmsConnector) .build() .start(); Prepare a channel for connecting jms connector with specific publisher configuration &#8594; listener Channel &#8594; connector mapping is automatic when using JmsConnector.configBuilder() Prepare JMS connector, can be used by any channel ",
            "title": "Explicit Config with Config Builder for JMS Connector"
        },
        {
            "location": "se/reactive-messaging",
            "text": "<markup lang=\"yaml\" title=\"Example of connector config:\" >mp.messaging: incoming.from-jms: connector: helidon-jms destination: se-example-queue-1 session-group-id: session-group-1 type: queue outgoing.to-jms: connector: helidon-jms destination: se-example-queue-1 type: queue connector: helidon-jms: jndi: jms-factory: ConnectionFactory env-properties: java.naming.factory.initial: org.apache.activemq.jndi.ActiveMQInitialContextFactory java.naming.provider.url: tcp://127.0.0.1:61616 <markup lang=\"java\" title=\"Example of consuming from JMS:\" >Config config = Config.create(); Channel&lt;String&gt; fromJms = Channel.create(\"from-jms\"); JmsConnector jmsConnector = JmsConnector.create(); Messaging messaging = Messaging.builder() .config(config) .connector(jmsConnector) .listener(fromJms, payload -&gt; { System.out.println(\"Jms says: \" + payload); }) .build() .start(); Prepare JMS connector, can be used by any channel <markup lang=\"java\" title=\"Example of producing to JMS:\" >Config config = Config.create(); Channel&lt;String&gt; toJms = Channel.create(\"to-jms\"); JmsConnector jmsConnector = JmsConnector.create(); messaging = Messaging.builder() .config(config) .publisher(toJms, Multi.just(\"test1\", \"test2\").map(Message::of)) .connector(jmsConnector) .build() .start(); Prepare JMS connector, can be used by any channel Don&#8217;t forget to check out the examples with pre-configured ActiveMQ docker image, for easy testing: https://github.com/oracle/helidon/tree/master/examples/messaging ",
            "title": "Implicit Helidon Config for JMS Connector"
        },
        {
            "location": "se/reactive-messaging",
            "text": "<markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.messaging.jms&lt;/groupId&gt; &lt;artifactId&gt;helidon-messaging-jms&lt;/artifactId&gt; &lt;/dependency&gt; Reactive JMS Connector Connecting streams to JMS with Reactive Messaging couldn&#8217;t be easier. Explicit Config with Config Builder for JMS Connector <markup lang=\"java\" title=\"Example of consuming from JMS:\" >Channel&lt;String&gt; fromJms = Channel.&lt;String&gt;builder() .name(\"from-jms\") .publisherConfig(JmsConnector.configBuilder() .jndiInitialFactory(ActiveMQInitialContextFactory.class) .jndiProviderUrl(\"tcp://127.0.0.1:61616\") .type(JmsConfigBuilder.Type.QUEUE) .destination(\"se-example-queue-1\") .build() ) .build(); JmsConnector jmsConnector = JmsConnector.create(); Messaging messaging = Messaging.builder() .connector(jmsConnector) .listener(fromJms, payload -&gt; { System.out.println(\"Jms says: \" + payload); }) .build() .start(); Prepare a channel for connecting jms connector with specific publisher configuration &#8594; listener Channel &#8594; connector mapping is automatic when using JmsConnector.configBuilder() Prepare JMS connector, can be used by any channel <markup lang=\"java\" title=\"Example of producing to JMS:\" >Channel&lt;String&gt; toJms = Channel.&lt;String&gt;builder() .subscriberConfig(JmsConnector.configBuilder() .jndiInitialFactory(ActiveMQInitialContextFactory.class) .jndiProviderUrl(\"tcp://127.0.0.1:61616\") .type(JmsConfigBuilder.Type.QUEUE) .destination(\"se-example-queue-1\") .build() ).build(); JmsConnector jmsConnector = JmsConnector.create(); messaging = Messaging.builder() .publisher(toJms, Multi.just(\"test1\", \"test2\").map(Message::of)) .connector(jmsConnector) .build() .start(); Prepare a channel for connecting jms connector with specific publisher configuration &#8594; listener Channel &#8594; connector mapping is automatic when using JmsConnector.configBuilder() Prepare JMS connector, can be used by any channel Implicit Helidon Config for JMS Connector <markup lang=\"yaml\" title=\"Example of connector config:\" >mp.messaging: incoming.from-jms: connector: helidon-jms destination: se-example-queue-1 session-group-id: session-group-1 type: queue outgoing.to-jms: connector: helidon-jms destination: se-example-queue-1 type: queue connector: helidon-jms: jndi: jms-factory: ConnectionFactory env-properties: java.naming.factory.initial: org.apache.activemq.jndi.ActiveMQInitialContextFactory java.naming.provider.url: tcp://127.0.0.1:61616 <markup lang=\"java\" title=\"Example of consuming from JMS:\" >Config config = Config.create(); Channel&lt;String&gt; fromJms = Channel.create(\"from-jms\"); JmsConnector jmsConnector = JmsConnector.create(); Messaging messaging = Messaging.builder() .config(config) .connector(jmsConnector) .listener(fromJms, payload -&gt; { System.out.println(\"Jms says: \" + payload); }) .build() .start(); Prepare JMS connector, can be used by any channel <markup lang=\"java\" title=\"Example of producing to JMS:\" >Config config = Config.create(); Channel&lt;String&gt; toJms = Channel.create(\"to-jms\"); JmsConnector jmsConnector = JmsConnector.create(); messaging = Messaging.builder() .config(config) .publisher(toJms, Multi.just(\"test1\", \"test2\").map(Message::of)) .connector(jmsConnector) .build() .start(); Prepare JMS connector, can be used by any channel Don&#8217;t forget to check out the examples with pre-configured ActiveMQ docker image, for easy testing: https://github.com/oracle/helidon/tree/master/examples/messaging ",
            "title": "JMS Connector"
        },
        {
            "location": "se/reactive-messaging",
            "text": "",
            "title": "Reactive Oracle AQ Connector"
        },
        {
            "location": "se/reactive-messaging",
            "text": "<markup lang=\"java\" title=\"Example of producing to and consuming from Oracle AQ:\" >PoolDataSource pds = PoolDataSourceFactory.getPoolDataSource(); pds.setConnectionFactoryClassName(\"oracle.jdbc.pool.OracleDataSource\"); pds.setURL(\"jdbc:oracle:thin:@(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(Host=192.168.0.123)(Port=1521))(CONNECT_DATA=(SID=XE)))\"); pds.setUser(\"frank\"); pds.setPassword(\"frank\"); AqConnector seConn = AqConnector.builder() .dataSource(\"test-ds\", pds) .build(); Channel&lt;String&gt; toAq = Channel.&lt;String&gt;builder() .name(\"toAq\") .subscriberConfig(AqConnector.configBuilder() .queue(\"example_queue_1\") .dataSource(\"test-ds\") .build()) .build(); Channel&lt;String&gt; fromAq = Channel.&lt;String&gt;builder() .name(\"fromAq\") .publisherConfig(AqConnector.configBuilder() .queue(\"example_queue_1\") .dataSource(\"test-ds\") .build()) .build(); Messaging.builder() .connector(seConn) .publisher(toAq, Multi.just(\"Hello\", \"world\", \"from\", \"Oracle\", \"DB!\").map(Message::of)) .listener(fromAq, s -&gt; System.out.pritln(\"Message received: \"+s)) .build() .start(); Prepare Oracle UCP Setup AQ connector and provide datasource with an identifier test-ds Setup channel for sending messages to queue example_queue_1 with datasource test-ds Setup channel for receiving messages from queue example_queue_1 with datasource test-ds Register connector and channels Add a publisher for several test messages to publish them to example_queue_1 immediately Subscribe callback for any message coming from example_queue_1 ",
            "title": "Sending and Receiving"
        },
        {
            "location": "se/reactive-messaging",
            "text": "<markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.messaging.aq&lt;/groupId&gt; &lt;artifactId&gt;helidon-messaging-aq&lt;/artifactId&gt; &lt;/dependency&gt; Reactive Oracle AQ Connector Sending and Receiving <markup lang=\"java\" title=\"Example of producing to and consuming from Oracle AQ:\" >PoolDataSource pds = PoolDataSourceFactory.getPoolDataSource(); pds.setConnectionFactoryClassName(\"oracle.jdbc.pool.OracleDataSource\"); pds.setURL(\"jdbc:oracle:thin:@(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(Host=192.168.0.123)(Port=1521))(CONNECT_DATA=(SID=XE)))\"); pds.setUser(\"frank\"); pds.setPassword(\"frank\"); AqConnector seConn = AqConnector.builder() .dataSource(\"test-ds\", pds) .build(); Channel&lt;String&gt; toAq = Channel.&lt;String&gt;builder() .name(\"toAq\") .subscriberConfig(AqConnector.configBuilder() .queue(\"example_queue_1\") .dataSource(\"test-ds\") .build()) .build(); Channel&lt;String&gt; fromAq = Channel.&lt;String&gt;builder() .name(\"fromAq\") .publisherConfig(AqConnector.configBuilder() .queue(\"example_queue_1\") .dataSource(\"test-ds\") .build()) .build(); Messaging.builder() .connector(seConn) .publisher(toAq, Multi.just(\"Hello\", \"world\", \"from\", \"Oracle\", \"DB!\").map(Message::of)) .listener(fromAq, s -&gt; System.out.pritln(\"Message received: \"+s)) .build() .start(); Prepare Oracle UCP Setup AQ connector and provide datasource with an identifier test-ds Setup channel for sending messages to queue example_queue_1 with datasource test-ds Setup channel for receiving messages from queue example_queue_1 with datasource test-ds Register connector and channels Add a publisher for several test messages to publish them to example_queue_1 immediately Subscribe callback for any message coming from example_queue_1 ",
            "title": "AQ Connector"
        },
        {
            "location": "se/reactive-messaging",
            "text": " Connectors are used to connect channels to external sources. To make the creation and usage of connectors as easy and versatile as possible, Helidon SE Messaging uses the same API for connectors that MicroProfile Reactive Messaging does. This allows connectors to be used in both flavors of Helidon with one limitation which is that the connector has to be able to work without CDI. Examples of versatile connectors in Helidon include the following: Kafka connector JMS connector AQ Connector Messaging Connector A connector for Reactive Messaging is a factory that produces Publishers and Subscribers for Channels in Reactive Messaging. Messaging connector is just an implementation of IncomingConnectorFactory , OutgoingConnectorFactory or both. <markup lang=\"java\" title=\"Example connector example-connector :\" >@Connector(\"example-connector\") public class ExampleConnector implements IncomingConnectorFactory, OutgoingConnectorFactory { @Override public PublisherBuilder&lt;? extends Message&lt;?&gt;&gt; getPublisherBuilder(Config config) { return ReactiveStreams.of(\"foo\", \"bar\") .map(Message::of); } @Override public SubscriberBuilder&lt;? extends Message&lt;?&gt;, Void&gt; getSubscriberBuilder(Config config) { return ReactiveStreams.&lt;Message&lt;?&gt;&gt;builder() .map(Message::getPayload) .forEach(o -&gt; System.out.println(\"Connector says: \" + o)); } } <markup lang=\"yaml\" title=\"Example of channel to connector mapping config:\" >mp.messaging.outgoing.to-connector-channel.connector: example-connector mp.messaging.incoming.from-connector-channel.connector: example-connector <markup lang=\"java\" title=\"Example producing to connector:\" >Config config = Config.create(); Messaging.builder() .config(config) .connector(new ExampleConnector()) .publisher(Channel.create(\"to-connector-channel\"), ReactiveStreams.of(\"fee\", \"fie\") .map(Message::of) ) .build() .start(); &gt; Connector says: fee &gt; Connector says: fie <markup lang=\"java\" title=\"Example consuming from connector:\" >Messaging.builder() .connector(new ExampleConnector()) .subscriber(Channel.create(\"from-connector-channel\"), ReactiveStreams.&lt;Message&lt;String&gt;&gt;builder() .peek(Message::ack) .map(Message::getPayload) .forEach(s -&gt; System.out.println(\"Consuming: \" + s)) ) .build() .start(); &gt; Consuming: foo &gt; Consuming: bar Configuration for Messaging Connector A messaging connector in Helidon SE can be configured explicitly by API or implicitly by config following the notation of MicroProfile Reactive Messaging . Configuration that is supplied to connector by the Messaging implementation must include two mandatory attributes: channel-name which is the name of the channel that has the connector configured as Publisher or Subscriber, or Channel.create('name-of-channel') in case of explicit configuration or mp.messaging.incoming.name-of-channel.connector: connector-name in case of implicit config connector name of the connector @Connector(\"connector-name\") <markup lang=\"java\" title=\"Example connector accessing configuration:\" >@Connector(\"example-connector\") public class ExampleConnector implements IncomingConnectorFactory { @Override public PublisherBuilder&lt;? extends Message&lt;?&gt;&gt; getPublisherBuilder(final Config config) { String firstPropValue = config.getValue(\"first-test-prop\", String.class); String secondPropValue = config.getValue(\"second-test-prop\", String.class); return ReactiveStreams.of(firstPropValue, secondPropValue) .map(Message::of); } } Config context is merged from channel and connector contexts Explicit Config for Messaging Connector An explicit config for channel&#8217;s publisher is possible with Channel.Builder#publisherConfig(Config config) and for a subscriber with the Channel.Builder#subscriberConfig(Config config) . The supplied Helidon Config is merged with the mandatory attributes and any implicit configuration found. The resulting configuration is then served to the Connector. <markup lang=\"java\" title=\"Example consuming from Kafka connector with explicit config:\" >String kafkaServer = config.get(\"app.kafka.bootstrap.servers\").asString().get(); String topic = config.get(\"app.kafka.topic\").asString().get(); Channel&lt;String&gt; fromKafka = Channel.&lt;String&gt;builder() .name(\"from-kafka\") .publisherConfig(KafkaConnector.configBuilder() .bootstrapServers(kafkaServer) .groupId(\"example-group-\" + session.getId()) .topic(topic) .autoOffsetReset(KafkaConfigBuilder.AutoOffsetReset.LATEST) .enableAutoCommit(true) .keyDeserializer(StringDeserializer.class) .valueDeserializer(StringDeserializer.class) .build() ) .build(); KafkaConnector kafkaConnector = KafkaConnector.create(); Messaging messaging = Messaging.builder() .connector(kafkaConnector) .listener(fromKafka, payload -&gt; { System.out.println(\"Kafka says: \" + payload); }) .build() .start(); Prepare channel for connecting kafka connector with specific publisher configuration &#8594; listener, Channel &#8594; connector mapping is automatic when using KafkaConnector.configBuilder() Prepare Kafka connector, can be used by any channel Implicit Config for Messaging Connector Implicit config without any hard-coding is possible with Helidon Config following notation of MicroProfile Reactive Messaging . <markup lang=\"yaml\" title=\"Example of channel to connector mapping config with custom properties:\" >mp.messaging.incoming.from-connector-channel.connector: example-connector mp.messaging.incoming.from-connector-channel.first-test-prop: foo mp.messaging.connector.example-connector.second-test-prop: bar Channel &#8594; Connector mapping Channel configuration properties Connector configuration properties <markup lang=\"java\" title=\"Example consuming from connector:\" >Config config = Config.create(); Messaging.builder() .config(config) .connector(new ExampleConnector()) .listener(Channel.create(\"from-connector-channel\"), s -&gt; System.out.println(\"Consuming: \" + s)) .build() .start(); &gt; Consuming: foo &gt; Consuming: bar Reusability in MP Messaging As the API is the same for MicroProfile Reactive Messaging connectors, all that is needed to make connector work in both ways is annotating it with @ApplicationScoped . Such connector is treated as a bean in Helidon MP. For specific information about creating messaging connectors for Helidon MP visit MicroProfile Reactive Messaging . Kafka Connector <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.messaging.kafka&lt;/groupId&gt; &lt;artifactId&gt;helidon-messaging-kafka&lt;/artifactId&gt; &lt;/dependency&gt; Reactive Kafka Connector Connecting streams to Kafka with Reactive Messaging couldn&#8217;t be easier. Explicit Config with Config Builder for Kafka Connector <markup lang=\"java\" title=\"Example of consuming from Kafka:\" >String kafkaServer = config.get(\"app.kafka.bootstrap.servers\").asString().get(); String topic = config.get(\"app.kafka.topic\").asString().get(); Channel&lt;String&gt; fromKafka = Channel.&lt;String&gt;builder() .name(\"from-kafka\") .publisherConfig(KafkaConnector.configBuilder() .bootstrapServers(kafkaServer) .groupId(\"example-group-\" + session.getId()) .topic(topic) .autoOffsetReset(KafkaConfigBuilder.AutoOffsetReset.LATEST) .enableAutoCommit(true) .keyDeserializer(StringDeserializer.class) .valueDeserializer(StringDeserializer.class) .build() ) .build(); KafkaConnector kafkaConnector = KafkaConnector.create(); Messaging messaging = Messaging.builder() .connector(kafkaConnector) .listener(fromKafka, payload -&gt; { System.out.println(\"Kafka says: \" + payload); }) .build() .start(); Prepare a channel for connecting kafka connector with specific publisher configuration &#8594; listener Channel &#8594; connector mapping is automatic when using KafkaConnector.configBuilder() Prepare Kafka connector, can be used by any channel <markup lang=\"java\" title=\"Example of producing to Kafka:\" >String kafkaServer = config.get(\"app.kafka.bootstrap.servers\").asString().get(); String topic = config.get(\"app.kafka.topic\").asString().get(); Channel&lt;String&gt; toKafka = Channel.&lt;String&gt;builder() .subscriberConfig(KafkaConnector.configBuilder() .bootstrapServers(kafkaServer) .topic(topic) .keySerializer(StringSerializer.class) .valueSerializer(StringSerializer.class) .build() ).build(); KafkaConnector kafkaConnector = KafkaConnector.create(); messaging = Messaging.builder() .publisher(toKafka, Multi.just(\"test1\", \"test2\").map(Message::of)) .connector(kafkaConnector) .build() .start(); Prepare a channel for connecting kafka connector with specific publisher configuration &#8594; listener Channel &#8594; connector mapping is automatic when using KafkaConnector.configBuilder() Prepare Kafka connector, can be used by any channel Implicit Helidon Config for Kafka Connector <markup lang=\"yaml\" title=\"Example of connector config:\" >mp.messaging: incoming.from-kafka: connector: helidon-kafka topic: messaging-test-topic-1 auto.offset.reset: latest enable.auto.commit: true group.id: example-group-id outgoing.to-kafka: connector: helidon-kafka topic: messaging-test-topic-1 connector: helidon-kafka: bootstrap.servers: localhost:9092 key.serializer: org.apache.kafka.common.serialization.StringSerializer value.serializer: org.apache.kafka.common.serialization.StringSerializer key.deserializer: org.apache.kafka.common.serialization.StringDeserializer value.deserializer: org.apache.kafka.common.serialization.StringDeserializer Kafka client consumer&#8217;s property auto.offset.reset configuration for from-kafka channel only Kafka client&#8217;s property bootstrap.servers configuration for all channels using the connector <markup lang=\"java\" title=\"Example of consuming from Kafka:\" >Config config = Config.create(); Channel&lt;String&gt; fromKafka = Channel.create(\"from-kafka\"); KafkaConnector kafkaConnector = KafkaConnector.create(); Messaging messaging = Messaging.builder() .config(config) .connector(kafkaConnector) .listener(fromKafka, payload -&gt; { System.out.println(\"Kafka says: \" + payload); }) .build() .start(); Prepare Kafka connector, can be used by any channel <markup lang=\"java\" title=\"Example of producing to Kafka:\" >Config config = Config.create(); Channel&lt;String&gt; toKafka = Channel.create(\"to-kafka\"); KafkaConnector kafkaConnector = KafkaConnector.create(); messaging = Messaging.builder() .config(config) .publisher(toKafka, Multi.just(\"test1\", \"test2\").map(Message::of)) .connector(kafkaConnector) .build() .start(); Prepare Kafka connector, can be used by any channel Don&#8217;t forget to check out the examples with pre-configured Kafka docker image, for easy testing: https://github.com/oracle/helidon/tree/master/examples/messaging JMS Connector <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.messaging.jms&lt;/groupId&gt; &lt;artifactId&gt;helidon-messaging-jms&lt;/artifactId&gt; &lt;/dependency&gt; Reactive JMS Connector Connecting streams to JMS with Reactive Messaging couldn&#8217;t be easier. Explicit Config with Config Builder for JMS Connector <markup lang=\"java\" title=\"Example of consuming from JMS:\" >Channel&lt;String&gt; fromJms = Channel.&lt;String&gt;builder() .name(\"from-jms\") .publisherConfig(JmsConnector.configBuilder() .jndiInitialFactory(ActiveMQInitialContextFactory.class) .jndiProviderUrl(\"tcp://127.0.0.1:61616\") .type(JmsConfigBuilder.Type.QUEUE) .destination(\"se-example-queue-1\") .build() ) .build(); JmsConnector jmsConnector = JmsConnector.create(); Messaging messaging = Messaging.builder() .connector(jmsConnector) .listener(fromJms, payload -&gt; { System.out.println(\"Jms says: \" + payload); }) .build() .start(); Prepare a channel for connecting jms connector with specific publisher configuration &#8594; listener Channel &#8594; connector mapping is automatic when using JmsConnector.configBuilder() Prepare JMS connector, can be used by any channel <markup lang=\"java\" title=\"Example of producing to JMS:\" >Channel&lt;String&gt; toJms = Channel.&lt;String&gt;builder() .subscriberConfig(JmsConnector.configBuilder() .jndiInitialFactory(ActiveMQInitialContextFactory.class) .jndiProviderUrl(\"tcp://127.0.0.1:61616\") .type(JmsConfigBuilder.Type.QUEUE) .destination(\"se-example-queue-1\") .build() ).build(); JmsConnector jmsConnector = JmsConnector.create(); messaging = Messaging.builder() .publisher(toJms, Multi.just(\"test1\", \"test2\").map(Message::of)) .connector(jmsConnector) .build() .start(); Prepare a channel for connecting jms connector with specific publisher configuration &#8594; listener Channel &#8594; connector mapping is automatic when using JmsConnector.configBuilder() Prepare JMS connector, can be used by any channel Implicit Helidon Config for JMS Connector <markup lang=\"yaml\" title=\"Example of connector config:\" >mp.messaging: incoming.from-jms: connector: helidon-jms destination: se-example-queue-1 session-group-id: session-group-1 type: queue outgoing.to-jms: connector: helidon-jms destination: se-example-queue-1 type: queue connector: helidon-jms: jndi: jms-factory: ConnectionFactory env-properties: java.naming.factory.initial: org.apache.activemq.jndi.ActiveMQInitialContextFactory java.naming.provider.url: tcp://127.0.0.1:61616 <markup lang=\"java\" title=\"Example of consuming from JMS:\" >Config config = Config.create(); Channel&lt;String&gt; fromJms = Channel.create(\"from-jms\"); JmsConnector jmsConnector = JmsConnector.create(); Messaging messaging = Messaging.builder() .config(config) .connector(jmsConnector) .listener(fromJms, payload -&gt; { System.out.println(\"Jms says: \" + payload); }) .build() .start(); Prepare JMS connector, can be used by any channel <markup lang=\"java\" title=\"Example of producing to JMS:\" >Config config = Config.create(); Channel&lt;String&gt; toJms = Channel.create(\"to-jms\"); JmsConnector jmsConnector = JmsConnector.create(); messaging = Messaging.builder() .config(config) .publisher(toJms, Multi.just(\"test1\", \"test2\").map(Message::of)) .connector(jmsConnector) .build() .start(); Prepare JMS connector, can be used by any channel Don&#8217;t forget to check out the examples with pre-configured ActiveMQ docker image, for easy testing: https://github.com/oracle/helidon/tree/master/examples/messaging AQ Connector <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.messaging.aq&lt;/groupId&gt; &lt;artifactId&gt;helidon-messaging-aq&lt;/artifactId&gt; &lt;/dependency&gt; Reactive Oracle AQ Connector Sending and Receiving <markup lang=\"java\" title=\"Example of producing to and consuming from Oracle AQ:\" >PoolDataSource pds = PoolDataSourceFactory.getPoolDataSource(); pds.setConnectionFactoryClassName(\"oracle.jdbc.pool.OracleDataSource\"); pds.setURL(\"jdbc:oracle:thin:@(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(Host=192.168.0.123)(Port=1521))(CONNECT_DATA=(SID=XE)))\"); pds.setUser(\"frank\"); pds.setPassword(\"frank\"); AqConnector seConn = AqConnector.builder() .dataSource(\"test-ds\", pds) .build(); Channel&lt;String&gt; toAq = Channel.&lt;String&gt;builder() .name(\"toAq\") .subscriberConfig(AqConnector.configBuilder() .queue(\"example_queue_1\") .dataSource(\"test-ds\") .build()) .build(); Channel&lt;String&gt; fromAq = Channel.&lt;String&gt;builder() .name(\"fromAq\") .publisherConfig(AqConnector.configBuilder() .queue(\"example_queue_1\") .dataSource(\"test-ds\") .build()) .build(); Messaging.builder() .connector(seConn) .publisher(toAq, Multi.just(\"Hello\", \"world\", \"from\", \"Oracle\", \"DB!\").map(Message::of)) .listener(fromAq, s -&gt; System.out.pritln(\"Message received: \"+s)) .build() .start(); Prepare Oracle UCP Setup AQ connector and provide datasource with an identifier test-ds Setup channel for sending messages to queue example_queue_1 with datasource test-ds Setup channel for receiving messages from queue example_queue_1 with datasource test-ds Register connector and channels Add a publisher for several test messages to publish them to example_queue_1 immediately Subscribe callback for any message coming from example_queue_1 ",
            "title": "Connectors"
        },
        {
            "location": "se/reactive-messaging",
            "text": " Connecting your streams to external services usually requires a lot of boiler-plate code for configuration handling, backpressure propagation, acknowledgement and more. In Helidon there is a system of connectors, emitters and means to orchestrate these tasks called Reactive Messaging . It&#8217;s basically an API for connecting and configuring connectors and emitters with your reactive streams through Channels . Reactive Messaging relates to MicroProfile Reactive Messaging as the making of connectors and configuring them can be a repetitive task that ultimately leads to the same results. Helidon SE Reactive Messaging supports the very same configuration format for connectors as its MicroProfile counterpart does. Also, MP Connectors are reusable in Helidon SE Messaging with some limitations such as there is no CDI in Helidon SE. All Messaging connectors in Helidon are made to be universally usable by Helidon MP and SE. Channel A channel is a named pair of Publisher and Subscriber . Channels can be connected together by processors . Registering a Publisher or Subscriber for a channel can be done by Messaging API, or configured implicitly using registered connectors to generate the Publisher or Subscriber . <markup lang=\"java\" title=\"Example of simple channel:\" >Channel&lt;String&gt; channel1 = Channel.create(\"channel1\"); Messaging.builder() .publisher(channel1, Multi.just(\"message 1\", \"message 2\") .map(Message::of)) .listener(channel1, s -&gt; System.out.println(\"Intecepted message \" + s)) .build() .start(); Processor Processor is a typical reactive processor acting as a Subscriber to upstream and as a Publisher to downstream. In terms of reactive messaging, it is able to connect two channels to one reactive stream. <markup lang=\"java\" title=\"Example of processor usage:\" >Channel&lt;String&gt; firstChannel = Channel.create(\"first-channel\"); Channel&lt;String&gt; secondChannel = Channel.create(\"second-channel\"); Messaging.builder() .publisher(secondChannel, ReactiveStreams.of(\"test1\", \"test2\", \"test3\") .map(Message::of)) .processor(secondChannel, firstChannel, ReactiveStreams.&lt;Message&lt;String&gt;&gt;builder() .map(Message::getPayload) .map(String::toUpperCase) .map(Message::of) ) .subscriber(firstChannel, ReactiveStreams.&lt;Message&lt;String&gt;&gt;builder() .peek(Message::ack) .map(Message::getPayload) .forEach(s -&gt; System.out.println(\"Consuming message \" + s))) .build() .start(); &gt;Consuming message TEST1 &gt;Consuming message TEST2 &gt;Consuming message TEST3 Message Reactive Messaging in Helidon SE uses the same concept of message wrapping as MicroProfile messaging. The only notable difference is that SE Messaging does almost no implicit or automatic acknowledgement due to no magic philosophy of Helidon SE. The only exception to this are the variants of the methods Messaging.Builder#listener and Messaging.Builder#processor configured with consumer or function parameters which will conveniently unwrap the payload for you. Once the payload is automatically unwrapped, it is not possible to do a manual acknowledgement, therefore an implicit acknowledgement is executed before the callback. Connectors Connectors are used to connect channels to external sources. To make the creation and usage of connectors as easy and versatile as possible, Helidon SE Messaging uses the same API for connectors that MicroProfile Reactive Messaging does. This allows connectors to be used in both flavors of Helidon with one limitation which is that the connector has to be able to work without CDI. Examples of versatile connectors in Helidon include the following: Kafka connector JMS connector AQ Connector Messaging Connector A connector for Reactive Messaging is a factory that produces Publishers and Subscribers for Channels in Reactive Messaging. Messaging connector is just an implementation of IncomingConnectorFactory , OutgoingConnectorFactory or both. <markup lang=\"java\" title=\"Example connector example-connector :\" >@Connector(\"example-connector\") public class ExampleConnector implements IncomingConnectorFactory, OutgoingConnectorFactory { @Override public PublisherBuilder&lt;? extends Message&lt;?&gt;&gt; getPublisherBuilder(Config config) { return ReactiveStreams.of(\"foo\", \"bar\") .map(Message::of); } @Override public SubscriberBuilder&lt;? extends Message&lt;?&gt;, Void&gt; getSubscriberBuilder(Config config) { return ReactiveStreams.&lt;Message&lt;?&gt;&gt;builder() .map(Message::getPayload) .forEach(o -&gt; System.out.println(\"Connector says: \" + o)); } } <markup lang=\"yaml\" title=\"Example of channel to connector mapping config:\" >mp.messaging.outgoing.to-connector-channel.connector: example-connector mp.messaging.incoming.from-connector-channel.connector: example-connector <markup lang=\"java\" title=\"Example producing to connector:\" >Config config = Config.create(); Messaging.builder() .config(config) .connector(new ExampleConnector()) .publisher(Channel.create(\"to-connector-channel\"), ReactiveStreams.of(\"fee\", \"fie\") .map(Message::of) ) .build() .start(); &gt; Connector says: fee &gt; Connector says: fie <markup lang=\"java\" title=\"Example consuming from connector:\" >Messaging.builder() .connector(new ExampleConnector()) .subscriber(Channel.create(\"from-connector-channel\"), ReactiveStreams.&lt;Message&lt;String&gt;&gt;builder() .peek(Message::ack) .map(Message::getPayload) .forEach(s -&gt; System.out.println(\"Consuming: \" + s)) ) .build() .start(); &gt; Consuming: foo &gt; Consuming: bar Configuration for Messaging Connector A messaging connector in Helidon SE can be configured explicitly by API or implicitly by config following the notation of MicroProfile Reactive Messaging . Configuration that is supplied to connector by the Messaging implementation must include two mandatory attributes: channel-name which is the name of the channel that has the connector configured as Publisher or Subscriber, or Channel.create('name-of-channel') in case of explicit configuration or mp.messaging.incoming.name-of-channel.connector: connector-name in case of implicit config connector name of the connector @Connector(\"connector-name\") <markup lang=\"java\" title=\"Example connector accessing configuration:\" >@Connector(\"example-connector\") public class ExampleConnector implements IncomingConnectorFactory { @Override public PublisherBuilder&lt;? extends Message&lt;?&gt;&gt; getPublisherBuilder(final Config config) { String firstPropValue = config.getValue(\"first-test-prop\", String.class); String secondPropValue = config.getValue(\"second-test-prop\", String.class); return ReactiveStreams.of(firstPropValue, secondPropValue) .map(Message::of); } } Config context is merged from channel and connector contexts Explicit Config for Messaging Connector An explicit config for channel&#8217;s publisher is possible with Channel.Builder#publisherConfig(Config config) and for a subscriber with the Channel.Builder#subscriberConfig(Config config) . The supplied Helidon Config is merged with the mandatory attributes and any implicit configuration found. The resulting configuration is then served to the Connector. <markup lang=\"java\" title=\"Example consuming from Kafka connector with explicit config:\" >String kafkaServer = config.get(\"app.kafka.bootstrap.servers\").asString().get(); String topic = config.get(\"app.kafka.topic\").asString().get(); Channel&lt;String&gt; fromKafka = Channel.&lt;String&gt;builder() .name(\"from-kafka\") .publisherConfig(KafkaConnector.configBuilder() .bootstrapServers(kafkaServer) .groupId(\"example-group-\" + session.getId()) .topic(topic) .autoOffsetReset(KafkaConfigBuilder.AutoOffsetReset.LATEST) .enableAutoCommit(true) .keyDeserializer(StringDeserializer.class) .valueDeserializer(StringDeserializer.class) .build() ) .build(); KafkaConnector kafkaConnector = KafkaConnector.create(); Messaging messaging = Messaging.builder() .connector(kafkaConnector) .listener(fromKafka, payload -&gt; { System.out.println(\"Kafka says: \" + payload); }) .build() .start(); Prepare channel for connecting kafka connector with specific publisher configuration &#8594; listener, Channel &#8594; connector mapping is automatic when using KafkaConnector.configBuilder() Prepare Kafka connector, can be used by any channel Implicit Config for Messaging Connector Implicit config without any hard-coding is possible with Helidon Config following notation of MicroProfile Reactive Messaging . <markup lang=\"yaml\" title=\"Example of channel to connector mapping config with custom properties:\" >mp.messaging.incoming.from-connector-channel.connector: example-connector mp.messaging.incoming.from-connector-channel.first-test-prop: foo mp.messaging.connector.example-connector.second-test-prop: bar Channel &#8594; Connector mapping Channel configuration properties Connector configuration properties <markup lang=\"java\" title=\"Example consuming from connector:\" >Config config = Config.create(); Messaging.builder() .config(config) .connector(new ExampleConnector()) .listener(Channel.create(\"from-connector-channel\"), s -&gt; System.out.println(\"Consuming: \" + s)) .build() .start(); &gt; Consuming: foo &gt; Consuming: bar Reusability in MP Messaging As the API is the same for MicroProfile Reactive Messaging connectors, all that is needed to make connector work in both ways is annotating it with @ApplicationScoped . Such connector is treated as a bean in Helidon MP. For specific information about creating messaging connectors for Helidon MP visit MicroProfile Reactive Messaging . Kafka Connector <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.messaging.kafka&lt;/groupId&gt; &lt;artifactId&gt;helidon-messaging-kafka&lt;/artifactId&gt; &lt;/dependency&gt; Reactive Kafka Connector Connecting streams to Kafka with Reactive Messaging couldn&#8217;t be easier. Explicit Config with Config Builder for Kafka Connector <markup lang=\"java\" title=\"Example of consuming from Kafka:\" >String kafkaServer = config.get(\"app.kafka.bootstrap.servers\").asString().get(); String topic = config.get(\"app.kafka.topic\").asString().get(); Channel&lt;String&gt; fromKafka = Channel.&lt;String&gt;builder() .name(\"from-kafka\") .publisherConfig(KafkaConnector.configBuilder() .bootstrapServers(kafkaServer) .groupId(\"example-group-\" + session.getId()) .topic(topic) .autoOffsetReset(KafkaConfigBuilder.AutoOffsetReset.LATEST) .enableAutoCommit(true) .keyDeserializer(StringDeserializer.class) .valueDeserializer(StringDeserializer.class) .build() ) .build(); KafkaConnector kafkaConnector = KafkaConnector.create(); Messaging messaging = Messaging.builder() .connector(kafkaConnector) .listener(fromKafka, payload -&gt; { System.out.println(\"Kafka says: \" + payload); }) .build() .start(); Prepare a channel for connecting kafka connector with specific publisher configuration &#8594; listener Channel &#8594; connector mapping is automatic when using KafkaConnector.configBuilder() Prepare Kafka connector, can be used by any channel <markup lang=\"java\" title=\"Example of producing to Kafka:\" >String kafkaServer = config.get(\"app.kafka.bootstrap.servers\").asString().get(); String topic = config.get(\"app.kafka.topic\").asString().get(); Channel&lt;String&gt; toKafka = Channel.&lt;String&gt;builder() .subscriberConfig(KafkaConnector.configBuilder() .bootstrapServers(kafkaServer) .topic(topic) .keySerializer(StringSerializer.class) .valueSerializer(StringSerializer.class) .build() ).build(); KafkaConnector kafkaConnector = KafkaConnector.create(); messaging = Messaging.builder() .publisher(toKafka, Multi.just(\"test1\", \"test2\").map(Message::of)) .connector(kafkaConnector) .build() .start(); Prepare a channel for connecting kafka connector with specific publisher configuration &#8594; listener Channel &#8594; connector mapping is automatic when using KafkaConnector.configBuilder() Prepare Kafka connector, can be used by any channel Implicit Helidon Config for Kafka Connector <markup lang=\"yaml\" title=\"Example of connector config:\" >mp.messaging: incoming.from-kafka: connector: helidon-kafka topic: messaging-test-topic-1 auto.offset.reset: latest enable.auto.commit: true group.id: example-group-id outgoing.to-kafka: connector: helidon-kafka topic: messaging-test-topic-1 connector: helidon-kafka: bootstrap.servers: localhost:9092 key.serializer: org.apache.kafka.common.serialization.StringSerializer value.serializer: org.apache.kafka.common.serialization.StringSerializer key.deserializer: org.apache.kafka.common.serialization.StringDeserializer value.deserializer: org.apache.kafka.common.serialization.StringDeserializer Kafka client consumer&#8217;s property auto.offset.reset configuration for from-kafka channel only Kafka client&#8217;s property bootstrap.servers configuration for all channels using the connector <markup lang=\"java\" title=\"Example of consuming from Kafka:\" >Config config = Config.create(); Channel&lt;String&gt; fromKafka = Channel.create(\"from-kafka\"); KafkaConnector kafkaConnector = KafkaConnector.create(); Messaging messaging = Messaging.builder() .config(config) .connector(kafkaConnector) .listener(fromKafka, payload -&gt; { System.out.println(\"Kafka says: \" + payload); }) .build() .start(); Prepare Kafka connector, can be used by any channel <markup lang=\"java\" title=\"Example of producing to Kafka:\" >Config config = Config.create(); Channel&lt;String&gt; toKafka = Channel.create(\"to-kafka\"); KafkaConnector kafkaConnector = KafkaConnector.create(); messaging = Messaging.builder() .config(config) .publisher(toKafka, Multi.just(\"test1\", \"test2\").map(Message::of)) .connector(kafkaConnector) .build() .start(); Prepare Kafka connector, can be used by any channel Don&#8217;t forget to check out the examples with pre-configured Kafka docker image, for easy testing: https://github.com/oracle/helidon/tree/master/examples/messaging JMS Connector <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.messaging.jms&lt;/groupId&gt; &lt;artifactId&gt;helidon-messaging-jms&lt;/artifactId&gt; &lt;/dependency&gt; Reactive JMS Connector Connecting streams to JMS with Reactive Messaging couldn&#8217;t be easier. Explicit Config with Config Builder for JMS Connector <markup lang=\"java\" title=\"Example of consuming from JMS:\" >Channel&lt;String&gt; fromJms = Channel.&lt;String&gt;builder() .name(\"from-jms\") .publisherConfig(JmsConnector.configBuilder() .jndiInitialFactory(ActiveMQInitialContextFactory.class) .jndiProviderUrl(\"tcp://127.0.0.1:61616\") .type(JmsConfigBuilder.Type.QUEUE) .destination(\"se-example-queue-1\") .build() ) .build(); JmsConnector jmsConnector = JmsConnector.create(); Messaging messaging = Messaging.builder() .connector(jmsConnector) .listener(fromJms, payload -&gt; { System.out.println(\"Jms says: \" + payload); }) .build() .start(); Prepare a channel for connecting jms connector with specific publisher configuration &#8594; listener Channel &#8594; connector mapping is automatic when using JmsConnector.configBuilder() Prepare JMS connector, can be used by any channel <markup lang=\"java\" title=\"Example of producing to JMS:\" >Channel&lt;String&gt; toJms = Channel.&lt;String&gt;builder() .subscriberConfig(JmsConnector.configBuilder() .jndiInitialFactory(ActiveMQInitialContextFactory.class) .jndiProviderUrl(\"tcp://127.0.0.1:61616\") .type(JmsConfigBuilder.Type.QUEUE) .destination(\"se-example-queue-1\") .build() ).build(); JmsConnector jmsConnector = JmsConnector.create(); messaging = Messaging.builder() .publisher(toJms, Multi.just(\"test1\", \"test2\").map(Message::of)) .connector(jmsConnector) .build() .start(); Prepare a channel for connecting jms connector with specific publisher configuration &#8594; listener Channel &#8594; connector mapping is automatic when using JmsConnector.configBuilder() Prepare JMS connector, can be used by any channel Implicit Helidon Config for JMS Connector <markup lang=\"yaml\" title=\"Example of connector config:\" >mp.messaging: incoming.from-jms: connector: helidon-jms destination: se-example-queue-1 session-group-id: session-group-1 type: queue outgoing.to-jms: connector: helidon-jms destination: se-example-queue-1 type: queue connector: helidon-jms: jndi: jms-factory: ConnectionFactory env-properties: java.naming.factory.initial: org.apache.activemq.jndi.ActiveMQInitialContextFactory java.naming.provider.url: tcp://127.0.0.1:61616 <markup lang=\"java\" title=\"Example of consuming from JMS:\" >Config config = Config.create(); Channel&lt;String&gt; fromJms = Channel.create(\"from-jms\"); JmsConnector jmsConnector = JmsConnector.create(); Messaging messaging = Messaging.builder() .config(config) .connector(jmsConnector) .listener(fromJms, payload -&gt; { System.out.println(\"Jms says: \" + payload); }) .build() .start(); Prepare JMS connector, can be used by any channel <markup lang=\"java\" title=\"Example of producing to JMS:\" >Config config = Config.create(); Channel&lt;String&gt; toJms = Channel.create(\"to-jms\"); JmsConnector jmsConnector = JmsConnector.create(); messaging = Messaging.builder() .config(config) .publisher(toJms, Multi.just(\"test1\", \"test2\").map(Message::of)) .connector(jmsConnector) .build() .start(); Prepare JMS connector, can be used by any channel Don&#8217;t forget to check out the examples with pre-configured ActiveMQ docker image, for easy testing: https://github.com/oracle/helidon/tree/master/examples/messaging AQ Connector <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.messaging.aq&lt;/groupId&gt; &lt;artifactId&gt;helidon-messaging-aq&lt;/artifactId&gt; &lt;/dependency&gt; Reactive Oracle AQ Connector Sending and Receiving <markup lang=\"java\" title=\"Example of producing to and consuming from Oracle AQ:\" >PoolDataSource pds = PoolDataSourceFactory.getPoolDataSource(); pds.setConnectionFactoryClassName(\"oracle.jdbc.pool.OracleDataSource\"); pds.setURL(\"jdbc:oracle:thin:@(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(Host=192.168.0.123)(Port=1521))(CONNECT_DATA=(SID=XE)))\"); pds.setUser(\"frank\"); pds.setPassword(\"frank\"); AqConnector seConn = AqConnector.builder() .dataSource(\"test-ds\", pds) .build(); Channel&lt;String&gt; toAq = Channel.&lt;String&gt;builder() .name(\"toAq\") .subscriberConfig(AqConnector.configBuilder() .queue(\"example_queue_1\") .dataSource(\"test-ds\") .build()) .build(); Channel&lt;String&gt; fromAq = Channel.&lt;String&gt;builder() .name(\"fromAq\") .publisherConfig(AqConnector.configBuilder() .queue(\"example_queue_1\") .dataSource(\"test-ds\") .build()) .build(); Messaging.builder() .connector(seConn) .publisher(toAq, Multi.just(\"Hello\", \"world\", \"from\", \"Oracle\", \"DB!\").map(Message::of)) .listener(fromAq, s -&gt; System.out.pritln(\"Message received: \"+s)) .build() .start(); Prepare Oracle UCP Setup AQ connector and provide datasource with an identifier test-ds Setup channel for sending messages to queue example_queue_1 with datasource test-ds Setup channel for receiving messages from queue example_queue_1 with datasource test-ds Register connector and channels Add a publisher for several test messages to publish them to example_queue_1 immediately Subscribe callback for any message coming from example_queue_1 ",
            "title": "Usage"
        },
        {
            "location": "se/reactive-messaging",
            "text": " Configuration for Messaging Connector Explicit Configuration with Config Builder for Kafka Connector Implicit Helidon Configuration for Kafka Connector Explicit Configuration with Config Builder for JMS Connector Implicit Helidon Configuration for JMS Connector ",
            "title": "Configuration"
        },
        {
            "location": "se/reactive-messaging",
            "text": " MicroProfile Reactive Messaging Specification MicroProfile Reactive Messaging on GitHub Helidon Messaging Examples ",
            "title": "Reference"
        },
        {
            "location": "se/reactivestreams/engine",
            "text": " Overview Maven Coordinates Usage ",
            "title": "Contents"
        },
        {
            "location": "se/reactivestreams/engine",
            "text": " Helidon has its own set of reactive operators that have no dependencies outside of the Helidon ecosystem. These operators can be used with java.util.concurrent.Flow based reactive streams. ",
            "title": "Overview"
        },
        {
            "location": "se/reactivestreams/engine",
            "text": " To enable Reactive Engine add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.common&lt;/groupId&gt; &lt;artifactId&gt;helidon-common-reactive&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "se/reactivestreams/engine",
            "text": " In the situations when part of the operator chain needs to be prepared in advance, compose and to operators are at hand. <markup lang=\"java\" title=\"Combining operator chains:\" >// Assembly of stream, nothing is streamed yet Multi&lt;String&gt; publisherStage = Multi.just(\"foo\", \"bar\") .map(String::trim); Function&lt;Multi&lt;T&gt;, Multi&lt;T&gt;&gt; processorStage = upstream -&gt; upstream.map(String::toUpperCase); // Execution of pre-prepared stream publisherStage .compose(processorStage) .map(s -&gt; \"Item received: \" + s) .forEach(System.out::println); &gt; Item received: FOO &gt; Item received: BAR ",
            "title": "Operator Chains Composition"
        },
        {
            "location": "se/reactivestreams/engine",
            "text": " The stream processing operator chain can be easily constructed by io.helidon.common.reactive.Multi , or io.helidon.common.reactive.Single for streams with single value. <markup lang=\"java\" title=\"Example of Multi usage:\" >AtomicInteger sum = new AtomicInteger(); Multi.just(\"1\", \"2\", \"3\", \"4\", \"5\") .limit(3) .map(Integer::parseInt) .forEach(sum::addAndGet); System.out.println(\"Sum: \" + sum.get()); &gt; Sum: 6 <markup lang=\"java\" title=\"Example of Single usage:\" >Single.just(\"1\") .map(Integer::parseInt) .map(i -&gt; i + 5) .toStage() .whenComplete((i, t) -&gt; System.out.println(\"Result: \" + i)); &gt; Result: 6 Operators defer Call the given supplier function for each individual downstream Subscriber to return a Flow.Publisher to subscribe to. map Map this Multi instance to a new Multi of another type using the given Mapper . defaultIfEmpty Signals the default item if the upstream is empty. switchIfEmpty Switch to the other publisher if the upstream is empty. peek Invoke provided consumer for every item in stream. distinct Filter out all duplicates. filter Filter stream items with provided predicate. takeWhile Take the longest prefix of elements from this stream that satisfy the given predicate. As long as predicate returns true, items from upstream are sent to downstream, when predicate returns false stream is completed. dropWhile Drop the longest prefix of elements from this stream that satisfy the given predicate. As long as predicate returns true, items from upstream are NOT sent to downstream but being dropped, predicate is never called again after it returns false for the first time. limit Limit stream to allow only specified number of items to pass. skip Skip first n items, all the others are emitted. flatMap Transform each upstream item with the supplied function into a Flow.Publisher , subscribe to them and then flatten their items into a single sequence of items emitted to the downstream. flatMap Transform each upstream item with the supplied function and flatten the resulting Flow.Publisher to downstream while limiting the maximum number of concurrent inner `Flow.Publisher`s and their in-flight item count, optionally aggregating and delaying all errors until all sources terminate. flatMapCompletionStage Transform each upstream item with the supplied function and flatten the resulting CompletionStage results to downstream. flatMapIterable Transform each upstream item with the supplied function and flatten the resulting Iterable to the downstream. flatMapOptional Transform each upstream item with the supplied function and flatten the resulting Optional to the downstream as item if present. observeOn Re-emit the upstream&#8217;s signals to the downstream on the given executor&#8217;s thread using a default buffer size of 32 and errors skipping ahead of items. observeOn Re-emit the upstream&#8217;s signals to the downstream on the given executor&#8217;s thread. forEach Terminal stage, invokes provided consumer for every item in the stream. collectList Collect the items of this Multi instance into a Single of List . collect Collect the items of this Multi instance into a Single . collect Collect the items of this Multi into a collection provided via a Supplier and mutated by a BiConsumer callback. collectStream Collects up upstream items with the help of the callbacks of a java.util.stream.Collector . reduce Combine subsequent items via a callback function and emit the final value result as a Single. reduce Combine every upstream item with an accumulator value to produce a new accumulator value and emit the final accumulator value as a Single. first Get the first item of this Multi instance as a Single . from Wrap a CompletionStage into a Multi and signal its outcome non-blockingly. from Wrap a CompletionStage into a Multi and signal its outcome non-blockingly. from Create a Multi instance wrapped around the given publisher. from Create a Multi instance that publishes the given iterable. from Create a Multi instance that publishes the given Stream . just Create a Multi instance that publishes the given items to a single subscriber. just Create a Multi instance that publishes the given items to a single subscriber. singleton Create a Multi that emits a pre-existing item and then completes. error Create a Multi instance that reports the given exception to its subscriber(s). The exception is reported by invoking Subscriber#onError(java.lang.Throwable) when Publisher#subscribe(Subscriber) is called. empty Get a Multi instance that completes immediately. never Get a Multi instance that never completes. concat Concat streams to one. onTerminate Executes given java.lang.Runnable when any of signals onComplete, onCancel or onError is received. ifEmpty Executes given java.lang.Runnable when stream is finished without value(empty stream). onComplete Executes given java.lang.Runnable when onComplete signal is received. onError Executes the given java.util.function.Consumer when an onError signal is received. onCancel Executes given java.lang.Runnable when a cancel signal is received. takeUntil Relay upstream items until the other source signals an item or completes. range Emits a range of ever increasing integers. rangeLong Emits a range of ever increasing longs. timer Signal 0L and complete the sequence after the given time elapsed. interval Signal 0L, 1L and so on periodically to the downstream. interval Signal 0L after an initial delay, then 1L, 2L and so on periodically to the downstream. timeout Signals a TimeoutException if the upstream doesn&#8217;t signal the next item, error or completion within the specified time. timeout Switches to a fallback source if the upstream doesn&#8217;t signal the next item, error or completion within the specified time. onErrorResume java.util.function.Function providing one item to be submitted as onNext in case of onError signal is received. onErrorResumeWith Resume stream from supplied publisher if onError signal is intercepted. retry Retry a failing upstream at most the given number of times before giving up. retry Retry a failing upstream if the predicate returns true. retryWhen Retry a failing upstream when the given function returns a publisher that signals an item. Operator Chains Composition In the situations when part of the operator chain needs to be prepared in advance, compose and to operators are at hand. <markup lang=\"java\" title=\"Combining operator chains:\" >// Assembly of stream, nothing is streamed yet Multi&lt;String&gt; publisherStage = Multi.just(\"foo\", \"bar\") .map(String::trim); Function&lt;Multi&lt;T&gt;, Multi&lt;T&gt;&gt; processorStage = upstream -&gt; upstream.map(String::toUpperCase); // Execution of pre-prepared stream publisherStage .compose(processorStage) .map(s -&gt; \"Item received: \" + s) .forEach(System.out::println); &gt; Item received: FOO &gt; Item received: BAR ",
            "title": "Usage"
        },
        {
            "location": "se/reactivestreams/rsoperators",
            "text": " Overview Maven Coordinates Usage Reference ",
            "title": "Contents"
        },
        {
            "location": "se/reactivestreams/rsoperators",
            "text": " Helidon implements MicroProfile Reactive Streams Operators specification which defines reactive operators and provides a standartized tool for manipulation with Reactive Streams . You can use the Helidon supported reactive operators and tooling when you want to maintain source-level portability between different implementations of the MicroProfile specifications. ",
            "title": "Overview"
        },
        {
            "location": "se/reactivestreams/rsoperators",
            "text": " To enable Reactive Streams add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.microprofile.reactive-streams&lt;/groupId&gt; &lt;artifactId&gt;helidon-microprofile-reactive-streams&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "se/reactivestreams/rsoperators",
            "text": " Graphs are pre-prepared stream builders with stages , which can be combined together to close graph with methods via and to . <markup lang=\"java\" title=\"Combining the graphs and running the stream:\" >// Assembly of stream, nothing is streamed yet PublisherBuilder&lt;String&gt; publisherStage = ReactiveStreams.of(\"foo\", \"bar\") .map(String::trim); ProcessorBuilder&lt;String, String&gt; processorStage = ReactiveStreams.&lt;String&gt;builder() .map(String::toUpperCase); SubscriberBuilder&lt;String, Void&gt; subscriberStage = ReactiveStreams.&lt;String&gt;builder() .map(s -&gt; \"Item received: \" + s) .forEach(System.out::println); // Execution of pre-prepared stream publisherStage .via(processorStage) .to(subscriberStage).run(); &gt; Item received: FOO &gt; Item received: BAR ",
            "title": "Graphs"
        },
        {
            "location": "se/reactivestreams/rsoperators",
            "text": " The MicroProfile Reactive Streams Operators specification provides a set of operators within stages, as well as the builders used to prepare graphs of stages from which streams can be built. <markup lang=\"java\" title=\"Example of simple closed graph usage:\" >AtomicInteger sum = new AtomicInteger(); ReactiveStreams.of(\"1\", \"2\", \"3\", \"4\", \"5\") .limit(3) .map(Integer::parseInt) .forEach(sum::addAndGet) .run() .whenComplete((r, t) -&gt; System.out.println(\"Sum: \" + sum.get())); &gt; Sum: 6 Operators(Stages) fromIterable Create new PublisherBuilder from supplied Iterable of Create new PublisherBuilder emitting supplied elements ofNullable Empty stream if supplied item is null iterate Create infinite stream with every next item created by supplied operator from previous item generate Create infinite stream with every item created by invocation of supplier empty Create new PublisherBuilder emitting as a first thing complete signal failed Create new PublisherBuilder emitting as a first thing error signal concat Concat two streams coupled Two parallel streams sharing cancel, onError and onComplete signals limit Limit the size of the stream, when limit is reached completes peek Invoke consumer for every item passing this operator filter Drop item when expression result to false map Transform items flatMap Flatten supplied stream to current stream flatMapIterable Flatten supplied iterable to current stream flatMapCompletionStage Map elements to completion stage and wait for each to be completed, keeps the order flatMapRSPublisher Map elements to Publishers and flatten this sub streams to original stream takeWhile Let items pass until expression is true, first time its false completes dropWhile Drop items until expression is true, first time its false let everything pass skip Drop first n items distinct Let pass only distinct items via Connect supplied processor to current stream return supplied processor onError Invoke supplied consumer when onError signal received onErrorResume Emit one last supplied item when onError signal received onErrorResumeWith When onError signal received continue emitting from supplied publisher builder onErrorResumeWithRsPublisher When onError signal received continue emitting from supplied publisher onComplete Invoke supplied runnable when onComplete signal received onTerminate Invoke supplied runnable when onComplete or onError signal received ifEmpty Executes given java.lang.Runnable when stream is finished without value(empty stream). to Connect this stream to supplied subscriber toList Collect all intercepted items to List collect Collect all intercepted items with provided collector forEach Invoke supplied Consumer for each intercepted item ignore Ignore all onNext signals, wait for onComplete reduce Reduction with provided expression cancel Cancel stream immediately findFirst Return first intercepted element Graphs Graphs are pre-prepared stream builders with stages , which can be combined together to close graph with methods via and to . <markup lang=\"java\" title=\"Combining the graphs and running the stream:\" >// Assembly of stream, nothing is streamed yet PublisherBuilder&lt;String&gt; publisherStage = ReactiveStreams.of(\"foo\", \"bar\") .map(String::trim); ProcessorBuilder&lt;String, String&gt; processorStage = ReactiveStreams.&lt;String&gt;builder() .map(String::toUpperCase); SubscriberBuilder&lt;String, Void&gt; subscriberStage = ReactiveStreams.&lt;String&gt;builder() .map(s -&gt; \"Item received: \" + s) .forEach(System.out::println); // Execution of pre-prepared stream publisherStage .via(processorStage) .to(subscriberStage).run(); &gt; Item received: FOO &gt; Item received: BAR ",
            "title": "Usage"
        },
        {
            "location": "se/reactivestreams/rsoperators",
            "text": " MicroProfile Reactive Streams Operators Specification MicroProfile Reactive Streams Operators JavaDoc MicroProfile Reactive Streams Operators on GitHub ",
            "title": "Reference"
        },
        {
            "location": "se/scheduling",
            "text": " Overview Maven Coordinates Usage Configuration Examples Reference ",
            "title": "Contents"
        },
        {
            "location": "se/scheduling",
            "text": " Scheduling is an essential feature for the Enterprise. Helidon has its own implementation of Scheduling functionality based on Cron-utils . ",
            "title": "Overview"
        },
        {
            "location": "se/scheduling",
            "text": " To enable Scheduling add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.scheduling&lt;/groupId&gt; &lt;artifactId&gt;helidon-scheduling&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "se/scheduling",
            "text": "<markup lang=\"java\" title=\"Scheduling with fixed rate use Scheduling.fixedRateBuilder() builder.\" >Scheduling.fixedRateBuilder() .delay(10) .initialDelay(5) .timeUnit(TimeUnit.MINUTES) .task(inv -&gt; System.out.println(\"Every 10 minutes, first invocation 5 minutes after start\")) .build(); Metadata like human-readable interval description or configured values are available through FixedRateInvocation provided as task parameter. <markup lang=\"java\" title=\"Invocation metadata\" >Scheduling.fixedRateBuilder() .delay(10) .task(inv -&gt; System.out.println(\"Method invoked \" + inv.description())) .build(); ",
            "title": "Fixed rate"
        },
        {
            "location": "se/scheduling",
            "text": " For more complicated interval definition, Cron expression can be leveraged with Scheduling.cronBuilder() builder. <markup lang=\"java\" title=\"Scheduling with Cron expression\" >Scheduling.cronBuilder() .expression(\"0 15 8 ? * *\") .task(inv -&gt; System.out.println(\"Executer every day at 8:15\")) .build(); ",
            "title": "Cron expression"
        },
        {
            "location": "se/scheduling",
            "text": " For scheduling periodic tasks, it is possible to choose a fixed rate or a Cron expression. Fixed rate <markup lang=\"java\" title=\"Scheduling with fixed rate use Scheduling.fixedRateBuilder() builder.\" >Scheduling.fixedRateBuilder() .delay(10) .initialDelay(5) .timeUnit(TimeUnit.MINUTES) .task(inv -&gt; System.out.println(\"Every 10 minutes, first invocation 5 minutes after start\")) .build(); Metadata like human-readable interval description or configured values are available through FixedRateInvocation provided as task parameter. <markup lang=\"java\" title=\"Invocation metadata\" >Scheduling.fixedRateBuilder() .delay(10) .task(inv -&gt; System.out.println(\"Method invoked \" + inv.description())) .build(); Cron expression For more complicated interval definition, Cron expression can be leveraged with Scheduling.cronBuilder() builder. <markup lang=\"java\" title=\"Scheduling with Cron expression\" >Scheduling.cronBuilder() .expression(\"0 15 8 ? * *\") .task(inv -&gt; System.out.println(\"Executer every day at 8:15\")) .build(); ",
            "title": "Usage"
        },
        {
            "location": "se/scheduling",
            "text": " Cron expressions should be configured as follows. ",
            "title": "Cron expression"
        },
        {
            "location": "se/scheduling",
            "text": "<markup title=\"Cron expression format\" >&lt;seconds&gt; &lt;minutes&gt; &lt;hours&gt; &lt;day-of-month&gt; &lt;month&gt; &lt;day-of-week&gt; &lt;year&gt; Cron expression fields Order Name Supported values Supported field format Optional 1 seconds 0-59 CONST, LIST, RANGE, WILDCARD, INCREMENT false 2 minutes 0-59 CONST, LIST, RANGE, WILDCARD, INCREMENT false 3 hours 0-23 CONST, LIST, RANGE, WILDCARD, INCREMENT false 4 day-of-month 1-31 CONST, LIST, RANGE, WILDCARD, INCREMENT, ANY, LAST, WEEKDAY false 5 month 1-12 or JAN-DEC CONST, LIST, RANGE, WILDCARD, INCREMENT false 6 day-of-week 1-7 or SUN-SAT CONST, LIST, RANGE, WILDCARD, INCREMENT, ANY, NTH, LAST false 7 year 1970-2099 CONST, LIST, RANGE, WILDCARD, INCREMENT true Field formats Name Regex format Example Description CONST \\d+ 12 exact value LIST \\d+,\\d+(,\\d+)* 1,2,3,4 list of constants RANGE \\d+-\\d+ 15-30 range of values from-to WILDCARD \\* * all values withing the field INCREMENT \\d+\\/\\d+ 0/5 inital number / increments, 2/5 means 2,7,9,11,16,&#8230;&#8203; ANY \\? ? any day(apply only to day-of-week and day-of-month) NTH \\# 1#3 nth day of the month, 2#3 means third monday of the month LAST \\d*L(+\\d+|\\-\\d+)? 3L-3 last day of the month in day-of-month or last nth day in the day-of-week WEEKDAY \\# 1#3 nearest weekday of the nth day of month, 1W is the first monday of the week Examples Cron expression Description * * * * * ? Every second 0/2 * * * * ? * Every 2 seconds 0 45 9 ? * * Every day at 9:45 0 15 8 ? * MON-FRI Every workday at 8:15 Metadata like human-readable interval description or configured values are available through CronInvocation provided as task parameter. ",
            "title": "Cron expression"
        },
        {
            "location": "se/scheduling",
            "text": " Configuration properties are added to application.yaml file: Configuration properties Property Description cron String containing Cron setup concurrent Boolean, equivalent concurrentExecution property of @Scheduled . Default true . Cron expression Cron expressions should be configured as follows. Cron expression <markup title=\"Cron expression format\" >&lt;seconds&gt; &lt;minutes&gt; &lt;hours&gt; &lt;day-of-month&gt; &lt;month&gt; &lt;day-of-week&gt; &lt;year&gt; Cron expression fields Order Name Supported values Supported field format Optional 1 seconds 0-59 CONST, LIST, RANGE, WILDCARD, INCREMENT false 2 minutes 0-59 CONST, LIST, RANGE, WILDCARD, INCREMENT false 3 hours 0-23 CONST, LIST, RANGE, WILDCARD, INCREMENT false 4 day-of-month 1-31 CONST, LIST, RANGE, WILDCARD, INCREMENT, ANY, LAST, WEEKDAY false 5 month 1-12 or JAN-DEC CONST, LIST, RANGE, WILDCARD, INCREMENT false 6 day-of-week 1-7 or SUN-SAT CONST, LIST, RANGE, WILDCARD, INCREMENT, ANY, NTH, LAST false 7 year 1970-2099 CONST, LIST, RANGE, WILDCARD, INCREMENT true Field formats Name Regex format Example Description CONST \\d+ 12 exact value LIST \\d+,\\d+(,\\d+)* 1,2,3,4 list of constants RANGE \\d+-\\d+ 15-30 range of values from-to WILDCARD \\* * all values withing the field INCREMENT \\d+\\/\\d+ 0/5 inital number / increments, 2/5 means 2,7,9,11,16,&#8230;&#8203; ANY \\? ? any day(apply only to day-of-week and day-of-month) NTH \\# 1#3 nth day of the month, 2#3 means third monday of the month LAST \\d*L(+\\d+|\\-\\d+)? 3L-3 last day of the month in day-of-month or last nth day in the day-of-week WEEKDAY \\# 1#3 nearest weekday of the nth day of month, 1W is the first monday of the week Examples Cron expression Description * * * * * ? Every second 0/2 * * * * ? * Every 2 seconds 0 45 9 ? * * Every day at 9:45 0 15 8 ? * MON-FRI Every workday at 8:15 Metadata like human-readable interval description or configured values are available through CronInvocation provided as task parameter. ",
            "title": "Configuration"
        },
        {
            "location": "se/scheduling",
            "text": " For simple fixed rate invocation use . <markup lang=\"java\" title=\"Example of scheduling with fixed rate use Scheduling.fixedRateBuilder() builder.\" >Scheduling.fixedRateBuilder() .delay(10) .initialDelay(5) .timeUnit(TimeUnit.MINUTES) .task(inv -&gt; System.out.println(\"Every 10 minutes, first invocation 5 minutes after start\")) .build(); Metadata like human-readable interval description or configured values are available through FixedRateInvocation provided as task parameter. <markup lang=\"java\" title=\"Example with invocation metadata\" >Scheduling.fixedRateBuilder() .delay(10) .task(inv -&gt; System.out.println(\"Method invoked \" + inv.description())) .build(); ",
            "title": "Fixed rate"
        },
        {
            "location": "se/scheduling",
            "text": " Fixed rate For simple fixed rate invocation use . <markup lang=\"java\" title=\"Example of scheduling with fixed rate use Scheduling.fixedRateBuilder() builder.\" >Scheduling.fixedRateBuilder() .delay(10) .initialDelay(5) .timeUnit(TimeUnit.MINUTES) .task(inv -&gt; System.out.println(\"Every 10 minutes, first invocation 5 minutes after start\")) .build(); Metadata like human-readable interval description or configured values are available through FixedRateInvocation provided as task parameter. <markup lang=\"java\" title=\"Example with invocation metadata\" >Scheduling.fixedRateBuilder() .delay(10) .task(inv -&gt; System.out.println(\"Method invoked \" + inv.description())) .build(); ",
            "title": "Examples"
        },
        {
            "location": "se/scheduling",
            "text": " Cron-utils GitHub page Helidon Scheduling JavaDoc ",
            "title": "Reference"
        },
        {
            "location": "se/security/containers-integration",
            "text": " The following cloud security containers are integrated with Helidon Security: WebServer Jersey ",
            "title": "preambule"
        },
        {
            "location": "se/security/containers-integration",
            "text": " There are two steps to configure security with WebServer: Create a security instance and register it with the server. Protect server routes with optional security features. <markup lang=\"java\" title=\"Example using builders\" >// web server's Routing Routing.builder() // This is step 1 - register security instance with web server processing // security - instance of security either from config or from a builder // securityDefaults - default enforcement for each route that has a security definition .register(WebSecurity.create(security).securityDefaults(WebSecurity.authenticate())) // this is step 2 - protect a route // protect this route with authentication (from defaults) and role \"user\" .get(\"/service1\", WebSecurity.rolesAllowed(\"user\"), (req, res) -&gt; { processService1Request(req, res); }) .build(); <markup lang=\"java\" title=\"Example using configuration\" >Routing.builder() // helper method to load both security and web server security from configuration .register(WebSecurity.create(config)) // continue with web server route configuration .build(); <markup lang=\"yaml\" title=\"Example using configuration (YAML)\" ># This may change in the future - to align with web server configuration, once it is supported security.web-server: # Configuration of integration with web server defaults: authenticate: true paths: - path: \"/service1/[/{*}]\" methods: [\"get\"] roles-allowed: [\"user\"] ",
            "title": "Configure Security with WebServer"
        },
        {
            "location": "se/security/containers-integration",
            "text": " The configuration is usually placed under security.web-server (this can be customized in Helidon SE). The following example shows how to configure the application.yaml using customized setting: <markup lang=\"yaml\" title=\"application.yaml\" >security: providers: - abac: - provider-key: web-server: defaults: authenticate: true paths: - path: \"/metrics[/{*}]\" roles-allowed: \"admin\" - path: \"/health[/{*}]\" roles-allowed: \"monitor\" - path: \"/openapi[/{*}]\" abac: scopes: [\"openapi\"] - path: \"/static[/{*}]\" roles-allowed: [\"user\", \"monitor\"] Attribute based access control provider that checks roles and scopes The provider(s) used in your application, such as oidc Default configuration for all configured paths Protection of /metrics and all nested paths with admin role required Protection of /health and all nested paths with monitor role required Protection of /openapi and all nested paths with openapi scope required Protection of static content configured on /static path with either user or monitor role required If you need to use a properties file, such as microprofile-config.properties , you can convert the file by using index based numbers for arrays, such as: <markup lang=\"properties\" title=\"microprofile-config.properties\" >security.providers.0.abac= security.providers.1.provider-key.optional=false security.web-server.defaults.authenticate=true security.web-server.paths.0.path=/metrics[/{*}] security.web-server.paths.0.roles-allowed=admin security.web-server.paths.3.path=/static[/{*}] security.web-server.paths.3.roles-allowed=user,monitor ",
            "title": "Configuring Endpoint Protection"
        },
        {
            "location": "se/security/containers-integration",
            "text": " There are several endpoints provided by Helidon services, such as: Health endpoint ( /health ) Metrics endpoint ( /metrics ) OpenAPI endpoint ( /openapi ) Configured static content (can use any path configured) These endpoints are all implemented using Helidon reactive WebServer and as such can be protected only through Security integration with WebServer. The following section describes configuration of such protection using configuration files, in this case using a yaml file, as it provides a tree structure. Configuring Endpoint Protection The configuration is usually placed under security.web-server (this can be customized in Helidon SE). The following example shows how to configure the application.yaml using customized setting: <markup lang=\"yaml\" title=\"application.yaml\" >security: providers: - abac: - provider-key: web-server: defaults: authenticate: true paths: - path: \"/metrics[/{*}]\" roles-allowed: \"admin\" - path: \"/health[/{*}]\" roles-allowed: \"monitor\" - path: \"/openapi[/{*}]\" abac: scopes: [\"openapi\"] - path: \"/static[/{*}]\" roles-allowed: [\"user\", \"monitor\"] Attribute based access control provider that checks roles and scopes The provider(s) used in your application, such as oidc Default configuration for all configured paths Protection of /metrics and all nested paths with admin role required Protection of /health and all nested paths with monitor role required Protection of /openapi and all nested paths with openapi scope required Protection of static content configured on /static path with either user or monitor role required If you need to use a properties file, such as microprofile-config.properties , you can convert the file by using index based numbers for arrays, such as: <markup lang=\"properties\" title=\"microprofile-config.properties\" >security.providers.0.abac= security.providers.1.provider-key.optional=false security.web-server.defaults.authenticate=true security.web-server.paths.0.path=/metrics[/{*}] security.web-server.paths.0.roles-allowed=admin security.web-server.paths.3.path=/static[/{*}] security.web-server.paths.3.roles-allowed=user,monitor ",
            "title": "Protecting Helidon Endpoints"
        },
        {
            "location": "se/security/containers-integration",
            "text": " To integrate reactive web server , add the following dependency to your project&#8217;s pom.xml file: <markup lang=\"xml\" title=\"Maven Dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.integration&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-integration-webserver&lt;/artifactId&gt; &lt;/dependency&gt; Configure Security with WebServer There are two steps to configure security with WebServer: Create a security instance and register it with the server. Protect server routes with optional security features. <markup lang=\"java\" title=\"Example using builders\" >// web server's Routing Routing.builder() // This is step 1 - register security instance with web server processing // security - instance of security either from config or from a builder // securityDefaults - default enforcement for each route that has a security definition .register(WebSecurity.create(security).securityDefaults(WebSecurity.authenticate())) // this is step 2 - protect a route // protect this route with authentication (from defaults) and role \"user\" .get(\"/service1\", WebSecurity.rolesAllowed(\"user\"), (req, res) -&gt; { processService1Request(req, res); }) .build(); <markup lang=\"java\" title=\"Example using configuration\" >Routing.builder() // helper method to load both security and web server security from configuration .register(WebSecurity.create(config)) // continue with web server route configuration .build(); <markup lang=\"yaml\" title=\"Example using configuration (YAML)\" ># This may change in the future - to align with web server configuration, once it is supported security.web-server: # Configuration of integration with web server defaults: authenticate: true paths: - path: \"/service1/[/{*}]\" methods: [\"get\"] roles-allowed: [\"user\"] Protecting Helidon Endpoints There are several endpoints provided by Helidon services, such as: Health endpoint ( /health ) Metrics endpoint ( /metrics ) OpenAPI endpoint ( /openapi ) Configured static content (can use any path configured) These endpoints are all implemented using Helidon reactive WebServer and as such can be protected only through Security integration with WebServer. The following section describes configuration of such protection using configuration files, in this case using a yaml file, as it provides a tree structure. Configuring Endpoint Protection The configuration is usually placed under security.web-server (this can be customized in Helidon SE). The following example shows how to configure the application.yaml using customized setting: <markup lang=\"yaml\" title=\"application.yaml\" >security: providers: - abac: - provider-key: web-server: defaults: authenticate: true paths: - path: \"/metrics[/{*}]\" roles-allowed: \"admin\" - path: \"/health[/{*}]\" roles-allowed: \"monitor\" - path: \"/openapi[/{*}]\" abac: scopes: [\"openapi\"] - path: \"/static[/{*}]\" roles-allowed: [\"user\", \"monitor\"] Attribute based access control provider that checks roles and scopes The provider(s) used in your application, such as oidc Default configuration for all configured paths Protection of /metrics and all nested paths with admin role required Protection of /health and all nested paths with monitor role required Protection of /openapi and all nested paths with openapi scope required Protection of static content configured on /static path with either user or monitor role required If you need to use a properties file, such as microprofile-config.properties , you can convert the file by using index based numbers for arrays, such as: <markup lang=\"properties\" title=\"microprofile-config.properties\" >security.providers.0.abac= security.providers.1.provider-key.optional=false security.web-server.defaults.authenticate=true security.web-server.paths.0.path=/metrics[/{*}] security.web-server.paths.0.roles-allowed=admin security.web-server.paths.3.path=/static[/{*}] security.web-server.paths.3.roles-allowed=user,monitor ",
            "title": "WebServer"
        },
        {
            "location": "se/security/containers-integration",
            "text": "<markup lang=\"java\" title=\"Integrate with Jersey\" >ResourceConfig resourceConfig = new ResourceConfig() // register JAX-RS resource .register(JaxRsResource.class) // integrate security .register(new io.helidon.security.jersey.SecurityFeature(security)); ",
            "title": "Inbound security"
        },
        {
            "location": "se/security/containers-integration",
            "text": " The current approach does not have a configuration option so security must be configured through annotations. Security currently supports @Authenticated and @Authorized. When a resource is annotated with one of these annotations (application class, resource class, or resource method), security will be triggered. <markup lang=\"java\" title=\"Securing a resource method\" >// this is sufficient for security to be triggered, see javadoc for further details @Authenticated @Path(\"/{name}\") @GET @Produces(MediaType.TEXT_PLAIN) // due to Jersey approach to path matching, we need two methods to match both the \"root\" and \"root\" + subpaths public String getHelloName(@PathParam(\"name\") String name) { return \"Hello \" + name + \", your current subject: \" + securityContext.getSubject(); } ",
            "title": "Secure a Resource Method"
        },
        {
            "location": "se/security/containers-integration",
            "text": "<markup lang=\"java\" title=\"Support in a JAX-RS resource\" >// inject io.helidon.security.SecurityContext @Context private SecurityContext securityContext; ",
            "title": "Access Context"
        },
        {
            "location": "se/security/containers-integration",
            "text": " Outbound security is automatically registered with Jersey client. The provider must have outbound security configured for identity to be propagated. <markup lang=\"xml\" title=\"Maven Dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.integration&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-integration-jersey-client&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"java\" title=\"Call remote target with outbound security\" >Client client = ClientBuilder.newClient(); try { // call the resource, will propagate identity as configured in Security String response = client.target(\"https://www.google.com\") .request() // configure the security context for this request (as client and targets may be re-used) .property(ClientSecurity.PROPERTY_CONTEXT, securityContext) .get(String.class); } finally { client.close(); } ",
            "title": "Outbound Security"
        },
        {
            "location": "se/security/containers-integration",
            "text": " Jersey (JAX-RS implementation) can be configured for both inbound and outbound security. <markup lang=\"xml\" title=\"Maven Dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.integration&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-integration-jersey&lt;/artifactId&gt; &lt;/dependency&gt; Inbound security <markup lang=\"java\" title=\"Integrate with Jersey\" >ResourceConfig resourceConfig = new ResourceConfig() // register JAX-RS resource .register(JaxRsResource.class) // integrate security .register(new io.helidon.security.jersey.SecurityFeature(security)); Secure a Resource Method The current approach does not have a configuration option so security must be configured through annotations. Security currently supports @Authenticated and @Authorized. When a resource is annotated with one of these annotations (application class, resource class, or resource method), security will be triggered. <markup lang=\"java\" title=\"Securing a resource method\" >// this is sufficient for security to be triggered, see javadoc for further details @Authenticated @Path(\"/{name}\") @GET @Produces(MediaType.TEXT_PLAIN) // due to Jersey approach to path matching, we need two methods to match both the \"root\" and \"root\" + subpaths public String getHelloName(@PathParam(\"name\") String name) { return \"Hello \" + name + \", your current subject: \" + securityContext.getSubject(); } Access Context <markup lang=\"java\" title=\"Support in a JAX-RS resource\" >// inject io.helidon.security.SecurityContext @Context private SecurityContext securityContext; Outbound Security Outbound security is automatically registered with Jersey client. The provider must have outbound security configured for identity to be propagated. <markup lang=\"xml\" title=\"Maven Dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.integration&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-integration-jersey-client&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"java\" title=\"Call remote target with outbound security\" >Client client = ClientBuilder.newClient(); try { // call the resource, will propagate identity as configured in Security String response = client.target(\"https://www.google.com\") .request() // configure the security context for this request (as client and targets may be re-used) .property(ClientSecurity.PROPERTY_CONTEXT, securityContext) .get(String.class); } finally { client.close(); } ",
            "title": "Jersey"
        },
        {
            "location": "se/security/containers-integration",
            "text": " Helidon Jersey Security Integration Helidon WebServer Security Integration ",
            "title": "Reference"
        },
        {
            "location": "se/security/extensibility",
            "text": " This guide describes how you can extend the Security component. The component has the following extension points: Security Providers Provider Selection Policy Framework Integration ",
            "title": "preambule"
        },
        {
            "location": "se/security/extensibility",
            "text": " To create a custom authentication provider, create a class that implements io.helidon.security.spi.AuthenticationProvider . Implementation is responsible for taking a request and asserting a subject based on that request. In case the protocol is multi-request (e.g. challenge for basic authentication), you have the possibility to return specific headers and a response code. The default semantics of these is HTTP, though providers may exist that are not HTTP specific. ",
            "title": "Authentication Provider"
        },
        {
            "location": "se/security/extensibility",
            "text": " To create a custom authorization provider, create a class that implements io.helidon.security.spi.AuthorizationProvider . Implementation is responsible for taking a request and checking whether the request can continue processing (e.g. if the current user and/or service subject has a right to execute it). If authentication is configured, the Security component guarantees it resolved before authorization. ",
            "title": "Authorization Provider"
        },
        {
            "location": "se/security/extensibility",
            "text": " To create a custom outbound security provider, create a class that implements io.helidon.security.spi.OutboundSecurityProvider . Implementation can update outgoing message headers to handle security for an outgoing request (e.g. identity propagation, mapping etc.). ",
            "title": "Outbound Security Provider"
        },
        {
            "location": "se/security/extensibility",
            "text": " To create a custom audit provider, create a class that implements io.helidon.security.spi.AuditProvider . Security component feeds each audit provider all messages from all components that invoke audit method on \"Security\" class, including internal audit events pre-configured in the component itself (e.g. authentication, authorization events). Implementation may do whatever desired with these messages, e.g.: filter them log them store them to a database forward them to an audit component discard them ",
            "title": "Audit Provider"
        },
        {
            "location": "se/security/extensibility",
            "text": " You can build a custom provider for each type of security concept supported. By default, each provider is asynchronous. For simple cases, a class exists in \"spi\" package to help implement a synchronous approach: SynchronousProvider . You have two options: Implement a provider interface and reference it in configuration (or from builder) by class Implement a provider interface and provide a Java ServiceLoader service implementing io.helidon.security.spi.SecurityProviderService The second option allows for easier configuration, as the configuration key can be used without a class definition and creates a default name of a provider. Authentication Provider To create a custom authentication provider, create a class that implements io.helidon.security.spi.AuthenticationProvider . Implementation is responsible for taking a request and asserting a subject based on that request. In case the protocol is multi-request (e.g. challenge for basic authentication), you have the possibility to return specific headers and a response code. The default semantics of these is HTTP, though providers may exist that are not HTTP specific. Authorization Provider To create a custom authorization provider, create a class that implements io.helidon.security.spi.AuthorizationProvider . Implementation is responsible for taking a request and checking whether the request can continue processing (e.g. if the current user and/or service subject has a right to execute it). If authentication is configured, the Security component guarantees it resolved before authorization. Outbound Security Provider To create a custom outbound security provider, create a class that implements io.helidon.security.spi.OutboundSecurityProvider . Implementation can update outgoing message headers to handle security for an outgoing request (e.g. identity propagation, mapping etc.). Audit Provider To create a custom audit provider, create a class that implements io.helidon.security.spi.AuditProvider . Security component feeds each audit provider all messages from all components that invoke audit method on \"Security\" class, including internal audit events pre-configured in the component itself (e.g. authentication, authorization events). Implementation may do whatever desired with these messages, e.g.: filter them log them store them to a database forward them to an audit component discard them ",
            "title": "Security Providers"
        },
        {
            "location": "se/security/extensibility",
            "text": " Each request is processed by a single authentication and/or authorization provider. The selection policy provides the security component information about which provider to use. Out of the box, there are three policies: \"First\" policy - first configured provider (or explicitly defined default provider) is used by default, if a named provider is requested, it would be used \"Composite\" policy - this policy allows for a sequence of providers to be executed (e.g. one request may have more than one provider) - used for example to resolve service and user authentication \"Class\" policy - this allows usage of a custom policy defined by fully qualified class name To create a custom provider selection policy, create a class that implements \"io.helidon.security.spi.ProviderSelectionPolicy\". ",
            "title": "Provider Selection Policy"
        },
        {
            "location": "se/security/extensibility",
            "text": " The Security component supports integration with Helidon WebServer ( helidon-security-integration-webserver ) and with Jersey ( helidon-security-integration-jersey ). Existing integrations (WebServer and Jersey) use Helidon Security APIs that are available to integrate any framework/application (for example we could integrate security with messaging, such as JMS). To create a new integration, an instance of Security class is needed, as it handles all configured providers. Usually a single Security instance is used for an application. Security is then used to create an instance of SecurityContext , which is used for interaction with a single user. A single SecurityContext is created for each HTTP request in Jersey and WebServer integration. SecurityContext is used to invoke authentication, authorization, and outbound security requests. Helidon Security also defines a set of annotations: @Authenticated - access to resources must follow authentication rules defined by the annotation @Authorized - access to resources must follow authorization rules defined by the annotation @Audited - to configure auditing If the protected resources (in Helidon MP, these are JAX-RS resource classes and methods) can be annotated, the integration component must use these annotations when deciding how to secure the endpoint. For example, the Jersey integration checks whether the @Authenticated annotation exists. If it does, then the integration component attempts to authenticate the request. Because other components of Helidon Security (such as ABAC validators) query the request for annotations, the integration component should also collect all annotations from the resource and correctly configure them when creating the security request. ",
            "title": "Framework Integration"
        },
        {
            "location": "se/security/introduction",
            "text": " Helidon Security provides authentication, authorization and auditing for your Helidon application. ",
            "title": "preambule"
        },
        {
            "location": "se/security/introduction",
            "text": " Overview Maven Coordinates Usage ",
            "title": "Contents"
        },
        {
            "location": "se/security/introduction",
            "text": " Helidon Security provides the following features Authentication - support for authenticating incoming requests, creating a security Subject with Principal and Grants. Principal represents current user/service. Grant may represent a Role, Scope etc. Responsibility to create Principals and Grants lies with with AuthenticationProvider SPI. The following Principals are expected and supported by default: UserPrincipal - the party is an end-user (e.g. a person) - there can be zero to one user principals in a subject ServicePrincipal - the party is a service (e.g. a computer program) - there can be zero to one service principals in a subject Authorization - support for authorizing incoming requests. Out-of-the-box the security module supports ABAC and RBAC (Attribute based access control and Role based access control). RBAC is handled through RolesAllowed annotation (for integrations that support injection). Outbound security - support for propagating identity or (in general) securing outbound requests. Modification of a request to include outbound security is responsibility of OutboundSecurityProvider SPI Audit - security module audits most important events through its own API (e.g. Authentication events, Authorization events, outbound security events). A default AuditProvider is provided as well, logging to Java util logging (JUL) logger called \"AUDIT\" (may be overridden through configuration). AuditProvider SPI may be implemented to support other auditing options. Security module is quite HTTP centric (as most common use cases are related to HTTP REST), though it is not HTTP specific (the security module may be used to secure even other transports, such as JMS, Kafka messages etc. if an appropriate integration module is developed, as all APIs can be mapped to a non-HTTP protocol). Nevertheless there may be security providers that only make sense with HTTP (such as HTTP digest authentication). ",
            "title": "Overview"
        },
        {
            "location": "se/security/introduction",
            "text": " To enable Security add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security&lt;/groupId&gt; &lt;artifactId&gt;helidon-security&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "se/security/introduction",
            "text": "<markup lang=\"java\" title=\"Security through a builder\" >Security security = Security.builder() // create a provider instance based on the provider documentation .addProvider(...) .build(); ",
            "title": "Builder Pattern"
        },
        {
            "location": "se/security/introduction",
            "text": " When a configuration needs to be overridden, we may have problems with the list type of the providers configuration. To simplify overrides using properties, you can explicitly setup a type of provider using a type key. Example: <markup lang=\"properties\" >security.providers.1.type=header-atn security.providers.1.header-atn.authenticate=false Would explicitly override the second provider ( http-basic-auth in example above) with header-atn provider. Note that the type and the key of the provider must match. ",
            "title": "Overriding Configuration"
        },
        {
            "location": "se/security/introduction",
            "text": " See Secure config for details about encrypting passwords in configuration files. <markup lang=\"java\" title=\"Security from configuration\" >// uses io.helidon.Config Security security = Security.create(config); <markup lang=\"yaml\" title=\"Security from configuration - application.yaml\" ># Uses config encryption filter to encrypt passwords security: providers: - abac: - http-basic-auth: realm: \"helidon\" users: - login: \"jack\" password: \"${CLEAR=password}\" roles: [\"user\", \"admin\"] - login: \"jill\" password: \"${CLEAR=password}\" roles: [\"user\"] Overriding Configuration When a configuration needs to be overridden, we may have problems with the list type of the providers configuration. To simplify overrides using properties, you can explicitly setup a type of provider using a type key. Example: <markup lang=\"properties\" >security.providers.1.type=header-atn security.providers.1.header-atn.authenticate=false Would explicitly override the second provider ( http-basic-auth in example above) with header-atn provider. Note that the type and the key of the provider must match. ",
            "title": "Configuration Pattern"
        },
        {
            "location": "se/security/introduction",
            "text": "<markup lang=\"java\" title=\"Security from configuration and builder\" >// uses io.helidon.Config Security security = Security.builder(config) .addProvider(...) .build(); // or reverse order: Security security = Security.builder() .addProvider() .config(config) .build(); ",
            "title": "Hybrid Pattern (Builder with Configuration)"
        },
        {
            "location": "se/security/introduction",
            "text": " To integrate with a container, or to use Security standalone, we must create an instance of security. In general, Security supports three approaches a fluent-API builder pattern - you configure everything \"by hand\" a configuration based pattern - you configure everything in a configuration file hybrid - you load a builder from configuration and update it in a program Once a security instance is built, it can be used to initialize an integration with a container , or to use security from a program directly: <markup lang=\"java\" title=\"Security direct usage\" >// create a security context SecurityContext context = security.contextBuilder(UUID.randomUUID().toString()) .env(SecurityEnvironment.builder() .method(\"get\") .path(\"/test\") .transport(\"http\") .header(\"Authorization\", \"Bearer abcdefgh\") .build()) .build(); // use the context to authenticate a request context.atnClientBuilder() .submit() .whenComplete((response, exception) -&gt; { // this is to show the features, not a real-world production code... if (null == exception) { if (response.getStatus().isSuccess()) { System.out.println(response.getUser()); System.out.println(response.getService()); } else { System.out.println(\"Authentication failed: \" + response.getDescription()); } } else { exception.printStackTrace(); } }); Builder Pattern <markup lang=\"java\" title=\"Security through a builder\" >Security security = Security.builder() // create a provider instance based on the provider documentation .addProvider(...) .build(); Configuration Pattern See Secure config for details about encrypting passwords in configuration files. <markup lang=\"java\" title=\"Security from configuration\" >// uses io.helidon.Config Security security = Security.create(config); <markup lang=\"yaml\" title=\"Security from configuration - application.yaml\" ># Uses config encryption filter to encrypt passwords security: providers: - abac: - http-basic-auth: realm: \"helidon\" users: - login: \"jack\" password: \"${CLEAR=password}\" roles: [\"user\", \"admin\"] - login: \"jill\" password: \"${CLEAR=password}\" roles: [\"user\"] Overriding Configuration When a configuration needs to be overridden, we may have problems with the list type of the providers configuration. To simplify overrides using properties, you can explicitly setup a type of provider using a type key. Example: <markup lang=\"properties\" >security.providers.1.type=header-atn security.providers.1.header-atn.authenticate=false Would explicitly override the second provider ( http-basic-auth in example above) with header-atn provider. Note that the type and the key of the provider must match. Hybrid Pattern (Builder with Configuration) <markup lang=\"java\" title=\"Security from configuration and builder\" >// uses io.helidon.Config Security security = Security.builder(config) .addProvider(...) .build(); // or reverse order: Security security = Security.builder() .addProvider() .config(config) .build(); ",
            "title": "Usage"
        },
        {
            "location": "se/security/jep-290",
            "text": " Overview Deserialization Setup System Property Configuration Programmatic Configuration ",
            "title": "Contents"
        },
        {
            "location": "se/security/jep-290",
            "text": " JEP-290 brought support for deserialization filters to Java programming language. Such filtering allows us to control which classes may be deserialized using Java serialization. ",
            "title": "Overview"
        },
        {
            "location": "se/security/jep-290",
            "text": " Helidon default settings forbids any deserialization except for patterns defined in a pattern property of any META-INF/helidon/serial-config.properties on classpath. The patterns are semicolon delimited strings, such as io.myapp.&#42;&#42;;java.util.HashMap (any subpackage of io.myapp and class java.util.HashMap ). Helidon will always add a deny-all filter pattern to the end of the pattern string (to make sure we exclude any unspecified class - we only operate on whitelists) These defaults can be modified either through system properties, or programmatically. ",
            "title": "Deserialization Setup"
        },
        {
            "location": "se/security/jep-290",
            "text": " The following system properties can be used to control deserialization in Helidon: System properties property default value description helidon.serialFilter.pattern !&#42; Filter pattern to use, deny all is always added helidon.serialFilter.ignoreFiles false Whether to ignore files META-INF/helidon/serial-config.properties in libraries on the classpath helidon.serialFilter.failure.action FAIL Action to do when the configuration of global filter exists and is not consistent with our security expectations (e.g. contains a pattern to include all). Options: FAIL - throw an exception to terminate startup WARN - log a warning IGNORE - ignore this and silently continue helidon.serialFilter.missing.action CONFIGURE Action to do when there is no global configuration. Options: CONFIGURE - configure Helidon defaults FAIL - throw an exception to terminate startup WARN - log a warning IGNORE - ignore this and silently continue helidon.serialFilter.trace NONE Tracing configuration for deserialization. Controls what information (if any) will be logged to a logger io.helidon.common.SerializationConfig.TracingObjectInputFilter in INFO log level. Options: NONE - do not trace BASIC - trace only classes, and only once per class FULL - trace all deserialization filter requests ",
            "title": "System Property Configuration"
        },
        {
            "location": "se/security/jep-290",
            "text": " Custom SerializationConfig may be registered, but it must be done before Helidon server is started. <markup lang=\"java\" title=\"Configure custom Helidon serialization config\" >SerializationConfig.builder() .traceSerialization(SerializationConfig.TraceOption.BASIC) .filterPattern(MyType.class.getName()) .ignoreFiles(true) .onWrongConfig(SerializationConfig.Action.IGNORE) .build() .configure(); Trace first instance of each class that is deserialized Configure a single class filter pattern (only allows deserialization of class MyType Ignore files defined in META-INF/helidon/serial-config.properties In case there is an existing global serialization configuration on JDK, ignore it and continue (global filter cannot be reconfigured) Configure this serialization config as the default for this JVM ",
            "title": "Programmatic Configuration"
        },
        {
            "location": "se/security/providers",
            "text": " Implemented Security Providers Maven Coordinates Reference ",
            "title": "Contents"
        },
        {
            "location": "se/security/providers",
            "text": " Open ID Connect security provider. ",
            "title": "OIDC Provider"
        },
        {
            "location": "se/security/providers",
            "text": " In Helidon SE, we need to register the redirection support with routing (in addition to WebSecurity that integrates with WebServer ). This is not required when redirect is set to false. <markup lang=\"java\" title=\"Adding support for OIDC redirects\" >Routing routing = Routing.builder() .register(WebSecurity.create(config.get(\"security\"))) .register(OidcSupport.create(config)) .build(); Open ID Connect security provider Type: io.helidon.security.providers.oidc.OidcProvider <markup lang=\"text\" title=\"Config key\" >oidc This type provides the following service implementations: io.helidon.security.spi.AuthenticationProvider io.helidon.security.spi.SecurityProvider ",
            "title": "Overview"
        },
        {
            "location": "se/security/providers",
            "text": " Optional configuration options key type default value description audience string &#160; Audience of issued tokens. authorization-endpoint-uri URI &#160; URI of an authorization endpoint used to redirect users to for logging-in. If not defined, it is obtained from #oidcMetadata(Resource), if that is not defined an attempt is made to use #identityUri(URI)/oauth2/v1/authorize. base-scopes string openid Configure base scopes. By default this is DEFAULT_BASE_SCOPES . If scope has a qualifier, it must be used here. client-id string &#160; Client ID as generated by OIDC server. client-secret string &#160; Client secret as generated by OIDC server. Used to authenticate this application with the server when requesting JWT based on a code. client-timeout-millis Duration 30000 Timeout of calls using web client. cookie-domain string &#160; Domain the cookie is valid for. Not used by default. cookie-http-only boolean true When using cookie, if set to true, the HttpOnly attribute will be configured. Defaults to OidcCookieHandler.Builder#DEFAULT_HTTP_ONLY . cookie-max-age-seconds long &#160; When using cookie, used to set MaxAge attribute of the cookie, defining how long the cookie is valid. Not used by default. cookie-name string JSESSIONID Name of the cookie to use. Defaults to DEFAULT_COOKIE_NAME . cookie-path string / Path the cookie is valid for. Defaults to \"/\". cookie-same-site SameSite (LAX, STRICT, NONE) LAX When using cookie, used to set the SameSite cookie value. Can be \"Strict\" or \"Lax\". cookie-secure boolean false When using cookie, if set to true, the Secure attribute will be configured. Defaults to false. cookie-use boolean true Whether to use cookie to store JWT between requests. Defaults to DEFAULT_COOKIE_USE . cors CrossOriginConfig &#160; Assign cross-origin resource sharing settings. force-https-redirects boolean false Force HTTPS for redirects to identity provider. Defaults to false . frontend-uri string &#160; Full URI of this application that is visible from user browser. Used to redirect request back from identity server after successful login. header-token TokenHandler &#160; A TokenHandler to process header containing a JWT. Default is \"Authorization\" header with a prefix \"bearer \". header-use boolean true Whether to expect JWT in a header field. identity-uri URI &#160; URI of the identity server, base used to retrieve OIDC metadata. introspect-endpoint-uri URI &#160; Endpoint to use to validate JWT. Either use this or set #signJwk(JwkKeys) or #signJwk(Resource). issuer string &#160; Issuer of issued tokens. max-redirects int 5 Configure maximal number of redirects when redirecting to an OIDC provider within a single authentication attempt. Defaults to `DEFAULT_MAX_REDIRECTS` oidc-metadata-well-known boolean true If set to true, metadata will be loaded from default (well known) location, unless it is explicitly defined using oidc-metadata-resource. If set to false, it would not be loaded even if oidc-metadata-resource is not defined. In such a case all URIs must be explicitly defined (e.g. token-endpoint-uri). oidc-metadata.resource Resource &#160; Resource configuration for OIDC Metadata containing endpoints to various identity services, as well as information about the identity server. optional boolean false Whether authentication is required. By default, request will fail if the authentication cannot be verified. If set to true, request will process and this provider will abstain. outbound OutboundTarget[&#93; &#160; Add a new target configuration. propagate boolean false Whether to propagate identity. proxy-host string &#160; Proxy host to use. When defined, triggers usage of proxy for HTTP requests. Setting to empty String has the same meaning as setting to null - disables proxy. proxy-port int 80 Proxy port. Defaults to DEFAULT_PROXY_PORT proxy-protocol string http Proxy protocol to use when proxy is used. Defaults to DEFAULT_PROXY_PROTOCOL . query-param-name string accessToken Name of a query parameter that contains the JWT token when parameter is used. query-param-use boolean false Whether to use a query parameter to send JWT token from application to this server. redirect boolean false By default the client should redirect to the identity server for the user to log in. This behavior can be overridden by setting redirect to false. When token is not present in the request, the client will not redirect and just return appropriate error response code. redirect-attempt-param string h_ra Configure the parameter used to store the number of attempts in redirect. Defaults to `DEFAULT_ATTEMPT_PARAM` redirect-uri string /oidc/redirect URI to register web server component on, used by the OIDC server to redirect authorization requests to after a user logs in or approves scopes. Note that usually the redirect URI configured here must be the same one as configured on OIDC server. Defaults to `DEFAULT_REDIRECT_URI` scope-audience string &#160; Audience of the scope required by this application. This is prefixed to the scope name when requesting scopes from the identity server. Defaults to empty string. server-type string @default Configure one of the supported types of identity servers. If the type does not have an explicit mapping, a warning is logged and the default implementation is used. sign-jwk.resource Resource &#160; A resource pointing to JWK with public keys of signing certificates used to validate JWT. token-endpoint-auth ClientAuthentication (CLIENT_SECRET_BASIC, CLIENT_SECRET_POST, CLIENT_SECRET_JWT, PRIVATE_KEY_JWT, NONE) CLIENT_SECRET_BASIC Type of authentication to use when invoking the token endpoint. Current supported options: io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#CLIENT_SECRET_BASIC io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#CLIENT_SECRET_POST io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#NONE token-endpoint-uri URI &#160; URI of a token endpoint used to obtain a JWT based on the authentication code. If not defined, it is obtained from #oidcMetadata(Resource), if that is not defined an attempt is made to use #identityUri(URI)/oauth2/v1/token. use-jwt-groups boolean true Claim groups from JWT will be used to automatically add groups to current subject (may be used with jakarta.annotation.security.RolesAllowed annotation). validate-jwt-with-jwk boolean true Use JWK (a set of keys to validate signatures of JWT) to validate tokens. Use this method when you want to use default values for JWK or introspection endpoint URI. ",
            "title": "Configuration options"
        },
        {
            "location": "se/security/providers",
            "text": "<markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-oidc&lt;/artifactId&gt; &lt;/dependency&gt; Overview In Helidon SE, we need to register the redirection support with routing (in addition to WebSecurity that integrates with WebServer ). This is not required when redirect is set to false. <markup lang=\"java\" title=\"Adding support for OIDC redirects\" >Routing routing = Routing.builder() .register(WebSecurity.create(config.get(\"security\"))) .register(OidcSupport.create(config)) .build(); Open ID Connect security provider Type: io.helidon.security.providers.oidc.OidcProvider <markup lang=\"text\" title=\"Config key\" >oidc This type provides the following service implementations: io.helidon.security.spi.AuthenticationProvider io.helidon.security.spi.SecurityProvider Configuration options Optional configuration options key type default value description audience string &#160; Audience of issued tokens. authorization-endpoint-uri URI &#160; URI of an authorization endpoint used to redirect users to for logging-in. If not defined, it is obtained from #oidcMetadata(Resource), if that is not defined an attempt is made to use #identityUri(URI)/oauth2/v1/authorize. base-scopes string openid Configure base scopes. By default this is DEFAULT_BASE_SCOPES . If scope has a qualifier, it must be used here. client-id string &#160; Client ID as generated by OIDC server. client-secret string &#160; Client secret as generated by OIDC server. Used to authenticate this application with the server when requesting JWT based on a code. client-timeout-millis Duration 30000 Timeout of calls using web client. cookie-domain string &#160; Domain the cookie is valid for. Not used by default. cookie-http-only boolean true When using cookie, if set to true, the HttpOnly attribute will be configured. Defaults to OidcCookieHandler.Builder#DEFAULT_HTTP_ONLY . cookie-max-age-seconds long &#160; When using cookie, used to set MaxAge attribute of the cookie, defining how long the cookie is valid. Not used by default. cookie-name string JSESSIONID Name of the cookie to use. Defaults to DEFAULT_COOKIE_NAME . cookie-path string / Path the cookie is valid for. Defaults to \"/\". cookie-same-site SameSite (LAX, STRICT, NONE) LAX When using cookie, used to set the SameSite cookie value. Can be \"Strict\" or \"Lax\". cookie-secure boolean false When using cookie, if set to true, the Secure attribute will be configured. Defaults to false. cookie-use boolean true Whether to use cookie to store JWT between requests. Defaults to DEFAULT_COOKIE_USE . cors CrossOriginConfig &#160; Assign cross-origin resource sharing settings. force-https-redirects boolean false Force HTTPS for redirects to identity provider. Defaults to false . frontend-uri string &#160; Full URI of this application that is visible from user browser. Used to redirect request back from identity server after successful login. header-token TokenHandler &#160; A TokenHandler to process header containing a JWT. Default is \"Authorization\" header with a prefix \"bearer \". header-use boolean true Whether to expect JWT in a header field. identity-uri URI &#160; URI of the identity server, base used to retrieve OIDC metadata. introspect-endpoint-uri URI &#160; Endpoint to use to validate JWT. Either use this or set #signJwk(JwkKeys) or #signJwk(Resource). issuer string &#160; Issuer of issued tokens. max-redirects int 5 Configure maximal number of redirects when redirecting to an OIDC provider within a single authentication attempt. Defaults to `DEFAULT_MAX_REDIRECTS` oidc-metadata-well-known boolean true If set to true, metadata will be loaded from default (well known) location, unless it is explicitly defined using oidc-metadata-resource. If set to false, it would not be loaded even if oidc-metadata-resource is not defined. In such a case all URIs must be explicitly defined (e.g. token-endpoint-uri). oidc-metadata.resource Resource &#160; Resource configuration for OIDC Metadata containing endpoints to various identity services, as well as information about the identity server. optional boolean false Whether authentication is required. By default, request will fail if the authentication cannot be verified. If set to true, request will process and this provider will abstain. outbound OutboundTarget[&#93; &#160; Add a new target configuration. propagate boolean false Whether to propagate identity. proxy-host string &#160; Proxy host to use. When defined, triggers usage of proxy for HTTP requests. Setting to empty String has the same meaning as setting to null - disables proxy. proxy-port int 80 Proxy port. Defaults to DEFAULT_PROXY_PORT proxy-protocol string http Proxy protocol to use when proxy is used. Defaults to DEFAULT_PROXY_PROTOCOL . query-param-name string accessToken Name of a query parameter that contains the JWT token when parameter is used. query-param-use boolean false Whether to use a query parameter to send JWT token from application to this server. redirect boolean false By default the client should redirect to the identity server for the user to log in. This behavior can be overridden by setting redirect to false. When token is not present in the request, the client will not redirect and just return appropriate error response code. redirect-attempt-param string h_ra Configure the parameter used to store the number of attempts in redirect. Defaults to `DEFAULT_ATTEMPT_PARAM` redirect-uri string /oidc/redirect URI to register web server component on, used by the OIDC server to redirect authorization requests to after a user logs in or approves scopes. Note that usually the redirect URI configured here must be the same one as configured on OIDC server. Defaults to `DEFAULT_REDIRECT_URI` scope-audience string &#160; Audience of the scope required by this application. This is prefixed to the scope name when requesting scopes from the identity server. Defaults to empty string. server-type string @default Configure one of the supported types of identity servers. If the type does not have an explicit mapping, a warning is logged and the default implementation is used. sign-jwk.resource Resource &#160; A resource pointing to JWK with public keys of signing certificates used to validate JWT. token-endpoint-auth ClientAuthentication (CLIENT_SECRET_BASIC, CLIENT_SECRET_POST, CLIENT_SECRET_JWT, PRIVATE_KEY_JWT, NONE) CLIENT_SECRET_BASIC Type of authentication to use when invoking the token endpoint. Current supported options: io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#CLIENT_SECRET_BASIC io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#CLIENT_SECRET_POST io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#NONE token-endpoint-uri URI &#160; URI of a token endpoint used to obtain a JWT based on the authentication code. If not defined, it is obtained from #oidcMetadata(Resource), if that is not defined an attempt is made to use #identityUri(URI)/oauth2/v1/token. use-jwt-groups boolean true Claim groups from JWT will be used to automatically add groups to current subject (may be used with jakarta.annotation.security.RolesAllowed annotation). validate-jwt-with-jwk boolean true Use JWK (a set of keys to validate signatures of JWT) to validate tokens. Use this method when you want to use default values for JWK or introspection endpoint URI. ",
            "title": "Maven Coordinates"
        },
        {
            "location": "se/security/providers",
            "text": " See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - oidc: client-id: \"client-id-of-this-service\" client-secret: \"${CLEAR=client-secret-of-this-service}\" identity-uri: \"http://your-tenant.identity-server.com\" frontend-uri: \"http://my-service:8080\" audience: \"http://my-service\" cors: allow-origins: [\"http://foo.com\", \"http://there.com\"] allow-methods: [\"PUT\", \"DELETE\"] outbound: - name: \"internal-services\" hosts: [\"*.example.org\"] outbound-token: header: \"X-Internal-Auth\" ",
            "title": "Example code"
        },
        {
            "location": "se/security/providers",
            "text": " At Helidon startup, if OIDC provider is configured, the following will happen: client-id , client-secret , and identityUri are validated - these must provide values Unless all resources are configured as local resources, the provider attempts to contact the oidc-metadata.resource endpoint to retrieve all endpoints At runtime, depending on configuration&#8230;&#8203; If a request comes without a token or with insufficient scopes: If redirect is set to true (default), request is redirected to the authorization endpoint of the identity server. If set to false, 401 is returned User authenticates against the identity server The identity server redirects back to Helidon service with a code Helidon service contacts the identity server&#8217;s token endpoint, to exchange the code for a JWT The JWT is stored in a cookie (if cookie support is enabled, which it is by default) Helidon service redirects to original endpoint (on itself) Helidon obtains a token from request (from cookie, header, or query parameter): Token is parsed as a singed JWT We validate the JWT signature either against local JWK or against the identity server&#8217;s introspection endpoint depending on configuration We validate the issuer and audience of the token if it matches the configured values A subject is created from the JWT, including scopes from the token We validate that we have sufficient scopes to proceed, and return 403 if not Handling is returned to security to process other security providers ",
            "title": "How does it work?"
        },
        {
            "location": "se/security/providers",
            "text": " Helidon provides the following security providers for endpoint protection: Provider Type Outbound supported Description OIDC Provider Authentication ✅ Open ID Connect supporting JWT, Scopes, Groups and OIDC code flow HTTP Basic Authentication Authentication ✅ HTTP Basic Authentication support HTTP Digest Authentication Authentication 🚫 HTTP Digest Authentication support Header Assertion Authentication ✅ Asserting a user based on a header value HTTP Signatures Authentication ✅ Protecting service to service communication through signatures IDCS Roles Role Mapping 🚫 Retrieves roles from IDCS provider for authenticated user ABAC Authorization Authorization 🚫 Attribute based access control authorization policies The following providers are no longer evolved: Provider Type Outbound supported Description Google Login Authentication ✅ Authenticates a token from request against Google servers JWT Provider Authentication ✅ JWT tokens passed from frontend OIDC Provider Open ID Connect security provider. Maven Coordinates <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-oidc&lt;/artifactId&gt; &lt;/dependency&gt; Overview In Helidon SE, we need to register the redirection support with routing (in addition to WebSecurity that integrates with WebServer ). This is not required when redirect is set to false. <markup lang=\"java\" title=\"Adding support for OIDC redirects\" >Routing routing = Routing.builder() .register(WebSecurity.create(config.get(\"security\"))) .register(OidcSupport.create(config)) .build(); Open ID Connect security provider Type: io.helidon.security.providers.oidc.OidcProvider <markup lang=\"text\" title=\"Config key\" >oidc This type provides the following service implementations: io.helidon.security.spi.AuthenticationProvider io.helidon.security.spi.SecurityProvider Configuration options Optional configuration options key type default value description audience string &#160; Audience of issued tokens. authorization-endpoint-uri URI &#160; URI of an authorization endpoint used to redirect users to for logging-in. If not defined, it is obtained from #oidcMetadata(Resource), if that is not defined an attempt is made to use #identityUri(URI)/oauth2/v1/authorize. base-scopes string openid Configure base scopes. By default this is DEFAULT_BASE_SCOPES . If scope has a qualifier, it must be used here. client-id string &#160; Client ID as generated by OIDC server. client-secret string &#160; Client secret as generated by OIDC server. Used to authenticate this application with the server when requesting JWT based on a code. client-timeout-millis Duration 30000 Timeout of calls using web client. cookie-domain string &#160; Domain the cookie is valid for. Not used by default. cookie-http-only boolean true When using cookie, if set to true, the HttpOnly attribute will be configured. Defaults to OidcCookieHandler.Builder#DEFAULT_HTTP_ONLY . cookie-max-age-seconds long &#160; When using cookie, used to set MaxAge attribute of the cookie, defining how long the cookie is valid. Not used by default. cookie-name string JSESSIONID Name of the cookie to use. Defaults to DEFAULT_COOKIE_NAME . cookie-path string / Path the cookie is valid for. Defaults to \"/\". cookie-same-site SameSite (LAX, STRICT, NONE) LAX When using cookie, used to set the SameSite cookie value. Can be \"Strict\" or \"Lax\". cookie-secure boolean false When using cookie, if set to true, the Secure attribute will be configured. Defaults to false. cookie-use boolean true Whether to use cookie to store JWT between requests. Defaults to DEFAULT_COOKIE_USE . cors CrossOriginConfig &#160; Assign cross-origin resource sharing settings. force-https-redirects boolean false Force HTTPS for redirects to identity provider. Defaults to false . frontend-uri string &#160; Full URI of this application that is visible from user browser. Used to redirect request back from identity server after successful login. header-token TokenHandler &#160; A TokenHandler to process header containing a JWT. Default is \"Authorization\" header with a prefix \"bearer \". header-use boolean true Whether to expect JWT in a header field. identity-uri URI &#160; URI of the identity server, base used to retrieve OIDC metadata. introspect-endpoint-uri URI &#160; Endpoint to use to validate JWT. Either use this or set #signJwk(JwkKeys) or #signJwk(Resource). issuer string &#160; Issuer of issued tokens. max-redirects int 5 Configure maximal number of redirects when redirecting to an OIDC provider within a single authentication attempt. Defaults to `DEFAULT_MAX_REDIRECTS` oidc-metadata-well-known boolean true If set to true, metadata will be loaded from default (well known) location, unless it is explicitly defined using oidc-metadata-resource. If set to false, it would not be loaded even if oidc-metadata-resource is not defined. In such a case all URIs must be explicitly defined (e.g. token-endpoint-uri). oidc-metadata.resource Resource &#160; Resource configuration for OIDC Metadata containing endpoints to various identity services, as well as information about the identity server. optional boolean false Whether authentication is required. By default, request will fail if the authentication cannot be verified. If set to true, request will process and this provider will abstain. outbound OutboundTarget[&#93; &#160; Add a new target configuration. propagate boolean false Whether to propagate identity. proxy-host string &#160; Proxy host to use. When defined, triggers usage of proxy for HTTP requests. Setting to empty String has the same meaning as setting to null - disables proxy. proxy-port int 80 Proxy port. Defaults to DEFAULT_PROXY_PORT proxy-protocol string http Proxy protocol to use when proxy is used. Defaults to DEFAULT_PROXY_PROTOCOL . query-param-name string accessToken Name of a query parameter that contains the JWT token when parameter is used. query-param-use boolean false Whether to use a query parameter to send JWT token from application to this server. redirect boolean false By default the client should redirect to the identity server for the user to log in. This behavior can be overridden by setting redirect to false. When token is not present in the request, the client will not redirect and just return appropriate error response code. redirect-attempt-param string h_ra Configure the parameter used to store the number of attempts in redirect. Defaults to `DEFAULT_ATTEMPT_PARAM` redirect-uri string /oidc/redirect URI to register web server component on, used by the OIDC server to redirect authorization requests to after a user logs in or approves scopes. Note that usually the redirect URI configured here must be the same one as configured on OIDC server. Defaults to `DEFAULT_REDIRECT_URI` scope-audience string &#160; Audience of the scope required by this application. This is prefixed to the scope name when requesting scopes from the identity server. Defaults to empty string. server-type string @default Configure one of the supported types of identity servers. If the type does not have an explicit mapping, a warning is logged and the default implementation is used. sign-jwk.resource Resource &#160; A resource pointing to JWK with public keys of signing certificates used to validate JWT. token-endpoint-auth ClientAuthentication (CLIENT_SECRET_BASIC, CLIENT_SECRET_POST, CLIENT_SECRET_JWT, PRIVATE_KEY_JWT, NONE) CLIENT_SECRET_BASIC Type of authentication to use when invoking the token endpoint. Current supported options: io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#CLIENT_SECRET_BASIC io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#CLIENT_SECRET_POST io.helidon.security.providers.oidc.common.OidcConfig.ClientAuthentication#NONE token-endpoint-uri URI &#160; URI of a token endpoint used to obtain a JWT based on the authentication code. If not defined, it is obtained from #oidcMetadata(Resource), if that is not defined an attempt is made to use #identityUri(URI)/oauth2/v1/token. use-jwt-groups boolean true Claim groups from JWT will be used to automatically add groups to current subject (may be used with jakarta.annotation.security.RolesAllowed annotation). validate-jwt-with-jwk boolean true Use JWK (a set of keys to validate signatures of JWT) to validate tokens. Use this method when you want to use default values for JWK or introspection endpoint URI. Example code See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - oidc: client-id: \"client-id-of-this-service\" client-secret: \"${CLEAR=client-secret-of-this-service}\" identity-uri: \"http://your-tenant.identity-server.com\" frontend-uri: \"http://my-service:8080\" audience: \"http://my-service\" cors: allow-origins: [\"http://foo.com\", \"http://there.com\"] allow-methods: [\"PUT\", \"DELETE\"] outbound: - name: \"internal-services\" hosts: [\"*.example.org\"] outbound-token: header: \"X-Internal-Auth\" How does it work? At Helidon startup, if OIDC provider is configured, the following will happen: client-id , client-secret , and identityUri are validated - these must provide values Unless all resources are configured as local resources, the provider attempts to contact the oidc-metadata.resource endpoint to retrieve all endpoints At runtime, depending on configuration&#8230;&#8203; If a request comes without a token or with insufficient scopes: If redirect is set to true (default), request is redirected to the authorization endpoint of the identity server. If set to false, 401 is returned User authenticates against the identity server The identity server redirects back to Helidon service with a code Helidon service contacts the identity server&#8217;s token endpoint, to exchange the code for a JWT The JWT is stored in a cookie (if cookie support is enabled, which it is by default) Helidon service redirects to original endpoint (on itself) Helidon obtains a token from request (from cookie, header, or query parameter): Token is parsed as a singed JWT We validate the JWT signature either against local JWK or against the identity server&#8217;s introspection endpoint depending on configuration We validate the issuer and audience of the token if it matches the configured values A subject is created from the JWT, including scopes from the token We validate that we have sufficient scopes to proceed, and return 403 if not Handling is returned to security to process other security providers ",
            "title": "Implemented Security Providers"
        },
        {
            "location": "se/security/providers",
            "text": "<markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-http-auth&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Setup"
        },
        {
            "location": "se/security/providers",
            "text": " HTTP Basic Authentication provider Type: io.helidon.security.providers.httpauth.HttpBasicAuthProvider <markup lang=\"text\" title=\"Config key\" >http-basic-auth This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthenticationProvider ",
            "title": "Overview"
        },
        {
            "location": "se/security/providers",
            "text": " Optional configuration options key type default value description optional boolean false Whether authentication is required. By default, request will fail if the authentication cannot be verified. If set to false, request will process and this provider will abstain. outbound OutboundTarget[&#93; &#160; Add a new outbound target to configure identity propagation or explicit username/password. principal-type SubjectType (USER, SERVICE) USER Principal type this provider extracts (and also propagates). realm string helidon Set the realm to use when challenging users. users ConfigUser[&#93; &#160; Set user store to validate users. Removes any other stores added through #addUserStore(SecureUserStore). ",
            "title": "Configuration options"
        },
        {
            "location": "se/security/providers",
            "text": " See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - http-basic-auth: realm: \"helidon\" users: - login: \"john\" password: \"${CLEAR=password}\" roles: [\"admin\"] - login: \"jack\" password: \"password\" roles: [\"user\", \"admin\"] outbound: - name: \"internal-services\" hosts: [\"*.example.org\"] # Propagates current user's identity or identity from request property outbound-token: header: \"X-Internal-Auth\" - name: \"partner-service\" hosts: [\"*.partner.org\"] # Uses this username and password username: \"partner-user-1\" password: \"${CLEAR=password}\" ",
            "title": "Example code"
        },
        {
            "location": "se/security/providers",
            "text": " See https://tools.ietf.org/html/rfc7617 . Authentication of request When a request is received without the Authorization: basic &#8230;&#8203;. header, a challenge is returned to provide such authentication. When a request is received with the Authorization: basic &#8230;&#8203;. header, the username and password is validated against configured users (and users obtained from custom service if any provided). Subject is created based on the username and roles provided by the user store. Identity propagation When identity propagation is configured, there are several options for identifying username and password to propagate: We propagate the current username and password (inbound request must be authenticated using basic authentication). We use username and password from an explicitly configured property (See HttpBasicAuthProvider.EP_PROPERTY_OUTBOUND_USER and HttpBasicAuthProvider.EP_PROPERTY_OUTBOUND_PASSWORD ) We use username and password associated with an outbound target (see example configuration above) Identity is propagated only if: There is an outbound target configured for the endpoint Or there is an explicitly configured username/password for the current request (through request property) Custom user store Java service loader service io.helidon.security.providers.httpauth.spi.UserStoreService can be implemented to provide users to the provider, such as when validated against an internal database or LDAP server. The user store is defined so you never need the clear text password of the user. Warning on security of HTTP Basic Authenticaton (or lack thereof) Basic authentication uses base64 encoded username and password and passes it over the network. Base64 is only encoding, not encryption - so anybody that gets hold of the header value can learn the actual username and password of the user. This is a security risk and an attack vector that everybody should be aware of before using HTTP Basic Authentication. We recommend using this approach only for testing and demo purposes. ",
            "title": "How does it work?"
        },
        {
            "location": "se/security/providers",
            "text": " HTTP Basic authentication support Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-http-auth&lt;/artifactId&gt; &lt;/dependency&gt; Overview HTTP Basic Authentication provider Type: io.helidon.security.providers.httpauth.HttpBasicAuthProvider <markup lang=\"text\" title=\"Config key\" >http-basic-auth This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthenticationProvider Configuration options Optional configuration options key type default value description optional boolean false Whether authentication is required. By default, request will fail if the authentication cannot be verified. If set to false, request will process and this provider will abstain. outbound OutboundTarget[&#93; &#160; Add a new outbound target to configure identity propagation or explicit username/password. principal-type SubjectType (USER, SERVICE) USER Principal type this provider extracts (and also propagates). realm string helidon Set the realm to use when challenging users. users ConfigUser[&#93; &#160; Set user store to validate users. Removes any other stores added through #addUserStore(SecureUserStore). Example code See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - http-basic-auth: realm: \"helidon\" users: - login: \"john\" password: \"${CLEAR=password}\" roles: [\"admin\"] - login: \"jack\" password: \"password\" roles: [\"user\", \"admin\"] outbound: - name: \"internal-services\" hosts: [\"*.example.org\"] # Propagates current user's identity or identity from request property outbound-token: header: \"X-Internal-Auth\" - name: \"partner-service\" hosts: [\"*.partner.org\"] # Uses this username and password username: \"partner-user-1\" password: \"${CLEAR=password}\" How does it work? See https://tools.ietf.org/html/rfc7617 . Authentication of request When a request is received without the Authorization: basic &#8230;&#8203;. header, a challenge is returned to provide such authentication. When a request is received with the Authorization: basic &#8230;&#8203;. header, the username and password is validated against configured users (and users obtained from custom service if any provided). Subject is created based on the username and roles provided by the user store. Identity propagation When identity propagation is configured, there are several options for identifying username and password to propagate: We propagate the current username and password (inbound request must be authenticated using basic authentication). We use username and password from an explicitly configured property (See HttpBasicAuthProvider.EP_PROPERTY_OUTBOUND_USER and HttpBasicAuthProvider.EP_PROPERTY_OUTBOUND_PASSWORD ) We use username and password associated with an outbound target (see example configuration above) Identity is propagated only if: There is an outbound target configured for the endpoint Or there is an explicitly configured username/password for the current request (through request property) Custom user store Java service loader service io.helidon.security.providers.httpauth.spi.UserStoreService can be implemented to provide users to the provider, such as when validated against an internal database or LDAP server. The user store is defined so you never need the clear text password of the user. Warning on security of HTTP Basic Authenticaton (or lack thereof) Basic authentication uses base64 encoded username and password and passes it over the network. Base64 is only encoding, not encryption - so anybody that gets hold of the header value can learn the actual username and password of the user. This is a security risk and an attack vector that everybody should be aware of before using HTTP Basic Authentication. We recommend using this approach only for testing and demo purposes. ",
            "title": "HTTP Basic Authentication Provider"
        },
        {
            "location": "se/security/providers",
            "text": "<markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-http-auth&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Setup"
        },
        {
            "location": "se/security/providers",
            "text": " Http digest authentication security provider Type: io.helidon.security.providers.httpauth.HttpDigestAuthProvider <markup lang=\"text\" title=\"Config key\" >http-digest-auth This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthenticationProvider ",
            "title": "Overview"
        },
        {
            "location": "se/security/providers",
            "text": " Optional configuration options key type default value description algorithm Algorithm (MD5) MD5 Digest algorithm to use. nonce-timeout-millis long 86400000 How long will the nonce value be valid. When timed-out, browser will re-request username/password. optional boolean false Whether authentication is required. By default, request will fail if the authentication cannot be verified. If set to false, request will process and this provider will abstain. principal-type SubjectType (USER, SERVICE) USER Principal type this provider extracts (and also propagates). qop Qop (NONE, AUTH) NONE Only AUTH supported. If left empty, uses the legacy approach (older RFC version). AUTH-INT is not supported. realm string Helidon Set the realm to use when challenging users. server-secret string &#160; The nonce is encrypted using this secret - to make sure the nonce we get back was generated by us and to make sure we can safely time-out nonce values. This secret must be the same for all service instances (or all services that want to share the same authentication). Defaults to a random password - e.g. if deployed to multiple servers, the authentication WILL NOT WORK. You MUST provide your own password to work in a distributed environment with non-sticky load balancing. users ConfigUser[&#93; &#160; Set user store to obtain passwords and roles based on logins. ",
            "title": "Configuration options"
        },
        {
            "location": "se/security/providers",
            "text": "<markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - http-digest-auth: realm: \"helidon\" server-secret: \"${CLEAR=service-wide-secret-not-known-outside}\" users: - login: \"john\" password: \"${CLEAR=password}\" roles: [\"admin\"] - login: \"jack\" password: \"password\" roles: [\"user\", \"admin\"] ",
            "title": "Example code"
        },
        {
            "location": "se/security/providers",
            "text": " See https://tools.ietf.org/html/rfc7616 . Authentication of request When a request is received without the Authorization: digest &#8230;&#8203;. header, a challenge is returned to provide such authentication using WWW-Authenticate header. When a request is received with the Authorization: digest &#8230;&#8203;. header, the request is validated against configured users (and users obtained from custom service if any provided). Subject is created based on the username and roles provided by the user store. Custom user store Java service loader service io.helidon.security.providers.httpauth.spi.UserStoreService can be implemented to provide users to the provider, such as when validated against an internal database or LDAP server. The user store is defined so you never need the clear text password of the user. Note on security of HTTP Digest Authenticaton These authentication schemes should be obsolete , though they provide a very easy way to test a protected resource. ",
            "title": "How does it work?"
        },
        {
            "location": "se/security/providers",
            "text": " HTTP Digest authentication support Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-http-auth&lt;/artifactId&gt; &lt;/dependency&gt; Overview Http digest authentication security provider Type: io.helidon.security.providers.httpauth.HttpDigestAuthProvider <markup lang=\"text\" title=\"Config key\" >http-digest-auth This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthenticationProvider Configuration options Optional configuration options key type default value description algorithm Algorithm (MD5) MD5 Digest algorithm to use. nonce-timeout-millis long 86400000 How long will the nonce value be valid. When timed-out, browser will re-request username/password. optional boolean false Whether authentication is required. By default, request will fail if the authentication cannot be verified. If set to false, request will process and this provider will abstain. principal-type SubjectType (USER, SERVICE) USER Principal type this provider extracts (and also propagates). qop Qop (NONE, AUTH) NONE Only AUTH supported. If left empty, uses the legacy approach (older RFC version). AUTH-INT is not supported. realm string Helidon Set the realm to use when challenging users. server-secret string &#160; The nonce is encrypted using this secret - to make sure the nonce we get back was generated by us and to make sure we can safely time-out nonce values. This secret must be the same for all service instances (or all services that want to share the same authentication). Defaults to a random password - e.g. if deployed to multiple servers, the authentication WILL NOT WORK. You MUST provide your own password to work in a distributed environment with non-sticky load balancing. users ConfigUser[&#93; &#160; Set user store to obtain passwords and roles based on logins. Example code <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - http-digest-auth: realm: \"helidon\" server-secret: \"${CLEAR=service-wide-secret-not-known-outside}\" users: - login: \"john\" password: \"${CLEAR=password}\" roles: [\"admin\"] - login: \"jack\" password: \"password\" roles: [\"user\", \"admin\"] How does it work? See https://tools.ietf.org/html/rfc7616 . Authentication of request When a request is received without the Authorization: digest &#8230;&#8203;. header, a challenge is returned to provide such authentication using WWW-Authenticate header. When a request is received with the Authorization: digest &#8230;&#8203;. header, the request is validated against configured users (and users obtained from custom service if any provided). Subject is created based on the username and roles provided by the user store. Custom user store Java service loader service io.helidon.security.providers.httpauth.spi.UserStoreService can be implemented to provide users to the provider, such as when validated against an internal database or LDAP server. The user store is defined so you never need the clear text password of the user. Note on security of HTTP Digest Authenticaton These authentication schemes should be obsolete , though they provide a very easy way to test a protected resource. ",
            "title": "HTTP Digest Authentication Provider"
        },
        {
            "location": "se/security/providers",
            "text": "<markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-header&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Setup"
        },
        {
            "location": "se/security/providers",
            "text": " Security provider that extracts a username (or service name) from a header. Type: io.helidon.security.providers.header.HeaderAtnProvider <markup lang=\"text\" title=\"Config key\" >header-atn This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthenticationProvider ",
            "title": "Overview"
        },
        {
            "location": "se/security/providers",
            "text": " Optional configuration options key type default value description atn-token TokenHandler &#160; Token handler to extract username from request. authenticate boolean true Whether to authenticate requests. optional boolean false Whether authentication is required. By default, request will fail if the username cannot be extracted. If set to false, request will process and this provider will abstain. outbound OutboundTarget[&#93; &#160; Configure outbound target for identity propagation. outbound-token TokenHandler &#160; Token handler to create outbound headers to propagate identity. If not defined, #atnTokenHandler will be used. principal-type SubjectType (USER, SERVICE) USER Principal type this provider extracts (and also propagates). propagate boolean false Whether to propagate identity. ",
            "title": "Configuration options"
        },
        {
            "location": "se/security/providers",
            "text": "<markup lang=\"yaml\" title=\"Configuration example\" >security: providers: header-atn: atn-token: header: \"X-AUTH-USER\" outbound: - name: \"internal-services\" hosts: [\"*.example.org\"] # propagates the current user or service id using the same header as authentication - name: \"partner-service\" hosts: [\"*.partner.org\"] # propagates an explicit username in a custom header username: \"service-27\" outbound-token: header: \"X-Service-Auth\" ",
            "title": "Example code"
        },
        {
            "location": "se/security/providers",
            "text": " This provider inspects a specified request header and extracts the username/service name from it and asserts it as current subject&#8217;s principal. This can be used when we use perimeter authentication (e.g. there is a gateway that takes care of authentication and propagates the user in a header). Identity propagation Identity is propagated only if an outbound target matches the target service. The following options exist when propagating identity: 1. We propagate the current username using the configured header 2. We use username associated with an outbound target (see example configuration above) Caution When using this provider, you must be sure the header cannot be explicitly configured by a user or another service. All requests should go through a gateway that removes this header from inbound traffic, and only configures it for authenticated users/services. Another option is to use this with fully trusted parties (such as services within a single company, on a single protected network not accessible to any users), and of course for testing and demo purposes. ",
            "title": "How does it work?"
        },
        {
            "location": "se/security/providers",
            "text": " Asserts user or service identity based on a value of a header. Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-header&lt;/artifactId&gt; &lt;/dependency&gt; Overview Security provider that extracts a username (or service name) from a header. Type: io.helidon.security.providers.header.HeaderAtnProvider <markup lang=\"text\" title=\"Config key\" >header-atn This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthenticationProvider Configuration options Optional configuration options key type default value description atn-token TokenHandler &#160; Token handler to extract username from request. authenticate boolean true Whether to authenticate requests. optional boolean false Whether authentication is required. By default, request will fail if the username cannot be extracted. If set to false, request will process and this provider will abstain. outbound OutboundTarget[&#93; &#160; Configure outbound target for identity propagation. outbound-token TokenHandler &#160; Token handler to create outbound headers to propagate identity. If not defined, #atnTokenHandler will be used. principal-type SubjectType (USER, SERVICE) USER Principal type this provider extracts (and also propagates). propagate boolean false Whether to propagate identity. Example code <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: header-atn: atn-token: header: \"X-AUTH-USER\" outbound: - name: \"internal-services\" hosts: [\"*.example.org\"] # propagates the current user or service id using the same header as authentication - name: \"partner-service\" hosts: [\"*.partner.org\"] # propagates an explicit username in a custom header username: \"service-27\" outbound-token: header: \"X-Service-Auth\" How does it work? This provider inspects a specified request header and extracts the username/service name from it and asserts it as current subject&#8217;s principal. This can be used when we use perimeter authentication (e.g. there is a gateway that takes care of authentication and propagates the user in a header). Identity propagation Identity is propagated only if an outbound target matches the target service. The following options exist when propagating identity: 1. We propagate the current username using the configured header 2. We use username associated with an outbound target (see example configuration above) Caution When using this provider, you must be sure the header cannot be explicitly configured by a user or another service. All requests should go through a gateway that removes this header from inbound traffic, and only configures it for authenticated users/services. Another option is to use this with fully trusted parties (such as services within a single company, on a single protected network not accessible to any users), and of course for testing and demo purposes. ",
            "title": "Header Authentication Provider"
        },
        {
            "location": "se/security/providers",
            "text": "<markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-http-sign&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Setup"
        },
        {
            "location": "se/security/providers",
            "text": " HTTP header signature provider. Type: io.helidon.security.providers.httpsign.HttpSignProvider <markup lang=\"text\" title=\"Config key\" >http-signatures This type provides the following service implementations: io.helidon.security.spi.AuthenticationProvider ",
            "title": "Overview"
        },
        {
            "location": "se/security/providers",
            "text": " Optional configuration options key type default value description backward-compatible-eol boolean false Enable support for Helidon versions before 3.0.0 (exclusive). Until version 3.0.0 (exclusive) there was a trailing end of line added to the signed data. To be able to communicate cross versions, we must configure this when talking to older versions of Helidon. Default value is `false`. In Helidon 2.x, this switch exists as well and the default is `true`, to allow communication between versions as needed. headers HttpSignHeader[&#93; (SIGNATURE, AUTHORIZATION, CUSTOM) &#160; Add a header that is validated on inbound requests. Provider may support more than one header to validate. inbound.keys InboundClientDefinition[&#93; &#160; Add inbound configuration. This is used to validate signature and authenticate the party. The same can be done through configuration: &lt;pre&gt; { name = \"http-signatures\" class = \"HttpSignProvider\" http-signatures { inbound { # This configures the InboundClientDefinition keys: [ { key-id = \"service1\" hmac.secret = \"${CLEAR=password}\" }] } } } &lt;/pre&gt; optional boolean true Set whether the signature is optional. If set to true (default), this provider will SecurityResponse.SecurityStatus#ABSTAIN from this request if signature is not present. If set to false, this provider will SecurityResponse.SecurityStatus#FAILURE fail if signature is not present. outbound OutboundConfig &#160; Add outbound targets to this builder. The targets are used to chose what to do for outbound communication. The targets should have OutboundTargetDefinition attached through OutboundTarget.Builder#customObject(Class, Object) to tell us how to sign the request. The same can be done through configuration: &lt;pre&gt; { name = \"http-signatures\" class = \"HttpSignProvider\" http-signatures { targets: [ { name = \"service2\" hosts = [\"localhost\"] paths = [\"/service2/.*\"] # This configures the OutboundTargetDefinition signature { key-id = \"service1\" hmac.secret = \"${CLEAR=password}\" } }] } } &lt;/pre&gt; realm string helidon Realm to use for challenging inbound requests that do not have \"Authorization\" header in case header is HttpSignHeader#AUTHORIZATION and singatures are not optional. sign-headers HeadersConfig[&#93; &#160; Override the default inbound required headers (e.g. headers that MUST be signed and headers that MUST be signed IF present). Defaults: get, head, delete methods: date, (request-target), host are mandatory; authorization if present (unless we are creating/validating the HttpSignHeader#AUTHORIZATION ourselves put, post: same as above, with addition of: content-length, content-type and digest if present for other methods: date, (request-target) Note that this provider DOES NOT validate the \"Digest\" HTTP header, only the signature. ",
            "title": "Configuration options"
        },
        {
            "location": "se/security/providers",
            "text": " See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - http-signatures: inbound: keys: - key-id: \"service1-hmac\" principal-name: \"Service1 - HMAC signature\" hmac.secret: \"${CLEAR=somePasswordForHmacShouldBeEncrypted}\" - key-id: \"service1-rsa\" principal-name: \"Service1 - RSA signature\" public-key: keystore: resource.path: \"src/main/resources/keystore.p12\" passphrase: \"password\" cert.alias: \"service_cert\" outbound: - name: \"service2-hmac\" hosts: [\"localhost\"] paths: [\"/service2\"] signature: key-id: \"service1-hmac\" hmac.secret: \"${CLEAR=somePasswordForHmacShouldBeEncrypted}\" - name: \"service2-rsa\" hosts: [\"localhost\"] paths: [\"/service2-rsa.*\"] signature: key-id: \"service1-rsa\" private-key: keystore: resource.path: \"src/main/resources/keystore.p12\" passphrase: \"password\" key.alias: \"myPrivateKey\" ",
            "title": "Example code"
        },
        {
            "location": "se/security/providers",
            "text": " standard: based on https://tools.ietf.org/html/draft-cavage-http-signatures-03 key-id: an arbitrary string used to locate signature configuration - when a request is received the provider locates validation configuration based on this id (e.g. HMAC shared secret or RSA public key). Commonly used meanings are: key fingerprint (RSA); API Key ",
            "title": "Signature basics"
        },
        {
            "location": "se/security/providers",
            "text": " Inbound Signatures We act as a server and another party is calling us with a signed HTTP request. We validate the signature and assume identity of the caller. Outbound Signatures We act as a client and we sign our outgoing requests. If there is a matching outbound target specified in configuration, its configuration will be applied for signing the outgoing request, otherwise there is no signature added ",
            "title": "How does it work?"
        },
        {
            "location": "se/security/providers",
            "text": " Support for HTTP Signatures. Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-http-sign&lt;/artifactId&gt; &lt;/dependency&gt; Overview HTTP header signature provider. Type: io.helidon.security.providers.httpsign.HttpSignProvider <markup lang=\"text\" title=\"Config key\" >http-signatures This type provides the following service implementations: io.helidon.security.spi.AuthenticationProvider Configuration options Optional configuration options key type default value description backward-compatible-eol boolean false Enable support for Helidon versions before 3.0.0 (exclusive). Until version 3.0.0 (exclusive) there was a trailing end of line added to the signed data. To be able to communicate cross versions, we must configure this when talking to older versions of Helidon. Default value is `false`. In Helidon 2.x, this switch exists as well and the default is `true`, to allow communication between versions as needed. headers HttpSignHeader[&#93; (SIGNATURE, AUTHORIZATION, CUSTOM) &#160; Add a header that is validated on inbound requests. Provider may support more than one header to validate. inbound.keys InboundClientDefinition[&#93; &#160; Add inbound configuration. This is used to validate signature and authenticate the party. The same can be done through configuration: &lt;pre&gt; { name = \"http-signatures\" class = \"HttpSignProvider\" http-signatures { inbound { # This configures the InboundClientDefinition keys: [ { key-id = \"service1\" hmac.secret = \"${CLEAR=password}\" }] } } } &lt;/pre&gt; optional boolean true Set whether the signature is optional. If set to true (default), this provider will SecurityResponse.SecurityStatus#ABSTAIN from this request if signature is not present. If set to false, this provider will SecurityResponse.SecurityStatus#FAILURE fail if signature is not present. outbound OutboundConfig &#160; Add outbound targets to this builder. The targets are used to chose what to do for outbound communication. The targets should have OutboundTargetDefinition attached through OutboundTarget.Builder#customObject(Class, Object) to tell us how to sign the request. The same can be done through configuration: &lt;pre&gt; { name = \"http-signatures\" class = \"HttpSignProvider\" http-signatures { targets: [ { name = \"service2\" hosts = [\"localhost\"] paths = [\"/service2/.*\"] # This configures the OutboundTargetDefinition signature { key-id = \"service1\" hmac.secret = \"${CLEAR=password}\" } }] } } &lt;/pre&gt; realm string helidon Realm to use for challenging inbound requests that do not have \"Authorization\" header in case header is HttpSignHeader#AUTHORIZATION and singatures are not optional. sign-headers HeadersConfig[&#93; &#160; Override the default inbound required headers (e.g. headers that MUST be signed and headers that MUST be signed IF present). Defaults: get, head, delete methods: date, (request-target), host are mandatory; authorization if present (unless we are creating/validating the HttpSignHeader#AUTHORIZATION ourselves put, post: same as above, with addition of: content-length, content-type and digest if present for other methods: date, (request-target) Note that this provider DOES NOT validate the \"Digest\" HTTP header, only the signature. Example code See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - http-signatures: inbound: keys: - key-id: \"service1-hmac\" principal-name: \"Service1 - HMAC signature\" hmac.secret: \"${CLEAR=somePasswordForHmacShouldBeEncrypted}\" - key-id: \"service1-rsa\" principal-name: \"Service1 - RSA signature\" public-key: keystore: resource.path: \"src/main/resources/keystore.p12\" passphrase: \"password\" cert.alias: \"service_cert\" outbound: - name: \"service2-hmac\" hosts: [\"localhost\"] paths: [\"/service2\"] signature: key-id: \"service1-hmac\" hmac.secret: \"${CLEAR=somePasswordForHmacShouldBeEncrypted}\" - name: \"service2-rsa\" hosts: [\"localhost\"] paths: [\"/service2-rsa.*\"] signature: key-id: \"service1-rsa\" private-key: keystore: resource.path: \"src/main/resources/keystore.p12\" passphrase: \"password\" key.alias: \"myPrivateKey\" Signature basics standard: based on https://tools.ietf.org/html/draft-cavage-http-signatures-03 key-id: an arbitrary string used to locate signature configuration - when a request is received the provider locates validation configuration based on this id (e.g. HMAC shared secret or RSA public key). Commonly used meanings are: key fingerprint (RSA); API Key How does it work? Inbound Signatures We act as a server and another party is calling us with a signed HTTP request. We validate the signature and assume identity of the caller. Outbound Signatures We act as a client and we sign our outgoing requests. If there is a matching outbound target specified in configuration, its configuration will be applied for signing the outgoing request, otherwise there is no signature added ",
            "title": "HTTP Signatures Provider"
        },
        {
            "location": "se/security/providers",
            "text": "<markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-idcs-mapper&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Setup"
        },
        {
            "location": "se/security/providers",
            "text": " IDCS role mapping provider Type: io.helidon.security.providers.idcs.mapper.IdcsRoleMapperRxProvider <markup lang=\"text\" title=\"Config key\" >idcs-role-mapper This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.SubjectMappingProvider ",
            "title": "Single-tenant IDCS Role Mapper"
        },
        {
            "location": "se/security/providers",
            "text": " Optional configuration options key type default value description cache-config EvictableCache &#160; Use explicit io.helidon.security.providers.common.EvictableCache for role caching. default-idcs-subject-type string user Configure subject type to use when requesting roles from IDCS. Can be either #IDCS_SUBJECT_TYPE_USER or #IDCS_SUBJECT_TYPE_CLIENT. Defaults to #IDCS_SUBJECT_TYPE_USER. oidc-config OidcConfig &#160; Use explicit io.helidon.security.providers.oidc.common.OidcConfig instance, e.g. when using it also for OIDC provider. subject-types SubjectType[&#93; (USER, SERVICE) USER Add a supported subject type. If none added, io.helidon.security.SubjectType#USER is used. If any added, only the ones added will be used (e.g. if you want to use both io.helidon.security.SubjectType#USER and io.helidon.security.SubjectType#SERVICE, both need to be added. ",
            "title": "Configuration options"
        },
        {
            "location": "se/security/providers",
            "text": " Multitenant IDCS role mapping provider Type: io.helidon.security.providers.idcs.mapper.IdcsMtRoleMapperRxProvider <markup lang=\"text\" title=\"Config key\" >idcs-role-mapper This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.SubjectMappingProvider ",
            "title": "Multi-tenant IDCS Role Mapper"
        },
        {
            "location": "se/security/providers",
            "text": " Optional configuration options key type default value description cache-config EvictableCache &#160; Use explicit io.helidon.security.providers.common.EvictableCache for role caching. default-idcs-subject-type string user Configure subject type to use when requesting roles from IDCS. Can be either #IDCS_SUBJECT_TYPE_USER or #IDCS_SUBJECT_TYPE_CLIENT. Defaults to #IDCS_SUBJECT_TYPE_USER. idcs-app-name-handler TokenHandler &#160; Configure token handler for IDCS Application name. By default the header IdcsMtRoleMapperRxProvider#IDCS_APP_HEADER is used. idcs-tenant-handler TokenHandler &#160; Configure token handler for IDCS Tenant ID. By default the header IdcsMtRoleMapperRxProvider#IDCS_TENANT_HEADER is used. oidc-config OidcConfig &#160; Use explicit io.helidon.security.providers.oidc.common.OidcConfig instance, e.g. when using it also for OIDC provider. subject-types SubjectType[&#93; (USER, SERVICE) USER Add a supported subject type. If none added, io.helidon.security.SubjectType#USER is used. If any added, only the ones added will be used (e.g. if you want to use both io.helidon.security.SubjectType#USER and io.helidon.security.SubjectType#SERVICE, both need to be added. ",
            "title": "Configuration options"
        },
        {
            "location": "se/security/providers",
            "text": " See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - idcs-role-mapper: multitenant: false oidc-config: client-id: \"client-id\" client-secret: \"client-secret\" identity-uri: \"IDCS identity server address\" ",
            "title": "Example code"
        },
        {
            "location": "se/security/providers",
            "text": " The provider asks the IDCS server to provide list of roles for the currently authenticated user. The result is cached for a certain period of time (see cache-config above). ",
            "title": "How does it work?"
        },
        {
            "location": "se/security/providers",
            "text": " A role mapper to retrieve roles from Oracle IDCS. Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-idcs-mapper&lt;/artifactId&gt; &lt;/dependency&gt; Single-tenant IDCS Role Mapper IDCS role mapping provider Type: io.helidon.security.providers.idcs.mapper.IdcsRoleMapperRxProvider <markup lang=\"text\" title=\"Config key\" >idcs-role-mapper This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.SubjectMappingProvider Configuration options Optional configuration options key type default value description cache-config EvictableCache &#160; Use explicit io.helidon.security.providers.common.EvictableCache for role caching. default-idcs-subject-type string user Configure subject type to use when requesting roles from IDCS. Can be either #IDCS_SUBJECT_TYPE_USER or #IDCS_SUBJECT_TYPE_CLIENT. Defaults to #IDCS_SUBJECT_TYPE_USER. oidc-config OidcConfig &#160; Use explicit io.helidon.security.providers.oidc.common.OidcConfig instance, e.g. when using it also for OIDC provider. subject-types SubjectType[&#93; (USER, SERVICE) USER Add a supported subject type. If none added, io.helidon.security.SubjectType#USER is used. If any added, only the ones added will be used (e.g. if you want to use both io.helidon.security.SubjectType#USER and io.helidon.security.SubjectType#SERVICE, both need to be added. Multi-tenant IDCS Role Mapper Multitenant IDCS role mapping provider Type: io.helidon.security.providers.idcs.mapper.IdcsMtRoleMapperRxProvider <markup lang=\"text\" title=\"Config key\" >idcs-role-mapper This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.SubjectMappingProvider Configuration options Optional configuration options key type default value description cache-config EvictableCache &#160; Use explicit io.helidon.security.providers.common.EvictableCache for role caching. default-idcs-subject-type string user Configure subject type to use when requesting roles from IDCS. Can be either #IDCS_SUBJECT_TYPE_USER or #IDCS_SUBJECT_TYPE_CLIENT. Defaults to #IDCS_SUBJECT_TYPE_USER. idcs-app-name-handler TokenHandler &#160; Configure token handler for IDCS Application name. By default the header IdcsMtRoleMapperRxProvider#IDCS_APP_HEADER is used. idcs-tenant-handler TokenHandler &#160; Configure token handler for IDCS Tenant ID. By default the header IdcsMtRoleMapperRxProvider#IDCS_TENANT_HEADER is used. oidc-config OidcConfig &#160; Use explicit io.helidon.security.providers.oidc.common.OidcConfig instance, e.g. when using it also for OIDC provider. subject-types SubjectType[&#93; (USER, SERVICE) USER Add a supported subject type. If none added, io.helidon.security.SubjectType#USER is used. If any added, only the ones added will be used (e.g. if you want to use both io.helidon.security.SubjectType#USER and io.helidon.security.SubjectType#SERVICE, both need to be added. Example code See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - idcs-role-mapper: multitenant: false oidc-config: client-id: \"client-id\" client-secret: \"client-secret\" identity-uri: \"IDCS identity server address\" How does it work? The provider asks the IDCS server to provide list of roles for the currently authenticated user. The result is cached for a certain period of time (see cache-config above). ",
            "title": "IDCS Role Mapper"
        },
        {
            "location": "se/security/providers",
            "text": " Attribute Based Access Control provider Type: io.helidon.security.providers.abac.AbacProvider <markup lang=\"text\" title=\"Config key\" >abac This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthorizationProvider ",
            "title": "Overview"
        },
        {
            "location": "se/security/providers",
            "text": " Optional configuration options key type default value description fail-if-none-validated boolean true Whether to fail if NONE of the attributes is validated. fail-on-unvalidated boolean true Whether to fail if any attribute is left unvalidated. ",
            "title": "Configuration options"
        },
        {
            "location": "se/security/providers",
            "text": "<markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-abac&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Dependency"
        },
        {
            "location": "se/security/providers",
            "text": " See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - abac: ",
            "title": "Examples"
        },
        {
            "location": "se/security/providers",
            "text": " The following table shows all configuration options of the provider and their default values key default value description fail-on-unvalidated true \"Unvalidated\" means: an attribute is defined, but there is no validator available for it fail-if-none-validated true \"None validated\" means: there was not a single attribute that was validated ",
            "title": "Configuration Options"
        },
        {
            "location": "se/security/providers",
            "text": " ABAC uses available validators and validates them against attributes of the authenticated user. Combinations of fail-on-unvalidated and fail-if-none-validated : true &amp; true : Will fail if any attribute is not validated and if any has failed validation false &amp; true : Will fail if there is one or more attributes present and NONE of them is validated or if any has failed validation, Will NOT fail if there is at least one validated attribute and any number of not validated attributes (and NONE failed) false &amp; false : Will fail if there is any attribute that failed validation, Will NOT fail if there are no failed validation or if there are NONE validated Any attribute of the following objects can be used: environment (such as time of request) - e.g. env.time.year subject (user) - e.g. subject.principal.id subject (service) - e.g. service.principal.id object (must be explicitly invoked by developer in code, as object cannot be automatically added to security context) - e.g. object.owner This provider checks that all defined ABAC validators are validated. If there is a definition for a validator that is not checked, the request is denied (depending on configuration as mentioned above). ABAC provider also allows an object to be used in authorization process, such as when evaluating if an object&#8217;s owner is the current user. The following example uses the Expression language validator to demonstrate the point in a JAX-RS resource: <markup lang=\"java\" title=\"Example of using an object\" >@Authenticated @Path(\"/abac\") public class AbacResource { @GET @Authorized(explicit = true) @PolicyStatement(\"${env.time.year &gt;= 2017 &amp;&amp; object.owner == subject.principal.id}\") public Response process(@Context SecurityContext context) { // probably looked up from a database SomeResource res = new SomeResource(\"user\"); AuthorizationResponse atzResponse = context.authorize(res); if (atzResponse.isPermitted()) { //do the update return Response.ok().entity(\"fine, sir\").build(); } else { return Response.status(Response.Status.FORBIDDEN) .entity(atzResponse.getDescription().orElse(\"Access not granted\")) .build(); } } } The following validators are implemented: Roles Scopes EL Policy ",
            "title": "Usage"
        },
        {
            "location": "se/security/providers",
            "text": " When using sub-resource locators in JAX-RS, the roles allowed are collected from each \"level\" of execution: - Application class annotations - Resource class annotations + resource method annotations - Sub-resource class annotations + sub-resource method annotations - Sub-resource class annotations + sub-resource method annotations (for every sub-resource on the path) The RolesAllowed or Roles annotation to be used is the last one in the path as defined above. Example 1: There is a RolesAllowed(\"admin\") defined on a sub-resource locator resource class. In this case the required role is admin . Example 2: There is a RolesAllowed(\"admin\") defined on a sub-resource locator resource class and a RolesAllowed(\"user\") defined on the method of the sub-resource that provides the response. In this case the required role is user . ",
            "title": "Interaction with JAX-RS Sub-Resource Locators"
        },
        {
            "location": "se/security/providers",
            "text": " Checks whether user/service is in either of the required role(s). Configuration Key: role-validator Annotations: @RolesAllowed , @RoleValidator.Roles <markup lang=\"yaml\" title=\"Configuration example for WebServer \" >security: web-server.paths: - path: \"/user[/{*}]\" roles-allowed: [\"user\"] <markup lang=\"java\" title=\"JAX-RS example\" >@RolesAllowed(\"user\") @RoleValidator.Roles(value = \"service_role\", subjectType = SubjectType.SERVICE) @Authenticated @Path(\"/abac\") public class AbacResource { } Interaction with JAX-RS Sub-Resource Locators When using sub-resource locators in JAX-RS, the roles allowed are collected from each \"level\" of execution: - Application class annotations - Resource class annotations + resource method annotations - Sub-resource class annotations + sub-resource method annotations - Sub-resource class annotations + sub-resource method annotations (for every sub-resource on the path) The RolesAllowed or Roles annotation to be used is the last one in the path as defined above. Example 1: There is a RolesAllowed(\"admin\") defined on a sub-resource locator resource class. In this case the required role is admin . Example 2: There is a RolesAllowed(\"admin\") defined on a sub-resource locator resource class and a RolesAllowed(\"user\") defined on the method of the sub-resource that provides the response. In this case the required role is user . ",
            "title": "Role Validator"
        },
        {
            "location": "se/security/providers",
            "text": " Checks whether user has all the required scopes. Configuration Key: scope-validator Annotations: @Scope <markup lang=\"yaml\" title=\"Configuration example for WebServer \" >security: web-server.paths: - path: \"/user[/{*}]\" abac.scopes: [\"calendar_read\", \"calendar_edit\"] <markup lang=\"java\" title=\"JAX-RS example\" >@Scope(\"calendar_read\") @Scope(\"calendar_edit\") @Authenticated @Path(\"/abac\") public class AbacResource { } ",
            "title": "Scope Validator"
        },
        {
            "location": "se/security/providers",
            "text": " Policy executor using Java EE policy expression language (EL) Configuration Key: policy-javax-el Annotations: @PolicyStatement Example of a policy statement: ${env.time.year &gt;= 2017} <markup lang=\"yaml\" title=\"Configuration example for WebServer \" >security: web-server.paths: - path: \"/user[/{*}]\" policy: statement: \"hasScopes('calendar_read','calendar_edit') AND timeOfDayBetween('8:15', '17:30')\" <markup lang=\"java\" title=\"JAX-RS example\" >@PolicyStatement(\"${env.time.year &gt;= 2017}\") @Authenticated @Path(\"/abac\") public class AbacResource { } ",
            "title": "Expression Language Policy Validator"
        },
        {
            "location": "se/security/providers",
            "text": " Attribute-based Access Control (ABAC) authorization provider provides security and authorization service implementations. Overview Attribute Based Access Control provider Type: io.helidon.security.providers.abac.AbacProvider <markup lang=\"text\" title=\"Config key\" >abac This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthorizationProvider Configuration options Optional configuration options key type default value description fail-if-none-validated boolean true Whether to fail if NONE of the attributes is validated. fail-on-unvalidated boolean true Whether to fail if any attribute is left unvalidated. Maven Dependency <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-abac&lt;/artifactId&gt; &lt;/dependency&gt; Examples See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - abac: Configuration Options The following table shows all configuration options of the provider and their default values key default value description fail-on-unvalidated true \"Unvalidated\" means: an attribute is defined, but there is no validator available for it fail-if-none-validated true \"None validated\" means: there was not a single attribute that was validated Usage ABAC uses available validators and validates them against attributes of the authenticated user. Combinations of fail-on-unvalidated and fail-if-none-validated : true &amp; true : Will fail if any attribute is not validated and if any has failed validation false &amp; true : Will fail if there is one or more attributes present and NONE of them is validated or if any has failed validation, Will NOT fail if there is at least one validated attribute and any number of not validated attributes (and NONE failed) false &amp; false : Will fail if there is any attribute that failed validation, Will NOT fail if there are no failed validation or if there are NONE validated Any attribute of the following objects can be used: environment (such as time of request) - e.g. env.time.year subject (user) - e.g. subject.principal.id subject (service) - e.g. service.principal.id object (must be explicitly invoked by developer in code, as object cannot be automatically added to security context) - e.g. object.owner This provider checks that all defined ABAC validators are validated. If there is a definition for a validator that is not checked, the request is denied (depending on configuration as mentioned above). ABAC provider also allows an object to be used in authorization process, such as when evaluating if an object&#8217;s owner is the current user. The following example uses the Expression language validator to demonstrate the point in a JAX-RS resource: <markup lang=\"java\" title=\"Example of using an object\" >@Authenticated @Path(\"/abac\") public class AbacResource { @GET @Authorized(explicit = true) @PolicyStatement(\"${env.time.year &gt;= 2017 &amp;&amp; object.owner == subject.principal.id}\") public Response process(@Context SecurityContext context) { // probably looked up from a database SomeResource res = new SomeResource(\"user\"); AuthorizationResponse atzResponse = context.authorize(res); if (atzResponse.isPermitted()) { //do the update return Response.ok().entity(\"fine, sir\").build(); } else { return Response.status(Response.Status.FORBIDDEN) .entity(atzResponse.getDescription().orElse(\"Access not granted\")) .build(); } } } The following validators are implemented: Roles Scopes EL Policy Role Validator Checks whether user/service is in either of the required role(s). Configuration Key: role-validator Annotations: @RolesAllowed , @RoleValidator.Roles <markup lang=\"yaml\" title=\"Configuration example for WebServer \" >security: web-server.paths: - path: \"/user[/{*}]\" roles-allowed: [\"user\"] <markup lang=\"java\" title=\"JAX-RS example\" >@RolesAllowed(\"user\") @RoleValidator.Roles(value = \"service_role\", subjectType = SubjectType.SERVICE) @Authenticated @Path(\"/abac\") public class AbacResource { } Interaction with JAX-RS Sub-Resource Locators When using sub-resource locators in JAX-RS, the roles allowed are collected from each \"level\" of execution: - Application class annotations - Resource class annotations + resource method annotations - Sub-resource class annotations + sub-resource method annotations - Sub-resource class annotations + sub-resource method annotations (for every sub-resource on the path) The RolesAllowed or Roles annotation to be used is the last one in the path as defined above. Example 1: There is a RolesAllowed(\"admin\") defined on a sub-resource locator resource class. In this case the required role is admin . Example 2: There is a RolesAllowed(\"admin\") defined on a sub-resource locator resource class and a RolesAllowed(\"user\") defined on the method of the sub-resource that provides the response. In this case the required role is user . Scope Validator Checks whether user has all the required scopes. Configuration Key: scope-validator Annotations: @Scope <markup lang=\"yaml\" title=\"Configuration example for WebServer \" >security: web-server.paths: - path: \"/user[/{*}]\" abac.scopes: [\"calendar_read\", \"calendar_edit\"] <markup lang=\"java\" title=\"JAX-RS example\" >@Scope(\"calendar_read\") @Scope(\"calendar_edit\") @Authenticated @Path(\"/abac\") public class AbacResource { } Expression Language Policy Validator Policy executor using Java EE policy expression language (EL) Configuration Key: policy-javax-el Annotations: @PolicyStatement Example of a policy statement: ${env.time.year &gt;= 2017} <markup lang=\"yaml\" title=\"Configuration example for WebServer \" >security: web-server.paths: - path: \"/user[/{*}]\" policy: statement: \"hasScopes('calendar_read','calendar_edit') AND timeOfDayBetween('8:15', '17:30')\" <markup lang=\"java\" title=\"JAX-RS example\" >@PolicyStatement(\"${env.time.year &gt;= 2017}\") @Authenticated @Path(\"/abac\") public class AbacResource { } ",
            "title": "ABAC Provider"
        },
        {
            "location": "se/security/providers",
            "text": "<markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-google-login&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Setup"
        },
        {
            "location": "se/security/providers",
            "text": " Google Authentication provider Type: io.helidon.security.providers.google.login.GoogleTokenProvider <markup lang=\"text\" title=\"Config key\" >google-login This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthenticationProvider ",
            "title": "Overview"
        },
        {
            "location": "se/security/providers",
            "text": " Optional configuration options key type default value description client-id string &#160; Google application client id, to validate that the token was generated by Google for us. optional boolean false If set to true, this provider will return io.helidon.security.SecurityResponse.SecurityStatus#ABSTAIN instead of failing in case of invalid request. outbound OutboundConfig &#160; Outbound configuration - a set of outbound targets that will have the token propagated. proxy-host string &#160; Set proxy host when talking to Google. proxy-port int 80 Set proxy port when talking to Google. realm string helidon Set the authentication realm to build challenge, defaults to \"helidon\". token TokenHandler &#x60;Authorization&#x60; header with &#x60;bearer&#x60; prefix Token provider to extract Google access token from request, defaults to \"Authorization\" header with a \"bearer \" prefix. ",
            "title": "Configuration options"
        },
        {
            "location": "se/security/providers",
            "text": " See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - provider: client-id: \"Google client id\" ",
            "title": "Example code"
        },
        {
            "location": "se/security/providers",
            "text": " We expect to receive a token (with sufficient scopes) from the inbound request, such as when using the Google login button on a page. The page has access to the token in javascript and can send it to backend with every request in a header field ( Authorization with `bearer ` prefix is assumed by default). Once we receive the token in Helidon, we parse it and: Validate if it timed out locally Return a cached response (see EvictableCache with default values) Otherwise verify using Google API - GoogleIdTokenVerifier We build a subject from the Google token with the following attributes filled (if in token): userId email name emailVerified locale family_name given_name picture (URL) Outbound security The token will be propagated to outbound calls if an outbound target exists that matches the invoked endpoint (see outbound configuration above). ",
            "title": "How does it work?"
        },
        {
            "location": "se/security/providers",
            "text": " Authenticates a token from request against Google identity provider Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-google-login&lt;/artifactId&gt; &lt;/dependency&gt; Overview Google Authentication provider Type: io.helidon.security.providers.google.login.GoogleTokenProvider <markup lang=\"text\" title=\"Config key\" >google-login This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthenticationProvider Configuration options Optional configuration options key type default value description client-id string &#160; Google application client id, to validate that the token was generated by Google for us. optional boolean false If set to true, this provider will return io.helidon.security.SecurityResponse.SecurityStatus#ABSTAIN instead of failing in case of invalid request. outbound OutboundConfig &#160; Outbound configuration - a set of outbound targets that will have the token propagated. proxy-host string &#160; Set proxy host when talking to Google. proxy-port int 80 Set proxy port when talking to Google. realm string helidon Set the authentication realm to build challenge, defaults to \"helidon\". token TokenHandler &#x60;Authorization&#x60; header with &#x60;bearer&#x60; prefix Token provider to extract Google access token from request, defaults to \"Authorization\" header with a \"bearer \" prefix. Example code See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - provider: client-id: \"Google client id\" How does it work? We expect to receive a token (with sufficient scopes) from the inbound request, such as when using the Google login button on a page. The page has access to the token in javascript and can send it to backend with every request in a header field ( Authorization with `bearer ` prefix is assumed by default). Once we receive the token in Helidon, we parse it and: Validate if it timed out locally Return a cached response (see EvictableCache with default values) Otherwise verify using Google API - GoogleIdTokenVerifier We build a subject from the Google token with the following attributes filled (if in token): userId email name emailVerified locale family_name given_name picture (URL) Outbound security The token will be propagated to outbound calls if an outbound target exists that matches the invoked endpoint (see outbound configuration above). ",
            "title": "Google Login Provider"
        },
        {
            "location": "se/security/providers",
            "text": "<markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-jwt&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Setup"
        },
        {
            "location": "se/security/providers",
            "text": " JWT authentication provider Type: io.helidon.security.providers.jwt.JwtProvider <markup lang=\"text\" title=\"Config key\" >jwt This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthenticationProvider ",
            "title": "Overview"
        },
        {
            "location": "se/security/providers",
            "text": " Optional configuration options key type default value description allow-impersonation boolean false Whether to allow impersonation by explicitly overriding username from outbound requests using #EP_PROPERTY_OUTBOUND_USER property. By default this is not allowed and identity can only be propagated. allow-unsigned boolean false Configure support for unsigned JWT. If this is set to true any JWT that has algorithm set to none and no kid defined will be accepted. Note that this has serious security impact - if JWT can be sent from a third party, this allows the third party to send ANY JWT and it would be accpted as valid. atn-token.handler TokenHandler &#160; Token handler to extract username from request. atn-token.jwk.resource Resource &#160; JWK resource used to verify JWTs created by other parties. atn-token.jwt-audience string &#160; Audience expected in inbound JWTs. atn-token.verify-signature boolean true Configure whether to verify signatures. Signatures verification is enabled by default. You can configure the provider not to verify signatures. &lt;b&gt;Make sure your service is properly secured on network level and only accessible from a secure endpoint that provides the JWTs when signature verification is disabled. If signature verification is disabled, this service will accept &lt;i&gt;ANY&lt;/i&gt; JWT&lt;/b&gt; authenticate boolean true Whether to authenticate requests. optional boolean false Whether authentication is required. By default, request will fail if the username cannot be extracted. If set to false, request will process and this provider will abstain. principal-type SubjectType (USER, SERVICE) USER Principal type this provider extracts (and also propagates). propagate boolean true Whether to propagate identity. sign-token OutboundConfig &#160; Configuration of outbound rules. sign-token.jwk.resource Resource &#160; JWK resource used to sign JWTs created by us. sign-token.jwt-issuer string &#160; Issuer used to create new JWTs. use-jwt-groups boolean true Claim groups from JWT will be used to automatically add groups to current subject (may be used with jakarta.annotation.security.RolesAllowed annotation). ",
            "title": "Configuration options"
        },
        {
            "location": "se/security/providers",
            "text": " See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - provider: atn-token: jwk.resource.resource-path: \"verifying-jwk.json\" jwt-audience: \"http://my.service\" sign-token: jwk.resource.resource-path: \"signing-jwk.json\" jwt-issuer: \"http://my.server/identity\" outbound: - name: \"propagate-token\" hosts: [\"*.internal.org\"] - name: \"generate-token\" hosts: [\"1.partner-service\"] jwk-kid: \"partner-1\" jwt-kid: \"helidon\" jwt-audience: \"http://1.partner-service\" ",
            "title": "Example code"
        },
        {
            "location": "se/security/providers",
            "text": " JSON Web Token (JWT) provider has support for authentication and outbound security. Authentication is based on validating the token (signature, valid before etc.) and on asserting the subject of the JWT subject claim. For outbound, we support either token propagation (e.g. the token from request is propagated further) or support for generating a brand new token based on configuration of this provider. ",
            "title": "How does it work?"
        },
        {
            "location": "se/security/providers",
            "text": " JWT token authentication and outbound security provider. Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-jwt&lt;/artifactId&gt; &lt;/dependency&gt; Overview JWT authentication provider Type: io.helidon.security.providers.jwt.JwtProvider <markup lang=\"text\" title=\"Config key\" >jwt This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthenticationProvider Configuration options Optional configuration options key type default value description allow-impersonation boolean false Whether to allow impersonation by explicitly overriding username from outbound requests using #EP_PROPERTY_OUTBOUND_USER property. By default this is not allowed and identity can only be propagated. allow-unsigned boolean false Configure support for unsigned JWT. If this is set to true any JWT that has algorithm set to none and no kid defined will be accepted. Note that this has serious security impact - if JWT can be sent from a third party, this allows the third party to send ANY JWT and it would be accpted as valid. atn-token.handler TokenHandler &#160; Token handler to extract username from request. atn-token.jwk.resource Resource &#160; JWK resource used to verify JWTs created by other parties. atn-token.jwt-audience string &#160; Audience expected in inbound JWTs. atn-token.verify-signature boolean true Configure whether to verify signatures. Signatures verification is enabled by default. You can configure the provider not to verify signatures. &lt;b&gt;Make sure your service is properly secured on network level and only accessible from a secure endpoint that provides the JWTs when signature verification is disabled. If signature verification is disabled, this service will accept &lt;i&gt;ANY&lt;/i&gt; JWT&lt;/b&gt; authenticate boolean true Whether to authenticate requests. optional boolean false Whether authentication is required. By default, request will fail if the username cannot be extracted. If set to false, request will process and this provider will abstain. principal-type SubjectType (USER, SERVICE) USER Principal type this provider extracts (and also propagates). propagate boolean true Whether to propagate identity. sign-token OutboundConfig &#160; Configuration of outbound rules. sign-token.jwk.resource Resource &#160; JWK resource used to sign JWTs created by us. sign-token.jwt-issuer string &#160; Issuer used to create new JWTs. use-jwt-groups boolean true Claim groups from JWT will be used to automatically add groups to current subject (may be used with jakarta.annotation.security.RolesAllowed annotation). Example code See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - provider: atn-token: jwk.resource.resource-path: \"verifying-jwk.json\" jwt-audience: \"http://my.service\" sign-token: jwk.resource.resource-path: \"signing-jwk.json\" jwt-issuer: \"http://my.server/identity\" outbound: - name: \"propagate-token\" hosts: [\"*.internal.org\"] - name: \"generate-token\" hosts: [\"1.partner-service\"] jwk-kid: \"partner-1\" jwt-kid: \"helidon\" jwt-audience: \"http://1.partner-service\" How does it work? JSON Web Token (JWT) provider has support for authentication and outbound security. Authentication is based on validating the token (signature, valid before etc.) and on asserting the subject of the JWT subject claim. For outbound, we support either token propagation (e.g. the token from request is propagated further) or support for generating a brand new token based on configuration of this provider. ",
            "title": "JWT Provider"
        },
        {
            "location": "se/security/providers",
            "text": " As an experimental feature, you can set up cross-origin handling for the redirect and logout endpoints in an optional cors block inside the oidc configuration. The table below lists the configuration keys that identify the CORS characteristics. include::[tag=cors-config-table] The following example of basic cross-origin configuration, when loaded and used by the application, limits cross-origin resource sharing for PUT and DELETE operations to only foo.com and there.com : <markup lang=\"yaml\" >restrictive-cors: allow-origins: [\"http://foo.com\", \"http://there.com\"] allow-methods: [\"PUT\", \"DELETE\"] HTTP Basic Authentication Provider HTTP Basic authentication support Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-http-auth&lt;/artifactId&gt; &lt;/dependency&gt; Overview HTTP Basic Authentication provider Type: io.helidon.security.providers.httpauth.HttpBasicAuthProvider <markup lang=\"text\" title=\"Config key\" >http-basic-auth This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthenticationProvider Configuration options Optional configuration options key type default value description optional boolean false Whether authentication is required. By default, request will fail if the authentication cannot be verified. If set to false, request will process and this provider will abstain. outbound OutboundTarget[&#93; &#160; Add a new outbound target to configure identity propagation or explicit username/password. principal-type SubjectType (USER, SERVICE) USER Principal type this provider extracts (and also propagates). realm string helidon Set the realm to use when challenging users. users ConfigUser[&#93; &#160; Set user store to validate users. Removes any other stores added through #addUserStore(SecureUserStore). Example code See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - http-basic-auth: realm: \"helidon\" users: - login: \"john\" password: \"${CLEAR=password}\" roles: [\"admin\"] - login: \"jack\" password: \"password\" roles: [\"user\", \"admin\"] outbound: - name: \"internal-services\" hosts: [\"*.example.org\"] # Propagates current user's identity or identity from request property outbound-token: header: \"X-Internal-Auth\" - name: \"partner-service\" hosts: [\"*.partner.org\"] # Uses this username and password username: \"partner-user-1\" password: \"${CLEAR=password}\" How does it work? See https://tools.ietf.org/html/rfc7617 . Authentication of request When a request is received without the Authorization: basic &#8230;&#8203;. header, a challenge is returned to provide such authentication. When a request is received with the Authorization: basic &#8230;&#8203;. header, the username and password is validated against configured users (and users obtained from custom service if any provided). Subject is created based on the username and roles provided by the user store. Identity propagation When identity propagation is configured, there are several options for identifying username and password to propagate: We propagate the current username and password (inbound request must be authenticated using basic authentication). We use username and password from an explicitly configured property (See HttpBasicAuthProvider.EP_PROPERTY_OUTBOUND_USER and HttpBasicAuthProvider.EP_PROPERTY_OUTBOUND_PASSWORD ) We use username and password associated with an outbound target (see example configuration above) Identity is propagated only if: There is an outbound target configured for the endpoint Or there is an explicitly configured username/password for the current request (through request property) Custom user store Java service loader service io.helidon.security.providers.httpauth.spi.UserStoreService can be implemented to provide users to the provider, such as when validated against an internal database or LDAP server. The user store is defined so you never need the clear text password of the user. Warning on security of HTTP Basic Authenticaton (or lack thereof) Basic authentication uses base64 encoded username and password and passes it over the network. Base64 is only encoding, not encryption - so anybody that gets hold of the header value can learn the actual username and password of the user. This is a security risk and an attack vector that everybody should be aware of before using HTTP Basic Authentication. We recommend using this approach only for testing and demo purposes. HTTP Digest Authentication Provider HTTP Digest authentication support Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-http-auth&lt;/artifactId&gt; &lt;/dependency&gt; Overview Http digest authentication security provider Type: io.helidon.security.providers.httpauth.HttpDigestAuthProvider <markup lang=\"text\" title=\"Config key\" >http-digest-auth This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthenticationProvider Configuration options Optional configuration options key type default value description algorithm Algorithm (MD5) MD5 Digest algorithm to use. nonce-timeout-millis long 86400000 How long will the nonce value be valid. When timed-out, browser will re-request username/password. optional boolean false Whether authentication is required. By default, request will fail if the authentication cannot be verified. If set to false, request will process and this provider will abstain. principal-type SubjectType (USER, SERVICE) USER Principal type this provider extracts (and also propagates). qop Qop (NONE, AUTH) NONE Only AUTH supported. If left empty, uses the legacy approach (older RFC version). AUTH-INT is not supported. realm string Helidon Set the realm to use when challenging users. server-secret string &#160; The nonce is encrypted using this secret - to make sure the nonce we get back was generated by us and to make sure we can safely time-out nonce values. This secret must be the same for all service instances (or all services that want to share the same authentication). Defaults to a random password - e.g. if deployed to multiple servers, the authentication WILL NOT WORK. You MUST provide your own password to work in a distributed environment with non-sticky load balancing. users ConfigUser[&#93; &#160; Set user store to obtain passwords and roles based on logins. Example code <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - http-digest-auth: realm: \"helidon\" server-secret: \"${CLEAR=service-wide-secret-not-known-outside}\" users: - login: \"john\" password: \"${CLEAR=password}\" roles: [\"admin\"] - login: \"jack\" password: \"password\" roles: [\"user\", \"admin\"] How does it work? See https://tools.ietf.org/html/rfc7616 . Authentication of request When a request is received without the Authorization: digest &#8230;&#8203;. header, a challenge is returned to provide such authentication using WWW-Authenticate header. When a request is received with the Authorization: digest &#8230;&#8203;. header, the request is validated against configured users (and users obtained from custom service if any provided). Subject is created based on the username and roles provided by the user store. Custom user store Java service loader service io.helidon.security.providers.httpauth.spi.UserStoreService can be implemented to provide users to the provider, such as when validated against an internal database or LDAP server. The user store is defined so you never need the clear text password of the user. Note on security of HTTP Digest Authenticaton These authentication schemes should be obsolete , though they provide a very easy way to test a protected resource. Header Authentication Provider Asserts user or service identity based on a value of a header. Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-header&lt;/artifactId&gt; &lt;/dependency&gt; Overview Security provider that extracts a username (or service name) from a header. Type: io.helidon.security.providers.header.HeaderAtnProvider <markup lang=\"text\" title=\"Config key\" >header-atn This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthenticationProvider Configuration options Optional configuration options key type default value description atn-token TokenHandler &#160; Token handler to extract username from request. authenticate boolean true Whether to authenticate requests. optional boolean false Whether authentication is required. By default, request will fail if the username cannot be extracted. If set to false, request will process and this provider will abstain. outbound OutboundTarget[&#93; &#160; Configure outbound target for identity propagation. outbound-token TokenHandler &#160; Token handler to create outbound headers to propagate identity. If not defined, #atnTokenHandler will be used. principal-type SubjectType (USER, SERVICE) USER Principal type this provider extracts (and also propagates). propagate boolean false Whether to propagate identity. Example code <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: header-atn: atn-token: header: \"X-AUTH-USER\" outbound: - name: \"internal-services\" hosts: [\"*.example.org\"] # propagates the current user or service id using the same header as authentication - name: \"partner-service\" hosts: [\"*.partner.org\"] # propagates an explicit username in a custom header username: \"service-27\" outbound-token: header: \"X-Service-Auth\" How does it work? This provider inspects a specified request header and extracts the username/service name from it and asserts it as current subject&#8217;s principal. This can be used when we use perimeter authentication (e.g. there is a gateway that takes care of authentication and propagates the user in a header). Identity propagation Identity is propagated only if an outbound target matches the target service. The following options exist when propagating identity: 1. We propagate the current username using the configured header 2. We use username associated with an outbound target (see example configuration above) Caution When using this provider, you must be sure the header cannot be explicitly configured by a user or another service. All requests should go through a gateway that removes this header from inbound traffic, and only configures it for authenticated users/services. Another option is to use this with fully trusted parties (such as services within a single company, on a single protected network not accessible to any users), and of course for testing and demo purposes. HTTP Signatures Provider Support for HTTP Signatures. Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-http-sign&lt;/artifactId&gt; &lt;/dependency&gt; Overview HTTP header signature provider. Type: io.helidon.security.providers.httpsign.HttpSignProvider <markup lang=\"text\" title=\"Config key\" >http-signatures This type provides the following service implementations: io.helidon.security.spi.AuthenticationProvider Configuration options Optional configuration options key type default value description backward-compatible-eol boolean false Enable support for Helidon versions before 3.0.0 (exclusive). Until version 3.0.0 (exclusive) there was a trailing end of line added to the signed data. To be able to communicate cross versions, we must configure this when talking to older versions of Helidon. Default value is `false`. In Helidon 2.x, this switch exists as well and the default is `true`, to allow communication between versions as needed. headers HttpSignHeader[&#93; (SIGNATURE, AUTHORIZATION, CUSTOM) &#160; Add a header that is validated on inbound requests. Provider may support more than one header to validate. inbound.keys InboundClientDefinition[&#93; &#160; Add inbound configuration. This is used to validate signature and authenticate the party. The same can be done through configuration: &lt;pre&gt; { name = \"http-signatures\" class = \"HttpSignProvider\" http-signatures { inbound { # This configures the InboundClientDefinition keys: [ { key-id = \"service1\" hmac.secret = \"${CLEAR=password}\" }] } } } &lt;/pre&gt; optional boolean true Set whether the signature is optional. If set to true (default), this provider will SecurityResponse.SecurityStatus#ABSTAIN from this request if signature is not present. If set to false, this provider will SecurityResponse.SecurityStatus#FAILURE fail if signature is not present. outbound OutboundConfig &#160; Add outbound targets to this builder. The targets are used to chose what to do for outbound communication. The targets should have OutboundTargetDefinition attached through OutboundTarget.Builder#customObject(Class, Object) to tell us how to sign the request. The same can be done through configuration: &lt;pre&gt; { name = \"http-signatures\" class = \"HttpSignProvider\" http-signatures { targets: [ { name = \"service2\" hosts = [\"localhost\"] paths = [\"/service2/.*\"] # This configures the OutboundTargetDefinition signature { key-id = \"service1\" hmac.secret = \"${CLEAR=password}\" } }] } } &lt;/pre&gt; realm string helidon Realm to use for challenging inbound requests that do not have \"Authorization\" header in case header is HttpSignHeader#AUTHORIZATION and singatures are not optional. sign-headers HeadersConfig[&#93; &#160; Override the default inbound required headers (e.g. headers that MUST be signed and headers that MUST be signed IF present). Defaults: get, head, delete methods: date, (request-target), host are mandatory; authorization if present (unless we are creating/validating the HttpSignHeader#AUTHORIZATION ourselves put, post: same as above, with addition of: content-length, content-type and digest if present for other methods: date, (request-target) Note that this provider DOES NOT validate the \"Digest\" HTTP header, only the signature. Example code See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - http-signatures: inbound: keys: - key-id: \"service1-hmac\" principal-name: \"Service1 - HMAC signature\" hmac.secret: \"${CLEAR=somePasswordForHmacShouldBeEncrypted}\" - key-id: \"service1-rsa\" principal-name: \"Service1 - RSA signature\" public-key: keystore: resource.path: \"src/main/resources/keystore.p12\" passphrase: \"password\" cert.alias: \"service_cert\" outbound: - name: \"service2-hmac\" hosts: [\"localhost\"] paths: [\"/service2\"] signature: key-id: \"service1-hmac\" hmac.secret: \"${CLEAR=somePasswordForHmacShouldBeEncrypted}\" - name: \"service2-rsa\" hosts: [\"localhost\"] paths: [\"/service2-rsa.*\"] signature: key-id: \"service1-rsa\" private-key: keystore: resource.path: \"src/main/resources/keystore.p12\" passphrase: \"password\" key.alias: \"myPrivateKey\" Signature basics standard: based on https://tools.ietf.org/html/draft-cavage-http-signatures-03 key-id: an arbitrary string used to locate signature configuration - when a request is received the provider locates validation configuration based on this id (e.g. HMAC shared secret or RSA public key). Commonly used meanings are: key fingerprint (RSA); API Key How does it work? Inbound Signatures We act as a server and another party is calling us with a signed HTTP request. We validate the signature and assume identity of the caller. Outbound Signatures We act as a client and we sign our outgoing requests. If there is a matching outbound target specified in configuration, its configuration will be applied for signing the outgoing request, otherwise there is no signature added IDCS Role Mapper A role mapper to retrieve roles from Oracle IDCS. Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-idcs-mapper&lt;/artifactId&gt; &lt;/dependency&gt; Single-tenant IDCS Role Mapper IDCS role mapping provider Type: io.helidon.security.providers.idcs.mapper.IdcsRoleMapperRxProvider <markup lang=\"text\" title=\"Config key\" >idcs-role-mapper This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.SubjectMappingProvider Configuration options Optional configuration options key type default value description cache-config EvictableCache &#160; Use explicit io.helidon.security.providers.common.EvictableCache for role caching. default-idcs-subject-type string user Configure subject type to use when requesting roles from IDCS. Can be either #IDCS_SUBJECT_TYPE_USER or #IDCS_SUBJECT_TYPE_CLIENT. Defaults to #IDCS_SUBJECT_TYPE_USER. oidc-config OidcConfig &#160; Use explicit io.helidon.security.providers.oidc.common.OidcConfig instance, e.g. when using it also for OIDC provider. subject-types SubjectType[&#93; (USER, SERVICE) USER Add a supported subject type. If none added, io.helidon.security.SubjectType#USER is used. If any added, only the ones added will be used (e.g. if you want to use both io.helidon.security.SubjectType#USER and io.helidon.security.SubjectType#SERVICE, both need to be added. Multi-tenant IDCS Role Mapper Multitenant IDCS role mapping provider Type: io.helidon.security.providers.idcs.mapper.IdcsMtRoleMapperRxProvider <markup lang=\"text\" title=\"Config key\" >idcs-role-mapper This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.SubjectMappingProvider Configuration options Optional configuration options key type default value description cache-config EvictableCache &#160; Use explicit io.helidon.security.providers.common.EvictableCache for role caching. default-idcs-subject-type string user Configure subject type to use when requesting roles from IDCS. Can be either #IDCS_SUBJECT_TYPE_USER or #IDCS_SUBJECT_TYPE_CLIENT. Defaults to #IDCS_SUBJECT_TYPE_USER. idcs-app-name-handler TokenHandler &#160; Configure token handler for IDCS Application name. By default the header IdcsMtRoleMapperRxProvider#IDCS_APP_HEADER is used. idcs-tenant-handler TokenHandler &#160; Configure token handler for IDCS Tenant ID. By default the header IdcsMtRoleMapperRxProvider#IDCS_TENANT_HEADER is used. oidc-config OidcConfig &#160; Use explicit io.helidon.security.providers.oidc.common.OidcConfig instance, e.g. when using it also for OIDC provider. subject-types SubjectType[&#93; (USER, SERVICE) USER Add a supported subject type. If none added, io.helidon.security.SubjectType#USER is used. If any added, only the ones added will be used (e.g. if you want to use both io.helidon.security.SubjectType#USER and io.helidon.security.SubjectType#SERVICE, both need to be added. Example code See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - idcs-role-mapper: multitenant: false oidc-config: client-id: \"client-id\" client-secret: \"client-secret\" identity-uri: \"IDCS identity server address\" How does it work? The provider asks the IDCS server to provide list of roles for the currently authenticated user. The result is cached for a certain period of time (see cache-config above). ABAC Provider Attribute-based Access Control (ABAC) authorization provider provides security and authorization service implementations. Overview Attribute Based Access Control provider Type: io.helidon.security.providers.abac.AbacProvider <markup lang=\"text\" title=\"Config key\" >abac This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthorizationProvider Configuration options Optional configuration options key type default value description fail-if-none-validated boolean true Whether to fail if NONE of the attributes is validated. fail-on-unvalidated boolean true Whether to fail if any attribute is left unvalidated. Maven Dependency <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-abac&lt;/artifactId&gt; &lt;/dependency&gt; Examples See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - abac: Configuration Options The following table shows all configuration options of the provider and their default values key default value description fail-on-unvalidated true \"Unvalidated\" means: an attribute is defined, but there is no validator available for it fail-if-none-validated true \"None validated\" means: there was not a single attribute that was validated Usage ABAC uses available validators and validates them against attributes of the authenticated user. Combinations of fail-on-unvalidated and fail-if-none-validated : true &amp; true : Will fail if any attribute is not validated and if any has failed validation false &amp; true : Will fail if there is one or more attributes present and NONE of them is validated or if any has failed validation, Will NOT fail if there is at least one validated attribute and any number of not validated attributes (and NONE failed) false &amp; false : Will fail if there is any attribute that failed validation, Will NOT fail if there are no failed validation or if there are NONE validated Any attribute of the following objects can be used: environment (such as time of request) - e.g. env.time.year subject (user) - e.g. subject.principal.id subject (service) - e.g. service.principal.id object (must be explicitly invoked by developer in code, as object cannot be automatically added to security context) - e.g. object.owner This provider checks that all defined ABAC validators are validated. If there is a definition for a validator that is not checked, the request is denied (depending on configuration as mentioned above). ABAC provider also allows an object to be used in authorization process, such as when evaluating if an object&#8217;s owner is the current user. The following example uses the Expression language validator to demonstrate the point in a JAX-RS resource: <markup lang=\"java\" title=\"Example of using an object\" >@Authenticated @Path(\"/abac\") public class AbacResource { @GET @Authorized(explicit = true) @PolicyStatement(\"${env.time.year &gt;= 2017 &amp;&amp; object.owner == subject.principal.id}\") public Response process(@Context SecurityContext context) { // probably looked up from a database SomeResource res = new SomeResource(\"user\"); AuthorizationResponse atzResponse = context.authorize(res); if (atzResponse.isPermitted()) { //do the update return Response.ok().entity(\"fine, sir\").build(); } else { return Response.status(Response.Status.FORBIDDEN) .entity(atzResponse.getDescription().orElse(\"Access not granted\")) .build(); } } } The following validators are implemented: Roles Scopes EL Policy Role Validator Checks whether user/service is in either of the required role(s). Configuration Key: role-validator Annotations: @RolesAllowed , @RoleValidator.Roles <markup lang=\"yaml\" title=\"Configuration example for WebServer \" >security: web-server.paths: - path: \"/user[/{*}]\" roles-allowed: [\"user\"] <markup lang=\"java\" title=\"JAX-RS example\" >@RolesAllowed(\"user\") @RoleValidator.Roles(value = \"service_role\", subjectType = SubjectType.SERVICE) @Authenticated @Path(\"/abac\") public class AbacResource { } Interaction with JAX-RS Sub-Resource Locators When using sub-resource locators in JAX-RS, the roles allowed are collected from each \"level\" of execution: - Application class annotations - Resource class annotations + resource method annotations - Sub-resource class annotations + sub-resource method annotations - Sub-resource class annotations + sub-resource method annotations (for every sub-resource on the path) The RolesAllowed or Roles annotation to be used is the last one in the path as defined above. Example 1: There is a RolesAllowed(\"admin\") defined on a sub-resource locator resource class. In this case the required role is admin . Example 2: There is a RolesAllowed(\"admin\") defined on a sub-resource locator resource class and a RolesAllowed(\"user\") defined on the method of the sub-resource that provides the response. In this case the required role is user . Scope Validator Checks whether user has all the required scopes. Configuration Key: scope-validator Annotations: @Scope <markup lang=\"yaml\" title=\"Configuration example for WebServer \" >security: web-server.paths: - path: \"/user[/{*}]\" abac.scopes: [\"calendar_read\", \"calendar_edit\"] <markup lang=\"java\" title=\"JAX-RS example\" >@Scope(\"calendar_read\") @Scope(\"calendar_edit\") @Authenticated @Path(\"/abac\") public class AbacResource { } Expression Language Policy Validator Policy executor using Java EE policy expression language (EL) Configuration Key: policy-javax-el Annotations: @PolicyStatement Example of a policy statement: ${env.time.year &gt;= 2017} <markup lang=\"yaml\" title=\"Configuration example for WebServer \" >security: web-server.paths: - path: \"/user[/{*}]\" policy: statement: \"hasScopes('calendar_read','calendar_edit') AND timeOfDayBetween('8:15', '17:30')\" <markup lang=\"java\" title=\"JAX-RS example\" >@PolicyStatement(\"${env.time.year &gt;= 2017}\") @Authenticated @Path(\"/abac\") public class AbacResource { } Google Login Provider Authenticates a token from request against Google identity provider Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-google-login&lt;/artifactId&gt; &lt;/dependency&gt; Overview Google Authentication provider Type: io.helidon.security.providers.google.login.GoogleTokenProvider <markup lang=\"text\" title=\"Config key\" >google-login This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthenticationProvider Configuration options Optional configuration options key type default value description client-id string &#160; Google application client id, to validate that the token was generated by Google for us. optional boolean false If set to true, this provider will return io.helidon.security.SecurityResponse.SecurityStatus#ABSTAIN instead of failing in case of invalid request. outbound OutboundConfig &#160; Outbound configuration - a set of outbound targets that will have the token propagated. proxy-host string &#160; Set proxy host when talking to Google. proxy-port int 80 Set proxy port when talking to Google. realm string helidon Set the authentication realm to build challenge, defaults to \"helidon\". token TokenHandler &#x60;Authorization&#x60; header with &#x60;bearer&#x60; prefix Token provider to extract Google access token from request, defaults to \"Authorization\" header with a \"bearer \" prefix. Example code See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - provider: client-id: \"Google client id\" How does it work? We expect to receive a token (with sufficient scopes) from the inbound request, such as when using the Google login button on a page. The page has access to the token in javascript and can send it to backend with every request in a header field ( Authorization with `bearer ` prefix is assumed by default). Once we receive the token in Helidon, we parse it and: Validate if it timed out locally Return a cached response (see EvictableCache with default values) Otherwise verify using Google API - GoogleIdTokenVerifier We build a subject from the Google token with the following attributes filled (if in token): userId email name emailVerified locale family_name given_name picture (URL) Outbound security The token will be propagated to outbound calls if an outbound target exists that matches the invoked endpoint (see outbound configuration above). JWT Provider JWT token authentication and outbound security provider. Setup <markup lang=\"xml\" title=\"Maven dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.security.providers&lt;/groupId&gt; &lt;artifactId&gt;helidon-security-providers-jwt&lt;/artifactId&gt; &lt;/dependency&gt; Overview JWT authentication provider Type: io.helidon.security.providers.jwt.JwtProvider <markup lang=\"text\" title=\"Config key\" >jwt This type provides the following service implementations: io.helidon.security.spi.SecurityProvider io.helidon.security.spi.AuthenticationProvider Configuration options Optional configuration options key type default value description allow-impersonation boolean false Whether to allow impersonation by explicitly overriding username from outbound requests using #EP_PROPERTY_OUTBOUND_USER property. By default this is not allowed and identity can only be propagated. allow-unsigned boolean false Configure support for unsigned JWT. If this is set to true any JWT that has algorithm set to none and no kid defined will be accepted. Note that this has serious security impact - if JWT can be sent from a third party, this allows the third party to send ANY JWT and it would be accpted as valid. atn-token.handler TokenHandler &#160; Token handler to extract username from request. atn-token.jwk.resource Resource &#160; JWK resource used to verify JWTs created by other parties. atn-token.jwt-audience string &#160; Audience expected in inbound JWTs. atn-token.verify-signature boolean true Configure whether to verify signatures. Signatures verification is enabled by default. You can configure the provider not to verify signatures. &lt;b&gt;Make sure your service is properly secured on network level and only accessible from a secure endpoint that provides the JWTs when signature verification is disabled. If signature verification is disabled, this service will accept &lt;i&gt;ANY&lt;/i&gt; JWT&lt;/b&gt; authenticate boolean true Whether to authenticate requests. optional boolean false Whether authentication is required. By default, request will fail if the username cannot be extracted. If set to false, request will process and this provider will abstain. principal-type SubjectType (USER, SERVICE) USER Principal type this provider extracts (and also propagates). propagate boolean true Whether to propagate identity. sign-token OutboundConfig &#160; Configuration of outbound rules. sign-token.jwk.resource Resource &#160; JWK resource used to sign JWTs created by us. sign-token.jwt-issuer string &#160; Issuer used to create new JWTs. use-jwt-groups boolean true Claim groups from JWT will be used to automatically add groups to current subject (may be used with jakarta.annotation.security.RolesAllowed annotation). Example code See the example on GitHub. <markup lang=\"yaml\" title=\"Configuration example\" >security: providers: - provider: atn-token: jwk.resource.resource-path: \"verifying-jwk.json\" jwt-audience: \"http://my.service\" sign-token: jwk.resource.resource-path: \"signing-jwk.json\" jwt-issuer: \"http://my.server/identity\" outbound: - name: \"propagate-token\" hosts: [\"*.internal.org\"] - name: \"generate-token\" hosts: [\"1.partner-service\"] jwk-kid: \"partner-1\" jwt-kid: \"helidon\" jwt-audience: \"http://1.partner-service\" How does it work? JSON Web Token (JWT) provider has support for authentication and outbound security. Authentication is based on validating the token (signature, valid before etc.) and on asserting the subject of the JWT subject claim. For outbound, we support either token propagation (e.g. the token from request is propagated further) or support for generating a brand new token based on configuration of this provider. ",
            "title": "CORS Settings"
        },
        {
            "location": "se/security/providers",
            "text": " Helidon Security Examples Helidon OIDC JavaDoc Helidon HTTP Authentication JavaDoc Helidon Header Authentication JavaDoc Helidon HTTP Signature JavaDoc Helidon IDCS Role Mapper JavaDoc Helidon ABAC JavaDoc Helidon Google Login JavaDoc Helidon JWT JavaDoc ",
            "title": "Reference"
        },
        {
            "location": "se/security/tools",
            "text": " Support for encrypting secrets in configuration files. <markup lang=\"xml\" title=\"Maven Dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.config&lt;/groupId&gt; &lt;artifactId&gt;helidon-config-encryption&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Secure Configuration"
        },
        {
            "location": "se/security/tools",
            "text": " Configuration support for accessing private keys, public keys, certificates and certificate chains including runtime access to instances of such. <markup lang=\"xml\" title=\"Maven Dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.common&lt;/groupId&gt; &lt;artifactId&gt;helidon-common-key-util&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Key and Certificate Configuration"
        },
        {
            "location": "se/security/tools",
            "text": " Secure Configuration Support for encrypting secrets in configuration files. <markup lang=\"xml\" title=\"Maven Dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.config&lt;/groupId&gt; &lt;artifactId&gt;helidon-config-encryption&lt;/artifactId&gt; &lt;/dependency&gt; Key and Certificate Configuration Configuration support for accessing private keys, public keys, certificates and certificate chains including runtime access to instances of such. <markup lang=\"xml\" title=\"Maven Dependency\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.common&lt;/groupId&gt; &lt;artifactId&gt;helidon-common-key-util&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Tools"
        },
        {
            "location": "se/tracing",
            "text": " Overview Maven Coordinates Usage Configuration Additional Information Span Propagation Zipkin Tracing Jaeger Tracing Reference ",
            "title": "Contents"
        },
        {
            "location": "se/tracing",
            "text": " Distributed tracing is a critical feature of micro-service based applications, since it traces workflow both within a service and across multiple services. This provides insight to sequence and timing data for specific blocks of work, which helps you identify performance and operational issues. Helidon includes support for distributed tracing through its own API, backed by either through the OpenTelemetry API , or by OpenTracing API . Tracing is integrated with WebServer, gRPC Server, and Security. ",
            "title": "Overview"
        },
        {
            "location": "se/tracing",
            "text": " To enable Helidon Tracing add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "se/tracing",
            "text": "<markup lang=\"java\" title=\"Configuring OpenTracing Tracer \" >WebServer.builder() .tracer(TracerBuilder.create(\"my-application\") .collectorUri(URI.create(\"http://10.0.0.18:9411\")) .build()) .build() The name of the application (service) to associate with the tracing events The endpoint for tracing events, specific to the tracer used, usually loaded from Config ",
            "title": "Setup WebServer"
        },
        {
            "location": "se/tracing",
            "text": "<markup lang=\"java\" title=\"Configuring Tracer \" >Tracer tracer = TracerBuilder.create(\"Server\") .collectorUri(URI.create(\"http://10.0.0.18:9411\")) .build(); If using zipkin tracing system, the endpoint would be: http://10.0.0.18:9411/api/v2/spans <markup lang=\"java\" title=\"Configuring Tracing Attributes\" >GrpcTracingConfig tracingConfig = new GrpcTracingConfig.Builder() .withStreaming() .withVerbosity() .withTracedAttributes(ServerRequestAttribute.CALL_ATTRIBUTES, ServerRequestAttribute.HEADERS, ServerRequestAttribute.METHOD_NAME) .build(); <markup lang=\"java\" title=\"Configuring gRPC Server\" >GrpcServerConfiguration serverConfig = GrpcServerConfiguration.builder().port(0) .tracer(tracer) .tracingConfig(tracingConfig) .build(); ",
            "title": "Setup gRPC Server"
        },
        {
            "location": "se/tracing",
            "text": " To create a custom span that is a child of the WebServer request: <markup lang=\"java\" >Span span = request.tracer() .buildSpan(\"my-operation\") .asChildOf(request.spanContext()) .start(); ",
            "title": "Creating custom spans"
        },
        {
            "location": "se/tracing",
            "text": "",
            "title": "Helidon Spans"
        },
        {
            "location": "se/tracing",
            "text": " This section explains a few concepts that you need to understand before you get started with tracing. In the context of this document, a service is synonymous with an application. A span is the basic unit of work done within a single service, on a single host. Every span has a name, starting timestamp, and duration. For example, the work done by a REST endpoint is a span. A span is associated to a single service, but its descendants can belong to different services and hosts. A trace contains a collection of spans from one or more services, running on one or more hosts. For example, if you trace a service endpoint that calls another service, then the trace would contain spans from both services. Within a trace, spans are organized as a directed acyclic graph (DAG) and can belong to multiple services, running on multiple hosts. Support for specific tracers is abstracted. Your application can depend on the Helidon abstraction layer and provide a specific tracer implementation as a Java ServiceLoader service. Helidon provides such an implementation for: OpenTracing tracers, either using the GlobalTracer , provider resolver approach, or explicitly using Zipkin tracer OpenTelemetry tracers, either using the global OpenTelemetry instance, or explicitly using Jaeger tracer Setup WebServer <markup lang=\"java\" title=\"Configuring OpenTracing Tracer \" >WebServer.builder() .tracer(TracerBuilder.create(\"my-application\") .collectorUri(URI.create(\"http://10.0.0.18:9411\")) .build()) .build() The name of the application (service) to associate with the tracing events The endpoint for tracing events, specific to the tracer used, usually loaded from Config Setup gRPC Server <markup lang=\"java\" title=\"Configuring Tracer \" >Tracer tracer = TracerBuilder.create(\"Server\") .collectorUri(URI.create(\"http://10.0.0.18:9411\")) .build(); If using zipkin tracing system, the endpoint would be: http://10.0.0.18:9411/api/v2/spans <markup lang=\"java\" title=\"Configuring Tracing Attributes\" >GrpcTracingConfig tracingConfig = new GrpcTracingConfig.Builder() .withStreaming() .withVerbosity() .withTracedAttributes(ServerRequestAttribute.CALL_ATTRIBUTES, ServerRequestAttribute.HEADERS, ServerRequestAttribute.METHOD_NAME) .build(); <markup lang=\"java\" title=\"Configuring gRPC Server\" >GrpcServerConfiguration serverConfig = GrpcServerConfiguration.builder().port(0) .tracer(tracer) .tracingConfig(tracingConfig) .build(); Creating custom spans To create a custom span that is a child of the WebServer request: <markup lang=\"java\" >Span span = request.tracer() .buildSpan(\"my-operation\") .asChildOf(request.spanContext()) .start(); Helidon Spans ",
            "title": "Usage"
        },
        {
            "location": "se/tracing",
            "text": " The following table lists all spans traced by Helidon components: <div class=\"table__overflow elevation-1 flex sm10 \"> component span name description web-server HTTP Request The overall span of the Web Server from request initiation until response Note that in Zipkin the name is replaced with jax-rs span name if jax-rs tracing is used. web-server content-read Span for reading the request entity web-server content-write Span for writing the response entity security security Processing of request security security security:atn Span for request authentication security security:atz Span for request authorization security security:response Processing of response security security security:outbound Processing of outbound security jax-rs A generated name Span for the resource method invocation, name is generated from class and method name jax-rs jersey-client-call Span for outbound client call Some of these spans log to the span. These log events can be (in most cases) configured: <div class=\"table__overflow elevation-1 flex sm10 \"> span name log name configurable enabled by default description HTTP Request handler.class YES YES Each handler has its class and event logged security status YES YES Logs either \"status: PROCEED\" or \"status: DENY\" security:atn security.user YES NO The username of the user if logged in security:atn security.service YES NO The name of the service if logged in security:atn status YES YES Logs the status of security response (such as SUCCESS ) security:atz status YES YES Logs the status of security response (such as SUCCESS ) security:outbound status YES YES Logs the status of security response (such as SUCCESS ) There are also tags that are set by Helidon components. These are not configurable. <div class=\"table__overflow elevation-1 flex sm10 \"> span name tag name description HTTP Request component name of the component - helidon-webserver , or jaxrs when using MP HTTP Request http.method HTTP method of the request, such as GET , POST HTTP Request http.status_code HTTP status code of the response HTTP Request http.url The path of the request (for SE without protocol, host and port) HTTP Request error If the request ends in error, this tag is set to true , usually accompanied by logs with details content-read requested.type Type (class) of the requested entity (if entity is read) content-write response.type Type (class) of the entity being sent (if entity is sent) security security.id ID of the security context created for this request (if security is used) jersey-client-call http.method HTTP method of the client request jersey-client-call http.status_code HTTP status code of client response jersey-client-call http.url Full URL of the request (such as http://localhost:8080/greet ) ",
            "title": "Traced spans"
        },
        {
            "location": "se/tracing",
            "text": " The following configuration should be supported by all tracer implementations (if feasible) Jaeger tracer configuration. Type: io.helidon.tracing.Tracer This is a standalone configuration type, prefix from configuration root: tracing ",
            "title": "Configuration"
        },
        {
            "location": "se/tracing",
            "text": " Builder approach, example that disables a single span log event: <markup lang=\"java\" title=\"Configure tracing using a builder\" >TracingConfig.builder() .addComponent(ComponentTracingConfig.builder(\"web-server\") .addSpan(SpanTracingConfig.builder(\"HTTP Request\") .addSpanLog(SpanLogTracingConfig.builder(\"content-write\").enabled(false).build()) .build()) .build()) .build() ",
            "title": "Configuration using builder"
        },
        {
            "location": "se/tracing",
            "text": " Tracing configuration can be defined in a config file. <markup lang=\"yaml\" title=\"Tracing configuration\" >tracing: components: web-server: spans: - name: \"HTTP Request\" logs: - name: \"content-write\" enabled: false <markup lang=\"java\" title=\"Use the configuration in web server\" >routing.register(WebTracingConfig.create(config.get(\"tracing\"))); ",
            "title": "Configuration using Helidon Config"
        },
        {
            "location": "se/tracing",
            "text": " For Web Server we have a path based support for configuring tracing, in addition to the configuration described above. Configuration of path can use any path string supported by the Web Server. The configuration itself has the same possibilities as traced configuration described above. The path specific configuration will be merged with global configuration (path is the \"newer\" configuration, global is the \"older\") <markup lang=\"yaml\" title=\"Configuration in YAML\" >tracing: paths: - path: \"/favicon.ico\" enabled: false - path: \"/metrics\" enabled: false - path: \"/health\" enabled: false - path: \"/greet\" components: web-server: spans: - name: \"content-read\" new-name: \"read\" enabled: false <markup lang=\"java\" title=\"Configuration with Web Server\" >routingBuilder.register(WebTracingConfig.create(config.get(\"tracing\")); <markup lang=\"java\" title=\"Configuration with Web Server using a builder\" >routingBuilder.register(WebTracingConfig.builder() .addPathConfig(PathTracingConfig.builder() .path(\"/metrics\") .tracingConfig(TracingConfig.DISABLED) .build(); .build()); ",
            "title": "Path based configuration in Helidon Web Server"
        },
        {
            "location": "se/tracing",
            "text": " To have a nicer overview in search pane of a tracer, you can customize the top-level span name using configuration. Example: <markup lang=\"yaml\" title=\"Configuration in YAML\" >tracing: components: web-server: spans: - name: \"HTTP Request\" new-name: \"HTTP %1$s %2$s\" This is supported ONLY for the span named \"HTTP Request\" on component \"web-server\". Parameters provided: Method - HTTP method Path - path of the request (such as '/greet') Query - query of the request (may be null) ",
            "title": "Renaming top level span using request properties"
        },
        {
            "location": "se/tracing",
            "text": " Each component and its spans can be configured using Config. The traced configuration has the following layers: TracingConfig - the overall configuration of traced components of Helidon ComponentTracingConfig - a component of Helidon that traces spans (such as web-server , security , jax-rs ) SpanTracingConfig - a single traced span within a component (such as security:atn ) SpanLogTracingConfig - a single log event on a span (such as security.user in span security:atn ) The components using tracing configuration use the TracingConfigUtil . This uses the io.helidon.common.Context to retrieve current configuration. Configuration using builder Builder approach, example that disables a single span log event: <markup lang=\"java\" title=\"Configure tracing using a builder\" >TracingConfig.builder() .addComponent(ComponentTracingConfig.builder(\"web-server\") .addSpan(SpanTracingConfig.builder(\"HTTP Request\") .addSpanLog(SpanLogTracingConfig.builder(\"content-write\").enabled(false).build()) .build()) .build()) .build() Configuration using Helidon Config Tracing configuration can be defined in a config file. <markup lang=\"yaml\" title=\"Tracing configuration\" >tracing: components: web-server: spans: - name: \"HTTP Request\" logs: - name: \"content-write\" enabled: false <markup lang=\"java\" title=\"Use the configuration in web server\" >routing.register(WebTracingConfig.create(config.get(\"tracing\"))); Path based configuration in Helidon Web Server For Web Server we have a path based support for configuring tracing, in addition to the configuration described above. Configuration of path can use any path string supported by the Web Server. The configuration itself has the same possibilities as traced configuration described above. The path specific configuration will be merged with global configuration (path is the \"newer\" configuration, global is the \"older\") <markup lang=\"yaml\" title=\"Configuration in YAML\" >tracing: paths: - path: \"/favicon.ico\" enabled: false - path: \"/metrics\" enabled: false - path: \"/health\" enabled: false - path: \"/greet\" components: web-server: spans: - name: \"content-read\" new-name: \"read\" enabled: false <markup lang=\"java\" title=\"Configuration with Web Server\" >routingBuilder.register(WebTracingConfig.create(config.get(\"tracing\")); <markup lang=\"java\" title=\"Configuration with Web Server using a builder\" >routingBuilder.register(WebTracingConfig.builder() .addPathConfig(PathTracingConfig.builder() .path(\"/metrics\") .tracingConfig(TracingConfig.DISABLED) .build(); .build()); Renaming top level span using request properties To have a nicer overview in search pane of a tracer, you can customize the top-level span name using configuration. Example: <markup lang=\"yaml\" title=\"Configuration in YAML\" >tracing: components: web-server: spans: - name: \"HTTP Request\" new-name: \"HTTP %1$s %2$s\" This is supported ONLY for the span named \"HTTP Request\" on component \"web-server\". Parameters provided: Method - HTTP method Path - path of the request (such as '/greet') Query - query of the request (may be null) ",
            "title": "Traced spans configuration"
        },
        {
            "location": "se/tracing",
            "text": " Optional configuration options key type default value description boolean-tags Map&lt;string, boolean&gt; &#160; Tracer level tags that get added to all reported spans. client-cert-pem Resource &#160; Certificate of client in PEM format. enabled boolean true When enabled, tracing will be sent. If enabled is false, tracing should use a no-op tracer. exporter-timeout-millis Duration 10000 Timeout of exporter requests. global boolean true When enabled, the created instance is also registered as a global tracer. host string &#160; Host to use to connect to tracing collector. Default is defined by each tracing integration. int-tags Map&lt;string, int&gt; &#160; Tracer level tags that get added to all reported spans. path string &#160; Path on the collector host to use when sending data to tracing collector. Default is defined by each tracing integration. port int &#160; Port to use to connect to tracing collector. Default is defined by each tracing integration. private-key-pem Resource &#160; Private key in PEM format. protocol string &#160; Protocol to use (such as http or https ) to connect to tracing collector. Default is defined by each tracing integration. sampler-param Number 1 The sampler parameter (number). sampler-type SamplerType (CONSTANT, RATIO) CONSTANT Sampler type. See &lt;a href=\"https://www.jaegertracing.io/docs/latest/sampling/#client-sampling-configuration\"&gt;Sampler types&lt;/a&gt;. service string &#160; Service name of the traced service. tags Map&lt;string, string&gt; &#160; Tracer level tags that get added to all reported spans. trusted-cert-pem Resource &#160; Trusted certificates in PEM format. Traced spans configuration Each component and its spans can be configured using Config. The traced configuration has the following layers: TracingConfig - the overall configuration of traced components of Helidon ComponentTracingConfig - a component of Helidon that traces spans (such as web-server , security , jax-rs ) SpanTracingConfig - a single traced span within a component (such as security:atn ) SpanLogTracingConfig - a single log event on a span (such as security.user in span security:atn ) The components using tracing configuration use the TracingConfigUtil . This uses the io.helidon.common.Context to retrieve current configuration. Configuration using builder Builder approach, example that disables a single span log event: <markup lang=\"java\" title=\"Configure tracing using a builder\" >TracingConfig.builder() .addComponent(ComponentTracingConfig.builder(\"web-server\") .addSpan(SpanTracingConfig.builder(\"HTTP Request\") .addSpanLog(SpanLogTracingConfig.builder(\"content-write\").enabled(false).build()) .build()) .build()) .build() Configuration using Helidon Config Tracing configuration can be defined in a config file. <markup lang=\"yaml\" title=\"Tracing configuration\" >tracing: components: web-server: spans: - name: \"HTTP Request\" logs: - name: \"content-write\" enabled: false <markup lang=\"java\" title=\"Use the configuration in web server\" >routing.register(WebTracingConfig.create(config.get(\"tracing\"))); Path based configuration in Helidon Web Server For Web Server we have a path based support for configuring tracing, in addition to the configuration described above. Configuration of path can use any path string supported by the Web Server. The configuration itself has the same possibilities as traced configuration described above. The path specific configuration will be merged with global configuration (path is the \"newer\" configuration, global is the \"older\") <markup lang=\"yaml\" title=\"Configuration in YAML\" >tracing: paths: - path: \"/favicon.ico\" enabled: false - path: \"/metrics\" enabled: false - path: \"/health\" enabled: false - path: \"/greet\" components: web-server: spans: - name: \"content-read\" new-name: \"read\" enabled: false <markup lang=\"java\" title=\"Configuration with Web Server\" >routingBuilder.register(WebTracingConfig.create(config.get(\"tracing\")); <markup lang=\"java\" title=\"Configuration with Web Server using a builder\" >routingBuilder.register(WebTracingConfig.builder() .addPathConfig(PathTracingConfig.builder() .path(\"/metrics\") .tracingConfig(TracingConfig.DISABLED) .build(); .build()); Renaming top level span using request properties To have a nicer overview in search pane of a tracer, you can customize the top-level span name using configuration. Example: <markup lang=\"yaml\" title=\"Configuration in YAML\" >tracing: components: web-server: spans: - name: \"HTTP Request\" new-name: \"HTTP %1$s %2$s\" This is supported ONLY for the span named \"HTTP Request\" on component \"web-server\". Parameters provided: Method - HTTP method Path - path of the request (such as '/greet') Query - query of the request (may be null) ",
            "title": "Configuration options"
        },
        {
            "location": "se/tracing",
            "text": " Span propagation is supported with Helidon WebClient (and with Jersey client, though it is blocking and not suitable for reactive implementations). Tracing propagation is automatic as long as the current span context is available in Helidon Context (which is automatic when running within a WebServer request). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-webclient&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.webclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-webclient-tracing&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"java\" title=\"Tracing propagation with Helidon WebClient\" >WebClient client = WebClient.builder() .addService(WebClientTracing.create()) .build(); Single&lt;String&gt; response = client.get() .uri(uri) .request(String.class); ",
            "title": "Span Propagation"
        },
        {
            "location": "se/tracing",
            "text": "<markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-zipkin&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Zipkin Tracing"
        },
        {
            "location": "se/tracing",
            "text": " Span Propagation Span propagation is supported with Helidon WebClient (and with Jersey client, though it is blocking and not suitable for reactive implementations). Tracing propagation is automatic as long as the current span context is available in Helidon Context (which is automatic when running within a WebServer request). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-webclient&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.helidon.webclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-webclient-tracing&lt;/artifactId&gt; &lt;/dependency&gt; <markup lang=\"java\" title=\"Tracing propagation with Helidon WebClient\" >WebClient client = WebClient.builder() .addService(WebClientTracing.create()) .build(); Single&lt;String&gt; response = client.get() .uri(uri) .request(String.class); Zipkin Tracing <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-zipkin&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Additional Information"
        },
        {
            "location": "se/tracing",
            "text": " Zipkin tracer configuration Type: io.opentracing.Tracer This is a standalone configuration type, prefix from configuration root: tracing ",
            "title": "Configuring Zipkin"
        },
        {
            "location": "se/tracing",
            "text": "<markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-jaeger&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Jaeger Tracing"
        },
        {
            "location": "se/tracing",
            "text": " Optional configuration options key type default value description api-version Version (V1, V2) V2 Version of Zipkin API to use. Defaults to Version#V2. boolean-tags Map&lt;string, boolean&gt; &#160; Tracer level tags that get added to all reported spans. enabled boolean true When enabled, tracing will be sent. If enabled is false, tracing should use a no-op tracer. global boolean true When enabled, the created instance is also registered as a global tracer. host string &#160; Host to use to connect to tracing collector. Default is defined by each tracing integration. int-tags Map&lt;string, int&gt; &#160; Tracer level tags that get added to all reported spans. path string &#160; Path on the collector host to use when sending data to tracing collector. Default is defined by each tracing integration. port int &#160; Port to use to connect to tracing collector. Default is defined by each tracing integration. protocol string &#160; Protocol to use (such as http or https ) to connect to tracing collector. Default is defined by each tracing integration. service string &#160; Service name of the traced service. tags Map&lt;string, string&gt; &#160; Tracer level tags that get added to all reported spans. The following is an example of a Zipkin configuration, specified in the YAML format. <markup lang=\"yaml\" >tracing: zipkin: service: \"helidon-service\" protocol: \"https\" host: \"zipkin\" port: 9987 api-version: 1 # this is the default path for API version 2 path: \"/api/v2/spans\" tags: tag1: \"tag1-value\" tag2: \"tag2-value\" boolean-tags: tag3: true tag4: false int-tags: tag5: 145 tag6: 741 Example of Zipkin trace: Jaeger Tracing <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.tracing&lt;/groupId&gt; &lt;artifactId&gt;helidon-tracing-jaeger&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Configuration options"
        },
        {
            "location": "se/tracing",
            "text": " Jaeger tracer configuration. Type: io.helidon.tracing.Tracer This is a standalone configuration type, prefix from configuration root: tracing ",
            "title": "Configuring Jaeger"
        },
        {
            "location": "se/tracing",
            "text": " As the Jaeger Tracing section describes, you can use Jaeger tracing in your Helidon application. ",
            "title": "Jaeger Tracing Metrics"
        },
        {
            "location": "se/tracing",
            "text": " Optional configuration options key type default value description boolean-tags Map&lt;string, boolean&gt; &#160; Tracer level tags that get added to all reported spans. client-cert-pem Resource &#160; Certificate of client in PEM format. enabled boolean true When enabled, tracing will be sent. If enabled is false, tracing should use a no-op tracer. exporter-timeout-millis Duration 10000 Timeout of exporter requests. global boolean true When enabled, the created instance is also registered as a global tracer. host string &#160; Host to use to connect to tracing collector. Default is defined by each tracing integration. int-tags Map&lt;string, int&gt; &#160; Tracer level tags that get added to all reported spans. path string &#160; Path on the collector host to use when sending data to tracing collector. Default is defined by each tracing integration. port int &#160; Port to use to connect to tracing collector. Default is defined by each tracing integration. private-key-pem Resource &#160; Private key in PEM format. protocol string &#160; Protocol to use (such as http or https ) to connect to tracing collector. Default is defined by each tracing integration. sampler-param Number 1 The sampler parameter (number). sampler-type SamplerType (CONSTANT, RATIO) CONSTANT Sampler type. See &lt;a href=\"https://www.jaegertracing.io/docs/latest/sampling/#client-sampling-configuration\"&gt;Sampler types&lt;/a&gt;. service string &#160; Service name of the traced service. tags Map&lt;string, string&gt; &#160; Tracer level tags that get added to all reported spans. trusted-cert-pem Resource &#160; Trusted certificates in PEM format. The following is an example of a Jaeger configuration, specified in the YAML format. <markup lang=\"yaml\" >tracing: service: \"helidon-full-http\" protocol: \"https\" host: \"jaeger\" port: 14240 Jaeger Tracing Metrics As the Jaeger Tracing section describes, you can use Jaeger tracing in your Helidon application. ",
            "title": "Configuration options"
        },
        {
            "location": "se/tracing",
            "text": " Opentracing Project OpenTelemetry API ",
            "title": "Reference"
        },
        {
            "location": "se/webclient",
            "text": " Overview Maven Coordinates Usage Configuring the WebClient Examples Reference ",
            "title": "Contents"
        },
        {
            "location": "se/webclient",
            "text": " WebClient is an HTTP client of Helidon SE. It handles the responses to the HTTP requests in a reactive way. Helidon WebClient provides the following features: Reactive approach Allows you to execute HTTP requests and handle the responses without having to wait for the server response. When the response is received, the client requests only the amount of data that it can handle at that time. So, there is no overflow of memory. Builder-like setup and execution Creates every client and request as a builder pattern. This improves readability and code maintenance. Redirect chain Follows the redirect chain and perform requests on the correct endpoint by itself. Tracing, metrics and security propagation Automatically propagates the configured tracing, metrics and security settings of the Helidon WebServer to the WebClient and uses them during request and response. ",
            "title": "Overview"
        },
        {
            "location": "se/webclient",
            "text": " To enable WebClient add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webclient&lt;/groupId&gt; &lt;artifactId&gt;helidon-webclient&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "se/webclient",
            "text": " You can create WebClient by executing WebClient.create() method. This will create an instance of client with default settings and without a base uri set. To change the default settings and register additional services, you can use simple builder that allows you to customize the client behavior. <markup lang=\"java\" title=\"Create a WebClient with simple builder:\" >WebClient client = WebClient.builder() .baseUri(\"http://localhost\") .build(); ",
            "title": "Creating the WebClient"
        },
        {
            "location": "se/webclient",
            "text": " WebClient executes requests to the target endpoints and returns specific response type. It offers variety of methods to specify the type of request you want to execute: put() get() method(String methodName) These methods set specific request type based on their name or parameter to the new instance of WebClientRequesBuilder and return this instance based on configurations for specific request type. You can set configuration for every request type before it is sent as described in . For the final execution, use the following methods with variations and different parameters: Single&lt;T&gt; submit(Object entity, Class&lt;T&gt; responseType) Single&lt;T&gt; request(Class&lt;T&gt; responseType) <markup lang=\"java\" title=\"Execute a simple GET request to endpoint:\" >Single&lt;String&gt; response = client.get() .path(\"/endpoint\") .request(String.class); ",
            "title": "Creating and Executing the WebClient Request"
        },
        {
            "location": "se/webclient",
            "text": " Creating the WebClient You can create WebClient by executing WebClient.create() method. This will create an instance of client with default settings and without a base uri set. To change the default settings and register additional services, you can use simple builder that allows you to customize the client behavior. <markup lang=\"java\" title=\"Create a WebClient with simple builder:\" >WebClient client = WebClient.builder() .baseUri(\"http://localhost\") .build(); Creating and Executing the WebClient Request WebClient executes requests to the target endpoints and returns specific response type. It offers variety of methods to specify the type of request you want to execute: put() get() method(String methodName) These methods set specific request type based on their name or parameter to the new instance of WebClientRequesBuilder and return this instance based on configurations for specific request type. You can set configuration for every request type before it is sent as described in . For the final execution, use the following methods with variations and different parameters: Single&lt;T&gt; submit(Object entity, Class&lt;T&gt; responseType) Single&lt;T&gt; request(Class&lt;T&gt; responseType) <markup lang=\"java\" title=\"Execute a simple GET request to endpoint:\" >Single&lt;String&gt; response = client.get() .path(\"/endpoint\") .request(String.class); ",
            "title": "Usage"
        },
        {
            "location": "se/webclient",
            "text": " Optional configuration options key type default value description connect-timeout-millis long 60000 Sets new connection timeout of the request. cookies.automatic-store-enabled boolean &#160; Whether to allow automatic cookie storing cookies.default-cookies Map &#160; Default cookies to be used in each request. Each list entry has to have \"name\" and \"value\" node follow-redirects boolean false Whether to follow any response redirections or not. headers Map &#160; Default headers to be used in each request. Each list entry has to have \"name\" and \"value\" node max-redirects int 5 Sets max number of followed redirects. media-support MediaContext &#160; proxy Proxy &#160; Sets new request proxy. read-timeout-millis long 600000 Sets new read timeout of the response. relative-uris boolean false Can be set to true to force the use of relative URIs in all requests, regardless of the presence or absence of proxies or no-proxy lists. tls WebClientTls &#160; New TLS configuration. uri string &#160; Base uri for each request. @return updated builder instance user-agent string &#160; Name of the user agent which should be used. ",
            "title": "Configuration options"
        },
        {
            "location": "se/webclient",
            "text": "<markup lang=\"java\" >Config config = Config.create(); WebClient client = WebClient.builder() .baseUri(\"http://localhost\") .config(config.get(\"client\")) .build(); ",
            "title": "Example of a WebClient Runtime Configuration"
        },
        {
            "location": "se/webclient",
            "text": "<markup lang=\"java\" >client: connect-timeout-millis: 2000 read-timeout-millis: 2000 follow-redirects: true max-redirects: 5 cookies: automatic-store-enabled: true default-cookies: - name: \"env\" value: \"dev\" headers: - name: \"Accept\" value: [\"application/json\",\"text/plain\"] services: config: metrics: - methods: [\"PUT\", \"POST\", \"DELETE\"] - type: METER name-format: \"client.meter.overall\" - type: TIMER # meter per method name-format: \"client.meter.%1$s\" - methods: [\"GET\"] type: COUNTER errors: false name-format: \"client.counter.%1$s.success\" description: \"Counter of successful GET requests\" - methods: [\"PUT\", \"POST\", \"DELETE\"] type: COUNTER success: false name-format: \"wc.counter.%1$s.error\" description: \"Counter of failed PUT, POST and DELETE requests\" - methods: [\"GET\"] type: GAUGE_IN_PROGRESS name-format: \"client.inprogress.%2$s\" description: \"In progress requests to host\" tracing: proxy: use-system-selector: false host: \"hostName\" port: 80 no-proxy: [\"localhost:8080\", \".helidon.io\", \"192.168.1.1\"] tls: server: trust-all: true disable-hostname-verification: true keystore: passphrase: \"password\" trust-store: true resource: resource-path: \"client.p12\" client: keystore: passphrase: \"password\" resource: resource-path: \"client.p12\" Client functional settings Default client headers and cookies Client service configuration Proxy configuration TLS configuration ",
            "title": "Example of a WebClient YAML Configuration"
        },
        {
            "location": "se/webclient",
            "text": " The class responsible for WebClient configuration is: Configuration of the HTTP client Type: io.helidon.webclient.WebClientConfiguration This is a standalone configuration type, prefix from configuration root: client Configuration options Optional configuration options key type default value description connect-timeout-millis long 60000 Sets new connection timeout of the request. cookies.automatic-store-enabled boolean &#160; Whether to allow automatic cookie storing cookies.default-cookies Map &#160; Default cookies to be used in each request. Each list entry has to have \"name\" and \"value\" node follow-redirects boolean false Whether to follow any response redirections or not. headers Map &#160; Default headers to be used in each request. Each list entry has to have \"name\" and \"value\" node max-redirects int 5 Sets max number of followed redirects. media-support MediaContext &#160; proxy Proxy &#160; Sets new request proxy. read-timeout-millis long 600000 Sets new read timeout of the response. relative-uris boolean false Can be set to true to force the use of relative URIs in all requests, regardless of the presence or absence of proxies or no-proxy lists. tls WebClientTls &#160; New TLS configuration. uri string &#160; Base uri for each request. @return updated builder instance user-agent string &#160; Name of the user agent which should be used. Example of a WebClient Runtime Configuration <markup lang=\"java\" >Config config = Config.create(); WebClient client = WebClient.builder() .baseUri(\"http://localhost\") .config(config.get(\"client\")) .build(); Example of a WebClient YAML Configuration <markup lang=\"java\" >client: connect-timeout-millis: 2000 read-timeout-millis: 2000 follow-redirects: true max-redirects: 5 cookies: automatic-store-enabled: true default-cookies: - name: \"env\" value: \"dev\" headers: - name: \"Accept\" value: [\"application/json\",\"text/plain\"] services: config: metrics: - methods: [\"PUT\", \"POST\", \"DELETE\"] - type: METER name-format: \"client.meter.overall\" - type: TIMER # meter per method name-format: \"client.meter.%1$s\" - methods: [\"GET\"] type: COUNTER errors: false name-format: \"client.counter.%1$s.success\" description: \"Counter of successful GET requests\" - methods: [\"PUT\", \"POST\", \"DELETE\"] type: COUNTER success: false name-format: \"wc.counter.%1$s.error\" description: \"Counter of failed PUT, POST and DELETE requests\" - methods: [\"GET\"] type: GAUGE_IN_PROGRESS name-format: \"client.inprogress.%2$s\" description: \"In progress requests to host\" tracing: proxy: use-system-selector: false host: \"hostName\" port: 80 no-proxy: [\"localhost:8080\", \".helidon.io\", \"192.168.1.1\"] tls: server: trust-all: true disable-hostname-verification: true keystore: passphrase: \"password\" trust-store: true resource: resource-path: \"client.p12\" client: keystore: passphrase: \"password\" resource: resource-path: \"client.p12\" Client functional settings Default client headers and cookies Client service configuration Proxy configuration TLS configuration ",
            "title": "Configuring the WebClient"
        },
        {
            "location": "se/webclient",
            "text": " The request settings are based on the following optional parameters, and change when a specific request is executed. Parameter Description uri(\"http://example.com\") Overrides baseUri from WebClient path(\"/path\") Adds path to the uri queryParam(\"query\", \"parameter\") Adds query parameter to the request fragment(\"someFragment\") Adds fragment to the request headers(headers &#8594; headers.addAccept(MediaType.APPLICATION_JSON)) Adds header to the request WebClientRequestBuilder class also provides specific header methods that help the user to set a particular header. The methods are: contentType (MediaType contentType) accept (MediaType&#8230;&#8203; mediaTypes) For more details, see the Request Headers API. ",
            "title": "Request Configuration"
        },
        {
            "location": "se/webclient",
            "text": " JSON Processing (JSON-P) media support is not present in the WebClient by default. So, in this case, you must first register it before making a request. This example shows how to register JsonpSupport using the following two methods. <markup lang=\"java\" title=\"Register JSON-P support to the WebClient.\" >WebClient.builder() .baseUri(\"http://localhost\") .addReader(JsonpSupport.reader()) .addWriter(JsonpSupport.writer()) .addMediaService(JsonpSupport.create()) .build(); Adds JSON-P reader to all client requests. Adds JSON-P writer to all client requests. Adds JSON-P writer and reader to all client requests. <markup lang=\"java\" title=\"Register JSON-P support only to the specific request.\" >WebClient webClient = WebClient.create(); WebClientRequestBuilder requestBuilder = webClient.get(); requestBuilder.writerContext().registerWriter(JsonSupport.writer()); requestBuilder.readerContext().registerReader(JsonSupport.reader()); requestBuilder.request(JsonObject.class) Adds JSON-P writer only to this request. Adds JSON-P reader only to this request. ",
            "title": "Adding JSON Processing Media Support to the WebClient"
        },
        {
            "location": "se/webclient",
            "text": " One way to configure TLS in WebClient is in your application code as shown below. <markup lang=\"java\" >KeyConfig keyConfig = KeyConfig.keystoreBuilder() //Whether this keystore is also trust store .trustStore() //Keystore location/name .keystore(Resource.create(\"client.p12\")) //Password to the keystore .keystorePassphrase(\"password\") .build(); WebClient.builder() .tls(WebClientTls.builder() .certificateTrustStore(keyConfig) .clientKeyStore(keyConfig) .build()) .build(); ",
            "title": "Configuring TLS in your code"
        },
        {
            "location": "se/webclient",
            "text": " Another way to configure TLS in WebClient is through the application.yaml configuration file. <markup lang=\"yaml\" title=\"WebClient TLS configuration file application.yaml \" >webclient: tls: #Server part defines settings for server certificate validation and truststore server: keystore: passphrase: \"password\" trust-store: true resource: resource-path: \"keystore.p12\" #Client part defines access to the keystore with client private key or certificate client: keystore: passphrase: \"password\" resource: resource-path: \"keystore.p12\" Then, in your application code, load the configuration from that file. <markup lang=\"java\" title=\"WebClient initialization using the application.yaml file located on the classpath\" >Config config = Config.create(); WebClient webClient = WebClient.create(config.get(\"webclient\")); Or you can only create WebClientTls instance based on the config file. <markup lang=\"java\" title=\"WebClientTls instance based on application.yaml file located on the classpath\" >Config config = Config.create(); WebClientTls.builder() .config(config.get(\"webclient.tls\")) .build(); ",
            "title": "Configuring TLS in the config file"
        },
        {
            "location": "se/webclient",
            "text": " Configure TLS either programmatically or by the Helidon configuration framework. Configuring TLS in your code One way to configure TLS in WebClient is in your application code as shown below. <markup lang=\"java\" >KeyConfig keyConfig = KeyConfig.keystoreBuilder() //Whether this keystore is also trust store .trustStore() //Keystore location/name .keystore(Resource.create(\"client.p12\")) //Password to the keystore .keystorePassphrase(\"password\") .build(); WebClient.builder() .tls(WebClientTls.builder() .certificateTrustStore(keyConfig) .clientKeyStore(keyConfig) .build()) .build(); Configuring TLS in the config file Another way to configure TLS in WebClient is through the application.yaml configuration file. <markup lang=\"yaml\" title=\"WebClient TLS configuration file application.yaml \" >webclient: tls: #Server part defines settings for server certificate validation and truststore server: keystore: passphrase: \"password\" trust-store: true resource: resource-path: \"keystore.p12\" #Client part defines access to the keystore with client private key or certificate client: keystore: passphrase: \"password\" resource: resource-path: \"keystore.p12\" Then, in your application code, load the configuration from that file. <markup lang=\"java\" title=\"WebClient initialization using the application.yaml file located on the classpath\" >Config config = Config.create(); WebClient webClient = WebClient.create(config.get(\"webclient\")); Or you can only create WebClientTls instance based on the config file. <markup lang=\"java\" title=\"WebClientTls instance based on application.yaml file located on the classpath\" >Config config = Config.create(); WebClientTls.builder() .config(config.get(\"webclient.tls\")) .build(); ",
            "title": "WebClient TLS setup"
        },
        {
            "location": "se/webclient",
            "text": " Request Configuration The request settings are based on the following optional parameters, and change when a specific request is executed. Parameter Description uri(\"http://example.com\") Overrides baseUri from WebClient path(\"/path\") Adds path to the uri queryParam(\"query\", \"parameter\") Adds query parameter to the request fragment(\"someFragment\") Adds fragment to the request headers(headers &#8594; headers.addAccept(MediaType.APPLICATION_JSON)) Adds header to the request WebClientRequestBuilder class also provides specific header methods that help the user to set a particular header. The methods are: contentType (MediaType contentType) accept (MediaType&#8230;&#8203; mediaTypes) For more details, see the Request Headers API. Adding JSON Processing Media Support to the WebClient JSON Processing (JSON-P) media support is not present in the WebClient by default. So, in this case, you must first register it before making a request. This example shows how to register JsonpSupport using the following two methods. <markup lang=\"java\" title=\"Register JSON-P support to the WebClient.\" >WebClient.builder() .baseUri(\"http://localhost\") .addReader(JsonpSupport.reader()) .addWriter(JsonpSupport.writer()) .addMediaService(JsonpSupport.create()) .build(); Adds JSON-P reader to all client requests. Adds JSON-P writer to all client requests. Adds JSON-P writer and reader to all client requests. <markup lang=\"java\" title=\"Register JSON-P support only to the specific request.\" >WebClient webClient = WebClient.create(); WebClientRequestBuilder requestBuilder = webClient.get(); requestBuilder.writerContext().registerWriter(JsonSupport.writer()); requestBuilder.readerContext().registerReader(JsonSupport.reader()); requestBuilder.request(JsonObject.class) Adds JSON-P writer only to this request. Adds JSON-P reader only to this request. WebClient TLS setup Configure TLS either programmatically or by the Helidon configuration framework. Configuring TLS in your code One way to configure TLS in WebClient is in your application code as shown below. <markup lang=\"java\" >KeyConfig keyConfig = KeyConfig.keystoreBuilder() //Whether this keystore is also trust store .trustStore() //Keystore location/name .keystore(Resource.create(\"client.p12\")) //Password to the keystore .keystorePassphrase(\"password\") .build(); WebClient.builder() .tls(WebClientTls.builder() .certificateTrustStore(keyConfig) .clientKeyStore(keyConfig) .build()) .build(); Configuring TLS in the config file Another way to configure TLS in WebClient is through the application.yaml configuration file. <markup lang=\"yaml\" title=\"WebClient TLS configuration file application.yaml \" >webclient: tls: #Server part defines settings for server certificate validation and truststore server: keystore: passphrase: \"password\" trust-store: true resource: resource-path: \"keystore.p12\" #Client part defines access to the keystore with client private key or certificate client: keystore: passphrase: \"password\" resource: resource-path: \"keystore.p12\" Then, in your application code, load the configuration from that file. <markup lang=\"java\" title=\"WebClient initialization using the application.yaml file located on the classpath\" >Config config = Config.create(); WebClient webClient = WebClient.create(config.get(\"webclient\")); Or you can only create WebClientTls instance based on the config file. <markup lang=\"java\" title=\"WebClientTls instance based on application.yaml file located on the classpath\" >Config config = Config.create(); WebClientTls.builder() .config(config.get(\"webclient.tls\")) .build(); ",
            "title": "Examples"
        },
        {
            "location": "se/webclient",
            "text": " Helidon WebClient JavaDoc ",
            "title": "Reference"
        },
        {
            "location": "se/webserver",
            "text": " Overview Maven Coordinates Usage Configuration Reference Additional Information ",
            "title": "Contents"
        },
        {
            "location": "se/webserver",
            "text": " WebServer provides an asynchronous and reactive API for creating web applications. The API is inspired by popular NodeJS and Java frameworks. ",
            "title": "Overview"
        },
        {
            "location": "se/webserver",
            "text": " To enable WebServer add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webserver&lt;/groupId&gt; &lt;artifactId&gt;helidon-webserver&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "se/webserver",
            "text": " The following sections describe how to use WebServer. ",
            "title": "Usage"
        },
        {
            "location": "se/webserver",
            "text": " The easiest way to configure the WebServer is in your application code. <markup lang=\"java\" >WebServer webServer = WebServer.builder() .bindAddress(InetAddress.getLocalHost()) .port(8080) .build(); ",
            "title": "Configuring the WebServer in Your Code"
        },
        {
            "location": "se/webserver",
            "text": " You can also define the configuration in a file. <markup lang=\"yaml\" title=\"WebServer configuration file application.yaml \" >server: port: 8080 bind-address: \"0.0.0.0\" Then, in your application code, load the configuration from that file. <markup lang=\"java\" title=\"WebServer initialization using the application.yaml file located on the classpath\" >Config config = Config.create(); WebServer webServer = WebServer.create(routing, config.get(\"server\")); application.yaml is a default configuration source loaded when YAML support is on classpath, so we can just use Config.create() Server expects the configuration tree located on the node of server ",
            "title": "Configuring the WebServer in a configuration file"
        },
        {
            "location": "se/webserver",
            "text": " Optional configuration options key type default value description backlog int 1024 Configures a maximum length of the queue of incoming connections on the server socket. Default value is #DEFAULT_BACKLOG_SIZE. bind-address string &#160; Deprecated Configures local address where the server listens on with the server socket. If not configured, then listens an all local addresses. enable-compression boolean false Enable negotiation for gzip/deflate content encodings. Clients can request compression using the \"Accept-Encoding\" header. Default is `false` features.print-details boolean false Set to true to print detailed feature information on startup. host string &#160; A helper method that just calls #bindAddress(String). max-header-size int 16384 Maximal number of bytes of all header values combined. When a bigger value is received, a io.helidon.common.http.Http.Status#BAD_REQUEST_400 is returned. Default is `8192` max-initial-line-length int 4096 Maximal number of characters in the initial HTTP line. Default is `4096` max-payload-size long &#160; Set a maximum payload size for a client request. Can prevent DoS attacks. max-upgrade-content-length int 65536 Set a maximum length of the content of an upgrade request. Default is `64*1024` backpressure-buffer-size long 5242880 Set a maximum length of the unflushed response data sending buffer can keep without applying backpressure. Depends on backpressure-policy what happens if max buffer size is reached. Default is `5*1024*1024` - 5Mb backpressure-policy String LINEAR Sets the strategy for applying backpressure to the reactive stream of response data. LINEAR - Data chunks are requested one-by-one after previous data chunk has been written to Netty&#8217;s buffer, when backpressure-buffer-size watermark is reached, new chunks are not requested until buffer size decrease under the watermark value. PREFETCH - After first data chunk arrives, expected number of chunks needed to fill the buffer up to watermark is calculated and requested. AUTO_FLUSH - Data are requested one-by-one, in case buffer reaches watermark, no other data is requested and extra flush is initiated. UNBOUNDED - No backpressure is applied, Long.MAX_VALUE(unbounded) is requested from upstream. Default is `LINEAR` port int 0 Configures a server port to listen on with the server socket. If port is 0 then any available ephemeral port will be used. receive-buffer-size int &#160; Configures proposed value of the TCP receive window that is advertised to the remote peer on the server socket. If `0` then use implementation default. sockets SocketConfiguration[&#93; &#160; Adds an additional named server socket configuration. As a result, the server will listen on multiple ports. An additional named server socket may have a dedicated Routing configured through io.helidon.webserver.WebServer.Builder#addNamedRouting(String, Routing). timeout-millis long 0 Socket timeout in milliseconds tls WebServerTls &#160; Configures SSL for this socket. When configured, the server enforces SSL configuration. If this method is called, any other method except for #tls(java.util.function.Supplier)¨ and repeated invocation of this method would be ignored. If this method is called again, the previous configuration would be ignored. worker-count int &#160; Sets a count of threads in pool used to process HTTP requests. Default value is CPU_COUNT * 2 . Configuration key: `workers` ",
            "title": "Configuration options"
        },
        {
            "location": "se/webserver",
            "text": " Configuration of the HTTP server. Type: io.helidon.webserver.WebServer This is a standalone configuration type, prefix from configuration root: server Configuration options Optional configuration options key type default value description backlog int 1024 Configures a maximum length of the queue of incoming connections on the server socket. Default value is #DEFAULT_BACKLOG_SIZE. bind-address string &#160; Deprecated Configures local address where the server listens on with the server socket. If not configured, then listens an all local addresses. enable-compression boolean false Enable negotiation for gzip/deflate content encodings. Clients can request compression using the \"Accept-Encoding\" header. Default is `false` features.print-details boolean false Set to true to print detailed feature information on startup. host string &#160; A helper method that just calls #bindAddress(String). max-header-size int 16384 Maximal number of bytes of all header values combined. When a bigger value is received, a io.helidon.common.http.Http.Status#BAD_REQUEST_400 is returned. Default is `8192` max-initial-line-length int 4096 Maximal number of characters in the initial HTTP line. Default is `4096` max-payload-size long &#160; Set a maximum payload size for a client request. Can prevent DoS attacks. max-upgrade-content-length int 65536 Set a maximum length of the content of an upgrade request. Default is `64*1024` backpressure-buffer-size long 5242880 Set a maximum length of the unflushed response data sending buffer can keep without applying backpressure. Depends on backpressure-policy what happens if max buffer size is reached. Default is `5*1024*1024` - 5Mb backpressure-policy String LINEAR Sets the strategy for applying backpressure to the reactive stream of response data. LINEAR - Data chunks are requested one-by-one after previous data chunk has been written to Netty&#8217;s buffer, when backpressure-buffer-size watermark is reached, new chunks are not requested until buffer size decrease under the watermark value. PREFETCH - After first data chunk arrives, expected number of chunks needed to fill the buffer up to watermark is calculated and requested. AUTO_FLUSH - Data are requested one-by-one, in case buffer reaches watermark, no other data is requested and extra flush is initiated. UNBOUNDED - No backpressure is applied, Long.MAX_VALUE(unbounded) is requested from upstream. Default is `LINEAR` port int 0 Configures a server port to listen on with the server socket. If port is 0 then any available ephemeral port will be used. receive-buffer-size int &#160; Configures proposed value of the TCP receive window that is advertised to the remote peer on the server socket. If `0` then use implementation default. sockets SocketConfiguration[&#93; &#160; Adds an additional named server socket configuration. As a result, the server will listen on multiple ports. An additional named server socket may have a dedicated Routing configured through io.helidon.webserver.WebServer.Builder#addNamedRouting(String, Routing). timeout-millis long 0 Socket timeout in milliseconds tls WebServerTls &#160; Configures SSL for this socket. When configured, the server enforces SSL configuration. If this method is called, any other method except for #tls(java.util.function.Supplier)¨ and repeated invocation of this method would be ignored. If this method is called again, the previous configuration would be ignored. worker-count int &#160; Sets a count of threads in pool used to process HTTP requests. Default value is CPU_COUNT * 2 . Configuration key: `workers` ",
            "title": "Configuration Options"
        },
        {
            "location": "se/webserver",
            "text": " Configure the WebServer either programmatically, or by the Helidon configuration framework. Configuring the WebServer in Your Code The easiest way to configure the WebServer is in your application code. <markup lang=\"java\" >WebServer webServer = WebServer.builder() .bindAddress(InetAddress.getLocalHost()) .port(8080) .build(); Configuring the WebServer in a configuration file You can also define the configuration in a file. <markup lang=\"yaml\" title=\"WebServer configuration file application.yaml \" >server: port: 8080 bind-address: \"0.0.0.0\" Then, in your application code, load the configuration from that file. <markup lang=\"java\" title=\"WebServer initialization using the application.yaml file located on the classpath\" >Config config = Config.create(); WebServer webServer = WebServer.create(routing, config.get(\"server\")); application.yaml is a default configuration source loaded when YAML support is on classpath, so we can just use Config.create() Server expects the configuration tree located on the node of server Configuration Options Configuration of the HTTP server. Type: io.helidon.webserver.WebServer This is a standalone configuration type, prefix from configuration root: server Configuration options Optional configuration options key type default value description backlog int 1024 Configures a maximum length of the queue of incoming connections on the server socket. Default value is #DEFAULT_BACKLOG_SIZE. bind-address string &#160; Deprecated Configures local address where the server listens on with the server socket. If not configured, then listens an all local addresses. enable-compression boolean false Enable negotiation for gzip/deflate content encodings. Clients can request compression using the \"Accept-Encoding\" header. Default is `false` features.print-details boolean false Set to true to print detailed feature information on startup. host string &#160; A helper method that just calls #bindAddress(String). max-header-size int 16384 Maximal number of bytes of all header values combined. When a bigger value is received, a io.helidon.common.http.Http.Status#BAD_REQUEST_400 is returned. Default is `8192` max-initial-line-length int 4096 Maximal number of characters in the initial HTTP line. Default is `4096` max-payload-size long &#160; Set a maximum payload size for a client request. Can prevent DoS attacks. max-upgrade-content-length int 65536 Set a maximum length of the content of an upgrade request. Default is `64*1024` backpressure-buffer-size long 5242880 Set a maximum length of the unflushed response data sending buffer can keep without applying backpressure. Depends on backpressure-policy what happens if max buffer size is reached. Default is `5*1024*1024` - 5Mb backpressure-policy String LINEAR Sets the strategy for applying backpressure to the reactive stream of response data. LINEAR - Data chunks are requested one-by-one after previous data chunk has been written to Netty&#8217;s buffer, when backpressure-buffer-size watermark is reached, new chunks are not requested until buffer size decrease under the watermark value. PREFETCH - After first data chunk arrives, expected number of chunks needed to fill the buffer up to watermark is calculated and requested. AUTO_FLUSH - Data are requested one-by-one, in case buffer reaches watermark, no other data is requested and extra flush is initiated. UNBOUNDED - No backpressure is applied, Long.MAX_VALUE(unbounded) is requested from upstream. Default is `LINEAR` port int 0 Configures a server port to listen on with the server socket. If port is 0 then any available ephemeral port will be used. receive-buffer-size int &#160; Configures proposed value of the TCP receive window that is advertised to the remote peer on the server socket. If `0` then use implementation default. sockets SocketConfiguration[&#93; &#160; Adds an additional named server socket configuration. As a result, the server will listen on multiple ports. An additional named server socket may have a dedicated Routing configured through io.helidon.webserver.WebServer.Builder#addNamedRouting(String, Routing). timeout-millis long 0 Socket timeout in milliseconds tls WebServerTls &#160; Configures SSL for this socket. When configured, the server enforces SSL configuration. If this method is called, any other method except for #tls(java.util.function.Supplier)¨ and repeated invocation of this method would be ignored. If this method is called again, the previous configuration would be ignored. worker-count int &#160; Sets a count of threads in pool used to process HTTP requests. Default value is CPU_COUNT * 2 . Configuration key: `workers` ",
            "title": "Configuration"
        },
        {
            "location": "se/webserver",
            "text": " Routing also supports Error Routing which binds Java Throwable to the handling logic. Configure HTTP request routing using Routing.Builder . <markup lang=\"java\" title=\"Using Routing.Builder to specify how HTTP requests are handled\" >Routing routing = Routing.builder() .get(\"/hello\", (req, res) -&gt; res.send(\"Hello World!\")) .build(); WebServer webServer = WebServer.create(routing); Handle all GETs to /hello path. Send the Hello World! string. Add the routing to the WebServer. ",
            "title": "Basics"
        },
        {
            "location": "se/webserver",
            "text": " Routing.Builder lets you specify how to handle each HTTP method. For example: <div class=\"table__overflow elevation-1 flex sm7 \"> HTTP Method Routing.Builder example GET .get((req, res) -&gt; { /* handler */ }) PUT .put((req, res) -&gt; { /* handler */ }) POST .post((req, res) -&gt; { /* handler */ }) HEAD .head((req, res) -&gt; { /* handler */ }) DELETE .delete((req, res) -&gt; { /* handler */ }) TRACE .trace((req, res) -&gt; { /* handler */ }) OPTIONS .options((req, res) -&gt; { /* handler */ }) any method .any((req, res) -&gt; { /* handler */ }) multiple methods .anyOf(List.of(Http.Method.GET, Http.Method.POST), (req, res) -&gt; { /* handler */ }) custom method .anyOf(Set.of(Http.RequestMethod.create(\"CUSTOM\")), (req, res) -&gt; { /* handler */ }) ",
            "title": "HTTP Method Routing"
        },
        {
            "location": "se/webserver",
            "text": " You can combine HTTP method routing with request path matching. <markup lang=\"java\" >Routing.builder() .post(\"/some/path\", (req, res) -&gt; { /* handler */ }) You can use path pattern instead of path with the following syntax: /foo/bar/baz - Exact path match against resolved path even with non-usual characters /foo/{}/baz - {} Unnamed regular expression segment ([^/]+) /foo/{var}/baz - Named regular expression segment ([^/]+) /foo/{var:\\d+} - Named regular expression segment with a specified expression /foo/{:\\d+} - Unnamed regular expression segment with a specified expression /foo/{+var} - Convenience shortcut for {var:.+}. A matcher is not a true URI template (as defined by RFC) but this convenience is in sync with the Apiary templates /foo/{+} - Convenience shortcut for unnamed segment with regular expression {:.+} /foo[/bar] - An optional block, which translates to the /foo(/bar)? regular expression / or /foo - * Wildcard character can be matched with any number of characters. Path (matcher) routing is exact . For example, a /foo/bar request is not routed to .post('/foo', &#8230;&#8203;) . Always start path and path patterns with the / character. ",
            "title": "Path Matcher Routing"
        },
        {
            "location": "se/webserver",
            "text": " Use the RequestPredicate utility class to identify more criteria. You can construct (build) a predicate based on typical request criteria such as content type, or the existence of a header or cookie. You can also construct a handler that only processes requests accepted by the predicate. All other requests are nexted , meaning that they are routed to the next valid handler. <markup lang=\"java\" >.post(\"/foo\", RequestPredicate.create() .containsHeader(\"my-gr8-header\") .accepts(MediaType.TEXT_PLAIN) .and(this::isUserAuthenticated) .thenApply((req, resp) -&gt; { // Some logic }) .otherwise((req, resp) -&gt; { /* Otherwise logic */ }); // Optional. Default logic is req.next() ",
            "title": "Request Predicate"
        },
        {
            "location": "se/webserver",
            "text": " By implementing the Service interface you can organize your code into one or more services, each with its own path prefix and set of handlers. <markup lang=\"java\" title=\"Use Routing.Builder.register to register your service\" >.register(\"/hello\", new HelloService()) <markup lang=\"java\" title=\"Service implementation\" >public class HelloService implements Service { @Override public void update(Routing.Rules rules) { rules.get(\"/subpath\", this::getHandler); } private void getHandler(ServerRequest request, ServerResponse response) { // Some logic } } In this example, the GET handler matches requests to /hello/subpath . ",
            "title": "Organizing Code into Services"
        },
        {
            "location": "se/webserver",
            "text": " Routing lets you use request matching criteria to bind requests to a handler that implements your custom business logic. Matching criteria include one or more HTTP Method(s) and, optionally, a request path matcher . Use the RequestPredicate class to specify more routing criteria. Basics Routing also supports Error Routing which binds Java Throwable to the handling logic. Configure HTTP request routing using Routing.Builder . <markup lang=\"java\" title=\"Using Routing.Builder to specify how HTTP requests are handled\" >Routing routing = Routing.builder() .get(\"/hello\", (req, res) -&gt; res.send(\"Hello World!\")) .build(); WebServer webServer = WebServer.create(routing); Handle all GETs to /hello path. Send the Hello World! string. Add the routing to the WebServer. HTTP Method Routing Routing.Builder lets you specify how to handle each HTTP method. For example: <div class=\"table__overflow elevation-1 flex sm7 \"> HTTP Method Routing.Builder example GET .get((req, res) -&gt; { /* handler */ }) PUT .put((req, res) -&gt; { /* handler */ }) POST .post((req, res) -&gt; { /* handler */ }) HEAD .head((req, res) -&gt; { /* handler */ }) DELETE .delete((req, res) -&gt; { /* handler */ }) TRACE .trace((req, res) -&gt; { /* handler */ }) OPTIONS .options((req, res) -&gt; { /* handler */ }) any method .any((req, res) -&gt; { /* handler */ }) multiple methods .anyOf(List.of(Http.Method.GET, Http.Method.POST), (req, res) -&gt; { /* handler */ }) custom method .anyOf(Set.of(Http.RequestMethod.create(\"CUSTOM\")), (req, res) -&gt; { /* handler */ }) Path Matcher Routing You can combine HTTP method routing with request path matching. <markup lang=\"java\" >Routing.builder() .post(\"/some/path\", (req, res) -&gt; { /* handler */ }) You can use path pattern instead of path with the following syntax: /foo/bar/baz - Exact path match against resolved path even with non-usual characters /foo/{}/baz - {} Unnamed regular expression segment ([^/]+) /foo/{var}/baz - Named regular expression segment ([^/]+) /foo/{var:\\d+} - Named regular expression segment with a specified expression /foo/{:\\d+} - Unnamed regular expression segment with a specified expression /foo/{+var} - Convenience shortcut for {var:.+}. A matcher is not a true URI template (as defined by RFC) but this convenience is in sync with the Apiary templates /foo/{+} - Convenience shortcut for unnamed segment with regular expression {:.+} /foo[/bar] - An optional block, which translates to the /foo(/bar)? regular expression / or /foo - * Wildcard character can be matched with any number of characters. Path (matcher) routing is exact . For example, a /foo/bar request is not routed to .post('/foo', &#8230;&#8203;) . Always start path and path patterns with the / character. Request Predicate Use the RequestPredicate utility class to identify more criteria. You can construct (build) a predicate based on typical request criteria such as content type, or the existence of a header or cookie. You can also construct a handler that only processes requests accepted by the predicate. All other requests are nexted , meaning that they are routed to the next valid handler. <markup lang=\"java\" >.post(\"/foo\", RequestPredicate.create() .containsHeader(\"my-gr8-header\") .accepts(MediaType.TEXT_PLAIN) .and(this::isUserAuthenticated) .thenApply((req, resp) -&gt; { // Some logic }) .otherwise((req, resp) -&gt; { /* Otherwise logic */ }); // Optional. Default logic is req.next() Organizing Code into Services By implementing the Service interface you can organize your code into one or more services, each with its own path prefix and set of handlers. <markup lang=\"java\" title=\"Use Routing.Builder.register to register your service\" >.register(\"/hello\", new HelloService()) <markup lang=\"java\" title=\"Service implementation\" >public class HelloService implements Service { @Override public void update(Routing.Rules rules) { rules.get(\"/subpath\", this::getHandler); } private void getHandler(ServerRequest request, ServerResponse response) { // Some logic } } In this example, the GET handler matches requests to /hello/subpath . ",
            "title": "Routing"
        },
        {
            "location": "se/webserver",
            "text": " Each Handler has two parameters. ServerRequest and ServerResponse . Request provides access to the request method, URI, path, query parameters, headers and entity. Response provides an ability to set response code, headers, and entity. ",
            "title": "Process Request and Produce Response"
        },
        {
            "location": "se/webserver",
            "text": " The handler forwards the request to the downstream handlers by nexting . There are two options: call req.next() <markup lang=\"java\" >.any(\"/hello\", (req, res) -&gt; { // filtering logic req.next(); }) handler for any HTTP method using the /hello path business logic implementation forward the current request to the downstream handler call req.next(throwable) to forward the handling to the error handling <markup lang=\"java\" >.any(\"/hello\", (req, res) -&gt; { // filtering logic (e.g., validating parameters) if (userParametersOk()) { req.next(); } else { req.next(new IllegalArgumentException(\"Invalid parameters.\"); } }) handler for any HTTP method using the /hello path custom logic forward the current request to the downstream handler forward the request to the error handler The handling logic can explicitly forward the execution to a different thread. This is the reason why returning from the handler can&#8217;t automatically trigger calling the next handler. ",
            "title": "Handler as a Filter"
        },
        {
            "location": "se/webserver",
            "text": " To complete the request handling, you must send a response by calling the res.send() method. <markup lang=\"java\" >.get(\"/hello\", (req, res) -&gt; { // terminating logic res.status(Http.Status.ACCEPTED_201); res.send(\"Saved!\"); }) handler that terminates the request handling for any HTTP method using the /hello path send the response ",
            "title": "Sending a response"
        },
        {
            "location": "se/webserver",
            "text": " Implement the logic to handle requests to WebServer in a Handler , which is a FunctionalInterface . Handlers: Process the request and send a response. Act as a filter and forward requests to downstream handlers using the request.next() method. Throw an exception or call request.next(exception) to begin error handling . Process Request and Produce Response Each Handler has two parameters. ServerRequest and ServerResponse . Request provides access to the request method, URI, path, query parameters, headers and entity. Response provides an ability to set response code, headers, and entity. Handler as a Filter The handler forwards the request to the downstream handlers by nexting . There are two options: call req.next() <markup lang=\"java\" >.any(\"/hello\", (req, res) -&gt; { // filtering logic req.next(); }) handler for any HTTP method using the /hello path business logic implementation forward the current request to the downstream handler call req.next(throwable) to forward the handling to the error handling <markup lang=\"java\" >.any(\"/hello\", (req, res) -&gt; { // filtering logic (e.g., validating parameters) if (userParametersOk()) { req.next(); } else { req.next(new IllegalArgumentException(\"Invalid parameters.\"); } }) handler for any HTTP method using the /hello path custom logic forward the current request to the downstream handler forward the request to the error handler The handling logic can explicitly forward the execution to a different thread. This is the reason why returning from the handler can&#8217;t automatically trigger calling the next handler. Sending a response To complete the request handling, you must send a response by calling the res.send() method. <markup lang=\"java\" >.get(\"/hello\", (req, res) -&gt; { // terminating logic res.status(Http.Status.ACCEPTED_201); res.send(\"Saved!\"); }) handler that terminates the request handling for any HTTP method using the /hello path send the response ",
            "title": "Request Handling"
        },
        {
            "location": "se/webserver",
            "text": " Handling routes based on the protocol version is possible by registering specific routes on routing builder. <markup lang=\"java\" title=\"Routing based on HTTP version\" >.routing(r -&gt; r .get(\"/any-version\", (req, res) -&gt; res.send(\"HTTP Version \" + req.version())) .route(Http1Route.route(GET, \"/version-specific\", (req, res) -&gt; res.send(\"HTTP/1.1 route\"))) .route(Http2Route.route(GET, \"/version-specific\", (req, res) -&gt; res.send(\"HTTP/2 route\"))) ) While Http1Route for Http/1 is always available with Helidon webserver, other routes like Http2Route for HTTP/2 needs to be added as additional dependency. ",
            "title": "Protocol Specific Routing"
        },
        {
            "location": "se/webserver",
            "text": " You may register an error handler for a specific Throwable in the Routing.Builder method. <markup lang=\"java\" >Routing routing = Routing.builder() .error(MyException.class, (req, res, ex) -&gt; { // handle the error, set the HTTP status code res.send(errorDescriptionObject); }) .build Registers an error handler that handles MyException that are thrown from the upstream handlers Finishes the request handling by sending a response Error handlers are called when an exception is thrown from a handler req.next(ex) is called, where ex is an instance of Throwable As with the standard handlers, the error handler must either send a response <markup lang=\"java\" >.error(MyException.class, (req, res, ex) -&gt; { res.status(Http.Status.BAD_REQUEST_400); res.send(\"Unable to parse request. Message: \" + ex.getMessage()); }) or, forward the error handling to the downstream error handlers <markup lang=\"java\" >.error(Throwable.class, (req, res, ex) -&gt; { // some logic req.next(ex); }) Error handling can&#8217;t be forwarded to the standard handlers. In fact, invoking req.next(ex) or req.next() in an error handler are equivalent. <markup lang=\"java\" >.error(Throwable.class, (req, res, ex) -&gt; { if (condition) { req.next(ex); } else { req.next(); } }) Call a downstream error handler with the Throwable instance. Here, req.next() is the same as req.next(ex) . In both cases, the downstream error handler is called. ",
            "title": "Error Routing"
        },
        {
            "location": "se/webserver",
            "text": " If no user-defined error handler is matched, or if the last error handler of the exception called req.next() , then the exception is translated to an HTTP response as follows: Subtypes of HttpException are translated to their associated HTTP error codes. <markup lang=\"java\" title=\"Reply with the 406 HTTP error code by throwing an exception\" >(req, res) -&gt; throw new HttpException(\"Amount of money must be greater than 0.\", Http.Status.NOT_ACCEPTABLE_406) Otherwise, the exceptions are translated to an Internal Server Error HTTP error code 500 . ",
            "title": "Default error handling"
        },
        {
            "location": "se/webserver",
            "text": " Error Routing You may register an error handler for a specific Throwable in the Routing.Builder method. <markup lang=\"java\" >Routing routing = Routing.builder() .error(MyException.class, (req, res, ex) -&gt; { // handle the error, set the HTTP status code res.send(errorDescriptionObject); }) .build Registers an error handler that handles MyException that are thrown from the upstream handlers Finishes the request handling by sending a response Error handlers are called when an exception is thrown from a handler req.next(ex) is called, where ex is an instance of Throwable As with the standard handlers, the error handler must either send a response <markup lang=\"java\" >.error(MyException.class, (req, res, ex) -&gt; { res.status(Http.Status.BAD_REQUEST_400); res.send(\"Unable to parse request. Message: \" + ex.getMessage()); }) or, forward the error handling to the downstream error handlers <markup lang=\"java\" >.error(Throwable.class, (req, res, ex) -&gt; { // some logic req.next(ex); }) Error handling can&#8217;t be forwarded to the standard handlers. In fact, invoking req.next(ex) or req.next() in an error handler are equivalent. <markup lang=\"java\" >.error(Throwable.class, (req, res, ex) -&gt; { if (condition) { req.next(ex); } else { req.next(); } }) Call a downstream error handler with the Throwable instance. Here, req.next() is the same as req.next(ex) . In both cases, the downstream error handler is called. Default error handling If no user-defined error handler is matched, or if the last error handler of the exception called req.next() , then the exception is translated to an HTTP response as follows: Subtypes of HttpException are translated to their associated HTTP error codes. <markup lang=\"java\" title=\"Reply with the 406 HTTP error code by throwing an exception\" >(req, res) -&gt; throw new HttpException(\"Amount of money must be greater than 0.\", Http.Status.NOT_ACCEPTABLE_406) Otherwise, the exceptions are translated to an Internal Server Error HTTP error code 500 . ",
            "title": "Error Handling"
        },
        {
            "location": "se/webserver",
            "text": " To enable Http/2 support add the following dependency to your project&#8217;s pom.xml . <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webserver&lt;/groupId&gt; &lt;artifactId&gt;helidon-webserver-http2&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "se/webserver",
            "text": " Helidon supports HTTP/2 upgrade from HTTP/1, HTTP/2 without prior knowledge and HTTP/2 with ALPN over TLS. HTTP/2 support is enabled in webserver by default when it&#8217;s artifact is available on classpath. Maven Coordinates To enable Http/2 support add the following dependency to your project&#8217;s pom.xml . <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webserver&lt;/groupId&gt; &lt;artifactId&gt;helidon-webserver-http2&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "HTTP/2 Support"
        },
        {
            "location": "se/webserver",
            "text": " To enable Static Content Support add the following dependency to your project&#8217;s pom.xml . <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webserver&lt;/groupId&gt; &lt;artifactId&gt;helidon-webserver-static-content&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "se/webserver",
            "text": " To register static content based on a file system ( /pictures ), and classpath ( / ): <markup lang=\"java\" >Routing.builder() .register(\"/pictures\", StaticContentSupport.create(Paths.get(\"/some/WEB/pics\"))) .register(\"/\", StaticContentSupport.builder(\"/static-content\") .welcomeFileName(\"index.html\") .build()); Create a new StaticContentSupport object to serve data from the file system, and associate it with the \"/pictures\" context path. Create a StaticContentSupport object to serve resources from the contextual ClassLoader . The specific classloader can be also defined. A builder lets you provide more configuration values. index.html is the file that is returned if a directory is requested. A StaticContentSupport object can be created using create(&#8230;&#8203;) factory methods or a builder . The builder lets you provide more configuration values, including welcome file-name and mappings of filename extensions to media types. ",
            "title": "Registering Static Content"
        },
        {
            "location": "se/webserver",
            "text": " Use the io.helidon.webserver.staticcontent.StaticContentSupport class to serve files and classpath resources. StaticContentSupport can be created for any readable directory or classpath context root and registered on a path in Routing . You can combine dynamic handlers with StaticContentSupport objects: if no file matches the request path, then the request is forwarded to the next handler. Maven Coordinates To enable Static Content Support add the following dependency to your project&#8217;s pom.xml . <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webserver&lt;/groupId&gt; &lt;artifactId&gt;helidon-webserver-static-content&lt;/artifactId&gt; &lt;/dependency&gt; Registering Static Content To register static content based on a file system ( /pictures ), and classpath ( / ): <markup lang=\"java\" >Routing.builder() .register(\"/pictures\", StaticContentSupport.create(Paths.get(\"/some/WEB/pics\"))) .register(\"/\", StaticContentSupport.builder(\"/static-content\") .welcomeFileName(\"index.html\") .build()); Create a new StaticContentSupport object to serve data from the file system, and associate it with the \"/pictures\" context path. Create a StaticContentSupport object to serve resources from the contextual ClassLoader . The specific classloader can be also defined. A builder lets you provide more configuration values. index.html is the file that is returned if a directory is requested. A StaticContentSupport object can be created using create(&#8230;&#8203;) factory methods or a builder . The builder lets you provide more configuration values, including welcome file-name and mappings of filename extensions to media types. ",
            "title": "Static Content Support"
        },
        {
            "location": "se/webserver",
            "text": " To enable Jersey (JAX-RS) Support add the following dependency to your project&#8217;s pom.xml . <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webserver&lt;/groupId&gt; &lt;artifactId&gt;helidon-webserver-jersey&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "se/webserver",
            "text": " You can also register the JAX-RS Application object. <markup lang=\"java\" title=\"Register the HelloWorld resource\" >Routing.builder() .register(\"/jersey\", JerseySupport.builder(new MyApplication()) .build()) .build(); Register the Jersey application at /jersey context root MyApplication handles requests made to /jersey context root. ",
            "title": "Registering a JAX-RS Application"
        },
        {
            "location": "se/webserver",
            "text": " You can inject WebServer request and response objects into your JAX-RS application using @Context . <markup lang=\"java\" title=\"Injection of WebServer internal objects\" >@Path(\"/\") @RequestScoped public class HelloWorld { @Context private ServerRequest request; @Context private ServerResponse response; } ",
            "title": "Accessing WebServer Internals from a JAX-RS Application"
        },
        {
            "location": "se/webserver",
            "text": " To register a Jersey application at a context root, use the JerseySupport class and its JerseySupport.Builder builder. JerseySupport can register the JAX-RS resources directly. <markup lang=\"java\" title=\"Jersey (JAX-RS) HelloWorld resource\" >@Path(\"/\") public class HelloWorld { @GET @Path(\"hello\") public Response hello() { return Response.ok(\"Hello World!\").build(); } } <markup lang=\"java\" title=\"Registering the HelloWorld resource\" >Routing.builder() .register(\"/jersey\", JerseySupport.builder() .register(HelloWorld.class) .build()) .build(); Register the Jersey application at /jersey context root The Jersey Application stays hidden and consists of a single HelloWorld resource class As a result, an HTTP GET request to /jersey/hello would yield a Hello World! response string. Registering a JAX-RS Application You can also register the JAX-RS Application object. <markup lang=\"java\" title=\"Register the HelloWorld resource\" >Routing.builder() .register(\"/jersey\", JerseySupport.builder(new MyApplication()) .build()) .build(); Register the Jersey application at /jersey context root MyApplication handles requests made to /jersey context root. Accessing WebServer Internals from a JAX-RS Application You can inject WebServer request and response objects into your JAX-RS application using @Context . <markup lang=\"java\" title=\"Injection of WebServer internal objects\" >@Path(\"/\") @RequestScoped public class HelloWorld { @Context private ServerRequest request; @Context private ServerResponse response; } ",
            "title": "Registering a Jersey Application"
        },
        {
            "location": "se/webserver",
            "text": " You can register a Jersey (JAX-RS) application at a context root using the JerseySupport class. Registering a Jersey Application To register a Jersey application at a context root, use the JerseySupport class and its JerseySupport.Builder builder. JerseySupport can register the JAX-RS resources directly. <markup lang=\"java\" title=\"Jersey (JAX-RS) HelloWorld resource\" >@Path(\"/\") public class HelloWorld { @GET @Path(\"hello\") public Response hello() { return Response.ok(\"Hello World!\").build(); } } <markup lang=\"java\" title=\"Registering the HelloWorld resource\" >Routing.builder() .register(\"/jersey\", JerseySupport.builder() .register(HelloWorld.class) .build()) .build(); Register the Jersey application at /jersey context root The Jersey Application stays hidden and consists of a single HelloWorld resource class As a result, an HTTP GET request to /jersey/hello would yield a Hello World! response string. Registering a JAX-RS Application You can also register the JAX-RS Application object. <markup lang=\"java\" title=\"Register the HelloWorld resource\" >Routing.builder() .register(\"/jersey\", JerseySupport.builder(new MyApplication()) .build()) .build(); Register the Jersey application at /jersey context root MyApplication handles requests made to /jersey context root. Accessing WebServer Internals from a JAX-RS Application You can inject WebServer request and response objects into your JAX-RS application using @Context . <markup lang=\"java\" title=\"Injection of WebServer internal objects\" >@Path(\"/\") @RequestScoped public class HelloWorld { @Context private ServerRequest request; @Context private ServerResponse response; } ",
            "title": "JAX-RS Support"
        },
        {
            "location": "se/webserver",
            "text": " Maven Coordinates To enable Jersey (JAX-RS) Support add the following dependency to your project&#8217;s pom.xml . <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webserver&lt;/groupId&gt; &lt;artifactId&gt;helidon-webserver-jersey&lt;/artifactId&gt; &lt;/dependency&gt; JAX-RS Support You can register a Jersey (JAX-RS) application at a context root using the JerseySupport class. Registering a Jersey Application To register a Jersey application at a context root, use the JerseySupport class and its JerseySupport.Builder builder. JerseySupport can register the JAX-RS resources directly. <markup lang=\"java\" title=\"Jersey (JAX-RS) HelloWorld resource\" >@Path(\"/\") public class HelloWorld { @GET @Path(\"hello\") public Response hello() { return Response.ok(\"Hello World!\").build(); } } <markup lang=\"java\" title=\"Registering the HelloWorld resource\" >Routing.builder() .register(\"/jersey\", JerseySupport.builder() .register(HelloWorld.class) .build()) .build(); Register the Jersey application at /jersey context root The Jersey Application stays hidden and consists of a single HelloWorld resource class As a result, an HTTP GET request to /jersey/hello would yield a Hello World! response string. Registering a JAX-RS Application You can also register the JAX-RS Application object. <markup lang=\"java\" title=\"Register the HelloWorld resource\" >Routing.builder() .register(\"/jersey\", JerseySupport.builder(new MyApplication()) .build()) .build(); Register the Jersey application at /jersey context root MyApplication handles requests made to /jersey context root. Accessing WebServer Internals from a JAX-RS Application You can inject WebServer request and response objects into your JAX-RS application using @Context . <markup lang=\"java\" title=\"Injection of WebServer internal objects\" >@Path(\"/\") @RequestScoped public class HelloWorld { @Context private ServerRequest request; @Context private ServerResponse response; } ",
            "title": "Jersey (JAX-RS) Support"
        },
        {
            "location": "se/webserver",
            "text": " To enable JSON Support add the following dependency to your project&#8217;s pom.xml . <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.media&lt;/groupId&gt; &lt;artifactId&gt;helidon-media-jsonp&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "se/webserver",
            "text": " To enable JSON-P support, first register it with the web server. Then you can add routes that handle and return JSON. <markup lang=\"java\" title=\"Configure JsonpSupport and use it for reading and writing of entities\" >JsonpSupport jsonbSupport = JsonpSupport.create(); WebServer webServer = WebServer.builder() .addMediaSupport(jsonpSupport) .build(); Register JsonpSupport to enable transformation from and to JsonObject objects Register that JsonpSupport instance to enable automatic deserialization of Java objects from and serialization of Java objects to JSON. <markup lang=\"java\" title=\"Handler that receives and returns JSON objects\" >private static final JsonBuilderFactory JSON_FACTORY = Json.createBuilderFactory(Collections.emptyMap()); private void sayHello(ServerRequest req, ServerResponse res, JsonObject json) { JsonObject msg = JSON_FACTORY.createObjectBuilder() .add(\"message\", \"Hello \" + json.getString(\"name\")) .build(); res.send(msg); } Using a JsonBuilderFactory is more efficient than Json.createObjectBuilder() JsonObject is passed to handler Create a JsonObject using JSON-P to hold return data Send JsonObject in response <markup lang=\"bash\" title=\"Example of posting JSON to sayHello endpoint\" >curl --noproxy '*' -X POST -H \"Content-Type: application/json\" \\ http://localhost:8080/sayhello -d '{\"name\":\"Joe\"}' <markup lang=\"json\" title=\"Response body\" >{\"message\":\"Hello Joe\"} ",
            "title": "Usage"
        },
        {
            "location": "se/webserver",
            "text": " To configure JSON-P JsonReaderFactory and JsonWriterFactory that are used by the JsonpSupport instance, create the JsonpSupport object: <markup lang=\"java\" title=\"Create JsonpSupport with the provided configuration\" >JsonpSupport.create(Map.of(JsonGenerator.PRETTY_PRINTING, false)); ",
            "title": "Configuring Json Reader/Writer factories"
        },
        {
            "location": "se/webserver",
            "text": " The WebServer supports JSON-P. When enabled, you can send and receive JSON-P objects transparently. Maven Coordinates To enable JSON Support add the following dependency to your project&#8217;s pom.xml . <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.media&lt;/groupId&gt; &lt;artifactId&gt;helidon-media-jsonp&lt;/artifactId&gt; &lt;/dependency&gt; Usage To enable JSON-P support, first register it with the web server. Then you can add routes that handle and return JSON. <markup lang=\"java\" title=\"Configure JsonpSupport and use it for reading and writing of entities\" >JsonpSupport jsonbSupport = JsonpSupport.create(); WebServer webServer = WebServer.builder() .addMediaSupport(jsonpSupport) .build(); Register JsonpSupport to enable transformation from and to JsonObject objects Register that JsonpSupport instance to enable automatic deserialization of Java objects from and serialization of Java objects to JSON. <markup lang=\"java\" title=\"Handler that receives and returns JSON objects\" >private static final JsonBuilderFactory JSON_FACTORY = Json.createBuilderFactory(Collections.emptyMap()); private void sayHello(ServerRequest req, ServerResponse res, JsonObject json) { JsonObject msg = JSON_FACTORY.createObjectBuilder() .add(\"message\", \"Hello \" + json.getString(\"name\")) .build(); res.send(msg); } Using a JsonBuilderFactory is more efficient than Json.createObjectBuilder() JsonObject is passed to handler Create a JsonObject using JSON-P to hold return data Send JsonObject in response <markup lang=\"bash\" title=\"Example of posting JSON to sayHello endpoint\" >curl --noproxy '*' -X POST -H \"Content-Type: application/json\" \\ http://localhost:8080/sayhello -d '{\"name\":\"Joe\"}' <markup lang=\"json\" title=\"Response body\" >{\"message\":\"Hello Joe\"} Configuring Json Reader/Writer factories To configure JSON-P JsonReaderFactory and JsonWriterFactory that are used by the JsonpSupport instance, create the JsonpSupport object: <markup lang=\"java\" title=\"Create JsonpSupport with the provided configuration\" >JsonpSupport.create(Map.of(JsonGenerator.PRETTY_PRINTING, false)); ",
            "title": "JSON Support"
        },
        {
            "location": "se/webserver",
            "text": " To enable JSON-B Support add the following dependency to your project&#8217;s pom.xml . <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.media&lt;/groupId&gt; &lt;artifactId&gt;helidon-media-jsonp&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "se/webserver",
            "text": " To enable JSON-B support, first create and register a JsonbSupport instance with a WebServer.Builder . <markup lang=\"java\" title=\"Registration of the JsonbSupport via WebServer \" >JsonbSupport jsonbSupport = JsonbSupport.create(); WebServer webServer = WebServer.builder() .addMediaSupport(jsonbSupport) .build(); Create a JsonbSupport instance. This instance may be reused freely. Register that JsonbSupport instance to enable automatic deserialization of Java objects from and serialization of Java objects to JSON. Now that automatic JSON serialization and deserialization facilities have been set up, you can register a Handler that works with Java objects instead of raw JSON. Deserialization from and serialization to JSON will be handled according to the JSON-B specification . Suppose you have a Person class that looks like this: <markup lang=\"java\" title=\"Hypothetical Person class\" >public class Person { private String name; public Person() { super(); } public String getName() { return this.name; } public void setName(final String name) { this.name = name; } } Then you can set up a Handler like this: <markup lang=\"java\" title=\"A Handler that works with Java objects instead of raw JSON\" >final Routing routing = routingBuilder.post(\"/echo\", Handler.create(Person.class, (req, res, person) -&gt; res.send(person)))) .build(); Set up a route for POST requests using the Routing.Builder#post(String, Handler&#8230;&#8203;) method Use the Handler#create(Class, Handler.EntityHandler) method to install a Handler.EntityHandler that works with Person instances. This Handler.EntityHandler consumes a Person instance ( person ) and simply echoes it back. Note that there is no working with raw JSON here. <markup lang=\"bash\" title=\"Example of posting JSON to the /echo endpoint\" >curl --noproxy '*' -X POST -H \"Content-Type: application/json\" \\ http://localhost:8080/echo -d '{\"name\":\"Joe\"}' {\"name\":\"Joe\"} ",
            "title": "Usage"
        },
        {
            "location": "se/webserver",
            "text": " The WebServer supports the JSON-B specification . When this support is enabled, Java objects will be serialized to and deserialized from JSON automatically using Yasson , an implementation of the JSON-B specification . Maven Coordinates To enable JSON-B Support add the following dependency to your project&#8217;s pom.xml . <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.media&lt;/groupId&gt; &lt;artifactId&gt;helidon-media-jsonp&lt;/artifactId&gt; &lt;/dependency&gt; Usage To enable JSON-B support, first create and register a JsonbSupport instance with a WebServer.Builder . <markup lang=\"java\" title=\"Registration of the JsonbSupport via WebServer \" >JsonbSupport jsonbSupport = JsonbSupport.create(); WebServer webServer = WebServer.builder() .addMediaSupport(jsonbSupport) .build(); Create a JsonbSupport instance. This instance may be reused freely. Register that JsonbSupport instance to enable automatic deserialization of Java objects from and serialization of Java objects to JSON. Now that automatic JSON serialization and deserialization facilities have been set up, you can register a Handler that works with Java objects instead of raw JSON. Deserialization from and serialization to JSON will be handled according to the JSON-B specification . Suppose you have a Person class that looks like this: <markup lang=\"java\" title=\"Hypothetical Person class\" >public class Person { private String name; public Person() { super(); } public String getName() { return this.name; } public void setName(final String name) { this.name = name; } } Then you can set up a Handler like this: <markup lang=\"java\" title=\"A Handler that works with Java objects instead of raw JSON\" >final Routing routing = routingBuilder.post(\"/echo\", Handler.create(Person.class, (req, res, person) -&gt; res.send(person)))) .build(); Set up a route for POST requests using the Routing.Builder#post(String, Handler&#8230;&#8203;) method Use the Handler#create(Class, Handler.EntityHandler) method to install a Handler.EntityHandler that works with Person instances. This Handler.EntityHandler consumes a Person instance ( person ) and simply echoes it back. Note that there is no working with raw JSON here. <markup lang=\"bash\" title=\"Example of posting JSON to the /echo endpoint\" >curl --noproxy '*' -X POST -H \"Content-Type: application/json\" \\ http://localhost:8080/echo -d '{\"name\":\"Joe\"}' {\"name\":\"Joe\"} ",
            "title": "JSON-B Support"
        },
        {
            "location": "se/webserver",
            "text": " To enable Jackson Support add the following dependency to your project&#8217;s pom.xml . <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.media&lt;/groupId&gt; &lt;artifactId&gt;helidon-media-jackson&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "se/webserver",
            "text": " To enable Jackson support, first create and register a JacksonSupport instance with a WebServer.Builder . <markup lang=\"java\" title=\"Registration of the JacksonSupport via WebServer \" >JacksonSupport jacksonSupport = JacksonSupport.create(); WebServer webServer = WebServer.builder() .addMediaSupport(jacksonSupport) .build(); Create a JacksonSupport instance. This instance may be reused freely. Register that JacksonSupport instance to enable automatic deserialization of Java objects from and serialization of Java objects to JSON. Now that automatic JSON serialization and deserialization facilities have been set up, you can register a Handler that works with Java objects instead of raw JSON. Deserialization from and serialization to JSON will be handled by Jackson . Suppose you have a Person class that looks like this: <markup lang=\"java\" title=\"Hypothetical Person class\" >public class Person { private String name; public Person() { super(); } public String getName() { return this.name; } public void setName(final String name) { this.name = name; } } Then you can set up a Handler like this: <markup lang=\"java\" title=\"A Handler that works with Java objects instead of raw JSON\" >final Routing routing = routingBuilder.post(\"/echo\", Handler.create(Person.class, (req, res, person) -&gt; res.send(person)))) .build(); Set up a route for POST requests using the Routing.Builder#post(String, Handler&#8230;&#8203;) method Use the Handler#create(Class, Handler.EntityHandler) method to install a Handler.EntityHandler that works with Person instances. This Handler.EntityHandler consumes a Person instance ( person ) and simply echoes it back. Note that there is no working with raw JSON here. <markup lang=\"bash\" title=\"Example of posting JSON to the /echo endpoint\" >curl --noproxy '*' -X POST -H \"Content-Type: application/json\" \\ http://localhost:8080/echo -d '{\"name\":\"Joe\"}' <markup lang=\"json\" title=\"Response body\" >{\"name\":\"Joe\"} ",
            "title": "Usage"
        },
        {
            "location": "se/webserver",
            "text": " The WebServer supports Jackson . When this support is enabled, Java objects will be serialized to and deserialized from JSON automatically using Jackson. Maven Coordinates To enable Jackson Support add the following dependency to your project&#8217;s pom.xml . <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.media&lt;/groupId&gt; &lt;artifactId&gt;helidon-media-jackson&lt;/artifactId&gt; &lt;/dependency&gt; Usage To enable Jackson support, first create and register a JacksonSupport instance with a WebServer.Builder . <markup lang=\"java\" title=\"Registration of the JacksonSupport via WebServer \" >JacksonSupport jacksonSupport = JacksonSupport.create(); WebServer webServer = WebServer.builder() .addMediaSupport(jacksonSupport) .build(); Create a JacksonSupport instance. This instance may be reused freely. Register that JacksonSupport instance to enable automatic deserialization of Java objects from and serialization of Java objects to JSON. Now that automatic JSON serialization and deserialization facilities have been set up, you can register a Handler that works with Java objects instead of raw JSON. Deserialization from and serialization to JSON will be handled by Jackson . Suppose you have a Person class that looks like this: <markup lang=\"java\" title=\"Hypothetical Person class\" >public class Person { private String name; public Person() { super(); } public String getName() { return this.name; } public void setName(final String name) { this.name = name; } } Then you can set up a Handler like this: <markup lang=\"java\" title=\"A Handler that works with Java objects instead of raw JSON\" >final Routing routing = routingBuilder.post(\"/echo\", Handler.create(Person.class, (req, res, person) -&gt; res.send(person)))) .build(); Set up a route for POST requests using the Routing.Builder#post(String, Handler&#8230;&#8203;) method Use the Handler#create(Class, Handler.EntityHandler) method to install a Handler.EntityHandler that works with Person instances. This Handler.EntityHandler consumes a Person instance ( person ) and simply echoes it back. Note that there is no working with raw JSON here. <markup lang=\"bash\" title=\"Example of posting JSON to the /echo endpoint\" >curl --noproxy '*' -X POST -H \"Content-Type: application/json\" \\ http://localhost:8080/echo -d '{\"name\":\"Joe\"}' <markup lang=\"json\" title=\"Response body\" >{\"name\":\"Joe\"} ",
            "title": "Jackson Support"
        },
        {
            "location": "se/webserver",
            "text": " Access log is configured in your code by registering it as a service with Routing <markup lang=\"java\" >Routing.builder() .register(AccessLogSupport.create(config.get(\"server.access-log\"))) .get(\"/greet\", myService) The order of registration is significant - make sure AccessLogSupport is registered first (even before security, tracing etc.). ",
            "title": "Configuring Access Log in your code"
        },
        {
            "location": "se/webserver",
            "text": " Access log can be configured as follows: <markup lang=\"yaml\" title=\"Access Log configuration file\" >server: port: 8080 access-log: format: \"%h %l %u %t %r %s %b %{Referer}i\" All options shown above are also available programmatically when using builder. ",
            "title": "Configuring Access Log in a configuration file"
        },
        {
            "location": "se/webserver",
            "text": " The following configuration options can be defined: <div class=\"table__overflow elevation-1 flex sm10 \"> Config key Default value Builder method Description enabled true enabled(boolean) When this option is set to false , access logging will be disabled logger-name io.helidon.webserver.AccessLog loggerName(String) Name of the logger to use when writing log entries format helidon helidonLogFormat() , commonLogFormat() , add(AccessLogEntry entry) Configuration of access log output, when helidon is defined, the Helidon log format (see below) is used. Can be configured to explicitly define log entries (see below as well) exclude-paths N/A excludePaths(List&lt;String&gt;) List of path patterns to exclude from access log. Path pattern syntax is as defined in io.helidon.webserver.PathMatcher . Can be used to exclude paths such as /health or /metrics to avoid cluttering log. ",
            "title": "Configuration Options"
        },
        {
            "location": "se/webserver",
            "text": " The following log entries are supported in Helidon: <div class=\"table__overflow elevation-1 flex sm7 \"> Config format Class (to use with builder) Description %h HostLogEntry IP address of the remote host %l UserIdLogEntry Client identity, always undefined in Helidon %u UserLogEntry The username of logged-in user (when Security is used) %t TimestampLogEntry The current timestamp %r RequestLineLogEntry The request line (method, path and HTTP version) %s StatusLogEntry The HTTP status returned to the client %b SizeLogEntry The response entity size (if available) %D TimeTakenLogEntry The time taken in microseconds %T TimeTakenLogEntry The time taken in seconds %{ header-name }i HeaderLogEntry Value of a header (can have multiple such specification to write multiple headers) Currently we only support the entries defined above, with NO support for free text. ",
            "title": "Supported Log Entries"
        },
        {
            "location": "se/webserver",
            "text": " When format is set to helidon , the format used is: \"%h %u %t %r %s %b %D\" The entries logged: IP Address Username of a logged-in user Timestamp Request Line HTTP Status code Entity size Time taken (microseconds) Access log example: <markup lang=\"listing\" >192.168.0.104 - [18/Jun/2019:22:28:55 +0200] \"GET /greet/test HTTP/1.1\" 200 53 0:0:0:0:0:0:0:1 - [18/Jun/2019:22:29:00 +0200] \"GET /metrics/vendor HTTP/1.1\" 200 1658 0:0:0:0:0:0:0:1 jack [18/Jun/2019:22:29:07 +0200] \"PUT /greet/greeting HTTP/1.1\" 200 21 0:0:0:0:0:0:0:1 jill [18/Jun/2019:22:29:12 +0200] \"PUT /greet/greeting HTTP/1.1\" 403 0 0:0:0:0:0:0:0:1 - [18/Jun/2019:22:29:17 +0200] \"PUT /greet/greeting HTTP/1.1\" 401 0 ",
            "title": "Helidon Log Format"
        },
        {
            "location": "se/webserver",
            "text": " Supported Log Entries The following log entries are supported in Helidon: <div class=\"table__overflow elevation-1 flex sm7 \"> Config format Class (to use with builder) Description %h HostLogEntry IP address of the remote host %l UserIdLogEntry Client identity, always undefined in Helidon %u UserLogEntry The username of logged-in user (when Security is used) %t TimestampLogEntry The current timestamp %r RequestLineLogEntry The request line (method, path and HTTP version) %s StatusLogEntry The HTTP status returned to the client %b SizeLogEntry The response entity size (if available) %D TimeTakenLogEntry The time taken in microseconds %T TimeTakenLogEntry The time taken in seconds %{ header-name }i HeaderLogEntry Value of a header (can have multiple such specification to write multiple headers) Currently we only support the entries defined above, with NO support for free text. Helidon Log Format When format is set to helidon , the format used is: \"%h %u %t %r %s %b %D\" The entries logged: IP Address Username of a logged-in user Timestamp Request Line HTTP Status code Entity size Time taken (microseconds) Access log example: <markup lang=\"listing\" >192.168.0.104 - [18/Jun/2019:22:28:55 +0200] \"GET /greet/test HTTP/1.1\" 200 53 0:0:0:0:0:0:0:1 - [18/Jun/2019:22:29:00 +0200] \"GET /metrics/vendor HTTP/1.1\" 200 1658 0:0:0:0:0:0:0:1 jack [18/Jun/2019:22:29:07 +0200] \"PUT /greet/greeting HTTP/1.1\" 200 21 0:0:0:0:0:0:0:1 jill [18/Jun/2019:22:29:12 +0200] \"PUT /greet/greeting HTTP/1.1\" 403 0 0:0:0:0:0:0:0:1 - [18/Jun/2019:22:29:17 +0200] \"PUT /greet/greeting HTTP/1.1\" 401 0 ",
            "title": "Supported Log Formats"
        },
        {
            "location": "se/webserver",
            "text": " Access logging in Helidon is done by a dedicated module that can be added to WebServer and configured. Access logging is a Helidon WebServer Service and as such is executed in the order it is registered with WebServer routing. This implies that if you register it last and another Service or Handler finishes the request, the service will not be invoked. To enable Access logging add the following dependency to project&#8217;s pom.xml : <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webserver&lt;/groupId&gt; &lt;artifactId&gt;helidon-webserver-access-log&lt;/artifactId&gt; &lt;/dependency&gt; Configuring Access Log in your code Access log is configured in your code by registering it as a service with Routing <markup lang=\"java\" >Routing.builder() .register(AccessLogSupport.create(config.get(\"server.access-log\"))) .get(\"/greet\", myService) The order of registration is significant - make sure AccessLogSupport is registered first (even before security, tracing etc.). Configuring Access Log in a configuration file Access log can be configured as follows: <markup lang=\"yaml\" title=\"Access Log configuration file\" >server: port: 8080 access-log: format: \"%h %l %u %t %r %s %b %{Referer}i\" All options shown above are also available programmatically when using builder. Configuration Options The following configuration options can be defined: <div class=\"table__overflow elevation-1 flex sm10 \"> Config key Default value Builder method Description enabled true enabled(boolean) When this option is set to false , access logging will be disabled logger-name io.helidon.webserver.AccessLog loggerName(String) Name of the logger to use when writing log entries format helidon helidonLogFormat() , commonLogFormat() , add(AccessLogEntry entry) Configuration of access log output, when helidon is defined, the Helidon log format (see below) is used. Can be configured to explicitly define log entries (see below as well) exclude-paths N/A excludePaths(List&lt;String&gt;) List of path patterns to exclude from access log. Path pattern syntax is as defined in io.helidon.webserver.PathMatcher . Can be used to exclude paths such as /health or /metrics to avoid cluttering log. Supported Log Formats Supported Log Entries The following log entries are supported in Helidon: <div class=\"table__overflow elevation-1 flex sm7 \"> Config format Class (to use with builder) Description %h HostLogEntry IP address of the remote host %l UserIdLogEntry Client identity, always undefined in Helidon %u UserLogEntry The username of logged-in user (when Security is used) %t TimestampLogEntry The current timestamp %r RequestLineLogEntry The request line (method, path and HTTP version) %s StatusLogEntry The HTTP status returned to the client %b SizeLogEntry The response entity size (if available) %D TimeTakenLogEntry The time taken in microseconds %T TimeTakenLogEntry The time taken in seconds %{ header-name }i HeaderLogEntry Value of a header (can have multiple such specification to write multiple headers) Currently we only support the entries defined above, with NO support for free text. Helidon Log Format When format is set to helidon , the format used is: \"%h %u %t %r %s %b %D\" The entries logged: IP Address Username of a logged-in user Timestamp Request Line HTTP Status code Entity size Time taken (microseconds) Access log example: <markup lang=\"listing\" >192.168.0.104 - [18/Jun/2019:22:28:55 +0200] \"GET /greet/test HTTP/1.1\" 200 53 0:0:0:0:0:0:0:1 - [18/Jun/2019:22:29:00 +0200] \"GET /metrics/vendor HTTP/1.1\" 200 1658 0:0:0:0:0:0:0:1 jack [18/Jun/2019:22:29:07 +0200] \"PUT /greet/greeting HTTP/1.1\" 200 21 0:0:0:0:0:0:0:1 jill [18/Jun/2019:22:29:12 +0200] \"PUT /greet/greeting HTTP/1.1\" 403 0 0:0:0:0:0:0:0:1 - [18/Jun/2019:22:29:17 +0200] \"PUT /greet/greeting HTTP/1.1\" 401 0 ",
            "title": "Access Log"
        },
        {
            "location": "se/webserver",
            "text": " To configure TLS in WebServer programmatically create your keystore configuration and pass it to the WebServer builder. <markup lang=\"java\" >KeyConfig keyConfig = KeyConfig.keystoreBuilder() //Whether this keystore is also trust store .trustStore() //Keystore location/name .keystore(Resource.create(\"keystore.p12\")) //Password to the keystore .keystorePassphrase(\"password\") .build(); WebServer.builder() .tls(WebServerTls.builder() .trust(keyConfig) .privateKey(keyConfig) .build()) .build(); ",
            "title": "Configuring TLS in your code"
        },
        {
            "location": "se/webserver",
            "text": " It is also possible to configure TLS via the config file. <markup lang=\"yaml\" title=\"WebServer TLS configuration file application.yaml \" >server: tls: #Truststore setup trust: keystore: passphrase: \"password\" trust-store: true resource: resource-path: \"keystore.p12\" #Keystore with private key and server certificate private-key: keystore: passphrase: \"password\" resource: resource-path: \"keystore.p12\" Then, in your application code, load the configuration from that file. <markup lang=\"java\" title=\"WebServer initialization using the application.yaml file located on the classpath\" >Config config = Config.create(); WebServer webClient = WebServer.create(routing, config.get(\"server\")); Or you can only create WebServerTls instance based on the config file. <markup lang=\"java\" title=\"WebServerTls instance based on application.yaml file located on the classpath\" >Config config = Config.create(); WebServerTls.builder() .config(config.get(\"server.tls\")) .build(); This can alternatively be configured with paths to PKCS#8 PEM files rather than KeyStores: <markup lang=\"yaml\" title=\"WebServer TLS configuration file application.yaml \" >server: tls: #Truststore setup trust: pem: certificates: resource: resource-path: \"ca-bundle.pem\" private-key: pem: key: resource: resource-path: \"key.pem\" cert-chain: resource: resource-path: \"chain.pem\" ",
            "title": "Configuring TLS in the config file"
        },
        {
            "location": "se/webserver",
            "text": " Required configuration options key type default value description private-key KeyConfig &#160; Configure private key to use for SSL context. Optional configuration options key type default value description cipher-suite string[&#93; &#160; Set allowed cipher suite. If an empty collection is set, an exception is thrown since it is required to support at least some ciphers. client-auth ClientAuthentication (REQUIRE, OPTIONAL, NONE) none Configures whether client authentication will be required or not. enabled boolean true Can be used to disable TLS even if keys are configured. session-cache-size long &#160; Set the size of the cache used for storing SSL session objects. 0 to use the default value. session-timeout-seconds long &#160; Set the timeout for the cached SSL session objects, in seconds. 0 to use the default value. trust KeyConfig &#160; Set the trust key configuration to be used to validate certificates. ",
            "title": "Configuration options"
        },
        {
            "location": "se/webserver",
            "text": " Type: io.helidon.webserver.WebServerTls Configuration options Required configuration options key type default value description private-key KeyConfig &#160; Configure private key to use for SSL context. Optional configuration options key type default value description cipher-suite string[&#93; &#160; Set allowed cipher suite. If an empty collection is set, an exception is thrown since it is required to support at least some ciphers. client-auth ClientAuthentication (REQUIRE, OPTIONAL, NONE) none Configures whether client authentication will be required or not. enabled boolean true Can be used to disable TLS even if keys are configured. session-cache-size long &#160; Set the size of the cache used for storing SSL session objects. 0 to use the default value. session-timeout-seconds long &#160; Set the timeout for the cached SSL session objects, in seconds. 0 to use the default value. trust KeyConfig &#160; Set the trust key configuration to be used to validate certificates. ",
            "title": "Configuration options"
        },
        {
            "location": "se/webserver",
            "text": " Configure TLS either programmatically, or by the Helidon configuration framework. Configuring TLS in your code To configure TLS in WebServer programmatically create your keystore configuration and pass it to the WebServer builder. <markup lang=\"java\" >KeyConfig keyConfig = KeyConfig.keystoreBuilder() //Whether this keystore is also trust store .trustStore() //Keystore location/name .keystore(Resource.create(\"keystore.p12\")) //Password to the keystore .keystorePassphrase(\"password\") .build(); WebServer.builder() .tls(WebServerTls.builder() .trust(keyConfig) .privateKey(keyConfig) .build()) .build(); Configuring TLS in the config file It is also possible to configure TLS via the config file. <markup lang=\"yaml\" title=\"WebServer TLS configuration file application.yaml \" >server: tls: #Truststore setup trust: keystore: passphrase: \"password\" trust-store: true resource: resource-path: \"keystore.p12\" #Keystore with private key and server certificate private-key: keystore: passphrase: \"password\" resource: resource-path: \"keystore.p12\" Then, in your application code, load the configuration from that file. <markup lang=\"java\" title=\"WebServer initialization using the application.yaml file located on the classpath\" >Config config = Config.create(); WebServer webClient = WebServer.create(routing, config.get(\"server\")); Or you can only create WebServerTls instance based on the config file. <markup lang=\"java\" title=\"WebServerTls instance based on application.yaml file located on the classpath\" >Config config = Config.create(); WebServerTls.builder() .config(config.get(\"server.tls\")) .build(); This can alternatively be configured with paths to PKCS#8 PEM files rather than KeyStores: <markup lang=\"yaml\" title=\"WebServer TLS configuration file application.yaml \" >server: tls: #Truststore setup trust: pem: certificates: resource: resource-path: \"ca-bundle.pem\" private-key: pem: key: resource: resource-path: \"key.pem\" cert-chain: resource: resource-path: \"chain.pem\" Configuration options Type: io.helidon.webserver.WebServerTls Configuration options Required configuration options key type default value description private-key KeyConfig &#160; Configure private key to use for SSL context. Optional configuration options key type default value description cipher-suite string[&#93; &#160; Set allowed cipher suite. If an empty collection is set, an exception is thrown since it is required to support at least some ciphers. client-auth ClientAuthentication (REQUIRE, OPTIONAL, NONE) none Configures whether client authentication will be required or not. enabled boolean true Can be used to disable TLS even if keys are configured. session-cache-size long &#160; Set the size of the cache used for storing SSL session objects. 0 to use the default value. session-timeout-seconds long &#160; Set the timeout for the cached SSL session objects, in seconds. 0 to use the default value. trust KeyConfig &#160; Set the trust key configuration to be used to validate certificates. ",
            "title": "TLS Configuration"
        },
        {
            "location": "se/webserver",
            "text": " HTTP compression in the Helidon WebServer is disabled by default. It can sometimes interfere with certain applications that use streaming, even if a compression encoding has not been negotiated with the client. It can be enabled either programmatically or via configuration, and it can also be enabled on a per-socket basis. When configured at the server level, it applies only to the default socket. Programmatically, simply use the enableCompression method during server creation: <markup lang=\"java\" >WebServer.builder() .port(8080) .routing(...) .enableCompression(true) // compression enabled .build() Or use a config file as follows and make sure the WebServer is created using it: <markup lang=\"yaml\" title=\"WebServer HTTP Compression configuration file application.yaml \" >server: port: 8080 enable-compression: true ",
            "title": "Configuring HTTP Compression"
        },
        {
            "location": "se/webserver",
            "text": " HTTP compression negotiation is controlled by clients using the Accept-Encoding header. The value of this header is a comma-separated list of encodings. The WebServer will select one of these encodings for compression purposes; it currently supports gzip and deflate . For example, if the request includes Accept-Encoding: gzip, deflate , and HTTP compression has been enabled as shown above, the response shall include the header Content-Encoding: gzip and a compressed payload. ",
            "title": "HTTP Compression Negotiation"
        },
        {
            "location": "se/webserver",
            "text": " HTTP compression can improve bandwidth utilization and transfer speeds in certain scenarios. It requires a few extra CPU cycles for compressing and uncompressing, but these can be offset if data is transferred over low-bandwidth network links. A client advertises the compression encodings it supports at request time, and the WebServer responds by selecting an encoding it supports and setting it in a header, effectively negotiating the content encoding of the response. If none of the advertised encodings is supported by the WebServer, the response is returned uncompressed. Configuring HTTP Compression HTTP compression in the Helidon WebServer is disabled by default. It can sometimes interfere with certain applications that use streaming, even if a compression encoding has not been negotiated with the client. It can be enabled either programmatically or via configuration, and it can also be enabled on a per-socket basis. When configured at the server level, it applies only to the default socket. Programmatically, simply use the enableCompression method during server creation: <markup lang=\"java\" >WebServer.builder() .port(8080) .routing(...) .enableCompression(true) // compression enabled .build() Or use a config file as follows and make sure the WebServer is created using it: <markup lang=\"yaml\" title=\"WebServer HTTP Compression configuration file application.yaml \" >server: port: 8080 enable-compression: true HTTP Compression Negotiation HTTP compression negotiation is controlled by clients using the Accept-Encoding header. The value of this header is a comma-separated list of encodings. The WebServer will select one of these encodings for compression purposes; it currently supports gzip and deflate . For example, if the request includes Accept-Encoding: gzip, deflate , and HTTP compression has been enabled as shown above, the response shall include the header Content-Encoding: gzip and a compressed payload. ",
            "title": "HTTP Compression"
        },
        {
            "location": "se/webserver",
            "text": " Here is the code for a minimalist web application that runs on a random free port: <markup lang=\"java\" >public static void main(String[] args) { WebServer webServer = WebServer .create(Routing.builder() .any((req, res) -&gt; res.send(\"It works!\"))) .start() .await(10, TimeUnit.SECONDS); System.out.println(\"Server started at: http://localhost:\" + webServer.port()); } For any kind of request, at any path, respond with It works! . Start the server. Wait for the server to start while throwing possible errors as runtime exceptions. The server is bound to a random free port. ",
            "title": "Additional Information"
        },
        {
            "location": "se/webserver",
            "text": " Helidon WebServer JavaDoc Helidon WebServer Static Content JavaDoc Helidon WebServer Jersey JavaDoc Helidon JSON-B Support JavaDoc Helidon JSON-P Support JavaDoc Helidon Jackson Support JavaDoc ",
            "title": "Reference"
        },
        {
            "location": "se/websocket",
            "text": " Overview Maven Coordinates Example Reference ",
            "title": "Contents"
        },
        {
            "location": "se/websocket",
            "text": " Helidon integrates with Tyrus to provide support for the Jakarta WebSocket API . The WebSocket API enables Java applications to participate in WebSocket interactions as both servers and clients. The server API supports two flavors: annotated and programmatic endpoints. Annotated endpoints, as suggested by their name, use Java annotations to provide the necessary meta-data to define WebSocket handlers; programmatic endpoints implement API interfaces and are annotation free. Annotated endpoints tend to be more flexible since they allow different method signatures depending on the application needs, whereas programmatic endpoints must implement an interface and are, therefore, bounded to its definition. Helidon SE support is based on the WebSocketRouting class which enables Helidon application to configure routing for both annotated and programmatic WebSocket endpoints. ",
            "title": "Overview"
        },
        {
            "location": "se/websocket",
            "text": " To enable {feature-name} add the following dependency to your project&#8217;s pom.xml (see Managing Dependencies ). <markup lang=\"xml\" >&lt;dependency&gt; &lt;groupId&gt;io.helidon.webserver&lt;/groupId&gt; &lt;artifactId&gt;helidon-webserver-websocket&lt;/artifactId&gt; &lt;/dependency&gt; ",
            "title": "Maven Coordinates"
        },
        {
            "location": "se/websocket",
            "text": " This section describes the implementation of a simple application that uses a REST resource to push messages into a shared queue and a programmatic WebSocket endpoint to download messages from the queue, one at a time, over a connection. The example will show how REST and WebSocket connections can be seamlessly combined into a Helidon application. The complete Helidon SE example is available here . Let us start by looking at MessageQueueService : <markup lang=\"java\" >public class MessageQueueService implements Service { private final MessageQueue messageQueue = MessageQueue.instance(); @Override public void update(Routing.Rules routingRules) { routingRules.post(\"/board\", this::handlePost); } private void handlePost(ServerRequest request, ServerResponse response) { request.content() .as(String.class) .thenAccept(it -&gt; { messageQueue.push(it); response.status(204).send(); }); } } This class exposes a REST resource where messages can be posted. Upon receiving a message, it simply pushes it into a shared queue and returns 204 (No Content). Messages pushed into the queue can be obtained by opening a WebSocket connection served by MessageBoardEndpoint : <markup lang=\"java\" >public class MessageBoardEndpoint extends Endpoint { private final MessageQueue messageQueue = MessageQueue.instance(); @Override public void onOpen(Session session, EndpointConfig endpointConfig) { session.addMessageHandler(new MessageHandler.Whole&lt;String&gt;() { @Override public void onMessage(String message) { try { // Send all messages in the queue if (message.equals(\"SEND\")) { while (!messageQueue.isEmpty()) { session.getBasicRemote().sendObject(messageQueue.pop()); } } } catch (Exception e) { // handle exception } } }); } } This is an example of a programmatic endpoint that extends Endpoint . The method onOpen will be invoked for every new connection. In this example, the application registers a message handler for strings, and when the special SEND message is received, it empties the shared queue sending messages one at a time over the WebSocket connection. In Helidon SE, REST and WebSocket classes need to be manually registered into the web server. This is accomplished via a Routing builder: <markup lang=\"java\" >List&lt;Class&lt;? extends Encoder&gt;&gt; encoders = Collections.singletonList(UppercaseEncoder.class); WebServer server = WebServer.builder() .port(8080) .routing(r -&gt; r .register(\"/web\", StaticContentSupport.builder(\"/WEB\") .welcomeFileName(\"index.html\") .build()) .register(\"/rest\", new MessageQueueService()) ) .addRouting(WebSocketRouting.builder() .endpoint(\"/websocket\", ServerEndpointConfig.Builder.create(MessageBoardEndpoint.class, \"/board\") .encoders(encoders) .build()) .build() ) .build() This code snippet uses multiple builders for Routing , WebSocketRouting and ServerEndpointConfig . In particular, it registers MessageBoardEndpoint.class at \"/websocket/board\" and associates with it a message encoder . For more information on message encoders and decoders the reader see the websocket specification ; in this example , UppercaseEncoder.class simply uppercases every message sent from the server. Endpoint methods in Helidon SE are executed in Netty&#8217;s worker thread pool. Threads in this pool are intended to be non-blocking , thus it is recommended for any blocking or long-running operation triggered by an endpoint method to be executed using a separate thread pool. See the documentation for io.helidon.common.configurable.ThreadPoolSupplier . ",
            "title": "Example"
        },
        {
            "location": "se/websocket",
            "text": " Helidon WebSocket JavaDoc Jakarta WebSocket Specification ",
            "title": "Reference"
        }
 ]
}
